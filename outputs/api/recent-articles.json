{
  "last_updated": "2025-09-23T22:13:03.769591+00:00",
  "count": 20,
  "articles": [
    {
      "id": "073f84c45a5f8620ebf995e438880746",
      "url": "https://arxiv.org/abs/2509.16779",
      "title": "Improving User Interface Generation Models from Designer Feedback",
      "content": "arXiv:2509.16779v1 Announce Type: new \nAbstract: Despite being trained on vast amounts of data, most LLMs are unable to reliably generate well-designed UIs. Designer feedback is essential to improving performance on UI generation; however, we find that existing RLHF methods based on ratings or rankings are not well-aligned with designers' workflows and ignore the rich rationale used to critique and improve UI designs. In this paper, we investigate several approaches for designers to give feedback to UI generation models, using familiar interactions such as commenting, sketching and direct manipulation. We first perform a study with 21 designers where they gave feedback using these interactions, which resulted in ~1500 design annotations. We then use this data to finetune a series of LLMs to generate higher quality UIs. Finally, we evaluate these models with human judges, and we find that our designer-aligned approaches outperform models trained with traditional ranking feedback and all tested baselines, including GPT-5.",
      "author": "Jason Wu, Amanda Swearngin, Arun Krishna Vajjala, Alan Leung, Jeffrey Nichols, Titus Barik",
      "published_date": "2025-09-23T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 153,
      "reading_time": 1,
      "created_at": "2025-09-23T21:37:43.595697+00:00",
      "updated_at": "2025-09-23T22:13:03.662082+00:00",
      "metadata": {
        "processed_at": "2025-09-23T22:13:03.662093+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "465a6608eba9a7a8a24c12ccd07bfbe3",
      "url": "https://arxiv.org/abs/2509.16778",
      "title": "Generative AI alone may not be enough: Evaluating AI Support for Learning Mathematical Proof",
      "content": "arXiv:2509.16778v1 Announce Type: new \nAbstract: We evaluate the effectiveness of LLM-Tutor, a large language model (LLM)-powered tutoring system that combines an AI-based proof-review tutor for real-time feedback on proof-writing and a chatbot for mathematics-related queries. Our experiment, involving 148 students, demonstrated that the use of LLM-Tutor significantly improved homework performance compared to a control group without access to the system. However, its impact on exam performance and time spent on tasks was found to be insignificant. Mediation analysis revealed that students with lower self-efficacy tended to use the chatbot more frequently, which partially contributed to lower midterm scores. Furthermore, students with lower self-efficacy were more likely to engage frequently with the proof-review-AI-tutor, a usage pattern that positively contributed to higher final exam scores. Interviews with 19 students highlighted the accessibility of LLM-Tutor and its effectiveness in addressing learning needs, while also revealing limitations and concerns regarding potential over-reliance on the tool. Our results suggest that generative AI alone like chatbot may not suffice for comprehensive learning support, underscoring the need for iterative design improvements with learning sciences principles with generative AI educational tools like LLM-Tutor.",
      "author": "Eason Chen, Sophia Judicke, Kayla Beigh, Xinyi Tang, Zimo Xiao, Chuangji Li, Shizhuo Li, Reed Luttmer, Shreya Singh, Maria Yampolsky, Naman Parikh, Yi Zhao, Meiyi Chen, Scarlett Huang, Anishka Mohanty, Gregory Johnson, John Mackey, Jionghao Lin, Ken Koedinger",
      "published_date": "2025-09-23T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 185,
      "reading_time": 1,
      "created_at": "2025-09-23T21:37:43.595668+00:00",
      "updated_at": "2025-09-23T22:13:03.662097+00:00",
      "metadata": {
        "processed_at": "2025-09-23T22:13:03.662099+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "f4797324b6774be2390fbcba716f6120",
      "url": "https://arxiv.org/abs/2509.16772",
      "title": "AI Knows Best? The Paradox of Expertise, AI-Reliance, and Performance in Educational Tutoring Decision-Making Tasks",
      "content": "arXiv:2509.16772v1 Announce Type: new \nAbstract: We present an empirical study of how both experienced tutors and non-tutors judge the correctness of tutor praise responses under different Artificial Intelligence (AI)-assisted interfaces, types of explanation (textual explanations vs. inline highlighting). We first fine-tuned several Large Language Models (LLMs) to produce binary correctness labels and explanations, achieving up to 88% accuracy and 0.92 F1 score with GPT-4. We then let the GPT-4 models assist 95 participants in tutoring decision-making tasks by offering different types of explanations. Our findings show that although human-AI collaboration outperforms humans alone in evaluating tutor responses, it remains less accurate than AI alone. Moreover, we find that non-tutors tend to follow the AI's advice more consistently, which boosts their overall accuracy on the task: especially when the AI is correct. In contrast, experienced tutors often override the AI's correct suggestions and thus miss out on potential gains from the AI's generally high baseline accuracy. Further analysis reveals that explanations in text reasoning will increase over-reliance and reduce underreliance, while inline highlighting does not. Moreover, neither explanation style actually has a significant effect on performance and costs participants more time to complete the task, instead of saving time. Our findings reveal a tension between expertise, explanation design, and efficiency in AI-assisted decision-making, highlighting the need for balanced approaches that foster more effective human-AI collaboration.",
      "author": "Eason Chen, Jeffrey Li, Scarlett Huang, Xinyi Tang, Jionghao Lin, Paulo Carvalho, Kenneth Koedinger",
      "published_date": "2025-09-23T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 224,
      "reading_time": 1,
      "created_at": "2025-09-23T21:37:43.595636+00:00",
      "updated_at": "2025-09-23T22:13:03.662102+00:00",
      "metadata": {
        "processed_at": "2025-09-23T22:13:03.662103+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "e00f08d55efdbec63c7c31e810ba6ddb",
      "url": "https://arxiv.org/abs/2509.16579",
      "title": "Tides of Memory: Digital Echoes of Netizen Remembran",
      "content": "arXiv:2509.16579v1 Announce Type: new \nAbstract: This artwork presents an interdisciplinary interaction installation that visualizes collective online mourning behavior in China. By focusing on commemorative content posted on Sina Weibo following the deaths of seven prominent Chinese authors, the artwork employs data scraping, natural language processing, and 3D modeling to transform fragmented textual expressions into immersive digital monuments. Through the analysis of word frequencies, topic models, and user engagement metrics, the system constructs a semantic-visual landscape that reflects both authorial legacies and collective memory. This research contributes to the fields of digital humanities, visualization design, and digital memorial architecture by proposing a novel approach for preserving and reactivating collective memory in the digital age.",
      "author": "Lingyu Peng, Chang Ge, Liying Long, Xin Li, Xiao Hu, Pengda Lu, Qingchuan Li, Jiangyue Wu",
      "published_date": "2025-09-23T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 113,
      "reading_time": 1,
      "created_at": "2025-09-23T21:37:43.595602+00:00",
      "updated_at": "2025-09-23T22:13:03.662106+00:00",
      "metadata": {
        "processed_at": "2025-09-23T22:13:03.662107+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "2a774104e7df165da90587252496b539",
      "url": "https://arxiv.org/abs/2509.16465",
      "title": "Graphical Perception of Icon Arrays versus Bar Charts for Value Comparisons in Health Risk Communication",
      "content": "arXiv:2509.16465v1 Announce Type: new \nAbstract: Visualizations support critical decision making in domains like health risk communication. This is particularly important for those at higher health risks and their care providers, allowing for better risk interpretation which may lead to more informed decisions. However, the kinds of visualizations used to represent data may impart biases that influence data interpretation and decision making. Both continuous representations using bar charts and discrete representations using icon arrays are pervasive in health risk communication, but express the same quantities using fundamentally different visual paradigms. We conducted a series of studies to investigate how bar charts, icon arrays, and their layout (juxtaposed, explicit encoding, explicit encoding plus juxtaposition) affect the perception of value comparison and subsequent decision-making in health risk communication. Our results suggest that icon arrays and explicit encoding combined with juxtaposition can optimize for both accurate difference estimation and perceptual biases in decision making. We also found misalignment between estimation accuracy and decision making, as well as between low and high literacy groups, emphasizing the importance of tailoring visualization approaches to specific audiences and evaluating visualizations beyond perceptual accuracy alone. This research contributes empirically-grounded design recommendations to improve comparison in health risk communication and support more informed decision-making across domains.",
      "author": "Jade Kandel, Jiayi Liu, Arran Zeyu Wang, Chin Tseng, Danielle Szafir",
      "published_date": "2025-09-23T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 206,
      "reading_time": 1,
      "created_at": "2025-09-23T21:37:43.595575+00:00",
      "updated_at": "2025-09-23T22:13:03.662110+00:00",
      "metadata": {
        "processed_at": "2025-09-23T22:13:03.662111+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "46fb1d126e36bc77a52c025c4a53cbfd",
      "url": "https://arxiv.org/abs/2509.16454",
      "title": "A Generative AI System for Biomedical Data Discovery with Grammar-Based Visualizations",
      "content": "arXiv:2509.16454v1 Announce Type: new \nAbstract: We explore the potential for combining generative AI with grammar-based visualizations for biomedical data discovery. In our prototype, we use a multi-agent system to generate visualization specifications and apply filters. These visualizations are linked together, resulting in an interactive dashboard that is progressively constructed. Our system leverages the strengths of natural language while maintaining the utility of traditional user interfaces. Furthermore, we utilize generated interactive widgets enabling user adjustment. Finally, we demonstrate the potential utility of this system for biomedical data discovery with a case study.",
      "author": "Devin Lange, Shanghua Gao, Pengwei Sui, Austen Money, Priya Misner, Marinka Zitnik, Nils Gehlenborg",
      "published_date": "2025-09-23T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 91,
      "reading_time": 1,
      "created_at": "2025-09-23T21:37:43.595538+00:00",
      "updated_at": "2025-09-23T21:37:43.595539+00:00"
    },
    {
      "id": "ecb399690d706f94fa4e80c5a3dc9650",
      "url": "https://arxiv.org/abs/2509.16437",
      "title": "SENSE-7: Taxonomy and Dataset for Measuring User Perceptions of Empathy in Sustained Human-AI Conversations",
      "content": "arXiv:2509.16437v1 Announce Type: new \nAbstract: Empathy is increasingly recognized as a key factor in human-AI communication, yet conventional approaches to \"digital empathy\" often focus on simulating internal, human-like emotional states while overlooking the inherently subjective, contextual, and relational facets of empathy as perceived by users. In this work, we propose a human-centered taxonomy that emphasizes observable empathic behaviors and introduce a new dataset, Sense-7, of real-world conversations between information workers and Large Language Models (LLMs), which includes per-turn empathy annotations directly from the users, along with user characteristics, and contextual details, offering a more user-grounded representation of empathy. Analysis of 695 conversations from 109 participants reveals that empathy judgments are highly individualized, context-sensitive, and vulnerable to disruption when conversational continuity fails or user expectations go unmet. To promote further research, we provide a subset of 672 anonymized conversation and provide exploratory classification analysis, showing that an LLM-based classifier can recognize 5 levels of empathy with an encouraging average Spearman $\\rho$=0.369 and Accuracy=0.487 over this set. Overall, our findings underscore the need for AI designs that dynamically tailor empathic behaviors to user contexts and goals, offering a roadmap for future research and practical development of socially attuned, human-centered artificial agents.",
      "author": "Jina Suh, Lindy Le, Erfan Shayegani, Gonzalo Ramos, Judith Amores, Desmond C. Ong, Mary Czerwinski, Javier Hernandez",
      "published_date": "2025-09-23T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 199,
      "reading_time": 1,
      "created_at": "2025-09-23T21:37:43.595513+00:00",
      "updated_at": "2025-09-23T21:37:43.595514+00:00"
    },
    {
      "id": "fa16db9b41fc965ccd2be8c37969d747",
      "url": "https://arxiv.org/abs/2509.16427",
      "title": "VisPubs Games: Joyful Discovery of Visualization Research(ers)",
      "content": "arXiv:2509.16427v1 Announce Type: new \nAbstract: Many sophisticated tools exist to help researchers find the academic literature they are searching for, but what about finding work that you aren't looking for? We promote joyful discovery of visualization research through two games (Colon and Authored) available to play now at https://games.vispubs.com. We believe these games provide several benefits to the visualization research community. First, the joyful discovery of visualization research and researchers occurs because these games randomly select authors and publications, thus exposing players to research areas they may not typically engage with. Second, these games were made by visualization researchers for visualization researchers; playing this game, sharing results with friends in person and online, has the potential to strengthen our academic community. Third, games centered around publication authors provide a passive way for academics to gain exposure within the community. Finally, we hope these games are simply fun to play. Try them now at games.vispubs.com.",
      "author": "Devin Lange, Zach Cutler, Maxim Lisnic",
      "published_date": "2025-09-23T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 154,
      "reading_time": 1,
      "created_at": "2025-09-23T21:37:43.595479+00:00",
      "updated_at": "2025-09-23T21:37:43.595481+00:00"
    },
    {
      "id": "c5041f286f34ce45e94683fa662ed2cc",
      "url": "https://arxiv.org/abs/2509.16402",
      "title": "\"It Was a Magical Box\": Understanding Practitioner Workflows and Needs in Optimization",
      "content": "arXiv:2509.16402v1 Announce Type: new \nAbstract: Optimization underpins decision-making in domains from healthcare to logistics, yet for many practitioners it remains a \"magical box\": powerful but opaque, difficult to use, and reliant on specialized expertise. While prior work has extensively studied machine learning workflows, the everyday practices of optimization model developers (OMDs) have received little attention. We conducted semi-structured interviews with 15 OMDs across diverse domains to examine how optimization is done in practice. Our findings reveal a highly iterative workflow spanning six stages: problem elicitation, data processing, model development, implementation, validation, and deployment. Importantly, we find that optimization practice is not only about algorithms that deliver better decisions, but is equally shaped by data and dialogue - the ongoing communication with stakeholders that enables problem framing, trust, and adoption. We discuss opportunities for future tooling that foregrounds data and dialogue alongside decision-making, opening new directions for human-centered optimization.",
      "author": "Connor Lawless, Jakob Schoeffer, Madeleine Udell",
      "published_date": "2025-09-23T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 148,
      "reading_time": 1,
      "created_at": "2025-09-23T21:37:43.595447+00:00",
      "updated_at": "2025-09-23T21:37:43.595449+00:00"
    },
    {
      "id": "f8cdbeae180cf5123c5ebd681d70758b",
      "url": "https://arxiv.org/abs/2509.16323",
      "title": "Funding the Frontier: Visualizing the Broad Impact of Science and Science Funding",
      "content": "arXiv:2509.16323v1 Announce Type: new \nAbstract: Understanding the broad impact of science and science funding is critical to ensuring that science investments and policies align with societal needs. Existing research links science funding to the output of scientific publications but largely leaves out the downstream uses of science and the myriad ways in which investing in science may impact human society. As funders seek to allocate scarce funding resources across a complex research landscape, there is an urgent need for informative and transparent tools that allow for comprehensive assessments and visualization of the impact of funding. Here we present Funding the Frontier (FtF), a visual analysis system for researchers, funders, policymakers, university leaders, and the broad public to analyze multidimensional impacts of funding and make informed decisions regarding research investments and opportunities. The system is built on a massive data collection that connects 7M research grants to 140M scientific publications, 160M patents, 10.9M policy documents, 800K clinical trials, and 5.8M newsfeeds, with 1.8B citation linkages among these entities, systematically linking science funding to its downstream impacts. As such, Funding the Frontier is distinguished by its multifaceted impact analysis framework. The system incorporates diverse impact metrics and predictive models that forecast future investment opportunities into an array of coordinated views, allowing for easy exploration of funding and its outcomes. We evaluate the effectiveness and usability of the system using case studies and expert interviews. Feedback suggests that our system not only fulfills the primary analysis needs of its target users, but the rich datasets of the complex science ecosystem and the proposed analysis framework also open new avenues for both visualization and the science of science research.",
      "author": "Yifang Wang, Yifan Qian, Xiaoyu Qi, Yian Yin, Shengqi Dang, Ziqing Qian, Benjamin F. Jones, Nan Cao, Dashun Wang",
      "published_date": "2025-09-23T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 275,
      "reading_time": 1,
      "created_at": "2025-09-23T21:37:43.595394+00:00",
      "updated_at": "2025-09-23T21:37:43.595399+00:00"
    },
    {
      "id": "9fd522c9fa965a09664993a31b042b22",
      "url": "https://arxiv.org/abs/2509.16803",
      "title": "Efficient Brain Network Estimation with Sparse ICA in Non-Human Primate Neuroimaging",
      "content": "arXiv:2509.16803v1 Announce Type: cross \nAbstract: Independent component analysis (ICA) is widely used to separate mixed signals and recover statistically independent components. However, in non-human primate neuroimaging studies, most ICA-recovered spatial maps are often dense. To extract the most relevant brain activation patterns, post-hoc thresholding is typically applied-though this approach is often imprecise and arbitrary. To address this limitation, we employed the Sparse ICA method, which enforces both sparsity and statistical independence, allowing it to extract the most relevant activation maps without requiring additional post-processing. Simulation experiments demonstrate that Sparse ICA performs competitively against 11 classical linear ICA methods. We further applied Sparse ICA to real non-human primate neuroimaging data, identifying several independent component networks spanning different brain networks. These spatial maps revealed clearly defined activation areas, providing further evidence that Sparse ICA is effective and reliable in practical applications.",
      "author": "Qiang Li, Liang Ma, Masoud Seraji, Shujian Yu, Yun Wang, Jingyu Liu, Vince D. Calhoun",
      "published_date": "2025-09-23T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 139,
      "reading_time": 1,
      "created_at": "2025-09-23T21:37:42.453372+00:00",
      "updated_at": "2025-09-23T21:37:42.453373+00:00"
    },
    {
      "id": "72ea2e88dbc012ec6915112de3816fdb",
      "url": "https://arxiv.org/abs/2509.17280",
      "title": "From Prediction to Understanding: Will AI Foundation Models Transform Brain Science?",
      "content": "arXiv:2509.17280v1 Announce Type: new \nAbstract: Generative pretraining (the \"GPT\" in ChatGPT) enables language models to learn from vast amounts of internet text without human supervision. This approach has driven breakthroughs across AI by allowing deep neural networks to learn from massive, unstructured datasets. We use the term foundation models to refer to large pretrained systems that can be adapted to a wide range of tasks within and across domains, and these models are increasingly applied beyond language to the brain sciences. These models achieve strong predictive accuracy, raising hopes that they might illuminate computational principles. But predictive success alone does not guarantee scientific understanding. Here, we outline how foundation models can be productively integrated into the brain sciences, highlighting both their promise and their limitations. The central challenge is to move from prediction to explanation: linking model computations to mechanisms underlying neural activity and cognition.",
      "author": "Thomas Serre, Ellie Pavlick",
      "published_date": "2025-09-23T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 145,
      "reading_time": 1,
      "created_at": "2025-09-23T21:37:42.453344+00:00",
      "updated_at": "2025-09-23T21:37:42.453345+00:00"
    },
    {
      "id": "b20eab1df77bcaedd1cbbae65a670e20",
      "url": "https://arxiv.org/abs/2509.17260",
      "title": "A tutorial on electrogastrography using low-cost hardware and open-source software",
      "content": "arXiv:2509.17260v1 Announce Type: new \nAbstract: Electrogastrography is the recording of changes in electric potential caused by the stomach's pacemaker region, typically through several cutaneous sensors placed on the abdomen. It is a worthwhile technique in medical and psychological research, but also relatively niche. Here we present a tutorial on the acquisition and analysis of the human electrogastrogram. Because dedicated equipment and software can be prohibitively expensive, we demonstrate how data can be acquired using a low-cost OpenBCI Ganglion amplifier. We also present a processing pipeline that minimises attrition, which is particularly helpful for low-cost equipment but also applicable to top-of-the-line hardware. Our approach comprises outlier rejection, frequency filtering, movement filtering, and noise reduction using independent component analysis. Where traditional approaches include a subjective step in which only one channel is manually selected for further analysis, our pipeline recomposes the electrogastrogram from all recorded channels after automatic rejection of nuisance components. The main benefits of this approach are reduced attrition, retention of data from all recorded channels, and reduced influence of researcher bias. In addition to our tutorial on the method, we offer a proof-of-principle in which our approach leads to reduced data rejection compared to established methods. We aimed to describe each step in sufficient detail to be implemented in any programming language. In addition, we made an open-source Python package freely available for ease of use.",
      "author": "Evgeniya Anisimova, Sameer N. B. Alladin, Styliani Tsamaz, Edwin S. Dalmaijer",
      "published_date": "2025-09-23T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 227,
      "reading_time": 1,
      "created_at": "2025-09-23T21:37:42.453312+00:00",
      "updated_at": "2025-09-23T21:37:42.453314+00:00"
    },
    {
      "id": "159237b10a63410ea1ca7dc6af02648a",
      "url": "https://arxiv.org/abs/2509.17174",
      "title": "Self-Supervised Discovery of Neural Circuits in Spatially Patterned Neural Responses with Graph Neural Networks",
      "content": "arXiv:2509.17174v1 Announce Type: new \nAbstract: Inferring synaptic connectivity from neural population activity is a fundamental challenge in computational neuroscience, complicated by partial observability and mismatches between inference models and true circuit dynamics. In this study, we propose a graph-based neural inference model that simultaneously predicts neural activity and infers latent connectivity by modeling neurons as interacting nodes in a graph. The architecture features two distinct modules: one for learning structural connectivity and another for predicting future spiking activity via a graph neural network (GNN). Our model accommodates unobserved neurons through auxiliary nodes, allowing for inference in partially observed circuits. We evaluate this approach using synthetic data from ring attractor networks and real spike recordings from head direction cells in mice. Across a wide range of conditions, including varying recurrent connectivity, external inputs, and incomplete observations, our model consistently outperforms standard baselines, resolving spurious correlations more effectively and recovering accurate weight profiles. When applied to real data, the inferred connectivity aligns with theoretical predictions of continuous attractor models. These results highlight the potential of GNN-based models to infer latent neural circuitry through self-supervised structure learning, while leveraging the spike prediction task to flexibly link connectivity and dynamics across both simulated and biological neural systems.",
      "author": "Kijung Yoon",
      "published_date": "2025-09-23T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 203,
      "reading_time": 1,
      "created_at": "2025-09-23T21:37:42.453279+00:00",
      "updated_at": "2025-09-23T21:37:42.453280+00:00"
    },
    {
      "id": "72213af31dd581d898da843460c100ee",
      "url": "https://arxiv.org/abs/2509.17138",
      "title": "Analyzing Memory Effects in Large Language Models through the lens of Cognitive Psychology",
      "content": "arXiv:2509.17138v1 Announce Type: new \nAbstract: Memory, a fundamental component of human cognition, exhibits adaptive yet fallible characteristics as illustrated by Schacter's memory \"sins\".These cognitive phenomena have been studied extensively in psychology and neuroscience, but the extent to which artificial systems, specifically Large Language Models (LLMs), emulate these cognitive phenomena remains underexplored. This study uses human memory research as a lens for understanding LLMs and systematically investigates human memory effects in state-of-the-art LLMs using paradigms drawn from psychological research. We evaluate seven key memory phenomena, comparing human behavior to LLM performance. Both people and models remember less when overloaded with information (list length effect) and remember better with repeated exposure (list strength effect). They also show similar difficulties when retrieving overlapping information, where storing too many similar facts leads to confusion (fan effect). Like humans, LLMs are susceptible to falsely \"remembering\" words that were never shown but are related to others (false memories), and they can apply prior learning to new, related situations (cross-domain generalization). However, LLMs differ in two key ways: they are less influenced by the order in which information is presented (positional bias) and more robust when processing random or meaningless material (nonsense effect). These results reveal both alignments and divergences in how LLMs and humans reconstruct memory. The findings help clarify how memory-like behavior in LLMs echoes core features of human cognition, while also highlighting the architectural differences that lead to distinct patterns of error and success.",
      "author": "Zhaoyang Cao, Lael Schooler, Reza Zafarani",
      "published_date": "2025-09-23T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 240,
      "reading_time": 1,
      "created_at": "2025-09-23T21:37:42.453247+00:00",
      "updated_at": "2025-09-23T21:37:42.453249+00:00"
    },
    {
      "id": "20a34f7803b17aff2730d2cfbc1f79bf",
      "url": "https://arxiv.org/abs/2509.16973",
      "title": "Deep Learning Inductive Biases for fMRI Time Series Classification during Resting-state and Movie-watching",
      "content": "arXiv:2509.16973v1 Announce Type: new \nAbstract: Deep learning has advanced fMRI analysis, yet it remains unclear which architectural inductive biases are most effective at capturing functional patterns in human brain activity. This issue is particularly important in small-sample settings, as most datasets fall into this category. We compare models with three major inductive biases in deep learning including convolutional neural networks (CNNs), long short-term memory networks (LSTMs), and Transformers for the task of biological sex classification. These models are evaluated within a unified pipeline using parcellated multivariate fMRI time series from the Human Connectome Project (HCP) 7-Tesla cohort, which includes four resting-state runs and four movie-watching task runs. We assess performance on Whole-brain, subcortex, and 12 functional networks. CNNs consistently achieved the highest discrimination for sex classification in both resting-state and movie-watching, while LSTM and Transformer models underperformed. Network-resolved analyses indicated that the Whole-brain, Default Mode, Cingulo-Opercular, Dorsal Attention, and Frontoparietal networks were the most discriminative. These results were largely similar between resting-state and movie-watching. Our findings indicate that, at this dataset size, discriminative information is carried by local spatial patterns and inter-regional dependencies, favoring convolutional inductive bias. Our study provides insights for selecting deep learning architectures for fMRI time series classification.",
      "author": "Behdad Khodabandehloo, Reza Rajimehr",
      "published_date": "2025-09-23T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 201,
      "reading_time": 1,
      "created_at": "2025-09-23T21:37:42.453212+00:00",
      "updated_at": "2025-09-23T21:37:42.453214+00:00"
    },
    {
      "id": "052fe326757319a236c97e2f7946d96d",
      "url": "https://arxiv.org/abs/2509.16253",
      "title": "Quantum-like representation of neuronal networks' activity: modeling \"mental entanglement\"",
      "content": "arXiv:2509.16253v1 Announce Type: new \nAbstract: Quantum-like modeling (QLM) - quantum theory applications outside of physics - are intensively developed with applications in biology, cognition, psychology, and decision-making. For cognition, QLM should be distinguished from quantum reductionist models in the spirit of Hameroff and Penrose and well as Umezawa and Vitiello. QLM is not concerned with just quantum physical processes in the brain but also QL information processing by macroscopic neuronal structures. Although QLM of cognition and decision-making has seen some success, it suffers from a knowledge gap that exists between oscillatory neuronal network functioning in the brain and QL behavioral patterns. Recently, steps toward closing this gap have been taken using the generalized probability theory and prequantum classical statistical field theory (PCSFT) - a random field model beyond the complex Hilbert space formalism. PCSFT is used to move from the classical ``oscillatory cognition'' of the neuronal networks to QLM for decision.making. In this study, we addressed the most difficult problem within this construction: QLM for entanglement generation by classical networks, i.e., mental entanglement. We started with the observational approach to entanglement based on operator algebras describing local observables and bringing into being the tensor product structure in the space of QL states. Moreover, we applied the standard states entanglement approach: entanglement generation by spatially separated networks in the brain. Finally, we discussed possible future experiments on mental entanglement detection using the EEG/MEG technique.",
      "author": "Andrei Khrennikov, Makiko Yamada",
      "published_date": "2025-09-23T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 233,
      "reading_time": 1,
      "created_at": "2025-09-23T21:37:42.453180+00:00",
      "updated_at": "2025-09-23T21:37:42.453181+00:00"
    },
    {
      "id": "bee7a708c48fa48ff7f058f87248dba0",
      "url": "https://arxiv.org/abs/2509.16238",
      "title": "Evolvable Graph Diffusion Optimal Transport with Pattern-Specific Alignment for Brain Connectome Modeling",
      "content": "arXiv:2509.16238v1 Announce Type: new \nAbstract: Network analysis of human brain connectivity indicates that individual differences in cognitive abilities arise from neurobiological mechanisms inherent in structural and functional brain networks. Existing studies routinely treat structural connectivity (SC) as optimal or fixed topological scaffolds for functional connectivity (FC), often overlooking higher-order dependencies between brain regions and limiting the modeling of complex cognitive processes. Besides, the distinct spatial organizations of SC and FC complicate direct integration, as naive alignment may distort intrinsic nonlinear patterns of brain connectivity. In this study, we propose a novel framework called Evolvable Graph Diffusion Optimal Transport with Pattern-Specific Alignment (EDT-PA), designed to identify disease-specific connectome patterns and classify brain disorders. To accurately model high-order structural dependencies, EDT-PA incorporates a spectrum of evolvable modeling blocks to dynamically capture high-order dependencies across brain regions. Additionally, a Pattern-Specific Alignment mechanism employs optimal transport to align structural and functional representations in a geometry-aware manner. By incorporating a Kolmogorov-Arnold network for flexible node aggregation, EDT-PA is capable of modeling complex nonlinear interactions among brain regions for downstream classification. Extensive evaluations on the REST-meta-MDD and ADNI datasets demonstrate that EDT-PA outperforms state-of-the-art methods, offering a more effective framework for revealing structure-function misalignments and disorder-specific subnetworks in brain disorders. The project of this work is released via this link.",
      "author": "Xiaoqi Sheng, Jiawen Liu, Jiaming Liang, Yiheng Zhang, Hongmin Cai",
      "published_date": "2025-09-23T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 214,
      "reading_time": 1,
      "created_at": "2025-09-23T21:37:42.453145+00:00",
      "updated_at": "2025-09-23T21:37:42.453147+00:00"
    },
    {
      "id": "0e6ed095323c6f550ff0d86d3637592d",
      "url": "https://arxiv.org/abs/2509.16232",
      "title": "Emotions are Recognized Patterns of Cognitive Activities",
      "content": "arXiv:2509.16232v1 Announce Type: new \nAbstract: Emotions play a crucial role in human life. The research community has proposed many theories on emotions without reaching much consensus. The situation is similar for emotions in cognitive architectures and autonomous agents. I propose in this paper that emotions are recognized patterns of cognitive activities. These activities are responses of an agent to the deviations between the targets of its goals and the performances of its actions. Emotions still arise even if these activities are purely logical. I map the patterns of cognitive activities to emotions. I show the link between emotions and attention and the impacts of the parameterized functions in the cognitive architecture on the computing of emotions. My proposition bridges different theories on emotions and advances the building of consensus.",
      "author": "Yue Jin (Nokia Bell Labs France)",
      "published_date": "2025-09-23T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 129,
      "reading_time": 1,
      "created_at": "2025-09-23T21:37:42.453108+00:00",
      "updated_at": "2025-09-23T21:37:42.453110+00:00"
    },
    {
      "id": "49795ce84a89ce115ce4fb0115d3b0d8",
      "url": "https://arxiv.org/abs/2509.16229",
      "title": "Low-Cost Shield MicroBCI to Measure EEG with STM32",
      "content": "arXiv:2509.16229v1 Announce Type: new \nAbstract: The article introduces an accessible pathway into neuroscience using the MicroBCI device, which leverages the STM32 Nucleo-55RG development board as the core platform. MicroBCI enables the STM32 board to function as a brain-computer interface, capable of recording EEG, EMG, and ECG signals across 8 channels. Over the past decade, the rapid growth of artificial intelligence has transformed many fields, including neurobiology. The application of machine learning methods has created opportunities for the practical use of EEG signals in diverse technological domains. This growing interest has fueled the popularity of affordable brain-computer interface systems that utilize non-invasive electrodes for EEG acquisition. The MicroBCI device demonstrates reliable noise performance and accuracy for applied research and prototyping. Furthermore, it effectively detects alpha brain waves, confirming its ability to capture key neurological signals.",
      "author": "Ildar Rakhmatulin",
      "published_date": "2025-09-23T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 134,
      "reading_time": 1,
      "created_at": "2025-09-23T21:37:42.453074+00:00",
      "updated_at": "2025-09-23T21:37:42.453078+00:00"
    }
  ]
}