{
  "last_updated": "2025-12-06T18:20:15.213659+00:00",
  "count": 20,
  "articles": [
    {
      "id": "fb588439a33dbfe3eb0b3edf79a54446",
      "url": "http://ieeexplore.ieee.org/document/11235874",
      "title": "Transient Inhibition of the Posterior Parietal Cortex Affects Action-related But Not Action-unrelated Visual Processing during Path Integration",
      "content": "Path integration refers to the ability to monitor self-motion cues to keep track of changes in position and orientation. This function is often assumed to rely predominantly on medial temporal lobe structures containing grid, place, and head direction cells. Recent evidence, however, suggests that key navigational computations may occur outside this system, for example, in posterior parietal areas. Here, we adopted a novel perspective derived from animal research and examined whether human path integration relies on processing streams in the posterior parietal cortex (PPC), depending on the involvement of actively controlled motion as opposed to passive perception of visual optic flow. We compared the effects of inhibiting the PPC via TMS on two path integration tasks in a virtual reality, only one of which involved active control of a visually simulated forward movement. Behavioral performance showed that distance judgments were selectively affected in the action-related path integration task. This finding shows that the processing of actively controlled motion depends on computations in the PPC, whereas passive processing of optic flow is largely independent of the PPC computations. Our results reinforce the hypothesis that the PPC plays a critical role for the integration of goal locations and self-positional signals within an egocentric frame of reference. In addition to the medial temporal lobe, the posterior parietal system is recruited during tasks involving actively controlled movements, whereas medial temporal computations are sufficient for passive monitoring of positional changes.",
      "author": "",
      "published_date": "2025-11-07T13:16:23+00:00",
      "source": "Cognitive Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 235,
      "reading_time": 1,
      "created_at": "2025-12-06T17:40:15.766583+00:00",
      "updated_at": "2025-12-06T18:20:15.106174+00:00",
      "metadata": {
        "processed_at": "2025-12-06T18:20:15.106183+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "dd956e22c649f8a69385d4e041a880c8",
      "url": "https://www.frontiersin.org/articles/10.3389/fnhum.2025.1707031",
      "title": "\u201cPICS\u201d: a novel patient-specific landmark for thalamic surgical interventions in the posterior limb of the internal capsule signal",
      "content": "IntroductionDifficulties in direct visualization of thalamic subnuclei are likely a contributor to inconsistent surgical outcomes among patients with medication refractory tremors. We present a new MRI landmark, represented by a bright signal in the posterior limb of the internal capsule signal (PICS), that can serve as a consistent marker for indirect location of the Vim nucleus of the thalamus. We evaluated the visibility of PICS across multiple MRI sequences at 7Tesla (T) and 3T, and its anatomical characteristics were identified using tractography.MethodsOne healthy control and 15 essential tremor (ET) patients were scanned. To characterize the PICS fibers, two posterior limb of internal capsule (pLIC) tractography schemes were conducted with cortical ROIs as seeds and the pLIC as a waypoint: (i) gross motor cortical ROIs, (ii) M1 and S1 homunculus. Finally, intra- and post-operative clinical data were merged for one ET DBS patient to show correspondence between the parcellation results and clinical observations.ResultsPICS was consistently identified across multiple MRI sequences. Tractography analyses identified PICS to correlate with the distribution of motor fibers from the internal capsule. For the M1 homunculus, two somatotopic clusters were observed: one including mostly trunk, lower and upper limbs; and another, more anteriorly, with head/face clustering with tongue/larynx. For the S1 homunculus, the trunk region was overall the most posterior region followed by the upper limb/face anteriorly and Area2. Intra-operative stimulation at two different depths resulted in pLIC-specific side effect in the tongue/face. At those depths, measurements showed closer proximity of the DBS electrode to M1 clusters of head/face and tongue/larynx, validating the imaging findings.ConclusionPICS appears to be a reliable radiological marker comprising cortico-spinal tracts, in isolation from corticobulbar tracts fibers. It is consistently located lateral to the Vim, making it a potential landmark to infer Vim location and help refine targeting for thalamic procedures. The parcellations of the pLIC using M1 homunculus could potentially inform lead or ablation location based on side effect profiles (e.g., head/face/tongue vs. trunk/limbs). Therefore, proximity or distance to PICS may potentially guide lead placement to avoid procedure-related capsular side effects while optimizing benefits.",
      "author": "Leonardo Almeida",
      "published_date": "2025-12-02T00:00:00+00:00",
      "source": "Frontiers Human Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 342,
      "reading_time": 1,
      "created_at": "2025-12-06T17:39:52.546647+00:00",
      "updated_at": "2025-12-06T18:20:15.106190+00:00",
      "metadata": {
        "processed_at": "2025-12-06T18:20:15.106192+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "d8c22ee6ffd2f7d03275ab46ef0fb3d7",
      "url": "https://www.nature.com/articles/s41598-025-31018-w",
      "title": "Temporal and spatial characterization of physiological noise in rs-fMRI at a high temporal resolution",
      "content": "",
      "author": "",
      "published_date": "2025-12-06T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-12-06T17:18:02.989141+00:00",
      "updated_at": "2025-12-06T18:20:15.106194+00:00",
      "metadata": {
        "processed_at": "2025-12-06T18:20:15.106196+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "b84f4acfaa385c55c9bcc74850be8c16",
      "url": "http://doi.org/10.1037/cns0000380",
      "title": "Sensory-processing sensitivity as a confounder in the positive relationship between mindful awareness and psychological distress: A theoretical review.",
      "content": "Mindfulness meditation is credited as a positive driver of promoting psychological well-being and reducing stress, anxiety, and depression symptoms. However, dispositional mindfulness has been somewhat correlated with psychological distress, as awareness has been positively correlated with psychological symptoms and negative affective states in many studies. This counterintuitive phenomenon has been tentatively explained in a variety of ways, including a wrong interpretation of the items of the mindfulness assessment scales in nonmeditators. The most credited explanation is that increasing attention to present-moment experiences would boost affective reaction to negative experiences and therefore exacerbate related psychological symptoms. This hypothesis is unsatisfactory, as there is much contrasting evidence in this regard. Therefore, we propose a new hypothesis: in dispositional studies, the assessment of the awareness skill of mindfulness would be affected by sensory-processing sensitivity, which could be a confounder in its relationship with psychological distress. Sensory-processing sensitivity refers to a temperamental trait characterized by both awareness of sensorial stimulation and reactivity to experience. Thus, highly sensitive persons usually report increased awareness of subtleties in the environment, ease of overstimulation, and increased affective reaction to stimulation. In support of our hypothesis, we showed in particular how the most widely used scale for assessing mindful awareness could be paired with and interpreted as a measure of sensory-processing sensitivity. We then propose a set of testable hypotheses to drive future research on this topic. If supported by future experimental results, our hypothesis would shed new light on the overall field of dispositional mindfulness studies. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2023-11-02T00:00:00+00:00",
      "source": "Clinical Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 257,
      "reading_time": 1,
      "created_at": "2025-12-06T17:17:31.895570+00:00",
      "updated_at": "2025-12-06T18:20:15.106198+00:00",
      "metadata": {
        "processed_at": "2025-12-06T18:20:15.106200+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "a89cc9d9bab0838b2e06072add1ef2ed",
      "url": "http://doi.org/10.1037/cns0000335",
      "title": "A shared perceptual inference for cross-modally induced illusions of self-attribution.",
      "content": "The representation of our own body is malleable. Evidence indicates that multisensory stimulation can trigger an illusory sense of ownership over a fake hand, a partner\u2019s face, or a virtual body. Despite our understanding of the processes supporting the construction of bodily self, we know less about the processes that trigger illusory ownership of nonbody attributes (e.g., voice during articulation) and about whether multisensory stimulation can drive a shared inference across distinct attributes. Here, we compared the classic rubber hand illusion with another multisensory illusion that elicits a sense of ownership over a stranger\u2019s voice during talking. We observed that, given congruent multisensory input, the degree to which one perceived the sense of ownership over the fake hand predicted the degree to which one perceived the sense of ownership over the stranger\u2019s voice, after controlling for task demand and suggestibility. Thus, our results provide evidence for a shared inference supporting subjective sense of self across fundamentally different attributes. We suggest that individual reliance on multisensory signals to drive such an inference can be further explored. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2022-08-25T00:00:00+00:00",
      "source": "Clinical Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 184,
      "reading_time": 1,
      "created_at": "2025-12-06T17:17:31.895529+00:00",
      "updated_at": "2025-12-06T18:20:15.106202+00:00",
      "metadata": {
        "processed_at": "2025-12-06T18:20:15.106203+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "fa250840ddf6808c93613cad856c7c25",
      "url": "http://doi.org/10.1037/cns0000353",
      "title": "Unmuting lucid dreams: Speech decoding and vocalization in real time.",
      "content": "Since the 1970s, scientists have been searching for ways to communicate with people in lucid dreams (LDs), during which it is possible to maintain consciousness. Previously, dreamers could hear sounds from reality and respond with some simple signals, but they could not speak back. In this study, facial surface electromyography (EMG) was tested as a proof of concept for unmuting people in LDs. Remmyo, an EMG distinctive constructed language, was used. The software was developed to translate facial EMG impulses into Remmyo sounds and letters, translate words into English, and digitally vocalize the final text in English. Four LD practitioners were trained to pronounce a short phrase or a word in Remmyo and were then asked to achieve the same task in LDs under polysomnographic observation. LDs were verified by preagreed eye movements in rapid eye movement (REM) sleep. Four volunteers tried to speak in Remmyo in 15 LDs. Due to software failures, mispronunciations, and missing sounds, the decoding efficiency in real time or in recordings ranged from 13% to 81%. The first phrase and word heard from sleeping people were \u201cno war\u201d and \u201cfreedom.\u201d The later was automatically translated and vocalized in English in real time for 11 times. Despite controversial results, the study shows that, with further development, people could possibly talk in LDs and could be heard in reality with the help of EMG sensors. To achieve this goal, a range of possible obstacles is discussed. This technology could provide opportunities for LD studies and their practical applications. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2023-03-13T00:00:00+00:00",
      "source": "Clinical Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 260,
      "reading_time": 1,
      "created_at": "2025-12-06T17:17:31.895493+00:00",
      "updated_at": "2025-12-06T17:17:31.895495+00:00"
    },
    {
      "id": "0e297c97f1d8d8e250b36b2872cf8d93",
      "url": "https://www.ycombinator.com/companies/infisical/jobs/2pwGcK9-senior-full-stack-engineer-us-canada",
      "title": "Infisical (YC W23) Is Hiring Engineers to Build the Modern OSS Security Stack",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46174789\">Comments</a>",
      "author": "",
      "published_date": "2025-12-06T17:01:53+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-06T17:17:22.897320+00:00",
      "updated_at": "2025-12-06T17:17:22.897321+00:00"
    },
    {
      "id": "c3704ced00e144f83c623f97a09f6e14",
      "url": "https://github.com/Tongyi-MAI/Z-Image",
      "title": "Z-Image: Powerful and highly efficient image generation model with 6B parameters",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46095817\">Comments</a>",
      "author": "",
      "published_date": "2025-11-30T11:36:34+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-06T17:17:22.897301+00:00",
      "updated_at": "2025-12-06T17:17:22.897302+00:00"
    },
    {
      "id": "0e297c97f1d8d8e250b36b2872cf8d93",
      "url": "https://www.ycombinator.com/companies/infisical/jobs/2pwGcK9-senior-full-stack-engineer-us-canada",
      "title": "Infisical (YC W23) Is Hiring Engineers to Build the Modern OSS Security Stack",
      "content": "<p>Article URL: <a href=\"https://www.ycombinator.com/companies/infisical/jobs/2pwGcK9-senior-full-stack-engineer-us-canada\">https://www.ycombinator.com/companies/infisical/jobs/2pwGcK9-senior-full-stack-engineer-us-canada</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46174789\">https://news.ycombinator.com/item?id=46174789</a></p>\n<p>Points: 0</p>\n<p># Comments: 0</p>",
      "author": "vmatsiiako",
      "published_date": "2025-12-06T17:01:53+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-06T17:17:21.499473+00:00",
      "updated_at": "2025-12-06T17:17:21.499482+00:00"
    },
    {
      "id": "3cace5c5d9bdc4eeebb05365c3e99538",
      "url": "http://doi.org/10.1037/cns0000402",
      "title": "Creating a world in the head: The conscious apprehension of neural content originating from internal sources.",
      "content": "Klein et al. (2023) argued that the evolutionary transition from respondent to agent during the Cambrian explosion would be a promising vantage point from which to gain insight into the evolution of organic sentience. They focused on how increased competition for resources\u2014in consequence of the proliferation of new, neurally sophisticated life-forms\u2014made awareness of the external world (in the service of agentic acts) an adaptive priority. The explanatory scope of Klein et al. (2023) was limited to consideration of the conscious apprehension of externally sourced content\u2014that is, content delivered from the sensory registration of objects occupying phenomenal space. But consciousness\u2014at least for humans\u2014takes its objects from internal as well as external sources. In the present article, we extend their analysis to the question of how internally sourced content (i.e., mental states) became the object of conscious apprehension. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2024-09-09T00:00:00+00:00",
      "source": "Clinical Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 145,
      "reading_time": 1,
      "created_at": "2025-12-06T16:45:44.048274+00:00",
      "updated_at": "2025-12-06T16:45:44.048276+00:00"
    },
    {
      "id": "4dc92cbf63e410e4d59f6ffd2f7dec90",
      "url": "http://doi.org/10.1037/cns0000406",
      "title": "Not all minds think alike: Examining the impact of time and task on visual and verbal thought.",
      "content": "Research suggests that individuals have different phenomenological experiences across various tasks. However, little is known about how these experiences vary by task or over time. This study examined participants\u2019 experiences of task-unrelated thoughts (i.e., TUTs), visual, and verbal thoughts across two experimental sessions and two different tasks. In addition, we examined relations between participants\u2019 thoughts and key individual difference factors. In Session 1, participants (<em>n</em> = 85) engaged in a focused-attention meditation and a reading task, then completed a second identical session with a new text. Throughout both tasks, participants were prompted to report on the characteristics of their thoughts. Participants\u2019 ratings of TUT, visual, and verbal thoughts were subject to change over time. Furthermore, on average, participants visualized more and had fewer TUTs while reading compared to meditation; however, no task difference was found for verbal-thinking reports. This suggests that visual imagery is more malleable than verbal-thinking. There was a strong negative correlation between visual and verbal thoughts, suggesting that at any given time, individuals\u2019 thoughts tended to be either predominantly visual or verbal. Finally, individual differences in the tendency to become immersed in narratives and motivation to engage with other people\u2019s perspectives (i.e., mind-reading motivation) were related to higher reports of visual imagery during reading, whereas verbal-thinking was negatively associated with mind-reading motivation and unrelated to TUT. Overall, this study revealed that individuals\u2019 phenomenological experiences vary during tasks and across time, providing a foundation for future work to examine why and how variability in these phenomenological experiences emerge. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2024-10-14T00:00:00+00:00",
      "source": "Clinical Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 259,
      "reading_time": 1,
      "created_at": "2025-12-06T16:45:44.048239+00:00",
      "updated_at": "2025-12-06T16:45:44.048241+00:00"
    },
    {
      "id": "ceea3048c29312b21022320cf8318283",
      "url": "https://grapheneos.social/@GrapheneOS/115647408229616018",
      "title": "GrapheneOS is the only Android OS providing full security patches",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46173407\">Comments</a>",
      "author": "",
      "published_date": "2025-12-06T13:58:31+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-06T16:45:35.250374+00:00",
      "updated_at": "2025-12-06T16:45:35.250376+00:00"
    },
    {
      "id": "ceea3048c29312b21022320cf8318283",
      "url": "https://grapheneos.social/@GrapheneOS/115647408229616018",
      "title": "GrapheneOS is the only Android OS providing full security patches",
      "content": "<p>Article URL: <a href=\"https://grapheneos.social/@GrapheneOS/115647408229616018\">https://grapheneos.social/@GrapheneOS/115647408229616018</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46173407\">https://news.ycombinator.com/item?id=46173407</a></p>\n<p>Points: 32</p>\n<p># Comments: 2</p>",
      "author": "akyuu",
      "published_date": "2025-12-06T13:58:31+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-06T16:45:34.154609+00:00",
      "updated_at": "2025-12-06T16:45:34.154611+00:00"
    },
    {
      "id": "7afc81aa0880badcd1c03d36a441934b",
      "url": "https://github.com/GoogleChromeLabs/carlo",
      "title": "Carlo is no longer maintained",
      "content": "<p>Article URL: <a href=\"https://github.com/GoogleChromeLabs/carlo\">https://github.com/GoogleChromeLabs/carlo</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46173785\">https://news.ycombinator.com/item?id=46173785</a></p>\n<p>Points: 6</p>\n<p># Comments: 3</p>",
      "author": "keepamovin",
      "published_date": "2025-12-06T14:55:03+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-06T16:45:34.154570+00:00",
      "updated_at": "2025-12-06T16:45:34.154572+00:00"
    },
    {
      "id": "82777821d77e55cfd47c05bfd6943862",
      "url": "https://www.nature.com/articles/s41526-025-00545-1",
      "title": "Identifying cognitive capabilities required for optimal surface extravehicular activity performance",
      "content": "",
      "author": "",
      "published_date": "2025-12-06T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-12-06T16:24:43.970473+00:00",
      "updated_at": "2025-12-06T16:24:43.970475+00:00"
    },
    {
      "id": "cc0602c30e0a3cba1386e8b12be5b4f9",
      "url": "https://www.nature.com/articles/s41598-025-29193-x",
      "title": "Development of urinary impairment after spinal cord injury courses with altered urethral serotonin signalling in the female mice",
      "content": "",
      "author": "",
      "published_date": "2025-12-06T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-12-06T16:24:43.970418+00:00",
      "updated_at": "2025-12-06T16:24:43.970420+00:00"
    },
    {
      "id": "20531d2605ffa3f02d10c4fd4a5021d0",
      "url": "https://www.nature.com/articles/s41598-025-31161-4",
      "title": "Acoustic features of music differentially modulate anxiety through EEG gamma oscillations and prefrontal connectivity",
      "content": "",
      "author": "",
      "published_date": "2025-12-06T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-12-06T16:24:43.970342+00:00",
      "updated_at": "2025-12-06T16:24:43.970344+00:00"
    },
    {
      "id": "7850d65659fc8ac190e4f5b355a0d2b9",
      "url": "https://www.nature.com/articles/s42003-025-09239-6",
      "title": "Amphetamine in adolescence induces a sex-specific mesolimbic dopamine phenotype in the adult prefrontal cortex",
      "content": "",
      "author": "",
      "published_date": "2025-12-06T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-12-06T16:24:43.970321+00:00",
      "updated_at": "2025-12-06T16:24:43.970323+00:00"
    },
    {
      "id": "5aa497e25ddfb58e172e67f30c878d1e",
      "url": "https://www.nature.com/articles/s41467-025-66980-6",
      "title": "Harnessing theta-gamma coupled brainwaves using ultrasound for spinal astrocyte revitalization and sustained neuropathic pain relief in mice",
      "content": "",
      "author": "",
      "published_date": "2025-12-06T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-12-06T16:24:43.970292+00:00",
      "updated_at": "2025-12-06T16:24:43.970295+00:00"
    },
    {
      "id": "6ca1b09b8ba0d885c5dff30a4084aaab",
      "url": "https://www.reddit.com/r/Python/comments/1pf7vj8/i_built_a_linter_specifically_for_aigenerated_code/",
      "title": "I built a linter specifically for AI-generated code",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>AI coding assistants are great for productivity but they produce a specific category of bugs that traditional linters miss. We've all seen it called &quot;AI slop&quot; - code that looks plausible but...</p> <p><strong>1. Imports packages that don't exist</strong> - AI hallucinates package names (~20% of AI imports)</p> <p><strong>2. Placeholder functions</strong> - `def validate(): pass # TODO`</p> <p>3. <strong>Wrong-language patterns</strong> - `.push()` instead of `.append()`, `.equals()` instead of `==`</p> <p><strong>4. Mutable default arguments</strong> - AI's favorite bug</p> <p><strong>5. Dead code</strong> - Functions defined but never called</p> <ul> <li><strong>What My Project Does</strong></li> </ul> <p>I built sloppylint to catch these patterns.</p> <p>To install:</p> <p><code>pip install sloppylint</code><br /> <code>sloppylint .</code></p> <ul> <li><strong>Target Audience</strong> it's meant to use locally, in CICD pipelines, in production or anywhere you are using AI to write python.</li> <li><strong>Comparison</strong> It detects 100+ AI-specific patterns. Not a replacement for flake8/ruff - it catches what they don't.</li> </ul> <p>GitHub: <a href=\"https://github.com/rsionnach/sloppylint\">https://github.com/rsionnach/sloppylint</a></p> <p>Anyone else notice patterns in AI-generated code that should be added?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/kyub\"> /u/kyub </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1pf7vj8/i_built_a_linter_specifically_for_aigenerated_code/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1pf7vj8/i_built_a_linter_specifically_for_aigenerated_code/\">[comments]</a></span>",
      "author": "/u/kyub",
      "published_date": "2025-12-05T21:54:11+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 181,
      "reading_time": 1,
      "created_at": "2025-12-06T16:24:09.843942+00:00",
      "updated_at": "2025-12-06T16:24:09.843943+00:00"
    }
  ]
}