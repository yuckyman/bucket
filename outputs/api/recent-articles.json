{
  "last_updated": "2026-01-26T20:30:37.556509+00:00",
  "count": 20,
  "articles": [
    {
      "id": "61e259c2875f1f44cbe6de07213648bd",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.23.701340v1?rss=1",
      "title": "Oculomotor dance learning task: Implications for audio-visual cued spatial learning",
      "content": "Learning dance of a motor sequence learning involves the coordination of both oculomotor and manual motor systems through the practiced repetition of a fixed sequence of actions, resulting in automatized execution of movement through habit learning. This study aims to address whether a sequence-based learning paradigm centered on the visual-motor system can feasibly be measured while listening to music (Bar and DeSouza 2016). It aims to develop a new visual-motor-based learning paradigm with music, potentially promoting neuroplasticity and creating new interventional tools, building upon prior research that shows behavioural and putative neural changes following dance-based neurorehabilitation in people with Parkinson's disease (Bearss et al. 2024). Eye movements of 10 participants (8 female, 2 male) were tracked using the Eyelink 1000 Plus system during a 68-second eye-dance sequence. The experiment consisted of a learning phase, where participants observed the sequence five times with 30-second breaks, and a performance phase, where they performed the sequence five times from memory on a grey screen without visual cues. Music was incorporated into both phases to aid memorization of the 4 spatial locations. After each performance, the participant was shown a visual reinforcer and asked for their thoughts on how well they executed the dance. A visual reinforcer flashes one of three different colours: red, yellow, or green. Each colour corresponds to how many steps in the dance a participant performed correctly, with key points being: under one third, between one to two thirds, and over two thirds of total steps correct. Participants were scored based on timing of the steps as well for exact (1.00), good (0.66), slightly off (0.33) or missed (0) steps. Data was analyzed using R4.3.1, MATLAB, and Experiment Builder: Data Viewer software. Results showed a significant improvement in performance accuracy between the first session (g1; M = 40%, SD = 7.2%) and the last session (g5; M = 69.7%, SD = 22.8%). A repeated-measures ANOVA revealed a significant main effect of session on performance accuracy, F(4, 36) = 6.99, p < 0.001, 2G = 0.26, indicating that accuracy significantly improved over sessions. Post-hoc Bonferroni comparisons showed that accuracy in later sessions was significantly higher than earlier sessions, suggesting a defined learning curve and consolidation of performance pattern across repeated practice. Similarly, there was significant improvement in timing accuracy between the first session g1; M = 0.29, SD = 0.06) and the fifth session (g5; M = 0.46, SD = 0.12). A repeated-measures ANOVA revealed a significant main effect of session on timing precision, F(4, 36) = 11.67, p < 0.001, 2G = 0.25, indicating significant improvements in temporal control and coordination over sessions. Post-hoc Bonferroni comparisons showed that timing precision significantly improved between early and late sessions (e.g, g1-g4, p <0.01; g1-g5, p < 0.001), suggesting a defined learning curve and increase in precision across repeated practice. These findings suggest that visual-motor-based interventions have the potential to enhance motor and non-motor symptoms like depression and anxiety for neurodegenerative diseases such as Parkinson's Disorder (PD). The results provide a foundation for developing targeted therapies that integrate learning paradigms to improve functional outcomes, warranting further exploration of their long-term efficacy.",
      "author": "Petrovski, M., Beheiry, S., Das, U. U., Rooprai, S., Karimi, A., Simon, J. R., Bar, R. J., DeSouza, J. F.",
      "published_date": "2026-01-26T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 518,
      "reading_time": 2,
      "created_at": "2026-01-26T20:30:05.527896+00:00",
      "updated_at": "2026-01-26T20:30:05.527899+00:00"
    },
    {
      "id": "f3968d6ca1a6621ed2cba328f550039a",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.23.701370v1?rss=1",
      "title": "Impaired Associative Memory, Inference, and Theta Dynamics in Postictal Psychosis of Epilepsy",
      "content": "Postictal psychosis (PIP) is a severe complication occurring in 2% of people with epilepsy (PWE) whose underlying pathophysiology remains poorly understood. Although historically considered separate from other forms of psychosis, newer evidence demonstrates a shared genetic susceptibility. People with schizophrenia are typically impaired at both associative learning and inferring connections between overlapping associations. Successful associative encoding, retrieval, and inference can each be predicted by changes in frontotemporal theta band activity, which is impaired in rodent models and people with schizophrenia. Here, we recorded high-density scalp EEG from PWE with history of PIP and well-matched control participants while they undertook a memory inference task. We found that associative memory and inference were both impaired in the PIP group, despite no difference in item recognition. Moreover, we found disrupted theta activity during memory encoding and the retrieval of inferred associations in PWE with PIP that likely originated from the medial temporal and frontal lobes. These results suggest a pattern of behavioural deficits and altered neural dynamics common to both PIP and schizophrenia. Interpreted in conjunction with previous genetic studies, they may reflect shared neural mechanisms contributing to psychopathology in both conditions and argue that PIP is a model of more general psychoses.",
      "author": "Dworkin, A., Wang, D., Jimenez, D., Ravenscroft, C., Turco, F., Johnson, C., Chowdhury, F. A., Pizarro, J., Walker, M., Balestrini, S., Bush, D., Vivekananda, U.",
      "published_date": "2026-01-26T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 200,
      "reading_time": 1,
      "created_at": "2026-01-26T20:30:05.527809+00:00",
      "updated_at": "2026-01-26T20:30:05.527811+00:00"
    },
    {
      "id": "89f6d50ed8bfe08d8cbc191c05268195",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.23.701367v1?rss=1",
      "title": "Systemic AAV delivery of a calcium indicator in marmosets: functional validation in visual area MT",
      "content": "Functional optical imaging in nonhuman primates provides an important complement to electrophysiological approaches in neuroscience research, but its broader use has been limited by challenges in achieving large-scale, homogeneous expression of genetically encoded reporters, and imaging accessibility in species with gyrencephalic brains with sulci and fissures (e.g., rhesus macaques). Specifically, conventional local intracortical viral injections are invasive and often produce spatially restricted or heterogeneous expression, constraining population-level analyses. Here, we show that systemic intravenous delivery of an adeno-associated virus (AAV) capsid engineered for enhanced blood-brain barrier crossing, AAV.CAP-B10, supports robust and widespread expression of a calcium indicator CAaMP8s in the common marmoset. Intravenous delivery in two marmosets resulted in widespread cortical expression. Using a large cranial window over extrastriate visual area MT (and its satellite areas), we performed widefield single-photon imaging and two-photon cellular-resolution imaging in awake,behaving marmosets to functionally validate activity in this well studied primate visual-motion sensitive cortical area. Population level responses to visual motion and spatial organization measured with widefield imaging, as well as single-cell level motion direction tuning measured with two-photon imaging, were consistent with canonical properties of MT reported in previous electrophysiological studies. Quantitative analyses of lightsheet imaging after whole hemisphere brain clearing further confirmed the broad expression of GCaMP in both cortical and subcortical areas. Together, these results indicate that systemic delivery using AAV.CAP-B10 provides a minimally invasive approach for robust multi-scale functional optical imaging in awake, behaving marmosets.",
      "author": "Chen, P.-S., Rowley, D. P., Rudd, M., Laudano, A., Villa, A. P., Garcia, F., Dong, H.-w., Shay, T. F., Huk, A. C., Steele, A. D., Wekselblatt, J.",
      "published_date": "2026-01-26T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 235,
      "reading_time": 1,
      "created_at": "2026-01-26T20:30:05.527774+00:00",
      "updated_at": "2026-01-26T20:30:05.527776+00:00"
    },
    {
      "id": "03ec6202da4bd0cff73daec2303723aa",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.23.700794v1?rss=1",
      "title": "Temporal Dynamics of EEG Decoding for Continuously Changing Visual Stimuli",
      "content": "Multivariate analyses of M/EEG data are typically performed on neural responses time-locked to discrete stimulus onsets. Such designs usually reveal high decoding performance during the initial transient response (0-500 ms), which subsequently drops to a lower, sustained level. Here, we examined time-resolved EEG decoding of natural scene processing when scenes gradually enter the visual field without a clear onset. We created video sequences in which one scene category (e.g., a beach) smoothly transitioned into another category (e.g., a forest) by blending images from two categories into a single composite panorama and moving a square aperture across it. We then compared EEG decoding for the first scenes within the transitions, which appeared with a sudden onset, to the second scenes, which emerged gradually as the videos progressed. For the first scenes, we observed robust category decoding from 60 ms after onset with a clear peak structure. For the second scene, category decoding was markedly weaker and showed no discernable peak structure. Realigning the appearance of category-diagnostic content for the second scene using deep neural networks did not enhance decoding or recover a peak structure. Further, classifiers trained on the first scene generalized to the second, but with a broad, temporally diffuse pattern, indicating that the second scene did not engage the same hierarchical temporal cascade as the first. Together, these results demonstrate that sudden versus gradual onsets produce distinct temporal decoding dynamics. Insights from onset-based decoding studies, therefore, do not straightforwardly extend to continuous and free-flowing natural stimulation.",
      "author": "Duymaz, I., Engeser, M., Kaiser, D.",
      "published_date": "2026-01-26T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 247,
      "reading_time": 1,
      "created_at": "2026-01-26T20:30:05.527729+00:00",
      "updated_at": "2026-01-26T20:30:05.527734+00:00"
    },
    {
      "id": "c89d2ad698747e7dcffde4a37776f9ab",
      "url": "https://www.nature.com/articles/s41593-025-02191-y",
      "title": "Rethinking the role of position in cortical function",
      "content": "<p>Nature Neuroscience, Published online: 08 January 2026; <a href=\"https://www.nature.com/articles/s41593-025-02191-y\">doi:10.1038/s41593-025-02191-y</a></p>Abnormally located cortical neurons, displaced in developing mice lacking cortical Eml1, retain their molecular identities, form appropriate connections and build functional sensory maps. Most strikingly, these misplaced neurons can drive behavior by themselves \u2014 showing that brain function depends on how neurons connect, and to what, more than where they live.",
      "author": "",
      "published_date": "2026-01-08T00:00:00+00:00",
      "source": "Nature Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 59,
      "reading_time": 1,
      "created_at": "2026-01-26T20:30:01.791580+00:00",
      "updated_at": "2026-01-26T20:30:01.791582+00:00"
    },
    {
      "id": "704e93957179c44d936aeac519f265d0",
      "url": "https://www.frontiersin.org/articles/10.3389/fncom.2025.1737839",
      "title": "Bridging neuromorphic computing and deep learning for next-generation neural data interpretation",
      "content": "",
      "author": "Zhiyuan Zhu",
      "published_date": "2026-01-08T00:00:00+00:00",
      "source": "Frontiers Computational Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2026-01-26T20:29:54.780642+00:00",
      "updated_at": "2026-01-26T20:29:54.780643+00:00"
    },
    {
      "id": "3061b8e679e36008588c7e3462b5a2f7",
      "url": "https://visualrambling.space/dithering-part-2/",
      "title": "Dithering \u2013 Part 2: The Ordered Dithering",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46770274\">Comments</a>",
      "author": "",
      "published_date": "2026-01-26T19:23:54+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-26T20:29:22.457521+00:00",
      "updated_at": "2026-01-26T20:29:22.457522+00:00"
    },
    {
      "id": "8b3f79354fbfa587a4aa7c0b16397bcd",
      "url": "https://danielsada.tech/blog/ai-lazyslop-and-personal-responsibility/",
      "title": "AI Lazyslop and Personal Responsibility",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46770675\">Comments</a>",
      "author": "",
      "published_date": "2026-01-26T19:56:18+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-26T20:29:22.457403+00:00",
      "updated_at": "2026-01-26T20:29:22.457409+00:00"
    },
    {
      "id": "3061b8e679e36008588c7e3462b5a2f7",
      "url": "https://visualrambling.space/dithering-part-2/",
      "title": "Dithering \u2013 Part 2: The Ordered Dithering",
      "content": "<p>Article URL: <a href=\"https://visualrambling.space/dithering-part-2/\">https://visualrambling.space/dithering-part-2/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46770274\">https://news.ycombinator.com/item?id=46770274</a></p>\n<p>Points: 19</p>\n<p># Comments: 2</p>",
      "author": "ChrisArchitect",
      "published_date": "2026-01-26T19:23:54+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2026-01-26T20:29:21.361052+00:00",
      "updated_at": "2026-01-26T20:29:21.361054+00:00"
    },
    {
      "id": "8b3f79354fbfa587a4aa7c0b16397bcd",
      "url": "https://danielsada.tech/blog/ai-lazyslop-and-personal-responsibility/",
      "title": "AI Lazyslop and Personal Responsibility",
      "content": "<p>Article URL: <a href=\"https://danielsada.tech/blog/ai-lazyslop-and-personal-responsibility/\">https://danielsada.tech/blog/ai-lazyslop-and-personal-responsibility/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46770675\">https://news.ycombinator.com/item?id=46770675</a></p>\n<p>Points: 22</p>\n<p># Comments: 21</p>",
      "author": "dshacker",
      "published_date": "2026-01-26T19:56:18+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2026-01-26T20:29:21.361022+00:00",
      "updated_at": "2026-01-26T20:29:21.361032+00:00"
    },
    {
      "id": "64140889d5ce0219063ec434c8e26505",
      "url": "https://www.reddit.com/r/Python/comments/1qno6hj/gopdfsuit_v400_a_highperformance_pdf_engine_for/",
      "title": "GoPdfSuit v4.0.0: A high-performance PDF engine for Python devs (No Go knowledge required)",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m the author of <strong>GoPdfSuit</strong> (<a href=\"https://chinmay-sawant.github.io/gopdfsuit\">https://chinmay-sawant.github.io/gopdfsuit</a>), and we just hit <strong>350+ stars</strong> and launched <strong>v4.0.0</strong> today! I wanted to share this with the community because it solves a pain point many of us have had with legacy PDF libraries: manual coordinate-based coding.</p> <h1>What My Project Does</h1> <p>GoPdfSuit is a high-performance PDF generation engine that allows you to design layouts visually and generate documents via a simple Python API.</p> <ul> <li><strong>Drag-and-Drop Editor:</strong> Includes a React-based UI to design your PDF. It exports a JSON template, so you never have to manually calculate <code>x,y</code> coordinates again.</li> <li><strong>Python Integration:</strong> You interact with the engine purely via standard Python <code>requests</code> (HTTP/JSON). You deploy the container/binary once and just hit the endpoint from your Python scripts.</li> <li><strong>Compliance:</strong> Supports Arlington Compatibility, PDF/UA-2 (Accessibility), and PDF/A (Archival) out of the box.</li> </ul> <h1>Target Audience</h1> <p>This is built for <strong>Production Use</strong>. It is specifically designed for:</p> <ul> <li><strong>Developers</strong> who need to generate complex reports (invoices, financial statements) but find existing libraries slow or hard to maintain.</li> <li><strong>Enterprise Teams</strong> requiring strict PDF compliance (accessibility and archival standards).</li> <li><strong>High-Volume Apps</strong> where PDF generation is a bottleneck (e.g., generating 1,000+ PDFs per minute).</li> </ul> <p><strong>Why this matters for Python devs:</strong></p> <ul> <li><strong>Insane Performance:</strong> The heavy lifting is done in Go, keeping generation lightning fast. <ul> <li><strong>Engine Generation:</strong> ~61ms</li> <li><strong>Total Python Execution:</strong> ~73ms</li> </ul></li> <li><strong>No Go Required:</strong> You interact with the engine purely via standard Python requests (HTTP/JSON). You just deploy the container/binary and hit the endpoint.</li> <li><strong>Modern Editor:</strong> Includes a React-based UI to visually drag-and-drop your layout. It exports a JSON template that your Python script fills with data.</li> <li><strong>Strict Compliance:</strong> Out-of-the-box support for Arlington Compatibility, PDF/UA-2 (Accessibility), and PDF/A (Archival).</li> </ul> <h1>Comparison (How it differs from ReportLab/JasperReports)</h1> <table><thead> <tr> <th align=\"left\"><strong>Feature</strong></th> <th align=\"left\"><strong>ReportLab / JasperReports</strong></th> <th align=\"left\"><strong>GoPdfSuit</strong></th> </tr> </thead><tbody> <tr> <td align=\"left\"><strong>Layout Design</strong></td> <td align=\"left\">Manual code / XML</td> <td align=\"left\">Visual Drag-and-Drop</td> </tr> <tr> <td align=\"left\"><strong>Performance</strong></td> <td align=\"left\">Python-level speed / Heavy Java</td> <td align=\"left\">Native Go speed (~70ms execution)</td> </tr> <tr> <td align=\"left\"><strong>Maintenance</strong></td> <td align=\"left\">Changing a layout requires code edits</td> <td align=\"left\">Change the JSON template; no code changes</td> </tr> <tr> <td align=\"left\"><strong>Compliance</strong></td> <td align=\"left\">Requires extra plugins/config</td> <td align=\"left\">Built-in PDF/UA and PDF/A support</td> </tr> </tbody></table> <h1>Performance Benchmarks</h1> <p>Tested on a standard financial report template including XMP data, image processing, and bookmarks:</p> <ul> <li><strong>Go Engine Internal Logic:</strong> ~61.53ms</li> <li><strong>Total Python Execution (Network + API):</strong> ~73.08ms</li> </ul> <h1>Links &amp; Resources</h1> <ul> <li><strong>Repository:</strong> <a href=\"https://github.com/chinmay-sawant/gopdfsuit\">github.com/chinmay-sawant/gopdfsuit</a></li> <li><strong>Python Integration Examples:</strong> <a href=\"https://github.com/chinmay-sawant/gopdfsuit/tree/master/sampledata/python\">Python Examples Folder</a></li> <li><strong>Validation:</strong> You can validate the output using <strong>OctoPDF</strong> or <strong>veraPDF</strong> to confirm compliance.</li> </ul> <p>If you find this useful, a <strong>Star</strong> on GitHub is much appreciated! I'm happy to answer any questions about the architecture or implementation.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/chinmay06\"> /u/chinmay06 </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1qno6hj/gopdfsuit_v400_a_highperformance_pdf_engine_for/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1qno6hj/gopdfsuit_v400_a_highperformance_pdf_engine_for/\">[comments]</a></span>",
      "author": "/u/chinmay06",
      "published_date": "2026-01-26T18:22:35+00:00",
      "source": "Reddit Python",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 465,
      "reading_time": 2,
      "created_at": "2026-01-26T19:44:53.955378+00:00",
      "updated_at": "2026-01-26T20:20:57.063840+00:00",
      "metadata": {
        "processed_at": "2026-01-26T20:20:57.063852+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "beda9dd7458b660f36f0a89e6371437f",
      "url": "https://tetrisbench.com/tetrisbench/",
      "title": "Show HN: TetrisBench \u2013 Gemini Flash reaches 66% win rate on Tetris against Opus",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46769752\">Comments</a>",
      "author": "",
      "published_date": "2026-01-26T18:42:40+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-26T19:44:52.685438+00:00",
      "updated_at": "2026-01-26T20:20:57.063860+00:00",
      "metadata": {
        "processed_at": "2026-01-26T20:20:57.063862+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "beda9dd7458b660f36f0a89e6371437f",
      "url": "https://tetrisbench.com/tetrisbench/",
      "title": "Show HN: TetrisBench \u2013 Gemini Flash reaches 66% win rate on Tetris against Opus",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46769752\">Comments</a>",
      "author": "",
      "published_date": "2026-01-26T18:42:40+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-26T19:44:52.685438+00:00",
      "updated_at": "2026-01-26T20:20:57.063860+00:00",
      "metadata": {
        "processed_at": "2026-01-26T20:20:57.063862+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "c0346ea40590698a825bf3f8bf36cb35",
      "url": "https://www.theregister.com/2026/01/26/cursor_opinion/",
      "title": "When AI 'builds a browser,' check the repo before believing the hype",
      "content": "<p>Article URL: <a href=\"https://www.theregister.com/2026/01/26/cursor_opinion/\">https://www.theregister.com/2026/01/26/cursor_opinion/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46769965\">https://news.ycombinator.com/item?id=46769965</a></p>\n<p>Points: 25</p>\n<p># Comments: 0</p>",
      "author": "CrankyBear",
      "published_date": "2026-01-26T18:58:37+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2026-01-26T19:44:51.394525+00:00",
      "updated_at": "2026-01-26T20:20:57.063869+00:00",
      "metadata": {
        "processed_at": "2026-01-26T20:20:57.063871+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "34bee8f48f95f50d92a9f9f36f414b5f",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.23.700559v1?rss=1",
      "title": "Csf1r-mediated depletion of midbrain microglia prevents dopaminergic neuron loss during chronic colitis",
      "content": "Inflammatory bowel disease (IBD) predisposes to neuropsychiatric comorbidity and particularly increases the risk of Parkinson's Disease (PD) in later life. Although the gut-immune-brain axis was proposed as a link between IBD and PD and a driver of PD immunopathogenesis, the regional pattern and single-cell landscape of the brain immune response during colitis and its contribution to PD pathology remain poorly defined. Here, we observe a loss of dopaminergic neurons in the substantia nigra pars compacta of adult mice with chronic colitis. By confocal microscopy and integrated multi-omics, we reveal a complex midbrain-centered immune response to chronic colitis in comparison to the cortex, hippocampus, and striatum. Single-cell mapping of the midbrain immune landscape showed an inflammatory shift of microglial clusters including an expansion of interferon-response microglia, CD8+ T cell extravasation, and increased numbers of vessel-associated neutrophils. Selective myeloid cell depletion using a colony stimulating factor 1 receptor (Csf1r) inhibitor after colitis onset reduced midbrain microglia by 67% and led to a complete rescue of dopaminergic neuron loss, without affecting mucosal pathology or T cell and neutrophil migration to the midbrain. Collectively, within the complex innate and adaptive midbrain immune response to chronic colitis, we demonstrate a causal role of Csf1r-dependent microglia for dopaminergic neurodegeneration. Thus, Csf1r inhibition in IBD may not locally ameliorate colitis, but provide neuroprotection to dopaminergic neurons. These results reveal a novel cellular link between chronic gut-derived peripheral inflammation and midbrain vulnerability and thereby substantially enhance our understanding of the risk for PD related to the gut-immune-brain axis.",
      "author": "Kutscherauer, R. K., Stolzer, I., Neumaier, E. E., Dedden, M., Kielkowski, P., Xiang, W., Grotemeyer, A., Prinz, M., Masuda, T., Knobeloch, K.-P., Rothhammer, V., Zundler, S., Schlachetzki, J. C., Winkler, J., Guenther, C., Suess, P.",
      "published_date": "2026-01-26T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 250,
      "reading_time": 1,
      "created_at": "2026-01-26T19:25:26.896870+00:00",
      "updated_at": "2026-01-26T20:20:57.063873+00:00",
      "metadata": {
        "processed_at": "2026-01-26T20:20:57.063875+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "b465bbdad04aef1f48c3afb94c7c8fc2",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.23.701404v1?rss=1",
      "title": "Can category-selective cortex predict categorisation behaviour?",
      "content": "One of the distinctive features of the human visual system is the presence in occipito-temporal cortex (OTC) of regions that show preferential activation to specific categories of visual objects. To understand how this selectivity relates to categorisation behaviour, studies have employed a distance-to-bound approach (DTB), where multivariate brain activity is used to estimate a decision boundary, from which behavioural performance can be predicted. Using this approach, correlations have been found between activity in OTC, and behavioural performance when carrying out certain categorisation tasks. However, it remains unclear what determines where in OTC this correlations can be found, and with which categorisation tasks they can be found. Here, we bridged this gap by relating category selective regions of OTC, to behavioural performance while participants categorised images as belonging or not to their preferred categories. We adopted a more basic approach and considered simple, univariate activity, rather than relying on decoding to build our DTB. Our results show that activation in regions selective to faces (FFA & OFA), bodies (EBA), and scenes (PPA), is sufficient to predict behavioural performance while categorising images as being faces, bodies, or scenes, respectively. These results are largely consistent across reaction time and motor movements, and generalise to animacy classification. Overall, our data adds to evidence that category-selective regions in OTC can serve to guide categorisation behaviour, and underlines the validity of the DTB approach to address this relationship.",
      "author": "Maniquet, T., Fang, H., Ratan Murty, N. A., Op de Beeck, H.",
      "published_date": "2026-01-26T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 232,
      "reading_time": 1,
      "created_at": "2026-01-26T19:25:26.896823+00:00",
      "updated_at": "2026-01-26T19:25:26.896827+00:00"
    },
    {
      "id": "8b9b0be1ee6e3c0a720e04a8768fb860",
      "url": "https://rendiment.io/postgresql/2026/01/21/pgtrgm-pgvector-music.html",
      "title": "Find 'Abbey Road when type 'Beatles abbey rd': Fuzzy/Semantic search in Postgres",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46709461\">Comments</a>",
      "author": "",
      "published_date": "2026-01-21T18:24:55+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-26T19:24:48.822984+00:00",
      "updated_at": "2026-01-26T19:24:48.822985+00:00"
    },
    {
      "id": "9bc1fe843fd9dd1d93f3f67916849604",
      "url": "https://workdaycase.com",
      "title": "Notice of Collective Action Lawsuit Against Workday, INC",
      "content": "<p>Article URL: <a href=\"https://workdaycase.com\">https://workdaycase.com</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46769668\">https://news.ycombinator.com/item?id=46769668</a></p>\n<p>Points: 6</p>\n<p># Comments: 0</p>",
      "author": "mooreds",
      "published_date": "2026-01-26T18:37:37+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2026-01-26T19:24:47.561883+00:00",
      "updated_at": "2026-01-26T19:24:47.561892+00:00"
    },
    {
      "id": "d8e5cf334e33e5cd2f643958699c3739",
      "url": "https://www.greptile.com/blog/ai-code-review-bubble",
      "title": "There is an AI code review bubble",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46766961\">Comments</a>",
      "author": "",
      "published_date": "2026-01-26T15:38:50+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-26T18:38:29.982327+00:00",
      "updated_at": "2026-01-26T18:38:29.982328+00:00"
    },
    {
      "id": "39404ce9d470ece6100c0b12cac22fce",
      "url": "https://nproject.io/blog/juicessh-give-me-back-my-pro-features/",
      "title": "JuiceSSH \u2013 Give me my pro features back",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46768909\">Comments</a>",
      "author": "",
      "published_date": "2026-01-26T17:46:38+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-26T18:38:29.982270+00:00",
      "updated_at": "2026-01-26T18:38:29.982271+00:00"
    }
  ]
}