{
  "last_updated": "2025-11-17T04:35:45.459223+00:00",
  "count": 20,
  "articles": [
    {
      "id": "3253e34d22d1c5457279d59dddc23124",
      "url": "https://www.sciencedirect.com/science/article/pii/S0306452225009868?dgcid=rss_sd_all",
      "title": "Comprehensive analysis of the prognostic value and immune infiltration of Uridine Monophosphate Synthetase (UMPS) in Pan-Glioma",
      "content": "<p>Publication date: 5 December 2025</p><p><b>Source:</b> Neuroscience, Volume 590</p><p>Author(s): Dong He, Xiaokun Jiang, Jinfeng Ma, Jinyan Chen, Yongfei Zhang, Xixi Dou, Qingwen Jia, Qian Liu, Ping Xie, Zhen Zhang</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroscience Journal",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 28,
      "reading_time": 1,
      "created_at": "2025-11-17T04:00:27.630458+00:00",
      "updated_at": "2025-11-17T04:21:52.051661+00:00",
      "metadata": {
        "processed_at": "2025-11-17T04:21:52.051670+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "4962c7307c1d0790faec32482dc3b2f2",
      "url": "https://www.reddit.com/r/Python/comments/1oz4x0f/ultrastrict_python_template_v2_uv_ruff/",
      "title": "Ultra-strict Python template v2 (uv + ruff + basedpyright)",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>Some time ago I shared a strict Python project setup. I\u2019ve since reworked and simplified it, and this is the <strong>new version</strong>.</p> <blockquote> <p><strong>pystrict-strict-python</strong> \u2013 an ultra-strict Python project template using <code>uv</code>, <code>ruff</code>, and <code>basedpyright</code>, inspired by TypeScript\u2019s <code>--strict</code> mode.</p> </blockquote> <p>Compared to my previous post, this version:</p> <ul> <li>focuses on a single <strong>pyproject.toml</strong> as the source of truth,</li> <li>switches to <code>basedpyright</code> with a clearer strict configuration,</li> <li>tightens the ruff rules and coverage settings,</li> <li>and is easier to drop into new or existing projects.</li> </ul> <p><strong>What it gives you</strong></p> <ul> <li><strong>Strict static typing</strong> with <code>basedpyright</code> (TS <code>--strict</code> style rules): <ul> <li>No implicit <code>Any</code></li> <li>Optional/<code>None</code> usage must be explicit</li> <li>Unused imports / variables / functions are treated as errors</li> </ul></li> <li><strong>Aggressive linting &amp; formatting</strong> with <code>ruff</code>: <ul> <li>pycodestyle, pyflakes, isort</li> <li>bugbear, security checks, performance, annotations, async, etc.</li> </ul></li> <li><strong>Testing &amp; coverage</strong>: <ul> <li><code>pytest</code> + <code>coverage</code> with 80% coverage enforced by default</li> </ul></li> <li><strong>Task runner via <code>poethepoet</code></strong>: <ul> <li><code>poe format</code> \u2192 format + lint + type check</li> <li><code>poe check</code> \u2192 lint + type check (no auto-fix)</li> <li><code>poe metrics</code> \u2192 dead code + complexity + maintainability</li> <li><code>poe quality</code> \u2192 full quality pipeline</li> </ul></li> <li><strong>Single-source config</strong>: everything is in <strong>pyproject.toml</strong></li> </ul> <p><strong>Use cases</strong></p> <ul> <li><p><strong>New projects</strong>:<br /> Copy the <strong>pyproject.toml</strong>, adjust the <code>[project]</code> metadata, create <code>src/your_package</code> + <code>tests/</code>, and install with:</p> <p>```bash uv venv .venv\\Scripts\\activate # Windows</p> <h1>or: source .venv/bin/activate</h1> <p>uv pip install -e &quot;.[dev]&quot; ```</p> <p>Then your daily loop is basically:</p> <p><code>bash uv run ruff format . uv run ruff check . --fix uv run basedpyright uv run pytest </code></p></li> <li><p><strong>Existing projects</strong>:<br /> You don\u2019t have to go \u201call in\u201d on day 1. You can cherry-pick:</p> <ul> <li>the <code>ruff</code> config,</li> <li>the <code>basedpyright</code> config,</li> <li>the pytest/coverage sections,</li> <li>and the dev dependencies,</li> </ul> <p>and progressively tighten things as you fix issues.</p></li> </ul> <p><strong>Why I built this v2</strong></p> <p>The first version worked, but it was a bit heavier and less focused. In this iteration I wanted:</p> <ul> <li>a cleaner, copy-pastable template,</li> <li>stricter typing rules by default,</li> <li>better defaults for dead code, complexity, and coverage,</li> <li>and a straightforward workflow that feels natural to run locally and in CI.</li> </ul> <p><strong>Repo</strong></p> <p>\ud83d\udc49 <a href=\"https://github.com/Ranteck/PyStrict-strict-python\">GitHub link here</a></p> <p>If you saw my previous post and tried that setup, I\u2019d love to hear how this version compares. Feedback very welcome:</p> <ul> <li>Rules that feel too strict or too lax?</li> <li>Basedpyright / ruff settings you\u2019d tweak?</li> <li>Ideas for a \u201cgradual adoption\u201d profile for large legacy codebases?</li> </ul> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Ranteck\"> /u/Ranteck </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1oz4x0f/ultrastrict_python_template_v2_uv_ruff/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1oz4x0f/ultrastrict_python_template_v2_uv_ruff/\">[comments]</a></span>",
      "author": "/u/Ranteck",
      "published_date": "2025-11-17T02:46:14+00:00",
      "source": "Reddit Python",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 426,
      "reading_time": 2,
      "created_at": "2025-11-17T03:59:43.472531+00:00",
      "updated_at": "2025-11-17T04:21:52.051674+00:00",
      "metadata": {
        "processed_at": "2025-11-17T04:21:52.051677+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "f987d9fd50052e48125e25bb3e4c804a",
      "url": "https://www.reddit.com/r/Python/comments/1oz3zqn/best_way_to_avoid_getting_rusty_with_python/",
      "title": "best way to avoid getting rusty with Python?",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>I don\u2019t code in Python daily, more like off and on for side projects or quick scripts. But every time I come back, it takes me a sec to get back in the groove. What do y\u2019all do to keep your Python skills fresh? Any favorite mini projects, sites, or habits that actually help?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Enlitenkanin\"> /u/Enlitenkanin </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1oz3zqn/best_way_to_avoid_getting_rusty_with_python/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1oz3zqn/best_way_to_avoid_getting_rusty_with_python/\">[comments]</a></span>",
      "author": "/u/Enlitenkanin",
      "published_date": "2025-11-17T02:02:50+00:00",
      "source": "Reddit Python",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 75,
      "reading_time": 1,
      "created_at": "2025-11-17T03:59:43.472469+00:00",
      "updated_at": "2025-11-17T04:21:52.051679+00:00",
      "metadata": {
        "processed_at": "2025-11-17T04:21:52.051681+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "5fc16aac7b513192595040d8cb3adddd",
      "url": "https://www.biorxiv.org/content/10.1101/2025.11.16.686778v1?rss=1",
      "title": "Fast Optimization of Robust Transcriptomics Embeddings using Probabilistic Inference Autoencoder Networks for multi-Omics",
      "content": "Advances in single-cell genomics technologies enable the routine acquisition of atlases with millions of cells. These datasets often include multiple sources of variation, such as donors, sequencing platforms, developmental timepoints, and species. Although these covariates provide new opportunities for discovery, they also present challenges for downstream analyses. To mitigate unwanted sources of variation, dataset integration is the starting point for most analyses. However, existing methods struggle with integrating large and complex datasets. To address these limitations, we developed PIANO, a variational autoencoder framework that uses a negative binomial generalized linear model for stronger batch correction, and code compilation for up to ten times faster training than existing tools. We first demonstrate performant integration compared to commonly used integration methods on single-species datasets. We then show PIANO enables superior analyses of multiple atlases, solving challenging integration tasks across sequencing platforms, developmental timepoints, and species, while simultaneously preserving desired biological signals. Our contributions include a novel, high-performance integration method and recommendations for integration applications.",
      "author": "Wang, N., Turner, D., Feinberg, H., Nieto Caballero, V. E., Yuan, D., Scott, N., Cardenas, C., DeBerardine, M., Dan, S., Caceres, L., Schembri, J., Yao, Z., Lee, C., Pillow, J. W., Krienen, F. M.",
      "published_date": "2025-11-16T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 162,
      "reading_time": 1,
      "created_at": "2025-11-17T03:17:36.641086+00:00",
      "updated_at": "2025-11-17T04:21:52.051683+00:00",
      "metadata": {
        "processed_at": "2025-11-17T04:21:52.051685+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "faedb2a4a699c9dfd41ac541edecb653",
      "url": "https://www.nature.com/articles/s41392-025-02474-7",
      "title": "Engineered butyrate-producing yeasts mitigate Alzheimer-associated phenotypes",
      "content": "",
      "author": "",
      "published_date": "2025-11-17T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-11-17T03:17:35.414954+00:00",
      "updated_at": "2025-11-17T04:21:52.051687+00:00",
      "metadata": {
        "processed_at": "2025-11-17T04:21:52.051688+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "adc4781ea11d927ebc2d92cc947ef47f",
      "url": "https://www.frontiersin.org/articles/10.3389/fninf.2025.1647194",
      "title": "Speech pattern disorders in verbally fluent individuals with autism spectrum disorder: a machine learning analysis",
      "content": "IntroductionDiagnosing Autism Spectrum Disorder (ASD) in verbally fluent individuals based on speech patterns in examiner-patient dialogues is challenging because speech-related symptoms are often subtle and heterogeneous. This study aimed to identify distinctive speech characteristics associated with ASD by analyzing recorded dialogues from the Autism Diagnostic Observation Schedule (ADOS-2).MethodsWe analyzed examiner-participant dialogues from ADOS-2 Module 4 and extracted 40 speech-related features categorized into intonation, volume, rate, pauses, spectral characteristics, chroma, and duration. These acoustic and prosodic features were processed using advanced speech analysis tools and used to train machine learning models to classify ASD participants into two subgroups: those with and without A2-defined speech pattern abnormalities. Model performance was evaluated using cross-validation and standard classification metrics.ResultsUsing all 40 features, the support vector machine (SVM) achieved an F1-score of 84.49%. After removing Mel-Frequency Cepstral Coefficients (MFCC) and Chroma features to focus on prosodic, rhythmic, energy, and selected spectral features aligned with ADOS-2 A2 scores, performance improved, achieving 85.77% accuracy and an F1-score of 86.27%. Spectral spread and spectral centroid emerged as key features in the reduced set, while MFCC 6 and Chroma 4 also contributed significantly in the full feature set.DiscussionThese findings demonstrate that a compact, diverse set of non-MFCC and selected spectral features effectively characterizes speech abnormalities in verbally fluent individuals with ASD. The approach highlights the potential of context-aware, data-driven models to complement clinical assessments and enhance understanding of speech-related manifestations in ASD.",
      "author": "Xin Li",
      "published_date": "2025-10-24T00:00:00+00:00",
      "source": "Frontiers Neuroinformatics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 233,
      "reading_time": 1,
      "created_at": "2025-11-17T03:17:28.632365+00:00",
      "updated_at": "2025-11-17T03:17:28.632367+00:00"
    },
    {
      "id": "81906f3f8b91f72233a0ce8a97740e16",
      "url": "https://www.frontiersin.org/articles/10.3389/fncom.2025.1691017",
      "title": "Triboelectric nanogenerators for neural data interpretation: bridging multi-sensing interfaces with neuromorphic and deep learning paradigms",
      "content": "The rapid growth of computational neuroscience and brain\u2013computer interface (BCI) technologies require efficient, scalable, and biologically compatible approaches for neural data acquisition and interpretation. Traditional sensors and signal processing pipelines often struggle with the high dimensionality, temporal variability, and noise inherent in neural signals, particularly in elderly populations where continuous monitoring is essential. Triboelectric nanogenerators (TENGs), as self-powered and flexible multi-sensing devices, offer a promising avenue for capturing neural-related biophysical signals such as electroencephalography (EEG), electromyography (EMG), and cardiorespiratory dynamics. Their low-power and wearable characteristics make them suitable for long-term health and neurocognitive monitoring. When combined with deep learning models\u2014including convolutional neural networks (CNNs), recurrent neural networks (RNNs), and spiking neural networks (SNNs)\u2014TENG-generated signals can be efficiently decoded, enabling insights into neural states, cognitive functions, and disease progression. Furthermore, neuromorphic computing paradigms provide an energy-efficient and biologically inspired framework that naturally aligns with the event-driven characteristics of TENG outputs. This mini review highlights the convergence of TENG-based sensing, deep learning algorithms, and neuromorphic systems for neural data interpretation. We discuss recent progress, challenges, and future perspectives, with an emphasis on applications in computational neuroscience, neurorehabilitation, and elderly health care.",
      "author": "Bin Jia",
      "published_date": "2025-11-07T00:00:00+00:00",
      "source": "Frontiers Computational Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 189,
      "reading_time": 1,
      "created_at": "2025-11-17T03:17:27.237443+00:00",
      "updated_at": "2025-11-17T03:17:27.237444+00:00"
    },
    {
      "id": "937601e293e87eaa770afad6efba0ad6",
      "url": "https://www.frontiersin.org/articles/10.3389/fncom.2025.1661070",
      "title": "Neural heterogeneity as a unifying mechanism for efficient learning in spiking neural networks",
      "content": "The brain is a highly diverse and heterogeneous network, yet the functional role of this neural heterogeneity remains largely unclear. Despite growing interest in neural heterogeneity, a comprehensive understanding of how it influences computation across different neural levels and learning methods is still lacking. In this work, we systematically examine the neural computation of spiking neural networks (SNNs) in three key sources of neural heterogeneity: external, network, and intrinsic heterogeneity. We evaluate their impact using three distinct learning methods, which can carry out tasks ranging from simple curve fitting to complex network reconstruction and real-world applications. Our results show that while different types of neural heterogeneity contribute in distinct ways, they consistently improve learning accuracy and robustness. These findings suggest that neural heterogeneity across multiple levels improves learning capacity and robustness of neural computation, and should be considered a core design principle in the optimization of SNNs.",
      "author": "Jingjing Cui",
      "published_date": "2025-11-07T00:00:00+00:00",
      "source": "Frontiers Computational Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 147,
      "reading_time": 1,
      "created_at": "2025-11-17T03:17:27.237402+00:00",
      "updated_at": "2025-11-17T03:17:27.237403+00:00"
    },
    {
      "id": "3455439c730dc268ae9c043416fbd943",
      "url": "https://www.frontiersin.org/articles/10.3389/fnhum.2025.1653894",
      "title": "Emotion, proficiency, and arousal: exploring speech and physiological responses in Chinese ESL learners",
      "content": "IntroductionThe coordination and expression of cultural specific affective cues during speech production in a second language (L2) reflects pragmatic adaptation, which is a critical step toward learning and achieving broader pragmatic competence. Embodied cognition provides a framework for understanding how cognitive and emotional processes shape L2 expression.ObjectiveThis study examined how immersive language experience influences pragmatic adaptation through the vocal expression of affect and physiological arousal in Chinese ESL learners.MethodsAcoustic analysis and electrodermal activity (EDA) measurements were used to assess affectively valenced word production in speakers with varying levels of immersive English experience.ResultsHigh-immersion speakers exhibited greater pitch, intensity, and duration variation, enhancing emotional expressivity. Low-immersion speakers showed constrained vocal patterns and significantly higher physiological arousal, likely due to increased cognitive demands and anxiety.DiscussionThese findings highlight the impact of L2 proficiency on affective language embodiment and the cognitive challenges faced by L2 learners. This study offers novel insights by considering a pictorial character-based language, broadening our understanding of emotion-language interaction. Findings have implications for second-language education, cross-cultural communication, and bilingual speech therapy.",
      "author": "Jennifer M. Roche",
      "published_date": "2025-11-11T00:00:00+00:00",
      "source": "Frontiers Human Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 170,
      "reading_time": 1,
      "created_at": "2025-11-17T03:17:25.991558+00:00",
      "updated_at": "2025-11-17T03:17:25.991559+00:00"
    },
    {
      "id": "21387330fd0768b022f3b44b9ba5e195",
      "url": "https://www.reddit.com/r/Python/comments/1oyf7ep/transforming_a_pair_of_lists_into_a_dictionary_in/",
      "title": "Transforming a pair of lists into a dictionary in Python",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>For given input lists &quot;keys and &quot;values&quot;, create a dictionary from two input lists #python #list #dictionary #cogianova #zip_function</p> <p><a href=\"https://youtu.be/uZVWVOJ1WSU\">https://youtu.be/uZVWVOJ1WSU</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/CogIANova\"> /u/CogIANova </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1oyf7ep/transforming_a_pair_of_lists_into_a_dictionary_in/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1oyf7ep/transforming_a_pair_of_lists_into_a_dictionary_in/\">[comments]</a></span>",
      "author": "/u/CogIANova",
      "published_date": "2025-11-16T07:09:09+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 42,
      "reading_time": 1,
      "created_at": "2025-11-17T03:17:00.790395+00:00",
      "updated_at": "2025-11-17T03:17:00.790396+00:00"
    },
    {
      "id": "6d9d68686b08808e85047b41f3c800f6",
      "url": "https://www.reddit.com/r/Python/comments/1oyhies/i_built_a_program_that_predicts_league_game/",
      "title": "I built a program that predicts League game outcomes from drafts with 56% accuracy, thoughts on what",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>I've built a program on python that uses all pro League of Legends games from 2020 to now to calculate which pro team has the better winning odds from the draft.</p> <p>It uses factors like counter matchups, synergies, champion's strength levels each patch based on their winrate and how often they are picked or banned and some more stuff, and with hundreds of thousands of simulations on past years I've chosen the best &quot;settings&quot; (eg. how much does mid-lane matchups weigh in vs the rest) for optimal prediction based on drafts.</p> <p>I've made a discord server called Draft Edge Beta to put theory into practice, and coded a bot to signal when there is a &quot;draft gap&quot;, which means the ROI of betting on a certain team is positive. The bot tells you what team to bet on, how many units to bet and the breakeven odds (let's say from my program T1 has a 50% chance to win the game, T1's breakeven odds is 2.00, which means you should bet on T1 if the but is above 2).</p> <p>Right now since the end of July after 240 games, we are up 30 units and have a 56.25% win rate on bets since July while only tracking about 75% of the games (I'm human lol), which syncs with the numbers from the simulations where we were making about 60 units per year.</p> <p>I know I'm sitting on a lottery ticket because all the math adds up: I've been perfecting the program for a while now and running hundreds of thousands of simulations to assure that, now I'm just wondering what to do with it, which is why I came here.</p> <p>I could make a website with data from pro games ressembling opgg, or I could also just launch Draft Edge as another subscription-based discord server for the upcoming season, but to do so I would have to make a better front-end and probably hire 1-2 people so we don't miss any games.</p> <p>I'm also wondering how much people would be willing to pay per month with a 40% referall system on whop, and basically what you guys think of it.</p> <p>Feel free to ask any question or give any thoughts, would be much appreciated</p> <p>Here's the link to the discord (the beta): <a href=\"https://discord.gg/mnQ7DfXs\">https://discord.gg/mnQ7DfXs</a><br /> Here's the link to the twitter page: <a href=\"https://x.com/draftedgelol?s=11\">https://x.com/draftedgelol?s=11</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Top-Share-4511\"> /u/Top-Share-4511 </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1oyhies/i_built_a_program_that_predicts_league_game/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1oyhies/i_built_a_program_that_predicts_league_game/\">[comments]</a></span>",
      "author": "/u/Top-Share-4511",
      "published_date": "2025-11-16T09:33:33+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 415,
      "reading_time": 2,
      "created_at": "2025-11-17T03:17:00.790371+00:00",
      "updated_at": "2025-11-17T03:17:00.790373+00:00"
    },
    {
      "id": "38e27474f98a89989ae806e317ce9f35",
      "url": "https://minivac.greg.technology/",
      "title": "A 1961 Relay Computer Running in the Browser",
      "content": "<a href=\"https://news.ycombinator.com/item?id=45950396\">Comments</a>",
      "author": "",
      "published_date": "2025-11-17T02:36:18+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-11-17T03:16:59.602218+00:00",
      "updated_at": "2025-11-17T03:16:59.602219+00:00"
    },
    {
      "id": "38e27474f98a89989ae806e317ce9f35",
      "url": "https://minivac.greg.technology/",
      "title": "A 1961 Relay Computer Running in the Browser",
      "content": "<p>Article URL: <a href=\"https://minivac.greg.technology/\">https://minivac.greg.technology/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=45950396\">https://news.ycombinator.com/item?id=45950396</a></p>\n<p>Points: 6</p>\n<p># Comments: 2</p>",
      "author": "vaibhavsagar",
      "published_date": "2025-11-17T02:36:18+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-11-17T03:16:58.205529+00:00",
      "updated_at": "2025-11-17T03:16:58.205539+00:00"
    },
    {
      "id": "5a99b6852a6b1306453c38854c0ed2d7",
      "url": "https://www.biorxiv.org/content/10.1101/2025.11.14.688497v1?rss=1",
      "title": "Cochlear histopathology in macaques after noise-induced temporary threshold shifts",
      "content": "Noise exposures causing transient hearing loss were previously considered benign. However, recent work has revealed that temporary noise-induced threshold shifts may be associated with long-lasting cochlear histopathology. One such effect is cochlear synaptopathy, i.e. changes to the afferent synapse between inner hair cells and auditory nerve fibers. Noise-induced synaptopathy has been extensively characterized in several rodent models, and temporal bone studies suggest similar age-related changes in humans. However, it remains unclear how noise-induced temporary threshold shifts affect cochlear structures in humans and nonhuman primates, which show greater resistance to noise exposure than other animals. Additionally, the long-term sequelae of temporary threshold shifts are largely unknown. Here, we characterized the effects of a noise exposure causing temporary hearing loss on cochlear histopathology in macaque monkeys at long post-exposure survival times. Overall, cochlear histopathology was variable across subjects, similar to the variable susceptibility observed in humans. At 2 and 10 months post-exposure, macaques had no significant loss of hair cells, inner hair cell synapses, or cholinergic efferent innervation. However, enlargement of ribbons in both inner and outer hair cells was observed. Together, these findings provide insight into the cochlear effects of single-exposure temporary threshold shifts in nonhuman primates.",
      "author": "Mondul, J., Mackey, C. A., Conner, A. N., Alek, C. A., Pitchford, D., Rausis, O., Liberman, L., Liberman, C., Ramachandran, R., Hackett, T. A.",
      "published_date": "2025-11-16T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 196,
      "reading_time": 1,
      "created_at": "2025-11-17T01:42:02.433284+00:00",
      "updated_at": "2025-11-17T03:12:38.655837+00:00",
      "metadata": {
        "processed_at": "2025-11-17T03:12:38.655848+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "21c462aa5bd17b81d74a4f2bea554ae2",
      "url": "https://www.biorxiv.org/content/10.1101/2025.11.16.688675v1?rss=1",
      "title": "Deciphering the role of brainstem vestibular-related inhibitory networks in shaping postural reflexes in the Xenopus tadpole",
      "content": "Brainstem vestibulospinal (VS) nuclei generate excitatory commands in response to multi-modality sensory integration, to activate specific spinal networks in order to generate adapted postural reflexes. Comparably organized in bilateral nuclei with both ipsi- and contralateral pathways in all species, excitatory VS projections alone fail to explain the mostly unilateral reflex responses typically observed. In the Xenopus laevis tadpole, we describe secondary vestibular neurons of inhibitory nature, and the synaptic contacts they make on VS neurons. Then, using a brainstem/spinal cord in vitro preparation we show that the spinal responses evoked by galvanic vestibular stimulation are shaped by both commissural and local inhibitory brainstem networks. We further show that a complex interaction between GABAergic and glycinergic inhibitory networks regulate VS neuron excitability and, consequently, the expression of the spinal response. Our data reveal that while excitatory VS neurons execute the neural score, inhibitory neurons in the central vestibular system coordinate and modulate the overall performance.",
      "author": "Lavenu, L., Pain, M., Barrios, G., Cardoit, L., Boulain, M., Duveau, A., Tostivint, H., Lambert, F. M., Fossat, P., Le Ray, D.",
      "published_date": "2025-11-16T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 154,
      "reading_time": 1,
      "created_at": "2025-11-17T01:42:02.433250+00:00",
      "updated_at": "2025-11-17T03:12:38.655852+00:00",
      "metadata": {
        "processed_at": "2025-11-17T03:12:38.655854+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "02110431a335b3ee1cb90671d5c013cf",
      "url": "https://www.biorxiv.org/content/10.1101/2025.11.15.688248v1?rss=1",
      "title": "No Evidence for Stronger Brain-Behavior Associations in the Bimanual Motor Network of Older Adults",
      "content": "Bimanual motor performance declines with age, is accompanied by cortical thinning and alterations in white matter microstructure within motor control networks. Aging is also associated with increased interindividual variability in behavioural and structural markers, and some studies report stronger brain-behaviour associations in older compared to younger adults. However, evidence for this remains mixed, and it is unclear whether young adults express similar relationships under comparable task demands. We tested whether bimanual performance is related differently to structural brain properties in younger and older adults. Twenty-three younger (22-27 years) and twenty-three older adults (65-70 years) performed a visually guided bimanual pinch-force task and underwent whole-brain structural magnetic resonance imaging (MRI). Fractional anisotropy (FA) and cortical thickness (CTh) were extracted from a pre-defined bilateral visuo-motor network and compared between groups. In regions showing significant age-related differences, we tested whether and how FA and CTh values correlates with bimanual performance within each age group. Older adults showed lower FA in the anterior portions of the bilateral superior longitudinal fasciculus (SLF) III and right inferior fronto-occipital fasciculus (IFOF), and lower CTh across most visuomotor regions, along with lower bimanual performance compared to young adults. Structure-function analyses in these areas revealed that bimanual performance correlated positively with FA in the anterior segment of the right SLF III in younger but not older adults. Furthermore, larger hemispheric asymmetries in cortical thickness between the dominant and non-dominant SMA correlated positively with larger intermanual performance differences between the dominant and non-dominant hand in younger but not older adults. These findings suggest that intrahemispheric white-matter integrity and interhemispheric cortical balance support efficient bimanual control in early adulthood, but they provide no evidence that structure-function relationships increase with age.",
      "author": "Noven, M., Lundbye-Jensen, J., Lundell, H., Siebner, H. R., Karabanov, A. N.",
      "published_date": "2025-11-16T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 279,
      "reading_time": 1,
      "created_at": "2025-11-17T01:42:02.433218+00:00",
      "updated_at": "2025-11-17T03:12:38.655856+00:00",
      "metadata": {
        "processed_at": "2025-11-17T03:12:38.655858+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "1ef518955c652975a90de516695eb6ab",
      "url": "https://www.biorxiv.org/content/10.1101/2025.11.14.687084v1?rss=1",
      "title": "Spontaneous otocoherence of the active ear",
      "content": "Spontaneous otoacoustic emission (SOAE) provides compelling evidence of active force generation inside the inner ear, although there is significant debate about the underlying generation mechanism(s). SOAE is commonly characterized by peaks in a spectral domain representation (as derived from a discrete Fourier transform), occurring at idiosyncratic frequencies unique to a given ear. Such is typically computed as an averaged magnitude spectrum that discards phase information. Here, we explore the hypothesis that SOAE phase, readily extracted from pre-existing recordings, contains complementary information. We propose several measures to use this information to quantify otocoherence (a form of autocoherence referring to a phenomenon of the ear), primarily by measuring the consistency in SOAE phase accumulation over a particular timescale. We present results based on recordings from different species with disparate inner ear morphologies (humans, barn owls, lizards). For regions of SOAE activity we extract time constants representing the timescale over which otocoherence is maintained. We demonstrate that these vary significantly across species and (for the barn owl and Tokay gecko where this data is available) appear to correlate with measures of auditory nerve fiber tuning. Additionally, we adapted the method to identify regions of weak SOAE activity among fluctuations in the noise floor. These methods can readily be employed to re-analyze SOAE waveforms previously collected from a variety of species, making them of broader comparative utility to reveal information about SOAE generation and thereby active cochlear mechanics.",
      "author": "Peacock, S. N. S., Vencovsky, V., Whiley, R. E., Mhatre, N., Bergevin, C.",
      "published_date": "2025-11-16T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 234,
      "reading_time": 1,
      "created_at": "2025-11-17T01:42:02.433177+00:00",
      "updated_at": "2025-11-17T03:12:38.655860+00:00",
      "metadata": {
        "processed_at": "2025-11-17T03:12:38.655862+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "d7624a3b5be885cd8e18cc0c728c3a48",
      "url": "https://www.biorxiv.org/content/10.1101/2025.11.15.688542v1?rss=1",
      "title": "Locus Coeruleus alpha-Synuclein Overexpression Induces Prodromal Parkinsonian Features in Mice",
      "content": "The locus coeruleus is one of the first brain regions to develop alpha-synuclein pathology during the prodromal phase of Parkinson Disease, contributing significantly to non-motor symptoms such as cognitive decline, mood alterations or sleep disturbances. However, the precise role of the locus coeruleus in the early stages of the disease remains unclear. To address this, we developed and characterized a novel mouse model based on the PRSx8-driven overexpression of human alpha-synuclein in noradrenergic neurons of the locus coeruleus using an adeno-associated viral vector. Animals were assessed at 1 and 3 months post-injection using an integrated battery of histological, behavioural, neurochemical, and electrophysiological analyses. We observed robust accumulation of phosphorylated alpha-synuclein in the locus coeruleus, along with widespread propagation to projection areas, including the hippocampus, prefrontal cortex, and dorsal raphe. Despite the absence of neuronal loss in the locus coeruleus, we identified reduced noradrenergic axonal integrity and marked decreases in both noradrenaline and serotonin levels, highlighting a disruption of neurochemical balance at an early stage. The electrophysiological data revealed transient alterations in the excitability and intrinsic properties of locus coeruleus neurons in a sex-dependent manner, suggesting that alpha-synuclein pathology induces early functional disruption prior to overt neurodegeneration. Behavioural outcomes demonstrated selective cognitive deficits and mild anxiety-like behaviours, while other non-motor functions remained preserved. Importantly, although several pathological and functional alterations were evident in the initial phases, behavioural impairments were also maintained at later time points, indicating that locus coeruleus-driven pathology exerts long-lasting consequences. Interestingly, female mice exhibited colon shortening, providing evidence of a sex-specific pathological process at the level of the gut-brain axis. We believe that this model accurately replicates key prodromal features of Parkinson disease, demonstrating that alpha-synuclein-induced pathology in the locus coeruleus leads to functional circuit impairment and cognitive decline. Our findings emphasize the locus coeruleus as a critical site of early vulnerability in Parkinson Disease and underscore the importance of sex as a biological variable influencing disease progression and therapeutic response.",
      "author": "Razquin, J., DeLasHeras-Garcia, L., Vaquero-Rodriguez, A., Gonzalez-Aseguinolaza, G., Soria-Gomez, E., Baufreton, J. M., Bengoetxea, H., Ortuzar, N., Ortega, J. E., Miguelez, C.",
      "published_date": "2025-11-16T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 323,
      "reading_time": 1,
      "created_at": "2025-11-17T01:42:02.433141+00:00",
      "updated_at": "2025-11-17T03:12:38.655864+00:00",
      "metadata": {
        "processed_at": "2025-11-17T03:12:38.655866+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "c4fd5dda357f991021162aee3714083b",
      "url": "https://www.biorxiv.org/content/10.1101/2025.11.14.688528v1?rss=1",
      "title": "Cortical response to balance perturbation is more sensitive in modern dancers than nondancers during biomechanically similar balance recovery",
      "content": "Motor skill expertise can facilitate more automatic movement, engaging less cortical activity while producing appropriate motor output. Accordingly, cortical-evoked N1 responses to balance perturbation, assessed using electroencephalography (EEG), are smaller in young and older adults with better balance. These responses may thus reflect individual balance challenge versus functional, or objective, task difficulty. However, the effect of balance expertise on cortical responses to balance perturbation has not been studied. We hypothesized that balance ability gained though long-term training facilitates more automatic balance control. Using professional modern dancers as balance experts, we compared cortical-evoked responses and biomechanics of the balance-correcting response between modern dancers and nondancers. We predicted that modern dancers would have smaller cortical-evoked responses and better balance recovery at equivalent levels of balance challenge. Support-surface perturbations were normalized to individual challenge levels by delivering perturbations scaled to 60% and 140% of each individual's step threshold. In contrast to our prediction, dancers exhibited larger N1 responses compared to nondancers while demonstrating similar biomechanical responses. Our results suggest dancers have greater cortical sensitivity to balance perturbations than nondancers. Further, dancer N1 responses modulated across perturbation magnitudes according to differences in objective task difficulty. In contrast, nondancer N1 responses modulated as a function of individual challenge level. Our findings suggest dance training increases sensitivity of the initial, cortical N1 response to balance perturbation, supporting postural alignment to an objective reference. The N1 response may reflect differences in balance-error processing that are altered with specific long-term training and may have implications for rehabilitation.",
      "author": "Kerr, K. G., Boebinger, S. E., Mirdamadi, J. L., Protzak, J., Borich, M. R., Ting, L. H.",
      "published_date": "2025-11-16T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 249,
      "reading_time": 1,
      "created_at": "2025-11-17T01:42:02.433090+00:00",
      "updated_at": "2025-11-17T01:42:02.433091+00:00"
    },
    {
      "id": "f9fa55617c00531e8c3df278d5dd852c",
      "url": "https://www.biorxiv.org/content/10.1101/2025.11.14.688311v1?rss=1",
      "title": "Live longitudinal imaging of meningeal cerebrovascular injury and its sequelae in adult zebrafish",
      "content": "Nearly 1.4 million people in the United States sustain a traumatic brain injury (TBI) each year, with almost half of those hospitalized for TBI developing long-term disability. For many patients, prolonged bleeding and inflammation from damaged vessels in the meninges result in long-lasting sequelae. Although their injured blood vessels regrow, the site of injury is full of inflammatory immune cells that may influence vascular function. Adult zebrafish have a thin, translucent skull and a mammalian-like meninges that is easily imaged in living animals. We have established a novel adult zebrafish model to investigate vessel-immune cell interactions after meningeal cerebrovascular injury (mCVI). We use carefully calibrated sonication to rupture meningeal blood vessels without breaching the skull or causing damage to the underlying brain. By performing longitudinal live imaging of intubated adult fish we observe vascular regrowth and immune responses to mCVI over time in the same animal with unprecedented resolution allowing measurement of blood flow, dynamics of vessel regrowth, and interactions between individual immune and vascular cells. This newly developed zebrafish model provides a powerful tool for longitudinal live imaging of meningeal immune cell-vascular interactions after cerebrovascular injury, opening the door to new insights into chronic neuroinflammatory disease.",
      "author": "Kraus, A., Prosper-Santiago, J. S., Potopova, A., Prevedel, J., Castranova, D., Weinstein, B.",
      "published_date": "2025-11-16T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 197,
      "reading_time": 1,
      "created_at": "2025-11-17T01:42:02.433051+00:00",
      "updated_at": "2025-11-17T01:42:02.433053+00:00"
    }
  ]
}