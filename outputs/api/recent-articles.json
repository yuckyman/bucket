{
  "last_updated": "2025-10-02T16:46:46.937052+00:00",
  "count": 20,
  "articles": [
    {
      "id": "ad1925564c97f30cab5b55e76f20793b",
      "url": "https://www.embs.org/blog-post/regional-shifts-and-patterns/",
      "title": "Bridging Biotech: Regional shifts and patterns",
      "content": "<p>The post <a href=\"https://www.embs.org/blog-post/regional-shifts-and-patterns/\">Bridging Biotech: Regional shifts and patterns</a> appeared first on <a href=\"https://www.embs.org\">IEEE EMBS</a>.</p>",
      "author": "dziura",
      "published_date": "2025-02-05T15:45:50+00:00",
      "source": "Embs",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 15,
      "reading_time": 1,
      "created_at": "2025-10-02T16:46:29.358248+00:00",
      "updated_at": "2025-10-02T16:46:29.358249+00:00"
    },
    {
      "id": "6b5f32570094f1cedcde640a7566d20a",
      "url": "https://www.embs.org/blog-post/welcoming-dr-ana-kyani-as-wibme-chair-ieee-embs/",
      "title": "Welcoming Dr. Ana Kyani as the New Women in Biomedical Engineering Chair for IEEE EMBS",
      "content": "<p>The post <a href=\"https://www.embs.org/blog-post/welcoming-dr-ana-kyani-as-wibme-chair-ieee-embs/\">Welcoming Dr. Ana Kyani as the New Women in Biomedical Engineering Chair for IEEE EMBS</a> appeared first on <a href=\"https://www.embs.org\">IEEE EMBS</a>.</p>",
      "author": "Nancy Zimmerman",
      "published_date": "2025-03-27T17:10:33+00:00",
      "source": "Embs",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 24,
      "reading_time": 1,
      "created_at": "2025-10-02T16:46:29.358229+00:00",
      "updated_at": "2025-10-02T16:46:29.358231+00:00"
    },
    {
      "id": "138dbc20af95ce55414e7d62214f9607",
      "url": "https://www.embs.org/press/embc-eic-sunghoon-ivan-lee/#new_tab",
      "title": "Ivan Lee, Appointed Editor-in-Chief of EMBC Proceedings",
      "content": "<p>&#160;</p>\n<p>The post <a href=\"https://www.embs.org/press/embc-eic-sunghoon-ivan-lee/#new_tab\">Ivan Lee, Appointed Editor-in-Chief of EMBC Proceedings</a> appeared first on <a href=\"https://www.embs.org\">IEEE EMBS</a>.</p>",
      "author": "Nancy Zimmerman",
      "published_date": "2025-09-08T16:27:03+00:00",
      "source": "Embs",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 17,
      "reading_time": 1,
      "created_at": "2025-10-02T16:46:29.358062+00:00",
      "updated_at": "2025-10-02T16:46:29.358066+00:00"
    },
    {
      "id": "a99eae14038f2392d9cd1e37f778675b",
      "url": "https://arxiv.org/abs/2510.00414",
      "title": "RELATE-Sim: Leveraging Turning Point Theory and LLM Agents to Predict and Understand Long-Term Relationship Dynamics through Interactive Narrative Simulations",
      "content": "arXiv:2510.00414v1 Announce Type: new \nAbstract: Most dating technologies optimize for getting together, not staying together. We present RELATE-Sim, a theory-grounded simulator that models how couples behave at consequential turning points-exclusivity talks, conflict-and-repair episodes, relocations-rather than static traits. Two persona-aligned LLM agents (one per partner) interact under a centralized Scene Master that frames each turning point as a compact set of realistic options, advances the narrative, and infers interpretable state changes and an auditable commitment estimate after each scene. On a longitudinal dataset of 71 couples with two-year follow-ups, simulation-aware predictions outperform a personas-only baseline while surfacing actionable markers (e.g., repair attempts acknowledged, clarity shifts) that explain why trajectories diverge. RELATE-Sim pushes the relationship research's focus from matchmaking to maintenance, providing a transparent, extensible platform for understanding and forecasting long-term relationship dynamics.",
      "author": "Matthew Yue, Zhikun Xu, Vivek Gupta, Thao Ha, Liesal Sharabi, Ben Zhou",
      "published_date": "2025-10-02T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 131,
      "reading_time": 1,
      "created_at": "2025-10-02T16:46:27.943273+00:00",
      "updated_at": "2025-10-02T16:46:27.943275+00:00"
    },
    {
      "id": "fcacbd1b4355b40ab55d92a95764e690",
      "url": "https://arxiv.org/abs/2510.00407",
      "title": "Investigating Encoding and Perspective for Augmented Reality",
      "content": "arXiv:2510.00407v1 Announce Type: new \nAbstract: Augmented reality (AR) offers promising opportunities to support movement-based activities, such as personal training or physical therapy, with real-time, spatially-situated visual cues. While many approaches leverage AR to guide motion, existing design guidelines focus on simple, upper-body movements within the user's field of view. We lack evidence-based design recommendations for guiding more diverse scenarios involving movements with varying levels of visibility and direction. We conducted an experiment to investigate how different visual encodings and perspectives affect motion guidance performance and usability, using three exercises that varied in visibility and planes of motion. Our findings reveal significant differences in preference and performance across designs. Notably, the best perspective varied depending on motion visibility and showing more information about the overall motion did not necessarily improve motion execution. We provide empirically-grounded guidelines for designing immersive, interactive visualizations for motion guidance to support more effective AR systems.",
      "author": "Jade Kandel, Sriya Kasumarthi, Spiros Tsalikis, Chelsea Duppen, Daniel Szafir, Michael Lewek, Henry Fuchs, Danielle Szafir",
      "published_date": "2025-10-02T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 149,
      "reading_time": 1,
      "created_at": "2025-10-02T16:46:27.943246+00:00",
      "updated_at": "2025-10-02T16:46:27.943247+00:00"
    },
    {
      "id": "d69c185466e15820a48e5107bd2c6653",
      "url": "https://arxiv.org/abs/2510.00361",
      "title": "Attribution Gradients: Incrementally Unfolding Citations for Critical Examination of Attributed AI Answers",
      "content": "arXiv:2510.00361v1 Announce Type: new \nAbstract: AI question answering systems increasingly generate responses with attributions to sources. However, the task of verifying the actual content of these attributions is in most cases impractical. In this paper, we present attribution gradients as a solution. Attribution gradients provide integrated, incremental affordances for diving into an attributed passage. A user can decompose a sentence of an answer into its claims. For each claim, the user can view supporting and contradictory excerpts mined from sources. Those excerpts serve as clickable conduits into the source (in our application, scientific papers). When evidence itself contains more citations, the UI unpacks the evidence into excerpts from the cited sources. These features of attribution gradients facilitate concurrent interconnections among answer, claim, excerpt, and context. In a usability study, we observed greater engagement with sources and richer revision in a task where participants revised an attributed AI answer with attribution gradients and a baseline.",
      "author": "Hita Kambhamettu, Alyssa Hwang, Philippe Laban, Andrew Head",
      "published_date": "2025-10-02T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 154,
      "reading_time": 1,
      "created_at": "2025-10-02T16:46:27.943217+00:00",
      "updated_at": "2025-10-02T16:46:27.943218+00:00"
    },
    {
      "id": "3ee0b12a623221da77e367811c6b5845",
      "url": "https://arxiv.org/abs/2510.00344",
      "title": "The Feng Shui of Visualization: Design the Path to SUCCESS and GOOD FORTUNE",
      "content": "arXiv:2510.00344v1 Announce Type: new \nAbstract: Superstition and religious belief system have historically shaped human behavior, offering powerful psychological motivations and persuasive frameworks to guide actions. Inspired by Feng Shui -- an ancient Chinese superstition -- this paper proposes a pseudo-theoretical framework that integrates superstition-like heuristics into visualization design. Rather than seeking empirical truth, this framework leverages culturally resonant (superstitious) narratives and symbolic metaphors as persuasive tools to encourage desirable design practices, such as clarity, accessibility, and audience-centered thinking. We articulate a set of visualization designs into a Feng Shui compass, reframing empirical design principles and guidelines within an engaing mythology. We present how visualization design principles can be intepreted in Feng Shui narratives, discussing the potential of these metaphorical principles in reducing designer anxiety, fostering community norms, and enhancing the memorability and internalization of visualization design guidelines. Finally, we discuss Feng Shui visualization theory as a set of cognitive shortcuts that can exert persuasive power through playful, belief-like activities.",
      "author": "Chang Han, Andrew Mcnutt",
      "published_date": "2025-10-02T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 159,
      "reading_time": 1,
      "created_at": "2025-10-02T16:46:27.943187+00:00",
      "updated_at": "2025-10-02T16:46:27.943189+00:00"
    },
    {
      "id": "39a3596a71c612421790084f5a7c705a",
      "url": "https://arxiv.org/abs/2510.00339",
      "title": "Navigating the Synchrony-Stability Frontier in Adaptive Chatbots",
      "content": "arXiv:2510.00339v1 Announce Type: new \nAbstract: Adaptive chatbots that mimic a user's linguistic style can build rapport and engagement, yet unconstrained mimicry risks an agent that feels unstable or sycophantic. We present a computational evaluation framework that makes the core design tension explicit: balancing moment-to-moment linguistic synchrony against long-term persona stability. Using an 8-dimensional style vector and a closed-loop \"base+delta\" prompting architecture, we simulate and compare explicit adaptation policies - Uncapped, Cap, Exponential Moving Average (EMA), Dead-Band, and Hybrids - on a human-log dataset. Our analysis maps a clear Pareto frontier: bounded policies achieve substantial gains in stability at a modest cost to synchrony. For example, a Hybrid (EMA+Cap) raises stability from 0.542 to 0.878 (+62%) while reducing synchrony by only 17%. We confirm this trade-off through large-scale replications on three public corpora (DailyDialog, Persona-Chat, EmpatheticDialogues) and LLM-in-the-loop validation across two model families. Furthermore, we quantify \"prompt legibility,\" showing that frontier policies reduce instruction churn and cut jarring register flips (major tone changes) from 0.254 to 0.092, yielding systems that are easier to reason about and maintain. Taken together, our framework provides a general evaluation harness for style adaptation; a systematic ablation that identifies Pareto-efficient policies; robust validation across diverse datasets and models; and novel legibility metrics linking policy choices to system maintainability.",
      "author": "T. James Brandt",
      "published_date": "2025-10-02T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 212,
      "reading_time": 1,
      "created_at": "2025-10-02T16:46:27.943157+00:00",
      "updated_at": "2025-10-02T16:46:27.943159+00:00"
    },
    {
      "id": "5c3eba2421238e54b07c4db3ac9d39ed",
      "url": "https://arxiv.org/abs/2510.00266",
      "title": "Visualization Was Here: Reorienting Research When Visualizations Fade into the Background",
      "content": "arXiv:2510.00266v1 Announce Type: new \nAbstract: Visualization research often centers on how visual representations generate insight, guide interpretation, or support decision-making. But in many real-world domains, visualizations do not stand out--they recede into the background, stabilized and trusted as part of the everyday infrastructure of work. This paper explores what it means to take such quiet roles seriously. Drawing on theoretical traditions from joint cognitive systems, naturalistic decision making, and infrastructure studies, I examine how visualization can become embedded in the rhythms of expert practice--less a site of intervention than a scaffold for attention, coordination, and judgment. I illustrate this reorientation with examples from mission control operations at NASA, where visualizations are deeply integrated but rarely interrogated. Rather than treat invisibility as a failure of design or innovation, I argue that visualization's infrastructural presence demands new concepts, methods, and critical sensibilities. The goal is not to diminish visualization's importance, but to broaden the field's theoretical repertoire--to recognize and support visualization-in-use even when it fades from view.",
      "author": "Paul C. Parsons",
      "published_date": "2025-10-02T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 165,
      "reading_time": 1,
      "created_at": "2025-10-02T16:46:27.943122+00:00",
      "updated_at": "2025-10-02T16:46:27.943124+00:00"
    },
    {
      "id": "97cfa127e10b50f7d1e1612fb5494d64",
      "url": "https://arxiv.org/abs/2510.00245",
      "title": "Can AI agents understand spoken conversations about data visualizations in online meetings?",
      "content": "arXiv:2510.00245v1 Announce Type: new \nAbstract: In this short paper, we present work evaluating an AI agent's understanding of spoken conversations about data visualizations in an online meeting scenario. There is growing interest in the development of AI-assistants that support meetings, such as by providing assistance with tasks or summarizing a discussion. The quality of this support depends on a model that understands the conversational dialogue. To evaluate this understanding, we introduce a dual-axis testing framework for diagnosing the AI agent's comprehension of spoken conversations about data. Using this framework, we designed a series of tests to evaluate understanding of a novel corpus of 72 spoken conversational dialogues about data visualizations. We examine diverse pipelines and model architectures, LLM vs VLM, and diverse input formats for visualizations (the chart image, its underlying source code, or a hybrid of both) to see how this affects model performance on our tests. Using our evaluation methods, we found that text-only input modalities achieved the best performance (96%) in understanding discussions of visualizations in online meetings.",
      "author": "Rizul Sharma, Tianyu Jiang, Seokki Lee, Jillian Aurisano",
      "published_date": "2025-10-02T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 171,
      "reading_time": 1,
      "created_at": "2025-10-02T16:46:27.943073+00:00",
      "updated_at": "2025-10-02T16:46:27.943074+00:00"
    },
    {
      "id": "f9bf3e949483910d8c1fa23d1fb5b088",
      "url": "https://arxiv.org/abs/2510.00222",
      "title": "Data Melodification FM: Where Musical Rhetoric Meets Sonification",
      "content": "arXiv:2510.00222v1 Announce Type: new \nAbstract: We propose a design space for data melodification, where standard visualization idioms and fundamental data characteristics map to rhetorical devices of music for a more affective experience of data. Traditional data sonification transforms data into sound by mapping it to different parameters such as pitch, volume, and duration. Often and regrettably, this mapping leaves behind melody, harmony, rhythm and other musical devices that compose the centuries-long persuasive and expressive power of music. What results is the occasional, unintentional sense of tinnitus and horror film-like impending doom caused by a disconnect between the semantics of data and sound. Through this work we ask, can the aestheticization of sonification through (classical) music theory make data simultaneously accessible, meaningful, and pleasing to one's ears?",
      "author": "Ke Er Amy Zhang, David Grellscheid, Laura Garrison",
      "published_date": "2025-10-02T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 126,
      "reading_time": 1,
      "created_at": "2025-10-02T16:46:27.943041+00:00",
      "updated_at": "2025-10-02T16:46:27.943043+00:00"
    },
    {
      "id": "f809af61f0dcb2fc94b6a8339eed9cd2",
      "url": "https://arxiv.org/abs/2510.00191",
      "title": "Perceived Weight of Mediated Reality Sticks",
      "content": "arXiv:2510.00191v1 Announce Type: new \nAbstract: Mediated reality, where augmented reality (AR) and diminished reality (DR) meet, enables visual modifications to real-world objects. A physical object with a mediated reality visual change retains its original physical properties. However, it is perceived differently from the original when interacted with. We present such a mediated reality object, a stick with different lengths or a stick with a missing portion in the middle, to investigate how users perceive its weight and center of gravity. We conducted two user studies (N=10), each of which consisted of two substudies. We found that the length of mediated reality sticks influences the perceived weight. A longer stick is perceived as lighter, and vice versa. The stick with a missing portion tends to be recognized as one continuous stick. Thus, its weight and center of gravity (COG) remain the same. We formulated the relationship between inertia based on the reported COG and perceived weight in the context of dynamic touch.",
      "author": "Satoshi Hashiguchi, Yuta Kataoka, Asako Kimura, Shohei Mori",
      "published_date": "2025-10-02T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 161,
      "reading_time": 1,
      "created_at": "2025-10-02T16:46:27.943007+00:00",
      "updated_at": "2025-10-02T16:46:27.943009+00:00"
    },
    {
      "id": "0169116e97fe32ef5bfb9ae9407a432b",
      "url": "https://arxiv.org/abs/2510.00120",
      "title": "The Formation of Trust in Autonomous Vehicles after Interacting with Robotaxis on Public Roads",
      "content": "arXiv:2510.00120v1 Announce Type: new \nAbstract: This study investigates how pedestrian trust, receptivity, and behavior evolve during interactions with Level-4 autonomous vehicles (AVs) at uncontrolled urban intersections in a naturalistic setting. While public acceptance is critical for AV adoption, most prior studies relied on simplified simulations or field tests. We conducted a real-world experiment in a commercial Robotaxi operation zone, where 33 participants repeatedly crossed an uncontrolled intersection with frequent Level-4 Robotaxi traffic. Participants completed the Pedestrian Behavior Questionnaire (PBQ), Pedestrian Receptivity Questionnaire for Fully AVs (PRQF), pre- and post-experiment Trust in AVs Scale, and Personal Innovativeness Scale (PIS). Results showed that trust in AVs significantly increased post-experiment, with the increase positively associated with the Interaction component of PRQF. Additionally, both the Positive and Error subscales of the PBQ significantly influenced trust change. This study reveals how trust forms in real-world pedestrian-AV encounters, offering insights beyond lab-based research by accounting for population heterogeneity.",
      "author": "Xiang Chang, Zhijie Yi, Yichang Liu, Hongling Sheng, Dengbo He",
      "published_date": "2025-10-02T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 152,
      "reading_time": 1,
      "created_at": "2025-10-02T16:46:27.942970+00:00",
      "updated_at": "2025-10-02T16:46:27.942974+00:00"
    },
    {
      "id": "a6a68cfc9a7783180548c63b9b3c08cc",
      "url": "https://arxiv.org/abs/2401.17231",
      "title": "Achieving More Human Brain-Like Vision via Human EEG Representational Alignment",
      "content": "arXiv:2401.17231v3 Announce Type: replace-cross \nAbstract: Despite advancements in artificial intelligence, object recognition models still lag behind in emulating visual information processing in human brains. Recent studies have highlighted the potential of using neural data to mimic brain processing; however, these often rely on invasive neural recordings from non-human subjects, leaving a critical gap in understanding human visual perception. Addressing this gap, we present, 'Re(presentational)Al(ignment)net', a vision model aligned with human brain activity based on non-invasive EEG, demonstrating a significantly higher similarity to human brain representations. Our innovative image-to-brain multi-layer encoding framework advances human neural alignment by optimizing multiple model layers and enabling the model to efficiently learn and mimic the human brain's visual representational patterns across object categories and different modalities. Our findings suggest that ReAlnets better align artificial neural networks with human brain representations, making it more similar to human brain processing than traditional computer vision models, which takes an important step toward bridging the gap between artificial and human vision and achieving more brain-like artificial intelligence systems.",
      "author": "Zitong Lu, Yile Wang, Julie D. Golomb",
      "published_date": "2025-10-02T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 169,
      "reading_time": 1,
      "created_at": "2025-10-02T16:46:26.792701+00:00",
      "updated_at": "2025-10-02T16:46:26.792702+00:00"
    },
    {
      "id": "332d3477c69cf3fa22fd1db7a567c01d",
      "url": "https://arxiv.org/abs/2501.14615",
      "title": "Integration of Calcium Imaging Traces via Deep Generative Modeling",
      "content": "arXiv:2501.14615v3 Announce Type: replace \nAbstract: Calcium imaging allows for the parallel measurement of large neuronal populations in a spatially resolved and minimally invasive manner, and has become a gold-standard for neuronal functionality. While deep generative models have been successfully applied to study the activity of neuronal ensembles, their potential for learning single-neuron representations from calcium imaging fluorescence traces remains largely unexplored, and batch effects remain an important hurdle. To address this, we explore supervised variational autoencoder architectures that learn compact representations of individual neurons from fluorescent traces without relying on spike inference algorithms. We find that this approach outperforms state-of-the-art models, preserving biological variability while mitigating batch effects. Across simulated and experimental datasets, this framework enables robust visualization, clustering, and interpretation of single-neuron dynamics.",
      "author": "Berta Ros, Mireia Olives-Verger, Caterina Fuses, Josep M Canals, Jordi Soriano, Jordi Abante",
      "published_date": "2025-10-02T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 124,
      "reading_time": 1,
      "created_at": "2025-10-02T16:46:26.792671+00:00",
      "updated_at": "2025-10-02T16:46:26.792672+00:00"
    },
    {
      "id": "a5ededb34e73b338a3e415a930cac872",
      "url": "https://arxiv.org/abs/2510.00032",
      "title": "WaveMind: Towards a Conversational EEG Foundation Model Aligned to Textual and Visual Modalities",
      "content": "arXiv:2510.00032v1 Announce Type: cross \nAbstract: Electroencephalography (EEG) interpretation using multimodal large language models (MLLMs) offers a novel approach for analyzing brain signals. However, the complex nature of brain activity introduces critical challenges: EEG signals simultaneously encode both cognitive processes and intrinsic neural states, creating a mismatch in EEG paired-data modality that hinders effective cross-modal representation learning. Through a pivot investigation, we uncover complementary relationships between these modalities. Leveraging this insight, we propose mapping EEG signals and their corresponding modalities into a unified semantic space to achieve generalized interpretation. To fully enable conversational capabilities, we further introduce WaveMind-Instruct-338k, the first cross-task EEG dataset for instruction tuning. The resulting model demonstrates robust classification accuracy while supporting flexible, open-ended conversations across four downstream tasks, thereby offering valuable insights for both neuroscience research and the development of general-purpose EEG models.",
      "author": "Ziyi Zeng, Zhenyang Cai, Yixi Cai, Xidong Wang, Junying Chen, Rongsheng Wang, Yipeng Liu, Siqi Cai, Benyou Wang, Zhiguo Zhang, Haizhou Li",
      "published_date": "2025-10-02T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 136,
      "reading_time": 1,
      "created_at": "2025-10-02T16:46:26.792644+00:00",
      "updated_at": "2025-10-02T16:46:26.792645+00:00"
    },
    {
      "id": "a57c843fd7f84b92b400d97ca14d4d58",
      "url": "https://arxiv.org/abs/2510.01000",
      "title": "Some Further Developments on a Neurobiologically-based Model for Color Sensations in Humans",
      "content": "arXiv:2510.01000v1 Announce Type: new \nAbstract: At HVEI-2012, I presented a neurobiologically-based model for trichromatic color sensations in humans, mapping the neural substrate for color sensations to V1-L4: the thalamic recipient layer of the primary visual cortex. In this paper, I propose that V1-L4 itself consists of three distinct sub-layers that directly correspond to the three primary color sensations: blue, red, and green. Furthermore, I apply this model to three aspects of color vision: the three-dimensional (3D) color solid, dichromatism, and ocular agnosticism. Regarding these aspects further: (1) 3D color solid: V1-L4 is known to exhibit a gradient of cell densities from its outermost layer (i.e., its pia side) to its innermost layer (i.e., its white matter side). Taken together with the proposition that the population size of a cell assembly directly corresponds with the magnitude of a color sensation, it can be inferred that the neurobiologically-based color solid is a tilted cuboid. (2) Chromatic color blindness: Using deuteranopia as an example, at the retinal level, M-cones are lost and replaced by L-cones. However, at the cortical level, deuteranopia manifests as a fusion of the two bottom layers of V1-L4. (3) Ocular agnosticism: Although color sensation is monocular, we normally are not aware of which eye we are seeing with. This visual phenomenon can be explained by the nature of ocular integration within V1-L4. A neurobiologically-based model for human color sensations could significantly contribute to future engineering efforts aimed at enhancing human color experiences.",
      "author": "Charles Q. Wu",
      "published_date": "2025-10-02T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 243,
      "reading_time": 1,
      "created_at": "2025-10-02T16:46:26.792616+00:00",
      "updated_at": "2025-10-02T16:46:26.792617+00:00"
    },
    {
      "id": "c024becc7963789f901b97a0e5a51b3b",
      "url": "https://arxiv.org/abs/2510.00764",
      "title": "Emergence of Deviance Detection in Cortical Cultures through Maturation, Criticality, and Early Experience",
      "content": "arXiv:2510.00764v1 Announce Type: new \nAbstract: Mismatch negativity (MMN) in humans reflects deviance detection (DD), a core neural mechanism of predictive processing. However, the fundamental principles by which DD emerges and matures during early cortical development-potentially providing a neuronal scaffold for MMN-remain unclear. Here, we tracked the development of DD in dissociated cortical cultures grown on high-density CMOS microelectrode arrays from 10 to 35 days in vitro (DIV). Cultures were stimulated with oddball and many-standards control paradigms while spontaneous and evoked activity were recorded longitudinally. At early stages, stimulus-evoked responses were confined to fast components reflecting direct activation. From DIV15-20 onward, robust late responses appeared, and deviant stimuli progressively evoked stronger responses than frequent and control stimuli, marking the onset of DD. By DIV30, responses became stronger, faster, and more temporally precise. Neuronal avalanche analysis revealed a gradual transition from subcritical to near-critical dynamics, with cultures exhibiting power-law statistics showing the strongest deviant responses. Nonetheless, DD was also present in non-critical networks, indicating that criticality is not required for its emergence but instead stabilizes and amplifies predictive processing as networks mature. Early oddball experience reinforces the deviant pathway, resulting in faster conduction along those circuits. However, as frequent and deviant pathways become less distinct, the deviance detection index is reduced. Together, these findings demonstrate that DD arises intrinsically through local circuit maturation, while self-organization toward criticality and early experience further refine its strength and timing, providing mechanistic insight into predictive coding in simplified cortical networks and informing the design of adaptive, prediction-sensitive artificial systems.",
      "author": "Zhuo Zhang, Amit Yaron, Dai Akita, Tomoyo Isoguchi Shiramatsu, Zenas C. Chao, Hirokazu Takahashi",
      "published_date": "2025-10-02T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 253,
      "reading_time": 1,
      "created_at": "2025-10-02T16:46:26.792580+00:00",
      "updated_at": "2025-10-02T16:46:26.792581+00:00"
    },
    {
      "id": "3a812dd9b204605ca50aa42358587848",
      "url": "https://arxiv.org/abs/2510.00498",
      "title": "Emergence of robust looming selectivity via coordinated inhibitory neural computations",
      "content": "arXiv:2510.00498v1 Announce Type: new \nAbstract: In the locust's lobula giant movement detector neural pathways, four categories of inhibition, i.e., global inhibition, self-inhibition, lateral inhibition, and feed-forward inhibition, have been functionally explored in the context of looming perception. However, their combined influence on shaping selectivity to looming motion remains unclear. Driven by recent physiological advancements, this paper offers new insights into the roles of these inhibitory mechanisms at multiple levels and scales in simulations, refining the specific selectivity for responding only to objects approaching the eyes while remaining unresponsive to other forms of movement. Within a feed-forward, multi-layer neural network framework, global inhibition, lateral inhibition, self-inhibition, and feed-forward inhibition are integrated. Global inhibition acts as an immediate feedback mechanism, normalising light intensities delivered by ommatidia, particularly addressing low-contrast looming. Self-inhibition, modelled numerically for the first time, suppresses translational motion. Lateral inhibition is formed by delayed local excitation spreading across a larger area. Notably, self-inhibition and lateral inhibition are sequential in time and are combined through feed-forward inhibition, which indicates the angular size subtended by moving objects. Together, these inhibitory processes attenuate motion-induced excitation at multiple levels and scales. This research suggests that self-inhibition may act earlier than lateral inhibition to rapidly reduce excitation in situ, thereby suppressing translational motion, and global inhibition can modulate excitation on a finer scale, enhancing selectivity in higher contrast range.",
      "author": "Qinbing Fu, Ziyan Qin",
      "published_date": "2025-10-02T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 224,
      "reading_time": 1,
      "created_at": "2025-10-02T16:46:26.792543+00:00",
      "updated_at": "2025-10-02T16:46:26.792544+00:00"
    },
    {
      "id": "9b0473c554b1873eaff9d8da05f19daf",
      "url": "https://arxiv.org/abs/2510.00423",
      "title": "Evolutionary Kuramoto dynamics unravels origins of chimera states in neural populations",
      "content": "arXiv:2510.00423v1 Announce Type: new \nAbstract: Neural synchronization is central to cognition However, incomplete synchronization often produces chimera states where coherent and incoherent dynamics coexist. While previous studies have explored such patterns using networks of coupled oscillators, it remains unclear why neurons commit to communication or how chimera states persist. Here, we investigate the coevolution of neuronal phases and communication strategies on directed, weighted networks, where interaction payoffs depend on phase alignment and may be asymmetric due to unilateral communication. We find that both connection weights and directionality influence the stability of communicative strategies -- and, consequently, full synchronization -- as well as the strategic nature of neuronal interactions. Applying our framework to the C. elegans connectome, we show that emergent payoff structures, such as the snowdrift game, underpin the formation of chimera states. Our computational results demonstrate a promising neurogame-theoretic perspective, leveraging evolutionary graph theory to shed light on mechanisms of neuronal coordination beyond classical synchronization models.",
      "author": "Thomas Zdyrski, Scott Pauls, Feng Fu",
      "published_date": "2025-10-02T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 157,
      "reading_time": 1,
      "created_at": "2025-10-02T16:46:26.792506+00:00",
      "updated_at": "2025-10-02T16:46:26.792508+00:00"
    }
  ]
}