{
  "last_updated": "2025-12-18T14:50:21.577605+00:00",
  "count": 20,
  "articles": [
    {
      "id": "11876944c3ea99e28f684e1e4ca3f956",
      "url": "https://www.sciencedirect.com/science/article/pii/S0306452225011662?dgcid=rss_sd_all",
      "title": "Cognition and postural balance in young adults: Investigating the limits of cognitive involvement in motor automaticity",
      "content": "<p>Publication date: 26 January 2026</p><p><b>Source:</b> Neuroscience, Volume 593</p><p>Author(s): Nahid Divandari, Marie\u2013Louise Bird, Maryam Zoghi, Fefe Vakili, Shapour Jaberzadeh</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroscience Journal",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 18,
      "reading_time": 1,
      "created_at": "2025-12-18T14:49:55.123756+00:00",
      "updated_at": "2025-12-18T14:49:55.123757+00:00"
    },
    {
      "id": "411ff0bba70b050e771397f0d0ec6adb",
      "url": "https://www.sciencedirect.com/science/article/pii/S0306452225011388?dgcid=rss_sd_all",
      "title": "GCANet: Enhancing EEG-based auditory attention decoding with temporal frequency GCN and cross attention mechanisms",
      "content": "<p>Publication date: 26 January 2026</p><p><b>Source:</b> Neuroscience, Volume 593</p><p>Author(s): Rui Dai, Yuan Liao, Qiushi Han, Yuanlin Dong, Yuhang Yang, Liya Huang</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroscience Journal",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 20,
      "reading_time": 1,
      "created_at": "2025-12-18T14:49:55.123736+00:00",
      "updated_at": "2025-12-18T14:49:55.123737+00:00"
    },
    {
      "id": "f80602711440f5ba21d7b9db98261236",
      "url": "https://www.sciencedirect.com/science/article/pii/S0306452225011704?dgcid=rss_sd_all",
      "title": "Novel hybrid peptide BNT12 displays potent antinociception with limited opioid-like side effects at the spinal level",
      "content": "<p>Publication date: 26 January 2026</p><p><b>Source:</b> Neuroscience, Volume 593</p><p>Author(s): Si-Yu Wang, Wen-Hui Liu, Jing-Jing Shi, Jun-Ren Dai, Dai-Yun Ning, Si-Yuan Huang, Che Xu, Xiao-Fang Wang, Yu-Jing Wu, Chang-Lin Wang</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroscience Journal",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 28,
      "reading_time": 1,
      "created_at": "2025-12-18T14:49:55.123717+00:00",
      "updated_at": "2025-12-18T14:49:55.123719+00:00"
    },
    {
      "id": "8e40adbea09bfe74f8fb1b62e52546ae",
      "url": "https://www.sciencedirect.com/science/article/pii/S0306452225010577?dgcid=rss_sd_all",
      "title": "Corrigendum to \u201cCEPO-Fc (An EPO Derivative) protects hippocampus against A\u03b2-induced memory deterioration: a behavioral and molecular study in a rat model of A\u03b2 toxicity\u201d. [Neuroscience 388 (2018) 405\u2013417]",
      "content": "<p>Publication date: 26 January 2026</p><p><b>Source:</b> Neuroscience, Volume 593</p><p>Author(s): Etrat Hooshmandi, Fereshteh Motamedi, Maryam Moosavi, Hermann Katinger, Zahra Zakeri, Jalal Zaringhalam, Amirhossein Maghsoudi, Rasoul Ghasemi, Nader Maghsoudi</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroscience Journal",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 26,
      "reading_time": 1,
      "created_at": "2025-12-18T14:49:55.123678+00:00",
      "updated_at": "2025-12-18T14:49:55.123680+00:00"
    },
    {
      "id": "cf9768dfc93ca6d4434354f7c8a3ef64",
      "url": "https://www.sciencedirect.com/science/article/pii/S030645222501173X?dgcid=rss_sd_all",
      "title": "Neural dynamics of unintentional empathy for physical and social pain",
      "content": "<p>Publication date: 6 February 2026</p><p><b>Source:</b> Neuroscience, Volume 594</p><p>Author(s): Nan Zhang, Jiayue Huang, Dongfang Zhao, Wenbo Luo</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroscience Journal",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 16,
      "reading_time": 1,
      "created_at": "2025-12-18T14:49:55.123635+00:00",
      "updated_at": "2025-12-18T14:49:55.123637+00:00"
    },
    {
      "id": "b112fbe3d62f73e7a5572ac9c9849b7f",
      "url": "https://www.sciencedirect.com/science/article/pii/S0306452225011376?dgcid=rss_sd_all",
      "title": "Transcriptomic analysis reveals pathway-specific targets for hyperlocomotion and social withdrawal in mouse models of schizophrenia",
      "content": "<p>Publication date: 6 February 2026</p><p><b>Source:</b> Neuroscience, Volume 594</p><p>Author(s): Xu Liu, Lin Yuan, Qian Chu, Yingxin Liu, Tian Zhao, Ying Zhang, Haihong Ye</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroscience Journal",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 22,
      "reading_time": 1,
      "created_at": "2025-12-18T14:49:55.123606+00:00",
      "updated_at": "2025-12-18T14:49:55.123614+00:00"
    },
    {
      "id": "76e9369d425d5a2f1f9cdcaaf96775e0",
      "url": "https://www.nature.com/articles/s44159-025-00524-z",
      "title": "The distinctiveness of aesthetic emotions",
      "content": "",
      "author": "",
      "published_date": "2025-12-18T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-12-18T14:49:50.217206+00:00",
      "updated_at": "2025-12-18T14:49:50.217208+00:00"
    },
    {
      "id": "22075e39705137d041063f5024bda8b0",
      "url": "https://www.reddit.com/r/Python/comments/1poznrh/resources_for_oops_in_python/",
      "title": "Resources for OOPS in python",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>Hi guys, just wanted some resources for OOP in python. Learnt all the basics but want to practice it a lot so that I can transition towards AI/ML smoothly. Please recommend any websites or practice resources so that this can be possible. Thank you for your time \ud83d\ude4f.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Fearless-Green3111\"> /u/Fearless-Green3111 </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1poznrh/resources_for_oops_in_python/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1poznrh/resources_for_oops_in_python/\">[comments]</a></span>",
      "author": "/u/Fearless-Green3111",
      "published_date": "2025-12-17T15:39:14+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 69,
      "reading_time": 1,
      "created_at": "2025-12-18T14:49:15.556733+00:00",
      "updated_at": "2025-12-18T14:49:15.556734+00:00"
    },
    {
      "id": "4b8f1e9bf22aa87b7cdc52a37305401f",
      "url": "https://github.com/Jawuilp/X-writer",
      "title": "Show HN: X Writer \u2013 Tweet from VS Code Without Distractions (BYOK, Open Source)",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46305008\">Comments</a>",
      "author": "",
      "published_date": "2025-12-17T20:21:25+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-18T14:49:13.982709+00:00",
      "updated_at": "2025-12-18T14:49:13.982710+00:00"
    },
    {
      "id": "ed944e36fc1bec4da75edbd241cd330b",
      "url": "https://daringfireball.net/linked/2025/12/17/are-apple-gift-cards-safe-to-redeem",
      "title": "Are Apple Gift Cards Safe to Redeem?",
      "content": "<p>Article URL: <a href=\"https://daringfireball.net/linked/2025/12/17/are-apple-gift-cards-safe-to-redeem\">https://daringfireball.net/linked/2025/12/17/are-apple-gift-cards-safe-to-redeem</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46313061\">https://news.ycombinator.com/item?id=46313061</a></p>\n<p>Points: 4</p>\n<p># Comments: 0</p>",
      "author": "tosh",
      "published_date": "2025-12-18T14:26:57+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-18T14:49:12.551969+00:00",
      "updated_at": "2025-12-18T14:49:12.551977+00:00"
    },
    {
      "id": "b414dbc286b7855b356d96ae4d0aa4ad",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.16.694774v1?rss=1",
      "title": "High-density lipoprotein mimetic peptide 4F ameliorates APOE4-associated lipid dysfunction in primary and iPSC-derived astrocytes and cerebral organoids",
      "content": "APOE is the greatest genetic risk factor for late-onset Alzheimer's disease (AD). In humans, APOE has three isoforms: APOE2 (E2), APOE3 (E3), and APOE4 (E4); E4 increases AD risk, while E3 is neutral and E2 decreases risk. In the brain, APOE is predominantly produced by astrocytes, where it binds lipids to form HDL-like particles, and plays a central role in lipid homeostasis, A{beta} clearance, and neuroimmune modulation. Its lipidation state is critical for function, with E4 being poorly lipidated compared to E2 and E3, contributing to the pathogenic effects of E4 while also offering a potential therapeutic target. We have previously demonstrated that the HDL-mimetic peptide 4F increases APOE secretion and lipidation in wild-type mouse astrocytes and counteracts the inhibitory effects of A{beta}42. Here, we assessed the ability of 4F to mitigate E4-associated dysfunction using primary astrocytes from humanized E3 and E4 knock-in mice and isogenic human iPSC-derived astrocytes and cerebral organoids. Results showed that 4F enhanced APOE secretion and lipidation in both cellular and organoid models in the absence or presence of aggregated A{beta}42. Compared to E3 astrocytes, E4 astrocytes were prone to A{beta}42-induced inhibition of APOE secretion and lipidation and increased accumulation of lipid droplets. 4F treatment ameliorated the inhibitory effects of A{beta}42 and reduced lipid droplet accumulation. These findings support the therapeutic potential of HDL-mimetic peptides for E4-associated dysfunction in AD.",
      "author": "Fredriksen, K., Joshi, S. S., Chang, A., Li, L.",
      "published_date": "2025-12-18T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 224,
      "reading_time": 1,
      "created_at": "2025-12-18T14:24:50.801169+00:00",
      "updated_at": "2025-12-18T14:24:50.801174+00:00"
    },
    {
      "id": "bd4f550ab1f10076b5b87e02c17803e2",
      "url": "https://iopscience.iop.org/article/10.1088/1741-2552/ae2953",
      "title": "Thermal lensing during infrared neural stimulation enables spatially resolved photothermal dosimetry",
      "content": "Photothermal laser tissue interactions are challenging to study at the subcellular level due to the complexity of accurately characterizing spatial energy distributions. Infrared (IR) neural stimulation, a label-free photothermal neuromodulation technique using pulsed IR light, has demonstrated promise but lacks standardized, high-resolution dosimetry methods. Objective. In this study, we present an automated, imaging-based workflow to perform spatially resolved photothermal dosimetry. This method uses thermal lensing to mark the location of IR exposure within the imaging field of view, enabling precise assessment of the radiant exposure dosage and correlated neuronal responses. Approach. Neuronal Ca2+responses to single IR pulses of varying duration (350 \u00b5s, 2 ms, and 8 ms) were measured using widefield fluorescence microscopy. The thermal lensing artifact (TLA) observed during stimulation was used to model the spatial energy distribution of the laser beam profile. Neuronal Ca2+ responses were analyzed relative to the local radiant exposure, H0(x,y), and the average radiant exposure, dosage, Havg, calculated using the laser pulse energy divided by the laser spot area. Main results. The TLA provided a reliable fiducial for tracking the IR stimulus within the imaging field. Neuronal responses to INS were spatially dependent and exhibited three phenotypes: unreactive, low-amplitude, and high-amplitude. The Gaussian laser beam profile led to cells near the beam center receiving higher radiant exposure dosages, exceeding activation thresholds. We find that shorter pulse durations required lower radiant exposure dosages to elicit neuronal responses. The Havg consistently underestimates the radiant exposure required for stimulation. The H0(x,y) required for stimulation did not produce measurable cellular damage. Significance. Local radiant exposure dosage dictates neuronal activation during INS. Our method provides a standardized, high-throughput approach for performing spatially resolved photothermal dosimetry at microscopic level.",
      "author": "Jacob Hardenburger, Bryan Millis, Joel Bixler, Christopher Valdez, E Duco Jansen and Anita Mahadevan-Jansen",
      "published_date": "2025-12-18T00:00:00+00:00",
      "source": "Journal Neural Engineering",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 279,
      "reading_time": 1,
      "created_at": "2025-12-18T14:24:34.397942+00:00",
      "updated_at": "2025-12-18T14:24:34.397944+00:00"
    },
    {
      "id": "df8dbe14f7b4977e799f60157ae4842a",
      "url": "https://iopscience.iop.org/article/10.1088/1741-2552/ae23ff",
      "title": "Regenerative potential of biogenic zinc oxide nanoparticles prepared with Vitis vinifera-derived extract on sciatic nerve injury in rats",
      "content": "Objective. Damage to the peripheral nerves frequently leads to significant impairments in their functional capacity, highlighting the need for effective treatments that can facilitate nerve repair. This study explores the potential of grape skin extract (Ex), alone and in combination with zinc oxide nanoparticles (ZnO NPs), to enhance regeneration following sciatic nerve injury (SNI) in rats. Approach. ZnO NPs were synthesized using both a conventional chemical route and a green synthesis method in which Ex served as a natural reducing and capping agent. The synthesized nanoparticles were characterized by Fourier-transform infrared spectroscopy, scanning electron microscopy, x-ray diffraction, Thermogravimetric analysis, Energy-dispersive x-ray spectroscopy, zeta potential, and Gas chromatography\u2013mass spectrometry analyses to confirm the role of Ex in shaping nanoparticle morphology and surface properties. Functional recovery and histological outcomes were then assessed in a murine SNI model. Main results. Treatment with Ex and ZnO/Ex significantly reduced collagen accumulation, fibrosis, and tissue vacuolization compared to untreated controls. Both interventions also improved myelination and enhanced the sciatic function index, indicating improved neural repair. Significance. These findings demonstrate that Ex and ZnO/Ex promote nerve regeneration and highlight their potential as promising candidates for the development of biogenic nanotherapeutics targeting peripheral nerve injuries.",
      "author": "Paria Piran, Abolfazl Bayrami, Shima Rahim Pouran, Fatemeh Asghari, Saeideh Aran and Pouya Bayrami",
      "published_date": "2025-12-18T00:00:00+00:00",
      "source": "Journal Neural Engineering",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 197,
      "reading_time": 1,
      "created_at": "2025-12-18T14:24:34.397884+00:00",
      "updated_at": "2025-12-18T14:24:34.397886+00:00"
    },
    {
      "id": "b6c795c8ef18d269460766259a525acc",
      "url": "https://iopscience.iop.org/article/10.1088/1741-2552/ae1bd9",
      "title": "Incorporating multi-modal prompt learning into foundation models enhances predictability of visual fMRI responses to dynamic natural stimuli",
      "content": "Objective. Modeling neural encoding of visual stimuli often uses deep neural networks (DNNs) to predict human brain response to external stimuli. However, each DNN depends on networks tailored for computer vision tasks, resulting in suboptimal brain correspondence. On the other hand, when end-to-end optimizing the encoding process for specific brain regions, challenges like training difficulties arise. Additionally, these models mostly focus on visual information processing, while the human brain integrates multi-modal information such as language to achieve a comprehensive understanding. Approach. To address these limitations, this paper proposes a multi-modal prompt learning (PL) model for neural encoding of dynamic natural stimuli. Specifically, we leverage the powerful representation ability of pre-trained foundation models and fine-tune them using our multi-modal prompts. These prompts, which include textual and visual prompts tailored to each specific regions of interest, can adapt foundation models to neural encoding tasks with fewer trainable parameters. We use the CLIP For video Clip retrieval (CLIP4clip) and Video Masked Autoencoder V2 (videoMAEv2) for feature extraction with backbone freezing, refine the representations via PL, and map the fused multi-modal features to predict voxel-wise brain responses. Main results. Extensive experiments on two functional magnetic resonance imaging video datasets demonstrate that our method outperforms existing fine-tuning methods and public models. Significance. This work highlights the potential of prompt-based fine-tuning strategies in bridging the gap between foundation models and neural encoding tasks.",
      "author": "Panpan Chen, Chi Zhang, Bao Li, Li Tong, Shuxiao Ma, Linyuan Wang, Long Cao, Ziya Yu and Bin Yan",
      "published_date": "2025-12-18T00:00:00+00:00",
      "source": "Journal Neural Engineering",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 227,
      "reading_time": 1,
      "created_at": "2025-12-18T14:24:34.397833+00:00",
      "updated_at": "2025-12-18T14:24:34.397837+00:00"
    },
    {
      "id": "3814ba69a4ccbb008b9f8c04f4733afd",
      "url": "https://www.reddit.com/r/Python/comments/1ppqz7m/nobodywho_the_simplest_way_to_run_local_llms_in/",
      "title": "NobodyWho: the simplest way to run local LLMs in python",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>Check it out on GitHub: <a href=\"https://github.com/nobodywho-ooo/nobodywho\">https://github.com/nobodywho-ooo/nobodywho</a></p> <p><strong>What my project does:</strong></p> <p>It's an ergonomic high-level python library on top of llama.cpp</p> <p>We add a bunch of need-to-have features on top of libllama.a, to make it much easier to build local LLM applications with GPU inference:</p> <ul> <li>GPU acceleration with Vulkan (or Metal on MacOS): skip wasting time with pytorch/cuda</li> <li>threaded execution with an async API, to avoid blocking the main thread for UI</li> <li>simple tool calling with normal functions: avoid the boilerplate of parsing tool call messages</li> <li>constrained generation for the parameter types of your tool, to guarantee correct tool calling every time</li> <li>actually using the upstream chat template from the GGUF file w/ minijinja, giving much improved accuracy compared to the chat template approximations in libllama.</li> <li>pre-built wheels for Windows, MacOS and Linux, with support for hardware acceleration built-in. Just `pip install` and that's it.</li> <li>good use of SIMD instructions when doing CPU inference</li> <li>automatic tokenization: only deal with strings</li> <li>streaming with normal iterators (async or blocking)</li> <li>clean context-shifting along message boundaries: avoid crashing on OOM, and avoid borked half-sentences like llama-server does</li> <li>prefix caching built-in: avoid re-reading old messages on each new generation</li> </ul> <p>Here's an example of an interactive, streaming, terminal chat interface with NobodyWho:</p> <p><code>python from nobodywho import Chat, TokenStream chat = Chat(&quot;./path/to/your/model.gguf&quot;) while True: prompt = input(&quot;Enter your prompt: &quot;) response: TokenStream = chat.ask(prompt) for token in response: print(token, end=&quot;&quot;, flush=True) print() </code></p> <p><strong>Comparison:</strong></p> <ul> <li>huggingface's transformers requires a lot more work and boilerplate to get to a decent tool-calling LLM chat. It also needs you to set up pytorch/cuda stuff to get GPUs working right</li> <li>llama-cpp-python is good, but is much more low-level, so you need to be very particular in &quot;holding it right&quot; to get performant and high quality responses. It also requires different install commands on different platforms, where nobodywho is fully portable</li> <li>ollama-python requires a separate ollama instance running, whereas nobodywho runs in-process. It's much simpler to set up and deploy.</li> <li>most other libraries (Pydantic AI, Simplemind, Langchain, etc) are just wrappers around APIs, so they offload all of the work to a server running somewhere else. NobodyWho is for running LLMs as part of your program, avoiding the infrastructure burden.</li> </ul> <p>Also see the above list of features. AFAIK, no other python lib provides all of these features. </p> <p><strong>Target audience:</strong></p> <p>Production environments as well as hobbyists. NobodyWho has been thoroughly tested in non-python environments (Godot and Unity), and we have a comprehensive unit and integration testing suite. It is very stable software.</p> <p>The core appeal of NobodyWho is to make it much simpler to write correct, performant LLM applications without deep ML skills or tons of infrastructure maintenance.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ex-ex-pat\"> /u/ex-ex-pat </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1ppqz7m/nobodywho_the_simplest_way_to_run_local_llms_in/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1ppqz7m/nobodywho_the_simplest_way_to_run_local_llms_in/\">[comments]</a></span>",
      "author": "/u/ex-ex-pat",
      "published_date": "2025-12-18T13:36:12+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 470,
      "reading_time": 2,
      "created_at": "2025-12-18T14:24:10.220325+00:00",
      "updated_at": "2025-12-18T14:24:10.220327+00:00"
    },
    {
      "id": "14ed0b6cdef6bb6c8ff6efa1c0ee19dc",
      "url": "https://www.ubicloud.com/blog/virtualizing-nvidia-hgx-b200-gpus-with-open-source",
      "title": "Virtualizing Nvidia HGX B200 GPUs with Open Source",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46312792\">Comments</a>",
      "author": "",
      "published_date": "2025-12-18T14:04:03+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-18T14:24:08.982157+00:00",
      "updated_at": "2025-12-18T14:24:08.982159+00:00"
    },
    {
      "id": "203de073c388c8d8d2d5f713a17732de",
      "url": "https://www.coderabbit.ai/blog/state-of-ai-vs-human-code-generation-report",
      "title": "AI helps ship faster but it produces 1.7\u00d7 more bugs",
      "content": "<p>Article URL: <a href=\"https://www.coderabbit.ai/blog/state-of-ai-vs-human-code-generation-report\">https://www.coderabbit.ai/blog/state-of-ai-vs-human-code-generation-report</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46312159\">https://news.ycombinator.com/item?id=46312159</a></p>\n<p>Points: 32</p>\n<p># Comments: 28</p>",
      "author": "birdculture",
      "published_date": "2025-12-18T13:06:51+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-18T14:24:07.884893+00:00",
      "updated_at": "2025-12-18T14:24:07.884895+00:00"
    },
    {
      "id": "14ed0b6cdef6bb6c8ff6efa1c0ee19dc",
      "url": "https://www.ubicloud.com/blog/virtualizing-nvidia-hgx-b200-gpus-with-open-source",
      "title": "Virtualizing Nvidia HGX B200 GPUs with Open Source",
      "content": "<p>Article URL: <a href=\"https://www.ubicloud.com/blog/virtualizing-nvidia-hgx-b200-gpus-with-open-source\">https://www.ubicloud.com/blog/virtualizing-nvidia-hgx-b200-gpus-with-open-source</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46312792\">https://news.ycombinator.com/item?id=46312792</a></p>\n<p>Points: 8</p>\n<p># Comments: 0</p>",
      "author": "ben_s",
      "published_date": "2025-12-18T14:04:03+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-18T14:24:07.884864+00:00",
      "updated_at": "2025-12-18T14:24:07.884871+00:00"
    },
    {
      "id": "0bea0d491a8ce3f229fee9c74b009dd5",
      "url": "https://worksinprogress.co/issue/were-classical-statues-painted-horribly/",
      "title": "Classical statues were not painted horribly",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46311856\">Comments</a>",
      "author": "",
      "published_date": "2025-12-18T12:28:45+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-18T13:37:05.035543+00:00",
      "updated_at": "2025-12-18T14:18:10.991250+00:00",
      "metadata": {
        "processed_at": "2025-12-18T14:18:10.991259+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "0bea0d491a8ce3f229fee9c74b009dd5",
      "url": "https://worksinprogress.co/issue/were-classical-statues-painted-horribly/",
      "title": "Classical statues were not painted horribly",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46311856\">Comments</a>",
      "author": "",
      "published_date": "2025-12-18T12:28:45+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-18T13:37:05.035543+00:00",
      "updated_at": "2025-12-18T14:18:10.991250+00:00",
      "metadata": {
        "processed_at": "2025-12-18T14:18:10.991259+00:00",
        "processing_method": "github_actions"
      }
    }
  ]
}