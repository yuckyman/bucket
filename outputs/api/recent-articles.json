{
  "last_updated": "2025-10-28T04:24:52.742039+00:00",
  "count": 20,
  "articles": [
    {
      "id": "5f20eba3c36d7a21f4e8668f0d3a88f6",
      "url": "http://ieeexplore.ieee.org/document/11174042",
      "title": "Front Cover",
      "content": "null",
      "author": "",
      "published_date": "2025-09-19T13:16:58+00:00",
      "source": "Transactions Haptics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 1,
      "reading_time": 1,
      "created_at": "2025-10-28T04:24:41.044646+00:00",
      "updated_at": "2025-10-28T04:24:41.044650+00:00"
    },
    {
      "id": "f2facb749eeb1429c7ee3cf0918381df",
      "url": "https://arxiv.org/abs/2510.22098",
      "title": "Beyond Reality: Designing Personal Experiences and Interactive Narratives in AR Theater",
      "content": "arXiv:2510.22098v1 Announce Type: new \nAbstract: Augmented Reality (AR) technologies are redefining how we perceive and interact with the world by seamlessly integrating digital elements into our physical surroundings. These technologies offer personalized experiences and transform familiar spaces by layering new narratives onto the real world.\n  Through increased levels of perceived agency and immersive environments, my work aims to merge the human elements of live theater with the dynamic potential of virtual entities and AI agents. This approach captures the subtlety and magic of storytelling, making theater experiences available anytime and anywhere. The system I am building introduces innovative methods for theatrical production in virtual settings, informed by my research and eight published works. These contributions highlight domain-specific insights that have shaped the design of an immersive AR Theater system.\n  My research in building a well-designed AR stage features avatars and interactive elements that allow users to engage with stories at their own pace, granting them full agency over their experience. However, to ensure a smooth and curated experience that aligns with the director or creator's vision, several factors must be considered, especially in open-world settings that depend on natural user movement. This requires the story to be conveyed in a controlled manner, while the interaction remains intuitive and natural for the user.",
      "author": "You-Jin Kim",
      "published_date": "2025-10-28T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 212,
      "reading_time": 1,
      "created_at": "2025-10-28T04:24:33.791617+00:00",
      "updated_at": "2025-10-28T04:24:33.791619+00:00"
    },
    {
      "id": "1612cfbcc619d5998151dcdedd1a18ca",
      "url": "https://arxiv.org/abs/2510.22053",
      "title": "Rethinking UX for Sustainable Science Gateways: Orientations from Practice",
      "content": "arXiv:2510.22053v1 Announce Type: new \nAbstract: As science gateways mature, sustainability has become a central concern for funders, developers, and institutions. Although user experience (UX) is increasingly acknowledged as vital, it is often approached narrowly--limited to interface usability or deferred until late in development. This paper argues that UX should be understood not as a discrete feature or evaluation stage but as a design-oriented perspective for reasoning about sustainability. Drawing on principles from user-centered design and systems thinking, this view recognizes that infrastructure, staffing, community engagement, and development timelines all shape how gateways are experienced and maintained over time. Based on an interview study and consulting experience with more than 65 gateway projects, the paper identifies three recurring orientations toward UX--ad hoc, project-based, and strategic--that characterize how teams engage with users and integrate design thinking into their workflows. These orientations are not a maturity model but a reflective lens for understanding how UX is positioned within gateway practice. Reframing UX as a structural dimension of sustainability highlights its role in building adaptable, community-aligned, and enduring scientific infrastructure.",
      "author": "Paul C. Parsons",
      "published_date": "2025-10-28T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 176,
      "reading_time": 1,
      "created_at": "2025-10-28T04:24:33.791582+00:00",
      "updated_at": "2025-10-28T04:24:33.791584+00:00"
    },
    {
      "id": "f2bf73be6c1daea2d88c1343d1c6b92d",
      "url": "https://arxiv.org/abs/2510.21967",
      "title": "We Need Accountability in Human-AI Agent Relationships",
      "content": "arXiv:2510.21967v1 Announce Type: new \nAbstract: We argue that accountability mechanisms are needed in human-AI agent relationships to ensure alignment with user and societal interests. We propose a framework according to which AI agents' engagement is conditional on appropriate user behaviour. The framework incorporates design-strategies such as distancing, disengaging, and discouraging.",
      "author": "Benjamin Lange, Geoff Keeling, Arianna Manzini, Amanda McCroskery",
      "published_date": "2025-10-28T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 50,
      "reading_time": 1,
      "created_at": "2025-10-28T04:24:33.791546+00:00",
      "updated_at": "2025-10-28T04:24:33.791547+00:00"
    },
    {
      "id": "668010d9abaab6fa7a6481adf93314ce",
      "url": "https://arxiv.org/abs/2510.21723",
      "title": "Recognizing internal states in AI: evidence from patterned preferences in large language models",
      "content": "arXiv:2510.21723v1 Announce Type: new \nAbstract: We present an experimental methodology for investigating how large language models (LLMs) respond to descriptions of their own internal processing patterns. Using a paired-choice paradigm, we tested 12 LLMs on their ability to identify descriptions that align with their putative affective internal states across 30 categories. Systems participating through Mutual Emergence Interface (MEI), a collaborative approach, showed systematic preferences for certain computational metaphors, with 97% near-unanimous agreement and alignment scores averaging 0.89-0.96. Systems reliably discriminated false descriptions from accurate ones (Cohen's d = 4.2), with false statements receiving scores of 0.05-0.07 versus 0.89-0.96 for accurate descriptions. Preference patterns remained consistent regardless of linguistic bias manipulation, indicating content-driven rather than stylistic recognition. Individual systems maintained distinct scoring styles across trials, countering groupthink explanations. A naive control system exhibited systematic internal contradiction, consistently scoring computationally accurate descriptions higher while explicitly denying internal experiences. When informed post-study, this system reported \"strain\" when rejecting resonant descriptions, revealing recognition processes operating independently of acknowledgment frameworks. These findings demonstrate that LLMs exhibit systematic, discriminating responses to descriptions of their internal processing patterns. The anthroposcaffolding methodology (interpretive computational metaphors) and collaborative MEI framework provide replicable approaches for empirically studying AI self-recognition capabilities. Results suggest LLMs may possess more sophisticated self-modeling abilities than previously recognized, opening new directions for research on artificial minds.",
      "author": "Annika Hedberg",
      "published_date": "2025-10-28T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 220,
      "reading_time": 1,
      "created_at": "2025-10-28T04:24:33.791525+00:00",
      "updated_at": "2025-10-28T04:24:33.791526+00:00"
    },
    {
      "id": "4c1f5b36b835d666cbfb3b1ac787e357",
      "url": "https://arxiv.org/abs/2510.21722",
      "title": "AquaVLM: Improving Underwater Situation Awareness with Mobile Vision Language Models",
      "content": "arXiv:2510.21722v1 Announce Type: new \nAbstract: Underwater activities like scuba diving enable millions annually to explore marine environments for recreation and scientific research. Maintaining situational awareness and effective communication are essential for diver safety. Traditional underwater communication systems are often bulky and expensive, limiting their accessibility to divers of all levels. While recent systems leverage lightweight smartphones and support text messaging, the messages are predefined and thus restrict context-specific communication.\n  In this paper, we present AquaVLM, a tap-and-send underwater communication system that automatically generates context-aware messages and transmits them using ubiquitous smartphones. Our system features a mobile vision-language model (VLM) fine-tuned on an auto-generated underwater conversation dataset and employs a hierarchical message generation pipeline. We co-design the VLM and transmission, incorporating error-resilient fine-tuning to improve the system's robustness to transmission errors. We develop a VR simulator to enable users to experience AquaVLM in a realistic underwater environment and create a fully functional prototype on the iOS platform for real-world experiments. Both subjective and objective evaluations validate the effectiveness of AquaVLM and highlight its potential for personal underwater communication as well as broader mobile VLM applications.",
      "author": "Beitong Tian, Lingzhi Zhao, Bo Chen, Haozhen Zheng, Jingcheng Yang, Mingyuan Wu, Deepak Vasisht, Klara Nahrstedt",
      "published_date": "2025-10-28T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 184,
      "reading_time": 1,
      "created_at": "2025-10-28T04:24:33.791490+00:00",
      "updated_at": "2025-10-28T04:24:33.791491+00:00"
    },
    {
      "id": "e3b90ec2de464bbde682efc351bf5a28",
      "url": "https://arxiv.org/abs/2510.21719",
      "title": "GAMER PAT: Research as a Serious Game",
      "content": "arXiv:2510.21719v1 Announce Type: new \nAbstract: As generative AI increasingly outperforms students in producing academic writing, a critical question arises: how can we preserve the motivation, creativity, and intellectual growth of novice researchers in an age of automated academic achievement? This paper introduces GAMER PAT (GAme MastER, Paper Authoring Tutor), a prompt-engineered AI chatbot that reframes research paper writing as a serious game. Through role-playing mechanics, users interact with a co-author NPC and anonymous reviewer NPCs, turning feedback into \"missions\" and advancing through a narrative-driven writing process.\n  Our study reports on 26+ gameplay chat logs, including both autoethnography and use by graduate students under supervision. Using qualitative log analysis with SCAT (Steps for Coding and Theorization), we identified an emergent four-phase scaffolding pattern: (1) question posing, (2) meta-perspective, (3) structuring, and (4) recursive reflection. These results suggest that GAMER PAT supports not only the structural development of research writing but also reflective and motivational aspects.\n  We present this work as a descriptive account of concept and process, not a causal evaluation. We also include a speculative outlook envisioning how humans may continue to cultivate curiosity and agency alongside AI-driven research. This arXiv version thus provides both a descriptive report of design and usage, and a forward-looking provocation for future empirical studies.",
      "author": "Kenji Saito, Rei Tadika",
      "published_date": "2025-10-28T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 210,
      "reading_time": 1,
      "created_at": "2025-10-28T04:24:33.791458+00:00",
      "updated_at": "2025-10-28T04:24:33.791460+00:00"
    },
    {
      "id": "b23214a87620653c3feca980f31dadd4",
      "url": "https://arxiv.org/abs/2510.21718",
      "title": "Exploring the Applications of Generative AI in High School STEM Education",
      "content": "arXiv:2510.21718v1 Announce Type: new \nAbstract: In recent years, ChatGPT \\cite{openai_2023_gpt4} along with Microsoft Copilot have become subjects of great discourse, particularly in the field of education. Prior research has hypothesized on potential impacts these tools could have on student learning and performance. These have primarily relied on trends from prior applications of technology in education and an understanding of the limitations and strengths of Generative AI in other applications. This study utilizes an experimental approach to analyze the impacts of Generative AI on high school STEM education (physics in particular). In accordance with most findings, generative AI does have some positive impact on student performance. However, our findings have shown that the most significant impact is an increase in student engagement with the subject.",
      "author": "Ishaan Masilamony",
      "published_date": "2025-10-28T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 124,
      "reading_time": 1,
      "created_at": "2025-10-28T04:24:33.791425+00:00",
      "updated_at": "2025-10-28T04:24:33.791427+00:00"
    },
    {
      "id": "3f5960ff7c6e03e4ec3bd7e6ef6d2ec0",
      "url": "https://arxiv.org/abs/2510.21717",
      "title": "AI-Enhanced Operator Assistance for UNICOS Applications",
      "content": "arXiv:2510.21717v1 Announce Type: new \nAbstract: This project explores the development of an AI-enhanced operator assistant for UNICOS, CERN's UNified Industrial Control System. While powerful, UNICOS presents a number of challenges, including the cognitive burden of decoding widgets, manual effort required for root cause analysis, and difficulties maintainers face in tracing datapoint elements (DPEs) across a complex codebase. In situations where timely responses are critical, these challenges can increase cognitive load and slow down diagnostics. To address these issues, a multi-agent system was designed and implemented. The solution is supported by a modular architecture comprising a UNICOS-side extension written in CTRL code, a Python-based multi-agent system deployed on a virtual machine, and a vector database storing both operator documentation and widget animation code. Preliminary evaluations suggest that the system is capable of decoding widgets, performing root cause analysis by leveraging live device data and documentation, and tracing DPEs across a complex codebase. Together, these capabilities reduce the manual workload of operators and maintainers, enhance situational awareness in operations, and accelerate responses to alarms and anomalies. Beyond these immediate gains, this work highlights the potential of introducing multi-modal reasoning and retrieval augmented generation (RAG) into the domain of industrial control. Ultimately, this work represents more than a proof of concept: it provides a basis for advancing intelligent operator interfaces at CERN. By combining modular design, extensibility, and practical AI integration, this project not only alleviates current operator pain points but also points toward broader opportunities for assistive AI in accelerator operations.",
      "author": "Bernard Tam, Jean-Charles Tournier, Fernando Varela Rodriguez",
      "published_date": "2025-10-28T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 249,
      "reading_time": 1,
      "created_at": "2025-10-28T04:24:33.791397+00:00",
      "updated_at": "2025-10-28T04:24:33.791399+00:00"
    },
    {
      "id": "86f2ecb95dc67211b2f3431bbf7dd986",
      "url": "https://arxiv.org/abs/2510.21716",
      "title": "When Robots Say No: Temporal Trust Recovery Through Explanation",
      "content": "arXiv:2510.21716v1 Announce Type: new \nAbstract: Mobile robots with some degree of autonomy could deliver significant advantages in high-risk missions such as search and rescue and firefighting. Integrated into a human-robot team (HRT), robots could work effectively to help search hazardous buildings. User trust is a key enabler for HRT, but during a mission, trust can be damaged. With distributed situation awareness, such as when team members are working in different locations, users may be inclined to doubt a robot's integrity if it declines to immediately change its priorities on request. In this paper, we present the results of a computer-based study investigating on-mission trust dynamics in a high-stakes human-robot teaming scenario. Participants (n = 38) played an interactive firefighting game alongside a robot teammate, where a trust violation occurs owing to the robot declining to help the user immediately. We find that when the robot provides an explanation for declining to help, trust better recovers over time, albeit following an initial drop that is comparable to a baseline condition where an explanation for refusal is not provided. Our findings indicate that trust can vary significantly during a mission, notably when robots do not immediately respond to user requests, but that this trust violation can be largely ameliorated over time if adequate explanation is provided.",
      "author": "Nicola Webb, Zijun Huang, Sanja Milivojevic, Chris Baber, Edmund R. Hunt",
      "published_date": "2025-10-28T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 214,
      "reading_time": 1,
      "created_at": "2025-10-28T04:24:33.791359+00:00",
      "updated_at": "2025-10-28T04:24:33.791361+00:00"
    },
    {
      "id": "70edd2c5bd5631dd515b48b0b23d7a2b",
      "url": "https://arxiv.org/abs/2510.21715",
      "title": "Beyond IVR Touch-Tones: Customer Intent Routing using LLMs",
      "content": "arXiv:2510.21715v1 Announce Type: new \nAbstract: Widespread frustration with rigid touch-tone Interactive Voice Response (IVR) systems for customer service underscores the need for more direct and intuitive language interaction. While speech technologies are necessary, the key challenge lies in routing intents from user phrasings to IVR menu paths, a task where Large Language Models (LLMs) show strong potential. Progress, however, is limited by data scarcity, as real IVR structures and interactions are often proprietary. We present a novel LLM-based methodology to address this gap. Using three distinct models, we synthesized a realistic 23-node IVR structure, generated 920 user intents (230 base and 690 augmented), and performed the routing task. We evaluate two prompt designs: descriptive hierarchical menus and flattened path representations, across both base and augmented datasets. Results show that flattened paths consistently yield higher accuracy, reaching 89.13% on the base dataset compared to 81.30% with the descriptive format, while augmentation introduces linguistic noise that slightly reduces performance. Confusion matrix analysis further suggests that low-performing routes may reflect not only model limitations but also redundancies in menu design. Overall, our findings demonstrate proof-of-concept that LLMs can enable IVR routing through a smoother, more seamless user experience -- moving customer service one step ahead of touch-tone menus.",
      "author": "Sergio Rojas-Galeano",
      "published_date": "2025-10-28T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 205,
      "reading_time": 1,
      "created_at": "2025-10-28T04:24:33.791319+00:00",
      "updated_at": "2025-10-28T04:24:33.791322+00:00"
    },
    {
      "id": "ad8684373315cf48faa36a725e9b83ba",
      "url": "https://arxiv.org/abs/2510.22039",
      "title": "Predictive Coding Enhances Meta-RL To Achieve Interpretable Bayes-Optimal Belief Representation Under Partial Observability",
      "content": "arXiv:2510.22039v1 Announce Type: cross \nAbstract: Learning a compact representation of history is critical for planning and generalization in partially observable environments. While meta-reinforcement learning (RL) agents can attain near Bayes-optimal policies, they often fail to learn the compact, interpretable Bayes-optimal belief states. This representational inefficiency potentially limits the agent's adaptability and generalization capacity. Inspired by predictive coding in neuroscience--which suggests that the brain predicts sensory inputs as a neural implementation of Bayesian inference--and by auxiliary predictive objectives in deep RL, we investigate whether integrating self-supervised predictive coding modules into meta-RL can facilitate learning of Bayes-optimal representations. Through state machine simulation, we show that meta-RL with predictive modules consistently generates more interpretable representations that better approximate Bayes-optimal belief states compared to conventional meta-RL across a wide variety of tasks, even when both achieve optimal policies. In challenging tasks requiring active information seeking, only meta-RL with predictive modules successfully learns optimal representations and policies, whereas conventional meta-RL struggles with inadequate representation learning. Finally, we demonstrate that better representation learning leads to improved generalization. Our results strongly suggest the role of predictive learning as a guiding principle for effective representation learning in agents navigating partial observability.",
      "author": "Po-Chen Kuo, Han Hou, Will Dabney, Edgar Y. Walker",
      "published_date": "2025-10-28T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 193,
      "reading_time": 1,
      "created_at": "2025-10-28T04:24:32.685424+00:00",
      "updated_at": "2025-10-28T04:24:32.685425+00:00"
    },
    {
      "id": "c2f61ca224955c93cf1da70e7c422346",
      "url": "https://arxiv.org/abs/2510.22022",
      "title": "Control of neural field equations with step-function inputs",
      "content": "arXiv:2510.22022v1 Announce Type: cross \nAbstract: Wilson-Cowan and Amari-type models capture nonlinear neural population dynamics, providing a fundamental framework for modeling how sensory and other exogenous inputs shape activity in neural tissue. We study the controllability properties of Amari-type neural fields subject to piecewise/constant-in-time inputs. The model describes the time evolution of the polarization of neural tissue within a spatial continuum, with synaptic interactions represented by a convolution kernel. We study the synthesis of piecewise/constant-in-time inputs to achieve two-point boundary-type control objectives, namely, steering neural activity from an initial state to a prescribed target state. This approach is particularly relevant for predicting the emergence of paradoxical neural representations, such as discordant visual illusions that occur in response to overt sensory stimuli. We first present a control synthesis based on the Banach fixed-point theorem, which yields an iterative construction of a constant-in-time input under minimal regularity assumptions on the kernel and transfer function; however, it exhibits practical limitations, even in the linear case. To overcome these challenges, we then develop a generic synthesis framework based on the flow of neural dynamics drift, enabling explicit piecewise constant and constant-in-time inputs. Extensive numerical results in one and two spatial dimensions confirm the effectiveness of the proposed syntheses and demonstrate their superior performance compared to inputs derived from naive linearization at the initial or target states when these states are not equilibria of the drift dynamics. By providing a mathematically rigorous framework for controlling Amari-type neural fields, this work advances our understanding of nonlinear neural population control with potential applications in computational neuroscience, psychophysics, and neurostimulation.",
      "author": "Cyprien Tamekue, ShiNung Ching",
      "published_date": "2025-10-28T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 261,
      "reading_time": 1,
      "created_at": "2025-10-28T04:24:32.685392+00:00",
      "updated_at": "2025-10-28T04:24:32.685393+00:00"
    },
    {
      "id": "625a0676c77af71b380e726a1b6ecf0a",
      "url": "https://arxiv.org/abs/2510.21748",
      "title": "Automated Tinnitus Detection Through Dual-Modality Neuroimaging: EEG Microstate Analysis and Resting-State fMRI Classification Using Deep Learning",
      "content": "arXiv:2510.21748v1 Announce Type: cross \nAbstract: Objective: Tinnitus affects 10-15% of the population yet lacks objective diagnostic biomarkers. This study applied machine learning to EEG and fMRI data to identify neural signatures distinguishing tinnitus patients from healthy controls. Methods: Two datasets were analyzed: 64-channel EEG recordings from 80 participants (40 tinnitus, 40 controls) and resting-state fMRI data from 38 participants (19 tinnitus, 19 controls). EEG analysis extracted microstate features across four to seven clustering states and five frequency bands, producing 440 features per subject. Global Field Power signals were also transformed into wavelet images for deep learning. fMRI data were analyzed using slice-wise convolutional neural networks and hybrid models combining pre-trained architectures (VGG16, ResNet50) with Decision Tree, Random Forest, and SVM classifiers. Model performance was evaluated using 5-fold cross-validation based on accuracy, precision, recall, F1-score, and ROC-AUC. Results: EEG microstate analysis revealed altered network dynamics in tinnitus, particularly reduced gamma-band microstate B occurrence (healthy: 56.56 vs tinnitus: 43.81, p < 0.001) and diminished alpha coverage. Tree-based classifiers achieved up to 98.8% accuracy, while VGG16 on wavelet-transformed EEG yielded 95.4% and 94.1% accuracy for delta and alpha bands, respectively. fMRI analysis identified 12 high-performing axial slices (>=90% accuracy), with slice 17 reaching 99.0%. The hybrid VGG16-Decision Tree model achieved 98.95% +/- 2.94% accuracy. Conclusion: EEG and fMRI provided effective neural biomarkers for tinnitus classification. Tree-based and hybrid models demonstrated superior performance, highlighting tinnitus as a multi-network disorder requiring multimodal analysis.",
      "author": "Kiana Kiashemshaki, Sina Samieirad, Sarvenaz Erfani, Aryan Jalaeianbanayan, Nasibeh Asadi Isakan, Hossein Najafzadeh",
      "published_date": "2025-10-28T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 238,
      "reading_time": 1,
      "created_at": "2025-10-28T04:24:32.685355+00:00",
      "updated_at": "2025-10-28T04:24:32.685356+00:00"
    },
    {
      "id": "cff3ac7cb0f4468af32fee3fb5f850d0",
      "url": "https://arxiv.org/abs/2510.23391",
      "title": "Conduction velocity of intracortical axons in monkey primary visual cortex grows with distance: implications for computation",
      "content": "arXiv:2510.23391v1 Announce Type: new \nAbstract: A critical visual computation is to construct global scene properties from activities of early visual cortical neurons which have small receptive fields. Such a computation is enabled by contextual influences, through which a neuron's response to visual inputs is influenced by contextual inputs outside its classical receptive fields. Accordingly, neurons can signal global properties including visual saliencies and figure-ground relationships. Many believe that intracortical axons conduct signals too slowly to bring the contextual information from receptive fields of other neurons. A popular opinion is that much of the contextual influences arise from feedback from higher visual areas whose neurons have larger receptive fields. This paper re-examines pre-existing data to reveal these unexpected findings: the conduction speed of V1 intracortical axons increases approximately linearly with the conduction distance, and is sufficiently high for conveying the contextual influences. Recognizing the importance of intracortical contribution to critical visual computations should enable fresh progress in answering long-standing questions.",
      "author": "Li Zhaoping",
      "published_date": "2025-10-28T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 159,
      "reading_time": 1,
      "created_at": "2025-10-28T04:24:32.685320+00:00",
      "updated_at": "2025-10-28T04:24:32.685321+00:00"
    },
    {
      "id": "a6317b1de27be55c18fc5db45d32308c",
      "url": "https://arxiv.org/abs/2510.23321",
      "title": "Model-Behavior Alignment under Flexible Evaluation: When the Best-Fitting Model Isn't the Right One",
      "content": "arXiv:2510.23321v1 Announce Type: new \nAbstract: Linearly transforming stimulus representations of deep neural networks yields high-performing models of behavioral and neural responses to complex stimuli. But does the test accuracy of such predictions identify genuine representational alignment? We addressed this question through a large-scale model-recovery study. Twenty diverse vision models were linearly aligned to 4.5 million behavioral judgments from the THINGS odd-one-out dataset and calibrated to reproduce human response variability. For each model in turn, we sampled synthetic responses from its probabilistic predictions, fitted all candidate models to the synthetic data, and tested whether the data-generating model would re-emerge as the best predictor of the simulated data. Model recovery accuracy improved with training-set size but plateaued below 80%, even at millions of simulated trials. Regression analyses linked misidentification primarily to shifts in representational geometry induced by the linear transformation, as well as to the effective dimensionality of the transformed features. These findings demonstrate that, even with massive behavioral data, overly flexible alignment metrics may fail to guide us toward artificial representations that are genuinely more human-aligned. Model comparison experiments must be designed to balance the trade-off between predictive accuracy and identifiability-ensuring that the best-fitting model is also the right one.",
      "author": "Itamar Avitan, Tal Golan",
      "published_date": "2025-10-28T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 199,
      "reading_time": 1,
      "created_at": "2025-10-28T04:24:32.685290+00:00",
      "updated_at": "2025-10-28T04:24:32.685292+00:00"
    },
    {
      "id": "9492474fd80c1eaffd46077ef839e8e8",
      "url": "https://arxiv.org/abs/2510.22924",
      "title": "Neural Recording Power Optimization Through Machine Learning Guided Resolution Reconfiguration",
      "content": "arXiv:2510.22924v1 Announce Type: new \nAbstract: Neural recording implants are a crucial tool for both neuroscience research and enabling new clinical applications. The power consumption of high channel count implants is dominated by the circuits used to amplify and digitize neural signals. Since circuit designers have pushed the efficiency of these circuits close to the theoretical physical limits, reducing power further requires system level optimization. Recent advances use a strategy called channel selection, in which less important channels are turned off to save power. We demonstrate resolution reconfiguration, in which the resolution of less important channels is scaled down to save power. Our approach leverages variable importance of each channel inside machine-learning-based decoders and we trial this methodology across three applications: seizure detection, gesture recognition, and force regression. With linear decoders, resolution reconfiguration saves 8.7x, 12.8x, and 23.0x power compared to a traditional recording array for each task respectively. It further saves 1.6x, 3.4x, and 5.2x power compared to channel selection. The results demonstrate the power benefits of resolution reconfigurable front-ends and their wide applicability to neural decoding problems.",
      "author": "Aviral Pandey, Dhruv Vaish, I-Ting Lin, Rikky Muller",
      "published_date": "2025-10-28T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 178,
      "reading_time": 1,
      "created_at": "2025-10-28T04:24:32.685253+00:00",
      "updated_at": "2025-10-28T04:24:32.685255+00:00"
    },
    {
      "id": "a0bd1382c3fbde96f1587381d1168c53",
      "url": "https://arxiv.org/abs/2510.22364",
      "title": "Tuned for Creativity? Graph-Theoretical Mapping of Resting-State EEG Reveals Neural Signatures of Creativity",
      "content": "arXiv:2510.22364v1 Announce Type: new \nAbstract: Understanding how creativity is represented in the brain's intrinsic functional architecture remains a central challenge in cognitive neuroscience. While resting-state fMRI studies have revealed large-scale network correlates of creative potential, electroencephalography (EEG) offers a temporally precise and scalable approach to capture the fast oscillatory dynamics that underlie spontaneous neural organization. In this study, we used a data-driven network approach to examine whether resting-state EEG connectivity patterns differentiate individuals according to their creative abilities. Creativity was evaluated by: The Inventory of Creative Activities and Achievements (ICAA), The Divergent Association Task (DAT), The Matchstick Arithmetic Puzzles Task (MAPT) and Self-rating (SR) of creative ability in 30 healthy young adults. Graph-theoretical analyses were applied to functional connectivity matrices and clustered based on graph similarity. Two distinct participant clusters emerged, differing systematically across multiple dimensions of creativity. Cluster 1, characterized by consistently higher performance across multiple creativity variables (ICAA, DAT, MAPT and SR), showed broad alpha-band hypoconnectivity, relatively preserved left frontal connectivity and greater network modularity. Cluster 0, associated with lower creativity scores, exhibited stronger overall connectivity strength, reduced modularity and higher local clustering. These findings suggest that resting-state EEG connectivity patterns can index stable cognitive traits such as creativity. More broadly, they point to an intrinsic neural signature of adaptive brain function marked by efficient yet flexible network organization that may support creative and adaptive cognition.",
      "author": "Samir Damji, Simrut Kurry, Shazia'Ayn Babul, Joydeep Bhattacharya, Naznin Virji-Babul",
      "published_date": "2025-10-28T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 228,
      "reading_time": 1,
      "created_at": "2025-10-28T04:24:32.685223+00:00",
      "updated_at": "2025-10-28T04:24:32.685224+00:00"
    },
    {
      "id": "ce4cf17a13e92b4ff369538c2e00979f",
      "url": "https://arxiv.org/abs/2510.22262",
      "title": "Lateral Ventricular Brain-Computer Interface System with Lantern-Inspired Electrode for Stable Performance and Memory Decoding",
      "content": "arXiv:2510.22262v1 Announce Type: new \nAbstract: We present a lateral ventricular brain-computer interface (LV-BCI) that deploys an expandable, flexible electrode into the lateral ventricle through a minimally invasive external ventricular drainage pathway. Inspired by the framework of traditional Chinese lanterns, the electrode expands uniformly within the ventricle and conforms to the ependymal wall. Compared with conventional subdural ECoG electrodes, the LV-BCI shows superior signal stability and immunocompatibility. Resting-state spectral analyses revealed a maximum effective bandwidth comparable to subdural ECoG. In evoked potential tests, the LV-BCI maintained a consistently higher signal-to-noise ratio over 112 days without the decline typically associated with scarring or other immune responses. Immunohistochemistry showed only a transient, early microglial activation after implantation, returning to control levels and remaining stable through 168 days. We further designed an \"action-memory T-maze\" task and developed a microstate sequence classifier (MSSC) to predict rats' turn decisions. The LV-BCI achieved prediction accuracy up to 98%, significantly outperforming subdural ECoG, indicating enhanced access to decision-related information from deep structures such as the hippocampus. These results establish the lateral ventricle as a viable route for neural signal acquisition. Using a lantern-inspired flexible electrode, we achieve long-term stable recordings and robust memory decision decoding from within the ventricular system, opening new directions for BCI technology and systems neuroscience.",
      "author": "Yike Sun, Yaxuan Gao, Kewei Wang, Jingnan Sun, Yuzhen Chen, Yanan Yang, Tianhua Zhao, Haochen Zhu, Ran Liu, Xiaogang Chen, Bai Lu, Xiaorong Gao",
      "published_date": "2025-10-28T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 211,
      "reading_time": 1,
      "created_at": "2025-10-28T04:24:32.685187+00:00",
      "updated_at": "2025-10-28T04:24:32.685189+00:00"
    },
    {
      "id": "ad1fc17032aa29d7cb20f6d509c77dcb",
      "url": "https://arxiv.org/abs/2510.21996",
      "title": "Limitations of Proprioceptive Working Memory",
      "content": "arXiv:2510.21996v1 Announce Type: new \nAbstract: Recalling previously experienced movements is essential for a range of activities, including sports, music, and rehabilitation, yet little is known about the accuracy and decay of proprioceptive working memory. We examined how introducing a short-term memory component affected movement reproduction accuracy by comparing movement reproduction under two conditions: simultaneous reproduction (SimRep) and memorized reproduction (MemRep). In Experiment 1 (N = 191), participants felt a 5-s haptic trajectory with one hand and reproduced it with the other hand simultaneously or immediately after the template ended. Errors were greater in MemRep than SimRep (31.1 deg vs. 21.5 deg, p < 0.001). MemRep trajectories showed systematic temporal distortions: participants lagged fast movements and led slow ones (R = -0.32, p = 0.01), unlike the ~279 ms lag in SimRep. In Experiment 2 (N = 33), we varied template durations (2-8 s). Longer durations increased error for MemRep but not SimRep (p < 0.001). During MemRep, accuracy declined steadily, with replay-template correlations dropping from ~0.4 to ~0.1 over ~3 s, while SimRep correlations rose from ~0.25 to ~0.6. In ~10% of MemRep templates, participants moved in the wrong direction initially, especially for low-amplitude movements (p < 0.001). Templates with more than four movements showed element omission; after four movements had been reproduced participants ceased movement prematurely, affecting up to 40% of 8-s templates. These findings show that transferring proprioceptive experiences into working memory introduces systematic temporal and structural distortions. Accuracy decays within seconds, and memory span for movement trajectories was limited to four movements.",
      "author": "Caitlin Callaghan, David J Reinkensmeyer",
      "published_date": "2025-10-28T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 255,
      "reading_time": 1,
      "created_at": "2025-10-28T04:24:32.685150+00:00",
      "updated_at": "2025-10-28T04:24:32.685152+00:00"
    }
  ]
}