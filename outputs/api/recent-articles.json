{
  "last_updated": "2025-11-20T18:32:14.378933+00:00",
  "count": 20,
  "articles": [
    {
      "id": "bd8c71e299906e7e2e81e2e918088984",
      "url": "https://www.biorxiv.org/content/10.1101/2025.11.20.689476v1?rss=1",
      "title": "Harmonized Protocol for Segmentation of the Hippocampal Tail on High-Resolution in vivo MRI from the Hippocampal Subfields Group (HSG)",
      "content": "The hippocampus is a heterogeneous structure with cytoarchitectonically distinct subfields that exhibit heterogeneous lifespan trajectories and are differentially susceptible to diseases. Advances in high-resolution imaging have accelerated research on these structures, yet variability in segmentation protocols limits cross-study comparability. The Hippocampal Subfields Group (HSG) is an international consortium addressing this challenge by developing a reliable, accessible, and freely available segmentation protocol for high-resolution T2-weighted 3 tesla MRI scans (http://www.hippocampalsubfields.com). Here, we present the harmonized protocol for the posterior portion of the hippocampus (the 'tail'), complementing the previously established 'body' protocol, and with an anterior 'head' protocol under development. The tail protocol provides standardized definitions of the external boundaries for the posterior-most extent of the hippocampus, facilitating consistent segmentation from surrounding tissues. The research community was extensively involved through an online survey that incorporated comprehensive protocol details, feasibility assessments, tutorial videos, and illustrative segmentations. Through this collaborative process, consensus emerged to exclude subfield labeling in the hippocampal tail due to limited visibility of internal landmarks and substantial anatomical variability in this region. All proposed boundary guidelines were deemed clear and agreed upon via a Delphi procedure. The harmonized tail protocol has high intra- (Averaged ICC(2,1) > 0.98; Averaged Dice Similarity Coefficient = 0.92) and inter-rater reliability (Averaged ICC(2,k) > 0.98; Averaged Dice Similarity Coefficient = 0.86) and offers a practical framework for replicable segmentation. By establishing standardized guidelines, this protocol enhances comparability of findings across developmental, aging, and clinical research and is compatible with ongoing technological advances.",
      "author": "de Flores, R., Canada, K. L., Brown, T., Gervais, N. J., Maass, A., Radman, G., Shine, J., Tucker, H. L., Molloy, E. N., Adams, J. N., Reinke, M. B., Bakker, A., Berron, D., Dalton, M. A., Kennedy, K. M., La Joie, R., Mueller, S. G., Ofen, N., Olsen, R. K., Raz, N., Riggins, T., Rodrigue, K. M., Stark, C., Wang, L., Wisse, L. E., Yushkevich, P. A., Carr, V. A., Daugherty, A. M., Alzheimer's Disease Neuroimaging Initiative,, Hippocampal Subfields Group",
      "published_date": "2025-11-20T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 246,
      "reading_time": 1,
      "created_at": "2025-11-20T18:31:45.475944+00:00",
      "updated_at": "2025-11-20T18:31:45.475945+00:00"
    },
    {
      "id": "0d89c8540c8cbc7b4270709fccdf93d4",
      "url": "https://www.biorxiv.org/content/10.1101/2025.11.19.689337v1?rss=1",
      "title": "Unveiling the Multifaceted Networks of the Left DLPFC for Precision TMS Targeting",
      "content": "The left dorsolateral prefrontal cortex (lDLPFC) is the standard target for transcranial magnetic stimulation (TMS) to ameliorate treatment-resistant depression (TRD), yet non-response rates remain high. TMS efficacy has been linked to the stimulation site's functional connectivity, particularly its anti-correlation with the subgenual cingulate cortex (SGC). While this pragmatic strategy has demonstrated clinical utility, it offers limited insight into how the lDLPFC's network interactions contribute to site-dependent variability in treatment response. Here, we used connectivity-based parcellation within an lDLPFC region encompassing common TMS targets and adjacent areas to delineate functional subdivisions and characterize their connectivity to large-scale networks and behavioral associations. Our results revealed a hierarchical organization: a coarse two-pole antagonism between anterior-central and superior-posterior subregions and a finer nine-cluster architecture exposing lDLPFC's heterogeneity along anterior-posterior and ventral-dorsal axes. Anterior-central areas were strongly anti-correlated with SGC and default-mode network, positively connected with salience, dorsal attention, and control networks, and associated with cognitive control. In contrast, superior-posterior subregions displayed the inverse pattern, while ventral clusters engaged somatomotor and visual networks, and language-related processes. Central and superior-anterior clusters showed differentiated profiles, including associations with inhibition, social cognition, and perceptual functions. To aid clinical translation, we derived an lDLPFC likelihood map integrating granularities, highlighting anterior-central lDLPFC as the strongest TMS candidate considering the relevance of its connectivity and behavioral profiles to depression, while indicating that neighboring subregions have distinct functions. These findings underscore the lDLPFC's hierarchical and heterogeneous organization and provide a network-informed reference for developing individualized, symptom-specific TMS interventions.",
      "author": "Paas Oliveros, L. K., Poeppl, T. B., Reuter, N., Patil, K. R., Kreuzer, S., Tse, N. Y., Cash, R. F. H., Hoffstaedter, F., Eickhoff, S. B., Mueller, V. I.",
      "published_date": "2025-11-20T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 246,
      "reading_time": 1,
      "created_at": "2025-11-20T18:31:45.475906+00:00",
      "updated_at": "2025-11-20T18:31:45.475907+00:00"
    },
    {
      "id": "a21dd59866158fc176b3bb1154c4ae4e",
      "url": "https://www.biorxiv.org/content/10.1101/2025.11.20.689416v1?rss=1",
      "title": "Impact of the pulse artifact on evoked activity in human wakefulness and sleep",
      "content": "The investigation of the neural evoked response to the heartbeat quantified using electroencephalography (i.e., heartbeat evoked potentials or HEPs), has gained recent attention in neuroscience, notably as a measure of interoception, the sensory system responding to internal bodily states. One main challenge in measuring HEPs is their susceptibility to cardiac artifacts contamination, including the cardiac field artifact and the pulse artifact (PA), the latter possibly caused by the mechanical pressure of pulsating vessels. Here, we aimed at assessing the impact of PAs on HEPs and auditory evoked potentials (AEPs, a proxy of the neural responses to exteroceptive sensory stimuli). To this aim, we compared two pre-processing pipelines using independent component analysis in healthy volunteers (N=30). The first, standard, pipeline excluded ocular, muscle, sweating-related activity and cardiac-related activity stemming from the cardiac field artifact. The second, pairwise phase consistency (PPC) pipeline, in addition to the removal of the aforementioned components, used the quantitative metric of PPC between independent components and the ECG to remove the cardiac-related PA. We tested how these two pre-processing approaches influenced HEPs and AEPs recorded under diverse neurophysiological conditions (wakefulness, N2, N3, and REM sleep). Comparing the HEPs from the standard and the PPC approaches (cluster-based permutation statistics, p<0.05, two-tailed) revealed a significant effect of PAs, particularly in wakefulness, followed by REM and N2 sleep, with Cohen's d effect sizes of 1.92, 0.95 and 0.88, respectively. By contrast, PA correction had a negligible effect (p>0.05, two-tailed) on the HEPs in N3 sleep and on the AEPs in all vigilance states. Our results emphasize the need to account for the PA as a significant confounding factor when comparing HEPs across groups with varying vascular or cardiac conditions.",
      "author": "Cataldi, J., Pelentritou, A., Schwartz, S., De Lucia, M.",
      "published_date": "2025-11-20T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 279,
      "reading_time": 1,
      "created_at": "2025-11-20T18:31:45.475867+00:00",
      "updated_at": "2025-11-20T18:31:45.475868+00:00"
    },
    {
      "id": "c900ceb20b4419a87b0a13c5d8a58bdf",
      "url": "https://www.biorxiv.org/content/10.1101/2025.11.19.689394v1?rss=1",
      "title": "MExConn: A Mechanistically Interpretable Multi-Expert Framework for Multi-Organelle Segmentation in Connectomics",
      "content": "Electron microscopy (EM) provides subcellular resolution which has made it a critical tool in fields such as cellular biology and connectomics. However, manual annotation of subcellular organelles in these EM images is extremely labor-intensive and impractical at scale. While computational segmentation methods have been developed, most existing approaches are limited to segmenting a single organelle at a time, neglecting the inherent shared information present in EM images containing multiple organelles. To address this, we present MExConn, the first known interpretable multi-expert U-Net architecture in the connectomics field that employs a shared encoder and multiple decoder heads to simultaneously segment multiple organelles from the same input EM image. MExConn significantly outperforms five baselines, including single-organelle model and four state of-the-art connectomics segmentation models in all evaluation metrics, reducing the Variation of Information by up to 33.54% on average across organelles. A key novelty of our approach is that MExConn offers mechanistic interpretability by revealing that the shared encoder learns shared representations essential for accurately segmenting multiple organelles. Through systematic analysis of encoder gradients with respect to each decoder output, we identify channel-wise importance profiles and reveal that many encoder channels are jointly essential for all organelles, while others are organelle-specific. Rigorous experiments on three connectomics datasets demonstrate the effectiveness of MExConn in both segmentation performance and interpretability, establishing it as a principled approach for multi-organelle analysis in connectomics. The source code is publicly available at https://github.com/abrarrahmanabir/MExConn.",
      "author": "Abir, A. R., Saha, A., Sawmya, S., Athey, T. L., Shavit, N. N., Bayzid, M. S.",
      "published_date": "2025-11-20T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 235,
      "reading_time": 1,
      "created_at": "2025-11-20T18:31:45.475826+00:00",
      "updated_at": "2025-11-20T18:31:45.475828+00:00"
    },
    {
      "id": "712484f17127e09503175c31e1df379b",
      "url": "https://www.biorxiv.org/content/10.1101/2025.11.20.689235v1?rss=1",
      "title": "Independent Filter Analysis for Group Discrimination in fMRI",
      "content": "Traditional group-level fMRI analysis approaches, such as Independent Component Analysis (ICA), often rely on unsupervised dimensionality reduction to map subjects into a common feature space. While effective for capturing common variance across all subjects, the preservation of discriminative features between groups of participants is not guaranteed. To address this limitation, we introduce Independent Filter Analysis (IFA), a supervised extension of group ICA that explicitly models group-discriminative information as part of the dimensionality reduction steps. Prior to unmixing, IFA constructs a subspace that simultaneously retains both shared and group-specific information, enhancing sensitivity to group effects while preserving biological interpretability. We validated IFA using simulated data and paired condition comparisons from three Human Connectome Project (HCP) tasks. In the simulation, IFA achieved 95% classification accuracy, outperforming group ICA, which failed to detect subtle group differences. On the HCP data, IFA increased network matrix classification accuracy by up to 15% and produced spatial maps that more precisely reflected task-relevant differences.",
      "author": "Souweidane, Z., Llera, A., Smith, S. M., Beckmann, C. F.",
      "published_date": "2025-11-20T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 157,
      "reading_time": 1,
      "created_at": "2025-11-20T18:31:45.475787+00:00",
      "updated_at": "2025-11-20T18:31:45.475789+00:00"
    },
    {
      "id": "fbd47b29a37b23c0a5c32ff7897e290c",
      "url": "https://www.biorxiv.org/content/10.1101/2025.11.19.689382v1?rss=1",
      "title": "Gut metabolite IPA alleviates white matter injury post-ICH by enhancing myelin debris phagocytosis via Stap1 inhibition",
      "content": "Background: Intracerebral hemorrhage (ICH) causes neurological dysfunction and white matter injury (WMI) characterized by myelin loss, axonal injury and myelin debris accumulation. Microglia-mediated debris clearance is critical for WMI repair. The microbiota-gut-brain axis plays an essential role in the central nervous system diseases, one of the ways in which gut microbiota affects brain is via producing metabolites. Indole-3-proprionic acid (IPA), a tryptophan-derived metabolite that mainly produced by Clostridium sporogenes, exhibits anti-inflammatory and neuroprotective properties. However, its effect on ICH remains unclear. This study aims to investigate the IPA level after ICH and the therapeutic effects of IPA on neurological deficits and WMI, as well as the potential mechanisms underlying IPA-mediated neuroprotection. Methods: An ICH model was established using C57BL/6 mice, which then received intragastric IPA (20 mg/kg/day). Fecal abundance of IPA-related genes and IPA levels in feces and plasma were measured by qPCR and UPLC-MS/MS. Behavioral tests, qPCR, and immunofluorescence staining were used to assess neurological function, myelin integrity, and axonal injury. In vitro, BV2 microglia, with or without Stap1 knockdown, were co-cultured with myelin debris to assess IPA?s effects on phagocytosis. Additionally, targeted plasma IPA profiling was performed in 30 ICH patients and 30 matched healthy controls. Results: The relative abundance of IPA production-related genes and IPA levels in feces and plasma were significantly decreased after ICH and remained low into the chronical phase. After IPA administration, the neurological deficits, myelin loss and axonal injury of mice with ICH were significantly improved. In vitro, IPA increased BV2 microglia myelin debris phagocytosis by inhibiting Stap1 expression. IPA levels were significantly reduced in ICH patients, consistent with ICH mouse model. Conclusions: Our findings demonstrated that the gut microbiota-derived metabolite IPA could facilitate neurological deficits recovery and alleviate WMI, which could be a promising therapeutic strategy to improve ICH prognosis.",
      "author": "Peng, M., Zeng, M., Tian, H., He, C., Zhang, L., Zhao, Z., Luo, Y., Li, X., Xia, F., Liu, S., Cheng, X., Sun, H.",
      "published_date": "2025-11-20T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 298,
      "reading_time": 1,
      "created_at": "2025-11-20T18:31:45.475752+00:00",
      "updated_at": "2025-11-20T18:31:45.475754+00:00"
    },
    {
      "id": "d61f857d67e0b90ad934bbb2275b8573",
      "url": "https://www.biorxiv.org/content/10.1101/2025.11.19.689293v1?rss=1",
      "title": "Transcutaneous auricular vagus nerve stimulation enhances emotional bias towards happiness in healthy young adults: A comparative study of electrical and ultrasound stimulation",
      "content": "Transcutaneous auricular vagus nerve stimulation (taVNS) is an emerging neuromodulation technique demonstrating promise in emotional regulation. This study investigated the acute effects of both electrical (E-taVNS) and ultrasound (U-taVNS) modalities on emotional bias using a facial emotion categorization task in healthy young adults. Fifty-nine participants underwent a single-blind, sham-controlled, within-subject design, with emotional bias assessed at pre-, during-, and post-stimulation phases. Our findings revealed that both E-taVNS and U-taVNS significantly enhanced emotional bias scores, shifting the perception of neutral and ambiguous faces towards positive interpretations and reducing negative emotional bias. No significant differences in efficacy were observed between the two stimulation modalities. Furthermore, individual differences in interoceptive awareness were found to be associated with the observed taVNS effects. These results suggest that both electrical and ultrasound taVNS can acutely modulate emotional regulation, highlighting the potential of taVNS as a non-invasive, well-tolerated alternative for interventions targeting emotional bias and mood disorders.",
      "author": "Kang, J. C., Ng, J. Y., Kaiser, M., Choi, H., Song, J.-J., Jung, J.",
      "published_date": "2025-11-20T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 150,
      "reading_time": 1,
      "created_at": "2025-11-20T18:31:45.475691+00:00",
      "updated_at": "2025-11-20T18:31:45.475696+00:00"
    },
    {
      "id": "48e81a0447d7157d50ba6230f4dd38ff",
      "url": "https://www.frontiersin.org/articles/10.3389/fncom.2025.1692418",
      "title": "Interleaving cortex-analog mixing improves deep non-negative matrix factorization networks",
      "content": "Considering biological constraints in artificial neural networks has led to dramatic improvements in performance. Nevertheless, to date, the positivity of long-range signals in the cortex has not been shown to yield improvements. While Non-negative matrix factorization (NMF) captures biological constraints of positive long-range interactions, deep convolutional neural networks with NMF modules do not match the performance of conventional neural networks (CNNs) of a similar size. This work shows that introducing intermediate modules that combine the NMF's positive activities, analogous to the processing in cortical columns, leads to improved performance on benchmark data that exceeds that of vanilla deep convolutional networks. This demonstrates that including positive long-range signaling together with local interactions of both signs in analogy to cortical hyper-columns has the potential to enhance the performance of deep networks.",
      "author": "Klaus R. Pawelzik",
      "published_date": "2025-11-05T00:00:00+00:00",
      "source": "Frontiers Computational Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 129,
      "reading_time": 1,
      "created_at": "2025-11-20T18:31:36.533425+00:00",
      "updated_at": "2025-11-20T18:31:36.533426+00:00"
    },
    {
      "id": "f04f02121b1d13836df0a2b01a861136",
      "url": "https://www.frontiersin.org/articles/10.3389/fnbot.2025.1681341",
      "title": "UAV-based intelligent traffic surveillance using recurrent neural networks and Swin transformer for dynamic environments",
      "content": "IntroductionUrban traffic congestion, environmental degradation, and road safety challenges necessitate intelligent aerial robotic systems capable of real-time adaptive decision-making. Unmanned Aerial Vehicles (UAVs), with their flexible deployment and high vantage point, offer a promising solution for large-scale traffic surveillance in complex urban environments. This study introduces a UAV-based neural framework that addresses challenges such as asymmetric vehicle motion, scale variations, and spatial inconsistencies in aerial imagery.MethodsThe proposed system integrates a multi-stage pipeline encompassing contrast enhancement and region-based clustering to optimize segmentation while maintaining computational efficiency for resource-constrained UAV platforms. Vehicle detection is carried out using a Recurrent Neural Network (RNN), optimized via a hybrid loss function combining cross-entropy and mean squared error to improve localization and confidence estimation. Upon detection, the system branches into two neural submodules: (i) a classification stream utilizing SURF and BRISK descriptors integrated with a Swin Transformer backbone for precise vehicle categorization, and (ii) a multi-object tracking stream employing DeepSORT, which fuses motion and appearance features within an affinity matrix for robust trajectory association.ResultsComprehensive evaluation on three benchmark UAV datasets\u2014AU-AIR, UAVDT, and VAID shows consistent and high performance. The model achieved detection precisions of 0.913, 0.930, and 0.920; tracking precisions of 0.901, 0.881, and 0.890; and classification accuracies of 92.14, 92.75, and 91.25%, respectively.DiscussionThese findings highlight the adaptability, robustness, and real-time viability of the proposed architecture in aerial traffic surveillance applications. By effectively integrating detection, classification, and tracking within a unified neural framework, the system contributes significant advancements to intelligent UAV-based traffic monitoring and supports future developments in smart city mobility and decision-making systems.",
      "author": "Hui Liu",
      "published_date": "2025-10-13T00:00:00+00:00",
      "source": "Frontiers Neurorobotics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 258,
      "reading_time": 1,
      "created_at": "2025-11-20T18:31:33.641511+00:00",
      "updated_at": "2025-11-20T18:31:33.641513+00:00"
    },
    {
      "id": "109baea45022e2871f03a6a22368cd82",
      "url": "https://www.reddit.com/r/Python/comments/1p211nn/realtime_discord_stt_bot_using_multiprocessing/",
      "title": "Real-time Discord STT Bot using Multiprocessing & Faster-Whisper",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>Hi <a href=\"/r/Python\">r/Python</a>, I built a Discord bot that transcribes voice channels in real-time using local AI models.</p> <p><strong>What My Project Does</strong> It joins a voice channel, listens to the audio stream using <code>discord-ext-voice-recv</code>, and transcribes speech to text using OpenAI's Whisper model. To ensure low latency, I implemented a pipeline where audio capture and AI inference run in separate processes via <code>multiprocessing</code>.</p> <p><strong>Target Audience</strong></p> <ul> <li><strong>Developers:</strong> Those interested in handling real-time audio streams in Python without blocking the main event loop.</li> <li><strong>Hobbyists:</strong> Anyone wanting to build their own self-hosted transcription service without relying on paid APIs.</li> </ul> <p><strong>Comparison</strong></p> <ul> <li><strong>vs. Standard Bot Implementations:</strong> Many Python bots handle logic in a single thread/loop, which causes lag during heavy AI inference. My project uses a <code>multiprocessing.Queue</code> to decouple audio recording from processing, preventing the bot from freezing.</li> <li><strong>vs. Cloud APIs:</strong> Instead of sending audio to Google or OpenAI APIs (which costs money and adds latency), this uses <code>Faster-Whisper</code> (large-v3-turbo) locally for free and faster processing.</li> </ul> <p><strong>Tech Stack:</strong> <a href=\"http://discord.py\"><code>discord.py</code></a>, <code>multiprocessing</code>, <code>Faster-Whisper</code>, <code>Silero VAD</code>.</p> <p>I'm looking for feedback on my audio buffering logic and resampling efficiency.</p> <p><strong>Contributions are always welcome! Whether it's code optimization, bug fixes, or feature suggestions, feel free to open a PR or issue on GitHub.</strong></p> <p><a href=\"https://github.com/Leehyunbin0131/Discord-Realtime-STT-Bot\">https://github.com/Leehyunbin0131/Discord-Realtime-STT-Bot</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Usual_Government_769\"> /u/Usual_Government_769 </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1p211nn/realtime_discord_stt_bot_using_multiprocessing/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1p211nn/realtime_discord_stt_bot_using_multiprocessing/\">[comments]</a></span>",
      "author": "/u/Usual_Government_769",
      "published_date": "2025-11-20T11:44:13+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 231,
      "reading_time": 1,
      "created_at": "2025-11-20T18:31:09.858736+00:00",
      "updated_at": "2025-11-20T18:31:09.858738+00:00"
    },
    {
      "id": "ff231b2a145bd9e93a7482039797323f",
      "url": "https://www.reddit.com/r/Python/comments/1p23zun/latest_python_podcasts_conference_talks_week_47/",
      "title": "Latest Python Podcasts & Conference Talks (week 47, 2025)",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>Hi <a href=\"/r/Python\">r/Python</a>!</p> <p>As part of <a href=\"https://www.techtalksweekly.io/\">Tech Talks Weekly</a>, I'll be posting here every week with all the latest Python conference talks and podcasts. To build this list, I'm following over <a href=\"https://www.techtalksweekly.io/i/170091550/conferences\">100 software engineering conferences</a> and even more podcasts. This means you no longer need to scroll through messy YT subscriptions or RSS feeds!</p> <p>In addition, I'll periodically post compilations, for example a list of the most-watched Python talks of 2025.</p> <p>The following list includes all the Python talks and podcasts published in the past 7 days (2025-11-13 - 2025-11-20).</p> <p>Let's get started!</p> <h1>1. Conference talks</h1> <h1>PyData Seattle 2025</h1> <ol> <li><a href=\"https://youtube.com/watch?v=2w5WZsY_DOw&amp;utm_source=techtalksweekly&amp;utm_medium=email\"><strong>&quot;Khuyen Tran &amp; Yibei Hu - Multi-Series Forecasting at Scale with StatsForecast | PyData Seattle 2025&quot;</strong></a> \u2e31 <strong>+200 views</strong> \u2e31 17 Nov 2025 \u2e31 00h 39m 36s</li> <li><a href=\"https://youtube.com/watch?v=smUeNnB6Xbs&amp;utm_source=techtalksweekly&amp;utm_medium=email\"><strong>&quot;Sebastian Duerr - Evaluation is all you need | PyData Seattle 2025&quot;</strong></a> \u2e31 <strong>+200 views</strong> \u2e31 17 Nov 2025 \u2e31 00h 43m 28s</li> <li><a href=\"https://youtube.com/watch?v=OBK_rgcY56I&amp;utm_source=techtalksweekly&amp;utm_medium=email\"><strong>&quot;Bill Engels - Actually using GPs in practice with PyMC | PyData Seattle 2025&quot;</strong></a> \u2e31 <strong>+200 views</strong> \u2e31 17 Nov 2025 \u2e31 00h 44m 15s</li> <li><a href=\"https://youtube.com/watch?v=1rQp5r6vbT8&amp;utm_source=techtalksweekly&amp;utm_medium=email\"><strong>&quot;Everett Kleven - Why Models Break Your Pipelines | PyData Seattle 2025&quot;</strong></a> \u2e31 <strong>+200 views</strong> \u2e31 17 Nov 2025 \u2e31 00h 36m 04s</li> <li><a href=\"https://youtube.com/watch?v=Hc-EH-NfbRg&amp;utm_source=techtalksweekly&amp;utm_medium=email\"><strong>&quot;Ojas Ankurbhai Ramwala - Explainable AI for Biomedical Image Processing | PyData Seattle 2025&quot;</strong></a> \u2e31 <strong>+100 views</strong> \u2e31 17 Nov 2025 \u2e31 00h 46m 02s</li> <li><a href=\"https://youtube.com/watch?v=uWxR845ciCI&amp;utm_source=techtalksweekly&amp;utm_medium=email\"><strong>&quot;Denny Lee - Building Agents with Agent Bricks and MCP | PyData Seattle 2025&quot;</strong></a> \u2e31 <strong>+100 views</strong> \u2e31 17 Nov 2025 \u2e31 00h 39m 58s</li> <li><a href=\"https://youtube.com/watch?v=KhEgqEE7LDY&amp;utm_source=techtalksweekly&amp;utm_medium=email\"><strong>&quot;Avik Basu - Beyond Just Prediction: Causal Thinking in Machine Learning | PyData Seattle 2025&quot;</strong></a> \u2e31 <strong>+100 views</strong> \u2e31 17 Nov 2025 \u2e31 00h 43m 14s</li> <li><a href=\"https://youtube.com/watch?v=_qDcLm0gMkE&amp;utm_source=techtalksweekly&amp;utm_medium=email\"><strong>&quot;Saurabh Garg - Optimizing AI/ML Workloads | PyData Seattle 2025&quot;</strong></a> \u2e31 <strong>+100 views</strong> \u2e31 17 Nov 2025 \u2e31 00h 40m 03s</li> <li><a href=\"https://youtube.com/watch?v=sMKOp3-EmD0&amp;utm_source=techtalksweekly&amp;utm_medium=email\"><strong>&quot;Pedro Albuquerque - Generalized Additive Models: Explainability Strikes Back | PyData Seattle 2025&quot;</strong></a> \u2e31 <strong>+100 views</strong> \u2e31 17 Nov 2025 \u2e31 00h 40m 31s</li> <li><a href=\"https://youtube.com/watch?v=CJznMMM6Svk&amp;utm_source=techtalksweekly&amp;utm_medium=email\"><strong>&quot;Keynote: Josh Starmer - Communicating Concepts, Clearly Explained!!! | \ufeff\ufeffPyData Seattle 2025&quot;</strong></a> \u2e31 <strong>+100 views</strong> \u2e31 17 Nov 2025 \u2e31 00h 49m 34s</li> <li><a href=\"https://youtube.com/watch?v=Hfspu0UO2Sc&amp;utm_source=techtalksweekly&amp;utm_medium=email\"><strong>&quot;Rajesh - Securing Retrieval-Augmented Generation | PyData Seattle 2025&quot;</strong></a> \u2e31 <strong>+100 views</strong> \u2e31 17 Nov 2025 \u2e31 00h 32m 32s</li> <li><a href=\"https://youtube.com/watch?v=p3eQgOexQho&amp;utm_source=techtalksweekly&amp;utm_medium=email\"><strong>&quot;Andy Terrel - Building Inference Workflows with Tile Languages | PyData Seattle 2025&quot;</strong></a> \u2e31 <strong>+100 views</strong> \u2e31 17 Nov 2025 \u2e31 00h 30m 36s</li> <li><a href=\"https://youtube.com/watch?v=_hv1LHaCcvU&amp;utm_source=techtalksweekly&amp;utm_medium=email\"><strong>&quot;Jyotinder Singh - Practical Quantization in Keras | PyData Seattle 2025&quot;</strong></a> \u2e31 <strong>+100 views</strong> \u2e31 17 Nov 2025 \u2e31 00h 48m 12s</li> <li><a href=\"https://youtube.com/watch?v=9PFcG9MZ3s8&amp;utm_source=techtalksweekly&amp;utm_medium=email\"><strong>&quot;Trent Nelson - Unlocking Parallel PyTorch Inference (and More!) | PyData Seattle 2025&quot;</strong></a> \u2e31 <strong>+100 views</strong> \u2e31 17 Nov 2025 \u2e31 00h 43m 53s</li> <li><a href=\"https://youtube.com/watch?v=gTYSbbDBYNQ&amp;utm_source=techtalksweekly&amp;utm_medium=email\"><strong>&quot;Dr. Jim Dowling - Real-TIme Context Engineering for Agents | PyData Seattle 2025&quot;</strong></a> \u2e31 <strong>&lt;100 views</strong> \u2e31 17 Nov 2025 \u2e31 00h 39m 33s</li> <li><a href=\"https://youtube.com/watch?v=Lypf_qNaeQs&amp;utm_source=techtalksweekly&amp;utm_medium=email\"><strong>&quot;JustinCastilla - There and back again... by ferry or I-5? | PyData Seattle 2025&quot;</strong></a> \u2e31 <strong>&lt;100 views</strong> \u2e31 17 Nov 2025 \u2e31 00h 40m 48s</li> <li><a href=\"https://youtube.com/watch?v=YL0Hb6CA0UI&amp;utm_source=techtalksweekly&amp;utm_medium=email\"><strong>&quot;Bernardo Dionisi - Know Your Data(Frame) with Paguro | PyData Seattle 2025&quot;</strong></a> \u2e31 <strong>&lt;100 views</strong> \u2e31 17 Nov 2025 \u2e31 00h 38m 59s</li> <li><a href=\"https://youtube.com/watch?v=u3aFp78BTno&amp;utm_source=techtalksweekly&amp;utm_medium=email\"><strong>&quot;Allison Wang &amp; Shujing Yang - Polars on Spark | PyData Seattle 2025&quot;</strong></a> \u2e31 <strong>&lt;100 views</strong> \u2e31 17 Nov 2025 \u2e31 00h 31m 20s</li> <li><a href=\"https://youtube.com/watch?v=NpoaDkacsTI&amp;utm_source=techtalksweekly&amp;utm_medium=email\"><strong>&quot;David Aronchick - Taming the Data Tsunami | PyData Seattle 2025&quot;</strong></a> \u2e31 <strong>&lt;100 views</strong> \u2e31 17 Nov 2025 \u2e31 00h 37m 29s</li> <li><a href=\"https://youtube.com/watch?v=qeIP6XYFJHA&amp;utm_source=techtalksweekly&amp;utm_medium=email\"><strong>&quot;John Carney- Building valuable Deterministic products in a Probabilistic world | PyData Seattle 2025&quot;</strong></a> \u2e31 <strong>&lt;100 views</strong> \u2e31 17 Nov 2025 \u2e31 00h 38m 17s</li> <li><a href=\"https://youtube.com/watch?v=wSiF1Bm8f3s&amp;utm_source=techtalksweekly&amp;utm_medium=email\"><strong>&quot;Carl Kadie - How to Optimize your Python Program for Slowness | PyData Seattle 2025&quot;</strong></a> \u2e31 <strong>&lt;100 views</strong> \u2e31 17 Nov 2025 \u2e31 00h 36m 24s</li> <li><a href=\"https://youtube.com/watch?v=ytRvvJgNdco&amp;utm_source=techtalksweekly&amp;utm_medium=email\"><strong>&quot;Devin Petersohn - We don't dataframe shame: A love letter to dataframes | PyData Seattle 2025&quot;</strong></a> \u2e31 <strong>&lt;100 views</strong> \u2e31 17 Nov 2025 \u2e31 00h 41m 29s</li> <li><a href=\"https://youtube.com/watch?v=02Bchtfb0AI&amp;utm_source=techtalksweekly&amp;utm_medium=email\"><strong>&quot;Carl Kadie - Explore Solvable and Unsolvable Equations with SymPy | PyData Seattle 2025&quot;</strong></a> \u2e31 <strong>&lt;100 views</strong> \u2e31 17 Nov 2025 \u2e31 00h 33m 30s</li> <li><a href=\"https://youtube.com/watch?v=9-0y8G_OoQ8&amp;utm_source=techtalksweekly&amp;utm_medium=email\"><strong>&quot;Merchant &amp; Suarez - Wrangling Internet-scale Image Datasets | PyData Seattle 2025&quot;</strong></a> \u2e31 <strong>&lt;100 views</strong> \u2e31 17 Nov 2025 \u2e31 00h 32m 37s</li> <li><a href=\"https://youtube.com/watch?v=op5WDRVhxVc&amp;utm_source=techtalksweekly&amp;utm_medium=email\"><strong>&quot;Keynote: Chang She - Never Send a Human to do an Agent's Search | PyData Seattle 2025&quot;</strong></a> \u2e31 <strong>&lt;100 views</strong> \u2e31 17 Nov 2025 \u2e31 00h 45m 19s</li> <li><a href=\"https://youtube.com/watch?v=l8flxQMPmPY&amp;utm_source=techtalksweekly&amp;utm_medium=email\"><strong>&quot;Aziza Mirsaidova - Prompt Variation as a Diagnostic Tool | PyData Seattle 2025&quot;</strong></a> \u2e31 <strong>&lt;100 views</strong> \u2e31 17 Nov 2025 \u2e31 00h 32m 02s</li> <li><a href=\"https://youtube.com/watch?v=7F2zHERZlGo&amp;utm_source=techtalksweekly&amp;utm_medium=email\"><strong>&quot;C.A.M. Gerlach - Democratizing (Py)Data | PyData Seattle 2025&quot;</strong></a> \u2e31 <strong>&lt;100 views</strong> \u2e31 17 Nov 2025 \u2e31 00h 31m 52s</li> <li><a href=\"https://youtube.com/watch?v=uapsxFc1D5o&amp;utm_source=techtalksweekly&amp;utm_medium=email\"><strong>&quot;Weston Pace - Data Loading for Data Engineers | PyData Seattle 2025&quot;</strong></a> \u2e31 <strong>&lt;100 views</strong> \u2e31 17 Nov 2025 \u2e31 00h 34m 23s</li> <li><a href=\"https://youtube.com/watch?v=pt_v-x0pT2Y&amp;utm_source=techtalksweekly&amp;utm_medium=email\"><strong>&quot;Jack Ye - Supercharging Multimodal Feature Engineering | PyData Seattle 2025&quot;</strong></a> \u2e31 <strong>&lt;100 views</strong> \u2e31 17 Nov 2025 \u2e31 00h 41m 54s</li> <li><a href=\"https://youtube.com/watch?v=3xjZy49R6A4&amp;utm_source=techtalksweekly&amp;utm_medium=email\"><strong>&quot;Lightning Talks | PyData Seattle 2025&quot;</strong></a> \u2e31 <strong>&lt;100 views</strong> \u2e31 17 Nov 2025 \u2e31 00h 38m 02s</li> <li><a href=\"https://youtube.com/watch?v=u4L4mUmuO9o&amp;utm_source=techtalksweekly&amp;utm_medium=email\"><strong>&quot;Panel: Building Data-Driven Startups with User-Centric Design | PyData Seattle 2025&quot;</strong></a> \u2e31 <strong>&lt;100 views</strong> \u2e31 17 Nov 2025 \u2e31 00h 40m 08s</li> <li><a href=\"https://youtube.com/watch?v=uoBknPqpm2w&amp;utm_source=techtalksweekly&amp;utm_medium=email\"><strong>&quot;Stephen Cheng - Scaling Background Noise Filtration for AI Voice Agents | PyData Seattle 2025&quot;</strong></a> \u2e31 <strong>&lt;100 views</strong> \u2e31 17 Nov 2025 \u2e31 00h 35m 07s</li> <li><a href=\"https://youtube.com/watch?v=KCRKbY8ewH0&amp;utm_source=techtalksweekly&amp;utm_medium=email\"><strong>&quot;Keynote: Zaheera Valani - Driving Data Democratization with the Databricks | PyData Seattle 2025&quot;</strong></a> \u2e31 <strong>&lt;100 views</strong> \u2e31 17 Nov 2025 \u2e31 00h 41m 54s</li> <li><a href=\"https://youtube.com/watch?v=sM9PO_dfDhI&amp;utm_source=techtalksweekly&amp;utm_medium=email\"><strong>&quot;Noor Aftab - The Missing 78% | PyData Seattle 2025&quot;</strong></a> \u2e31 <strong>&lt;100 views</strong> \u2e31 17 Nov 2025 \u2e31 00h 39m 42s</li> <li><a href=\"https://youtube.com/watch?v=oehEhQ93HiM&amp;utm_source=techtalksweekly&amp;utm_medium=email\"><strong>&quot;Roman Lutz - Red Teaming AI: Getting Started with PyRIT | PyData Seattle 2025&quot;</strong></a> \u2e31 <strong>&lt;100 views</strong> \u2e31 17 Nov 2025 \u2e31 00h 44m 15s</li> </ol> <h1>PyData Vermont 2025</h1> <ol> <li><a href=\"https://youtube.com/watch?v=qovKXSoxeRE&amp;utm_source=techtalksweekly&amp;utm_medium=email\"><strong>&quot;Zhao - Complex Data Ingestion with Open Source AI | PyData Vermont 2025&quot;</strong></a> \u2e31 <strong>+400 views</strong> \u2e31 14 Nov 2025 \u2e31 01h 00m 17s</li> <li><a href=\"https://youtube.com/watch?v=WwzT33OrXmY&amp;utm_source=techtalksweekly&amp;utm_medium=email\"><strong>&quot;Dody - Cleaning Messy Data at Scale: APIs, LLMs, and Custom NLP Pipelines | PyData Vermont 2025&quot;</strong></a> \u2e31 <strong>+200 views</strong> \u2e31 14 Nov 2025 \u2e31 00h 48m 03s tldw: Cleaning messy address data at scale with a practical tour from regex and third party APIs to open source parsers and scalable LLM embeddings, showing when to pick each method and how to balance cost, speed, and precision.</li> <li><a href=\"https://youtube.com/watch?v=bPc0afWxEwo&amp;utm_source=techtalksweekly&amp;utm_medium=email\"><strong>&quot;Bouquin - MCP basics with Conda and Claude | PyData Vermont 2025&quot;</strong></a> \u2e31 <strong>+100 views</strong> \u2e31 14 Nov 2025 \u2e31 00h 56m 05s</li> <li><a href=\"https://youtube.com/watch?v=An7RWSuZ8LE&amp;utm_source=techtalksweekly&amp;utm_medium=email\"><strong>&quot;Zimmerman, Ashley - Context is all you need: FUNdamental linguistics for NLP | PyData Vermont 2025&quot;</strong></a> \u2e31 <strong>+100 views</strong> \u2e31 14 Nov 2025 \u2e31 00h 46m 23s</li> <li><a href=\"https://youtube.com/watch?v=FzaMnDCHIA4&amp;utm_source=techtalksweekly&amp;utm_medium=email\"><strong>&quot;Wages - From Chaos to Confidence: Solving Python's Environment Reprodu... | PyData Vermont 2025&quot;</strong></a> \u2e31 <strong>+100 views</strong> \u2e31 14 Nov 2025 \u2e31 00h 30m 29s</li> <li><a href=\"https://youtube.com/watch?v=eKmb6tI4y0Y&amp;utm_source=techtalksweekly&amp;utm_medium=email\"><strong>&quot;Fortney, Cooley - The Art of Data: Hand-crafted, Human-centered Dat... | PyData Vermont 2025&quot;</strong></a> \u2e31 <strong>+100 views</strong> \u2e31 14 Nov 2025 \u2e31 00h 19m 21s</li> <li><a href=\"https://youtube.com/watch?v=g9hvUl0YWTo&amp;utm_source=techtalksweekly&amp;utm_medium=email\"><strong>&quot;Clementi, McCarty - GPU-Accelerated Data Science for PyData Users | PyData Vermont 2025&quot;</strong></a> \u2e31 <strong>+100 views</strong> \u2e31 14 Nov 2025 \u2e31 00h 15m 30s</li> <li><a href=\"https://youtube.com/watch?v=23zhw9Jf71U&amp;utm_source=techtalksweekly&amp;utm_medium=email\"><strong>&quot;Koch - Open Source Vermont Data Platform: Access, Analysis, and Visualization | PyData Vermont 2025&quot;</strong></a> \u2e31 <strong>&lt;100 views</strong> \u2e31 14 Nov 2025 \u2e31 00h 40m 35s</li> </ol> <h1>2. Podcasts</h1> <ul> <li><a href=\"https://www.thenerdnook.io/p/automate-your-day-in-python?utm_source=techtalksweekly&amp;utm_medium=email\"><strong>&quot;Automate Your Day: How to Run Python Scripts on a Schedule (Windows, macOS, Linux)&quot;</strong></a> \u2e31 <em>The PyPod Chronicles</em> \u2e31 13 Nov 2025 \u2e31 00h 11m 17s</li> </ul> <p>This post is an excerpt from <strong>Tech Talks Weekly</strong> which is a free weekly email with all the recently published Software Engineering podcasts and conference talks. Currently subscribed by +7,200 Software Engineers who stopped scrolling through messy YT subscriptions/RSS feeds and reduced FOMO. Consider subscribing if this sounds useful: <a href=\"https://www.techtalksweekly.io/\">https://www.techtalksweekly.io/</a></p> <p>Please let me know what you think about this format \ud83d\udc47 Thank you \ud83d\ude4f</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/TechTalksWeekly\"> /u/TechTalksWeekly </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1p23zun/latest_python_podcasts_conference_talks_week_47/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1p23zun/latest_python_podcasts_conference_talks_week_47/\">[comments]</a></span>",
      "author": "/u/TechTalksWeekly",
      "published_date": "2025-11-20T14:04:43+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 1338,
      "reading_time": 6,
      "created_at": "2025-11-20T18:31:09.858698+00:00",
      "updated_at": "2025-11-20T18:31:09.858700+00:00"
    },
    {
      "id": "3f96e216e47809fbde2fdb18d52c4e9b",
      "url": "https://github.com/PegorK/f32",
      "title": "Show HN: F32 \u2013 An Extremely Small ESP32 Board",
      "content": "<a href=\"https://news.ycombinator.com/item?id=45984461\">Comments</a>",
      "author": "",
      "published_date": "2025-11-19T20:09:30+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-11-20T18:31:08.603978+00:00",
      "updated_at": "2025-11-20T18:31:08.603979+00:00"
    },
    {
      "id": "eceabf8a39b8fb06d1fe4fe6b82b32d8",
      "url": "https://lionsos.org",
      "title": "The Lions Operating System",
      "content": "<a href=\"https://news.ycombinator.com/item?id=45995816\">Comments</a>",
      "author": "",
      "published_date": "2025-11-20T18:19:31+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-11-20T18:31:08.603940+00:00",
      "updated_at": "2025-11-20T18:31:08.603942+00:00"
    },
    {
      "id": "e3acc39ab00ae116ef6b89a6386bb3ca",
      "url": "https://news.ycombinator.com/item?id=45995394",
      "title": "Launch HN: Poly (YC S22) \u2013 Cursor for Files",
      "content": "<a href=\"https://news.ycombinator.com/item?id=45995394\">Comments</a>",
      "author": "",
      "published_date": "2025-11-20T17:47:06+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-11-20T18:31:08.603922+00:00",
      "updated_at": "2025-11-20T18:31:08.603923+00:00"
    },
    {
      "id": "7a32050ade6c10620889fca50fa5189a",
      "url": "https://opensource.microsoft.com/blog/2025/11/20/preserving-code-that-shaped-generations-zork-i-ii-and-iii-go-open-source",
      "title": "Microsoft makes Zork open-source",
      "content": "<a href=\"https://news.ycombinator.com/item?id=45995740\">Comments</a>",
      "author": "",
      "published_date": "2025-11-20T18:13:39+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-11-20T18:31:08.603843+00:00",
      "updated_at": "2025-11-20T18:31:08.603844+00:00"
    },
    {
      "id": "3064297af4914de40e19c9ff26f36811",
      "url": "https://www.centauri-dreams.org/2025/11/20/the-firefly-and-the-pulsar/",
      "title": "The Firefly and the Pulsar",
      "content": "<p>Article URL: <a href=\"https://www.centauri-dreams.org/2025/11/20/the-firefly-and-the-pulsar/\">https://www.centauri-dreams.org/2025/11/20/the-firefly-and-the-pulsar/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=45994537\">https://news.ycombinator.com/item?id=45994537</a></p>\n<p>Points: 3</p>\n<p># Comments: 0</p>",
      "author": "JPLeRouzic",
      "published_date": "2025-11-20T16:37:42+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-11-20T18:31:07.295996+00:00",
      "updated_at": "2025-11-20T18:31:07.295998+00:00"
    },
    {
      "id": "e3acc39ab00ae116ef6b89a6386bb3ca",
      "url": "https://news.ycombinator.com/item?id=45995394",
      "title": "Launch HN: Poly (YC S22) \u2013 Cursor for Files",
      "content": "<p>Hello world, this is Abhay from Poly (<a href=\"https://poly.app\">https://poly.app</a>). We\u2019re building an app to replace Finder/File Explorer with something more intelligent and searchable. Think of it like Dropbox + NotebookLM + Perplexity for terabytes of your files. Here\u2019s a quick demo: <a href=\"https://www.youtube.com/watch?v=RsqCySU4Ln0\" rel=\"nofollow\">https://www.youtube.com/watch?v=RsqCySU4Ln0</a>.<p>Poly can search your content in natural language, across a broad range of file types and down to the page, paragraph, pixel, or point in time. We also provide an integrated agent that can take actions on your files such as creating, editing, summarizing, and researching. Any action that you can take, the agent can also take, from renaming, moving, tagging, annotating, and organizing files for you. The agent can also read URLs, youtube links, and can search the web and even download files for you.<p>Here are some public drives that you can poke around in (note: it doesn\u2019t work in Safari yet\u2014sorry! we\u2019re working on it.)<p><i>Every issue of the Whole Earth Catalogue</i>: <a href=\"https://poly.app/shared/whole-earth-catalogues\">https://poly.app/shared/whole-earth-catalogues</a><p><i>Archive of old Playstation Manuals</i>: <a href=\"https://poly.app/shared/playstation-manuals-archive\">https://poly.app/shared/playstation-manuals-archive</a><p><i>Mini archive of Orson Welles interviews and commercial spots</i>: <a href=\"https://poly.app/shared/orson-welles-archive\">https://poly.app/shared/orson-welles-archive</a><p><i>Archive of Salvador Dali\u2019s paintings for Alice in Wonderland</i>: <a href=\"https://poly.app/shared/salvador-dali-alice-in-wonderland\">https://poly.app/shared/salvador-dali-alice-in-wonderland</a><p>To try it out, navigate to one of these public folders and use the agent or search to find things. The demo video above can give you an idea of how the UI roughly works. Select files by clicking on them. Quick view by pressing space. Open the details for any file by pressing cmd + i. You can search from the top middle bar (or press cmd + K), and all searches will use semantic similarity and search within the files. Or use the agent from the bottom right tools menu (or press cmd + ?) and you can ask about the files, have the agent search for you, summarize things, etc.<p>We decided to build this after launching an early image-gen company back in March 2022, and realizing how painful it was for users to store, manage, and search their libraries, especially in a world of generative media. Despite our service having over 150,000 users at that point, we realized that our true calling was fixing the file browser to make it intelligent, so we shut our service down in 2023 and pivoted to this.<p>We think Poly will be a great fit for anyone that wants to do useful things with their files, such as summarizing research papers, finding the right media or asset, creating a shareable portfolio, searching for a particular form or document, and producing reports and overviews. Of course, it\u2019s a great way to organize your genAI assets as well. Or just use it to organize notes, links, inspo, etc.<p>Under the hood, Poly is built on our advanced search model, Polyembed-v1 that natively supports multimodal search across text, documents, spreadsheets, presentations, images, audio, video, PDFs, and more. We allow you to search by phrase, file similarity, color, face, and several other kinds of features. The agent is particularly skilled at using the search, so you can type in something like \u201cfind me the last lease agreement I signed\u201d and it can go look for it by searching, reading the first few files, searching again if nothing matches, etc. But the quality of our embed model means it almost always finds the file in the first search.<p>It works identically across web and desktop, except on desktop it syncs your cloud files to a folder (just like google drive). On the web we use clever caching to enable offline support and file conflict recovery. We\u2019ve taken great pains to make our system faster than your existing file browser, even if you\u2019re using it from a web browser.<p>File storage plans are currently at: 100GB free tier, paid tier is 2TB at $10/m, and 1c per GB per month on top of the 2TB. We also have rate limits for agent use that vary at different tiers.<p>We\u2019re excited to expand with many features over the following months, including \u201cvirtual files\u201d (store your google docs in Poly), sync from other hosting providers, mobile apps, an MCP ecosystem for the agent, access to web search and deep research modes, offline search, local file support (on desktop), third-party sources (WebDAV, NAS), and a whole lot more.<p>Our waitlist is now open and we\u2019ll be letting folks in starting today! Sign up at <a href=\"https://poly.app\">https://poly.app</a>.<p>We\u2019d also love to hear your thoughts (and concerns) about what we\u2019re building, as we\u2019re early in this journey so your feedback can very much shape the future of our company!</p>\n<hr />\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=45995394\">https://news.ycombinator.com/item?id=45995394</a></p>\n<p>Points: 9</p>\n<p># Comments: 4</p>",
      "author": "aabhay",
      "published_date": "2025-11-20T17:47:06+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 754,
      "reading_time": 3,
      "created_at": "2025-11-20T18:31:07.295861+00:00",
      "updated_at": "2025-11-20T18:31:07.295870+00:00"
    },
    {
      "id": "7435952e0834ce3bab69423a0615bac7",
      "url": "https://www.frontiersin.org/articles/10.3389/fnbot.2025.1691300",
      "title": "UHGAN: a dual-phase GAN with Hough-transform constraints for accurate farmland road extraction",
      "content": "IntroductionTraditional methods for farmland road extraction, such as U-Net, often struggle with complex noise and geometric features, leading to discontinuous extraction and insufficient sensitivity. To address these limitations, this study proposes a novel dual-phase generative adversarial network (GAN) named UHGAN, which integrates Hough-transform constraints.MethodsWe designed a cascaded U-Net generator within a two-stage GAN framework. The Stage 1 GAN combines a differentiable Hough transform loss with cross-entropy loss to generate initial road masks. Subsequently, the Stage 2 U-Net refines these masks by repairing breakpoints and suppressing isolated noise.ResultsWhen evaluated on the WHU RuR+rural road dataset, the proposed UHGAN method achieved an accuracy of 0.826, a recall of 0.750, and an F1-score of 0.789. This represents a significant improvement over the single-stage U-Net (F1\u202f=\u202f0.756) and ResNet (F1\u202f=\u202f0.762) baselines.DiscussionThe results demonstrate that our approach effectively mitigates the issues of discontinuous extraction caused by the complex geometric shapes and partial occlusion characteristic of farmland roads. The integration of Hough-transform loss, an technique that has received limited attention in prior studies, proves to be highly beneficial. This method shows considerable promise for practical applications in rural infrastructure planning and precision agriculture.",
      "author": "Yuan Ma",
      "published_date": "2025-10-13T00:00:00+00:00",
      "source": "Frontiers Neurorobotics",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 190,
      "reading_time": 1,
      "created_at": "2025-11-20T17:41:03.187101+00:00",
      "updated_at": "2025-11-20T18:22:23.740709+00:00",
      "metadata": {
        "processed_at": "2025-11-20T18:22:23.740717+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "a32ea48b60e8e1b7caf108c75272fe21",
      "url": "https://words.filippo.io/2025-state/",
      "title": "Go Cryptography State of the Union",
      "content": "<a href=\"https://news.ycombinator.com/item?id=45994895\">Comments</a>",
      "author": "",
      "published_date": "2025-11-20T17:07:49+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-11-20T17:40:38.336213+00:00",
      "updated_at": "2025-11-20T18:22:23.740722+00:00",
      "metadata": {
        "processed_at": "2025-11-20T18:22:23.740723+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "1906344a759d1ea101922c5dbefae7b1",
      "url": "https://github.com/telophasehq/tangent",
      "title": "Show HN: Tangent \u2013 Open-source security data pipeline",
      "content": "<a href=\"https://news.ycombinator.com/item?id=45994592\">Comments</a>",
      "author": "",
      "published_date": "2025-11-20T16:41:31+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-11-20T17:40:38.336191+00:00",
      "updated_at": "2025-11-20T18:22:23.740728+00:00",
      "metadata": {
        "processed_at": "2025-11-20T18:22:23.740730+00:00",
        "processing_method": "github_actions"
      }
    }
  ]
}