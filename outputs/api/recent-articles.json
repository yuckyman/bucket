{
  "last_updated": "2025-11-01T01:13:15.835369+00:00",
  "count": 20,
  "articles": [
    {
      "id": "902df770854423011000edd238dd0b09",
      "url": "http://ieeexplore.ieee.org/document/10972321",
      "title": "A Pilot Study on Fabric-Based Pneumatic Soft Gloves for Assisting Patients With Severe Brachial Plexus Injury",
      "content": "Objective: Robotic gloves show promise in hand assistance due to their wearability and home-based potential, yet empirical research remains limited. This pilot study presents a fabric-based pneumatic soft glove, aiming to identify its potential and challenges in clinical practice by evaluating its effectiveness in assisting patients with severe brachial plexus injury (BPI). Methods: The glove integrates a thumb abduction actuator and four bidirectional fabric-based pneumatic actuators (FPAs) with asymmetric chambers for high output force. Sixteen healthy volunteers and five individuals with BPI, all of whom lacked active hand and wrist movements, were recruited. Participants performed object grasping across 25 cm. The healthy group performed seven tasks using objects weighing up to 2 kg, with muscle activities recorded for analysis. The BPI group further performed tasks with eight objects from the action research arm test (ARAT) and twelve objects for activities of daily living (ADLs), encompassing various sizes, weights, and geometries. Results: In the healthy group, sEMG showed a decrease in 89.3% of trials, with 56.0% of these decreases being significant (p$< $0.01). For BPI group, the range of motion (ROM) improved, ranging from 28.5 $\\pm$ 7.9$^{\\circ }$ to 63.1 $\\pm$ 5.1$^{\\circ }$ (thumb) and 10.3 $\\pm$ 17.5$^{\\circ }$ to 122.5 $\\pm$ 19.0$^{\\circ }$ (index finger). With a zero baseline for all tasks, their completion rates were 6.8 $\\pm$ 0.8 out of 8 for ARAT tasks and 10.0 $\\pm$ 1.7 out of 12 for ADLs. Conclusion: The fabric-based pneumatic soft glove significantly enhanced the hand function of patients with severe BPI, demonstrating its potential for hand assistance.",
      "author": "",
      "published_date": "2025-04-22T13:18:18+00:00",
      "source": "Transactions Biomedical Engineering",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 256,
      "reading_time": 1,
      "created_at": "2025-10-31T23:36:47.723794+00:00",
      "updated_at": "2025-11-01T01:13:15.729998+00:00",
      "metadata": {
        "processed_at": "2025-11-01T01:13:15.730007+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "97b029153a3ff523dd3e21c1b2ebeaf8",
      "url": "http://ieeexplore.ieee.org/document/10971951",
      "title": "Building and Sustaining Open-Source Medical Device Projects",
      "content": "The open-source development model has been successfully applied to consumer and enterprise software, and recently to consumer hardware. Medical devices may become a beneficiary of this trend, as open-source medical device development has the potential to reduce costs, democratize patient access, and provide continued support to abandoned devices from failed companies. Unlike the consumer device market, the medical device market is highly regulated and involves considerable manufacturer liability that may limit the use of open-source technology. This review of open-source medical device development explores the current state of development in research and clinical products and suggests best practices for creating sustainable and effective open-source medical devices.",
      "author": "",
      "published_date": "2025-04-21T13:18:20+00:00",
      "source": "Transactions Biomedical Engineering",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 106,
      "reading_time": 1,
      "created_at": "2025-10-31T23:36:47.723755+00:00",
      "updated_at": "2025-11-01T01:13:15.730011+00:00",
      "metadata": {
        "processed_at": "2025-11-01T01:13:15.730016+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "0077ae0d8a956fdc349ff6b154403d02",
      "url": "http://ieeexplore.ieee.org/document/10971210",
      "title": "A Neighbor-Sensitive Multi-Modal Flexible Learning Framework for Improved Prostate Tumor Segmentation in Anisotropic MR Images",
      "content": "Accurate segmentation of prostate tumors from multi-modal magnetic resonance (MR) images is crucial for the diagnosis and treatment of prostate cancer. However, the robustness of existing segmentation methods is limited, mainly because these methods 1) fail to flexibly assess subject-specific information of each MR modality and integrate modality-specific information for accurate tumor delineation, and 2) lack effective utilization of inter-slice information across thick slices in MR images to segment the tumor as a whole 3D volume. In this work, we propose a neighbor-sensitive multi-modal flexible learning network (NesMFle) for accurate prostate tumor segmentation from multi-modal anisotropic MR images. Specifically, we perform multi-modal fusion for each slice by developing a Modality-informativeness Flexible Learning (MFLe) module for selecting and flexibly fusing informative representations of each modality based on inter-modality correlation in a pre-trained manner. After that, we exploit inter-slice feature correlation to derive volumetric tumor segmentation. In particular, we first use a Unet variant equipped with a Sequence Layer, which can coarsely capture slice relationship using 3D convolution and an attention mechanism. Then, we introduce an Activation Mapping Guidance (AMG) module to refine slice-wise representations using information from adjacent slices, ensuring consistent tumor segmentation across neighboring slices based on slice quality assessment on activation maps. Besides, during the network training, we further apply a random mask strategy to each MR modality for improving feature representation efficiency. Experiments on both in-house and public (PICAI) multi-modal prostate tumor datasets demonstrate that our proposed NesMFLe achieves competitive performance compared to state-of-the-art methods.",
      "author": "",
      "published_date": "2025-04-21T13:18:20+00:00",
      "source": "Transactions Biomedical Engineering",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 247,
      "reading_time": 1,
      "created_at": "2025-10-31T23:36:47.723727+00:00",
      "updated_at": "2025-11-01T01:13:15.730018+00:00",
      "metadata": {
        "processed_at": "2025-11-01T01:13:15.730020+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "c5c5803bb1ce94f0603b54dd6e222c56",
      "url": "http://ieeexplore.ieee.org/document/11210869",
      "title": "Table of Contents",
      "content": "null",
      "author": "",
      "published_date": "2025-10-21T13:16:30+00:00",
      "source": "Transactions Biomedical Engineering",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 1,
      "reading_time": 1,
      "created_at": "2025-10-31T23:36:47.723680+00:00",
      "updated_at": "2025-11-01T01:13:15.730022+00:00",
      "metadata": {
        "processed_at": "2025-11-01T01:13:15.730024+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "1eb4001d65c7b4ac3708121d6a31ca06",
      "url": "http://ieeexplore.ieee.org/document/11210865",
      "title": "IEEE Transactions on Biomedical Engineering Handling Editors Information",
      "content": "null",
      "author": "",
      "published_date": "2025-10-21T13:16:29+00:00",
      "source": "Transactions Biomedical Engineering",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 1,
      "reading_time": 1,
      "created_at": "2025-10-31T23:36:47.723661+00:00",
      "updated_at": "2025-11-01T01:13:15.730026+00:00",
      "metadata": {
        "processed_at": "2025-11-01T01:13:15.730027+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "69a981fc0bd4f82123c01313f3e8ff3d",
      "url": "http://ieeexplore.ieee.org/document/11210870",
      "title": "IEEE Transactions on Biomedical Engineering Information for Authors",
      "content": "null",
      "author": "",
      "published_date": "2025-10-21T13:16:30+00:00",
      "source": "Transactions Biomedical Engineering",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 1,
      "reading_time": 1,
      "created_at": "2025-10-31T23:36:47.723642+00:00",
      "updated_at": "2025-10-31T23:36:47.723644+00:00"
    },
    {
      "id": "c6f0d0b84e49febca3da2525cc567a0d",
      "url": "http://ieeexplore.ieee.org/document/11210864",
      "title": "IEEE Engineering in Medicine and Biology Society Publication Information",
      "content": "null",
      "author": "",
      "published_date": "2025-10-21T13:16:29+00:00",
      "source": "Transactions Biomedical Engineering",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 1,
      "reading_time": 1,
      "created_at": "2025-10-31T23:36:47.723622+00:00",
      "updated_at": "2025-10-31T23:36:47.723624+00:00"
    },
    {
      "id": "f81ce0f85283a86d6b8262d8422a9d77",
      "url": "http://ieeexplore.ieee.org/document/11210866",
      "title": "Front Cover",
      "content": "null",
      "author": "",
      "published_date": "2025-10-21T13:16:29+00:00",
      "source": "Transactions Biomedical Engineering",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 1,
      "reading_time": 1,
      "created_at": "2025-10-31T23:36:47.723598+00:00",
      "updated_at": "2025-10-31T23:36:47.723602+00:00"
    },
    {
      "id": "f7f416118a32b0e243911d8ef725d75c",
      "url": "https://www.embs.org/blog-post/change-foi-for-ieee-embs/",
      "title": "Notice to IEEE EMBS Members: Change to Field of Interest",
      "content": "<p>The post <a href=\"https://www.embs.org/blog-post/change-foi-for-ieee-embs/\">Notice to IEEE EMBS Members: Change to Field of Interest</a> appeared first on <a href=\"https://www.embs.org\">IEEE EMBS</a>.</p>",
      "author": "Nancy Zimmerman",
      "published_date": "2025-04-27T21:41:29+00:00",
      "source": "Embs",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 19,
      "reading_time": 1,
      "created_at": "2025-10-31T23:36:43.750847+00:00",
      "updated_at": "2025-10-31T23:36:43.750849+00:00"
    },
    {
      "id": "1afc4c4e54184a244c216bb5b044f863",
      "url": "https://www.embs.org/blog-post/change-foi-for-ieee-embs/#new_tab",
      "title": "Notice to IEEE EMBS Members: Change to Field of Interest",
      "content": "<p>The post <a href=\"https://www.embs.org/blog-post/change-foi-for-ieee-embs/#new_tab\">Notice to IEEE EMBS Members: Change to Field of Interest</a> appeared first on <a href=\"https://www.embs.org\">IEEE EMBS</a>.</p>",
      "author": "Nancy Zimmerman",
      "published_date": "2025-04-27T21:46:11+00:00",
      "source": "Embs",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 19,
      "reading_time": 1,
      "created_at": "2025-10-31T23:36:43.750828+00:00",
      "updated_at": "2025-10-31T23:36:43.750830+00:00"
    },
    {
      "id": "5d49304b30e3f1cca1ea313fc654375e",
      "url": "https://www.embs.org/uncategorized/call-for-adcom-nominations/",
      "title": "Open Call for AdCom Nominations",
      "content": "<p>The post <a href=\"https://www.embs.org/uncategorized/call-for-adcom-nominations/\">Open Call for AdCom Nominations</a> appeared first on <a href=\"https://www.embs.org\">IEEE EMBS</a>.</p>",
      "author": "Nancy Zimmerman",
      "published_date": "2025-05-02T17:09:21+00:00",
      "source": "Embs",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 14,
      "reading_time": 1,
      "created_at": "2025-10-31T23:36:43.750808+00:00",
      "updated_at": "2025-10-31T23:36:43.750810+00:00"
    },
    {
      "id": "44512f317cc36cf87dc8beab536d92fd",
      "url": "https://www.nature.com/articles/s41539-025-00373-8",
      "title": "Motor learning mechanisms are not modified by feedback manipulations in a real-world task",
      "content": "",
      "author": "",
      "published_date": "2025-10-30T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-10-31T23:36:31.349050+00:00",
      "updated_at": "2025-10-31T23:36:31.349051+00:00"
    },
    {
      "id": "94d9be0bf9eb668bb6f07b012d5fec1b",
      "url": "https://www.nature.com/articles/s41467-025-64988-6",
      "title": "Childhood gut microbiome is linked to internalizing symptoms at school age via the functional connectome",
      "content": "",
      "author": "",
      "published_date": "2025-10-30T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-10-31T23:36:31.348958+00:00",
      "updated_at": "2025-10-31T23:36:31.348959+00:00"
    },
    {
      "id": "c7dd8f657e7c4e9192922822c91a584e",
      "url": "https://www.frontiersin.org/articles/10.3389/fnbot.2025.1676787",
      "title": "DWMamba: a structure-aware adaptive state space network for image quality improvement",
      "content": "Overcoming visual degradation in challenging imaging scenarios is essential for accurate scene understanding. Although deep learning methods have integrated various perceptual capabilities and achieved remarkable progress, their high computational cost limits practical deployment under resource-constrained conditions. Moreover, when confronted with diverse degradation types, existing methods often fail to effectively model the inconsistent attenuation across color channels and spatial regions. To tackle these challenges, we propose DWMamba, a degradation-aware and weight-efficient Mamba network for image quality enhancement. Specifically, DWMamba introduces an Adaptive State Space Module (ASSM) that employs a dual-stream channel monitoring mechanism and a soft fusion strategy to capture global dependencies. With linear computational complexity, ASSM strengthens the models ability to address non-uniform degradations. In addition, by leveraging explicit edge priors and region partitioning as guidance, we design a Structure-guided Residual Fusion (SGRF) module to selectively fuse shallow and deep features, thereby restoring degraded details and enhancing low-light textures. Extensive experiments demonstrate that the proposed network delivers superior qualitative and quantitative performance, with strong generalization to diverse extreme lighting conditions. The code is available at https://github.com/WindySprint/DWMamba.",
      "author": "Zhixiong Huang",
      "published_date": "2025-10-02T00:00:00+00:00",
      "source": "Frontiers Neurorobotics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 176,
      "reading_time": 1,
      "created_at": "2025-10-31T23:36:21.653260+00:00",
      "updated_at": "2025-10-31T23:36:21.653261+00:00"
    },
    {
      "id": "f04f02121b1d13836df0a2b01a861136",
      "url": "https://www.frontiersin.org/articles/10.3389/fnbot.2025.1681341",
      "title": "UAV-based intelligent traffic surveillance using recurrent neural networks and Swin transformer for dynamic environments",
      "content": "IntroductionUrban traffic congestion, environmental degradation, and road safety challenges necessitate intelligent aerial robotic systems capable of real-time adaptive decision-making. Unmanned Aerial Vehicles (UAVs), with their flexible deployment and high vantage point, offer a promising solution for large-scale traffic surveillance in complex urban environments. This study introduces a UAV-based neural framework that addresses challenges such as asymmetric vehicle motion, scale variations, and spatial inconsistencies in aerial imagery.MethodsThe proposed system integrates a multi-stage pipeline encompassing contrast enhancement and region-based clustering to optimize segmentation while maintaining computational efficiency for resource-constrained UAV platforms. Vehicle detection is carried out using a Recurrent Neural Network (RNN), optimized via a hybrid loss function combining cross-entropy and mean squared error to improve localization and confidence estimation. Upon detection, the system branches into two neural submodules: (i) a classification stream utilizing SURF and BRISK descriptors integrated with a Swin Transformer backbone for precise vehicle categorization, and (ii) a multi-object tracking stream employing DeepSORT, which fuses motion and appearance features within an affinity matrix for robust trajectory association.ResultsComprehensive evaluation on three benchmark UAV datasets\u2014AU-AIR, UAVDT, and VAID shows consistent and high performance. The model achieved detection precisions of 0.913, 0.930, and 0.920; tracking precisions of 0.901, 0.881, and 0.890; and classification accuracies of 92.14, 92.75, and 91.25%, respectively.DiscussionThese findings highlight the adaptability, robustness, and real-time viability of the proposed architecture in aerial traffic surveillance applications. By effectively integrating detection, classification, and tracking within a unified neural framework, the system contributes significant advancements to intelligent UAV-based traffic monitoring and supports future developments in smart city mobility and decision-making systems.",
      "author": "Hui Liu",
      "published_date": "2025-10-13T00:00:00+00:00",
      "source": "Frontiers Neurorobotics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 258,
      "reading_time": 1,
      "created_at": "2025-10-31T23:36:21.653191+00:00",
      "updated_at": "2025-10-31T23:36:21.653192+00:00"
    },
    {
      "id": "7435952e0834ce3bab69423a0615bac7",
      "url": "https://www.frontiersin.org/articles/10.3389/fnbot.2025.1691300",
      "title": "UHGAN: a dual-phase GAN with Hough-transform constraints for accurate farmland road extraction",
      "content": "IntroductionTraditional methods for farmland road extraction, such as U-Net, often struggle with complex noise and geometric features, leading to discontinuous extraction and insufficient sensitivity. To address these limitations, this study proposes a novel dual-phase generative adversarial network (GAN) named UHGAN, which integrates Hough-transform constraints.MethodsWe designed a cascaded U-Net generator within a two-stage GAN framework. The Stage 1 GAN combines a differentiable Hough transform loss with cross-entropy loss to generate initial road masks. Subsequently, the Stage 2 U-Net refines these masks by repairing breakpoints and suppressing isolated noise.ResultsWhen evaluated on the WHU RuR+rural road dataset, the proposed UHGAN method achieved an accuracy of 0.826, a recall of 0.750, and an F1-score of 0.789. This represents a significant improvement over the single-stage U-Net (F1\u202f=\u202f0.756) and ResNet (F1\u202f=\u202f0.762) baselines.DiscussionThe results demonstrate that our approach effectively mitigates the issues of discontinuous extraction caused by the complex geometric shapes and partial occlusion characteristic of farmland roads. The integration of Hough-transform loss, an technique that has received limited attention in prior studies, proves to be highly beneficial. This method shows considerable promise for practical applications in rural infrastructure planning and precision agriculture.",
      "author": "Yuan Ma",
      "published_date": "2025-10-13T00:00:00+00:00",
      "source": "Frontiers Neurorobotics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 190,
      "reading_time": 1,
      "created_at": "2025-10-31T23:36:21.653149+00:00",
      "updated_at": "2025-10-31T23:36:21.653151+00:00"
    },
    {
      "id": "ff201f433ce74b05f9172aa17cd65f8e",
      "url": "http://iopscience.iop.org/article/10.1088/1741-2552/ae0eef",
      "title": "Co-cultured sensory neuron classification using extracellular electrophysiology and machine learning approaches for enhancing analgesic screening",
      "content": "Objective. Chronic pain affects over 20% of the adult population in the United States, posing a substantial personal as well as economic burden and contributing to the ongoing opioid crisis. Effective, non-addictive chronic pain treatments are urgently needed. Traditional drug discovery methods have failed to identify novel, non-addictive compounds, highlighting the need for alternative approaches such as phenotypic screening. Our lab developed a phenotypic screening assay using extracellular electrophysiological recordings from co-cultures of human induced pluripotent stem cell sensory neurons and glia. This study aimed to identify responsive neuronal subtypes within these presumptively heterogeneous cultures. Approach. We induced an inflammation-like state using tumor necrosis factor alpha and evaluated acute responses to nociceptor agonist capsaicin, which targets transient receptor potential vanilloid-1. By employing unsupervised learning, we labeled responsive cells based on changes in mean firing rates (MFR). We then used the labeled cells\u2019 baseline activity to train and validate five classifiers. Main results. None of the classifiers outperformed the others in regards to accuracy. Nonetheless, an RUS-boosted ensemble of decision trees achieved an AUC-ROC of 0.877 classifying nociceptors in an unseen labeled culture. Significance. The notable accuracy suggests that machine learning techniques could be employed to enhance microelectrode array-based neuronal phenotypic assays as readouts (e.g. MFR) can be weighted based on target cell type (e.g. nociceptors).",
      "author": "Alexander Somers and Bryan James Black",
      "published_date": "2025-10-22T23:00:00+00:00",
      "source": "Journal Neural Engineering",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 215,
      "reading_time": 1,
      "created_at": "2025-10-31T23:36:18.869510+00:00",
      "updated_at": "2025-10-31T23:36:18.869511+00:00"
    },
    {
      "id": "cfe24e13f8045d3071bb435788947946",
      "url": "http://iopscience.iop.org/article/10.1088/1741-2552/ae15bf",
      "title": "Spec2VolCAMU-Net: a spectrogram-to-volume model for EEG-to-fMRI reconstruction based on Multi-directional Time\u2013Frequency Convolutional Attention Encoder and Vision-Mamba U-Net",
      "content": "Objective. High-resolution functional magnetic resonance imaging (fMRI) is essential for mapping human brain activity; however, it remains costly and logistically challenging. If comparable volumes could be generated directly from widely available scalp electroencephalography (EEG), advanced neuroimaging would become significantly more accessible. Existing EEG-to-fMRI generators rely on plain convolutional neural networks that fail to capture cross-channel time\u2013frequency cues or on heavy transformer/generative adversarial network decoders that strain memory and stability. Approach. To address these limitations, we propose Spec2VolCAMU-Net, a lightweight architecture featuring a Multi-directional Time\u2013Frequency Convolutional Attention Encoder for rich feature extraction and a Vision-Mamba U-Net decoder that uses linear-time state-space blocks for efficient long-range spatial modeling. We frame the goal of this work as establishing a new state of the art in the spatial fidelity of single-volume reconstruction, a foundational prerequisite for the ultimate aim of generating temporally coherent fMRI time series. Main results. Trained end-to-end with a hybrid SSI-MSE loss, Spec2VolCAMU-Net achieves state-of-the-art fidelity on three public benchmarks, recording structural similarity index (SSIM) of 0.693 on NODDI, 0.725 on Oddball and 0.788 on CN-EPFL, representing improvements of 14.5%, 14.9%, and 16.9% respectively over previous best SSIM scores. Furthermore, it achieves competitive peak signal-to-noise ratio (PSNR) scores, particularly excelling on the CN-EPFL dataset with a 4.6% improvement over the previous best PSNR, thus striking a better balance in reconstruction quality. Significance. The proposed model is lightweight and efficient, making it suitable for real-time applications in clinical and research settings. The code is available at https://github.com/hdy6438/Spec2VolCAMU-Net.",
      "author": "Dongyi He, Shiyang Li, Bin Jiang and He Yan",
      "published_date": "2025-10-30T00:00:00+00:00",
      "source": "Journal Neural Engineering",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 245,
      "reading_time": 1,
      "created_at": "2025-10-31T23:36:18.869221+00:00",
      "updated_at": "2025-10-31T23:36:18.869222+00:00"
    },
    {
      "id": "0e5245b3fb8829637e6ad1ef8dcd3983",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38873838/?utm_source=BucketBot&utm_medium=rss&utm_campaign=None&utm_content=1BUB2BG5RbxOblm-hBbiJWEhGG43qlVrvGNHOTqBKva9wWrItM&fc=None&ff=20251031193616&v=2.18.0.post22+67771e2",
      "title": "The impact of CSF-filled cavities on scalp EEG and its implications",
      "content": "Previous studies have found electroencephalogram (EEG) amplitude and scalp topography differences between neurotypical and neurological/neurosurgical groups, being interpreted at the cognitive level. However, these comparisons are invariably accompanied by anatomical changes. Critical to EEG are the so-called volume currents, which are affected by the spatial distribution of the different tissues in the head. We investigated the effect of cerebrospinal fluid (CSF)-filled cavities on simulated...",
      "author": "Maria Carla Piastra",
      "published_date": "2024-06-14T10:00:00+00:00",
      "source": "Oostenveld Robert",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 64,
      "reading_time": 1,
      "created_at": "2025-10-31T23:36:17.155741+00:00",
      "updated_at": "2025-10-31T23:36:17.155743+00:00"
    },
    {
      "id": "84af52c7e96e12e6b47181058bd70412",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38956071/?utm_source=BucketBot&utm_medium=rss&utm_campaign=None&utm_content=1BUB2BG5RbxOblm-hBbiJWEhGG43qlVrvGNHOTqBKva9wWrItM&fc=None&ff=20251031193616&v=2.18.0.post22+67771e2",
      "title": "Motion-BIDS: an extension to the brain imaging data structure to organize motion data for reproducible research",
      "content": "We present an extension to the Brain Imaging Data Structure (BIDS) for motion data. Motion data is frequently recorded alongside human brain imaging and electrophysiological data. The goal of Motion-BIDS is to make motion data interoperable across different laboratories and with other data modalities in human brain and behavioral research. To this end, Motion-BIDS standardizes the data format and metadata structure. It describes how to document experimental details, considering the diversity of...",
      "author": "Julius Welzel",
      "published_date": "2024-07-02T10:00:00+00:00",
      "source": "Oostenveld Robert",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 72,
      "reading_time": 1,
      "created_at": "2025-10-31T23:36:17.155719+00:00",
      "updated_at": "2025-10-31T23:36:17.155720+00:00"
    }
  ]
}