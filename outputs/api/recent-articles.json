{
  "last_updated": "2025-11-12T18:30:26.882262+00:00",
  "count": 20,
  "articles": [
    {
      "id": "487d931ed84f487ba4532d787d6b35d5",
      "url": "https://www.biorxiv.org/content/10.1101/2025.11.10.687649v1?rss=1",
      "title": "PIAS1/PIAS4-Mediated SUMOylation of TDP-43 is Induced by Oxidative Stress",
      "content": "TAR DNA-binding protein 43 (TDP-43) is a conserved RNA and DNA binding protein that functions in transcriptional repression, pre-mRNA splicing and mRNA stabilization. Under pathological conditions found in multiple neurodegenerative diseases, TDP-43 shows aberrant mislocalization from the nucleus and cytoplasmic accumulation and aggregation. TDP-43 also appears to play a role in DNA damage repair, specifically in non-homologous end-joining (NHEJ), suggesting that nuclear depletion of TDP-43 may contribute towards the accumulation of DNA damage observed in TDP-43 proteinopathies. These TDP-43 pathological inclusions are decorated with post-translational modifications, most notably phosphorylation. SUMOylation (Small Ubiquitin-like Modifier) is a dynamic post-translational modification that regulates many protein properties and is implicated in neurodegenerative disease pathology. DNA damage repair proteins are commonly regulated through SUMOylation, and the SUMO E3 ligases PIAS1 and PIAS4 are required for efficient DNA repair of double-strand DNA breaks. Given these findings, we investigated TDP-43 SUMOylation and whether SUMO modification impacts TDP-43s DNA damage repair function. We show that TDP-43 can be modified by SUMO1 and SUMO2/3 and confirm SUMOylation in response to oxidative stress. We also determine which regions of TDP-43 are SUMOylated and show that this modification is facilitated by the SUMO E3 ligases PIAS1 and PIAS4. Etoposide-induced DNA damage did not promote SUMOylation of TDP-43; studies are ongoing to determine the impact of TDP-43 SUMOylation on DNA repair.",
      "author": "Pendlebury, D., Truong, K., Heath, M., Reidling, J. C., Sarkar, P., Thompson, L. M.",
      "published_date": "2025-11-12T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 219,
      "reading_time": 1,
      "created_at": "2025-11-12T18:29:53.693460+00:00",
      "updated_at": "2025-11-12T18:29:53.693466+00:00"
    },
    {
      "id": "e689d66a4dd917a07746feb08b1acf32",
      "url": "https://www.nature.com/articles/d41586-025-03526-2",
      "title": "Three rising stars in ageing research",
      "content": "",
      "author": "",
      "published_date": "2025-11-12T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-11-12T18:29:52.017206+00:00",
      "updated_at": "2025-11-12T18:29:52.017207+00:00"
    },
    {
      "id": "145920d012e3531068f5ccc6fb98ad5c",
      "url": "https://www.nature.com/articles/d41586-025-03525-3",
      "title": "Is ageing a disease? The debate that could reshape medicine",
      "content": "",
      "author": "",
      "published_date": "2025-11-12T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-11-12T18:29:52.017188+00:00",
      "updated_at": "2025-11-12T18:29:52.017189+00:00"
    },
    {
      "id": "293025ef74569a79d2aa8c27bf2d5bfa",
      "url": "https://www.nature.com/articles/d41586-025-03523-5",
      "title": "The future of ageing: science aims to deliver another leap in lifespan",
      "content": "",
      "author": "",
      "published_date": "2025-11-12T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-11-12T18:29:52.017056+00:00",
      "updated_at": "2025-11-12T18:29:52.017058+00:00"
    },
    {
      "id": "b91c6f0e851b17fda569b4c0b4115ffa",
      "url": "https://store.steampowered.com/sale/steamframe",
      "title": "Steam Frame",
      "content": "<a href=\"https://news.ycombinator.com/item?id=45903325\">Comments</a>",
      "author": "",
      "published_date": "2025-11-12T17:54:58+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-11-12T18:29:11.248035+00:00",
      "updated_at": "2025-11-12T18:29:11.248036+00:00"
    },
    {
      "id": "1ab2f06170a9c003bac34de90438d524",
      "url": "https://store.steampowered.com/sale/steammachine",
      "title": "Steam Machine",
      "content": "<a href=\"https://news.ycombinator.com/item?id=45903404\">Comments</a>",
      "author": "",
      "published_date": "2025-11-12T17:59:43+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-11-12T18:29:11.247978+00:00",
      "updated_at": "2025-11-12T18:29:11.247980+00:00"
    },
    {
      "id": "1bbd9445335a9f46cb280009996a8460",
      "url": "https://news.ycombinator.com/item?id=45903161",
      "title": "Launch HN: JSX Tool (YC F25) \u2013 A Browser Dev-Panel IDE for React",
      "content": "<a href=\"https://news.ycombinator.com/item?id=45903161\">Comments</a>",
      "author": "",
      "published_date": "2025-11-12T17:43:42+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-11-12T18:29:11.247959+00:00",
      "updated_at": "2025-11-12T18:29:11.247960+00:00"
    },
    {
      "id": "6f6d716ac81cf9c14d46bdc2bf081c83",
      "url": "https://www.apple.com/newsroom/2025/11/apple-introduces-digital-id-a-new-way-to-create-and-present-an-id-in-apple-wallet/",
      "title": "Apple Introduced Digital ID in Apple Wallet",
      "content": "<p>Article URL: <a href=\"https://www.apple.com/newsroom/2025/11/apple-introduces-digital-id-a-new-way-to-create-and-present-an-id-in-apple-wallet/\">https://www.apple.com/newsroom/2025/11/apple-introduces-digital-id-a-new-way-to-create-and-present-an-id-in-apple-wallet/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=45902273\">https://news.ycombinator.com/item?id=45902273</a></p>\n<p>Points: 5</p>\n<p># Comments: 1</p>",
      "author": "meetpateltech",
      "published_date": "2025-11-12T16:40:17+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-11-12T18:29:10.055175+00:00",
      "updated_at": "2025-11-12T18:29:10.055177+00:00"
    },
    {
      "id": "e8a1bdcdabc7462b2f28efd7dd773a41",
      "url": "https://news.ycombinator.com/item?id=45902590",
      "title": "Show HN: Cancer diagnosis makes for an interesting RL environment for LLMs",
      "content": "<p>Hey HN, this is David from Aluna (YC S24). We work with diagnostic labs to build datasets and evals for oncology tasks.<p>I wanted to share a simple RL environment I built that gave frontier LLMs a set of tools that lets it zoom and pan across a digitized pathology slide to find the relevant regions to make a diagnosis. \nHere are some videos of the LLM performing diagnosis on a few slides:<p>(<a href=\"https://www.youtube.com/watch?v=k7ixTWswT5c\" rel=\"nofollow\">https://www.youtube.com/watch?v=k7ixTWswT5c</a>): traces of an LLM choosing different regions to view before making a diagnosis on a case of small-cell carcinoma of the lung<p>(<a href=\"https://youtube.com/watch?v=0cMbqLnKkGU\" rel=\"nofollow\">https://youtube.com/watch?v=0cMbqLnKkGU</a>): traces of an LLM choosing different regions to view before making a diagnosis on a case of benign fibroadenoma of the breast<p>Why I built this:<p>Pathology slides are the backbone of modern cancer diagnosis. Tissue from a biopsy is sliced, stained, and mounted on glass for a pathologist to examine abnormalities.<p>Today, many of these slides are digitized into whole-slide images (WSIs)in TIF or SVS format and are several gigabytes in size.<p>While there exists several pathology-focused AI models, I was curious to test whether frontier LLMs can perform well on pathology-based tasks. The main challenge is that WSIs are too large to fit into an LLM\u2019s context window. The standard workaround, splitting them into thousands of smaller tiles, is inefficient for large frontier LLMs.<p>Inspired by how pathologists zoom and pan under a microscope, I built a set of tools that let LLMs control magnification and coordinates, viewing small regions at a time and deciding where to look next.<p>This ended up resulting in some interesting behaviors, and actually seemed to yield pretty good results with prompt engineering:<p>- GPT 5: explored up to ~30 regions before deciding (concurred with an expert pathologist on 4 out of 6 cancer subtyping tasks and 3 out of 5 IHC scoring tasks)<p>- Claude 4.5: Typically used 10\u201315 views but similar accuracy as GPT-5 (concurred with the pathologist on 3 out of 6 cancer subtyping tasks and 4 out of 5 IHC scoring tasks)<p>- Smaller models (GPT 4o, Claude 3.5 Haiku): examined ~8 frames and were less accurate overall (1 out of 6 cancer subtytping tasks and 1 out of 5 IHC scoring tasks)<p>Obviously, this was a small sample set, so we are working on creating a larger benchmark suite with more cases and types of tasks, but I thought this was cool that it even worked so I wanted to share with HN!</p>\n<hr />\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=45902590\">https://news.ycombinator.com/item?id=45902590</a></p>\n<p>Points: 3</p>\n<p># Comments: 0</p>",
      "author": "dchu17",
      "published_date": "2025-11-12T17:01:42+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 414,
      "reading_time": 2,
      "created_at": "2025-11-12T18:29:10.055155+00:00",
      "updated_at": "2025-11-12T18:29:10.055157+00:00"
    },
    {
      "id": "1bbd9445335a9f46cb280009996a8460",
      "url": "https://news.ycombinator.com/item?id=45903161",
      "title": "Launch HN: JSX Tool (YC F25) \u2013 A Browser Dev-Panel IDE for React",
      "content": "<p>Hi HN, We\u2019re Jamie & Dan, building JSX Tool (<a href=\"https://jsxtool.com\">https://jsxtool.com</a>) a new inspector/dev panel IDE that allows you to navigate to any line of your React project\u2019s JSX with just a click and a command click to explore your render stack.<p>Demo video: <a href=\"https://www.youtube.com/watch?v=JIIXvN7vhrs\" rel=\"nofollow\">https://www.youtube.com/watch?v=JIIXvN7vhrs</a><p>I\u2019ve been writing React code for nearly a decade. Since I first saw source maps in the days of Babel and Redux, I\u2019ve always wanted to be able to edit my code from the source maps. I\u2019ve also always wanted to be able to inspect my JSX like it was HTML.<p>Last year, I found my first real use of AI was taking ad-hoc CSS changes in the Chrome element inspector, pasting them into ChatGPT, and asking for the equivalent in Tailwind. I\u2019d then paste those changes into my React TSX files.<p>I wanted to streamline this process but came to the conclusion that to do so I needed to build a JSX inspector. I had to write a custom AST parser to create a mapping between the JSX and HTML. So I hacked on an inspector for a couple of months that connected JSX to the DOM in both directions.<p>The next feature was adding a CSS editor, like the one in the browser inspectors but for JSX. Unlike styling a piece of HTML I decided that any in memory style edits to a React fiber should be globally applied, as if you had tweaked that line of code in your codebase.<p>Finally, I was able to add the two AI features I really wanted: (1) prompt for in-memory styles for when I was pixel tweaking, and (2) save those temporary changes back to my codebase in the convention of the codebase I was working in.<p>To accomplish talking to the filesystem from the Chrome extension I built a little local server that mounts from the root of your project and allows the extension to send file-system commands back to your project root. We named this the \u201cDev Server\u201d. (Note: You can fully use us as a JSX inspector without this server installed.)<p>After all that, I found that to convert myself as a user I needed it to be a pretty fully functional IDE. I needed vim bindings, I needed a typechecker, I needed auto-complete, I needed a linter, I needed code search and I needed a proper file explorer. Fortunately we were able to take advantage of the dev-server architecture we had stumbled onto in order to add an LSP server and Rip Grep. At this point, after months of dog fooding, I use JSX Tool for almost all of my website edits.<p>We\u2019re still rough around the edges for mobile but we\u2019re working on that.<p>All of the IDE stuff not involving AI is free and works fine without AI. We let you get a taste of the prompting stuff for free but apply some rate limits.<p>The extension itself is not open source but the dev server with the LSP is. It\u2019s a great foundation if you want to build any sort of in-browser IDE and it's nearly React agnostic. Building the dev server was a big undertaking so I\u2019d love to see someone fork it and find value in it.<p>In the future we want to start adding things that we are in a position to take advantage of over something like Cursor, such as letting AI give you code suggestions for runtime exceptions or work with the network logs. We think that the convenience of having your IDE in the dev panel gives us a leg up in convenience and workflow context.<p>Anyway, regardless of how you feel about AI coding, I wanted to make something that was useful with or without AI. We\u2019d love it if you gave it a spin and we want to share anything we can about the technical side of the product that you might find interesting.</p>\n<hr />\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=45903161\">https://news.ycombinator.com/item?id=45903161</a></p>\n<p>Points: 11</p>\n<p># Comments: 4</p>",
      "author": "jsunderland323",
      "published_date": "2025-11-12T17:43:42+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 654,
      "reading_time": 3,
      "created_at": "2025-11-12T18:29:10.055080+00:00",
      "updated_at": "2025-11-12T18:29:10.055082+00:00"
    },
    {
      "id": "b91c6f0e851b17fda569b4c0b4115ffa",
      "url": "https://store.steampowered.com/sale/steamframe",
      "title": "Steam Frame",
      "content": "<p>Article URL: <a href=\"https://store.steampowered.com/sale/steamframe\">https://store.steampowered.com/sale/steamframe</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=45903325\">https://news.ycombinator.com/item?id=45903325</a></p>\n<p>Points: 32</p>\n<p># Comments: 8</p>",
      "author": "Philpax",
      "published_date": "2025-11-12T17:54:58+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-11-12T18:29:10.054983+00:00",
      "updated_at": "2025-11-12T18:29:10.054985+00:00"
    },
    {
      "id": "1ab2f06170a9c003bac34de90438d524",
      "url": "https://store.steampowered.com/sale/steammachine",
      "title": "Steam Machine",
      "content": "<p>Article URL: <a href=\"https://store.steampowered.com/sale/steammachine\">https://store.steampowered.com/sale/steammachine</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=45903404\">https://news.ycombinator.com/item?id=45903404</a></p>\n<p>Points: 24</p>\n<p># Comments: 7</p>",
      "author": "davikr",
      "published_date": "2025-11-12T17:59:43+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-11-12T18:29:10.054962+00:00",
      "updated_at": "2025-11-12T18:29:10.054963+00:00"
    },
    {
      "id": "6805bda2f60a00c913fc244ec7e2bf5f",
      "url": "https://tratt.net/laurie/blog/2025/async_and_finaliser_deadlocks.html",
      "title": "Async and Finaliser Deadlocks",
      "content": "<p>Article URL: <a href=\"https://tratt.net/laurie/blog/2025/async_and_finaliser_deadlocks.html\">https://tratt.net/laurie/blog/2025/async_and_finaliser_deadlocks.html</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=45903586\">https://news.ycombinator.com/item?id=45903586</a></p>\n<p>Points: 4</p>\n<p># Comments: 0</p>",
      "author": "emailed",
      "published_date": "2025-11-12T18:12:29+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-11-12T18:29:10.054931+00:00",
      "updated_at": "2025-11-12T18:29:10.054939+00:00"
    },
    {
      "id": "78adc31950b695b3e7df951fe61ffaf1",
      "url": "https://www.reddit.com/r/Python/comments/1ouwa42/webcam_rubiks_cube_solver_gui_app_pyside6_opengl/",
      "title": "Webcam Rubik's Cube Solver GUI App [PySide6 / OpenGL / OpenCV]",
      "content": "<!-- SC_OFF --><div class=\"md\"><h1>Background</h1> <p>This toy-project started as a self-challenge to see if I could build an application that uses the webcam and some foundational computer vision techniques to detect the state of a scrambled Rubik's cube and then show the solution steps to the user.</p> <h1>Target Audience</h1> <p>As it is a toy-project it is mainly meant for casual use by those who are curious or it serves as an example project for students trying to learn computer vision and/or graphics programming.</p> <h1>Comparison</h1> <p>I have seen a few projects on GitHub that implement a Rubik's cube facelet detection pipeline but they seem to fall short of actually solving the cube and show the solution to the user. I have also seen a few android solver apps but those don't seem to have a way to auto detect the state of the cube using your phone camera and you need to manually set the state.</p> <h1>Installation and Usage</h1> <pre><code>git clone https://github.com/pdadhikary/rubiksolver.git cd rubiksolver uv sync uv run rubiksolver </code></pre> <p>When scanning their Rubik's cube the user should hold up each face of the cube to the webcam. By convention we assume that the white face is UP and the yellow face is DOWN. When scanning the white face, the red face is DOWN and it should be UP when scanning the yellow face.</p> <p>Once the scan is complete press the <code>Play</code> button to animate the solution steps. You can also step through each of the moves using the <code>Previous</code> and <code>Next</code> buttons.</p> <h1>Repository and Demo</h1> <p>A demo of the project can be <a href=\"https://www.youtube.com/watch?v=abj7ubu9g8o\">viewed on YouTube</a></p> <p>The code repository is <a href=\"https://github.com/pdadhikary/rubiksolver\">available on GitHub</a></p> <p>Any and all feedback are welcome! </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Deepta_512\"> /u/Deepta_512 </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1ouwa42/webcam_rubiks_cube_solver_gui_app_pyside6_opengl/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1ouwa42/webcam_rubiks_cube_solver_gui_app_pyside6_opengl/\">[comments]</a></span>",
      "author": "/u/Deepta_512",
      "published_date": "2025-11-12T04:59:54+00:00",
      "source": "Reddit Python",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 298,
      "reading_time": 1,
      "created_at": "2025-11-12T17:41:48.348486+00:00",
      "updated_at": "2025-11-12T18:24:23.106388+00:00",
      "metadata": {
        "processed_at": "2025-11-12T18:24:23.106397+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "97b4af58ae8dff998c6ab6225bb6b1e3",
      "url": "https://www.biorxiv.org/content/10.1101/2025.11.10.687295v1?rss=1",
      "title": "The effects of Alcohol Dependence on the CSF Proteome in Mice: Evidence for Blood-Brain Barrier Dysfunction and Neuroinflammation",
      "content": "Alcohol use disorder (AUD) represents a significant neurological health burden, yet the biological mechanisms underlying alcohol-induced brain pathology remain incompletely understood. Moreover, the molecular underpinnings of the transition from alcohol exposure to alcohol dependence are not well-characterized. We used mass spectrometry (MS)-based proteomics in a preliminary discovery study to compare cerebrospinal fluid (CSF) of alcohol-exposed Non-dependent (Non-dep) versus alcohol-dependent (Dep) mice that underwent the chronic intermittent ethanol (alcohol) - two-bottle choice (CIE-2BC) procedure and systemic anti-IL-6 Receptor antibody administration. CSF samples from individual mice were processed for proteomic analysis and digested with trypsin overnight. Peptides were analyzed via data-independent acquisition (DIA)-MS and data were processed in DIA-NN at 1% FDR. We identified 611 unique proteins across both groups, with 140 proteins differentially detected in CSF from Dep mice and 67 proteins specific to alcohol-exposed but Non-dep controls. The Dep-specific proteins revealed signatures of blood-brain barrier (BBB) disruption, neuroinflammation, cellular stress responses, and complement system activation. In contrast, Non-dep-specific proteins indicated preserved protective mechanisms including complement regulation, anti-inflammatory signaling, and neuronal calcium homeostasis. Ethanol-dependent-specific findings include MMP2, BIP, and to a lesser extent VE-cadherin (CDH5) and VCAM1, indicative of the beginnings of endothelial damage and BBB disruption, alongside established neuroinflammation markers GFAP, CHI3L1, and CX3CL1. This work provides novel preliminary protein-level evidence that alcohol exposure and alcohol dependence are dichotomous; despite the small sample size and limited power for moderate effect sizes, there appears to be a clear molecular transition from maintained protective mechanisms to vascular damage, BBB breakdown, and sustained neuroinflammation.",
      "author": "Turner, N. P., Bajo, M., Roberts, A. J., Roberto, M. P., Yates, J. R.",
      "published_date": "2025-11-12T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 251,
      "reading_time": 1,
      "created_at": "2025-11-12T17:20:27.363490+00:00",
      "updated_at": "2025-11-12T18:24:23.106402+00:00",
      "metadata": {
        "processed_at": "2025-11-12T18:24:23.106404+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "e0e30bb4a2e0dfcbde9d91f5c1f29602",
      "url": "https://www.biorxiv.org/content/10.1101/2025.11.12.687961v1?rss=1",
      "title": "The Primate Hippocampus Constructs a Temporal Scaffold Anchored to Behavioral Events",
      "content": "The hippocampus has been shown to support a variety of cognitive functions, ranging from spatial navigation to anxiety regulation to memory formation, but how its moment-to-moment neuronal activity contributes to cognition remains poorly understood. The activity of single hippocampal neurons is correlated with numerous perceptual features and task variables, raising the question of whether these response properties reflect distinct mechanisms or a single generalized computation. Here, we show that diverse hippocampal responses reflect unified event-driven dynamics in which population activity transitions between discrete ensemble states at behaviorally salient events. Recording from monkeys performing a virtual spatial alternation task, we found that population activity did not evolve smoothly over time but instead transitioned abruptly at each relevant event. These discontinuities segmented activity into distinct ensemble codes, effectively chunking conceptually defined task epochs. Notably, many neuronal responses persisted across visually distinct environments, demonstrating that these dynamics reflect abstract task structure rather than specific sensory features. These results reveal that the hippocampus constructs a temporal scaffold anchored to relevant behavioral events, with each neural state tracking a distinct task phase. This organizational principle may explain the diverse correlates observed across studies: rather than individually encoding task features, hippocampal neurons collectively signal which phase of a behavioral sequence is currently active. Our findings suggest that the hippocampus parses experience into meaningful elements and tracks \"position\" within a learned behavioral structure.",
      "author": "Rueckemann, J. W., Browning, Y., Mallory, A. J., Kim, B., Fairhall, A. L., Buffalo, E. A.",
      "published_date": "2025-11-12T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 226,
      "reading_time": 1,
      "created_at": "2025-11-12T17:20:27.363448+00:00",
      "updated_at": "2025-11-12T18:24:23.106407+00:00",
      "metadata": {
        "processed_at": "2025-11-12T18:24:23.106408+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "b45c87a5819f99aefc31a36226a0ad02",
      "url": "https://www.biorxiv.org/content/10.1101/2025.11.12.688012v1?rss=1",
      "title": "Low-Dimensional and Optimised Representations of High-Level Information in the Expert Brain",
      "content": "What transforms a novice into an expert? While decades of research show that expertise relies on domain-specific knowledge, a neural account of this transformation has remained fragmentary. We lack an understanding of what information expert representations encode, how they are structured for efficient use, and where in the brain they reside. Here, using chess as a model system for outstanding performance, we combine neuroimaging with multivariate pattern analysis to reveal three principles of the expert brain. We show that expertise drives a shift in representational content, from surface visual features to high-level, relational information. This is accompanied by a structural change, to low-dimensional, optimised representation. Neural codes become more compact and better organised for rapid use, yet retain the details needed for precise evaluation. Finally, we find the representational load shifts from sensory-specific cortices to domain-general frontoparietal networks. These principles show how the expert brain packs more into less, concentrating richer knowledge into fewer, better-organised representations that support rapid, flexible decision-making that defines mastery.",
      "author": "Costantino, A. I., Platonov, A., Fontana Vieira, F., Van Hove, E., Bilalic, M., Op de Beeck, H.",
      "published_date": "2025-11-12T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 164,
      "reading_time": 1,
      "created_at": "2025-11-12T17:20:27.363396+00:00",
      "updated_at": "2025-11-12T18:24:23.106410+00:00",
      "metadata": {
        "processed_at": "2025-11-12T18:24:23.106412+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "eb0181da5ba0475b6600bf6cd5ff8808",
      "url": "https://github.com/helm/helm/releases/tag/v4.0.0",
      "title": "Helm v4.0.0",
      "content": "<p>Article URL: <a href=\"https://github.com/helm/helm/releases/tag/v4.0.0\">https://github.com/helm/helm/releases/tag/v4.0.0</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=45902604\">https://news.ycombinator.com/item?id=45902604</a></p>\n<p>Points: 6</p>\n<p># Comments: 0</p>",
      "author": "todsacerdoti",
      "published_date": "2025-11-12T17:02:38+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-11-12T17:19:49.448592+00:00",
      "updated_at": "2025-11-12T18:24:23.106414+00:00",
      "metadata": {
        "processed_at": "2025-11-12T18:24:23.106416+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "e0f8e3eb1827a3e709c7286010e184c9",
      "url": "https://techcrunch.com/2025/11/12/waymo-robotaxis-are-now-giving-rides-on-freeways-in-these-3-cities/",
      "title": "Waymo begins freeway rides for the public",
      "content": "<a href=\"https://news.ycombinator.com/item?id=45901855\">Comments</a>",
      "author": "",
      "published_date": "2025-11-12T16:06:29+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-11-12T16:52:47.326241+00:00",
      "updated_at": "2025-11-12T16:52:47.326242+00:00"
    },
    {
      "id": "0e4ad11bf403c12124b4ba22c21ba5e4",
      "url": "https://oneuptime.com/blog/post/2025-11-12-kubernetes-is-your-private-cloud/view",
      "title": "Kubernetes Is Your Private Cloud",
      "content": "<a href=\"https://news.ycombinator.com/item?id=45901869\">Comments</a>",
      "author": "",
      "published_date": "2025-11-12T16:07:30+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-11-12T16:52:47.326124+00:00",
      "updated_at": "2025-11-12T16:52:47.326126+00:00"
    }
  ]
}