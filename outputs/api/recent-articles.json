{
  "last_updated": "2025-12-12T05:47:27.130548+00:00",
  "count": 20,
  "articles": [
    {
      "id": "0adbf76a60a38e99e1fe333e7ad9a143",
      "url": "https://www.danieleteti.it/post/html-first-frameworks-htmx-revolution-en/#building-with-html-instead-of-fighting-with-javascript-layers-",
      "title": "The HTML-First Approach: Why Htmx and Lightweight Frameworks Are Revolutionizin",
      "content": "<p>Article URL: <a href=\"https://www.danieleteti.it/post/html-first-frameworks-htmx-revolution-en/#building-with-html-instead-of-fighting-with-javascript-layers-\">https://www.danieleteti.it/post/html-first-frameworks-htmx-revolution-en/#building-with-html-instead-of-fighting-with-javascript-layers-</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46239445\">https://news.ycombinator.com/item?id=46239445</a></p>\n<p>Points: 10</p>\n<p># Comments: 0</p>",
      "author": "todsacerdoti",
      "published_date": "2025-12-12T00:37:42+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-12T05:46:13.534540+00:00",
      "updated_at": "2025-12-12T05:46:13.534542+00:00"
    },
    {
      "id": "5e148265dd0f3ead7b90275271106ab2",
      "url": "https://arxiv.org/abs/2512.10110",
      "title": "Generate-Then-Validate: A Novel Question Generation Approach Using Small Language Models",
      "content": "arXiv:2512.10110v1 Announce Type: cross \nAbstract: We explore the use of small language models (SLMs) for automatic question generation as a complement to the prevalent use of their large counterparts in learning analytics research. We present a novel question generation pipeline that leverages both the text generation and the probabilistic reasoning abilities of SLMs to generate high-quality questions. Adopting a \"generate-then-validate\" strategy, our pipeline first performs expansive generation to create an abundance of candidate questions and refine them through selective validation based on novel probabilistic reasoning. We conducted two evaluation studies, one with seven human experts and the other with a large language model (LLM), to assess the quality of the generated questions. Most judges (humans or LLMs) agreed that the generated questions had clear answers and generally aligned well with the intended learning objectives. Our findings suggest that an SLM can effectively generate high-quality questions when guided by a well-designed pipeline that leverages its strengths.",
      "author": "Yumou Wei, John Stamper, Paulo F. Carvalho",
      "published_date": "2025-12-12T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 155,
      "reading_time": 1,
      "created_at": "2025-12-12T05:24:15.356971+00:00",
      "updated_at": "2025-12-12T05:24:15.356972+00:00"
    },
    {
      "id": "637fe6fb1dfe3cd73e15fa20257e4084",
      "url": "https://arxiv.org/abs/2512.10065",
      "title": "Linear socio-demographic representations emerge in Large Language Models from indirect cues",
      "content": "arXiv:2512.10065v1 Announce Type: cross \nAbstract: We investigate how LLMs encode sociodemographic attributes of human conversational partners inferred from indirect cues such as names and occupations. We show that LLMs develop linear representations of user demographics within activation space, wherein stereotypically associated attributes are encoded along interpretable geometric directions. We first probe residual streams across layers of four open transformer-based LLMs (Magistral 24B, Qwen3 14B, GPT-OSS 20B, OLMo2-1B) prompted with explicit demographic disclosure. We show that the same probes predict demographics from implicit cues: names activate census-aligned gender and race representations, while occupations trigger representations correlated with real-world workforce statistics. These linear representations allow us to explain demographic inferences implicitly formed by LLMs during conversation. We demonstrate that these implicit demographic representations actively shape downstream behavior, such as career recommendations. Our study further highlights that models that pass bias benchmark tests may still harbor and leverage implicit biases, with implications for fairness when applied at scale.",
      "author": "Paul Bouchaud, Pedro Ramaciotti",
      "published_date": "2025-12-12T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 155,
      "reading_time": 1,
      "created_at": "2025-12-12T05:24:15.356942+00:00",
      "updated_at": "2025-12-12T05:24:15.356944+00:00"
    },
    {
      "id": "34304dc9d156c05cfd5da8ddae14b0d2",
      "url": "https://arxiv.org/abs/2512.10058",
      "title": "Mind the Gap! Pathways Towards Unifying AI Safety and Ethics Research",
      "content": "arXiv:2512.10058v1 Announce Type: cross \nAbstract: While much research in artificial intelligence (AI) has focused on scaling capabilities, the accelerating pace of development makes countervailing work on producing harmless, \"aligned\" systems increasingly urgent. Yet research on alignment has diverged along two largely parallel tracks: safety--centered on scaled intelligence, deceptive or scheming behaviors, and existential risk--and ethics--focused on present harms, the reproduction of social bias, and flaws in production pipelines. Although both communities warn of insufficient investment in alignment, they disagree on what alignment means or ought to mean. As a result, their efforts have evolved in relative isolation, shaped by distinct methodologies, institutional homes, and disciplinary genealogies.\n  We present a large-scale, quantitative study showing the structural split between AI safety and AI ethics. Using a bibliometric and co-authorship network analysis of 6,442 papers from twelve major ML and NLP conferences (2020-2025), we find that over 80% of collaborations occur within either the safety or ethics communities, and cross-field connectivity is highly concentrated: roughly 5% of papers account for more than 85% of bridging links. Removing a small number of these brokers sharply increases segregation, indicating that cross-disciplinary exchange depends on a handful of actors rather than broad, distributed collaboration. These results show that the safety-ethics divide is not only conceptual but institutional, with implications for research agendas, policy, and venues. We argue that integrating technical safety work with normative ethics--via shared benchmarks, cross-institutional venues, and mixed-method methodologies--is essential for building AI systems that are both robust and just.",
      "author": "Dani Roytburg, Beck Miller",
      "published_date": "2025-12-12T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 247,
      "reading_time": 1,
      "created_at": "2025-12-12T05:24:15.356913+00:00",
      "updated_at": "2025-12-12T05:24:15.356914+00:00"
    },
    {
      "id": "f60ee20cca667440802aac5f2786980b",
      "url": "https://arxiv.org/abs/2512.09932",
      "title": "Suzume-chan: Your Personal Navigator as an Embodied Information Hub",
      "content": "arXiv:2512.09932v1 Announce Type: cross \nAbstract: Access to expert knowledge often requires real-time human communication. Digital tools improve access to information but rarely create the sense of connection needed for deep understanding. This study addresses this issue using Social Presence Theory, which explains how a feeling of \"being together\" enhances communication. An \"Embodied Information Hub\" is proposed as a new way to share knowledge through physical and conversational interaction. The prototype, Suzume-chan, is a small, soft AI agent running locally with a language model and retrieval-augmented generation (RAG). It learns from spoken explanations and responds through dialogue, reducing psychological distance and making knowledge sharing warmer and more human-centered.",
      "author": "Maya Grace Torii, Takahito Murakami, Shuka Koseki, Yoichi Ochiai",
      "published_date": "2025-12-12T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 107,
      "reading_time": 1,
      "created_at": "2025-12-12T05:24:15.356875+00:00",
      "updated_at": "2025-12-12T05:24:15.356876+00:00"
    },
    {
      "id": "246648cffd19dac9d5a8c65ec237eb29",
      "url": "https://arxiv.org/abs/2512.09931",
      "title": "ExaCraft: Dynamic Learning Context Adaptation for Personalized Educational Examples",
      "content": "arXiv:2512.09931v1 Announce Type: cross \nAbstract: Learning is most effective when it's connected to relevant, relatable examples that resonate with learners on a personal level. However, existing educational AI tools don't focus on generating examples or adapting to learners' changing understanding, struggles, or growing skills. We've developed ExaCraft, an AI system that generates personalized examples by adapting to the learner's dynamic context. Through the Google Gemini AI and Python Flask API, accessible via a Chrome extension, ExaCraft combines user-defined profiles (including location, education, profession, and complexity preferences) with real-time analysis of learner behavior. This ensures examples are both culturally relevant and tailored to individual learning needs. The system's core innovation is its ability to adapt to five key aspects of the learning context: indicators of struggle, mastery patterns, topic progression history, session boundaries, and learning progression signals. Our demonstration will show how ExaCraft's examples evolve from basic concepts to advanced technical implementations, responding to topic repetition, regeneration requests, and topic progression patterns in different use cases.",
      "author": "Akaash Chatterjee (Indian Institute of Technology Jodhpur), Suman Kundu (Indian Institute of Technology Jodhpur)",
      "published_date": "2025-12-12T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 165,
      "reading_time": 1,
      "created_at": "2025-12-12T05:24:15.356848+00:00",
      "updated_at": "2025-12-12T05:24:15.356850+00:00"
    },
    {
      "id": "b2f67bf2bd4bdcb2db92ee9f2f6c94ae",
      "url": "https://arxiv.org/abs/2512.10918",
      "title": "CompanionCast: A Multi-Agent Conversational AI Framework with Spatial Audio for Social Co-Viewing Experiences",
      "content": "arXiv:2512.10918v1 Announce Type: new \nAbstract: Social presence is central to the enjoyment of watching content together, yet modern media consumption is increasingly solitary. We investigate whether multi-agent conversational AI systems can recreate the dynamics of shared viewing experiences across diverse content types. We present CompanionCast, a general framework for orchestrating multiple role-specialized AI agents that respond to video content using multimodal inputs, speech synthesis, and spatial audio. Distinctly, CompanionCast integrates an LLM-as-a-Judge module that iteratively scores and refines conversations across five dimensions (relevance, authenticity, engagement, diversity, personality consistency). We validate this framework through sports viewing, a domain with rich dynamics and strong social traditions, where a pilot study with soccer fans suggests that multi-agent interaction improves perceived social presence compared to solo viewing. We contribute: (1) a generalizable framework for orchestrating multi-agent conversations around multimodal video content, (2) a novel evaluator-agent pipeline for conversation quality control, and (3) exploratory evidence of increased social presence in AI-mediated co-viewing. We discuss challenges and future directions for applying this approach to diverse viewing contexts including entertainment, education, and collaborative watching experiences.",
      "author": "Yiyang Wang, Chen Chen, Tica Lin, Vishnu Raj, Josh Kimball, Alex Cabral, Josiah Hester",
      "published_date": "2025-12-12T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 178,
      "reading_time": 1,
      "created_at": "2025-12-12T05:24:15.356818+00:00",
      "updated_at": "2025-12-12T05:24:15.356819+00:00"
    },
    {
      "id": "93276278ba05c7e2b111e6049e86ccfa",
      "url": "https://arxiv.org/abs/2512.10257",
      "title": "Reject or Not?: A Benchmark for Voice Assistant Query Rejection in Smart Home Scenario and an Improved Method Based on LLMs",
      "content": "arXiv:2512.10257v1 Announce Type: new \nAbstract: In smart-home voice assistant scenario, deciding whether to accept or reject a user query is the first step before any downstream processing. To address the limited query-rejection capability of current voice assistants, this paper presents the first Chinese-oriented open-source benchmark and evaluation suite for smart homes, together with a personalized query-rejection method based on large language models. On the data side, we construct the first multimodal query-rejection dataset tailored for domestic scenarios, containing 11,913 manually labeled text-speech pairs that systematically cover twelve typical dialogue types (e.g., chit-chat, non-human sounds, valid commands, ambiguous references, device-irrelevant requests). Fine-grained labels, conversational context and multi-turn information are provided to support both zero-shot and fine-tuning evaluations across language and multimodal large models. On the method side, we propose a three-tier collaborative architecture: first, a Qwen-2.5-3B adapter fine-tuned to model family-agnostic semantic boundaries; second, a dynamic household-level historical dialogue module to capture personalized habits; third, a household-specific RAG knowledge base that explicitly memorizes and revises past false-rejection cases. Experiments show that the proposed approach significantly outperforms zero-shot and fine-tuned general LLMs on the constructed dataset, with pronounced gains in rejection accuracy for family-specific expressions and complex multi-turn scenarios. This work provides a reproducible data foundation, evaluation standard and extensible technical framework for reliability research in smart-home voice interaction.",
      "author": "Huichao Men, Yizhen Hu, Yingyang He, Yu Gao, Xiaofeng Mou, Yi Xu",
      "published_date": "2025-12-12T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 217,
      "reading_time": 1,
      "created_at": "2025-12-12T05:24:15.356785+00:00",
      "updated_at": "2025-12-12T05:24:15.356787+00:00"
    },
    {
      "id": "572d170170bf86e9aea3b2f7de3ced85",
      "url": "https://arxiv.org/abs/2512.10234",
      "title": "InFerActive: Towards Scalable Human Evaluation of Large Language Models through Interactive Inference",
      "content": "arXiv:2512.10234v1 Announce Type: new \nAbstract: Human evaluation remains the gold standard for evaluating outputs of Large Language Models (LLMs). The current evaluation paradigm reviews numerous individual responses, leading to significant scalability challenges. LLM outputs can be more efficiently represented as a tree structure, reflecting their autoregressive generation process and stochastic token selection. However, conventional tree visualization cannot scale to the exponentially large trees generated by modern sampling methods of LLMs. To address this problem, we present InFerActive, an interactive inference system for scalable human evaluation. InFerActive enables on-demand exploration through probability-based filtering and evaluation features, while bridging the semantic gap between computational tokens and human-readable text through adaptive visualization techniques. Through a technical evaluation and user study (N=12), we demonstrate that InFerActive significantly improves evaluation efficiency and enables more comprehensive assessment of model behavior. We further conduct expert case studies that demonstrate InFerActive's practical applicability and potential for transforming LLM evaluation workflows.",
      "author": "Junhyeong Hwangbo, Soohyun Lee, Minsoo Cheong, Hyeon Jeon, Jinwook Seo",
      "published_date": "2025-12-12T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 152,
      "reading_time": 1,
      "created_at": "2025-12-12T05:24:15.356745+00:00",
      "updated_at": "2025-12-12T05:24:15.356747+00:00"
    },
    {
      "id": "5c8db1c2419d80b9f1dcbc61291c4875",
      "url": "https://arxiv.org/abs/2512.10196",
      "title": "HyFinBall: a Hybrid User Interface for Coordinated 2D+3D Visualization in Semi-Immersive VR",
      "content": "arXiv:2512.10196v1 Announce Type: new \nAbstract: Sophisticated 3D visualization applications usually provide coordinated 2D and 3D views. Normally 3D input device is used for 3D tasks since they perform better than traditional 2D input devices. However, they do not perform better for 2D tasks. This paper presents a bimanual hybrid user interface that supports four interaction modes: a dual 6-degree-of-freedom (DOF) input device mode, a dual planar constrained 3DOF input device mode, a dual 2-finger multi-touch mode, and 3D hand and finger gestures. The application is a multi-dimensional visualization with coordinated 3D and 2D views on a desktop VR system. The input devices are buttonballs with seamless switching between 3D and 2D device modes, as well as between free-hand finger input and device usage. The 3D and 2D device mode switch automatically switches a buttonball's visual representation between a 3D cursor and a 2D cursor while changing the available user interaction techniques between 3D and 2D interaction techniques to interact with the coordinated views. The paper also provides two formal user studies to evaluate HyFinBall for various dimensional tasks, including 3D, 2D, and cross-dimensional tasks. Our experimental results show the benefits of the HyFinBall interface for cross-dimensional tasks that require 3D and 2D interactions.",
      "author": "Isaac Cho, Zachary Wartell",
      "published_date": "2025-12-12T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 203,
      "reading_time": 1,
      "created_at": "2025-12-12T05:24:15.356714+00:00",
      "updated_at": "2025-12-12T05:24:15.356716+00:00"
    },
    {
      "id": "c69bcb50d68d8be4e0dac001c144f3d6",
      "url": "https://arxiv.org/abs/2512.10172",
      "title": "Offscript: Automated Auditing of Instruction Adherence in LLMs",
      "content": "arXiv:2512.10172v1 Announce Type: new \nAbstract: Large Language Models (LLMs) and generative search systems are increasingly used for information seeking by diverse populations with varying preferences for knowledge sourcing and presentation. While users can customize LLM behavior through custom instructions and behavioral prompts, no mechanism exists to evaluate whether these instructions are being followed effectively. We present Offscript, an automated auditing tool that efficiently identifies potential instruction following failures in LLMs. In a pilot study analyzing custom instructions sourced from Reddit, Offscript detected potential deviations from instructed behavior in 86.4% of conversations, 22.2% of which were confirmed as material violations through human review. Our findings suggest that automated auditing serves as a viable approach for evaluating compliance to behavioral instructions related to information seeking.",
      "author": "Nicholas Clark, Ryan Bai, Tanu Mitra",
      "published_date": "2025-12-12T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 123,
      "reading_time": 1,
      "created_at": "2025-12-12T05:24:15.356672+00:00",
      "updated_at": "2025-12-12T05:24:15.356678+00:00"
    },
    {
      "id": "bafd3e4b8432b24bbc745812beb5ada4",
      "url": "https://arxiv.org/abs/2507.01098",
      "title": "Proof of a perfect platonic representation hypothesis",
      "content": "arXiv:2507.01098v2 Announce Type: replace-cross \nAbstract: In this note, we elaborate on and explain in detail the proof given by Ziyin et al. (2025) of the ``perfect\" Platonic Representation Hypothesis (PRH) for the embedded deep linear network model (EDLN). We show that if trained with the stochastic gradient descent (SGD), two EDLNs with different widths and depths and trained on different data will become Perfectly Platonic, meaning that every possible pair of layers will learn the same representation up to a rotation. Because most of the global minima of the loss function are not Platonic, that SGD only finds the perfectly Platonic solution is rather extraordinary. The proof also suggests at least six ways the PRH can be broken. We also show that in the EDLN model, the emergence of the Platonic representations is due to the same reason as the emergence of progressive sharpening. This implies that these two seemingly unrelated phenomena in deep learning can, surprisingly, have a common cause. Overall, the theory and proof highlight the importance of understanding emergent \"entropic forces\" due to the irreversibility of SGD training and their role in representation learning. The goal of this note is to be instructive while avoiding jargon and lengthy technical details.",
      "author": "Liu Ziyin, Isaac Chuang",
      "published_date": "2025-12-12T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 203,
      "reading_time": 1,
      "created_at": "2025-12-12T05:24:14.152299+00:00",
      "updated_at": "2025-12-12T05:24:14.152301+00:00"
    },
    {
      "id": "783f12d737d787f62baa6b1acfd0999f",
      "url": "https://arxiv.org/abs/2509.04454",
      "title": "Mechanisms for anesthesia, unawareness, respiratory depression, memory replay and sleep: MHb > IPN > PAG + DRN + MRN > claustrum > cortical slow waves",
      "content": "arXiv:2509.04454v3 Announce Type: replace \nAbstract: My findings show what causes loss of awareness, anesthesia, memory replay, opioid induced respiratory depression (OIRD), and slow-wave sleep (SWS). Opiates are fast pain relievers and anesthetics that can cause respiratory arrest. I found how mu-opioids and anesthetics by activating medial habenula (MHb) and/or interpeduncular nucleus (IPN) induce unawareness and slowdown respiration. MHb projects to IPN and both increase their glucose intake during anesthesia (Herkenham, 1981). The question is: What is the MHb-IPN circuit doing? I found that it promotes SWS, memory replay, sharp-wave ripples, spindles, hippocampo-cortical replay, synaptogenesis, rest and recovery, by activating median raphe (MRN) serotonin, and by inhibiting the theta state circuit, new memories encoding, awareness, arousal, alert wakefulness, and REM sleep. It causes also natural slowdown of respiration and heart rate, while it inhibits locomotion and arousal. This extended model adds role of the dentate gyrus>posterior septum>MHb>IPN>MRN>hippocampus + BF + claustrum>cortical slow-waves in memory replay, ripples, loss of awareness, SWS, and anesthesia. It proposes new neural mechanism for anesthetic ketamine, nitrous oxide, and phencyclidine effects: activation of the IPN>MRN>claustrum>cortical SWA circuit by the 5-HT2a receptors in the IPN and claustrum. My model shows why are ketamine and psychedelics anxiolytic and antidepressant. How they by activating the 5-HT2a receptors in vACC/infralimbic cortex increase safety, well-being signal, socializing, and cognitive flexibility, and attenuate fear, worries, anger, impulsivity, self-defence, and wanting. This model claims that mu-opioids, acetylcholine, nicotine, endocannabinoids, adenosine, GLP-1RA, and substance P activate the MHb-IPN-MRN circuit which promotes rest, recovery, repair, serotonin-BDNF-protein production, spines growth, and anti-inflammatory state.",
      "author": "Karin Vadovi\\v{c}ov\\'a",
      "published_date": "2025-12-12T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 256,
      "reading_time": 1,
      "created_at": "2025-12-12T05:24:14.152212+00:00",
      "updated_at": "2025-12-12T05:24:14.152213+00:00"
    },
    {
      "id": "de360f3f476ad0416e00b0ce3c4513c8",
      "url": "https://arxiv.org/abs/2502.15440",
      "title": "State-space kinetic Ising model reveals task-dependent entropy flow in sparsely active nonequilibrium neuronal dynamics",
      "content": "arXiv:2502.15440v3 Announce Type: replace \nAbstract: Neuronal ensemble activity, including coordinated and oscillatory patterns, exhibits hallmarks of nonequilibrium systems with time-asymmetric trajectories to maintain their organization. However, assessing time asymmetry from neuronal spiking activity remains challenging. The kinetic Ising model provides a framework for studying the causal, nonequilibrium dynamics in spiking recurrent neural networks. Recent theoretical advances in this model have enabled time-asymmetry estimation from large-scale steady-state data. Yet, neuronal activity often exhibits time-varying firing rates and coupling strengths, violating the steady-state assumption. To overcome this limitation, we developed a state-space kinetic Ising model that accounts for nonstationary and nonequilibrium properties of neural systems. This approach incorporates a mean-field method for estimating time-varying entropy flow, a key measure for maintaining the system's organization through dissipation. Applying this method to mouse visual cortex data revealed greater variability in causal couplings during task engagement despite reduced neuronal activity with increased sparsity. Moreover, higher-performing mice exhibited increased coupling-related entropy flow per spike during task engagement, suggesting more efficient computation in the higher-performing mice. These findings underscore the model's utility in uncovering intricate asymmetric causal dynamics in neuronal ensembles and linking them to behavior through the thermodynamic underpinnings of neural computation.",
      "author": "Ken Ishihara, Hideaki Shimazaki",
      "published_date": "2025-12-12T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 196,
      "reading_time": 1,
      "created_at": "2025-12-12T05:24:14.152174+00:00",
      "updated_at": "2025-12-12T05:24:14.152175+00:00"
    },
    {
      "id": "3928666ff0946874b8b1253e5b1df60f",
      "url": "https://arxiv.org/abs/2512.10011",
      "title": "Spatial Spiking Neural Networks Enable Efficient and Robust Temporal Computation",
      "content": "arXiv:2512.10011v1 Announce Type: cross \nAbstract: The efficiency of modern machine intelligence depends on high accuracy with minimal computational cost. In spiking neural networks (SNNs), synaptic delays are crucial for encoding temporal structure, yet existing models treat them as fully trainable, unconstrained parameters, leading to large memory footprints, higher computational demand, and a departure from biological plausibility. In the brain, however, delays arise from physical distances between neurons embedded in space. Building on this principle, we introduce Spatial Spiking Neural Networks (SpSNNs), a framework in which neurons learn coordinates in a finite-dimensional Euclidean space and delays emerge from inter-neuron distances. This replaces per-synapse delay learning with position learning, substantially reducing parameter count while retaining temporal expressiveness. Across the Yin-Yang and Spiking Heidelberg Digits benchmarks, SpSNNs outperform SNNs with unconstrained delays despite using far fewer parameters. Performance consistently peaks in 2D and 3D networks rather than infinite-dimensional delay spaces, revealing a geometric regularization effect. Moreover, dynamically sparsified SpSNNs maintain full accuracy even at 90% sparsity, matching standard delay-trained SNNs while using up to 18x fewer parameters. Because learned spatial layouts map naturally onto hardware geometries, SpSNNs lend themselves to efficient neuromorphic implementation. Methodologically, SpSNNs compute exact delay gradients via automatic differentiation with custom-derived rules, supporting arbitrary neuron models and architectures. Altogether, SpSNNs provide a principled platform for exploring spatial structure in temporal computation and offer a hardware-friendly substrate for scalable, energy-efficient neuromorphic intelligence.",
      "author": "Lennart P. L. Landsmeer, Amirreza Movahedin, Mario Negrello, Said Hamdioui, Christos Strydis",
      "published_date": "2025-12-12T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 231,
      "reading_time": 1,
      "created_at": "2025-12-12T05:24:14.152142+00:00",
      "updated_at": "2025-12-12T05:24:14.152143+00:00"
    },
    {
      "id": "02d50a5aaf80d84549b0bcbc6f73b533",
      "url": "https://arxiv.org/abs/2512.10844",
      "title": "Modeling, Segmenting and Statistics of Transient Spindles via Two-Dimensional Ornstein-Uhlenbeck Dynamics",
      "content": "arXiv:2512.10844v1 Announce Type: new \nAbstract: We develop here a stochastic framework for modeling and segmenting transient spindle- like oscillatory bursts in electroencephalogram (EEG) signals. At the modeling level, individ- ual spindles are represented as path realizations of a two-dimensional Ornstein{Uhlenbeck (OU) process with a stable focus, providing a low-dimensional stochastic dynamical sys- tem whose trajectories reproduce key morphological features of spindles, including their characteristic rise{decay amplitude envelopes. On the signal processing side, we propose a segmentation procedure based on Empirical Mode Decomposition (EMD) combined with the detection of a central extremum, which isolates single spindle events and yields a collection of oscillatory atoms. This construction enables a systematic statistical analysis of spindle features: we derive empirical laws for the distributions of amplitudes, inter-spindle intervals, and rise/decay durations, and show that these exhibit exponential tails consistent with the underlying OU dynamics. We further extend the model to a pair of weakly coupled OU processes with distinct natural frequencies, generating a stochastic mixture of slow, fast, and mixed spindles in random temporal order. The resulting framework provides a data- driven framework for the analysis of transient oscillations in EEG and, more generally, in nonstationary time series.",
      "author": "C. Sun, D. Fettahoglu, D. Holcman",
      "published_date": "2025-12-12T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 194,
      "reading_time": 1,
      "created_at": "2025-12-12T05:24:14.152106+00:00",
      "updated_at": "2025-12-12T05:24:14.152108+00:00"
    },
    {
      "id": "5bad725159fcc9eb3f7fa091b7585e94",
      "url": "https://arxiv.org/abs/2512.10834",
      "title": "Allometric scaling of brain activity explained by avalanche criticality",
      "content": "arXiv:2512.10834v1 Announce Type: new \nAbstract: Allometric scaling laws, such as Kleiber's law for metabolic rate, highlight how efficiency emerges with size across living systems. The brain, with its characteristic sublinear scaling of activity, has long posed a puzzle: why do larger brains operate with disproportionately lower firing rates? Here we show that this economy of scale is a universal outcome of avalanche dynamics. We derive analytical scaling laws directly from avalanche statistics, establishing that any system governed by critical avalanches must exhibit sublinear activity-size relations. This theoretical prediction is then verified in integrate-and-fire neuronal networks at criticality and in classical self-organized criticality models, demonstrating that the effect is not model-specific but generic. The predicted exponents align with experimental observations across mammal species, bridging dynamical criticality with the allometry of brain metabolism. Our results reveal avalanche criticality as a fundamental mechanism underlying Kleiber-like scaling in the brain.",
      "author": "Tiago S. A. N. Sim\\~oes, Jos\\'e S. Andrade Jr., Hans J. Herrmann, Stefano Zapperi, Lucilla de Arcangelis",
      "published_date": "2025-12-12T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 146,
      "reading_time": 1,
      "created_at": "2025-12-12T05:24:14.152072+00:00",
      "updated_at": "2025-12-12T05:24:14.152074+00:00"
    },
    {
      "id": "bb0c35a1d45c10fe5a36075afad3124f",
      "url": "https://arxiv.org/abs/2512.10525",
      "title": "Parallel Neuron Groups in the Drosophila Brain",
      "content": "arXiv:2512.10525v1 Announce Type: new \nAbstract: The full connectome of an adult Drosophila enables a search for novel neural structures in the insect brain. I describe a new neural structure, called a Parallel Neuron Group (PNG). Two neurons are called parallel if they share a significant number of input neurons and output neurons. Most pairs of neurons in the Drosophila brain have very small parallel match. There are about twenty larger groups of neurons for which any pair of neurons in the group has a high match. These are the parallel groups. Parallel groups contain only about 1000 out of the 65,000 neurons in the brain, and have distinctive properties. There are groups in the right mushroom bodies, the antennal lobes, the lobula, and in two central neuropils (GNG and EB). Most parallel groups do not have lateral symmetry. A group usually has one major input neuron, which inputs to all the neurons in the group, and a small number of major output neurons. The major input and output neurons are laterally asymmetric. Parallel neuron groups present puzzles, such as: what does a group do, that could not be done by one larger neuron? Do all neurons in a group fire in synchrony, or do they perform different functions? Why are they laterally asymmetric? These may merit further investigation.",
      "author": "Robert Worden",
      "published_date": "2025-12-12T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 218,
      "reading_time": 1,
      "created_at": "2025-12-12T05:24:14.152035+00:00",
      "updated_at": "2025-12-12T05:24:14.152040+00:00"
    },
    {
      "id": "44cf4211b89a2f5b97015ff2f16aae0c",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.09.693025v1?rss=1",
      "title": "Altered Brain Network Topology during Successful Response Inhibition in Children with Binge Eating",
      "content": "Aim: Although a risk factor for the later development of eating disorders, few studies examine the neural underpinnings of binge eating (BE) in children. Preliminary evidence suggests a role of the corticostriatal system; the purpose of this study was to evaluate the role of the inhibitory control brain network for risk of BE in children. Methods: Data from 65 children with BE (57% girls) and 84 matched controls (52% girls) from the 4.0 baseline release of the Adolescent Brain Cognitive Development (ABCD) Study were included. Stop Signal Task-based fMRI data were analyzed using graph theoretic techniques. Global and nodal network properties (e.g. efficiency, betweenness-centrality) were compared for between-group differences and sex-by-group interactions. Results: Despite comparable behavioral performance, children with BE showed significantly increased nodal efficiency of the right postcentral gyrus and left middle frontal gyrus (MFG), and increased connectedness of the right postcentral gyrus compared to control children. Children with BE showed distinct network hubs including the right MFG and left insula, while controls had distinct hubs in the right orbitofrontal and left fusiform gyri. Group-specific sex differences were found in the functioning of insular and frontal cortices. Conclusion: Increased efficiency and connectedness in frontal and parietal nodes of the inhibitory control network functioning in children with BE may represent a vulnerability for overeating. Distinct sex differences in functioning in children with BE compared to control children may reflect specific vulnerabilities to BE in the inhibitory control system in boys and girls that may contribute to sex differences in prevalence.",
      "author": "Martin, E., Schulz, K. P., Hildebrandt, T., Sysko, R., Berner, L. A., Li, X.",
      "published_date": "2025-12-11T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 250,
      "reading_time": 1,
      "created_at": "2025-12-12T05:24:04.250097+00:00",
      "updated_at": "2025-12-12T05:24:04.250099+00:00"
    },
    {
      "id": "43b26a12f324f686b774b2ab656f97f2",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.09.693191v1?rss=1",
      "title": "Insular cortex predictions regulate glucose homeostasis",
      "content": "Brain-body interactions are essential for physical and emotional homeostasis. The brain uses information from the external world to predict upcoming bodily changes. This process involves interoceptive predictions, which are thought to play a central role in brain-body interactions. Yet there is little direct experimental evidence causally linking interoceptive predictions to regulation of bodily physiology. Here we address this by focusing on insular cortex and glucose homeostasis. We find that just before the onset of a meal, insular cortex exhibits a transient burst of activity, reflecting a prediction of the future metabolic state. This transient predictive burst of activity is essential for anticipatory insulin release, subsequent post-meal insulin release, post-meal glucose and lipid homeostasis, and post-meal metabolism signaling in the liver. Our results highlight that insular cortex predictive computations are essential for anticipatory physiological control and for subsequently maintaining metabolic homeostasis.",
      "author": "Litvak, E., Zhao, Z., Perets, I., Lavi, A., Rafael-Izhaki, O., Barkan-Michaeli, R., Levin, Y., Stern, S. A., Sharabi, K., Livneh, Y.",
      "published_date": "2025-12-11T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 140,
      "reading_time": 1,
      "created_at": "2025-12-12T05:24:04.250050+00:00",
      "updated_at": "2025-12-12T05:24:04.250052+00:00"
    }
  ]
}