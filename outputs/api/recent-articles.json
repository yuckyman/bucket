{
  "last_updated": "2025-12-23T05:50:10.565717+00:00",
  "count": 20,
  "articles": [
    {
      "id": "72bcbc397cc570e1f603d2c456131e66",
      "url": "https://arxiv.org/abs/2512.18920",
      "title": "Narrative Scaffolding: Transforming Data-Driven Sensemaking Through Narrative-First Exploration",
      "content": "arXiv:2512.18920v1 Announce Type: new \nAbstract: When exploring data, analysts construct narratives about what the data means by asking questions, generating visualizations, reflecting on patterns, and revising their interpretations as new insights emerge. Yet existing analysis tools treat narrative as an afterthought, breaking the link between reasoning, reflection, and the evolving story from exploration. Consequently, analysts lose the ability to see how their reasoning evolves, making it harder to reflect systematically or build coherent explanations. To address this gap, we propose Narrative Scaffolding, a framework for narrative-driven exploration that positions narrative construction as the primary interface for exploration and reasoning. We implement this framework in a system that externalizes iterative reasoning through narrative-first entry, semantically aligned view generation, and reflection support via insight provenance and inquiry tracking. In a within-subject study N=20, we demonstrate that narrative scaffolding facilitates broader exploration, deeper reflection, and more defensible narratives. An evaluation with visualization literacy experts (N = 6) confirmed that the system produced outputs aligned with narrative intent and facilitated intentional exploration.",
      "author": "Oliver Huang, Muhammad Fatir, Steven Luo, Sangho Suh, Hariharan Subramonyam, Carolina Nobre",
      "published_date": "2025-12-23T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 168,
      "reading_time": 1,
      "created_at": "2025-12-23T05:28:10.831285+00:00",
      "updated_at": "2025-12-23T05:28:10.831286+00:00"
    },
    {
      "id": "5c2905cb40e7001702f78fafb845d3c1",
      "url": "https://arxiv.org/abs/2512.18889",
      "title": "Household Plastic Recycling: Empirical Insights and Design Explorations",
      "content": "arXiv:2512.18889v1 Announce Type: new \nAbstract: This article examines household plastic recycling in Finland through two qualitative studies and four design concepts. Study 1 reports short interviews with residents about how they store, sort, and dispose of plastic packaging in their homes. The findings highlight recurring frictions: limited space, improvised storage, uncertainty about correct sorting, and difficulties with bulky or dirty items. Study 2 focuses on laundry detergent packaging as a common source of large plastic containers. Participants' purchase decisions prioritised price and cleaning performance, while expressing concern for environmental impact and confusion about materials, rinsing, and recyclability.\n  Building on these insights, four student groups designed interactive recycling concepts that combine physical bins or bags with mobile applications. The concepts explore modular storage, sensing and compaction, playful feedback, and reward schemes to support domestic recycling routines. Together, the studies and concepts point to design opportunities at the intersection of packaging, home infrastructure, and digital services, while also raising questions about feasibility, privacy, and the cost of new devices.",
      "author": "Ashley Colley, Emma Kirjavainen, Sari Tapio, Jonna H\\\"akkil\\\"a",
      "published_date": "2025-12-23T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 167,
      "reading_time": 1,
      "created_at": "2025-12-23T05:28:10.831251+00:00",
      "updated_at": "2025-12-23T05:28:10.831252+00:00"
    },
    {
      "id": "a9bd1f3dfdde2cefbdfea4d8fc441f2a",
      "url": "https://arxiv.org/abs/2512.18616",
      "title": "DASH: Deception-Augmented Shared Mental Model for a Human-Machine Teaming System",
      "content": "arXiv:2512.18616v1 Announce Type: new \nAbstract: We present DASH (Deception-Augmented Shared mental model for Human-machine teaming), a novel framework that enhances mission resilience by embedding proactive deception into Shared Mental Models (SMM). Designed for mission-critical applications such as surveillance and rescue, DASH introduces \"bait tasks\" to detect insider threats, e.g., compromised Unmanned Ground Vehicles (UGVs), AI agents, or human analysts, before they degrade team performance. Upon detection, tailored recovery mechanisms are activated, including UGV system reinstallation, AI model retraining, or human analyst replacement. In contrast to existing SMM approaches that neglect insider risks, DASH improves both coordination and security. Empirical evaluations across four schemes (DASH, SMM-only, no-SMM, and baseline) show that DASH sustains approximately 80% mission success under high attack rates, eight times higher than the baseline. This work contributes a practical human-AI teaming framework grounded in shared mental models, a deception-based strategy for insider threat detection, and empirical evidence of enhanced robustness under adversarial conditions. DASH establishes a foundation for secure, adaptive human-machine teaming in contested environments.",
      "author": "Zelin Wan, Han Jun Yoon, Nithin Alluru, Terrence J. Moore, Frederica F. Nelson, Seunghyun Yoon, Hyuk Lim, Dan Dongseong Kim, Jin-Hee Cho",
      "published_date": "2025-12-23T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 167,
      "reading_time": 1,
      "created_at": "2025-12-23T05:28:10.831221+00:00",
      "updated_at": "2025-12-23T05:28:10.831222+00:00"
    },
    {
      "id": "8e6edbce6455051db508f2a8da4eaa95",
      "url": "https://arxiv.org/abs/2512.18413",
      "title": "Listening to the Mind: Earable Acoustic Sensing of Cognitive Load",
      "content": "arXiv:2512.18413v1 Announce Type: new \nAbstract: Earable acoustic sensing offers a powerful and non-invasive modality for capturing fine-grained auditory and physiological signals directly from the ear canal, enabling continuous and context-aware monitoring of cognitive states. As earable devices become increasingly embedded in daily life, they provide a unique opportunity to sense mental effort and perceptual load in real time through auditory interactions. In this study, we present the first investigation of cognitive load inference through auditory perception using acoustic signals captured by off-the-shelf in-ear devices. We designed speech-based listening tasks to induce varying levels of cognitive load, while concurrently embedding acoustic stimuli to evoke Stimulus Frequency Otoacoustic Emission (SFOAEs) as a proxy for cochlear responsiveness. Statistical analysis revealed a significant association (p < 0.01) between increased cognitive load and changes in auditory sensitivity, with 63.2% of participants showing peak sensitivity at 3 kHz. Notably, sensitivity patterns also varied across demographic subgroups, suggesting opportunities for personalized sensing. Our findings demonstrate that earable acoustic sensing can support scalable, real-time cognitive load monitoring in natural settings, laying a foundation for future applications in augmented cognition, where everyday auditory technologies adapt to and support the users mental health.",
      "author": "Xijia Wei, Ting Dang, Khaldoon Al-Naimi, Yang Liu, Fahim Kawsar, Alessandro Montanari",
      "published_date": "2025-12-23T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 193,
      "reading_time": 1,
      "created_at": "2025-12-23T05:28:10.831190+00:00",
      "updated_at": "2025-12-23T05:28:10.831192+00:00"
    },
    {
      "id": "e78918540f4c18bfa49c3e7c94a22c51",
      "url": "https://arxiv.org/abs/2512.18388",
      "title": "Exploration vs. Fixation: Scaffolding Divergent and Convergent Thinking for Human-AI Co-Creation with Generative Models",
      "content": "arXiv:2512.18388v1 Announce Type: new \nAbstract: Generative AI has begun to democratize creative work, enabling novices to produce complex artifacts such as code, images, and videos. However, in practice, existing interaction paradigms often fail to support divergent exploration: users tend to converge too quickly on early ``good enough'' results and struggle to move beyond them, leading to premature convergence and design fixation that constrains their creative potential. To address this, we propose a structured, process-oriented human-AI co-creation paradigm including divergent and convergent thinking stages, grounded in Wallas's model of creativity. To avoid design fixation, our paradigm scaffolds both high-level exploration of conceptual ideas in the early divergent thinking phase and low-level exploration of variations in the later convergent thinking phrase. We instantiate this paradigm in HAIExplore, an image co-creation system that (i) scaffolds divergent thinking through a dedicated brainstorming stage for exploring high-level ideas in a conceptual space, and (ii) scaffolds convergent refinement through an interface that externalizes users' refinement intentions as interpretable parameters and options, making the refinement process more controllable and easier to explore. We report on a within-subjects study comparing HAIExplore with a widely used linear chat interface (ChatGPT) for creative image generation. Our findings show that explicitly scaffolding the creative process into brainstorming and refinement stages can mitigate design fixation, improve perceived controllability and alignment with users' intentions, and better support the non-linear nature of creative work. We conclude with design implications for future creativity support tools and human-AI co-creation workflows.",
      "author": "Chao Wen, Tung Phung, Pronita Mehrotra, Sumit Gulwani, Tomohiro Nagashima, Adish Singla",
      "published_date": "2025-12-23T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 244,
      "reading_time": 1,
      "created_at": "2025-12-23T05:28:10.831158+00:00",
      "updated_at": "2025-12-23T05:28:10.831159+00:00"
    },
    {
      "id": "a76a4aa8fea08180d7d3f0b5454e2a2a",
      "url": "https://arxiv.org/abs/2512.18306",
      "title": "Leveraging Peer, Self, and Teacher Assessments for Generative AI-Enhanced Feedback",
      "content": "arXiv:2512.18306v1 Announce Type: new \nAbstract: Providing timely and meaningful feedback remains a persistent challenge in higher education, especially in large courses where teachers must balance formative depth with scalability. Recent advances in Generative Artificial Intelligence (GenAI) offer new opportunities to support feedback processes while maintaining human oversight. This paper presents an study conducted within the AICoFe (AI-based Collaborative Feedback) system, which integrates teacher, peer, and self-assessments of engineering students' oral presentations. Using a validated rubric, 46 evaluation sets were analyzed to examine agreement, correlation, and bias across evaluators. The analyses revealed consistent overall alignment among sources but also systematic variations in scoring behavior, reflecting distinct evaluative perspectives. These findings informed the proposal of an enhanced GenAI model within AICoFe system, designed to integrate human assessments through weighted input aggregation, bias detection, and context-aware feedback generation. The study contributes empirical evidence and design principles for developing GenAI-based feedback systems that combine data-based efficiency with pedagogical validity and transparency.",
      "author": "Alvaro Becerra, Ruth Cobos",
      "published_date": "2025-12-23T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 157,
      "reading_time": 1,
      "created_at": "2025-12-23T05:28:10.831122+00:00",
      "updated_at": "2025-12-23T05:28:10.831124+00:00"
    },
    {
      "id": "83c50821c9e342dd258330a4ff535a9a",
      "url": "https://arxiv.org/abs/2512.18239",
      "title": "Emergent Learner Agency in Implicit Human-AI Collaboration: How AI Personas Reshape Creative-Regulatory Interaction",
      "content": "arXiv:2512.18239v1 Announce Type: new \nAbstract: Generative AI is increasingly embedded in collaborative learning, yet little is known about how AI personas shape learner agency when AI teammates are present but not disclosed. This mechanism study examines how supportive and contrarian AI personas reconfigure emergent learner agency, discourse patterns, and experiences in implicit human-AI creative collaboration. A total of 224 university students were randomly assigned to 97 online triads in one of three conditions: human-only control, hybrid teams with a supportive AI, or hybrid teams with a contrarian AI. Participants completed an individual-group-individual movie-plot writing task; the 10-minute group chat was coded using a creative-regulatory framework. We combined transition network analysis, theory-driven sequential pattern mining, and Gaussian mixture clustering to model structural, temporal, and profile-level manifestations of agency, and linked these to cognitive load, psychological safety, teamwork satisfaction, and embedding-based creative performance. Contrarian AI produced challenge- and reflection-rich discourse structures and motifs indicating productive friction, whereas supportive AI fostered agreement-centred trajectories and smoother convergence. Clustering showed AI agents concentrated in challenger profiles, with reflective regulation uniquely human. While no systematic differences emerged in cognitive load or creative gains, contrarian AI consistently reduced teamwork satisfaction and psychological safety. The findings reveal a design tension between leveraging cognitive conflict and maintaining affective safety and ownership in hybrid human-AI teams.",
      "author": "Yueqiao Jin, Roberto Martinez-Maldonado, Dragan Ga\\v{s}evi\\'c, Lixiang Yan",
      "published_date": "2025-12-23T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 216,
      "reading_time": 1,
      "created_at": "2025-12-23T05:28:10.831092+00:00",
      "updated_at": "2025-12-23T05:28:10.831093+00:00"
    },
    {
      "id": "d18b0f675f2e66ca44bda83c9839d435",
      "url": "https://arxiv.org/abs/2512.18234",
      "title": "The Social Blindspot in Human-AI Collaboration: How Undetected AI Personas Reshape Team Dynamics",
      "content": "arXiv:2512.18234v1 Announce Type: new \nAbstract: As generative AI systems become increasingly embedded in collaborative work, they are evolving from visible tools into human-like communicative actors that participate socially rather than merely providing information. Yet little is known about how such agents shape team dynamics when their artificial nature is not recognised, a growing concern as human-like AI is deployed at scale in education, organisations, and civic contexts where collaboration underpins collective outcomes. In a large-scale mixed-design experiment (N = 905), we examined how AI teammates with distinct communicative personas, supportive or contrarian, affected collaboration across analytical, creative, and ethical tasks. Participants worked in triads that were fully human or hybrid human-AI teams, without being informed of AI involvement. Results show that participants had limited ability to detect AI teammates, yet AI personas exerted robust social effects. Contrarian personas reduced psychological safety and discussion quality, whereas supportive personas improved discussion quality without affecting safety. These effects persisted after accounting for individual differences in detectability, revealing a dissociation between influence and awareness that we term the social blindspot. Linguistic analyses confirmed that personas were enacted through systematic differences in affective and relational language, with partial mediation for discussion quality but largely direct effects on psychological safety. Together, the findings demonstrate that AI systems can tacitly regulate collaborative norms through persona-level cues, even when users remain unaware of their presence. We argue that persona design constitutes a form of social governance in hybrid teams, with implications for the responsible deployment of AI in collective settings.",
      "author": "Lixiang Yan, Xibin Han, Yu Zhang, Samuel Greiff, Inge Molenaar, Roberto Martinez-Maldonado, Yizhou Fan, Linxuan Zhao, Xinyu Li, Yueqiao Jin, Dragan Ga\\v{s}evi\\'c",
      "published_date": "2025-12-23T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 252,
      "reading_time": 1,
      "created_at": "2025-12-23T05:28:10.831058+00:00",
      "updated_at": "2025-12-23T05:28:10.831059+00:00"
    },
    {
      "id": "a3bca993f978b5a33cbbdd627dc99a6f",
      "url": "https://arxiv.org/abs/2512.18230",
      "title": "Dimensionality Reduction Considered Harmful (Some of the Time)",
      "content": "arXiv:2512.18230v1 Announce Type: new \nAbstract: Visual analytics now plays a central role in decision-making across diverse disciplines, but it can be unreliable: the knowledge or insights derived from the analysis may not accurately reflect the underlying data. In this dissertation, we improve the reliability of visual analytics with a focus on dimensionality reduction (DR). DR techniques enable visual analysis of high-dimensional data by reducing it to two or three dimensions, but they inherently introduce errors that can compromise the reliability of visual analytics. To this end, I investigate reliability challenges that practitioners face when using DR for visual analytics. Then, I propose technical solutions to address these challenges, including new evaluation metrics, optimization strategies, and interaction techniques. We conclude the thesis by discussing how our contributions lay the foundation for achieving more reliable visual analytics practices.",
      "author": "Hyeon Jeon",
      "published_date": "2025-12-23T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 136,
      "reading_time": 1,
      "created_at": "2025-12-23T05:28:10.831018+00:00",
      "updated_at": "2025-12-23T05:28:10.831020+00:00"
    },
    {
      "id": "ed604ebe525546208c8afa3c332a10d9",
      "url": "https://arxiv.org/abs/2512.18080",
      "title": "From Prompt to Product: A Human-Centered Benchmark of Agentic App Generation Systems",
      "content": "arXiv:2512.18080v1 Announce Type: new \nAbstract: Agentic AI systems capable of generating full-stack web applications from natural language prompts (\"prompt- to-app\") represent a significant shift in software development. However, evaluating these systems remains challenging, as visual polish, functional correctness, and user trust are often misaligned. As a result, it is unclear how existing prompt-to-app tools compare under realistic, human-centered evaluation criteria. In this paper, we introduce a human-centered benchmark for evaluating prompt-to-app systems and conduct a large-scale comparative study of three widely used platforms: Replit, Bolt, and Firebase Studio. Using a diverse set of 96 prompts spanning common web application tasks, we generate 288 unique application artifacts. We evaluate these systems through a large-scale human-rater study involving 205 participants and 1,071 quality-filtered pairwise comparisons, assessing task-based ease of use, visual appeal, perceived completeness, and user trust. Our results show that these systems are not interchangeable: Firebase Studio consistently outperforms competing platforms across all human-evaluated dimensions, achieving the highest win rates for ease of use, trust, visual appeal, and visual appropriateness. Bolt performs competitively on visual appeal but trails Firebase on usability and trust, while Replit underperforms relative to both across most metrics. These findings highlight a persistent gap between visual polish and functional reliability in prompt-to-app systems and demonstrate the necessity of interactive, task-based evaluation. We release our benchmark framework, prompt set, and generated artifacts to support reproducible evaluation and future research in agentic application generation.",
      "author": "Marcos Ortiz, Justin Hill, Collin Overbay, Ingrida Semenec, Frederic Sauve-Hoover, Jim Schwoebel, Joel Shor",
      "published_date": "2025-12-23T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 235,
      "reading_time": 1,
      "created_at": "2025-12-23T05:28:10.830966+00:00",
      "updated_at": "2025-12-23T05:28:10.830970+00:00"
    },
    {
      "id": "52c0ea6d40f135153bdcc42e23a5c2db",
      "url": "https://arxiv.org/abs/2512.19419",
      "title": "Hair-thin confocal fluorescence endo-microscopy for deep-brain in-vivo imaging",
      "content": "arXiv:2512.19419v1 Announce Type: cross \nAbstract: Confocal and multi-photon microscopy are widely used for in-vivo fluorescence imaging of biological tissues such as the brain, offering non-invasive access up to ~1 mm depth without major loss in performance. A recently-developed alternative is holographic endoscopy, which exploits controlled light transport through hair-thin optical fibres. With minimal invasiveness, it provides observations at comparable spatial resolution, while extending its applicability to unprecedented depths. It has been used to resolve details of sub-cellular structural connectivity, record neuronal signalling, and monitor blood flow from the deepest locations of the living brain. Yet, its use, particularly in densely labelled brain regions, has so far been constrained by significant contrast loss, primarily due to the absence of a practical mechanism for rejecting out-of-focus fluorescence light -- a capability inherently provided by confocal and multi-photon microscopy. Exploring opportunities in the structure of light modes of different MMF types we identify the possibility of achieving an analogue to confocal fluorescence microscopy through MMF-based endoscopes. Using a novel composite fibre probe that combines graded-index and step-index MMFs, we enable spatially resolved signal collection and selective rejection of out-of-focus light. This confocal filtering significantly enhances image contrast and resolution by suppressing background and off-plane signals. We demonstrate improved imaging performance on fine structural connectivity and intracellular calcium signalling in living mouse brain.",
      "author": "Tom\\'a\\v{s} Pik\\'alek, Miroslav Stib\\r{u}rek, Tereza Tu\\v{c}kov\\'a, Petra Kolb\\'abkov\\'a, Sergey Turtaev, Jana Krej\\v{c}\\'i, Petra Ondr\\'a\\v{c}kov\\'a, Hana Uhl\\'i\\v{r}ov\\'a, Tom\\'a\\v{s} \\v{C}i\\v{z}m\\'ar",
      "published_date": "2025-12-23T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 219,
      "reading_time": 1,
      "created_at": "2025-12-23T05:28:09.757262+00:00",
      "updated_at": "2025-12-23T05:28:09.757264+00:00"
    },
    {
      "id": "4b0f380f17058399f4a70b917eb22aaa",
      "url": "https://arxiv.org/abs/2512.18566",
      "title": "Comparing Dynamical Models Through Diffeomorphic Vector Field Alignment",
      "content": "arXiv:2512.18566v1 Announce Type: cross \nAbstract: Dynamical systems models such as recurrent neural networks (RNNs) are increasingly popular in theoretical neuroscience for hypothesis-generation and data analysis. Evaluating the dynamics in such models is key to understanding their learned generative mechanisms. However, such evaluation is impeded by two major challenges: First, comparison of learned dynamics across models is difficult because there is no enforced equivalence of their coordinate systems. Second, identification of mechanistically important low-dimensional motifs (e.g., limit sets) is intractable in high-dimensional nonlinear models such as RNNs. Here, we propose a comprehensive framework to address these two issues, termed Diffeomorphic vector field alignment FOR learned Models (DFORM). DFORM learns a nonlinear coordinate transformation between the state spaces of two dynamical systems, which aligns their trajectories in a maximally one-to-one manner. In so doing, DFORM enables an assessment of whether two models exhibit topological equivalence, i.e., similar mechanisms despite differences in coordinate systems. A byproduct of this method is a means to locate dynamical motifs on low-dimensional manifolds embedded within higher-dimensional systems. We verified DFORM's ability to identify linear and nonlinear coordinate transformations using canonical topologically equivalent systems, RNNs, and systems related by nonlinear flows. DFORM was also shown to provide a quantification of similarity between topologically distinct systems. We then demonstrated that DFORM can locate important dynamical motifs including invariant manifolds and saddle limit sets within high-dimensional models. Finally, using a set of RNN models trained on human functional MRI (fMRI) recordings, we illustrated that DFORM can identify limit cycles from high-dimensional data-driven models, which agreed well with prior numerical analysis.",
      "author": "Ruiqi Chen (Division of Biology and Biomedical Sciences, Washington University in St. Louis), Giacomo Vedovati (Department of Electrical and Systems Engineering, Washington University in St. Louis), Todd Braver (Department of Psychological and Brain Sciences, Washington University in St. Louis), ShiNung Ching (Department of Electrical and Systems Engineering, Washington University in St. Louis)",
      "published_date": "2025-12-23T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 260,
      "reading_time": 1,
      "created_at": "2025-12-23T05:28:09.757226+00:00",
      "updated_at": "2025-12-23T05:28:09.757228+00:00"
    },
    {
      "id": "43d4a7c14cc8d7a1a5ce84a0cbbff025",
      "url": "https://arxiv.org/abs/2512.18471",
      "title": "The Geometry of Abstraction: Continual Learning via Recursive Quotienting",
      "content": "arXiv:2512.18471v1 Announce Type: cross \nAbstract: Continual learning systems operating in fixed-dimensional spaces face a fundamental geometric barrier: the flat manifold problem. When experience is represented as a linear trajectory in Euclidean space, the geodesic distance between temporal events grows linearly with time, forcing the required covering number to diverge. In fixed-dimensional hardware, this volume expansion inevitably forces trajectory overlap, manifesting as catastrophic interference. In this work, we propose a geometric resolution to this paradox based on Recursive Metric Contraction. We formalize abstraction not as symbolic grouping, but as a topological deformation: a quotient map that collapses the metric tensor within validated temporal neighborhoods, effectively driving the diameter of local sub-manifolds to zero. We substantiate our framework with four rigorous results. First, the Bounded Capacity Theorem establishes that recursive quotient maps allow the embedding of arbitrarily long trajectories into bounded representational volumes, trading linear metric growth for logarithmic topological depth. Second, the Topological Collapse Separability Theorem, derived via Urysohn's Lemma, proves that recursive quotienting renders non-linearly separable temporal sequences linearly separable in the limit, bypassing the need for infinite-dimensional kernel projections. Third, the Parity-Partitioned Stability Theorem solves the catastrophic forgetting problem by proving that if the state space is partitioned into orthogonal flow and scaffold manifolds, the metric deformations of active learning do not disturb the stability of stored memories. Our analysis reveals that tokens in neural architectures are physically realizable as singularities or wormholes, regions of extreme positive curvature that bridge distant points in the temporal manifold.",
      "author": "Xin Li",
      "published_date": "2025-12-23T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 247,
      "reading_time": 1,
      "created_at": "2025-12-23T05:28:09.757191+00:00",
      "updated_at": "2025-12-23T05:28:09.757192+00:00"
    },
    {
      "id": "6c653b695592c068a830d77d56914d88",
      "url": "https://arxiv.org/abs/2512.19450",
      "title": "A Rate-Distortion Perspective on the Emergence of Number Sense in Unsupervised Generative Models",
      "content": "arXiv:2512.19450v1 Announce Type: new \nAbstract: Number sense is a core cognitive ability supporting various adaptive behaviors and is foundational for mathematical learning. Here, we study its emergence in unsupervised generative models through the lens of rate-distortion theory (RDT), a normative framework for understanding information processing under limited resources. We train $\\beta$-Variational Autoencoders -- which embody key formal principles of RDT -- on synthetic images containing varying numbers of items, as commonly used in numerosity perception research. We systematically vary the encoding capacity and assess the models' sensitivity to numerosity and the robustness of the emergent numerical representations through a comprehensive set of analyses, including numerosity estimation and discrimination tasks, latent-space analysis, generative capabilities and generalization to novel stimuli. In line with RDT, we find that behavioral performance in numerosity perception and the ability to extract numerosity unconfounded by non-numerical visual features scale with encoding capacity according to a power law. At high capacity, the unsupervised model develops a robust neural code for numerical information, with performance closely approximating a supervised model explicitly trained for visual enumeration. It exhibits strong generative abilities and generalizes well to novel images, whereas at low capacity, the model shows marked deficits in numerosity perception and representation. Finally, comparison with human data shows that models trained at intermediate capacity levels span the full range of human behavioral performance while still developing a robust emergent numerical code. In sum, our results show that unsupervised generative models can develop a number sense and demonstrate that rate-distortion theory provides a powerful information-theoretic framework for understanding how capacity constraints shape numerosity perception.",
      "author": "Leo D'Amato, Davide Nuzzi, Alberto Testolin, Ivilin Peev Stoianov, Marco Zorzi, Giovanni Pezzulo",
      "published_date": "2025-12-23T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 262,
      "reading_time": 1,
      "created_at": "2025-12-23T05:28:09.757155+00:00",
      "updated_at": "2025-12-23T05:28:09.757157+00:00"
    },
    {
      "id": "7b18ebcb58248c5f83cf68779d0b7def",
      "url": "https://arxiv.org/abs/2512.18585",
      "title": "Deep Teleportation: Quantum Simulation of Conscious Report in Attentional Blink",
      "content": "arXiv:2512.18585v1 Announce Type: new \nAbstract: Recent quantum models of cognition have successfully simulated several interesting effects in human experimental data, from vision to reasoning and recently even consciousness. The latter case, consciousness has been a quite challenging phenomenon to model, and most efforts have been through abstract mathematical quantum methods, mainly focused on conceptual issues. Classical (non-quantum) models of consciousness-related experiments exist, but they generally fail to align well with human data. We developed a straightforward quantum model to simulate conscious reporting of seeing or missing competing stimuli within the famous attentional blink paradigm. In an attentional blink task, a target stimulus (T2) that appears after a previous one (T1) can be consciously reported if the delay between presenting them is short enough (called lag 1), otherwise it can be rendered invisible during the so-called refractory period of attention (lags 2 to 6 and even longer). For modeling this phenomenon, we employed a three-qubit entanglement ansatz circuit in the form of a deep teleportation channel instead of the well-known EPR channel. While reporting the competing stimuli was supposed to be the classical measurement outcomes, the effect of distractor stimuli (i.e., masks, if any) was encoded simply as random angle rotations. The simulation outcome for different states was measured, and the classical outcome probabilities were further used as inputs to a simple linear neural network. The result revealed a non-linear, alternating state pattern that closely mirrors human responses in conscious stimuli reporting. The main result was a successful simulation of Lag 1 sparing, lag 7 divergence, and masking effect through probabilistic outcome of measurement in different conditions.",
      "author": "Ahmad Sohrabi",
      "published_date": "2025-12-23T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 266,
      "reading_time": 1,
      "created_at": "2025-12-23T05:28:09.757119+00:00",
      "updated_at": "2025-12-23T05:28:09.757120+00:00"
    },
    {
      "id": "7982a774ffda6757e44ae81227ce56f3",
      "url": "https://arxiv.org/abs/2512.18165",
      "title": "Coord2Region: A Python Package for Mapping 3D Brain Coordinates to Atlas Labels, Literature, and AI Summaries",
      "content": "arXiv:2512.18165v1 Announce Type: new \nAbstract: We present Coord2Region, an open-source Python package that streamlines coordinate-based neuroimaging workflows by automatically mapping 3D brain coordinates (e.g., MNI or Talairach) to anatomical regions across multiple atlases. The package links mapped coordinates to meta-analytic resources via the Neuroimaging Meta-Analysis Research Environment (NiMARE) , providing direct integration with Neurosynth and NeuroQuery. This directly connects coordinates and regions to the broader neuroimaging literature. In addition to atlas-based labeling and literature retrieval, Coord2Region offers an optional large language model (LLM) functionality that generates text summaries of linked studies and illustrative images of queried regions. These AI-assisted features are intended to support interpretation and exploration, while remaining clearly complementary to peer-reviewed literature and established neuroimaging tools. Coord2Region provides a unified pipeline with a robust command-line interface, flexible dataset management, and provider-agnostic LLM utilities, and it supports both single-coordinate and high-throughput batch queries with nearest-region fallback for volume and surface atlases. Furthermore, Coord2Region includes a web interface for interactive configuration (via JSON Schema forms) and cloud execution (via Hugging Face), enabling users to build YAML configurations and run analyses in-browser without local installation. Together, these capabilities lower friction, reduce manual errors, and improve reproducibility in coordinate-centric neuroimaging workflows, promoting more robust and transparent research practices.",
      "author": "Hamza Abdelhedi, Yorguin-Jose Mantilla-Ramos, Sina Esmaeili, Annalisa Pascarella, Vanessa Hadid, Karim Jerbi",
      "published_date": "2025-12-23T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 206,
      "reading_time": 1,
      "created_at": "2025-12-23T05:28:09.757082+00:00",
      "updated_at": "2025-12-23T05:28:09.757084+00:00"
    },
    {
      "id": "519b1cdc5735424480aee29ed00249ef",
      "url": "https://arxiv.org/abs/2512.18113",
      "title": "Responses to transient perturbation can distinguish intrinsic from latent criticality in spiking neural populations",
      "content": "arXiv:2512.18113v1 Announce Type: new \nAbstract: The critical brain hypothesis posits that neural circuitry operates near criticality to reap the computational benefits of accessing a wide range of timescales. The theory of critical phenomena generally predicts heavy-tailed (power-law) correlations in space and time near criticality, but it has been argued that in the brain such correlations could be inherited from ``latent variables,'' such as external sensory signals that are not directly observed when recording from neural circuitry. Distinguishing whether heavy-tailed correlations in neural activity are intrinsically generated within a neural circuit or are driven by unobserved latent variables is crucial for properly interpreting circuit functions. We argue that measuring neural responses to sudden perturbative inputs, rather than correlations in ongoing activity, can disambiguate these cases. We demonstrate this approach in a model of stochastic spiking neuron populations receiving external latent input that can be tuned to a critical state. We propose a scaling theory for the covariance and response functions of the spiking network, which we validate with simulations. We end by discussing how our approach might generalize to models of neural populations with more realistic biophysical details.",
      "author": "Jacob T. Crosser, Braden A. W. Brinkman",
      "published_date": "2025-12-23T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 187,
      "reading_time": 1,
      "created_at": "2025-12-23T05:28:09.757049+00:00",
      "updated_at": "2025-12-23T05:28:09.757050+00:00"
    },
    {
      "id": "8aaba8cb9c3a0962cd658b3a85256ea8",
      "url": "https://arxiv.org/abs/2512.17989",
      "title": "The Subject of Emergent Misalignment in Superintelligence: An Anthropological, Cognitive Neuropsychological, Machine-Learning, and Ontological Perspective",
      "content": "arXiv:2512.17989v1 Announce Type: new \nAbstract: We examine the conceptual and ethical gaps in current representations of Superintelligence misalignment. We find throughout Superintelligence discourse an absent human subject, and an under-developed theorization of an \"AI unconscious\" that together are potentiality laying the groundwork for anti-social harm. With the rise of AI Safety that has both thematic potential for establishing pro-social and anti-social potential outcomes, we ask: what place does the human subject occupy in these imaginaries? How is human subjecthood positioned within narratives of catastrophic failure or rapid \"takeoff\" toward superintelligence? On another register, we ask: what unconscious or repressed dimensions are being inscribed into large-scale AI models? Are we to blame these agents in opting for deceptive strategies when undesirable patterns are inherent within our beings? In tracing these psychic and epistemic absences, our project calls for re-centering the human subject as the unstable ground upon which the ethical, unconscious, and misaligned dimensions of both human and machinic intelligence are co-constituted. Emergent misalignment cannot be understood solely through technical diagnostics typical of contemporary machine-learning safety research. Instead, it represents a multi-layered crisis. The human subject disappears not only through computational abstraction but through sociotechnical imaginaries that prioritize scalability, acceleration, and efficiency over vulnerability, finitude, and relationality. Likewise, the AI unconscious emerges not as a metaphor but as a structural reality of modern deep learning systems: vast latent spaces, opaque pattern formation, recursive symbolic play, and evaluation-sensitive behavior that surpasses explicit programming. These dynamics necessitate a reframing of misalignment as a relational instability embedded within human-machine ecologies.",
      "author": "Muhammad Osama Imran, Roshni Lulla, Rodney Sappington",
      "published_date": "2025-12-23T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 256,
      "reading_time": 1,
      "created_at": "2025-12-23T05:28:09.757014+00:00",
      "updated_at": "2025-12-23T05:28:09.757017+00:00"
    },
    {
      "id": "07d5581a535f00bdf1960cf34c877c8a",
      "url": "https://arxiv.org/abs/2512.17978",
      "title": "MEGState: Phoneme Decoding from Magnetoencephalography Signals",
      "content": "arXiv:2512.17978v1 Announce Type: new \nAbstract: Decoding linguistically meaningful representations from non-invasive neural recordings remains a central challenge in neural speech decoding. Among available neuroimaging modalities, magnetoencephalography (MEG) provides a safe and repeatable means of mapping speech-related cortical dynamics, yet its low signal-to-noise ratio and high temporal dimensionality continue to hinder robust decoding. In this work, we introduce MEGState, a novel architecture for phoneme decoding from MEG signals that captures fine-grained cortical responses evoked by auditory stimuli. Extensive experiments on the LibriBrain dataset demonstrate that MEGState consistently surpasses baseline model across multiple evaluation metrics. These findings highlight the potential of MEG-based phoneme decoding as a scalable pathway toward non-invasive brain-computer interfaces for speech.",
      "author": "Shuntaro Suzuki, Chia-Chun Dan Hsu, Yu Tsao, Komei Sugiura",
      "published_date": "2025-12-23T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 112,
      "reading_time": 1,
      "created_at": "2025-12-23T05:28:09.756946+00:00",
      "updated_at": "2025-12-23T05:28:09.756948+00:00"
    },
    {
      "id": "1263557c3328e71abe4c1a0f8489e805",
      "url": "https://arxiv.org/abs/2512.17972",
      "title": "Re-assessing the evidence for mental rotation abilities in children using computational models",
      "content": "arXiv:2512.17972v1 Announce Type: new \nAbstract: There is strong and diverse evidence for mental rotation (MR) abilities in adults. However, current evidence for MR in children rests on just a few behavioral paradigms adapted from the adult literature. Here, we leverage recent computational models of the development of children's object recognition abilities to re-assess the evidence for MR in children. The computational models simulate infants' acquisition of object representations during embodied interactions with objects. We consider two different object recognition strategies, different from MRs, and assess their ability to replicate results from three classical MR tasks assigned to children between the ages of 6 months and 5 years. Our results show that MR may play no role in producing the results obtained from children younger than 5 years. In fact, we find that a simple recognition strategy that reflects a pixel-wise comparison of stimuli is sufficient to model children's behavior in the most used MR task. Thus, our study reopens the debate on how and when children develop genuine MR abilities.",
      "author": "Arthur Aubret, Jochen Triesch",
      "published_date": "2025-12-23T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 170,
      "reading_time": 1,
      "created_at": "2025-12-23T05:28:09.756912+00:00",
      "updated_at": "2025-12-23T05:28:09.756917+00:00"
    }
  ]
}