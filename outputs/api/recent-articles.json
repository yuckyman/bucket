{
  "last_updated": "2025-09-18T04:24:17.351256+00:00",
  "count": 20,
  "articles": [
    {
      "id": "ad1925564c97f30cab5b55e76f20793b",
      "url": "https://www.embs.org/blog-post/regional-shifts-and-patterns/",
      "title": "Bridging Biotech: Regional shifts and patterns",
      "content": "<p>The post <a href=\"https://www.embs.org/blog-post/regional-shifts-and-patterns/\">Bridging Biotech: Regional shifts and patterns</a> appeared first on <a href=\"https://www.embs.org\">IEEE EMBS</a>.</p>",
      "author": "dziura",
      "published_date": "2025-02-05T15:45:50+00:00",
      "source": "Embs",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 15,
      "reading_time": 1,
      "created_at": "2025-09-18T04:23:59.665428+00:00",
      "updated_at": "2025-09-18T04:23:59.665430+00:00"
    },
    {
      "id": "6b5f32570094f1cedcde640a7566d20a",
      "url": "https://www.embs.org/blog-post/welcoming-dr-ana-kyani-as-wibme-chair-ieee-embs/",
      "title": "Welcoming Dr. Ana Kyani as the New Women in Biomedical Engineering Chair for IEEE EMBS",
      "content": "<p>The post <a href=\"https://www.embs.org/blog-post/welcoming-dr-ana-kyani-as-wibme-chair-ieee-embs/\">Welcoming Dr. Ana Kyani as the New Women in Biomedical Engineering Chair for IEEE EMBS</a> appeared first on <a href=\"https://www.embs.org\">IEEE EMBS</a>.</p>",
      "author": "Nancy Zimmerman",
      "published_date": "2025-03-27T17:10:33+00:00",
      "source": "Embs",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 24,
      "reading_time": 1,
      "created_at": "2025-09-18T04:23:59.665410+00:00",
      "updated_at": "2025-09-18T04:23:59.665411+00:00"
    },
    {
      "id": "a6aabb5bbf80a68ab04340d8ad0ea080",
      "url": "https://arxiv.org/abs/2509.13679",
      "title": "From Prompts to Reflection: Designing Reflective Play for GenAI Literacy",
      "content": "arXiv:2509.13679v1 Announce Type: new \nAbstract: The wide adoption of Generative AI (GenAI) in everyday life highlights the need for greater literacy around its evolving capabilities, biases, and limitations. While many AI literacy efforts focus on children through game-based learning, few interventions support adults in developing a nuanced, reflective understanding of GenAI via playful exploration. To address the gap, we introduce ImaginAItion, a multiplayer party game inspired by Drawful and grounded in the reflective play framework to surface model defaults, biases, and human-AI perception gaps through prompting and discussion. From ten sessions (n=30), we show how gameplay helped adults recognize systematic biases in GenAI, reflect on humans and AI interpretation differences, and adapt their prompting strategies. We also found that group dynamics and composition, such as expertise and diversity, amplified or muted reflection. Our work provides a starting point to scale critical GenAI literacy through playful, social interventions resilient to rapidly evolving technologies.",
      "author": "Qianou Ma, Megan Chai, Yike Tan, Jihun Choi, Jini Kim, Erik Harpstead, Geoff Kauffman, Tongshuang Wu",
      "published_date": "2025-09-18T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 152,
      "reading_time": 1,
      "created_at": "2025-09-18T04:23:58.232618+00:00",
      "updated_at": "2025-09-18T04:23:58.232619+00:00"
    },
    {
      "id": "538aaf7a395f2265f32462170f33ca06",
      "url": "https://arxiv.org/abs/2509.13671",
      "title": "I, Robot? Socio-Technical Implications of Ultra-Personalized AI-Powered AAC; an Autoethnographic Account",
      "content": "arXiv:2509.13671v1 Announce Type: new \nAbstract: Generic AI auto-complete for message composition often fails to capture the nuance of personal identity, requiring significant editing. While harmless in low-stakes settings, for users of Augmentative and Alternative Communication (AAC) devices, who rely on such systems for everyday communication, this editing burden is particularly acute. Intuitively, the need for edits would be lower if language models were personalized to the communication of the specific user. While technically feasible, such personalization raises socio-technical questions: what are the implications of logging one's own conversations, and how does personalization affect privacy, authorship, and control? We explore these questions through an autoethnographic study in three phases: (1) seven months of collecting all the lead author's AAC communication data, (2) fine-tuning a model on this dataset, and (3) three months of daily use of personalized AI suggestions. We reflect on these phases through continuous diary entries and interaction logs. Our findings highlight the value of personalization as well as implications on privacy, authorship, and blurring the boundaries of self-expression.",
      "author": "Tobias Weinberg, Ricardo E. Gonzalez Penuela, Stephanie Valencia, Thijs Roumen",
      "published_date": "2025-09-18T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 170,
      "reading_time": 1,
      "created_at": "2025-09-18T04:23:58.232587+00:00",
      "updated_at": "2025-09-18T04:23:58.232588+00:00"
    },
    {
      "id": "5dbcd493c8192982d2a950e0b824ada9",
      "url": "https://arxiv.org/abs/2509.13646",
      "title": "Vistoria: A Multimodal System to Support Fictional Story Writing through Instrumental Text-Image Co-Editing",
      "content": "arXiv:2509.13646v1 Announce Type: new \nAbstract: Humans think visually-we remember in images, dream in pictures, and use visual metaphors to communicate. Yet, most creative writing tools remain text-centric, limiting how authors plan and translate ideas. We present Vistoria, a system for synchronized text-image co-editing in fictional story writing that treats visuals and text as coequal narrative materials. A formative Wizard-of-Oz co-design study with 10 story writers revealed how sketches, images, and annotations serve as essential instruments for ideation and organization. Drawing on theories of Instrumental Interaction and Structural Mapping, Vistoria introduces multimodal operations-lasso, collage, filters, and perspective shifts that enable seamless narrative exploration across modalities. A controlled study with 12 participants shows that co-editing enhances expressiveness, immersion, and collaboration, enabling writers to explore divergent directions, embrace serendipitous randomness, and trace evolving storylines. While multimodality increased cognitive demand, participants reported stronger senses of authorship and agency. These findings demonstrate how multimodal co-editing expands creative potential by balancing abstraction and concreteness in narrative development.",
      "author": "Kexue Fu, Jingfei Huang, Long Ling, Sumin Hong, Yihang Zuo, Ray LC, Toby Jia-jun Li",
      "published_date": "2025-09-18T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 161,
      "reading_time": 1,
      "created_at": "2025-09-18T04:23:58.232556+00:00",
      "updated_at": "2025-09-18T04:23:58.232558+00:00"
    },
    {
      "id": "8dbac422a8f6e126525f6bdf031c93be",
      "url": "https://arxiv.org/abs/2509.13532",
      "title": "Py maidr: Bridging Visual and Non-Visual Data Experiences Through a Unified Python Framework",
      "content": "arXiv:2509.13532v1 Announce Type: new \nAbstract: Although recent efforts have developed accessible data visualization tools for blind and low-vision (BLV) users, most follow a \"design for them\" approach that creates an unintentional divide between sighted creators and BLV consumers. This unidirectional paradigm perpetuates a power dynamic where sighted creators produce non-visual content boundaries for BLV consumers to access. This paper proposes a bidirectional approach, \"design for us,\" where both sighted and BLV collaborators can employ the same tool to create, interpret, and communicate data visualizations for each other. We introduce Py maidr, a Python package that seamlessly encodes multimodal (e.g., tactile, auditory, conversational) data representations into visual plots generated by Matplotlib and Seaborn. By simply importing the maidr package and invoking the maidr.show() method, users can generate accessible plots with minimal changes to their existing codebase regardless of their visual dis/abilities. Our technical case studies demonstrate how this tool is scalable and can be integrated into interactive computing (e.g., Jupyter Notebook, Google Colab), reproducible and literate programming (e.g., Quarto), and reactive dashboards (e.g., Shiny, Streamlit). Our performance benchmarks demonstrate that Py maidr introduces minimal and consistent overhead during the rendering and export of plots against Matplotlib and Seaborn baselines. This work significantly contributes to narrowing the accessibility gap in data visualization by providing a unified framework that fosters collaboration and communication between sighted and BLV individuals.",
      "author": "JooYoung Seo, Saairam Venkatesh, Daksh Pokar, Sanchita Kamath, Krishna Anandan Ganesan",
      "published_date": "2025-09-18T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 225,
      "reading_time": 1,
      "created_at": "2025-09-18T04:23:58.232526+00:00",
      "updated_at": "2025-09-18T04:23:58.232528+00:00"
    },
    {
      "id": "8e8b294da21cd1fcdb385d12aa776b8e",
      "url": "https://arxiv.org/abs/2509.13468",
      "title": "AR-TMT: Investigating the Impact of Distraction Types on Attention and Behavior in AR-based Trail Making Test",
      "content": "arXiv:2509.13468v1 Announce Type: new \nAbstract: Despite the growing use of AR in safety-critical domains, the field lacks a systematic understanding of how different types of distraction affect user behavior in AR environments. To address this gap, we present AR-TMT, an AR adaptation of the Trail Making Test that spatially renders targets for sequential selection on the Magic Leap 2. We implemented distractions in three categories: top-down, bottom-up, and spatial distraction based on Wolfe's Guided Search model, and captured performance, gaze, motor behavior, and subjective load measures to analyze user attention and behavior. A user study with 34 participants revealed that top-down distraction degraded performance through semantic interference, while bottom-up distraction disrupted initial attentional engagement. Spatial distraction destabilized gaze behavior, leading to more scattered and less structured visual scanning patterns. We also found that performance was correlated with attention control ($R^2 = .20$--$.35$) under object-based distraction conditions, where distractors possessed task-relevant features. The study offers insights into distraction mechanisms and their impact on users, providing opportunities for generalization to ecologically relevant AR tasks while underscoring the need to address the unique demands of AR environments.",
      "author": "Sihun Baek, Zhehan Qu, Maria Gorlatova",
      "published_date": "2025-09-18T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 184,
      "reading_time": 1,
      "created_at": "2025-09-18T04:23:58.232491+00:00",
      "updated_at": "2025-09-18T04:23:58.232493+00:00"
    },
    {
      "id": "68b040b7e97875a90eccb0698214fc93",
      "url": "https://arxiv.org/abs/2509.13466",
      "title": "Do We Need Subsidiarity in Software?",
      "content": "arXiv:2509.13466v1 Announce Type: new \nAbstract: Subsidiarity is a principle of social organization that promotes human dignity and resists over-centralization by balancing personal autonomy with intervention from higher authorities only when necessary. Thus it is a relevant, but not previously explored, critical lens for discerning the tradeoffs between complete user control of software and surrendering control to \"big tech\" for convenience, as is common in surveillance capitalism. Our study explores data privacy through the lens of subsidiarity: we employ a multi-method approach of data flow monitoring and user interviews to determine the level of control different everyday technologies currently operate at, and the level of control everyday computer users think is necessary. We found that chat platforms like Slack and Discord violate subsidiarity the most. Our work provides insight into when users are willing to surrender privacy for convenience and demonstrates how subsidiarity can inform designs that promote human flourishing.",
      "author": "Louisa Conwill, Megan Levis Scheirer, Walter Scheirer",
      "published_date": "2025-09-18T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 149,
      "reading_time": 1,
      "created_at": "2025-09-18T04:23:58.232459+00:00",
      "updated_at": "2025-09-18T04:23:58.232461+00:00"
    },
    {
      "id": "70fa26fcbd3732cca6092a170ceca182",
      "url": "https://arxiv.org/abs/2509.13444",
      "title": "DuetUI: A Bidirectional Context Loop for Human-Agent Co-Generation of Task-Oriented Interfaces",
      "content": "arXiv:2509.13444v1 Announce Type: new \nAbstract: Large Language Models are reshaping task automation, yet remain limited in complex, multi-step real-world tasks that require aligning with vague user intent and enabling dynamic user override. From a formative study with 12 participants, we found that end-users actively seek to shape generative interfaces rather than relying on one-shot outputs. To address this, we introduce the human-agent co-generation paradigm, materialized in DuetUI. This LLM-empowered system unfolds alongside task progress through a bidirectional context loop--the agent scaffolds the interface by decomposing the task, while the user's direct manipulations implicitly steer the agent's next generation step. In a user study with 24 participants, DuetUI significantly improved task efficiency and interface usability compared to a baseline, fostering seamless human-agent collaboration. Our contributions include the proposal and validation of this novel paradigm, the design of the DuetUI prototype embodying it, and empirical insights into how this bidirectional loop better aligns agents with human intent.",
      "author": "Yuan Xu, Shaowen Xiang, Yizhi Song, Ruoting Sun, Xin Tong",
      "published_date": "2025-09-18T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 155,
      "reading_time": 1,
      "created_at": "2025-09-18T04:23:58.232430+00:00",
      "updated_at": "2025-09-18T04:23:58.232431+00:00"
    },
    {
      "id": "d1fb039a31220d09ed97992ac3269c60",
      "url": "https://arxiv.org/abs/2509.13326",
      "title": "LLM Chatbot-Creation Approaches",
      "content": "arXiv:2509.13326v1 Announce Type: new \nAbstract: This full research-to-practice paper explores approaches for developing course chatbots by comparing low-code platforms and custom-coded solutions in educational contexts. With the rise of Large Language Models (LLMs) like GPT-4 and LLaMA, LLM-based chatbots are being integrated into teaching workflows to automate tasks, provide assistance, and offer scalable support. However, selecting the optimal development strategy requires balancing ease of use, customization, data privacy, and scalability. This study compares two development approaches: low-code platforms like AnythingLLM and Botpress, with custom-coded solutions using LangChain, FAISS, and FastAPI. The research uses Prompt engineering, Retrieval-augmented generation (RAG), and personalization to evaluate chatbot prototypes across technical performance, scalability, and user experience. Findings indicate that while low-code platforms enable rapid prototyping, they face limitations in customization and scaling, while custom-coded systems offer more control but require significant technical expertise. Both approaches successfully implement key research principles such as adaptive feedback loops and conversational continuity. The study provides a framework for selecting the appropriate development strategy based on institutional goals and resources. Future work will focus on hybrid solutions that combine low-code accessibility with modular customization and incorporate multimodal input for intelligent tutoring systems.",
      "author": "Hemil Mehta, Tanvi Raut, Kohav Yadav, Edward F. Gehringer",
      "published_date": "2025-09-18T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 192,
      "reading_time": 1,
      "created_at": "2025-09-18T04:23:58.232399+00:00",
      "updated_at": "2025-09-18T04:23:58.232401+00:00"
    },
    {
      "id": "aafeb3cc353ec86adb822ad0d659602d",
      "url": "https://arxiv.org/abs/2509.13324",
      "title": "Designing Psychometric Bias Measures for ChatBots: An Application to Racial Bias Measurement",
      "content": "arXiv:2509.13324v1 Announce Type: new \nAbstract: Artificial intelligence (AI), particularly in the form of large language models (LLMs) or chatbots, has become increasingly integrated into our daily lives. In the past five years, several LLMs have been introduced, including ChatGPT by OpenAI, Claude by Anthropic, and Llama by Meta, among others. These models have the potential to be employed across a wide range of human-machine interaction applications, such as chatbots for information retrieval, assistance in corporate hiring decisions, college admissions, financial loan approvals, parole determinations, and even in medical fields like psychotherapy delivered through chatbots. The key question is whether these chatbots will interact with humans in a bias-free manner or if they will further reinforce the existing pathological biases present in human-to-human interactions. If the latter is true, then how to rigorously measure these biases? We aim to address this challenge by proposing a principled framework for designing psychometric measures to evaluate chatbot biases.",
      "author": "Mouhacine Benosman",
      "published_date": "2025-09-18T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 154,
      "reading_time": 1,
      "created_at": "2025-09-18T04:23:58.232364+00:00",
      "updated_at": "2025-09-18T04:23:58.232366+00:00"
    },
    {
      "id": "011a72339988610bb05bb5fac6735b40",
      "url": "https://arxiv.org/abs/2509.13323",
      "title": "AI Behavioral Science",
      "content": "arXiv:2509.13323v1 Announce Type: new \nAbstract: We discuss the three main areas comprising the new and emerging field of \"AI Behavioral Science\". This includes not only how AI can enhance research in the behavioral sciences, but also how the behavioral sciences can be used to study and better design AI and to understand how the world will change as AI and humans interact in increasingly layered and complex ways.",
      "author": "Matthew O. Jackson, Qiaozhu Me, Stephanie W. Wang, Yutong Xie, Walter Yuan, Seth Benzell, Erik Brynjolfsson, Colin F. Camerer, James Evans, Brian Jabarian, Jon Kleinberg, Juanjuan Meng, Sendhil Mullainathan, Asuman Ozdaglar, Thomas Pfeiffer, Moshe Tennenholtz, Robb Willer, Diyi Yang, Teng Ye",
      "published_date": "2025-09-18T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 68,
      "reading_time": 1,
      "created_at": "2025-09-18T04:23:58.232323+00:00",
      "updated_at": "2025-09-18T04:23:58.232327+00:00"
    },
    {
      "id": "c577165b98c14d3ce1154c74d3f19a28",
      "url": "https://arxiv.org/abs/2508.08548",
      "title": "Emergence: from physics to biology, sociology, and computer science",
      "content": "arXiv:2508.08548v2 Announce Type: replace-cross \nAbstract: Many systems involve numerous interacting parts and the whole system can have properties that the individual parts do not. I take this novelty as the defining characteristic of an emergent property. Other characteristics associated with emergence discussed include universality, order, complexity, unpredictability, irreducibility, diversity, self-organisation, discontinuities, and singularities. Emergent phenomena are widespread across physics, biology, social sciences, and computing, and are central to major scientific and societal challenges. Understanding emergence involves considering the stratification of reality across different scales (energy, time, length, complexity), each with its distinct ontology and epistemology, leading to semi-autonomous scientific disciplines. A central challenge is bridging the gap between macroscopic emergent properties and microscopic component interactions. Identifying an intermediate mesoscopic scale where new, weakly interacting entities or modular structures emerge is key. Theoretical approaches, such as effective theories (describing phenomena at a specific scale) and toy models (simplified systems for analysis), are vital. The Ising model exemplifies how toy models can elucidate emergence characteristics. Emergence is central to condensed matter physics, chaotic systems, fluid dynamics, nuclear physics, quantum gravity, neural networks, protein folding, and social segregation. An emergent perspective should influence scientific strategy by shaping research questions, methodologies, priorities, and resource allocation. An elusive goal is the design and control of emergent properties.",
      "author": "Ross H. McKenzie",
      "published_date": "2025-09-18T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 212,
      "reading_time": 1,
      "created_at": "2025-09-18T04:23:57.018342+00:00",
      "updated_at": "2025-09-18T04:23:57.018343+00:00"
    },
    {
      "id": "8a344c71ff23f0f479f09609d969aba5",
      "url": "https://arxiv.org/abs/2509.08179",
      "title": "Computational modelling of Parkinson's disease: A multiscale approach with deep brain stimulation and stochastic noise",
      "content": "arXiv:2509.08179v2 Announce Type: replace \nAbstract: Multiscale modelling presents a multifaceted perspective into understanding the mechanisms of the brain and how neurodegenerative disorders like Parkinson's disease (PD) manifest and evolve over time. In this study, we propose a novel co-simulation multiscale approach that unifies both micro- and macroscales to more rigorously capture brain dynamics. The presented design considers the electrodiffusive activity across the brain and in the network defined by the cortex, basal ganglia, and thalamus that is implicated in the mechanics of PD, as well as the contribution of presynaptic inputs in the highlighted regions. The application of deep brain stimulation (DBS) and its effects, along with the inclusion of stochastic noise are also examined. We found that the thalamus exhibits large, fluctuating spiking in both the deterministic and stochastic conditions, suggesting that noise contributes primarily to neural variability, rather than driving the overall spiking activity. Ultimately, this work intends to provide greater insights into the dynamics of PD and the brain which can eventually be converted into clinical use.",
      "author": "Aaron Herrera, Hina Shaheen",
      "published_date": "2025-09-18T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 170,
      "reading_time": 1,
      "created_at": "2025-09-18T04:23:57.018309+00:00",
      "updated_at": "2025-09-18T04:23:57.018310+00:00"
    },
    {
      "id": "f435d2bc58055c762aa6893359e07301",
      "url": "https://arxiv.org/abs/2501.13628",
      "title": "Language modulates vision: Evidence from neural networks and human brain-lesion models",
      "content": "arXiv:2501.13628v2 Announce Type: replace \nAbstract: Comparing information structures in between deep neural networks (DNNs) and the human brain has become a key method for exploring their similarities and differences. Recent research has shown better alignment of vision-language DNN models, such as CLIP, with the activity of the human ventral occipitotemporal cortex (VOTC) than earlier vision models, supporting the idea that language modulates human visual perception. However, interpreting the results from such comparisons is inherently limited due to the \"black box\" nature of DNNs. To address this, we combined model-brain fitness analyses with human brain lesion data to examine how disrupting the communication pathway between the visual and language systems causally affects the ability of vision-language DNNs to explain the activity of the VOTC. Across four diverse datasets, CLIP consistently captured unique variance in VOTC neural representations, relative to both label-supervised (ResNet) and unsupervised (MoCo) models. This advantage tended to be left-lateralized at the group level, aligning with the human language network. Analyses of 33 stroke patients revealed that reduced white matter integrity between the VOTC and the language region in the left angular gyrus was correlated with decreased CLIP-brain correspondence and increased MoCo-brain correspondence, indicating a dynamic influence of language processing on the activity of the VOTC. These findings support the integration of language modulation in neurocognitive models of human vision, reinforcing concepts from vision-language DNN models. The sensitivity of model-brain similarity to specific brain lesions demonstrates that leveraging manipulation of the human brain is a promising framework for evaluating and developing brain-like computer models.",
      "author": "Haoyang Chen, Bo Liu, Shuyue Wang, Xiaosha Wang, Wenjuan Han, Yixin Zhu, Xiaochun Wang, Yanchao Bi",
      "published_date": "2025-09-18T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 255,
      "reading_time": 1,
      "created_at": "2025-09-18T04:23:57.018279+00:00",
      "updated_at": "2025-09-18T04:23:57.018281+00:00"
    },
    {
      "id": "5ff92aa9bcf59d42ca888db10f0696a0",
      "url": "https://arxiv.org/abs/2410.13034",
      "title": "Synthesis and Perceptual Scaling of High Resolution Naturalistic Images Using Stable Diffusion",
      "content": "arXiv:2410.13034v2 Announce Type: replace \nAbstract: Naturalistic scenes are of key interest for visual perception, but controlling their perceptual and semantic properties is challenging. Previous work on naturalistic scenes has frequently focused on collections of discrete images with considerable physical differences between stimuli. However, it is often desirable to assess representations of naturalistic images that vary along a continuum. Traditionally, perceptually continuous variations of naturalistic stimuli have been obtained by morphing a source image into a target image. This produces transitions driven mainly by low-level physical features and can result in semantically ambiguous outcomes. More recently, generative adversarial networks (GANs) have been used to generate continuous perceptual variations within a stimulus category. Here we extend and generalize this approach using a different machine learning approach, a text-to-image diffusion model (Stable Diffusion XL), to generate a freely customizable stimulus set of photorealistic images that are characterized by gradual transitions, with each image representing a unique exemplar within a prompted category. We demonstrate the approach by generating a set of 108 object scenes from 6 categories. For each object scene, we generate 10 variants that are ordered along a perceptual continuum. This ordering was first estimated using a machine learning model of perceptual similarity (LPIPS) and then subsequently validated with a large online sample of human participants. In a subsequent experiment we show that this ordering is also predictive of confusability of stimuli in a working memory experiment. Our image set is suited for studies investigating the graded encoding of naturalistic stimuli in visual perception, attention, and memory.",
      "author": "Leonardo Pettini, Carsten Bogler, Christian Doeller, John-Dylan Haynes",
      "published_date": "2025-09-18T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 255,
      "reading_time": 1,
      "created_at": "2025-09-18T04:23:57.018243+00:00",
      "updated_at": "2025-09-18T04:23:57.018245+00:00"
    },
    {
      "id": "46780a0562df490593b47eaca60c915c",
      "url": "https://arxiv.org/abs/2509.14118",
      "title": "Multi-Source Neural Activity Indices and Spatial Filters for EEG/MEG Inverse Problem: An Extension to MNE-Python",
      "content": "arXiv:2509.14118v1 Announce Type: cross \nAbstract: Accurate EEG/MEG source localization is essential for understanding brain function, yet remains challenging because the inverse problem is inherently ill-posed. In spatial filtering (beamforming) approaches, single-source LCMV spatial filters, though widely used, suffer from source cancellation when sources are correlated - a common experimental scenario. Multi-source frameworks, such as the multi-source minimum-variance pseudo-unbiased reduced-rank (MV-PURE) method, offer improved reconstruction and robust neural activity indices, yet their adoption has been limited by incomplete theory and lack of accessible implementations. In this paper, we present a rigorous derivation of multi-source neural activity indices and spatial filters, establishing a complete analytical framework with automated parameter selection. The resulting compact algebraic forms enable straightforward implementation. To facilitate adoption, we provide a full implementation extending MNE-Python, along with an accompanying tutorial, and demonstrate its utility on EEG experimental data, highlighting the practical advantages of multi-source spatial filtering for source localization and reconstruction.",
      "author": "Julia Jurkowska, Joanna Dreszer, Monika Lewandowska, Krzysztof To{\\l}pa, Tomasz Piotrowski",
      "published_date": "2025-09-18T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 152,
      "reading_time": 1,
      "created_at": "2025-09-18T04:23:57.018208+00:00",
      "updated_at": "2025-09-18T04:23:57.018210+00:00"
    },
    {
      "id": "c2e35fc52884eee6b9fe6ffdb1a40eff",
      "url": "https://arxiv.org/abs/2509.13867",
      "title": "Plasticity-induced multistability on fast and slow timescales enables optimal information encoding and spontaneous sequence discrimination",
      "content": "arXiv:2509.13867v1 Announce Type: cross \nAbstract: Neural circuits exhibit remarkable computational flexibility, enabling adaptive responses to noisy and ever-changing environmental cues. A fundamental question in neuroscience concerns how a wide range of behaviors can emerge from a relatively limited set of underlying biological mechanisms. In particular, the interaction between activities of neuronal populations and plasticity modulation of synaptic connections may endow neural circuits with a variety of functional responses when coordinated over different characteristic timescales. Here, we develop an information-theoretic framework to quantitatively explore this idea. We consider a stochastic model for neural activities that incorporates the presence of a coupled dynamic plasticity and time-varying stimuli. We show that long-term plasticity modulations play the functional role of steering neural activities towards a regime of optimal information encoding. By constructing the associated phase diagram, we demonstrate that either Hebbian or anti-Hebbian plasticity may become optimal strategies depending on how the external input is projected to the target neural populations. Conversely, short-term plasticity enables the discrimination of temporal ordering in sequences of inputs by navigating the emergent multistable attractor landscape. By allowing a degree of variability in external stimuli, we also highlight the existence of an optimal variability for sequence discrimination at a given plasticity strength. In summary, the timescale of plasticity modulation shapes how inputs are represented in neural activities, thereby fundamentally altering the computational properties of the system. Our approach offers a unifying information-theoretic perspective of the role of plasticity, paving the way for a quantitative understanding of the emergence of complex computations in coupled neuronal-synaptic dynamics.",
      "author": "Giacomo Barzon, Daniel M. Busiello, Giorgio Nicoletti",
      "published_date": "2025-09-18T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 256,
      "reading_time": 1,
      "created_at": "2025-09-18T04:23:57.018179+00:00",
      "updated_at": "2025-09-18T04:23:57.018181+00:00"
    },
    {
      "id": "64696584d5ca1e17002742ef3f89f997",
      "url": "https://arxiv.org/abs/2509.13875",
      "title": "Personalized Detection of Stress via hdrEEG: Linking Neuro-markers to Cortisol, HRV, and Self-Report",
      "content": "arXiv:2509.13875v1 Announce Type: new \nAbstract: Chronic stress is a major risk factor for cognitive decline, neurodegenerative disease, and systemic health burden, underscoring the need for reliable individual-level biomarkers of stress reactivity. While cortisol, heart rate variability (HRV), and self-report measures are widely used, they provide limited insight into neural mechanisms. Here, we tested whether two single-channel hdrEEG biomarkers, ST4 and T2, serve as personalized indices of stress regulation by linking neural activity to validated physiological and subjective measures. We conducted two studies. Study 1 included 101 healthy adults (22-82 years) who completed questionnaires on resilience, burnout, and perceived stress, provided salivary cortisol, and underwent hdrEEG during resting, detection, n-back, lexical, emotional music, and startle tasks. Study 2 included 82 adults (19-42 years) who completed the State-Trait Anxiety Inventory, were monitored for HRV, and performed auditory, stress-inducing (job interview, arithmetic), and emotional tasks during hdrEEG recording. Across studies, ST4 reflected physiological arousal and cognitive strain, correlating positively with cortisol, subjective stress, and pulse pressure, and negatively with resilience and HRV indices. T2 showed a complementary profile, linking emotional and autonomic processes. T2 activity correlated with cortisol, heart rate, HRV measures, resilience, and trait anxiety, especially during lexical and emotional tasks. Together, ST4 and T2 capture distinct facets of the stress response: physiological arousal versus emotional-regulatory sensitivity. These findings highlight portable hdrEEG as a promising tool for personalized stress assessment, bridging neural, physiological, and subjective domains with implications for clinical and occupational monitoring.",
      "author": "N. B. Maimon, Ganit Baruchin, Itamar Grotto, Nathan Intrator, Talya Zeimer, Ofir Chibotero, Efrat Danino",
      "published_date": "2025-09-18T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 241,
      "reading_time": 1,
      "created_at": "2025-09-18T04:23:57.018143+00:00",
      "updated_at": "2025-09-18T04:23:57.018145+00:00"
    },
    {
      "id": "16f2b3d4cfd690310e1f40f92a321e81",
      "url": "https://arxiv.org/abs/2509.13612",
      "title": "Rest2Visual: Predicting Visually Evoked fMRI from Resting-State Scans",
      "content": "arXiv:2509.13612v1 Announce Type: new \nAbstract: Understanding how spontaneous brain activity relates to stimulus-driven neural responses is a fundamental challenge in cognitive neuroscience. While task-based functional magnetic resonance imaging (fMRI) captures localized stimulus-evoked brain activation, its acquisition is costly, time-consuming, and difficult to scale across populations. In contrast, resting-state fMRI (rs-fMRI) is task-free and abundant, but lacks direct interpretability. We introduce Rest2Visual, a conditional generative model that predicts visually evoked fMRI (ve-fMRI) from resting-state input and 2D visual stimuli. It follows a volumetric encoder--decoder design, where multiscale 3D features from rs-fMRI are modulated by image embeddings via adaptive normalization, enabling spatially accurate, stimulus-specific activation synthesis. To enable model training, we construct a large-scale triplet dataset from the Natural Scenes Dataset (NSD), aligning each rs-fMRI volume with stimulus images and their corresponding ve-fMRI activation maps. Quantitative evaluation shows that the predicted activations closely match ground truth across standard similarity and representational metrics, and support successful image reconstruction in downstream decoding. Notably, the predicted maps preserve subject-specific structure, demonstrating the model's capacity to generate individualized functional surrogates. Our results provide compelling evidence that individualized spontaneous neural activity can be transformed into stimulus-aligned representations, opening new avenues for scalable, task-free functional brain modeling.",
      "author": "Chuyang Zhou, Ziao Ji, Daochang Liu, Dongang Wang, Chenyu Wang, Chang Xu",
      "published_date": "2025-09-18T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 199,
      "reading_time": 1,
      "created_at": "2025-09-18T04:23:57.018106+00:00",
      "updated_at": "2025-09-18T04:23:57.018108+00:00"
    }
  ]
}