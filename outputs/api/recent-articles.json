{
  "last_updated": "2026-01-09T03:26:44.099058+00:00",
  "count": 20,
  "articles": [
    {
      "id": "e5246537140813f4ad3087687aae473d",
      "url": "http://ieeexplore.ieee.org/document/11170404",
      "title": "Rendering Affective Touch With an Array of Pneumatic Unit Cell Actuators",
      "content": "Rendering affective touch through haptic interfaces has gathered significant interest due to its ability to elicit emotional responses. Among various forms of affective touch, this study focuses on stroke stimuli. An illusory stroke stimulus is rendered using eight discrete Pneumatic Unit Cell (PUC) actuators on the left forearm. The study systematically investigates how rendering parameters\u2014including the traveling speed of the illusory stroke, the stimulus onset asynchrony (SOA) of consecutive indentations, and indentation pressure\u2014affect the perceived pleasantness and continuity of the stimulus. Results reveal that higher speeds significantly improved both pleasantness and continuity, with speed emerging as the most influential factor. In contrast, SOA has no significant effect on either perceived pleasantness or continuity. Indentation pressure shows a moderate impact on pleasantness, with high pressures reducing pleasantness but having no significant effect on continuity. Additionally, a positive correlation is observed between perceived pleasantness and continuity, underscoring the relevance of the continuity illusion created by sequential indentations with discrete actuators in evoking pleasant sensations. These findings demonstrate the potential of PUC actuators for creating affective touch stimuli and provide preliminary insights into the influence of rendering parameters on affective touch in human-machine and human-robot interactions.",
      "author": "",
      "published_date": "2025-09-18T13:16:54+00:00",
      "source": "Transactions Haptics",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 193,
      "reading_time": 1,
      "created_at": "2026-01-09T01:50:37.961195+00:00",
      "updated_at": "2026-01-09T03:26:43.988956+00:00",
      "metadata": {
        "processed_at": "2026-01-09T03:26:43.988966+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "560b53b8a9f1b10c46ba5f7d619d4dec",
      "url": "http://ieeexplore.ieee.org/document/11164370",
      "title": "Drawing the Line: Wearable Linear Haptics Motivated by Guided Breathing",
      "content": "Haptic wearables provide an intuitive human-machine interface to convey information through the sense of touch, which may have promising applications in guided breathing. In this paper, we detail the design and evaluation of three wearable prototypes (Vibration, Skin Drag, and Tapping) capable of administering discrete (individual, separate pulses and stimuli). and continuous (overlapping or uninterrupted stimuli) forms of linear haptic cycles with inspiration from slow, deep guided breathing. Characterization was performed to quantify and validate the performance of six haptic stimuli (discrete/continuous vibration, skin drag, and tapping). Devices were quantified with key metrics that described the applied stimuli and the dynamics of the wearable. A human subjects study (N = 25), composed of two-cycle tracking tasks, was conducted to determine device performance and user aptitude. Results indicated consistent directional recognition across all six stimuli, but discrete stimuli performed better in spatial localization tasks. Although outperformed in tracking/localization tasks, continuous stimuli, especially skin drag, were described as the most apt and intuitive pairing to guided breathing. Findings highlight the potential of these linear haptic stimuli in a number of applications, including guided breathing, navigation, virtual immersion, and communication.",
      "author": "",
      "published_date": "2025-09-15T13:17:38+00:00",
      "source": "Transactions Haptics",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 187,
      "reading_time": 1,
      "created_at": "2026-01-09T01:50:37.961160+00:00",
      "updated_at": "2026-01-09T03:26:43.988970+00:00",
      "metadata": {
        "processed_at": "2026-01-09T03:26:43.988972+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "273f5b74995aee1a22f54d9a1ad2625a",
      "url": "http://ieeexplore.ieee.org/document/11145272",
      "title": "Haptics of Pulse Palpation: Simulation and Validation Through Novel Sensor-Actuator System",
      "content": "Palpation of arteries holds significant physiological importance. Existing pulse actuator designs intended to replicate the haptic sensations of palpation primarily focus on normal force interactions, often overlooking the shear forces generated by oscillations of the arterial wall during blood flow. This study aims to evaluate the normal, longitudinal, and transverse forces exerted by arteries through both theoretical and experimental analyses during palpation. The experimental validation features a pulse actuator-sensor system. The actuator component is a hydroelectromagnetic actuator, while the haptic sensing is performed by the Subblescope. The Subblescope measures arterial force feedback from both soft and hard artery models, as well as from the radial pulse in 18 human subjects. Mathematical analysis establishes the operational range of the sensor-actuator system as 0.005 N to 2.5 N. The force feedback from the simulation has been used for designing the total force generation by the actuator. The reactive force along the Z-axis varies between 19.3 mN to 500 mN, while the transverse and longitudinal forces along the Y and X axes range from 6.9 mN to 88.01 mN and 5.46 mN to 87.85 mN, respectively. The pulse-force map of the hard artery reveals higher three-dimensional force interactions compared to the soft artery. The hydroelectromagnetic actuator effectively generates both normal and shear forces during pulsatile flow. Future work will focus on developing training modules that replicate pulse haptics associated with various physiological conditions such as diabetes.",
      "author": "",
      "published_date": "2025-08-29T13:18:28+00:00",
      "source": "Transactions Haptics",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 233,
      "reading_time": 1,
      "created_at": "2026-01-09T01:50:37.961127+00:00",
      "updated_at": "2026-01-09T03:26:43.988975+00:00",
      "metadata": {
        "processed_at": "2026-01-09T03:26:43.988976+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "bcb6b72cd62b8e161b8fb3f40caa20b0",
      "url": "http://ieeexplore.ieee.org/document/11125831",
      "title": "HapticGiant: A Novel Very Large Kinesthetic Haptic Interface With Hierarchical Force Control",
      "content": "Research in virtual reality and haptic technologies has consistently aimed to enhance immersion. While advanced head-mounted displays are now commercially available, kinesthetic haptic interfaces still face challenges such as limited workspaces, insufficient degrees of freedom, and kinematics not matching the human arm. In this paper, we present HapticGiant, a novel large-scale kinesthetic haptic interface designed to match the properties of the human arm as closely as possible and to facilitate natural user locomotion while providing full haptic feedback. The interface incorporates a novel admittance-type force control scheme, leveraging hierarchical optimization to render both arbitrary serial kinematic chains and Cartesian admittances. Notably, the proposed control scheme natively accounts for system limitations, including joint and Cartesian constraints, as well as singularities. Experimental results demonstrate the effectiveness of HapticGiant and its control scheme, paving the way for highly immersive virtual reality applications.",
      "author": "",
      "published_date": "2025-08-14T13:17:43+00:00",
      "source": "Transactions Haptics",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 139,
      "reading_time": 1,
      "created_at": "2026-01-09T01:50:37.961091+00:00",
      "updated_at": "2026-01-09T03:26:43.988978+00:00",
      "metadata": {
        "processed_at": "2026-01-09T03:26:43.988980+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "76c23c5300399082bb749ca190929d23",
      "url": "http://ieeexplore.ieee.org/document/11130394",
      "title": "\u201cPersuasive Vibrations\u201d: Studying the Influence of Vibration Parameters on Speech Persuasion",
      "content": "This paper investigates the notion of \u201cPersuasive Vibrations\u201d, which showed that augmenting a person's speech with vibrotactile feedback could artificially increase persuasion. However, while the initial paper has shown the effect, the underlying reasons why vibrations enhance persuasion remain unknown. Through two different user studies, this paper aims to study how the underlying parameters of the vibratory feedback (e.g., frequency, amplitude, or audio-vibration synchronization) influence persuasion. The first study aimed to identify the parameters of vibrotactile feedback that can positively influence persuasion. The second study evaluated vibrotactile feedback that might impair the persuasive effect. In a nutshell, the first experiment suggests that the isolation of different properties of the vibratory signal could tend to provide higher persuasion compared to no vibratory feedback. A lower frequency at 100 Hz seems the most efficient way to generate a persuasive effect. In contrast, the second experiment suggests that some alteration of the vibratory signal (e.g., latency) does not decrease the levels of persuasion compared to the no-vibration condition. All in all, the results suggest that using lower frequencies could have a better effect on persuasion. These results could serve as a basis for haptic design in applications like videoconferencing, virtual meetings, and training systems where supporting user speech is essential.",
      "author": "",
      "published_date": "2025-08-19T13:17:09+00:00",
      "source": "Transactions Haptics",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 207,
      "reading_time": 1,
      "created_at": "2026-01-09T01:50:37.961060+00:00",
      "updated_at": "2026-01-09T03:26:43.988985+00:00",
      "metadata": {
        "processed_at": "2026-01-09T03:26:43.988986+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "23dd8d4f1e90a8b410a6b21713fcf022",
      "url": "http://ieeexplore.ieee.org/document/11121155",
      "title": "A Survey on Tactile Change Blindness",
      "content": "While vibrotactile displays continue to gain popularity, it remains that the phenomenon of tactile change blindness negatively impacts the human ability to detect changes between and within tactile signals. This paper surveys the research literature on tactile change detection and blindness under various parameters, including the number of tactors used, the intensity and length of the stimulus, and whether distractors between stimuli (i.e., transients) were used during experimentation, among others. The goal of this survey is to summarize what has been done in an attempt to better understand the parameters that exacerbate tactile change blindness and identify potential areas of future research. When such an understanding is reached, the design of haptic and multimodal displays may ideally be improved.",
      "author": "",
      "published_date": "2025-08-08T13:16:47+00:00",
      "source": "Transactions Haptics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 119,
      "reading_time": 1,
      "created_at": "2026-01-09T01:50:37.961001+00:00",
      "updated_at": "2026-01-09T01:50:37.961002+00:00"
    },
    {
      "id": "87344862fd4253ecc468dd068b2c0436",
      "url": "http://ieeexplore.ieee.org/document/11284873",
      "title": "From Restoration to Augmentation: New Approaches to Haptic Feedback for Artificial Limbs",
      "content": "Haptic feedback is essential for precise motor control, making its integration into artificial limbs a critical design challenge. Current approaches to restoring lost tactile input in patients have focused on interfacing with somatosensory pathways at the brain, nerve, or skin level, achieving partial restoration. However, augmentative artificial limbs, devices that provide novel movement capabilities beyond the biological body, pose unique challenges. These limbs lack dedicated sensory pathways, raising fundamental questions about how to deliver tactile feedback for these devices without disrupting existing somatosensory function. A promising direction lies in exploiting intrinsic tactile feedback, which emerges naturally at the interface between wearable devices and the body. When an artificial limb moves or interacts with objects, the skin detects rich tactile cues transmitted through this interface. Amplifying and refining this intrinsic feedback, via materials optimized for transmission of tactile signals and wearable designs, could enable more intuitive and interpretable haptic feedback for augmentative limbs. This approach offers a pathway toward enhancing embodiment and motor control of augmentative artificial limbs.",
      "author": "",
      "published_date": "2025-12-08T13:16:55+00:00",
      "source": "Transactions Haptics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 167,
      "reading_time": 1,
      "created_at": "2026-01-09T01:50:37.960973+00:00",
      "updated_at": "2026-01-09T01:50:37.960974+00:00"
    },
    {
      "id": "0e26a7e93d9b4a75df2d60781a3dcc65",
      "url": "http://ieeexplore.ieee.org/document/11264420",
      "title": "Recent Achievements of Electrotactile Displays in IEEE Transactions on Haptics",
      "content": "Electrotactile displays are a promising technology that combines the simplicity of implementation using only electronic circuits with the flexibility to deliver tactile sensations across many body sites. In recent years, their applications and research have rapidly advanced. This article provides an overview of studies published in IEEE Transactions on Haptics, covering diverse aspects such as application domains of electrotactile stimulation, techniques for stabilizing percepts, methods for efficient information rendering, and the use of electrotactile displays as tools for investigating human tactile perception. Through this review, the engineering and scientific potential of electrotactile interfaces is highlighted, along with prospects for realizing future tactile displays that are low-cost, high-density, and large-area.",
      "author": "",
      "published_date": "2025-11-21T13:16:44+00:00",
      "source": "Transactions Haptics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 109,
      "reading_time": 1,
      "created_at": "2026-01-09T01:50:37.960938+00:00",
      "updated_at": "2026-01-09T01:50:37.960940+00:00"
    },
    {
      "id": "c578348c6b9165044969f256985bad4c",
      "url": "http://ieeexplore.ieee.org/document/11339382",
      "title": "Table of Contents",
      "content": "null",
      "author": "",
      "published_date": "2026-01-08T13:16:13+00:00",
      "source": "Transactions Haptics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 1,
      "reading_time": 1,
      "created_at": "2026-01-09T01:50:37.960904+00:00",
      "updated_at": "2026-01-09T01:50:37.960906+00:00"
    },
    {
      "id": "d6b415f22fbdcebeedebdf554a107289",
      "url": "http://ieeexplore.ieee.org/document/11339381",
      "title": "Front Cover",
      "content": "null",
      "author": "",
      "published_date": "2026-01-08T13:16:12+00:00",
      "source": "Transactions Haptics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 1,
      "reading_time": 1,
      "created_at": "2026-01-09T01:50:37.960878+00:00",
      "updated_at": "2026-01-09T01:50:37.960883+00:00"
    },
    {
      "id": "54d230cf25ea414894ace2b4e1450120",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.07.698027v1?rss=1",
      "title": "Dynamic control of Raf-ERK signaling modulates neuronal activity across biological scales",
      "content": "Neuronal activity robustly engages the extracellular signal-regulated kinase (ERK) signaling pathway through Calcium-dependent mechanisms; however, whether ERK can acutely and causally modulates ongoing neuronal activity remains unsolved due to complex upstream regulation and diverse subcellular functions. Here, we directly address this question using an optogenetic ERK activator, opto-miniRaf, that enables selective, rapid, graded, and reversible control of ERK signaling. Combining this AAV-compatible system with calcium imaging and electrophysiology, we interrogate ERK functions across biological scales, from cultured neurons, acute brain slices, and the intact brain. Acute optogenetic activation of ERK enhances synchronized network burst activity in cultured rat cortical neurons and increases calcium activity of cortical pyramidal neurons in awake and moving mice following non-invasive light stimulation. Together, these results establish ERK signaling as an acute modulator of neuronal and network activity, positioning opto-miniRaf as a generalizable platform for precise spatiotemporal control of intracellular kinase signaling in complex biological systems.",
      "author": "Fan, H., Kang, E., Zhou, Y., Barnes, C., Gron, N., Du, H., Christian-Hinman, C. A., Yu, X., Zhang, K.",
      "published_date": "2026-01-08T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 150,
      "reading_time": 1,
      "created_at": "2026-01-09T01:50:19.794188+00:00",
      "updated_at": "2026-01-09T01:50:19.794189+00:00"
    },
    {
      "id": "d7719ad3b37ab0956764f5dc5e907ac2",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.08.698329v1?rss=1",
      "title": "Linguistic information compensates for age-related decline in attentional filtering",
      "content": "As we age, understanding speech in social situations imposes an increasingly difficult challenge to the auditory system. However, the attentional mechanisms underlying age-related speech comprehension difficulties in multitalker situations remain unclear. We collected EEG signals while 63 normal hearing participants from 19 to 71 years performed a speech comprehension task involving a multitalker paradigm at individually adjusted target-to-distractor ratios. Combining trial-resolved multivariate temporal response function modeling with detailed behavioral comprehension responses, we provide a window into lower-level impairments and higher-level compensatory mechanisms across the adult life span. Neuro-behavioral correlations on a trial-by-trial level provide direct evidence for increased distractor representation underlying reduced behavioral performance in late adulthood. This points towards increased distractability as a potential mechanism underlying age-related speech comprehension deficits. Additionally, at the behavioral and neural levels, we show that older adults relied more on higher-level linguistic information. Finally, we show that an increased reliance on linguistic information may serve as a compensatory mechanism that supports comprehension performance across the adult life span. Summarizing, combining behavioral and neural data, we directly show that an increased reliance on linguistic processing can offset age-related impairments in attentional filtering.",
      "author": "Barchet, A. V., Bruera, A., Rimmele, J. M., Obleser, J., Hartwigsen, G.",
      "published_date": "2026-01-08T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 187,
      "reading_time": 1,
      "created_at": "2026-01-09T01:50:19.794155+00:00",
      "updated_at": "2026-01-09T01:50:19.794157+00:00"
    },
    {
      "id": "731822fdcac8dcb52fc46565b603b0d2",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.07.698269v1?rss=1",
      "title": "Claustral Input Consolidates Anterior Cingulate Cortical States for Selective Behavior",
      "content": "Efficient behavior depends on consolidating selective strategies that prioritize informative cues and suppress irrelevant signals. Previous studies have implicated the claustrum in coordinating cortical activity and large-scale brain states across behavioral contexts, yet its precise contribution to online behavioral control versus the consolidation of frontal control strategies remains unresolved. Here we combined large-scale Neuropixels recordings with targeted optogenetic perturbation of claustral neurons projecting to the anterior cingulate cortex in behaving mice. During adaptation to altered task context and constraints, frontal cortical activity reorganized into a coordinated control regime characterized by sharpened encoding of task-relevant cues, suppression of non-instructive signals, structured low-frequency dynamics, and rapid transitions between population-level neural states. Temporally misaligned claustral signaling disrupted this reorganization, selectively impairing the consolidation of efficient, cue-selective strategies across sessions without affecting trial-by-trial task execution. These findings identify a role for the claustrum in shaping frontal dynamics that consolidate adaptive control strategies.",
      "author": "Peretz-Rivlin, N., Fatal, Y., Levin, S., Gold, O., Profesorsky, K., Groysman, M., Citri, A.",
      "published_date": "2026-01-08T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 148,
      "reading_time": 1,
      "created_at": "2026-01-09T01:50:19.794113+00:00",
      "updated_at": "2026-01-09T01:50:19.794116+00:00"
    },
    {
      "id": "2051c17a44aa9633fb25f61554fb6958",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.08.698312v1?rss=1",
      "title": "Hierarchical processing and polarization encoding in the cephalopod visual system",
      "content": "Coleoid cephalopods (octopus, cuttlefish, and squid; hereafter \"cephalopods\") have evolved a range of complex visually guided behaviors, from dexterous hunting to skin pattern based camouflage and communication (1). They have also evolved sensitivity to the polarization of light (2), an adaptation thought to help detect camouflaged or semitransparent predators and prey in low-visibility underwater environments (3-10). How visual information is processed by the cephalopod brain to support these behaviors remains unclear. Here, studying the bigfin reef squid Sepioteuthis lessoniana, we performed calcium imaging and electrophysiological recordings from populations of neurons in the large visual center of the cephalopod brain, the optic lobe (OL). We found that the retina-recipient superficial OL contains a diversity of functionally distinct cell types, spatially organized into sublayers, that process spatiotemporal features of light intensity and exhibit polarization angle selectivity. More complex features, such as direction selectivity, are observed in deeper regions of the OL cortex, which also exhibit spontaneous waves of neural activity in the absence of visual input. Neurons in the downstream OL medulla exhibit visual receptive field sizes and spontaneous activity levels that increase with brain depth, consistent with hierarchical processing of visual information through the medulla's tree-like anatomical organization. Medulla neurons show sensitivity to local decreases in the degree of linear polarization (DoLP), which are integrated additively with light intensity information. Underwater imaging in the squid's natural habitat off the coast of Okinawa, Japan, demonstrates that polarization sensitivity provides a robust short-range increase in object-background contrast across a range of objects and environmental conditions. Together, these findings reveal convergent principles of hierarchical visual processing shared between cephalopods and vertebrates, and highlight how cephalopods exploit polarization sensitivity to solve fundamental visual challenges in underwater environments.",
      "author": "Mano, T., Tsaridis, K., Kojima, Y., Masucci, G. D., Dinh, T. T. V., Tong, R., Glykos, V., Dolezalova, L., Asada, K., Shumkova, D., Rogers, L., Hamon, M., Santon, M., Hiroi, M., Iglesias, T. L., Bellono, N. W., How, M. J., Goda, Y., Meshulam, L., Reiter, S.",
      "published_date": "2026-01-08T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 282,
      "reading_time": 1,
      "created_at": "2026-01-09T01:50:19.794072+00:00",
      "updated_at": "2026-01-09T01:50:19.794077+00:00"
    },
    {
      "id": "7680858203f43f4f5d8470de39e24d5b",
      "url": "https://www.reddit.com/r/Python/comments/1q7lkfw/omega_infinity_v41_a_metarecursive_markov_chain/",
      "title": "Omega Infinity v4.1: A Meta-Recursive Markov Chain Compressor that achieves 2.40x on random binaries",
      "content": "<!-- SC_OFF --><div class=\"md\"><h1>What My Project Does</h1> <p><strong>Omega Infinity v4.1</strong> is a compression system based on <strong>Meta-Recursive Markov Chains</strong>. Instead of looking for simple literal repetitions (like LZW or Huffman), it uses a multi-level ranking system to &quot;fold&quot; bitstreams recursively.</p> <p>In my latest stress test using a massive random binary (1.6 MB of high-entropy data generated via Browserling), it achieved:</p> <ul> <li><strong>Original:</strong> 1,600,005 bytes</li> <li><strong>Compressed:</strong> 666,413 bytes</li> <li><strong>Ratio:</strong> 58.3% (<strong>2.40x Factor</strong>)</li> </ul> <h1>Target Audience</h1> <p>This is currently a <strong>research/experimental project</strong>. It is meant for developers interested in information theory, cryptography, and non-traditional compression methods. While it shows incredible results on high-entropy data and binaries without spaces, it is a proof-of-concept for my &quot;Omega Infinity&quot; logic.</p> <h1>Comparison</h1> <p>Unlike existing alternatives like <strong>zlib, bzip2, or lzma</strong>, which often struggle (or even expand) when faced with purely random binary data or &quot;space-less&quot; bitstreams, Omega Infinity v4.1 finds micro-patterns through recursive depth. While standard algorithms rely on a sliding window, my system uses <strong>Recursive Ranking States</strong>, allowing it to &quot;predict&quot; and condense data that traditional entropy models consider incompressible.</p> <p><strong>Code &amp; Resources:</strong></p> <ul> <li><strong>GitHub:</strong><a href=\"https://github.com/POlLLOGAMER/OMEGA-INFINITY-META-MARKOV-COMPRESION\">https://github.com/POlLLOGAMER/OMEGA-INFINITY-META-MARKOV-COMPRESION</a></li> <li><strong>Colab (Compression):</strong><a href=\"https://osf.io/v239h\">https://osf.io/v239h</a></li> <li><strong>Colab (Decompression):</strong><a href=\"https://osf.io/8ks2w\">https://osf.io/8ks2w</a></li> <li><strong>Technical Paper:</strong><a href=\"https://osf.io/x2t9c\">https://osf.io/x2t9c</a></li> </ul> <p><em>(Note: If viewing on OSF, please download and view it in Google Colab for proper rendering).</em></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/No_Arachnid_5563\"> /u/No_Arachnid_5563 </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1q7lkfw/omega_infinity_v41_a_metarecursive_markov_chain/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1q7lkfw/omega_infinity_v41_a_metarecursive_markov_chain/\">[comments]</a></span>",
      "author": "/u/No_Arachnid_5563",
      "published_date": "2026-01-08T19:35:45+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 225,
      "reading_time": 1,
      "created_at": "2026-01-09T01:49:37.093618+00:00",
      "updated_at": "2026-01-09T01:49:37.093619+00:00"
    },
    {
      "id": "0039e9774e1b3563dff5336bdb95637f",
      "url": "https://www.reddit.com/r/Python/comments/1q74ivt/html_to_pdf_library_suggestions/",
      "title": "Html to Pdf library suggestions",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>I am working on a django project where i am trying to convert html content to pdf and then return the pdf as response. While generating the pdf the library needs to fetch styles from another file(styles.css) as well as images from relative links.</p> <p>I have tried playwright but for it to work i need to write inline css. wweasyprint is giving me a dll issue which I cant really fix. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Conscious_Question69\"> /u/Conscious_Question69 </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1q74ivt/html_to_pdf_library_suggestions/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1q74ivt/html_to_pdf_library_suggestions/\">[comments]</a></span>",
      "author": "/u/Conscious_Question69",
      "published_date": "2026-01-08T06:31:27+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 93,
      "reading_time": 1,
      "created_at": "2026-01-09T01:49:37.093582+00:00",
      "updated_at": "2026-01-09T01:49:37.093584+00:00"
    },
    {
      "id": "08d2d89b0e5f951e5e3af0b076cda9c7",
      "url": "https://www.reddit.com/r/Python/comments/1q77abp/built_an_http_client_that_matches_chromes/",
      "title": "Built an HTTP client that matches Chrome's JA4/Akamai fingerprint",
      "content": "<!-- SC_OFF --><div class=\"md\"><h1>What my project does?</h1> <p>Most of the HTTP clients like requests in python gets easily flagged by Cloudflare and such. Specially when it comes to HTTP/3 there are almost no good libraries which has native spoofing like chrome. So I got a little frustated and had built this library in Golang. It mimics chrome from top to bottom in all protocols. This is still definitely not fully ready for production, need a lot of testing and still might have edge cases pending. But please do try this and let me know how it goes for you - <a href=\"https://github.com/sardanioss/httpcloak\">https://github.com/sardanioss/httpcloak</a></p> <p>Thanks to cffi bindings, this library is available in Python, Golang, JS and C#</p> <p>It mimics Chrome across HTTP/1.1, HTTP/2, and HTTP/3 - matching JA4, Akamai hash, h3_hash, and ECH. Even does the TLS extension shuffling that Chrome does per-connection.. Won't help if they're checking JS execution or browser APIs - you'd need a real browser for that.</p> <p>If there is any feature missing or something you'd like to get added just lemme know. I'm gonna work on tcp/ip fingerprinting spoofing too once this lib is stable enough.</p> <h1>Target Audience</h1> <p>Mainly for people looking for a strong tls fingerprint spoofing for HTTP/3 and people looking to bypass akamai or cloudflare at transport layer.</p> <h1>Comparision</h1> <table><thead> <tr> <th align=\"left\">Feature</th> <th align=\"left\">requests</th> <th align=\"left\">httpcloak</th> </tr> </thead><tbody> <tr> <td align=\"left\"></td> <td align=\"left\" colspan=\"2\"></td> </tr> <tr> <td align=\"left\">HTTP/1.1</td> <td align=\"left\">\u2705</td> <td align=\"left\">\u2705</td> </tr> <tr> <td align=\"left\">HTTP/2</td> <td align=\"left\">\u274c</td> <td align=\"left\">\u2705</td> </tr> <tr> <td align=\"left\">HTTP/3 (QUIC)</td> <td align=\"left\">\u274c</td> <td align=\"left\">\u2705</td> </tr> <tr> <td align=\"left\">TLS Fingerprint Emulation</td> <td align=\"left\">\u274c</td> <td align=\"left\">\u2705</td> </tr> <tr> <td align=\"left\">Browser Presets (Chrome, Firefox, Safari)</td> <td align=\"left\">\u274c</td> <td align=\"left\">\u2705</td> </tr> <tr> <td align=\"left\">JA3/JA4 Fingerprint Spoofing</td> <td align=\"left\">\u274c</td> <td align=\"left\">\u2705</td> </tr> <tr> <td align=\"left\">TLS Extension Shuffling</td> <td align=\"left\">\u274c</td> <td align=\"left\">\u2705</td> </tr> <tr> <td align=\"left\">QUIC Transport Parameter Shuffling</td> <td align=\"left\">\u274c</td> <td align=\"left\">\u2705</td> </tr> <tr> <td align=\"left\">ECH (Encrypted Client Hello)</td> <td align=\"left\">\u274c</td> <td align=\"left\">\u2705</td> </tr> <tr> <td align=\"left\">Akamai HTTP/2 Fingerprint</td> <td align=\"left\">\u274c</td> <td align=\"left\">\u2705</td> </tr> <tr> <td align=\"left\">Session-Consistent Fingerprints</td> <td align=\"left\">\u274c</td> <td align=\"left\">\u2705</td> </tr> <tr> <td align=\"left\">IPv6 Support</td> <td align=\"left\">\u2705</td> <td align=\"left\">\u2705</td> </tr> <tr> <td align=\"left\">Cookie Handling</td> <td align=\"left\">\u2705</td> <td align=\"left\">\u2705</td> </tr> <tr> <td align=\"left\">Automatic Redirects</td> <td align=\"left\">\u2705</td> <td align=\"left\">\u2705</td> </tr> <tr> <td align=\"left\">Connection Pooling</td> <td align=\"left\">\u2705</td> <td align=\"left\">\u2705</td> </tr> </tbody></table> <p>If this is useful for you or you like it then please give it a star, thankyou!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/sardanioss\"> /u/sardanioss </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1q77abp/built_an_http_client_that_matches_chromes/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1q77abp/built_an_http_client_that_matches_chromes/\">[comments]</a></span>",
      "author": "/u/sardanioss",
      "published_date": "2026-01-08T09:20:19+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 413,
      "reading_time": 2,
      "created_at": "2026-01-09T01:49:37.093555+00:00",
      "updated_at": "2026-01-09T01:49:37.093557+00:00"
    },
    {
      "id": "c1d2b86e24d1dab42470e55abe2b914c",
      "url": "https://www.reddit.com/r/Python/comments/1q7it2g/state_machine_frameworks/",
      "title": "State Machine Frameworks?",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>At work we find ourselves writing many apps that include a notion of &quot;workflow.&quot; In many cases these have grown organically over the past few years and I'm starting to find ways to refactor these things to remove the if/then trees that are hard to follow and reason about.</p> <p>A lot of what we have are really state machines, and I'd like to begin a series of projects to start cleaning up all the old applications, replacing the byzantine indirection and if/thens with something like declarative descriptions of states and transitions.</p> <p>Of course, Google tells me that there are quite a few frameworks in this domain and I'd love to see some opinions from y'all about the strengths of projects like &quot;python-statemachine,&quot; &quot;transitions&quot; and &quot;statesman&quot;. We'll need something that plays well with both sync and async code and is relatively accessible even for those without a computer science background (lots of us are geneticists and bioinformaticists).</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/NoSenseOfPorpoise\"> /u/NoSenseOfPorpoise </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1q7it2g/state_machine_frameworks/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1q7it2g/state_machine_frameworks/\">[comments]</a></span>",
      "author": "/u/NoSenseOfPorpoise",
      "published_date": "2026-01-08T17:58:05+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 177,
      "reading_time": 1,
      "created_at": "2026-01-09T01:49:37.093493+00:00",
      "updated_at": "2026-01-09T01:49:37.093495+00:00"
    },
    {
      "id": "d1adf45043326fcc6613c9c569f4548c",
      "url": "https://www.reddit.com/r/Python/comments/1q7cyz4/python_typing_survey_2025_code_quality_and/",
      "title": "Python Typing Survey 2025: Code Quality and Flexibility As Top Reasons for Typing Adoption",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>The 2025 Typed Python Survey, conducted by contributors from JetBrains, Meta, and the broader Python typing community, offers a comprehensive look at the current state of Python\u2019s type system and developer tooling.</p> <p>The survey captures the evolving sentiment, challenges, and opportunities around Python typing in the open-source ecosystem.</p> <p>In this blog we\u2019ll cover a summary of the key findings and trends from this year\u2019s results.</p> <p><a href=\"https://engineering.fb.com/2025/12/22/developer-tools/python-typing-survey-2025-code-quality-flexibility-typing-adoption/\">LINK</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/BeamMeUpBiscotti\"> /u/BeamMeUpBiscotti </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1q7cyz4/python_typing_survey_2025_code_quality_and/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1q7cyz4/python_typing_survey_2025_code_quality_and/\">[comments]</a></span>",
      "author": "/u/BeamMeUpBiscotti",
      "published_date": "2026-01-08T14:19:05+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 88,
      "reading_time": 1,
      "created_at": "2026-01-09T01:49:37.093452+00:00",
      "updated_at": "2026-01-09T01:49:37.093457+00:00"
    },
    {
      "id": "6395d124a40d9149d0dc19eaadb7feec",
      "url": "https://kueda.net/blog/2026/01/06/why-i-left-inat/",
      "title": "Why I Left iNaturalist",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46548940\">Comments</a>",
      "author": "",
      "published_date": "2026-01-09T01:17:51+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-09T01:49:35.762003+00:00",
      "updated_at": "2026-01-09T01:49:35.762004+00:00"
    }
  ]
}