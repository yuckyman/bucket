{
  "last_updated": "2025-12-23T18:24:05.513734+00:00",
  "count": 20,
  "articles": [
    {
      "id": "08e664e88f4ab84df159a973a76a40e7",
      "url": "http://doi.org/10.1037/bne0000634",
      "title": "Conditioned place preferences for virtual reality cannabis cues.",
      "content": "This study investigated whether 221 undergraduates (123 males, 98 females) with varying levels of cannabis use displayed a conditioned place preference (CPP) for a virtual reality (VR) room that previously contained virtual cannabis stimuli compared to a neutral VR room that was not paired with cannabis cues. We hypothesized that cannabis-using participants (<em>n</em> = 180) would spend a greater amount of time in, report greater subjective enjoyment in, and explicitly prefer a VR room that was previously paired with virtual cannabis stimuli relative to a neutral room, while participants with nonuse (<em>n</em> = 41) would not. Overall, participants did not demonstrate an implicit or explicit CPP for a VR room that was previously paired with cannabis cues. Interestingly, however, participants with recent cannabis use (<em>n</em> = 41) exhibited a significant implicit CPP for the cannabis-cue-paired VR room, while participants with nonrecent cannabis use (<em>n</em> = 113) did not. Furthermore, relative to males with cannabis use (<em>n</em> = 93), females with cannabis use (<em>n</em> = 87) demonstrated a significant explicit CPP for the cannabis-cue-paired context as well as significantly greater cannabis cravings. These findings elucidate the need for further research on the role of acute cannabis intoxication, sex, and cue-induced cravings in modulating CPP for cannabis-associated contexts. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2025-09-01T00:00:00+00:00",
      "source": "Behavioral Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 215,
      "reading_time": 1,
      "created_at": "2025-12-23T17:44:45.183037+00:00",
      "updated_at": "2025-12-23T18:24:05.403879+00:00",
      "metadata": {
        "processed_at": "2025-12-23T18:24:05.403889+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "5168657f83102357e9854c856d6e8912",
      "url": "http://doi.org/10.1037/bne0000630",
      "title": "Paraventricular thalamic inputs to the ventral pallidum shape reward seeking during threat and fear responding in extinction.",
      "content": "Environmental threats are typically encountered when animals are searching for food and other necessities. Adaptive behavior must balance competition between fear behavior and reward seeking. We gave rats local neuronal deletions of the ventral pallidum (VP) or specifically deleted paraventricular thalamic nucleus (PVT) neurons projecting directly to the VP. Rats were then assessed in a conditioned suppression procedure in which cues predicting unique foot shock probabilities were presented during, but independent from, reward seeking. Foot shock introduction generally suppressed reward seeking in rats, and recovery from shock introduction was facilitated in rats with VP or PVT \u2192 VP pathway deletions. Discriminative fear was observed in controls, and this fear responding reduced over a single extinction session. VP deletion enhanced extinction fear responding, and PVT \u2192 VP pathway deletion abolished within-session fear reductions. The results demonstrate the VP and its inputs from the PVT shape reward seeking in threat settings and govern fear extinction responding. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2025-09-01T00:00:00+00:00",
      "source": "Behavioral Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 163,
      "reading_time": 1,
      "created_at": "2025-12-23T17:44:45.183000+00:00",
      "updated_at": "2025-12-23T18:24:05.403893+00:00",
      "metadata": {
        "processed_at": "2025-12-23T18:24:05.403895+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "a8bbd636a4560189b204aa4362d5d614",
      "url": "https://github.com/bellard/mquickjs/blob/main/README.md",
      "title": "Fabrice Bellard Releases MicroQuickJS",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46367224\">Comments</a>",
      "author": "",
      "published_date": "2025-12-23T17:33:42+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-23T17:44:40.479952+00:00",
      "updated_at": "2025-12-23T18:24:05.403897+00:00",
      "metadata": {
        "processed_at": "2025-12-23T18:24:05.403899+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "a3d213dde683645a6f59de9d80bcf5db",
      "url": "https://www.phoronix.com/news/Meta-SCX-LAVD-Steam-Deck-Server",
      "title": "Meta Is Using the Linux Scheduler Designed for Valve's Steam Deck on Its Servers",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46366998\">Comments</a>",
      "author": "",
      "published_date": "2025-12-23T17:08:34+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-23T17:44:40.479913+00:00",
      "updated_at": "2025-12-23T18:24:05.403902+00:00",
      "metadata": {
        "processed_at": "2025-12-23T18:24:05.403903+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "a3d213dde683645a6f59de9d80bcf5db",
      "url": "https://www.phoronix.com/news/Meta-SCX-LAVD-Steam-Deck-Server",
      "title": "Meta Is Using the Linux Scheduler Designed for Valve's Steam Deck on Its Servers",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46366998\">Comments</a>",
      "author": "",
      "published_date": "2025-12-23T17:08:34+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-23T17:44:40.479913+00:00",
      "updated_at": "2025-12-23T18:24:05.403902+00:00",
      "metadata": {
        "processed_at": "2025-12-23T18:24:05.403903+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "a8bbd636a4560189b204aa4362d5d614",
      "url": "https://github.com/bellard/mquickjs/blob/main/README.md",
      "title": "Fabrice Bellard Releases MicroQuickJS",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46367224\">Comments</a>",
      "author": "",
      "published_date": "2025-12-23T17:33:42+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-23T17:44:40.479952+00:00",
      "updated_at": "2025-12-23T18:24:05.403897+00:00",
      "metadata": {
        "processed_at": "2025-12-23T18:24:05.403899+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "b1cdce7f5e061a4ca5bf268adc4e71f2",
      "url": "http://doi.org/10.1037/bne0000629",
      "title": "Patterns of prefrontal cortical activity associated with attention-demanding and motor aspects of dual-task walking as measured with functional near-infrared spectroscopy.",
      "content": "The ability to engage in everyday tasks, such as walking, requires the integration of cognitive and motor processes. How these processes integrate may be discernable through the relation of brain activity patterns to behavioral performance, particularly in the prefrontal cortex (PFC), examination of which has been restricted because of the limitations in experimental design. We related behavior (cognition, walking) to brain activity, as measured by functional near-infrared spectroscopy, under dual-task conditions (cognition while walking) in healthy young adults. Our probe design enabled us to examine eight regions of interest across PFC and motor cortex to identify key areas related to behavior. Healthy young adults (N = 19) engaged in standing cognition (Serial 3 subtraction), single-task walking, and dual-task walking. We used functional near-infrared spectroscopy to identify regions associated with increases or decreases in activity under dual-task relative to the other conditions. We observed differences in brain activity patterns by task across multiple regions of interest, mostly in PFC. Specifically, more lateral regions were related to attention-demanding tasks, whereas motor tasks were related to relatively medial regions. Our results relate behavior to brain activity, as measured by functional near-infrared spectroscopy, under dual-task conditions. Our finding of relatively lateral PFC activity during attention-demanding tasks provides insights into behavioral and brain processes during experimental analogues of everyday activity, bringing us closer to understanding behavior-brain relations in the real world. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2025-09-01T00:00:00+00:00",
      "source": "Behavioral Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 235,
      "reading_time": 1,
      "created_at": "2025-12-23T17:21:38.042719+00:00",
      "updated_at": "2025-12-23T17:21:38.042723+00:00"
    },
    {
      "id": "98738c175114f372cd7deaeb64145720",
      "url": "https://astroimagery.com/techniques/imaging/astrophotography-target-planner/",
      "title": "Astrophotography Target Planner: Discover Hidden Nebulas",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46330012\">Comments</a>",
      "author": "",
      "published_date": "2025-12-19T19:44:41+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-23T17:21:33.565182+00:00",
      "updated_at": "2025-12-23T17:21:33.565183+00:00"
    },
    {
      "id": "23a96a2a2c038884db3681a5ba667d30",
      "url": "https://yapi.run/blog/what-is-yapi",
      "title": "Show HN: Yapi \u2013 FOSS terminal API client for power users",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46352350\">Comments</a>",
      "author": "",
      "published_date": "2025-12-22T08:49:47+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-23T17:21:33.565163+00:00",
      "updated_at": "2025-12-23T17:21:33.565164+00:00"
    },
    {
      "id": "e1385798428586a67ced89a895faeb47",
      "url": "https://erpinfo.org/blog/2024/6/10/erp-core-decoding-paper",
      "title": "New Paper: Using Multivariate Pattern Analysis to Increase Effect Sizes for ERP Amplitude Comparisons",
      "content": "<p class=\"\">Carrasco, C. D., Bahle, B., Simmons, A. M., &amp; Luck, S. J. (2024). Using multivariate pattern analysis to increase effect sizes for event-related potential analyses. Psychophysiology, 61, e14570. <a href=\"https://doi.org/10.1111/psyp.14570\">https://doi.org/10.1111/psyp.14570</a> [<a href=\"https://doi.org/10.1101/2023.11.07.566051\">preprint</a>]</p><p class=\"\">Multivariate pattern analysis (MVPA) can be used to \u201cdecode\u201d subtle information from ERP signals, such as which of several faces a participant is perceiving or the orientation that someone is holding in working memory (see <a href=\"https://erpinfo.org/blog/2018/9/16/decoding\">this previous blog post</a>). This approach is so powerful that we started wondering whether it might also give us greater statistical power in more typical experiments where the goal is to determine whether an ERP component differs in amplitude across experimental conditions. For example, might we more easily be able to tell if N400 amplitude is different between two different classes of words by using decoding? If so, that might make it possible to detect effects that would otherwise be too small to be significant.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"688\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/08f353c7-f484-4e87-b5d3-a256fe1206e2/N170_ES.png?format=1000w\" width=\"971\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">To address this question, we compared decoding with the conventional ERP analysis approach with using the 6 experimental paradigms in the <a href=\"https://doi.org/10.18115/D5JW4R\">ERP CORE</a>. In the conventional ERP analysis, we measured the mean amplitude during the standard measurement window from each participant in the two conditions of the paradigm (e.g., faces versus cars for N170, deviants versus standards for MMN). We quantified the magnitude of the difference between conditions using Cohen\u2019s <em>dz</em> (the variant of Cohen\u2019s <em>d</em> corresponding to a paired <em>t</em> test). For example, the effect size in the conventional ERP comparison of faces versus cars in the N170 paradigm was approximately 1.7 (see the figure).</p><p class=\"\">We also applied decoding to each paradigm. For example, in the N170 paradigm, we trained a support vector machine (SVM) to distinguish between ERPs elicited by faces and ERPs elicited by cars. This was done separately for each subject, and we converted the decoding accuracy into Cohen\u2019s <em>dz</em> so that it could be compared with the <em>dz</em> from the conventional ERP analysis. As you can see from the bar labeled SVM in the figure above, the effect size for the SVM-based decoding analysis was almost twice as large as the effect size for the conventional ERP analysis. That\u2019s a huge difference!</p><p class=\"\">We found a similar benefit for SVM-based decoding over conventional ERP analyses in 7 of the 10 cases we tested (see the figure below). In the other 3 cases, the ERP and SVM effects were approximately equivalent. So, there doesn\u2019t seem to be a downside to using decoding, at least in terms of effect size. But there can be a big benefit.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1371\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/d16f0782-7205-4d50-95e1-c6729cbc153e/All_Components.png?format=1000w\" width=\"4641\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">Because decoding has many possible benefits, we\u2019ve added it into <a href=\"ERPLAB Toolbox\">ERPLAB Toolbox</a>. It\u2019s super easy to use, and we\u2019ve created <a href=\"https://erpinfo.org/blog/2023/6/23/decoding-webinar\">detailed documentation and a video</a> to explain how it works at a conceptual level and to show you how to use it.</p><p class=\"\">We encourage you to apply it to your own data. It may give you the power to detect effects that are too small to be detected with conventional ERP analyses.</p>",
      "author": "Steve Luck",
      "published_date": "2024-06-10T18:01:45+00:00",
      "source": "Erp Boot Camp",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 525,
      "reading_time": 2,
      "created_at": "2025-12-23T16:55:07.829282+00:00",
      "updated_at": "2025-12-23T16:55:07.829284+00:00"
    },
    {
      "id": "906f73f5c36ba087882a0ad17e01fc20",
      "url": "https://erpinfo.org/blog/2024/6/11/erplab-studio",
      "title": "New software package: ERPLAB Studio",
      "content": "<p class=\"\">We are excited to announce the release of a new EEG/ERP analysis package, <a href=\"https://github.com/ucdavis/erplab/releases\">ERPLAB Studio</a>. We think it\u2019s a huge improvement over the classic EEGLAB user interface. See our cheesy <a href=\"https://www.youtube.com/watch?v=lIaKVQ9DD6E\">\u201cadvertisement\u201d video</a> to get a quick overview. </p><p class=\"\">Rather than operating as an EEGLAB plugin, ERPLAB Studio is a standalone Matlab program that provides a more efficient and user-friendly interface to the most commonly used EEGLAB and ERPLAB routines.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1080\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/c874d4ec-5186-4de9-981b-58010c7a06e1/Interface.jpeg?format=1000w\" width=\"1920\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">With ERPLAB Studio, you automatically see the EEG or ERP waveforms as soon as you load a file. And as soon as you perform an operation, you see what the new EEG/ERP looks like. For example, when you filter the data, you immediately see the filtered waveforms.</p><p class=\"\">You can even select multiple datasets and apply an operation like artifact detection on all of them in one step. And then you can immediately see the results, such as which EEG epochs have been marked with artifacts.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1080\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/b45f514d-2d21-4a5a-8be6-f3a8ff99c388/Artifacts.jpeg?format=1000w\" width=\"1920\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">We give you access to EEGLAB\u2019s ICA-based artifact correction tools, but with a nice bonus. You can plot the ICA activations in the same window with the EEG data, making it easy to see which ICA components correspond to specific artifacts such as eyeblinks.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1080\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/8bc191da-9040-4042-ae9c-550cd98def7d/ICA.jpeg?format=1000w\" width=\"1920\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">The program has an EEG tab for processing continuous and epoched EEG data, and an ERP tab for processing averaged ERPs.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1080\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/84bdd9df-b02e-4fc5-83b9-1139a91938f5/Tabs.jpg?format=1000w\" width=\"1920\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">The automatic ERP plotting makes it easy for you to view the data laid out according to the electrode locations. And we have an Advanced Waveform Viewer that can make publication-quality plots.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1080\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/a932631f-fc30-415f-b11d-660d2bf90da5/ERP.jpeg?format=1000w\" width=\"1920\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">ERPLAB Studio is mainly just a new user interface. Under the hood, we\u2019re running the same EEGLAB and ERPLAB routines you\u2019ve always used. And scripting is identical.</p><p class=\"\">ERPLAB Studio is included in <a href=\"https://github.com/ucdavis/erplab/releases\">version 11 and higher of ERPLAB</a>. You simply follow our <a href=\"https://github.com/ucdavis/erplab/wiki/installation\">download/installation instructions</a> and then type estudio from the Matlab command line. </p><p class=\"\">If you\u2019re new to ERPLAB, we strongly recommend that you go through our <a href=\"https://github.com/ucdavis/erplab/wiki/ERPLAB-Studio-Tutorial\" target=\"_blank\">tutorial</a> before starting to process your own data. </p><p class=\"\">If you already know how to use the original version of ERPLAB (which we now call ERPLAB Classic), you can quickly learn how to use ERPLAB Studio with our <a href=\"https://ucdavis.box.com/s/i4jfv22gv6rj9t5obctuk6yaruxqomcc\">Transition Guide</a>.</p><p class=\"\">We also have a <a href=\"https://github.com/ucdavis/erplab/wiki/ERPLAB-Studio-Manual\">manual</a> that describes every feature in detail. </p>",
      "author": "Steve Luck",
      "published_date": "2024-06-12T02:02:16+00:00",
      "source": "Erp Boot Camp",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 444,
      "reading_time": 2,
      "created_at": "2025-12-23T16:55:07.829201+00:00",
      "updated_at": "2025-12-23T16:55:07.829202+00:00"
    },
    {
      "id": "79d603b3db5911be59b9e07e11acc674",
      "url": "https://erpinfo.org/blog/2024/6/28/recording-and-slides-now-available-for-erplab-studio-webinar",
      "title": "Recording and slides now available for ERPLAB Studio webinar",
      "content": "<p class=\"\">We held a webinar to demonstration ERPLAB Studio on 28 June 2024.</p><p class=\"\"><a href=\"https://youtu.be/k-nGv00rTP8\">Click here</a> to access a recording.</p><p class=\"\"><a href=\"https://ucdavis.box.com/s/4fseqz6327dtuouauj12rgvivy1d1nmo\">Click here </a>to access a PDF of the slides.</p>",
      "author": "Steve Luck",
      "published_date": "2024-06-28T22:21:45+00:00",
      "source": "Erp Boot Camp",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 30,
      "reading_time": 1,
      "created_at": "2025-12-23T16:55:07.829141+00:00",
      "updated_at": "2025-12-23T16:55:07.829143+00:00"
    },
    {
      "id": "e7f8dc252b6b560ce86af30ca863b092",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.21.695825v1?rss=1",
      "title": "Dendrite-targeting OLM interneurons regulate the formation of learning-related CA1 place cell representations",
      "content": "Spatial learning depends on the rapid formation of hippocampal CA1 place cell representations through behavioral timescale synaptic plasticity (BTSP). BTSP is driven by dendritic calcium plateau potentials in the distal apical dendrites of CA1 pyramidal neurons and is thought to arise from the interaction of an excitatory target signal from entorhinal cortex layer 3 (EC3) with inhibitory feedback reflecting the current CA1 population state. However, the cellular source of this feedback remains unknown. To identify this circuit element, we combined in vivo two-photon calcium imaging with bidirectional optogenetic manipulation to examine the role of dendrite-targeting oriens lacunosum-moleculare (OLM) interneurons. We found that axonal and somatic activity of OLM interneurons increased with learning and was spatially biased toward behaviorally salient locations, closely matching the evolving CA1 population representation and the environment-specific EC3 target signal. Causal manipulations revealed that optogenetic silencing of Chrna2alpha-positive OLM interneurons, a genetically defined OLM subset, late in learning increased dendritic plateaus and promoted place cell formation at stimulated locations, whereas activation of the same population early in learning suppressed plateau initiation and place field formation. Together, these findings identify OLM interneurons as the key inhibitory feedback element that dynamically regulates BTSP and stabilizes hippocampal representations during learning.",
      "author": "Campbell, E. P., Martin, L., Magee, J. C., Grienberger, C.",
      "published_date": "2025-12-23T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 200,
      "reading_time": 1,
      "created_at": "2025-12-23T16:29:50.755936+00:00",
      "updated_at": "2025-12-23T16:29:50.755940+00:00"
    },
    {
      "id": "306fa0568ad3a1d0b18ea23b14dcfd62",
      "url": "https://www.pnas.org/doi/abs/10.1073/pnas.2528602122?af=R",
      "title": "Synaptic integration and competition in the substantia nigra pars reticulata\u2014An experimental and in silico analysis",
      "content": "Proceedings of the National Academy of Sciences, Volume 122, Issue 52, December 2025. <br />SignificanceThe basal ganglia, in the forebrain, play a major role in determining when to move. The major output is via the substantia nigra pars reticulata (SNr), a small nucleus of inhibitory neurons that are spontaneously active and target motor ...",
      "author": "William Scott ThompsonJ. J. Johannes HjorthAlexander KozlovWilhelm ThunbergGilad SilberbergJeanette Hellgren KotaleskiSten GrillneraDepartment of Neuroscience, Karolinska Institutet, Stockholm 17165, SwedenbScience for Life Laboratory, Division of Computational Science and Technology, Royal Institute of Technology, Stockholm 10044, Sweden",
      "published_date": "2025-12-22T08:00:00+00:00",
      "source": "Pnas Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 54,
      "reading_time": 1,
      "created_at": "2025-12-23T16:29:44.453456+00:00",
      "updated_at": "2025-12-23T16:29:44.453458+00:00"
    },
    {
      "id": "a471c336db421632d74b241644b4787d",
      "url": "https://www.pnas.org/doi/abs/10.1073/pnas.2518159122?af=R",
      "title": "Preservation of anticorrelated brain networks predicts recovery after traumatic brain injury",
      "content": "Proceedings of the National Academy of Sciences, Volume 122, Issue 52, December 2025. <br />SignificanceHere, we identify a resting-state functional MRI (rs-fMRI) signature of recovery after moderate or severe traumatic brain injury (TBI): the preservation of functional anticorrelations. This signature accurately predicted functional outcomes ...",
      "author": "Samuel B. SniderHui ShiYelena G. BodienCalvin HowardXiaoying SunAlexandra J. GolbyKarl A. ZimmermanGuido BertoliniSandra MagnoniVincent DunetMauro OddoNeil S. N. GrahamEmma-Jane MallasFederico MoroPratik MukherjeeNancy R. TemkinSonia JainDavid J. SharpBrian L. EdlowMichael D. FoxaDivision of Neurocritical Care, Department of Neurology, Brigham and Women\u2019s Hospital, Boston, MA 02115bHarvard Medical School, Boston, MA 02115cCenter for Brain Circuit Therapeutics, Departments of Neurology, Psychiatry and Radiology, Brigham and Women\u2019s Hospital, Boston, MA 02115dDepartment Surgery, Vanderbilt University Medical Center, Nashville, TN 37212eDepartment of Neurological Surgery, Vanderbilt University Medical Center, Nashville, TN 37212fDepartment of Physical Medicine and Rehabilitation, Vanderbilt University Medical Center, Nashville, TN 37212gBiostatistics Research Center, Herbert Wertheim School of Public Health, University of California San Diego, San Diego, CA 92122hDepartment of Neurosurgery, Brigham and Women\u2019s Hospital, Boston, MA 27517iUnited Kingdom Dementia Research Institute, Care Research and Technology Centre, Imperial College London, London NW1 3BT, United KingdomjDepartment of Brain Sciences, Hammersmith Hospital, Imperial College London, London W12 0HS, United KingdomkHuman Experience Analysis and Design (HEAD) Lab, Dyson School of Design Engineering, Imperial College London, London SW7 2DB, United KingdomlDepartment of Medical Epidemiology, Istituto di Ricerche Farmacologiche Mario Negri IRCCS, Bergamo 24126, ItalymAnesthesiology and Pain Medicine Service, Department of Medicine, Surgery and Pharmacy, University of Sassari, Sassari 07100, ItalynRadiology Department, Lausanne University Hospital (CHUV), Lausanne 1011, SwitzerlandoClinical Research Center and Directorate of Innovation and Clinical Research, Lausanne University Hospital (CHUV), Faculty of Biology and Medicine, University of Lausanne, Lausanne 1011, SwitzerlandpDepartment of Acute Brain and Cardiovascular Injury, Istituto di Ricerche Farmacologiche Mario Negri Istituto di Ricovero e Cura a Carattere Scientifico, Milan 20156, ItalyqDepartment of Radiology, University of California San Francisco, San Francisco, CA 94143rDepartment of Neurological Surgery, University of Washington, Seattle, WA 98195sDepartment of Biostatistics, University of Washington, Seattle, WA 98195tThe Imperial Centre for Injury Studies, Imperial College London, London SW7 2AZ, United KingdomuCenter for Neurotechnology and Neurorecovery, Department of Neurology, Massachusetts General Hospital, Boston, MA 02114vAthinoula A. Martinos Center for Biomedical Imaging, Massachusetts General Hospital, Charlestown, MA 02129",
      "published_date": "2025-12-22T08:00:00+00:00",
      "source": "Pnas Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 45,
      "reading_time": 1,
      "created_at": "2025-12-23T16:29:44.453431+00:00",
      "updated_at": "2025-12-23T16:29:44.453433+00:00"
    },
    {
      "id": "8f83e9fb7739ed832776de2e50f7cd98",
      "url": "https://www.pnas.org/doi/abs/10.1073/pnas.2513375122?af=R",
      "title": "Multicolor photoreactions of the red light\u2013activated channelrhodopsin Chrimson",
      "content": "Proceedings of the National Academy of Sciences, Volume 122, Issue 52, December 2025. <br />SignificanceOptogenetics enables light control of specific cell types by expressing light-modulated channels and enzymes. Red-light-activated ion channels are of special interest, as red light penetrates deeper into brain tissue and allows multicolor ...",
      "author": "Johannes VierockJoel C. D. KaufmannLukas Fai\u00dfLinda TillertBenjamin S. KrausePaul FischerThi Bich Thao NguyenDietmar SchmitzBenjamin R. RostFranz BartlPeter HegemannaCharit\u00e9\u2013Universit\u00e4tsmedizin Berlin, Corporate Member of Freie Universit\u00e4t Berlin and Humboldt-Universit\u00e4t zu Berlin, Neurosciences Research Center, Berlin 10117, GermanybInstitute of Biology, Experimental Biophysics, Humboldt-Universit\u00e4t zu Berlin, Berlin 10115, GermanycInstitute of Biology, Biophysical Chemistry, Humboldt-Universit\u00e4t zu Berlin, Berlin 10115, GermanydGerman Center for Neurodegenerative Diseases, Berlin 10117, Germany",
      "published_date": "2025-12-22T08:00:00+00:00",
      "source": "Pnas Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 47,
      "reading_time": 1,
      "created_at": "2025-12-23T16:29:44.453399+00:00",
      "updated_at": "2025-12-23T16:29:44.453403+00:00"
    },
    {
      "id": "d19953af66119824ea075bdb93588484",
      "url": "https://stopslopware.net/",
      "title": "Stop Slopware",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46366285\">Comments</a>",
      "author": "",
      "published_date": "2025-12-23T15:51:17+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-23T16:29:09.799665+00:00",
      "updated_at": "2025-12-23T16:29:09.799669+00:00"
    },
    {
      "id": "d19953af66119824ea075bdb93588484",
      "url": "https://stopslopware.net/",
      "title": "Stop Slopware",
      "content": "<p>Article URL: <a href=\"https://stopslopware.net/\">https://stopslopware.net/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46366285\">https://news.ycombinator.com/item?id=46366285</a></p>\n<p>Points: 22</p>\n<p># Comments: 6</p>",
      "author": "bradley_taunt",
      "published_date": "2025-12-23T15:51:17+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-23T16:29:08.704014+00:00",
      "updated_at": "2025-12-23T16:29:08.704023+00:00"
    },
    {
      "id": "19393aecd74e811233e54b6dea640900",
      "url": "https://areweloongyet.com/en/",
      "title": "Are We Loong Yet?",
      "content": "<p>Article URL: <a href=\"https://areweloongyet.com/en/\">https://areweloongyet.com/en/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46363948\">https://news.ycombinator.com/item?id=46363948</a></p>\n<p>Points: 13</p>\n<p># Comments: 5</p>",
      "author": "todsacerdoti",
      "published_date": "2025-12-23T09:54:59+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-23T15:44:51.519544+00:00",
      "updated_at": "2025-12-23T16:21:13.349568+00:00",
      "metadata": {
        "processed_at": "2025-12-23T16:21:13.349578+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "4954934153b8439369ccb3a6a45ca7d0",
      "url": "https://arxiv.org/abs/2512.19156",
      "title": "Classical billiards can compute (2d billiard systems are Turing complete)",
      "content": "<p>Article URL: <a href=\"https://arxiv.org/abs/2512.19156\">https://arxiv.org/abs/2512.19156</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46363993\">https://news.ycombinator.com/item?id=46363993</a></p>\n<p>Points: 10</p>\n<p># Comments: 0</p>",
      "author": "nabla9",
      "published_date": "2025-12-23T10:05:00+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-23T15:23:20.448413+00:00",
      "updated_at": "2025-12-23T16:21:13.349582+00:00",
      "metadata": {
        "processed_at": "2025-12-23T16:21:13.349584+00:00",
        "processing_method": "github_actions"
      }
    }
  ]
}