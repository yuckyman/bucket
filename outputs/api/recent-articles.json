{
  "last_updated": "2025-10-24T04:43:43.494280+00:00",
  "count": 20,
  "articles": [
    {
      "id": "a07bb58009d0c700eba383662b3fed57",
      "url": "http://daniellakens.blogspot.com/2025/09/type-s-and-m-errors-as-rhetorical-tool.html",
      "title": "Type S and M errors as a \u201crhetorical tool\u201d",
      "content": "<p><i>Update 30/09/2025: I have added a reply by Andrew Gelman below my original blog post.</i>&nbsp;</p><p>We recently\nposted a preprint criticizing the idea of Type S and M errors (<a href=\"https://osf.io/2phzb_v1\">https://osf.io/2phzb_v1</a>). From our abstract:\n\u201cWhile these concepts have been proposed to be useful both when designing a\nstudy (prospective) and when evaluating results (retroactive), we argue that\nthese statistics do not facilitate the proper design of studies, nor the\nmeaningful interpretation of results.\u201d</p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">In a recent\n<a href=\"https://statmodeling.stat.columbia.edu/2025/09/25/on-the-poor-statistical-properties-of-the-p-curve-meta-analytic-procedure/#comment-2403979\" target=\"_blank\">blog post</a> that is mainly on p-curve analysis, Gelman writes briefly about Type\nS and M errors, stating that he does not see them as tools that should be used\nregularly, but that they mainly function as a \u2018rhetorical tool\u2019:</span></p>\n\n<p class=\"MsoNormal\"><i><span lang=\"EN-US\">I offer\na three well-known examples of statistical ideas arising in the field of\nscience criticism, three methods whose main value is rhetorical:</span></i></p>\n\n<p class=\"MsoNormal\"><i><span lang=\"EN-US\">[\u2026]</span></i></p>\n\n<p class=\"MsoNormal\"><i><span lang=\"EN-US\">2. The\nconcepts of Type M and Type S errors, which I developed with Francis Tuerlinckx\nin 2000 and John Carlin in 2014. This has been an influential idea\u2013ok, not as\ninfluential as Ioannidis\u2019s paper!\u2013and I like it a lot, but it doesn\u2019t\ncorrespond to a method that I will typically use in practice. To me, the value\nof the concepts of Type M and Type S errors is they help us understand certain\nexisting statistical procedures, such as selection on statistical significance,\nthat have serious problems. There\u2019s mathematical content here for sure, but I\nfundamentally think of these error calculations as having rhetorical value for\nthe design of studies and interpretation of reported results.</span></i></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">The main\nsentence of interest here is that Gelman says this is not a method he would use\nin practice. I was surprised, because in their article Gelman and Carlin (2014)\nrecommend the calculation of Type S and M errors more forcefully: \u201cWe suggest\nthat design calculations be performed after as well as before data collection\nand analysis.\u201d Throughout their article, they compare design calculations where\nType S and M errors are calculated to power analyses, which are widely seen as\na requirement before data collection of any hypothesis testing study. For\nexample, in the abstract they write \u201cpower analysis is flawed in that a narrow\nemphasis on statistical significance is placed as the primary focus of study\ndesign. In noisy, small-sample settings, statistically significant results can\noften be misleading. To help researchers address this problem in the context of\ntheir own studies, we recommend design calculations\u201d.</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">They also say\ndesign calculations are useful when interpreting results, and that they add\nsomething to p-values and effect sizes, which again seems to suggest they can complement\nordinary data analysis: \u201cOur retrospective analysis provided useful insight, beyond\nwhat was revealed by the estimate, confidence interval, and p value that came\nfrom the original data summary.\u201d (Gelman &amp; Carlin, 2014, p. 646). In\ngeneral, they seem to suggest design analyses are done before or after data analysis:\n\u201cFirst, it is indeed preferable to do a design analysis ahead of time, but a\nresearcher can analyze data in many different ways\u2014indeed, an important part of\ndata analysis is the discovery of unanticipated patterns (Tukey, 1977) so that it\nis unreasonable to suppose that all potential analyses could have been\ndetermined ahead of time. The second reason for performing postdata design\ncalculations is that they can be a useful way to interpret the results from a\ndata analysis, as we next demonstrate in two examples.\u201d (Gelman &amp; Carlin,\n2014, p. 643).</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">One the other\nhand, in a single sentence in the discussion, they also write: \u201cOur goal in\ndeveloping this software is not so much to provide a tool for routine use but\nrather to demonstrate that such calculations are possible and to allow\nresearchers to play around and get a sense of the sizes of Type S errors and Type\nM errors in realistic data settings.\u201d</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">Maybe I\nhave always misinterpreted Gelman and Carlin, 2014, in that I took it as a\npaper that recommended the regular use of Type S and M errors, and I should\nhave understood that the sentence in the discussion made it clear that this was\nnever their intention. If the idea is to replace Type 1 and 2 errors, and\nhence, replace power analysis and the interpretation of data, design analysis\nshould be part of every hypothesis testing study. Sentences such as \u201cthe\nrequirement of design analysis can stimulate engagement with the existing literature\nin the subject-matter field\u201d seemed to suggest to me that design analyses could\nbe a requirement for all studies. But maybe I was wrong. </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">Or maybe I\nwasn\u2019t. </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">In this <a href=\"https://statmodeling.stat.columbia.edu/2016/11/13/more-on-my-paper-with-john-carlin-on-type-m-and-type-s-errors/\">blog\npost</a>, Gelman writes: \u201cNow, one odd thing about my paper with Carlin is that\nit gives some tools that I recommend others use when designing and evaluating\ntheir research, but I would not typically use these tools directly myself!\nBecause I am not wanting to summarize inference by statistical significance.\u201d So,\nhere there seems to be the idea that others routinely use Type S and M errors. And\nin a very early version of the paper with Carlin, available <a href=\"https://statmodeling.stat.columbia.edu/wp-content/uploads/2016/11/retropower.pdf\">here</a>,\nthe opening sentence also suggests routine use: \u201cThe present article proposes\nan ideal that every statistical analysis be followed up with a power\ncalculation to better understand the inference from the data. As the quotations\nabove illustrate, however, our suggestion contradicts the advice of many\nrespected statisticians. Our resolution of this apparent disagreement is that\nwe perform retrospective power analysis in a different way and for a different\npurpose than is typically recommended in the literature.\u201d</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">Of course,\none good thing about science is that people change their beliefs about things.\nMaybe Gelman one time thought Type S and M errors should be part of \u2018every\nstatistical analysis\u2019 but now sees the tool mainly as a \u2018rhetorical device\u2019. And\nthat is perfectly fine. It is also good to know, because I regular see people\nwho suggest that Type S and M error should routinely be used in practice. I\nguess I can now point them to a blog post where Gelman himself disagrees with\nthat suggestion.</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">As we explain\nin our preprint, the idea of Type S errors is conceptually incoherent, and any\nprobabilities calculated will be identical to the Type 1 error in directional\ntests, or the false discovery rate, as all that Type S errors do is remove the\npossibility of an effect being 0 from the distribution, but this probability is\nitself 0. We also explain how other tools are better to educate researchers\nabout effect size inflation in studies selected for significance (for which\nGelman would recommend Type M errors), and we actually recommend p-uniform for\nthis, or just teaching people about critical effect sizes.</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">Personally,\nI don\u2019t like rhetorical tools. Although in our preprint we agree that teaching\nthe idea of Type S and M errors can be useful in education, there are also conceptually\ncoherent and practically useful statistical ideas that we can teach instead to\nachieve the same understanding. Rhetorical tools might be useful to convince\npeople who do not think logically about a topic, but I prefer to have a\nslightly higher bar for the scientists that I aim to educate about good\nresearch practices, and I think they are able to understand the problem of low\nstatistical power and selection bias without rhetorical tools. </span></p><p class=\"MsoNormal\"><span lang=\"EN-US\"><br /></span></p><div>--Reply by Andrew Gelman--</div><p class=\"MsoNormal\"><span lang=\"EN-US\"></span></p><div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">Hi, Daniel. &nbsp;Thanks for your comments. &nbsp;It's always good to see that people are reading our articles and blog posts. &nbsp;I think you are a little bit confused about what we wrote, but ultimately that's our fault for not being clear, so I appreciate the opportunity to clarify.</div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">So you don't need to consider this comment as a \"rebuttal\" to your post. &nbsp;For convenience I'll go through several of your statements one by one, but my goal is to clarify.</div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">First, I guess I should've avoided the word \"rhetorical.\" &nbsp;In my post, I characterized Ioannidis's 2005 claim, type M and S errors, and multiverse analysis as \"rhetorical tools\" that have been been useful in the field of science criticism but which I would not use in my own analyses. &nbsp;I could've added to this many other statistical methods including p-values and Bayes factors.</div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">When I describe a statistical method as \"rhetorical\" in this context, I'm not saying it's mathematically invalid or that it's conceptually incoherent (to use your term), nor am I saying these methods should not be used! &nbsp;All these tools can be useful; they just rely on very strong assumptions. &nbsp;P-values and Bayes factors are measures of evidence relative to a null hypothesis (not just an assumption that a particular parameter equals zero, but an entire set of assumptions about the data-generating process) that is irrelevant in the science and decision problems I've seen--but these methods are clearly defined and theoretically justified, and many practitioners get a lot out of them. &nbsp;I very rarely would use p-values or Bayes factors in my work because I'm very rarely interested in this sort of discrepancy from a null hypothesis.</div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">A related point comes up in my paper with Hill and Yajima, \"Why we (usually) don't have to worry about multiple comparisons\" (https://sites.stat.columbia.edu/gelman/research/published/multiple2f.pdf). &nbsp;Multiple comparisons corrections can be important, indeed I've criticized some published work for misinterpreting evidence by not accounting for multiple comparisons or multiple potential comparisons--but it doesn't come up so much in the context of multilevel modeling.</div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">Ioannidis (2005) is a provocative paper that I think has a lot of value--but you have to be really careful to try to directly apply such an analysis to real data. &nbsp; He's making some really strong assumptions! &nbsp;The logic of his paper is clear, though. &nbsp;O'Rourke and I discuss the challenges of moving from that sort of model to larger conclusions in our 2013 paper (https://sites.stat.columbia.edu/gelman/research/published/GelmanORourkeBiostatistics.pdf).</div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">The multiverse is a cool idea, and researchers have found it to be useful. &nbsp;The sociologists Cristobal Young and Erin Cumberworth recently published a book on it (https://www.cambridge.org/core/books/multiverse-analysis/D53C3AB449F6747B4A319174E5C95FA1). &nbsp;I don't think I'd apply the method in my own applied research, though, because the whole idea of the multiverse is to consider all the possible analyses you might have done on a dataset, and if I get to that point I'm more inclined to fit a multilevel model that subsumes all these analyses. &nbsp;I have found multiverse analysis to be useful in understanding research published by others, and maybe it would be useful for my own work too, given that my final published analyses never really include all the possibilities of what I might have done. &nbsp;The point is that this is yet another useful method that can have conceptual value even if I might not apply it to my own work. &nbsp;Again, the term \"rhetorical\" might be misleading, as these are real methods that, like all statistical methods, are appropriate in some settings and not in others.</div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">So please don't let your personal dislike of the term \"rhetorical tools\" to dissuade you from taking seriously the tools that I happen to have characterized as \"rhetorical,\" as these include p-values, multiple comparisons corrections, Bayesian analysis with point priors, and all sorts of other methods that are rigorously defined and can be useful in many applied settings, including some of yours!</div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">OK, now on to Type M and Type S errors. &nbsp;You seem to imply that at some time I thought that these \"should be part of \u2018every statistical analysis,'\" but I can assure you that I have never believed or written such a thing. &nbsp;You put the phrase \"every statistical analysis,\" but this is your phrase, not mine.</div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">One very obvious way to see that I never thought Type M and Type S errors \"should be part of \u2018every statistical analysis'\" is that, since the appearance of that article in 2014, I've published dozens of applied papers, and in only very few of these did I look at Type M and Type S errors.</div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">What is that? &nbsp;Why is it that my colleagues and I came up with this idea that has been influential, and which I indeed think can be very useful and which I do think should often be used by practitioners, but I only use it myself?</div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">The reason is that the focus of our work on Type M and Type S errors has been to understand selection on statistical significance (as in that notorious estimate that early childhood intervention increases adult earnings by 42% on average, but with that being the result of an inferential procedure that, under any reasonable assumptions, greatly overestimates the magnitude of any real effect; that is, Type M error). &nbsp;In my applied work it's very rare that I condition on statistical significance, and so this sort of use of Type M and S errors is not so relevant. &nbsp;So it's perfectly coherent for me to say that Type M and S error analysis is valuable in a wide range of settings that that I think these tools should be applied very widely, without believing that they should be part of \"every statistical analysis\" or that I should necessarily use them for my own analyses.</div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">That said, more recently I've been thinking that Type M and S errors are a useful approach to understanding statistical estimates more generally, not just for estimates that are conditioned on statistical significance. &nbsp;I'm working with Erik van Zwet and Witold Wi\u0119cek on applying these ideas to Bayesian inferences as well. &nbsp;So I'm actually finding these methods to be more, not less, valuable for statistical understanding, and not just for \"people who do not think logically about a topic\" (in your phrasing). &nbsp;Our papers on these topics are published in real journals and of course they're intended for people who &lt;em&gt;do&lt;/em&gt; think logically about the topic! &nbsp;And, just to be clear, I believe that you're thinking logically in your post too; I just think you've been misled by my terminology (again, I accept the blame for that), and also you work on different sorts of problems than I do, so it makes sense that a method that I find useful might not be so helpful to you. &nbsp;There are many ways to Rome, which is another point I was making in that blog post.</div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">Finally, a few things in your post that I did not address above:</div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">1. &nbsp;You quote from my blog post, where I wrote, \u201cNow, one odd thing about my paper with Carlin is that it gives some tools that I recommend others use when designing and evaluating their research, but I would not typically use these tools directly myself! Because I am not wanting to summarize inference by statistical significance.\u201d &nbsp;That's exactly my point above! &nbsp;You had it right there.</div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">2. &nbsp;You wrote, \"Maybe I have always misinterpreted Gelman and Carlin, 2014, in that I took it as a paper that recommended the regular use of Type S and M errors, and I should have understood that the sentence in the discussion made it clear that this was never their intention.\" &nbsp;So, just to clarify, yes in our paper we recommended the regular use of Type M and S errors, and we still recommend that!</div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">3. &nbsp;You write that our \"sentences such as 'the requirement of design analysis can stimulate engagement with the existing literature in the subject-matter field' seemed to suggest to me that design analyses could be a requirement for all studies.\" &nbsp;That's right--I actually do think that design analysis should be done for all studies!</div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">OK, nothing is done all the time. &nbsp;I guess that some studies are so cheap that there's no need for a design analysis--or maybe we could say that in such studies the design analysis is implicit. &nbsp;For example, if I'm doing A/B testing in a company, and they've done lots of A/B tests before, and I think the new effect will be comparable to previous things being studied, then maybe I just go with the same design as in previous experiments, without performing a formal design analysis. &nbsp;But one could argue that this corresponds to some implicit calculation.</div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">In any case, yeah, in general I think that a design analysis should come before any study. &nbsp;Indeed, that is what I tell students and colleagues: &nbsp;never collect data before doing a simulation study first. &nbsp;Often we do fake-data simulation after the data come in, to validate our model-fitting strategies, but for a while I've been thinking it's best to do it before.</div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">This is not controversial advice in statistics, to recommend a design analysis before gathering data! &nbsp;Indeed, in medical research it's basically a requirement. &nbsp;In our paper, Carlin and I argue--and I still believe--that a design analysis using Type M and S errors is more valuable than the traditional Type 1 and 2 errors. &nbsp;But in any case I consider \"design analysis\" to be the general term, with \"power analysis\" being a special case (design analysis looking at the probability of attaining statistical significance). &nbsp;I don't think traditional power analysis is useless--one way you can see this is that we demonstrate power calculations in chapter 16 of Regression and Other Stories, a book that came out several years after my paper with Carlin--; I just think it can be misleading, especially if it is done without consideration of Type M and S errors.</div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">Thanks again for your comments. &nbsp;It's good to have an opportunity to clarify my thinking, and these are important issues in statistics.</div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">P.S. &nbsp;If you see something on our blog that you disagree with, feel free to comment there directly, as that way you can also reach readers of the original post.</div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">--</div></div><p class=\"MsoNormal\"><span lang=\"EN-US\">References:&nbsp;</span></p><p class=\"MsoNormal\"><span lang=\"EN-US\"></span></p>Lakens, D., Cristian, Xavier-Quintais, G., Rasti, S., Toffalini, E., &amp; Alto\u00e8, G. (2025). Rethinking Type S and M Errors. OSF. <a href=\"https://doi.org/10.31234/osf.io/2phzb_v1\">https://doi.org/10.31234/osf.io/2phzb_v1</a><br /> <br />Gelman, A., &amp; Carlin, J. (2014). Beyond Power Calculations: Assessing Type S (Sign) and Type M (Magnitude) Errors. Perspectives on Psychological Science, 9(6), 641\u2013651. <a href=\"https://doi.org/10.1177/1745691614551642\">https://doi.org/10.1177/1745691614551642</a>",
      "author": "noreply@blogger.com (Daniel Lakens)",
      "published_date": "2025-09-28T05:19:00+00:00",
      "source": "Twenty Percent Statistician",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 3572,
      "reading_time": 17,
      "created_at": "2025-10-24T04:43:38.369285+00:00",
      "updated_at": "2025-10-24T04:43:38.369291+00:00"
    },
    {
      "id": "78a543035cc17e2ac6f73ecd95cce1ae",
      "url": "http://ieeexplore.ieee.org/document/10750441",
      "title": "Foundation Model for Advancing Healthcare: Challenges, Opportunities and Future Directions",
      "content": "Foundation model, trained on a diverse range of data and adaptable to a myriad of tasks, is advancing healthcare. It fosters the development of healthcare artificial intelligence (AI) models tailored to the intricacies of the medical field, bridging the gap between limited AI models and the varied nature of healthcare practices. The advancement of a healthcare foundation model (HFM) brings forth tremendous potential to augment intelligent healthcare services across a broad spectrum of scenarios. However, despite the imminent widespread deployment of HFMs, there is currently a lack of clear understanding regarding their operation in the healthcare field, their existing challenges, and their future trajectory. To answer these critical inquiries, we present a comprehensive and in-depth examination that delves into the landscape of HFMs. It begins with a comprehensive overview of HFMs, encompassing their methods, data, and applications, to provide a quick understanding of the current progress. Subsequently, it delves into a thorough exploration of the challenges associated with data, algorithms, and computing infrastructures in constructing and widely applying foundation models in healthcare. Furthermore, this survey identifies promising directions for future development in this field. We believe that this survey will enhance the community's understanding of the current progress of HFMs and serve as a valuable source of guidance for future advancements in this domain.",
      "author": "",
      "published_date": "2024-11-12T13:16:56+00:00",
      "source": "Reviews Biomedical Engineering",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 214,
      "reading_time": 1,
      "created_at": "2025-10-24T04:43:28.966340+00:00",
      "updated_at": "2025-10-24T04:43:28.966342+00:00"
    },
    {
      "id": "f3ebee0a159c29e785b8640ab568613e",
      "url": "http://ieeexplore.ieee.org/document/10729663",
      "title": "Data- and Physics-Driven Deep Learning Based Reconstruction for Fast MRI: Fundamentals and Methodologies",
      "content": "Magnetic Resonance Imaging (MRI) is a pivotal clinical diagnostic tool, yet its extended scanning times often compromise patient comfort and image quality, especially in volumetric, temporal and quantitative scans. This review elucidates recent advances in MRI acceleration via data and physics-driven models, leveraging techniques from algorithm unrolling models, enhancement-based methods, and plug-and-play models to the emerging full spectrum of generative model-based methods. We also explore the synergistic integration of data models with physics-based insights, encompassing the advancements in multi-coil hardware accelerations like parallel imaging and simultaneous multi-slice imaging, and the optimization of sampling patterns. We then focus on domain-specific challenges and opportunities, including image redundancy exploitation, image integrity, evaluation metrics, data heterogeneity, and model generalization. This work also discusses potential solutions and future research directions, with an emphasis on the role of data harmonization and federated learning for further improving the general applicability and performance of these methods in MRI reconstruction.",
      "author": "",
      "published_date": "2024-10-22T13:18:56+00:00",
      "source": "Reviews Biomedical Engineering",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 151,
      "reading_time": 1,
      "created_at": "2025-10-24T04:43:28.966301+00:00",
      "updated_at": "2025-10-24T04:43:28.966303+00:00"
    },
    {
      "id": "9e4ae40928a7fe025d996b5cfd67d530",
      "url": "https://www.sciencedirect.com/science/article/pii/S0006899325005347?dgcid=rss_sd_all",
      "title": "Astrocyte response in Alzheimer\u2019s disease: Good or bad?",
      "content": "<p>Publication date: 1 December 2025</p><p><b>Source:</b> Brain Research, Volume 1868</p><p>Author(s): Alaa Ismail, Hayder M. Al-kuraishy, Ali I. Al-Gareeb, Ali K. Albuhadily, Asmaa S.A. Yassen, Athanasios Alexiou, Marios Papadakis, Gaber El-Saber Batiha</p>",
      "author": "",
      "published_date": null,
      "source": "Brain Research",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 30,
      "reading_time": 1,
      "created_at": "2025-10-24T04:43:20.137600+00:00",
      "updated_at": "2025-10-24T04:43:20.137601+00:00"
    },
    {
      "id": "a77e3aacc0dbd4ff3d96224228a38e9e",
      "url": "https://www.nature.com/articles/s41598-025-20784-2",
      "title": "Alterations of multilayer network correlated with cognitive impairment and gene expression profiles in children with idiopathic generalized epilepsy",
      "content": "",
      "author": "",
      "published_date": "2025-10-22T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-10-24T04:43:14.510773+00:00",
      "updated_at": "2025-10-24T04:43:14.510774+00:00"
    },
    {
      "id": "6d3173f91794d6d4ba90155b9235d599",
      "url": "https://www.nature.com/articles/s41598-025-20811-2",
      "title": "Layered structure of cortex explains reversal dynamics in bistable perception",
      "content": "",
      "author": "",
      "published_date": "2025-10-22T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-10-24T04:43:14.510717+00:00",
      "updated_at": "2025-10-24T04:43:14.510718+00:00"
    },
    {
      "id": "9c25d04ef521d5290f3e3c5b56c62fde",
      "url": "https://www.nature.com/articles/s41593-025-02074-2",
      "title": "Oxytocin modulates respiratory heart rate variability through a hypothalamus\u2013brainstem\u2013heart neuronal pathway",
      "content": "<p>Nature Neuroscience, Published online: 20 October 2025; <a href=\"https://www.nature.com/articles/s41593-025-02074-2\">doi:10.1038/s41593-025-02074-2</a></p>Buron et al. show that oxytocin enhances heart rate variability linked to breathing during recovery from stress. This calming and cardio-protective effect is produced through a hypothalamus\u2013brainstem pathway for parasympathetic control of the heart.",
      "author": "Cl\u00e9ment Menuet",
      "published_date": "2025-10-20T00:00:00+00:00",
      "source": "Nature Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 42,
      "reading_time": 1,
      "created_at": "2025-10-24T04:43:13.468078+00:00",
      "updated_at": "2025-10-24T04:43:13.468080+00:00"
    },
    {
      "id": "37ac660fa3e93d92b389a395c0d2a045",
      "url": "https://www.nature.com/articles/s41593-025-02078-y",
      "title": "A lateral hypothalamic neuronal population expressing leptin receptors counteracts anxiety to enable adaptive behavioral responses",
      "content": "<p>Nature Neuroscience, Published online: 20 October 2025; <a href=\"https://www.nature.com/articles/s41593-025-02078-y\">doi:10.1038/s41593-025-02078-y</a></p>Figge-Schlensok et al. show that leptin-sensitive neurons in the lateral hypothalamus encode anxiogenic stimuli and facilitate adaptive strategies to enable an animal to overcome anxiety in threatening situations.",
      "author": "Tatiana Korotkova",
      "published_date": "2025-10-20T00:00:00+00:00",
      "source": "Nature Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 36,
      "reading_time": 1,
      "created_at": "2025-10-24T04:43:13.468054+00:00",
      "updated_at": "2025-10-24T04:43:13.468055+00:00"
    },
    {
      "id": "f7733bd8c0f09d6f965c7e3b8ba92493",
      "url": "https://www.nature.com/articles/s41593-025-02049-3",
      "title": "TDP-43 nuclear loss in FTD/ALS causes widespread alternative polyadenylation changes",
      "content": "<p>Nature Neuroscience, Published online: 21 October 2025; <a href=\"https://www.nature.com/articles/s41593-025-02049-3\">doi:10.1038/s41593-025-02049-3</a></p>Zeng et al. show that TDP-43, known for repressing cryptic exon usage in frontotemporal dementia/amyotrophic lateral sclerosis, also controls alternative polyadenylation, impacting expression of disease-linked genes (SFPQ, NEFL and TMEM106B).",
      "author": "Aaron D. Gitler",
      "published_date": "2025-10-21T00:00:00+00:00",
      "source": "Nature Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 38,
      "reading_time": 1,
      "created_at": "2025-10-24T04:43:13.468030+00:00",
      "updated_at": "2025-10-24T04:43:13.468032+00:00"
    },
    {
      "id": "c2df8e7504511f538f80093415d8b8e9",
      "url": "https://www.nature.com/articles/s41593-025-02050-w",
      "title": "TDP-43 loss induces cryptic polyadenylation in ALS/FTD",
      "content": "<p>Nature Neuroscience, Published online: 21 October 2025; <a href=\"https://www.nature.com/articles/s41593-025-02050-w\">doi:10.1038/s41593-025-02050-w</a></p>The authors find that TDP-43 loss of function\u2014the pathology defining the neurodegenerative conditions ALS and FTD\u2014induces novel mRNA polyadenylation events, which have different effects, including an increase in RNA stability, leading to higher protein levels.",
      "author": "Pietro Fratta",
      "published_date": "2025-10-21T00:00:00+00:00",
      "source": "Nature Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 43,
      "reading_time": 1,
      "created_at": "2025-10-24T04:43:13.468007+00:00",
      "updated_at": "2025-10-24T04:43:13.468009+00:00"
    },
    {
      "id": "9c2f2b52c6f0360f23e5e1d0623cf444",
      "url": "https://www.nature.com/articles/s41593-025-02065-3",
      "title": "TDP-43 loss brings RNA to a twist ending",
      "content": "<p>Nature Neuroscience, Published online: 21 October 2025; <a href=\"https://www.nature.com/articles/s41593-025-02065-3\">doi:10.1038/s41593-025-02065-3</a></p>In amyotrophic lateral sclerosis (ALS), nuclear depletion and cytoplasmic aggregation of the RNA-binding protein TDP-43 cause widespread dysregulation of mRNA splicing. Two recent studies have now revealed that loss of TDP-43 also affects mRNA 3\u2032 end cleavage and polyadenylation, further influencing mRNA metabolism and protein expression.",
      "author": "Junjie U. Guo",
      "published_date": "2025-10-21T00:00:00+00:00",
      "source": "Nature Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 54,
      "reading_time": 1,
      "created_at": "2025-10-24T04:43:13.467980+00:00",
      "updated_at": "2025-10-24T04:43:13.467983+00:00"
    },
    {
      "id": "c4bfc48ffa497341602baa2315c66f16",
      "url": "https://www.pnas.org/doi/abs/10.1073/pnas.2425388122?af=R",
      "title": "Functional organization of the primary motor cortex in psychosis and the potential role of intereffector regions in psychomotor slowing",
      "content": "Proceedings of the National Academy of Sciences, Volume 122, Issue 42, October 2025. <br />SignificanceRecent literature recommended a revision of the human motor homunculus to include, in addition to the primary motor cortex regions active during movement execution, intereffector regions orchestrating complex movement patterns. If ...",
      "author": "Sebastian WaltherFlorian W\u00fcthrichAnastasia PavlidouNiluja NadesalingamStephan HeckersMelanie G. NuofferVictoria ChapellierKatharina StegmayerLydia V. MaderthanerAlexandra KyrouSofie von K\u00e4nelStephanie LefebvreaUniversity Hospital of Psychiatry and Psychotherapy Bern, Translational Research Center, University of Bern, 3000 Bern, SwitzerlandbTranslational Imaging Center, Swiss Institute for Translational and Entrepreneurial Medicine, 3000 Bern, SwitzerlandcDepartment of Psychiatry, Psychosomatics, and Psychotherapy, Center of Mental Health, University Hospital of W\u00fcrzburg, 97080 W\u00fcrzburg, GermanydDepartment of Psychiatry and Behavioral Science, Vanderbilt University, Nashville, TN 37232eGraduate School for Health Sciences, University of Bern, 3000 Bern, SwitzerlandfUniversity Hospital Inselspital Bern, Department for Neurology, Psychosomatic Medicine, 3000 Bern, SwitzerlandgDepartment of Consultation-Liaison Psychiatry and Psychosomatic Medicine, University Hospital Zurich, University of Zurich, 8091 Zurich, Switzerland",
      "published_date": "2025-10-13T07:00:00+00:00",
      "source": "Pnas Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 46,
      "reading_time": 1,
      "created_at": "2025-10-24T04:43:09.908399+00:00",
      "updated_at": "2025-10-24T04:43:09.908401+00:00"
    },
    {
      "id": "f696dd0700cee6d33cee0d16412c334f",
      "url": "https://www.frontiersin.org/articles/10.3389/fninf.2025.1630133",
      "title": "Super-resolution microscopy and deep learning methods: what can they bring to neuroscience: from neuron to 3D spine segmentation",
      "content": "In recent years, advances in microscopy and the development of novel fluorescent probes have significantly improved neuronal imaging. Many neuropsychiatric disorders are characterized by alterations in neuronal arborization, neuronal loss\u2014as seen in Parkinson\u2019s disease\u2014or synaptic loss, as in Alzheimer\u2019s disease. Neurodevelopmental disorders can also impact dendritic spine morphogenesis, as observed in autism spectrum disorders and schizophrenia. In this review, we provide an overview of the various labeling and microscopy techniques available to visualize neuronal structure, including dendritic spines and synapses. Particular attention is given to available fluorescent probes, recent technological advances in super-resolution microscopy (SIM, STED, STORM, MINFLUX), and segmentation methods. Aimed at biologists, this review presents both classical segmentation approaches and recent tools based on deep learning methods, with the goal of remaining accessible to readers without programming expertise.",
      "author": "Lydia Danglot",
      "published_date": "2025-09-29T00:00:00+00:00",
      "source": "Frontiers Neuroinformatics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 130,
      "reading_time": 1,
      "created_at": "2025-10-24T04:43:08.818640+00:00",
      "updated_at": "2025-10-24T04:43:08.818642+00:00"
    },
    {
      "id": "ce2834ff6be8a78f6e4217922408aef3",
      "url": "https://www.frontiersin.org/articles/10.3389/fninf.2025.1655003",
      "title": "Early heart disease prediction using LV-PSO and Fuzzy Inference Xception Convolution Neural Network on phonocardiogram signals",
      "content": "IntroductionHeart disease is one of the leading causes of mortality worldwide, and early detection is crucial for effective treatment. Phonocardiogram (PCG) signals have shown potential in diagnosing cardiovascular conditions. However, accurate classification of PCG signals remains challenging due to high dimensional features, leading to misclassification and reduced performance in conventional systems.MethodsTo address these challenges, we propose a Linear Vectored Particle Swarm Optimization (LV-PSO) integrated with a Fuzzy Inference Xception Convolutional Neural Network (XCNN) for early heart risk prediction. PC G signals are analyzed to extract variations such as delta, theta, diastolic, and systolic differences. A Support Scalar Cardiac Impact Rate (S2CIR) is employed to capture disease specific scalar variations and behavioral impacts. LV-PSO is used to reduce feature dimensionality, and the optimized features are subsequently trained using the Fuzzy Inference XCNN model to classify disease types.ResultsExperimental evaluation demonstrates that the proposed system achieves superior predictive performance compared to existing models. The method attained a precision of 95.6%, recall of 93.1%, and an overall prediction accuracy of 95.8% across multiple disease categories.DiscussionThe integration of LV-PSO with Fuzzy Inference XCNN enhances feature selection aPSO with Fuzzy Inference XCNN enhances feature selection and nd classification accuracy, significantly improving the diagnostic capabilities of PCG-classification accuracy, significantly improving the diagnostic capabilities of PCG-based systems. These results highlight the potential of the proposed framework as a based systems. These results highlight the potential of the proposed framework as a reliable tool for early heart disease prediction and clinical decision support.reliable tool for early heart disease prediction and clinical decision support.",
      "author": "C. Palanisamy",
      "published_date": "2025-10-01T00:00:00+00:00",
      "source": "Frontiers Neuroinformatics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 254,
      "reading_time": 1,
      "created_at": "2025-10-24T04:43:08.818588+00:00",
      "updated_at": "2025-10-24T04:43:08.818597+00:00"
    },
    {
      "id": "a5df7a6f0b4e33c3671e617a5c4976d7",
      "url": "https://www.frontiersin.org/articles/10.3389/fncom.2025.1551555",
      "title": "Circuit-level modeling of prediction error computation of multi-dimensional features in voluntary actions",
      "content": "IntroductionPredictive processing posits that the brain minimizes discrepancies between internal predictions and sensory inputs, offering a unifying account of perception, cognition, and action. In voluntary actions, it is thought to suppress self-generated sensory outcomes. Although sensory mismatch signals have been extensively investigated and modeled, mechanistic insights into the neural computation of predictive processing in voluntary actions remain limited.MethodsWe developed a computational model comprising two-compartment excitatory pyramidal cells (PCs) and three major types of inhibitory interneurons with biologically realistic connectivity. The model incorporates experience-dependent inhibitory plasticity and feature selectivity to shape excitation-inhibition (E/I) balance. We then extended it to a two-dimensional prediction-error (PE) circuit in which each PC has two segregated, top-down modulated dendrites-each bell-tuned to a distinct feature-enabling combination selectivity.ResultsThe model reveals that top-down predictions can selectively suppress PCs with matching feature selectivity via experience-dependent inhibitory plasticity. This suppression depends on the response selectivity of inhibitory interneurons and on balanced excitation and inhibition across multiple pathways. The framework also accommodates predictions involving two independent features.DiscussionBy combining biological connectivity data with computational modeling, this study provides insights into the neural circuits and computations underlying the active suppression of sensory responses in voluntary actions. These findings contribute to understanding how the brain generates and processes predictions to guide behavior.",
      "author": "Yiling Li",
      "published_date": "2025-09-29T00:00:00+00:00",
      "source": "Frontiers Computational Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 207,
      "reading_time": 1,
      "created_at": "2025-10-24T04:43:07.497797+00:00",
      "updated_at": "2025-10-24T04:43:07.497799+00:00"
    },
    {
      "id": "613a712795cae89d04b5c7e3674d9877",
      "url": "https://www.frontiersin.org/articles/10.3389/fnbot.2025.1590994",
      "title": "Adaptive-expert-weight-based load balance scheme for dynamic routing of MoE",
      "content": "Load imbalance is a major performance bottleneck in training mixture-of-experts (MoE) models, as unbalanced expert loads can lead to routing collapse. Most existing approaches address this issue by introducing auxiliary loss functions to balance the load; however, the hyperparameters within these loss functions often need to be tuned for different tasks. Furthermore, increasing the number of activated experts tends to exacerbate load imbalance, while fixing the activation count can reduce the model\u2019s confidence in handling difficult tasks. To address these challenges, this paper proposes a dynamically balanced routing strategy that employs a threshold-based dynamic routing algorithm. After each routing step, the method adjusts expert weights to influence the load distribution in the subsequent routing. Unlike loss-function-based balancing methods, our approach operates directly at the routing level, avoiding gradient perturbations that could degrade model quality, while dynamically routing to make more efficient use of computational resources. Experiments on Natural Language Understanding (NLU) benchmarks demonstrate that the proposed method achieves accuracy comparable to top-2 routing, while significantly reducing the load standard deviation (e.g., from 12.25 to 1.18 on MNLI). In addition, threshold-based dynamic expert activation reduces model parameters and provides a new perspective for mitigating load imbalance among experts.",
      "author": "Peng Cheng",
      "published_date": "2025-10-14T00:00:00+00:00",
      "source": "Frontiers Neurorobotics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 197,
      "reading_time": 1,
      "created_at": "2025-10-24T04:43:04.720871+00:00",
      "updated_at": "2025-10-24T04:43:04.720873+00:00"
    },
    {
      "id": "1fdc9c034ba7d50cf3c15378119e3360",
      "url": "http://iopscience.iop.org/article/10.1088/1741-2552/ae0c3b",
      "title": "Development of novel signal and spike velocity analysis tools in compact peripheral nerve recording designs",
      "content": "Objective. Analysis tools for peripheral nerve recordings remain underdeveloped compared to those for brain signals, limiting the advancement of nerve neurotechnologies for clinical treatments such as closed-loop systems. This study introduces and explores the performance of two novel nerve signal analysis techniques\u2014cross-correlation analysis and spike delay velocity analysis\u2014which rely on a defining feature of peripheral nerve signals: the reliable conduction velocity of signals transmitted by axons in nerves. Approach. We test the capabilities of the introduced cross-correlation and spike delay velocity analysis techniques both in silico on synthetic nerve signals and on in vivo nerve signals acquired from freely-moving rats. Main results. Our findings show that both techniques can be successfully employed to extract transmission direction and velocity information from compact two-electrode site peripheral nerve recording designs. Notably, cross-correlation analysis can be employed to detect neural signals of very low signal-to-noise ratio, otherwise undetectable by typical spike detection approaches. Significance. Our findings provide new techniques to both enhance detection and extract new information in the form of velocity data from nerve recordings using a compact two-electrode site recording setup. Unlike traditional methods, this design eliminates the need for long electrode arrays, making it particularly well-suited for use in freely-moving animal models and translational applications. As axon signal conduction direction and velocity are tightly linked to neural function, these techniques can support new research into peripheral nervous system function and new therapeutic approaches driven by neural interfaces.",
      "author": "Jonas Klus, Alexander J Boys, Ruben Ruiz-Mateos Serrano, George G Malliaras and Alejandro Carnicer-Lombarte",
      "published_date": "2025-10-14T23:00:00+00:00",
      "source": "Journal Neural Engineering",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 236,
      "reading_time": 1,
      "created_at": "2025-10-24T04:43:01.855277+00:00",
      "updated_at": "2025-10-24T04:43:01.855278+00:00"
    },
    {
      "id": "1d47258436da451679f96de15c01acc3",
      "url": "http://iopscience.iop.org/article/10.1088/1741-2552/ae0c3a",
      "title": "BGTransform: a neurophysiologically informed EEG data augmentation framework",
      "content": "Objective. Deep learning has emerged as a powerful approach for decoding electroencephalography (EEG)-based brain\u2013computer interface (BCI) signals. However, its effectiveness is often limited by the scarcity and variability of available training data. Existing data augmentation methods often introduce signal distortions or lack physiological validity. This study proposes a novel augmentation strategy designed to improve generalization while preserving the underlying neurophysiological structure of EEG signals. Approach. We propose Background EEG Transform (BGTransform), a principled data augmentation framework that leverages the neurophysiological dissociation between task-related activity and ongoing background EEG. In contrast to existing methods, BGTransform generates new trials by selectively perturbing the background EEG component while preserving the task-related signal, thus enabling controlled variability without compromising class-discriminative features. We applied BGTransform to three publicly available EEG-BCI datasets spanning steady-state visual evoked potential and P300 paradigms. The effectiveness of BGTransform is evaluated using several widely adopted neural decoding models under three training regimes: (1) without augmentation (baseline model), (2) with conventional augmentation methods, and (3) with BGTransform. Main results. Across all datasets and model architectures, BGTransform consistently outperformed both baseline models and conventional augmentation techniques. Compared to models trained without BGTransform, it achieved average classification accuracy improvements of 2.45%\u201315.52%, 4.36%\u201317.15% and 7.55%\u201310.47% across the three datasets, respectively. In addition, BGTransform demonstrated greater robustness across subjects and tasks, maintaining stable performance under varying recording conditions. Significance. BGTransform provides a principled and effective approach to augmenting EEG data, informed by neurophysiological insight. By preserving task-related components and introducing controlled variability, the method addresses the challenge of data sparsity in EEG-BCI training. These findings support the utility of BGTransform for improving the accuracy, robustness, and generalizability of deep learning models in neural engineering applications.",
      "author": "Jin Yue, Xiaolin Xiao, Hao Zhang, Minpeng Xu and Dong Ming",
      "published_date": "2025-10-14T23:00:00+00:00",
      "source": "Journal Neural Engineering",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 279,
      "reading_time": 1,
      "created_at": "2025-10-24T04:43:01.855237+00:00",
      "updated_at": "2025-10-24T04:43:01.855239+00:00"
    },
    {
      "id": "6ca8a706922679823be8498ca03bd8d5",
      "url": "http://iopscience.iop.org/article/10.1088/1741-2552/ae0bf6",
      "title": "Using economic value signals from primate prefrontal cortex in neuro-engineering applications",
      "content": "Objective. Brain\u2013machine interface (BMI) research has shown the efficacy of using motor and sensory-related neural signals to assist physically impaired patients. Despite the comparable ability to extract more abstract cognitive signals from the brain, little effort has been devoted to leveraging these signals in neuro-engineering applications. In this study, we explore the use of neural signals related to economic value, a key cognitive construct, in a BMI context. Approach. Using multivariate time series data collected from the orbitofrontal cortex in non-human primates, we develop deep learning-based neural decoders to predict the monkeys\u2019 choices in a value-based decision-making task. We implement a reinforcement learning-based training approach to develop adaptive decoders that can be extended to handle multi-step decisions, which frequently arise in real-world settings. Main results. We develop neural decoders leveraging subjective value signals to predict the monkeys\u2019 choices with accuracy on average, with above-chance accuracy even when choice options are objectively equal. We show that this same decoder architecture can be trained to execute choice-related actions and execute action sequences aligned with the user\u2019s goal. Finally, we explore a decoder architecture that uses a neural forecasting model equipped with task-related information, and show that it makes high accuracy predictions \u2009ms sooner than would otherwise be possible. Significance. These findings support the feasibility of user preference-informed neuro-engineering devices that leverage abstract cognitive signals to aid users in goal-directed behavior. They suggest that using abstract cognitive signals in real-world settings may be more accurate when combined with information from multiple sources, such as motor and sensory regions. This research also highlights the potential need for systems to measure their confidence in their actions when user input is minimal.",
      "author": "Tevin C Rouse, Shira M Lupkin and Vincent B McGinty",
      "published_date": "2025-10-14T23:00:00+00:00",
      "source": "Journal Neural Engineering",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 276,
      "reading_time": 1,
      "created_at": "2025-10-24T04:43:01.855191+00:00",
      "updated_at": "2025-10-24T04:43:01.855192+00:00"
    },
    {
      "id": "ca6637ea4338d58ff9cd31ce4b61cf91",
      "url": "http://iopscience.iop.org/article/10.1088/1741-2552/ae0521",
      "title": "Inter-ictal spike rates are not modulated by anti-seizure medication taper in the epilepsy monitoring unit: a tale of two confounders *",
      "content": "Objective. New implantable and wearable devices hold great promise to help patients manage their seizure disorders. One proposed application is measuring the rate of interictal epileptiform discharges as a biomarker of medication levels and seizure risk. This study aims to determine whether interictal epileptiform spike rates (spikes) are independently associated with anti-seizure medication (ASM) levels and evaluate whether spike rates are a reliable biomarker for ASM levels. Approach. We conducted a retrospective analysis of 69 patients with drug resistant epilepsy undergoing intracranial EEG monitoring during ASM taper in the epilepsy monitoring unit. An automated spike detection algorithm, validated seizure annotations, and a model of ASM load were used to assess the relationship between spike rates, ASM level, state of consciousness, and seizure timing using linear mixed effects models. Event related analysis and seasonal autoregressive models were applied to evaluate both short-term and longer-term effects of ASMs on spike rates, respectively. Main Results. Spike rates were found to increase following seizures, during sleep, and in patients experiencing early seizures, with no significant association between ASM load and spike rates after controlling for these confounders. Initial models without controls showed a positive association between ASM load and spike rates. However, this relationship disappeared when the effects of sleep and seizures were accounted for. Medication-specific analysis revealed that only levetiracetam showed a significant impact on spike rates during taper. Significance. This study demonstrates that interictal spike rates are more strongly influenced by seizure activity and sleep than by ASM levels, suggesting limited utility of spike rates as a biomarker for ASM load. However, spikes may still serve as important markers for seizure control and disease severity.",
      "author": "Nina J Ghosn, Katherine Walsh, Kevin Xie, Carlos Aguila, Akash R Pattnaik, Devin Ma, Abba M Krieger, Erin C Conrad and Brian Litt",
      "published_date": "2025-10-14T23:00:00+00:00",
      "source": "Journal Neural Engineering",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 273,
      "reading_time": 1,
      "created_at": "2025-10-24T04:43:01.855147+00:00",
      "updated_at": "2025-10-24T04:43:01.855148+00:00"
    }
  ]
}