{
  "last_updated": "2025-12-04T20:18:21.820529+00:00",
  "count": 20,
  "articles": [
    {
      "id": "f5723c8b1453705984d37ffe2f0cc535",
      "url": "https://www.jeffgeerling.com/blog/2025/ram-shortage-comes-us-all",
      "title": "The RAM Shortage Comes for Us All",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46151578\">Comments</a>",
      "author": "",
      "published_date": "2025-12-04T19:16:11+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-04T19:40:31.344832+00:00",
      "updated_at": "2025-12-04T20:18:21.706730+00:00",
      "metadata": {
        "processed_at": "2025-12-04T20:18:21.706739+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "f5723c8b1453705984d37ffe2f0cc535",
      "url": "https://www.jeffgeerling.com/blog/2025/ram-shortage-comes-us-all",
      "title": "The RAM Shortage Comes for Us All",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46151578\">Comments</a>",
      "author": "",
      "published_date": "2025-12-04T19:16:11+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-04T19:40:31.344832+00:00",
      "updated_at": "2025-12-04T20:18:21.706730+00:00",
      "metadata": {
        "processed_at": "2025-12-04T20:18:21.706739+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "a8ae29db847401bc5f4b0b48dfe56574",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.03.692134v1?rss=1",
      "title": "An extended structure of the intracellular domain of the Torpedo nicotinic acetylcholine receptor and its proposed interactions with rapsyn",
      "content": "To gain insight into the interactions between rapsyn and the nAChR that induce clustering at the post-synaptic membrane, we refined a cryo-EM dataset using an intracellular domain focused strategy to obtain a 3.0 [A] map with the most extensive density yet for the intracellular domain of the Torpedo nAChR. The improved map allowed us to extend the structure beyond the MX -helix and prior to the MA -helix of the intracellular domain. The new structure defines a sharp N-terminal boundary of each MA -helix to place agrin-dependent phosphorylated tyrosines unambiguously within the flexible regions of the MX-MA loops. Two distinct conformations of the {delta} M4 -helix were also resolved, indicating that M4 conformational heterogeneity reflects intrinsic flexibility rather than a change in gating state. The new structural constraints defined for the MX-MA loop were then used to evaluate AlphaFold3-predicted full-length models of the nAChR, rapsyn, and various rapsyn-nAChR complexes, identifying a consistent, asymmetric 3:1 binding architecture where each rapsyn is always sandwiched between the MX-MA loops from two subunits and where each phospho-tyrosine is lodged in a cationic pocket formed by conserved residues implicated in congenital myasthenic syndromes. The defined architecture fits published cryo-ET maps of Torpedo post-synaptic membranes and explains how both phosphorylated tyrosines and myasthenic syndrome-causing rapsyn mutations modulate receptor clustering.",
      "author": "Henault, C. M., Habes, M., Tessier, C. J. G., Baenziger, J. E.",
      "published_date": "2025-12-04T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 213,
      "reading_time": 1,
      "created_at": "2025-12-04T19:20:00.141203+00:00",
      "updated_at": "2025-12-04T20:18:21.706748+00:00",
      "metadata": {
        "processed_at": "2025-12-04T20:18:21.706750+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "77f136d75c2c4ffa4143e2bf4d4d94cb",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.03.692036v1?rss=1",
      "title": "A paradoxical impact of alcohol on sleep-memory coupling",
      "content": "Sleep serves a fundamental role in memory consolidation, and yet it must adapt to the organism's physiological state. Acute ethanol consumption has a profound impact on animal physiology, but whether intoxication affects the role of sleep in memory consolidation remains unexplored. We demonstrate that acute ethanol exerts a paradoxical dual impact on sleep-memory coupling in Drosophila. Typically, satiated flies require sleep for memory consolidation, but starved flies that must forage for food switch to sleep-independent memory. Ethanol selectively impairs memory consolidation in satiated flies, whereas memories in starved flies remain intact despite intoxication. The observed impairment in satiated flies is due to a switch to sleep-independent memory, which then can't be supported because of ethanol-induced sedation. Mechanistically, the ethanol-induced switch to sleep-independent memory is driven by neuropeptide F-mediated modulation of dopamine signaling. These findings reveal that ethanol intoxication inverts the canonical function of sleep, wherein it becomes detrimental to memory consolidation.",
      "author": "Chouhan, N. S., Mitra, W., Singh, K., Sehgal, A.",
      "published_date": "2025-12-04T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 151,
      "reading_time": 1,
      "created_at": "2025-12-04T19:20:00.141168+00:00",
      "updated_at": "2025-12-04T20:18:21.706752+00:00",
      "metadata": {
        "processed_at": "2025-12-04T20:18:21.706753+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "6223fae52b1321c461ec0a8992425e72",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.02.691969v1?rss=1",
      "title": "Genetic rescue of disrupted synaptic protein interaction network dynamics following SYNGAP1 reactivation",
      "content": "Synaptic protein interaction networks (PINs) dynamically translate neural activity into biochemical signals that regulate synaptic structure and plasticity. Disruption of these coordinated networks is a common feature of autism spectrum disorder (ASD) risk genes, yet it remains unclear whether the molecular organization of a perturbed network can be restored after development. Here, we examined how post-developmental re-expression of the synaptic Ras GTPase-activating protein SynGAP1 affects network structure and signaling dynamics in a conditional SynGAP1 haploinsufficient mouse. Quantitative multiplex co-immunoprecipitation (QMI) across development revealed that SynGAP haploinsufficiency selectively reduced SynGAP-containing complexes without broadly disrupting NMDA-dependent network responses. Tamoxifen-inducible re-expression of SynGAP at postnatal day 21 fully restored both steady-state and activity-dependent interactions within the SynGAP module in hippocampus, and additionally normalized secondary alterations in Shank-Homer scaffolding complexes in somatosensory cortex. These data demonstrate that biochemical restoration of a disrupted synaptic network is achievable, even after early developmental windows have closed. Our findings suggest that while critical periods may constrain functional recovery, molecular network normalization remains possible through genetic reactivation of haploinsufficient synaptic regulators.",
      "author": "Stamenkovic, V., Harsh, F. M., Kniffen, B., Rumbaugh, G. R., Smith, S. E. P.",
      "published_date": "2025-12-04T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 172,
      "reading_time": 1,
      "created_at": "2025-12-04T19:20:00.141137+00:00",
      "updated_at": "2025-12-04T20:18:21.706756+00:00",
      "metadata": {
        "processed_at": "2025-12-04T20:18:21.706757+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "4bd7c15d04f4740db1f4c58ccf20ed6c",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.02.691416v1?rss=1",
      "title": "Real-life ear-EEG Recordings of Auditory Responses to Ambient Sounds",
      "content": "Despite being one of the most researched neural responses, auditory potentials have primarily been measured in controlled laboratory environments. However, there is a big interest in measuring auditory potentials in more naturalistic environments, with stimuli resembling, to a higher degree, natural sounds. The objective of this study is to investigate auditory evoked potentials elicited by naturally occurring sounds in real-life environments. The paper presents an integration of a portable hearing aid research platform and a portable ear-EEG platform. This setup was validated through recordings of an Auditory Steady State Response (ASSR), elicited by real-time amplitude modulation of the ambient sound at 40Hz. Recordings were conducted in real-life under three conditions: walking and sitting with open and closed eyes. In addition to ear-EEG, scalp EEG was recorded as a reference. For analysis, EEG signals were categorized into three groups: scalp channels, cross-ear channels, and within-ear channels. For each condition and channel group, the signal-to-noise (SNR) of the ASSR was calculated. The ASSR was statistically significant across all channel groups and conditions. A post-hoc analysis assessed the recording duration required to obtain a significant ASSR, revealing that 10 minutes were enough for within ear ear-EEG for all but two cases, whereas less than 7 minutes were sufficient for all but one case when using scalp-EEG.",
      "author": "Comoglio, J., Duan, B., Rands Bertelsen, A., Lind Kappel, S., Kidmose, P.",
      "published_date": "2025-12-04T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 213,
      "reading_time": 1,
      "created_at": "2025-12-04T19:20:00.141104+00:00",
      "updated_at": "2025-12-04T19:20:00.141105+00:00"
    },
    {
      "id": "ee6689d14a3252c6e13a0e7cf9654d7e",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.02.691389v1?rss=1",
      "title": "Asymmetrical modulation of fear expression via GABAB receptors in the mouse medial habenula",
      "content": "The medial habenula (MHb) is implicated in regulating emotional responses to aversive events. Studies in zebrafish have identified a remarkable morphological left-right asymmetry in the dorsal habenula (zebrafish equivalent of mammalian MHb) to interpeduncular nucleus (IPN) pathway and its left-sided-specific role in modulating fear responses. However, there is little evidence for structural or functional lateralization in the mammalian MHb-IPN pathway. Here, we investigated the synaptic properties of left- and right-MHb afferents to the IPN and their roles in the expression of conditioned fear in mice. We found that each IPN neuron receives inputs from both left and right MHb, but the left MHb-originating synapses exhibit lower release probability and higher {gamma}-aminobutyric acid type B receptor (GABABR)-mediated potentiation compared to the right MHb-originating synapses. Interestingly, these asymmetrical properties persist in the inversus visceral mutant mice with normal laterality of the internal organs (situs solitus), but nearly disappear in those with reversed internal organ laterality (situs inversus). Behaviorally, chemogenetic inhibition of cholinergic neurons and conditional deletion of GABABR in the left, but not the right, MHb significantly attenuated cue-dependent fear recall. Our results demonstrate functional asymmetry of the MHb under partial influence of the nodal flow in mice, revealing a predominant role of GABABR-mediated signaling in the left MHb-IPN pathway in modulating fear memories. These findings suggest that lateralized MHb pathways could represent a fundamental principle in the neural regulation of emotion across species, but that they develop differently in zebrafish and mice.",
      "author": "O\u0308nal, C., Koppensteiner, P., Muhia, M., Le Monnier, E., Shigemoto, R.",
      "published_date": "2025-12-04T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 241,
      "reading_time": 1,
      "created_at": "2025-12-04T19:20:00.141069+00:00",
      "updated_at": "2025-12-04T19:20:00.141070+00:00"
    },
    {
      "id": "5bae27180843a2827b1e22f3a291e872",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.02.691796v1?rss=1",
      "title": "Theta activity in the RSC anchors space to the body cardinal axes",
      "content": "Understanding human navigation in ecological, freely moving conditions requires uncovering how the brain anchors directional representations to the 's orientation. Using high-density mobile electroencephalography and immersive virtual reality during goal-directed whole-body rotations, we found that theta bursts reconstructed in the retrosplenial complex (RSC) encode both acceleration and alignment with the body's principal axes. Crucially, this body-axis-anchored neural signal emerged only during goal-directed rotations, and its strength correlated with individual navigation performance, suggesting an adaptive mechanism which provides a stable egocentric scaffold for orientation. These results provide compelling evidence for a self-motion-gated, body-centered reference frame that supports efficient navigation, and bridge the gap between static neuroimaging findings in humans and rodent research on RSC geometry codes. Overall, our findings advance an embodied, mechanistic account of human navigation, opening new avenues for investigating brain dynamics in naturalistic, movement-rich settings using non-invasive neural recordings.",
      "author": "Naveilhan, C., Ramanoel, S.",
      "published_date": "2025-12-04T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 141,
      "reading_time": 1,
      "created_at": "2025-12-04T19:20:00.141030+00:00",
      "updated_at": "2025-12-04T19:20:00.141032+00:00"
    },
    {
      "id": "8364f686dcde52fd6c2effbbcb86cc88",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.02.691797v1?rss=1",
      "title": "Combining membrane potential and calcium imaging in brain slices using the voltage sensitive dye ElectroFluor630 and the calcium indicator Calbryte520",
      "content": "Wide-field imaging from brain slices stained with a voltage sensitive dye (VSD) and simultaneously loaded with a Ca2+ indicator allows investigating neuronal excitability and synaptic transmission at multi-cellular scale. So far, achieving this type of combined imaging has been limited by experimental constraints. We assessed the ability of the red-IR emitting VSD ElectroFluor630 (EF-630) to be combined with blue-excitable green-emitting Ca2+ indicators to record signals elicited by electrical stimulation in hippocampal slices. Transversal mouse hippocampal slices were stained with EF-630. Ca2+ indicators, either Fluo-4, Fluo-8, Cal520 or Calbryte520, were loaded using their AM-ester forms. Fluorescence, during stimulation of the CA3 region was imaged at 5 kHz from hippocampal areas of [~]750X250 square microns at 1 micron pixel resolution. After assessing all Ca2+ indicators, we selected Calbryte520 for achieving >30 minutes stable recordings in combination with EF-630. Action potentials and related Ca2+ transients were detected in the CA3 stimulated area whereas synaptic signals were observed in the CA1 region. On these signals, we tested the pharmacological blockade of either action potentials or glutamatergic synaptic potentials. We report novel optical measurements of both electrical and Ca2+ transients in brain slices, providing unique information on neuronal excitability and network activity.",
      "author": "Canepari, M., Ghasemiform, S.",
      "published_date": "2025-12-04T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 197,
      "reading_time": 1,
      "created_at": "2025-12-04T19:20:00.140998+00:00",
      "updated_at": "2025-12-04T19:20:00.141000+00:00"
    },
    {
      "id": "bbcbe5e6b581ced5d03122393d938430",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.02.691546v1?rss=1",
      "title": "Beyond Inheritance: De novo Fast Motion Computation in Primate Visual Cortex",
      "content": "Objects move through space and time, generating sequential visuotopic activations in all sighted animals leading to motion perception of velocity defined by direction and speed. Humans can effortlessly see motion with speeds ranging from 0.25 to 500deg/s. However, direction-selective neurons in the primary visual cortex (V1)-from which all subsequent processing is presumed to derive-only encode directionality at low speeds. To resolve this paradox, we recorded neuronal responses to moving dots, gratings, and movies across the LGN, V1, MT and MST of the macaque motion pathway. Regardless of cell type and motion stimuli, V1 neurons lost direction selectivity at ~29deg/s while MT and MST neurons maintained it up to ~82deg/s and ~183deg/s, respectively. A cascaded spatiotemporal integration model reveals that at each cortex direction-selective neurons can generate velocity selectivity de novo, by integrating sequential visuotopic activations from preceding areas, irrespective of speed and directionality. By computing velocity anew, the primate brain effectively uses the cortical hierarchy itself to 'shift gears' to efficiently encode slow and fast motion. Thus, five visual areas from the retina into the brain's processing hierarchy, external spatiotemporal information is being computed afresh, offering insights for motion processing in other species, modalities and machine vision.",
      "author": "He, K., Liu, L., Luo, J., Lu, Y., Yin, J., Liu, Y., Xie, W., Li, Y., Li, X., Andolina, I. M., Shipp, S., Yu, H., Wang, Y., Xing, D., McLoughlin, N., Wang, W.",
      "published_date": "2025-12-04T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 197,
      "reading_time": 1,
      "created_at": "2025-12-04T19:20:00.140956+00:00",
      "updated_at": "2025-12-04T19:20:00.140961+00:00"
    },
    {
      "id": "4b8fb847883ba36d507827a77b9eb441",
      "url": "https://www.reddit.com/r/Python/comments/1pe1cm1/built_an_opensource_app_to_convert_linkedin/",
      "title": "Built an open-source app to convert LinkedIn -> Personal portfolio generator using FastAPI backend",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>I was always too lazy to build and deploy my own personal website. So, I built an app to convert a LinkedIn profile (via PDF export) or GitHub profile into a personal portfolio that can be deployed to Vercel in one click.</p> <p>Here are the details required for the showcase:</p> <p><strong>What My Project Does</strong> It is a full-stack application where the backend is built with <strong>Python FastAPI</strong>.</p> <ol> <li><strong>Ingestion:</strong> It accepts a LinkedIn PDF export or fetched projects using a GitHub username or uses a Resume PDF.</li> <li><strong>Parsing:</strong> I wrote a custom parsing logic in Python that extracts the raw text and converts it into structured JSON (Experience, Education, Skills).</li> <li><strong>Generation:</strong> This JSON is then used to populate a Next.js template.</li> <li><strong>AI Chat Integration:</strong> It also injects this structured data into a system prompt, allowing visitors to &quot;chat&quot; with the portfolio. It is like having an AI-twin for viewers/recruiters.</li> </ol> <p>The backend is containerized and deployed on <strong>Azure App Containers</strong>, using <strong>Firebase</strong> for the database.</p> <p><strong>Target Audience</strong> This is meant for <strong>Developers, Students, and Job Seekers</strong> who want a professional site but don't want to spend days coding it from scratch. It is open source so you are free to clone it, customize it and run it locally. </p> <p><strong>Comparison</strong> Compared to tools like <strong>JSON Resume</strong> or generic website builders (Wix, Squarespace):</p> <ul> <li>You don't need to manually write a JSON file. The Python backend parses your existing PDF.</li> <li><strong>AI Features:</strong> Unlike static templates, this includes an &quot;AI-twin Chat Mode&quot; where the portfolio answers questions about you.</li> <li><strong>Open Source:</strong> It is AGPL-3 licensed and self-hostable.</li> </ul> <p>It started as a hobby project for myself as I was always too lazy to build out portfolio from scratch or fill out templates and always felt a need for something like this.</p> <p>GitHub: <a href=\"https://github.com/yashrathi-git/portfolioly\">https://github.com/yashrathi-git/portfolioly</a><br /> Demo: <a href=\"https://portfolioly.app/demo\">https://portfolioly.app/demo</a></p> <p>I am thinking the same parsing logic could be used for generating targeted Resumes. What do you think about a similar resume generator tool?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/CleverProgrammer12\"> /u/CleverProgrammer12 </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1pe1cm1/built_an_opensource_app_to_convert_linkedin/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1pe1cm1/built_an_opensource_app_to_convert_linkedin/\">[comments]</a></span>",
      "author": "/u/CleverProgrammer12",
      "published_date": "2025-12-04T14:26:41+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 351,
      "reading_time": 1,
      "created_at": "2025-12-04T19:19:21.511300+00:00",
      "updated_at": "2025-12-04T19:19:21.511302+00:00"
    },
    {
      "id": "c57dd5148fa9f41f4be5fdb22ae8d65f",
      "url": "https://endeavouros.com/news/the-long-wait-is-over-ganymede-has-arrived/",
      "title": "The long wait is over, Ganymede has arrived",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46092035\">Comments</a>",
      "author": "",
      "published_date": "2025-11-29T23:57:13+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-04T19:19:20.251092+00:00",
      "updated_at": "2025-12-04T19:19:20.251093+00:00"
    },
    {
      "id": "9f249892a034bda1d3c7ca7b1e1f275d",
      "url": "https://github.com/SJRiz/pytogether",
      "title": "PyTogether: Collaborative lightweight real-time Python IDE for teachers/learners",
      "content": "<p>Article URL: <a href=\"https://github.com/SJRiz/pytogether\">https://github.com/SJRiz/pytogether</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46150447\">https://news.ycombinator.com/item?id=46150447</a></p>\n<p>Points: 4</p>\n<p># Comments: 0</p>",
      "author": "indigodaddy",
      "published_date": "2025-12-04T17:43:07+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-04T19:19:18.881512+00:00",
      "updated_at": "2025-12-04T19:19:18.881513+00:00"
    },
    {
      "id": "7435952e0834ce3bab69423a0615bac7",
      "url": "https://www.frontiersin.org/articles/10.3389/fnbot.2025.1691300",
      "title": "UHGAN: a dual-phase GAN with Hough-transform constraints for accurate farmland road extraction",
      "content": "IntroductionTraditional methods for farmland road extraction, such as U-Net, often struggle with complex noise and geometric features, leading to discontinuous extraction and insufficient sensitivity. To address these limitations, this study proposes a novel dual-phase generative adversarial network (GAN) named UHGAN, which integrates Hough-transform constraints.MethodsWe designed a cascaded U-Net generator within a two-stage GAN framework. The Stage 1 GAN combines a differentiable Hough transform loss with cross-entropy loss to generate initial road masks. Subsequently, the Stage 2 U-Net refines these masks by repairing breakpoints and suppressing isolated noise.ResultsWhen evaluated on the WHU RuR+rural road dataset, the proposed UHGAN method achieved an accuracy of 0.826, a recall of 0.750, and an F1-score of 0.789. This represents a significant improvement over the single-stage U-Net (F1\u202f=\u202f0.756) and ResNet (F1\u202f=\u202f0.762) baselines.DiscussionThe results demonstrate that our approach effectively mitigates the issues of discontinuous extraction caused by the complex geometric shapes and partial occlusion characteristic of farmland roads. The integration of Hough-transform loss, an technique that has received limited attention in prior studies, proves to be highly beneficial. This method shows considerable promise for practical applications in rural infrastructure planning and precision agriculture.",
      "author": "Yuan Ma",
      "published_date": "2025-10-13T00:00:00+00:00",
      "source": "Frontiers Neurorobotics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 190,
      "reading_time": 1,
      "created_at": "2025-12-04T18:34:37.747832+00:00",
      "updated_at": "2025-12-04T18:34:37.747834+00:00"
    },
    {
      "id": "f968e93486f1eebef85e4f9426a76b54",
      "url": "https://folio.benguzovsky.com/train-test",
      "title": "The End of the Train-Test Split",
      "content": "<p>Article URL: <a href=\"https://folio.benguzovsky.com/train-test\">https://folio.benguzovsky.com/train-test</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46149740\">https://news.ycombinator.com/item?id=46149740</a></p>\n<p>Points: 21</p>\n<p># Comments: 1</p>",
      "author": "gmays",
      "published_date": "2025-12-04T16:53:49+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-04T18:34:08.503346+00:00",
      "updated_at": "2025-12-04T18:34:08.503347+00:00"
    },
    {
      "id": "28f3f8efe735c0c00fce7c376bf928bf",
      "url": "https://reason.com/2025/12/04/why-are-38-percent-of-stanford-students-saying-theyre-disabled/",
      "title": "Why Are 38 Percent of Stanford Students Saying They're Disabled?",
      "content": "<p>Article URL: <a href=\"https://reason.com/2025/12/04/why-are-38-percent-of-stanford-students-saying-theyre-disabled/\">https://reason.com/2025/12/04/why-are-38-percent-of-stanford-students-saying-theyre-disabled/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46150715\">https://news.ycombinator.com/item?id=46150715</a></p>\n<p>Points: 22</p>\n<p># Comments: 12</p>",
      "author": "delichon",
      "published_date": "2025-12-04T18:04:07+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-04T18:34:08.503281+00:00",
      "updated_at": "2025-12-04T18:34:08.503289+00:00"
    },
    {
      "id": "40e74262d6860121eaadea625e9ab033",
      "url": "https://www.sciencedirect.com/science/article/pii/S0006899325006286?dgcid=rss_sd_all",
      "title": "The role of semantic features in word production",
      "content": "<p>Publication date: 15 January 2026</p><p><b>Source:</b> Brain Research, Volume 1871</p><p>Author(s): Yufang Wang, Jurriaan Witteman, Niels O. Schiller</p>",
      "author": "",
      "published_date": null,
      "source": "Brain Research",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 16,
      "reading_time": 1,
      "created_at": "2025-12-04T17:47:37.408662+00:00",
      "updated_at": "2025-12-04T18:25:36.660311+00:00",
      "metadata": {
        "processed_at": "2025-12-04T18:25:36.660322+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "7082398b9709e97b92f79d48d34465cc",
      "url": "https://www.nature.com/articles/s41583-025-01007-z",
      "title": "Tiny recurrent neural networks for discovering cognitive strategies",
      "content": "",
      "author": "",
      "published_date": "2025-12-04T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-12-04T17:47:30.978573+00:00",
      "updated_at": "2025-12-04T18:25:36.660326+00:00",
      "metadata": {
        "processed_at": "2025-12-04T18:25:36.660328+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "c5df907383dc5077b3c790401b6c5762",
      "url": "https://fmhy.net/posts/dec-2025",
      "title": "Monthly Updates [December]",
      "content": "<div class=\"info custom-block\"><p class=\"custom-block-title\">INFO</p>\n<p>These update threads only contains major updates. If you're interested\nin seeing all minor changes you can follow our\n<a href=\"https://github.com/fmhy/FMHYedit/commits/main\" rel=\"noreferrer\" target=\"_blank\">Commits Page</a> on GitHub or\n<a href=\"https://redd.it/17f8msf\" rel=\"noreferrer\" target=\"_blank\">Updates Channel</a> in Discord.</p>\n</div>\n<h1 id=\"wiki-updates\" tabindex=\"-1\">Wiki Updates <a class=\"header-anchor\" href=\"#wiki-updates\"></a></h1>\n<ul>\n<li>\n<p>Added new backup site <strong><a href=\"https://fmhy.bid/\" rel=\"noreferrer\" target=\"_blank\">FMHY.bid</a></strong>. Should be unblocked more places than .net currently.</p>\n</li>\n<li>\n<p>Added new section for <a href=\"https://fmhy.net/image-tools#photography-cameras\" rel=\"noreferrer\" target=\"_blank\">Photography / Cameras</a>.</p>\n</li>\n<li>\n<p>Added new section for <a href=\"https://fmhy.net/image-tools#_3d-printing\" rel=\"noreferrer\" target=\"_blank\">3D Printing / Printers</a>.</p>\n</li>\n<li>\n<p>Re-ordered <a href=\"https://fmhy.net/ai#ai-benchmarks\" rel=\"noreferrer\" target=\"_blank\">AI Benchmarks</a>, starred Kaggle Benchmarks, removed ones with dated testing, and added a subsection for <a href=\"https://fmhy.net/ai#specialized-benchmarks\" rel=\"noreferrer\" target=\"_blank\">Specialized Benchmarks</a>. <a href=\"https://i.ibb.co/5xY36Pk5/Untitled.png\" rel=\"noreferrer\" target=\"_blank\">Before vs After</a> / <a href=\"https://i.imgur.com/NuIHGhC.png\" rel=\"noreferrer\" target=\"_blank\">2</a>.</p>\n</li>\n<li>\n<p>Re-ordered and cleaned up ugly formatting in <a href=\"https://fmhy.net/developer-tools#hosting-tools\" rel=\"noreferrer\" target=\"_blank\">Hosting Tools</a>. <a href=\"https://i.ibb.co/21g23vSy/Untitled.png\" rel=\"noreferrer\" target=\"_blank\">Before vs After</a> / <a href=\"https://i.imgur.com/G6sJPo1.png\" rel=\"noreferrer\" target=\"_blank\">2</a>.</p>\n</li>\n<li>\n<p>Moved <a href=\"https://fmhy.net/internet-tools#browser-startpages\" rel=\"noreferrer\" target=\"_blank\">Browser Startpages</a> + <a href=\"https://fmhy.net/internet-tools#custom-new-tab-pages\" rel=\"noreferrer\" target=\"_blank\">Custom New Tab Pages</a> out of storage into their own sections.</p>\n</li>\n<li>\n<p>Brought back the <a href=\"https://fmhy.github.io/FMHY-SafeGuard/\" rel=\"noreferrer\" target=\"_blank\">Website</a> for FMHY SafeGuard.</p>\n</li>\n</ul>\n<hr />\n<h1 id=\"stars-added-\u2b50\" tabindex=\"-1\">Stars Added \u2b50 <a class=\"header-anchor\" href=\"#stars-added-\u2b50\"></a></h1>\n<ul>\n<li>\n<p>Starred <a href=\"https://fmhy.net/video#anime-streaming\" rel=\"noreferrer\" target=\"_blank\">AnimeX</a> in Anime Streaming. Feature-rich, solid sources, big library, nice UI, has forums.</p>\n</li>\n<li>\n<p>Starred <a href=\"https://fmhy.net/ai#image-generation\" rel=\"noreferrer\" target=\"_blank\">Bing Image Creator</a> in Image Gen. Gives 200 daily, has good editing, seems to be best way to use GPT Image 1 as of now.</p>\n</li>\n<li>\n<p>Starred <a href=\"https://fmhy.net/video#android-tv\" rel=\"noreferrer\" target=\"_blank\">\u2060TizenTube Cobalt</a> in Android TV. Ad-free YouTube app, updated often, has Sponsorblock support, uses official YouTube UI.</p>\n</li>\n<li>\n<p>Starred <a href=\"https://fmhy.net/video#live-sports\" rel=\"noreferrer\" target=\"_blank\">Watch Footy</a> in Live Sports. Solid sources, nice UI, lots of events.</p>\n</li>\n<li>\n<p>Starred <a href=\"https://fmhy.net/video-tools#live-streaming\" rel=\"noreferrer\" target=\"_blank\">Streamer.bot</a> in Live Streaming Tools. <a href=\"https://streamer.bot/features\" rel=\"noreferrer\" target=\"_blank\">Feature-rich</a> live stream manager, compatible w/ OBS, Streamlabs, etc.</p>\n</li>\n<li>\n<p>Starred <a href=\"https://fmhy.net/gaming-tools#roblox-tools\" rel=\"noreferrer\" target=\"_blank\">RoSeal</a> in Roblox Tools. Improves Roblox website and adds nearly 200 extra features.</p>\n</li>\n<li>\n<p>Starred <a href=\"https://fmhy.net/mobile#android-reading\" rel=\"noreferrer\" target=\"_blank\">Voice</a> in Android Audiobook Players. Open-source, multi-format, has cover fetch, and nice minimal design.</p>\n</li>\n<li>\n<p>Starred <a href=\"https://fmhy.net/mobile#productivity-trackers\" rel=\"noreferrer\" target=\"_blank\">Loop Habit Tracker</a> in Mobile Productivity. Open-source, has sticky notifications, and better limits than most free options.</p>\n</li>\n<li>\n<p>Re-starred <a href=\"https://fmhy.net/gaming#rom-sites\" rel=\"noreferrer\" target=\"_blank\">CDRomance</a> in ROM Sites as its made a comeback. Note that RetroGamingTalk accounts will work on CDRomance.</p>\n</li>\n</ul>\n<hr />\n<h1 id=\"things-removed\" tabindex=\"-1\">Things Removed <a class=\"header-anchor\" href=\"#things-removed\"></a></h1>\n<ul>\n<li>\n<p>Removed Anadius as they've <a href=\"https://i.ibb.co/TD9kRCR3/image.png\" rel=\"noreferrer\" target=\"_blank\">decided to step down</a> / <a href=\"https://i.imgur.com/2Xk8Jor.png\" rel=\"noreferrer\" target=\"_blank\">2</a>. It may be re-added in the future if someone new steps up to maintain it.</p>\n</li>\n<li>\n<p>Removed ContextSearch as it's been removed by Firefox. It seems to be causing issues, and in some cases flooding sites with requests. We're unsure if it's purposefully malicious, or mistakes by its dev, but regardless its recommended to remove it, and try other options like <a href=\"https://fmhy.net/internet-tools#firefox-extensions\" rel=\"noreferrer\" target=\"_blank\">ContextSearch web-ext</a>.</p>\n</li>\n<li>\n<p>Unstarred <a href=\"https://fmhy.net/file-tools#file-managers\" rel=\"noreferrer\" target=\"_blank\">Files</a> in File Managers. There was a lot of hype for this originally, but people have started to come forward saying its too laggy / slow to be useful.</p>\n</li>\n<li>\n<p>Unstarred Grok, Qwen, Mage and Flux.1 Schnell in <a href=\"https://fmhy.net/ai#image-generation\" rel=\"noreferrer\" target=\"_blank\">Image Gen</a>. These were considered good in the past, but there's much better, less dated free options at this point.</p>\n</li>\n</ul>",
      "author": "",
      "published_date": "2025-12-01T00:00:00+00:00",
      "source": "Fmhy",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 563,
      "reading_time": 2,
      "created_at": "2025-12-04T17:46:53.240012+00:00",
      "updated_at": "2025-12-04T18:25:36.660330+00:00",
      "metadata": {
        "processed_at": "2025-12-04T18:25:36.660332+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "be19edd8d151e6271a49e4608442fb33",
      "url": "https://github.com/AncientJames/multivox",
      "title": "Multivox: Volumetric Display",
      "content": "<p>Article URL: <a href=\"https://github.com/AncientJames/multivox\">https://github.com/AncientJames/multivox</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46149813\">https://news.ycombinator.com/item?id=46149813</a></p>\n<p>Points: 9</p>\n<p># Comments: 1</p>",
      "author": "jk_tech",
      "published_date": "2025-12-04T16:58:35+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-04T17:46:49.107186+00:00",
      "updated_at": "2025-12-04T18:25:36.660334+00:00",
      "metadata": {
        "processed_at": "2025-12-04T18:25:36.660335+00:00",
        "processing_method": "github_actions"
      }
    }
  ]
}