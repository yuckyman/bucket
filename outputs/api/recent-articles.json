{
  "last_updated": "2025-10-23T16:48:47.310262+00:00",
  "count": 20,
  "articles": [
    {
      "id": "ac6f3ab92725084e2b49600ca6243d2a",
      "url": "https://brain.ieee.org/braininsight-articles/call-for-papers-ieee-transactions-on-human-machine-systems/",
      "title": "Call for Papers: IEEE Transactions on Human-Machine Systems",
      "content": "Special Issue on Brain Discovery and Neurotechnology: Featured Research from 2024 IEEE Brain Discovery &#38; Neurotechnology Workshop\u00a0 &#160; This special issue is motivated by the success of the IEEE Brain Discovery and Neurotechnology Workshop held in October 2024. This annual workshop is sponsored by the IEEE Brain Technical Community. It is intended to foster interactions among researchers and clinical practitioners ...",
      "author": "Adriel Carridice",
      "published_date": "2025-06-18T14:50:14+00:00",
      "source": "Brain",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 61,
      "reading_time": 1,
      "created_at": "2025-10-23T16:48:37.003589+00:00",
      "updated_at": "2025-10-23T16:48:37.003592+00:00"
    },
    {
      "id": "16712c82fde7bee131cf339ae97552f5",
      "url": "http://ieeexplore.ieee.org/document/10994678",
      "title": "Evaluation on Human Perception of Various Vibrotactile Encoding Methods Through a High Density Haptic Feedback Interface",
      "content": "High density (HD) haptic interfaces have become increasingly common for entertainment thanks to advancements in virtual reality technology, however their flexibility may make them a useful sensory substitution interface for motor rehabilitation. Yet little research has explored how users interpret different haptic feedback encoding methods. Therefore, this study's objective was to evaluate the effectiveness of various encoding methods for conveying information based on existing sensory substitution strategies, one being a line motion tracking task and the other a direction tracking task. The first encoding method was Perceived Position Encoding (PPE), where information was encoded into the perceived position of stimulation. The second was Perceived Intensity Encoding (PIE), encoded information into the perceived amplitude of the stimuli. Twenty-one participants performed tracking tasks using both the PIE and PPE methods. The results showed similar performance in line motion tracking between the PIE and PPE methods, although the extra motors used in the PPE method appear to introduce uncertainty in users. Nevertheless, users were significantly more accurate with direction tracking when using PPE. These findings highlight the need for task-specific encoding methods, and showcase the versatility of the HD haptic vest as a tool for augmented feedback in motor rehabilitation.",
      "author": "",
      "published_date": "2025-05-09T13:16:51+00:00",
      "source": "Transactions Haptics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 197,
      "reading_time": 1,
      "created_at": "2025-10-23T16:48:35.772412+00:00",
      "updated_at": "2025-10-23T16:48:35.772413+00:00"
    },
    {
      "id": "bbe0f805e4fabfb0ac2476417484aef4",
      "url": "http://ieeexplore.ieee.org/document/10946856",
      "title": "Enhancing Video Experiences for DHH Individuals Through Sound-Inspired Motion Caption-Based Spatiotemporal Tacton",
      "content": "When deaf and hard of hearing (DHH) individuals watch videos, captions are essential for them to understand the linguistic content. Current captions, however, are not suitable for conveying non-verbal sound information, such as background music, sound effects, or speech nuances. In this paper, we designed a multimodal system, Motion Caption Haptic System (MCHS), that enables DHH individuals to encounter sounds in videos through animated caption and spatiotemporal vibration patterns, supporting a more vivid and immersive experience. We elaborately designed motion captions and spatiotemporal haptic patterns for representative sound effects and spoken emotions to work well together through surveys from 27 DHH and 64 hearing participants. An evaluation with 19 DHH individuals demonstrated the capabilities and potential of the MCHS to improve their video viewing experience, along with a discussion of important issues that need to be addressed when designing multimodal captioning systems for the DHH viewers.",
      "author": "",
      "published_date": "2025-04-01T13:17:18+00:00",
      "source": "Transactions Haptics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 146,
      "reading_time": 1,
      "created_at": "2025-10-23T16:48:35.772378+00:00",
      "updated_at": "2025-10-23T16:48:35.772380+00:00"
    },
    {
      "id": "609521b013e1243f77b1eaa5e01eab3e",
      "url": "http://ieeexplore.ieee.org/document/10965524",
      "title": "VibTac: A High-Resolution High-Bandwidth Tactile Sensing Finger for Multi-Modal Perception in Robotic Manipulation",
      "content": "Tactile sensing is pivotal for enhancing robot manipulation abilities by providing crucial feedback for localized information. However, existing sensors often lack the necessary resolution and bandwidth required for intricate tasks. To address this gap, we introduce VibTac, a novel multi-modal tactile sensing finger designed to offer high-resolution and high-bandwidth tactile sensing simultaneously. VibTac seamlessly integrates vision-based and vibration-based tactile sensing modes to achieve high-resolution and high-bandwidth tactile sensing respectively, leveraging a streamlined human-inspired design for versatility in tasks. This paper outlines the key design elements of VibTac and its fabrication methods, highlighting the significance of the Elastomer Gel Pad (EGP) in its sensing mechanism. The sensor's multi-modal performance is validated through 3D reconstruction and spectral analysis to discern tactile stimuli effectively. In experimental trials, VibTac demonstrates its efficacy by achieving over 90% accuracy in insertion tasks involving objects emitting distinct sounds, such as ethernet connectors. Leveraging vision-based tactile sensing for object localization and employing a deep learning model for \u201cclick\u201d sound classification, VibTac showcases its robustness in real-world scenarios.",
      "author": "",
      "published_date": "2025-04-15T13:16:45+00:00",
      "source": "Transactions Haptics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 169,
      "reading_time": 1,
      "created_at": "2025-10-23T16:48:35.772349+00:00",
      "updated_at": "2025-10-23T16:48:35.772351+00:00"
    },
    {
      "id": "6e5289b1927a2560a61773b58736ef16",
      "url": "http://ieeexplore.ieee.org/document/10955171",
      "title": "Age-Related Impact in Illusory Torque Cues Induced by Asymmetric Vibrations",
      "content": "Illusory pulling sensations in the translational or rotational direction are induced by asymmetric vibrations applied to the fingertips. Although previous studies have discussed the involvement of mechanoreceptors associated with skin deformation and spatial processing in the parietal association cortex in the generation of illusory cues, the precise mechanism underlying this phenomenon remains unclear. In this study, we aimed to indirectly estimate the contribution of mechanoreceptors to the perception of illusory pulling torque cues by examining the relationship between vibration thresholds and the properties of these illusions, leveraging the known decline in cutaneous sensation sensitivity associated with aging (N = 40). Our results revealed an age-related increase in vibration thresholds, which is consistent with previous research. While male participants showed consistent sensitivity to illusory pulling cues across age groups, female participants exhibited a decline in sensitivity with age. Moreover, we observed only weak or no correlations between the vibration thresholds and the sensitivity of the illusory pulling cue. Although we were unable to identify any findings that explain the contribution of mechanoreceptors, we discovered a gender difference in the sensitivity to induced illusions among older individuals. These findings offer valuable insights for elucidating the mechanism underlying the illusion.",
      "author": "",
      "published_date": "2025-04-07T13:17:32+00:00",
      "source": "Transactions Haptics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 197,
      "reading_time": 1,
      "created_at": "2025-10-23T16:48:35.772314+00:00",
      "updated_at": "2025-10-23T16:48:35.772315+00:00"
    },
    {
      "id": "b36c483362d8e2adfbd29771d0c72343",
      "url": "https://www.embs.org/awards/society-awards/#new_tab",
      "title": "Call for 2025 Society Awards Nominations",
      "content": "<p>The post <a href=\"https://www.embs.org/awards/society-awards/#new_tab\">Call for 2025 Society Awards Nominations</a> appeared first on <a href=\"https://www.embs.org\">IEEE EMBS</a>.</p>",
      "author": "Deidre Artis",
      "published_date": "2025-02-03T21:05:59+00:00",
      "source": "Embs",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 15,
      "reading_time": 1,
      "created_at": "2025-10-23T16:48:29.990634+00:00",
      "updated_at": "2025-10-23T16:48:29.990635+00:00"
    },
    {
      "id": "ad1925564c97f30cab5b55e76f20793b",
      "url": "https://www.embs.org/blog-post/regional-shifts-and-patterns/",
      "title": "Bridging Biotech: Regional shifts and patterns",
      "content": "<p>The post <a href=\"https://www.embs.org/blog-post/regional-shifts-and-patterns/\">Bridging Biotech: Regional shifts and patterns</a> appeared first on <a href=\"https://www.embs.org\">IEEE EMBS</a>.</p>",
      "author": "dziura",
      "published_date": "2025-02-05T15:45:50+00:00",
      "source": "Embs",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 15,
      "reading_time": 1,
      "created_at": "2025-10-23T16:48:29.990615+00:00",
      "updated_at": "2025-10-23T16:48:29.990617+00:00"
    },
    {
      "id": "6b5f32570094f1cedcde640a7566d20a",
      "url": "https://www.embs.org/blog-post/welcoming-dr-ana-kyani-as-wibme-chair-ieee-embs/",
      "title": "Welcoming Dr. Ana Kyani as the New Women in Biomedical Engineering Chair for IEEE EMBS",
      "content": "<p>The post <a href=\"https://www.embs.org/blog-post/welcoming-dr-ana-kyani-as-wibme-chair-ieee-embs/\">Welcoming Dr. Ana Kyani as the New Women in Biomedical Engineering Chair for IEEE EMBS</a> appeared first on <a href=\"https://www.embs.org\">IEEE EMBS</a>.</p>",
      "author": "Nancy Zimmerman",
      "published_date": "2025-03-27T17:10:33+00:00",
      "source": "Embs",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 24,
      "reading_time": 1,
      "created_at": "2025-10-23T16:48:29.990597+00:00",
      "updated_at": "2025-10-23T16:48:29.990599+00:00"
    },
    {
      "id": "138dbc20af95ce55414e7d62214f9607",
      "url": "https://www.embs.org/press/embc-eic-sunghoon-ivan-lee/#new_tab",
      "title": "Ivan Lee, Appointed Editor-in-Chief of EMBC Proceedings",
      "content": "<p>&#160;</p>\n<p>The post <a href=\"https://www.embs.org/press/embc-eic-sunghoon-ivan-lee/#new_tab\">Ivan Lee, Appointed Editor-in-Chief of EMBC Proceedings</a> appeared first on <a href=\"https://www.embs.org\">IEEE EMBS</a>.</p>",
      "author": "Nancy Zimmerman",
      "published_date": "2025-09-08T16:27:03+00:00",
      "source": "Embs",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 17,
      "reading_time": 1,
      "created_at": "2025-10-23T16:48:29.990428+00:00",
      "updated_at": "2025-10-23T16:48:29.990432+00:00"
    },
    {
      "id": "95c7cd5d20ee3c613c3a6b1cd60208fb",
      "url": "https://arxiv.org/abs/2510.19033",
      "title": "\"Over-the-Hood\" AI Inclusivity Bugs and How 3 AI Product Teams Found and Fixed Them",
      "content": "arXiv:2510.19033v1 Announce Type: new \nAbstract: While much research has shown the presence of AI's \"under-the-hood\" biases (e.g., algorithmic, training data, etc.), what about \"over-the-hood\" inclusivity biases: barriers in user-facing AI products that disproportionately exclude users with certain problem-solving approaches? Recent research has begun to report the existence of such biases -- but what do they look like, how prevalent are they, and how can developers find and fix them? To find out, we conducted a field study with 3 AI product teams, to investigate what kinds of AI inclusivity bugs exist uniquely in user-facing AI products, and whether/how AI product teams might harness an existing (non-AI-oriented) inclusive design method to find and fix them. The teams' work resulted in identifying 6 types of AI inclusivity bugs arising 83 times, fixes covering 47 of these bug instances, and a new variation of the GenderMag inclusive design method, GenderMag-for-AI, that is especially effective at detecting certain kinds of AI inclusivity bugs.",
      "author": "Andrew Anderson, Fatima A. Moussaoui, Jimena Noa Guevara, Md Montaser Hamid, Margaret Burnett",
      "published_date": "2025-10-23T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 159,
      "reading_time": 1,
      "created_at": "2025-10-23T16:48:28.595531+00:00",
      "updated_at": "2025-10-23T16:48:28.595533+00:00"
    },
    {
      "id": "d5d80ced71fba8258964ff7f71ebf530",
      "url": "https://www.sciencedirect.com/science/article/pii/S0006899325005463?dgcid=rss_sd_all",
      "title": "Altered social proximity in adult mice following prenatal stress Exposure: An exploratory link to cortical neurogenesis",
      "content": "<p>Publication date: 1 December 2025</p><p><b>Source:</b> Brain Research, Volume 1868</p><p>Author(s): Tsukasa Tomoe, Rei Sugiyama, Niina Kiriyama, Airi Otsuka, Munekazu Komada</p>",
      "author": "",
      "published_date": null,
      "source": "Brain Research",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 19,
      "reading_time": 1,
      "created_at": "2025-10-23T16:48:22.910841+00:00",
      "updated_at": "2025-10-23T16:48:22.910843+00:00"
    },
    {
      "id": "b0bbd0bbd9f57cef88d67b715e8a3a80",
      "url": "https://www.sciencedirect.com/science/article/pii/S000689932500544X?dgcid=rss_sd_all",
      "title": "Photobiomodulation in stroke prevention and treatment: neuroprotective mechanisms and therapeutic challenges",
      "content": "<p>Publication date: 1 December 2025</p><p><b>Source:</b> Brain Research, Volume 1868</p><p>Author(s): Yuecheng Li, Lei Zhang, Jiaqiang Lin, Luodan Yang, Rui Duan</p>",
      "author": "",
      "published_date": null,
      "source": "Brain Research",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 19,
      "reading_time": 1,
      "created_at": "2025-10-23T16:48:22.910744+00:00",
      "updated_at": "2025-10-23T16:48:22.910745+00:00"
    },
    {
      "id": "63142fbe3d76dcf7309d1664f68e6b1d",
      "url": "https://www.sciencedirect.com/science/article/pii/S1053811925005166?dgcid=rss_sd_all",
      "title": "Crossing the scales: Single-neuron recruitment and continuous cortical propagation of slow wave events revealed by integrative opto-magnetic imaging",
      "content": "<p>Publication date: 1 November 2025</p><p><b>Source:</b> NeuroImage, Volume 321</p><p>Author(s): Dirk Cleppien, Miriam Schwalm, Hendrik Backhaus, Ting Fu, Felipe Aedo-Jury, Gaby Schneider, Albrecht Stroh</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroimage",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 22,
      "reading_time": 1,
      "created_at": "2025-10-23T16:48:19.342732+00:00",
      "updated_at": "2025-10-23T16:48:19.342734+00:00"
    },
    {
      "id": "bcd3bea7058e66cb9222045d033fee8f",
      "url": "http://www.jneurosci.org/cgi/content/short/45/41/etwij45412025?rss=1",
      "title": "This Week in The Journal",
      "content": "",
      "author": "McKeon, P.",
      "published_date": "2025-10-08T16:30:38+00:00",
      "source": "Journal Neuroscience This Week",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-10-23T16:48:14.046166+00:00",
      "updated_at": "2025-10-23T16:48:14.046168+00:00"
    },
    {
      "id": "01c2974d9c0475f1e747f064d64c3438",
      "url": "http://www.jneurosci.org/cgi/content/short/45/42/etwij45422025?rss=1",
      "title": "This Week in The Journal",
      "content": "",
      "author": "McKeon, P.",
      "published_date": "2025-10-15T16:30:28+00:00",
      "source": "Journal Neuroscience This Week",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-10-23T16:48:14.046146+00:00",
      "updated_at": "2025-10-23T16:48:14.046148+00:00"
    },
    {
      "id": "45271a80a221a35912e75ec358f4cf54",
      "url": "https://www.frontiersin.org/articles/10.3389/fninf.2025.1633273",
      "title": "Generation of synthetic TSPO PET maps from structural MRI images",
      "content": "IntroductionNeuroinflammation, a pathophysiological process involved in numerous disorders, is typically imaged using [11C]PBR28 (or TSPO) PET. However, this technique is limited by high costs and ionizing radiation, restricting its widespread clinical use. MRI, a more accessible alternative, is commonly used for structural or functional imaging, but when used using traditional approaches has limited sensitivity to specific molecular processes. This study aims to develop a deep learning model to generate TSPO PET images from structural MRI data collected in human subjects.MethodsA total of 204 scans, from participants with knee osteoarthritis (n\u202f=\u202f15 scanned once, 15 scanned twice, 14 scanned three times), back pain (n\u202f=\u202f40 scanned twice, 3 scanned three times), and healthy controls (n\u202f=\u202f28, scanned once), underwent simultaneous 3\u202fT MRI and [11C]PBR28 TSPO PET scans. A 3D U-Net model was trained on 80% of these PET-MRI pairs and validated using 5-fold cross-validation. The model\u2019s accuracy in reconstructed PET from MRI only was assessed using various intensity and noise metrics.ResultsThe model achieved a low voxel-wise mean squared error (0.0033\u202f\u00b1\u202f0.0010) across all folds and a median contrast-to-noise ratio of 0.0640\u202f\u00b1\u202f0.2500 when comparing true to reconstructed PET images. The synthesized PET images accurately replicated the spatial patterns observed in the original PET data. Additionally, the reconstruction accuracy was maintained even after spatial normalization.DiscussionThis study demonstrates that deep learning can accurately synthesize TSPO PET images from conventional, T1-weighted MRI. This approach could enable low-cost, noninvasive neuroinflammation imaging, expanding the clinical applicability of this imaging method.",
      "author": "Marco L. Loggia",
      "published_date": "2025-09-08T00:00:00+00:00",
      "source": "Frontiers Neuroinformatics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 250,
      "reading_time": 1,
      "created_at": "2025-10-23T16:48:09.785360+00:00",
      "updated_at": "2025-10-23T16:48:09.785362+00:00"
    },
    {
      "id": "7435952e0834ce3bab69423a0615bac7",
      "url": "https://www.frontiersin.org/articles/10.3389/fnbot.2025.1691300",
      "title": "UHGAN: a dual-phase GAN with Hough-transform constraints for accurate farmland road extraction",
      "content": "IntroductionTraditional methods for farmland road extraction, such as U-Net, often struggle with complex noise and geometric features, leading to discontinuous extraction and insufficient sensitivity. To address these limitations, this study proposes a novel dual-phase generative adversarial network (GAN) named UHGAN, which integrates Hough-transform constraints.MethodsWe designed a cascaded U-Net generator within a two-stage GAN framework. The Stage 1 GAN combines a differentiable Hough transform loss with cross-entropy loss to generate initial road masks. Subsequently, the Stage 2 U-Net refines these masks by repairing breakpoints and suppressing isolated noise.ResultsWhen evaluated on the WHU RuR+rural road dataset, the proposed UHGAN method achieved an accuracy of 0.826, a recall of 0.750, and an F1-score of 0.789. This represents a significant improvement over the single-stage U-Net (F1\u202f=\u202f0.756) and ResNet (F1\u202f=\u202f0.762) baselines.DiscussionThe results demonstrate that our approach effectively mitigates the issues of discontinuous extraction caused by the complex geometric shapes and partial occlusion characteristic of farmland roads. The integration of Hough-transform loss, an technique that has received limited attention in prior studies, proves to be highly beneficial. This method shows considerable promise for practical applications in rural infrastructure planning and precision agriculture.",
      "author": "Yuan Ma",
      "published_date": "2025-10-13T00:00:00+00:00",
      "source": "Frontiers Neurorobotics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 190,
      "reading_time": 1,
      "created_at": "2025-10-23T16:48:05.383648+00:00",
      "updated_at": "2025-10-23T16:48:05.383649+00:00"
    },
    {
      "id": "f04f02121b1d13836df0a2b01a861136",
      "url": "https://www.frontiersin.org/articles/10.3389/fnbot.2025.1681341",
      "title": "UAV-based intelligent traffic surveillance using recurrent neural networks and Swin transformer for dynamic environments",
      "content": "IntroductionUrban traffic congestion, environmental degradation, and road safety challenges necessitate intelligent aerial robotic systems capable of real-time adaptive decision-making. Unmanned Aerial Vehicles (UAVs), with their flexible deployment and high vantage point, offer a promising solution for large-scale traffic surveillance in complex urban environments. This study introduces a UAV-based neural framework that addresses challenges such as asymmetric vehicle motion, scale variations, and spatial inconsistencies in aerial imagery.MethodsThe proposed system integrates a multi-stage pipeline encompassing contrast enhancement and region-based clustering to optimize segmentation while maintaining computational efficiency for resource-constrained UAV platforms. Vehicle detection is carried out using a Recurrent Neural Network (RNN), optimized via a hybrid loss function combining cross-entropy and mean squared error to improve localization and confidence estimation. Upon detection, the system branches into two neural submodules: (i) a classification stream utilizing SURF and BRISK descriptors integrated with a Swin Transformer backbone for precise vehicle categorization, and (ii) a multi-object tracking stream employing DeepSORT, which fuses motion and appearance features within an affinity matrix for robust trajectory association.ResultsComprehensive evaluation on three benchmark UAV datasets\u2014AU-AIR, UAVDT, and VAID shows consistent and high performance. The model achieved detection precisions of 0.913, 0.930, and 0.920; tracking precisions of 0.901, 0.881, and 0.890; and classification accuracies of 92.14, 92.75, and 91.25%, respectively.DiscussionThese findings highlight the adaptability, robustness, and real-time viability of the proposed architecture in aerial traffic surveillance applications. By effectively integrating detection, classification, and tracking within a unified neural framework, the system contributes significant advancements to intelligent UAV-based traffic monitoring and supports future developments in smart city mobility and decision-making systems.",
      "author": "Hui Liu",
      "published_date": "2025-10-13T00:00:00+00:00",
      "source": "Frontiers Neurorobotics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 258,
      "reading_time": 1,
      "created_at": "2025-10-23T16:48:05.383614+00:00",
      "updated_at": "2025-10-23T16:48:05.383615+00:00"
    },
    {
      "id": "ec4dc4c8caa14e240215366f555ff354",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38873838/?utm_source=BucketBot&utm_medium=rss&utm_campaign=None&utm_content=1BUB2BG5RbxOblm-hBbiJWEhGG43qlVrvGNHOTqBKva9wWrItM&fc=None&ff=20251023124756&v=2.18.0.post22+67771e2",
      "title": "The impact of CSF-filled cavities on scalp EEG and its implications",
      "content": "Previous studies have found electroencephalogram (EEG) amplitude and scalp topography differences between neurotypical and neurological/neurosurgical groups, being interpreted at the cognitive level. However, these comparisons are invariably accompanied by anatomical changes. Critical to EEG are the so-called volume currents, which are affected by the spatial distribution of the different tissues in the head. We investigated the effect of cerebrospinal fluid (CSF)-filled cavities on simulated...",
      "author": "Maria Carla Piastra",
      "published_date": "2024-06-14T10:00:00+00:00",
      "source": "Oostenveld Robert",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 64,
      "reading_time": 1,
      "created_at": "2025-10-23T16:48:00.525379+00:00",
      "updated_at": "2025-10-23T16:48:00.525381+00:00"
    },
    {
      "id": "37522aa898c869c350988bf36355e328",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38956071/?utm_source=BucketBot&utm_medium=rss&utm_campaign=None&utm_content=1BUB2BG5RbxOblm-hBbiJWEhGG43qlVrvGNHOTqBKva9wWrItM&fc=None&ff=20251023124756&v=2.18.0.post22+67771e2",
      "title": "Motion-BIDS: an extension to the brain imaging data structure to organize motion data for reproducible research",
      "content": "We present an extension to the Brain Imaging Data Structure (BIDS) for motion data. Motion data is frequently recorded alongside human brain imaging and electrophysiological data. The goal of Motion-BIDS is to make motion data interoperable across different laboratories and with other data modalities in human brain and behavioral research. To this end, Motion-BIDS standardizes the data format and metadata structure. It describes how to document experimental details, considering the diversity of...",
      "author": "Julius Welzel",
      "published_date": "2024-07-02T10:00:00+00:00",
      "source": "Oostenveld Robert",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 72,
      "reading_time": 1,
      "created_at": "2025-10-23T16:48:00.525356+00:00",
      "updated_at": "2025-10-23T16:48:00.525358+00:00"
    }
  ]
}