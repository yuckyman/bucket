{
  "last_updated": "2025-11-19T16:53:34.390841+00:00",
  "count": 20,
  "articles": [
    {
      "id": "c0f4c8d357820caa0d637b9d31451e82",
      "url": "https://www.sciencedirect.com/science/article/pii/S1053811925005695?dgcid=rss_sd_all",
      "title": "Cingulate and striatal hubs are linked to early skill learning",
      "content": "<p>Publication date: 1 December 2025</p><p><b>Source:</b> NeuroImage, Volume 323</p><p>Author(s): Hisato Sugata, Fumiaki Iwane, William Hayward, Valentina Azzollini, Debadatta Dash, Roberto F Salamanca-Giron, Marlene B\u00f6nstrup, Ethan R Buch, Leonardo G Cohen</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroimage",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 29,
      "reading_time": 1,
      "created_at": "2025-11-19T16:53:06.004122+00:00",
      "updated_at": "2025-11-19T16:53:06.004124+00:00"
    },
    {
      "id": "a59f41cfafede309bb69d5bdae765790",
      "url": "https://www.pnas.org/doi/abs/10.1073/pnas.2518032122?af=R",
      "title": "Structural dynamics and neural representation of wing deformation",
      "content": "Proceedings of the National Academy of Sciences, Volume 122, Issue 46, November 2025. <br />SignificanceMany systems in nature precisely control highly deformable structures, yet monitoring deformations has posed a significant challenge for biologists and engineers. By measuring and modeling the intricate structure of compliant dragonfly wings, ...",
      "author": "Alexandra M. YargerMasateru MaedaIgor SiwanowiczHaruhiro KajiyamaSimon M. WalkerRichard J. BomphreyHuai-Ti LinaDepartment of Bioengineering, Imperial College London, London SW7 2AZ, United KingdombThe Grass Fellowship Laboratory at the Marine Biological Laboratory, Woods Hole, MA 02543cFaculty of Engineering, Takushoku University, Tokyo 193-0985, JapandDepartment of Comparative Biomedical Sciences, Royal Veterinary College, Hatfield AL9 7TA, United KingdomeHHMI Janelia Research Campus, Ashburn, VA 20147fGraduate School of Engineering, Takushoku University, Tokyo 193-0985, JapangSchool of Biomedical Sciences, University of Leeds, Leeds LS2 9JT, United Kingdom",
      "published_date": "2025-11-13T08:00:00+00:00",
      "source": "Pnas Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 47,
      "reading_time": 1,
      "created_at": "2025-11-19T16:52:57.809374+00:00",
      "updated_at": "2025-11-19T16:52:57.809375+00:00"
    },
    {
      "id": "b93b2f6d45eb9b8ef0dd30a01109a433",
      "url": "https://www.pnas.org/doi/abs/10.1073/pnas.2514182122?af=R",
      "title": "MARK2 regulates C9orf72 repeat\u2013associated non-AUG translation",
      "content": "Proceedings of the National Academy of Sciences, Volume 122, Issue 46, November 2025. <br />Protein homeostasis is exquisitely regulated through processes involving protein synthesis essential for cellular health and disease prevention. Repeat-associated non-AUG (RAN) translation at expanded GGGGCC repeats in theC9orf72gene produces dipeptide ...",
      "author": "Yu-Ning LuXiangning LiLindsey HayesXiao-Feng ZhaoJiou WangaDepartment of Biochemistry and Molecular Biology, Bloomberg School of Public Health, Johns Hopkins University, Baltimore, MD 21205bBrain Science Institute and Department of Neurology, Johns Hopkins University School of Medicine, Baltimore, MD 21205cDepartment of Neuroscience, School of Medicine, Johns Hopkins University, Baltimore, MD 21205",
      "published_date": "2025-11-13T08:00:00+00:00",
      "source": "Pnas Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 44,
      "reading_time": 1,
      "created_at": "2025-11-19T16:52:57.809351+00:00",
      "updated_at": "2025-11-19T16:52:57.809353+00:00"
    },
    {
      "id": "ef4ce3fe071860888089bc5c4ab6921d",
      "url": "https://www.pnas.org/doi/abs/10.1073/pnas.2411909122?af=R",
      "title": "Emergent neuronal mechanisms mediating covert attention in convolutional neural networks",
      "content": "Proceedings of the National Academy of Sciences, Volume 122, Issue 46, November 2025. <br />SignificanceCues predictive of target locations orient covert attention, improving perceptual performance. Studies have focused on attentional influences on neural activity, but how cues activate attention and how neuronal populations enable perceptual ...",
      "author": "Sudhanshu SrivastavaWilliam Yang WangMiguel P. EcksteinaGraduate Program in Dynamical Neuroscience, University of California Santa Barbara, Santa Barbara, CA 93106bInstitute for Collaborative Biotechnologies, University of California Santa Barbara, Santa Barbara, CA 93106cDepartment of Computer Science, University of California Santa Barbara, Santa Barbara, CA 93106dDepartment of Electrical and Computer Engineering, University of California Santa Barbara, Santa Barbara, CA 93106eDepartment of Psychological and Brain Sciences, University of California Santa Barbara, Santa Barbara, CA 93106",
      "published_date": "2025-11-13T08:00:00+00:00",
      "source": "Pnas Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 46,
      "reading_time": 1,
      "created_at": "2025-11-19T16:52:57.809302+00:00",
      "updated_at": "2025-11-19T16:52:57.809303+00:00"
    },
    {
      "id": "8dd38fafcd3ff05eca00b43abd22d945",
      "url": "https://www.biorxiv.org/content/10.1101/2025.11.19.689229v1?rss=1",
      "title": "Identity Domains Reveal How Life Experiences and the Microbiome Shape Individuality and Uncover the Presence of Social Memory in Drosophila",
      "content": "Personality is comprised of enduring traits that shape behavior across contexts and over time. Yet outside humans, research often equates individuality with personality, focusing on how one animal differs from another in each behavior. This overlooks the latent space that spans an animal's behavioral repertoire, how it is shaped by innate tendencies and prior experiences, and how it differs from transient factors. Here, we bridge this gap by integrating a data-driven framework with unbiased trait interpretation via large language models, revealing how social, sexual, and physiological conditions systematically alter the expression of personality-like traits in Drosophila melanogaster. This approach yielded four identities: space-use (exploration), time-use (social investment), avoidance, and aggression. Large language models produced strong consensus on the interpretation of some of these axes and divergence on others. These dimensions proved stable within individuals yet shifted predictably following mating, isolation, and microbiome manipulation, often in sex dependent ways. Notably, flies behaved differently toward familiar and unfamiliar peers, revealing a capacity for social memory. These findings bridge temperament and personality, showing how life history reshapes baseline tendencies into individualized profiles within constrained dimensions. They establish Drosophila as a tractable system for uncovering the biological logic of personality and advancing cross-species principles for individuality research.",
      "author": "Pozeilov, H., Dayan, E., Yehuda, R., Levi, M., Shohat-Ophir, G., Forkosh, O.",
      "published_date": "2025-11-19T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 203,
      "reading_time": 1,
      "created_at": "2025-11-19T16:28:50.933576+00:00",
      "updated_at": "2025-11-19T16:28:50.933578+00:00"
    },
    {
      "id": "c6d0e05ebdadef3114f4b46e7f7c163d",
      "url": "https://www.biorxiv.org/content/10.1101/2025.11.19.688847v1?rss=1",
      "title": "A novel method to sort and enrich sensory neurons",
      "content": "Peripheral sensory neurons, residing in the dorsal root ganglia (DRG), relay sensory information from the periphery to the central nervous system. Although single-cell transcriptomic studies have identified over 20 distinct sensory neuron subtypes, functional analysis and assessment of subtype-specific pathological changes remain difficult. Effective isolation and enrichment of sensory neurons are challenging yet essential for functional studies. Therefore, we used single-cell transcriptomic data from DRG to identify a panel of neuronal surface markers, including Nrxn2 and Pirt. Using these markers, we developed a fluorescence-activated cell sorting (FACS) panel for neuronal enrichment and analysis that does not rely on transgenic mouse strains and can be broadly applied. The panel was validated by microscopy and single-cell RNA (scRNA) sequencing, which also revealed broad representation of neuronal subtypes. Expression of these markers in human DRG underscores the translational value of this isolation method for sensory and pain studies. Overall, this study provides a valuable tool for isolating DRG neurons, advancing research on sensory neuron function and pain biology, and facilitating neuroimmune studies.",
      "author": "Kurtovic, Z., Arvidsson, S. D., Vazquez Mora, J. A., Ye, S., Bersellini Farinotti, A., Simon, N., Krock, E., Haglund, L., Hagemann-Jensen, M., Lund, H., Svensson, C. I.",
      "published_date": "2025-11-19T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 169,
      "reading_time": 1,
      "created_at": "2025-11-19T16:28:50.933540+00:00",
      "updated_at": "2025-11-19T16:28:50.933542+00:00"
    },
    {
      "id": "67f221596417a576a02485c7000259b0",
      "url": "https://www.biorxiv.org/content/10.1101/2025.11.19.689106v1?rss=1",
      "title": "Immature C. elegans motor neurons control early embryo behavior via both synaptic and non-synaptic GABA release",
      "content": "Pre-natal brain activity has long lasting effects on subsequent neurodevelopment. It is unclear if early brain activity is dominated by cell intrinsic, synaptic, or non-synaptic mechanisms. We address this question by analyzing C. elegans embryo behavior in snf-11 mutants, which lack a plasma membrane GABA re-uptake pump (orthologous to GAT1). At 510-570 minutes post-fertilization, embryo motion was transiently and potently inhibited in snf-11 GAT1 mutants, which precedes formation of most nerve ring synapses. This transient motion inhibition requires GABA synthesis in DD motor neurons and UNC-49 GABAA receptors in body muscles. When motion inhibition occurs, DD neurons have not yet completed neurite outgrowth. Genetic analysis suggests that motion inhibition was mediated by both synaptic and tonic GABA release from DD motor neurons. These results suggest that DD neurons control embryo behavior prior to completing their developmental maturation.",
      "author": "Marvel-Coen, J., Ardiel, E. L., Zhao, J., Nurrish, S., Kaplan, J. M.",
      "published_date": "2025-11-19T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 137,
      "reading_time": 1,
      "created_at": "2025-11-19T16:28:50.933502+00:00",
      "updated_at": "2025-11-19T16:28:50.933505+00:00"
    },
    {
      "id": "5674b36b408b0150fa1e1012243a7372",
      "url": "https://www.biorxiv.org/content/10.1101/2025.11.18.689167v1?rss=1",
      "title": "Convergent and divergent spatial topographies of individualized brain functional networks and their developmental origins",
      "content": "The human brain is intrinsically organized into canonical functional networks with distinct spatial topographies. While precision functional mapping delineates individualized topographies of single networks, the spatial coordination among networks and its developmental origin remains largely unknown. Here, we propose functional topography covariance analysis (FOCA), a novel framework that quantifies convergent and divergent spatial alignments across individualized functional networks and further delineates their internetwork relationships, neurobiological basis, ontogenetic layouts, and cognitive outcomes. Across two well-established task-free functional MRI (fMRI) datasets encompassing both conventional and densely sampled scans, FOCA consistently revealed self-clustered hierarchies in the coordination of functional topographies, closely aligned with existing functional gradients and characterized by convergent couplings within primary systems and divergent couplings in higher-order systems. Such pattern was well predicted by fundamental neurobiological attributes, especially aerobic glycolysis. In a large public neonatal cohort, FOCA matrix exhibited adult-inverted hierarchical couplings and marked changes in auditory and action-mode networks, primarily driven by prominent redistributions of negative couplings. Moreover, neonatal FOCA profiles in the primary visual system significantly predicted neurodevelopmental outcomes at 18 months. Finally, compared with conventional functional connectivity (FC), FOCA proved more robust to global signals and more sensitive to the maturation of negative couplings. These findings highlight the critical role of negative connectivity in brain functional reorganization and advance our understanding of the cooperative and competitive relationships among functional systems and their developmental origins.",
      "author": "Zhao, J., Zhai, Y., Xu, Y., Sun, L., Zhao, T.",
      "published_date": "2025-11-19T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 226,
      "reading_time": 1,
      "created_at": "2025-11-19T16:28:50.933441+00:00",
      "updated_at": "2025-11-19T16:28:50.933452+00:00"
    },
    {
      "id": "afd27399ef2d03ed4b57dd2cef25b103",
      "url": "https://www.nature.com/articles/s41398-025-03703-x",
      "title": "rbfox1 LoF mutants show disrupted bdnf/trkb2 and crhb/nr3c2 expression and increased cortisol levels during development coupled with signs of allostatic overload in adulthood",
      "content": "",
      "author": "",
      "published_date": "2025-11-19T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-11-19T16:28:49.711723+00:00",
      "updated_at": "2025-11-19T16:28:49.711725+00:00"
    },
    {
      "id": "d1dd3c7f7715f1e019c934aca946594c",
      "url": "https://www.nature.com/articles/s41531-025-01169-8",
      "title": "A review of the evidence for a protective role of uric acid in Parkinson\u2019s disease",
      "content": "",
      "author": "",
      "published_date": "2025-11-19T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-11-19T16:28:49.711705+00:00",
      "updated_at": "2025-11-19T16:28:49.711706+00:00"
    },
    {
      "id": "0572ab7602e8af856bcdd15d6ed17371",
      "url": "https://www.nature.com/articles/s42003-025-08971-3",
      "title": "Probabilistic inference of social presence across brain scales reveals enhanced synaptic efficacy",
      "content": "",
      "author": "",
      "published_date": "2025-11-19T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-11-19T16:28:49.711687+00:00",
      "updated_at": "2025-11-19T16:28:49.711688+00:00"
    },
    {
      "id": "daa37ef9a8352e3b13a4e3170b0ba346",
      "url": "https://www.nature.com/articles/s42003-025-09022-7",
      "title": "Socioeconomic context influences the heritability of child cortical structure",
      "content": "",
      "author": "",
      "published_date": "2025-11-19T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-11-19T16:28:49.711669+00:00",
      "updated_at": "2025-11-19T16:28:49.711671+00:00"
    },
    {
      "id": "09b4abe5ac670dcb42082f6994a3e35e",
      "url": "https://www.nature.com/articles/s41597-025-06115-0",
      "title": "Mouse Hippocampal Sharp-Wave Ripple Dataset Curated From Public Neuropixels Datasets",
      "content": "",
      "author": "",
      "published_date": "2025-11-19T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-11-19T16:28:49.711650+00:00",
      "updated_at": "2025-11-19T16:28:49.711652+00:00"
    },
    {
      "id": "2e2f76ba1227e01c4512fa0ab34ba99f",
      "url": "https://www.nature.com/articles/s41539-025-00369-4",
      "title": "Personalized and gamified auditory-cognitive training improves naturalistic speech-in-noise comprehension in older adults with hearing loss",
      "content": "",
      "author": "",
      "published_date": "2025-11-19T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-11-19T16:28:49.711632+00:00",
      "updated_at": "2025-11-19T16:28:49.711634+00:00"
    },
    {
      "id": "8c7c881857c14bc950c91a9c5a7f1132",
      "url": "https://www.nature.com/articles/s41467-025-65238-5",
      "title": "Molecularly defined cellular atlas of the entire mouse brain with isotropic single-cell resolution",
      "content": "",
      "author": "",
      "published_date": "2025-11-19T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-11-19T16:28:49.711614+00:00",
      "updated_at": "2025-11-19T16:28:49.711616+00:00"
    },
    {
      "id": "a370b7ed12463a02134304ccc9d8cfd6",
      "url": "https://www.reddit.com/r/Python/comments/1p1avym/open_python_directory_libraries_for_the_public/",
      "title": "Open Python Directory -- Libraries for the Public Sector",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>I'm on a search for creators of Python libraries that are useful for the public sector.</p> <p>I work in civic tech, where there is growing interest in open source and sharing solutions. The mission is to improve government tech and the lives of citizens. </p> <p>So, we've created an <a href=\"https://github.com/CivicActions/open-python-directory\">Open Python Directory </a>to list libraries centered around the public sector. We've had a couple of contributions from other like-minded organizations, but would love to get more. </p> <p>If you've created a civic-focused open source Python library, <a href=\"https://github.com/CivicActions/open-python-directory/issues/new?template=directory-contribution.md\">let us know so we can list it.</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/funkminster\"> /u/funkminster </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1p1avym/open_python_directory_libraries_for_the_public/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1p1avym/open_python_directory_libraries_for_the_public/\">[comments]</a></span>",
      "author": "/u/funkminster",
      "published_date": "2025-11-19T15:37:05+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 117,
      "reading_time": 1,
      "created_at": "2025-11-19T16:28:15.184877+00:00",
      "updated_at": "2025-11-19T16:28:15.184878+00:00"
    },
    {
      "id": "53f5d773a3aab762bb3a43cffc1c1e22",
      "url": "https://www.reddit.com/r/Python/comments/1p1axnq/pyrefly_beta_release_fast_language_server_type/",
      "title": "Pyrefly Beta Release (fast language server & type checker)",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>As of v0.42.0, <a href=\"https://github.com/facebook/pyrefly\">Pyrefly</a> has now graduated from Alpha to Beta.</p> <p>At a high level, this means:</p> <ul> <li>The IDE extension is ready for production use right now</li> <li>The core type-checking features are robust, with some edge cases that will be addressed as we make progress towards a later stable v1.0 release</li> </ul> <p>Below is a peek at some of the goodies that have been shipped since the Alpha launch in May:</p> <p>Language Server/IDE: - automatic import refactoring - Jupyter notebook support - Type stubs for third-party packages are now shipped with the VS Code extension</p> <p>Type Checking: - Improved type inference &amp; type narrowing - Special handling for Pydantic and Django - Better error messages</p> <p>For more details, check out the release announcement blog: <a href=\"https://pyrefly.org/blog/pyrefly-beta/\">https://pyrefly.org/blog/pyrefly-beta/</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/BeamMeUpBiscotti\"> /u/BeamMeUpBiscotti </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1p1axnq/pyrefly_beta_release_fast_language_server_type/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1p1axnq/pyrefly_beta_release_fast_language_server_type/\">[comments]</a></span>",
      "author": "/u/BeamMeUpBiscotti",
      "published_date": "2025-11-19T15:38:55+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 149,
      "reading_time": 1,
      "created_at": "2025-11-19T16:28:15.184823+00:00",
      "updated_at": "2025-11-19T16:28:15.184825+00:00"
    },
    {
      "id": "a416a0515cbe2b6bd36f3008dc02068d",
      "url": "https://mosaic.so",
      "title": "Launch HN: Mosaic (YC W25) \u2013 Agentic Video Editing",
      "content": "<a href=\"https://news.ycombinator.com/item?id=45980760\">Comments</a>",
      "author": "",
      "published_date": "2025-11-19T15:28:04+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-11-19T16:28:14.015344+00:00",
      "updated_at": "2025-11-19T16:28:14.015346+00:00"
    },
    {
      "id": "75c31498455d19290924212606ed5d3c",
      "url": "https://blog.ericgoldman.org/archives/2025/11/emoji-evidence-errors-dont-undo-a-murder-conviction-people-v-harmon.htm",
      "title": "Emoji Evidence Errors Don't Undo a Murder Conviction\u2013People vs. Harmon",
      "content": "<a href=\"https://news.ycombinator.com/item?id=45981009\">Comments</a>",
      "author": "",
      "published_date": "2025-11-19T15:46:30+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-11-19T16:28:14.015323+00:00",
      "updated_at": "2025-11-19T16:28:14.015325+00:00"
    },
    {
      "id": "a416a0515cbe2b6bd36f3008dc02068d",
      "url": "https://mosaic.so",
      "title": "Launch HN: Mosaic (YC W25) \u2013 Agentic Video Editing",
      "content": "<p>Hey HN! We\u2019re Adish & Kyle from Mosaic (<a href=\"https://mosaic.so\">https://mosaic.so</a>). Mosaic lets you create and run your own multimodal video editing agents in a node-based canvas. It\u2019s different from traditional video editing tools in two ways: (1) the user interface and (2) the visual intelligence built into our agent.<p>We were engineers at Tesla and one day had a fun idea to make a YouTube video of Cybertrucks in Palo Alto. We recorded hours of cars driving by, but got stuck on how to scrub through all this raw footage to edit it down to just the Cybertrucks.<p>We got frustrated trying to accomplish simple tasks in video editors like DaVinci Resolve and Adobe Premiere Pro. Features are hidden behind menus, buttons, and icons, and we often found ourselves Googling or asking ChatGPT how to do certain edits.<p>We thought that surely now, with multimodal AI, we could accelerate this process. Better yet, an AI video editor could automatically apply edits based off what it sees and hears in your video. The idea quickly snowballed and we began our side quest to build \u201cCursor for Video Editing\u201d.<p>We put together a prototype and to our amazement, it was able to analyze and add text overlays based on what it saw or heard in the video. We could now automate our Cybertruck counting with a single chat prompt. That prototype is shown here: <a href=\"https://www.youtube.com/watch?v=GXr7q7Dl9X0\" rel=\"nofollow\">https://www.youtube.com/watch?v=GXr7q7Dl9X0</a>.<p>After that, we spent a chunk of time building our own timeline-based video editor and making our multimodal copilot powerful and stateful. In natural language, we could now ask chat to help with AI asset generation, enhancements, searching through assets, and automatically applying edits like dynamic text overlays. That version is shown here: <a href=\"https://youtu.be/X4ki-QEwN40\" rel=\"nofollow\">https://youtu.be/X4ki-QEwN40</a>.<p>After talking to users though, we realized that the chat UX has limitations for video: (1) the longer the video, the more time it takes to process. Users have to wait too long between chat responses. (2) Users have set workflows that they use across video projects. Especially for people who have to produce a lot of content, the chat interface is a bottleneck rather than an accelerant.<p>That took us back to first principles to rethink what a \u201cnon-linear editor\u201d really means. The result: a node-based canvas which enables you to create and run your own multimodal video editing agents. <a href=\"https://screen.studio/share/SP7DItVD\" rel=\"nofollow\">https://screen.studio/share/SP7DItVD</a>.<p>Each tile in the canvas represents a video editing operation and is configurable, so you still have creative control. You can also branch and run edits in parallel, creating multiple variants from the same raw footage to A/B test different prompts, models, and workflows. In the canvas, you can see inline how your content evolves as the agent goes through each step.<p>The idea is that canvas will run your video editing on autopilot, and get you 80-90% of the way there. Then you can adjust and modify it in an inline timeline editor. We support exporting your timeline state out to traditional editing tools like DaVinci Resolve, Adobe Premiere Pro, and Final Cut Pro.<p>We\u2019ve also used multimodal AI to build in visual understanding and intelligence. This gives our system a deep understanding of video concepts, emotions, actions, spoken word, light levels, shot types.<p>We\u2019re doing a ton of additional processing in our pipeline, such as saliency analysis, audio analysis, and determining objects of significance\u2014all to help guide the best edit. These are things that we as human editors internalize so deeply we may not think twice about it, but reverse-engineering the process to build it into the AI agent has been an interesting challenge.<p>Some of our analysis findings:\nOptimal Safe Rectangles: <a href=\"https://assets.frameapp.ai/mosaicresearchimage1.png\" rel=\"nofollow\">https://assets.frameapp.ai/mosaicresearchimage1.png</a>\nVideo Analysis: <a href=\"https://assets.frameapp.ai/mosaicresearchimage2.png\" rel=\"nofollow\">https://assets.frameapp.ai/mosaicresearchimage2.png</a>\nSaliency Analysis: <a href=\"https://assets.frameapp.ai/mosaicresearchimage3.png\" rel=\"nofollow\">https://assets.frameapp.ai/mosaicresearchimage3.png</a>\nMean Movement Analysis: <a href=\"https://assets.frameapp.ai/mosaicresearchimage4.png\" rel=\"nofollow\">https://assets.frameapp.ai/mosaicresearchimage4.png</a><p>Use cases for editing include: - Removing bad takes or creating script-based cuts from videos / talking-heads - Repurposing longer-form videos into clips, shorts, and reels (e.g. podcasts, webinars, interviews) - Creating sizzle reels or montages from one or many input videos - Creating assembly edits and rough cuts from one or many input videos - Optimizing content for various social media platforms (reframing, captions, etc.) - Dubbing content with voice cloning and lip syncing.<p>We also support use cases for generating content such as motion graphic animations, cinematic captions, AI UGC content, adding contextual AI-generated B-Rolls to existing content, or modifying existing video footage (changing lighting, applying VFX).<p>Currently, our canvas can be used to build repeatable agentic workflows, but we\u2019re working on a fully autonomous agent which will be able to do things like: style transfer using existing video content, define its own editing sequence / workflow without needing a canvas, do research and pull assets from web references, and so on.<p>You can try it today at <a href=\"https://edit.mosaic.so\">https://edit.mosaic.so</a>. You can sign up for free and get started playing with the interface by uploading videos, making workflows on the canvas, and editing them in the timeline editor. We do paywall node runs to help cover model costs. Our API docs are at <a href=\"https://docs.mosaic.so\">https://docs.mosaic.so</a>. We\u2019d love to hear your feedback!</p>\n<hr />\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=45980760\">https://news.ycombinator.com/item?id=45980760</a></p>\n<p>Points: 18</p>\n<p># Comments: 9</p>",
      "author": "adishj",
      "published_date": "2025-11-19T15:28:04+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 846,
      "reading_time": 4,
      "created_at": "2025-11-19T16:28:12.633863+00:00",
      "updated_at": "2025-11-19T16:28:12.633865+00:00"
    }
  ]
}