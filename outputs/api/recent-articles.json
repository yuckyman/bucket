{
  "last_updated": "2025-12-22T08:33:19.911036+00:00",
  "count": 20,
  "articles": [
    {
      "id": "c76193c7196dea33c171f25e81f8164f",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.18.694946v1?rss=1",
      "title": "Physiological Arousal as a Predominant Source of Individual Differences in Functional Brain Networks",
      "content": "Individual differences in brain network function and organization are promising targets for fMRI-based biomarkers in precision psychiatry, yet the sources of individual variability remain poorly understood. We show that arousal, assessed by systemic low-frequency oscillation (sLFO) amplitude in the fMRI signal, accounts for a substantial portion of variance in brain network properties (e.g.: R= 0.70 for default mode network (DMN)-dorsal attention connectivity; R= -0.63 for DMN dynamics). These relationships replicated across sessions, across independent samples, and when assessed with traditional arousal indices. Critically, associations persisted after sLFO denoising, indicating a genuine brain-physiology relationship rather than hemodynamic artifact. Pharmacological manipulation showed that drug-induced sLFO-assessed arousal changes were accompanied by corresponding shifts in network connectivity and dynamics. This work identifies arousal as a prominent determinant of variability in functional brain networks, providing a new perspective on brain-based individual differences while offering an approach to measure arousal directly from fMRI data.",
      "author": "Hill, J. A., Zhai, T., Korponay, C., Welsh, J., Salmeron, B. J., Ross, T. J., Yang, Y., Frederick, B., Janes, A.",
      "published_date": "2025-12-22T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 148,
      "reading_time": 1,
      "created_at": "2025-12-22T08:32:51.748444+00:00",
      "updated_at": "2025-12-22T08:32:51.748445+00:00"
    },
    {
      "id": "4b59dfe733173188583b80e6b0a90053",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.20.692681v1?rss=1",
      "title": "Distinct neural temporal architectures encode rapid social expressions and sustained internal mood states",
      "content": "Affective processing operates across multiple temporal scales, from rapid social signaling through facial expressions to sustained internal mood states, yet the neural computational principles governing these different timescales remain unclear. Understanding how the brain implements distinct temporal architectures for momentary versus persistent affective phenomena is important to comprehending emotional processing and developing objective biomarkers for psychiatric conditions. Here, we introduced a multimodal approach combining automated facial expression monitoring and continuous intracranial electroencephalography in 2,037 electrode contacts across 16 epilepsy patients, over multiple days. Of these, 15 and 12 patients met criteria for facial expression and for mood analysis, respectively. Among patients meeting criteria, we captured 1,396 naturalistic smiles, and 3,746 neutral expressions, separated by at least 10 seconds, alongside 336 periodic mood assessments. This paradigm revealed distinct behavioral and neural computational architectures. Aperiodic neural activity in the lateral temporal cortex (79.5% accuracy) encoded facial expressions with high cross-participant generalizability. Mood states, however, showed different encoding patterns. Facial expressions provided no consistent mood indicators across participants. Critically, low-gamma power dynamics in limbic regions encoded mood states in only a subset of individuals (5 of 12 participants) with expression-mood behavioral correlations, suggesting a distinct encoding phenotype. Cross-domain analysis confirmed computational independence: neural features optimized for facial expression decoding failed to predict sustained mood states, and vice versa. These findings suggest that multiple neural mechanisms may influence underlying affective processing, with variations in their contributions between individuals. The results provide a framework for understanding individual differences in neural mood representation and establish methodological approaches for objective measurement of naturalistic affective behaviors.",
      "author": "Kakusa, B., Gopal, J., Forman, L., Hartford, J. W., Brennan, T., Pantis, S., Persad, A., Cline, C., Buch, V., Parvizi, J., Huang, Y., Keller, C.",
      "published_date": "2025-12-22T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 258,
      "reading_time": 1,
      "created_at": "2025-12-22T08:32:51.748412+00:00",
      "updated_at": "2025-12-22T08:32:51.748414+00:00"
    },
    {
      "id": "1b240e5634731d477389802c92673601",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.19.695176v1?rss=1",
      "title": "Single-cell perturbations reveal adaptive, stimulus-dependent recurrence in visual cortex",
      "content": "Cortical processing must adapt dynamically to the strength of sensory inputs, integrating information when signals are weak and refining representations when they are strong. Experimental and theoretical studies suggest this adaptation involves recurrent cortical circuits through cooperative amplification and competitive interactions within functional networks. Recent studies in mouse primary visual cortex (V1) have begun to support this idea, consistent with novel circuit motifs whereby excitatory and inhibitory cells are strongly connected. Despite these advancements, neither models or data provide a clear picture of the behavior of cortical columns within circuits with functional topography. Here, neighboring cells (excitatory and inhibitory) are selective for similar features in visual space, raising the question as to whether cortical columns act as amplifiers or engage in feature competition. Moreover, columnar network models make a strong prediction: cortical circuits should engage in functional amplification during weak sensory drive, transitioning to suppressive interactions with increasing sensory drive-a prediction not yet directly tested. Using single-cell perturbations in ferret V1, we show that cortical networks switch between amplification and suppression, depending on stimulus strength. Combining two-photon optogenetic stimulation with a generalized linear model (GLM) to quantify perturbations, we uncovered spatially broad suppressive influence modulated by stimulus contrast. At low contrast, we observed amplification between functionally-coupled cells. At high contrast, these networks switched to suppression. This reversal emerged in a recurrent network model with strong inhibitory-excitatory connectivity and weaker excitatory-excitatory connections. This class of models predicts markedly stronger suppressive influences from inhibitory cells onto excitatory populations, which we confirmed with cell-specific perturbations. Our results show that cortical recurrence with functional topography toggles between amplification and suppression, providing direct evidence long-predicted by normative and mechanistic circuit models of visual cortex.",
      "author": "Kong, D., Barreto, J., Butti, L., Kaschube, M., Scholl, B.",
      "published_date": "2025-12-22T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 279,
      "reading_time": 1,
      "created_at": "2025-12-22T08:32:51.748373+00:00",
      "updated_at": "2025-12-22T08:32:51.748375+00:00"
    },
    {
      "id": "14e96b051800be49f99d15a962fcaf84",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.18.694943v1?rss=1",
      "title": "Cortex-wide Dynamics of Internal Decisions About Behavioral Context",
      "content": "Many human decisions manifest in the outside world as motor actions. Correspondingly, neural signals reflecting decision formation are expressed in neural populations encoding the final action. Some decisions, however, are internal, shaping overt behavior indirectly through the selection of policies or rules that guide elementary sensory-motor decisions. We studied the human brain dynamics underlying internal decisions about the stimulus-response mapping rule for reporting visual orientation judgments. The rule changed unpredictably in a hidden fashion, and participants tracked it by accumulating ambiguous sensory cues. Computational model-based decoding of source-level magnetoencephalography data uncovered representations of the internal belief about the active rule in many areas, including occipital cortex. These representations exhibited profiles as predicted by normative models and as observed in action-related frontal areas during overt decisions. We conclude that a widely distributed network of cortical areas implements evidence accumulation for internal decisions, and that even visual cortex may represent high-level beliefs.",
      "author": "Calder-Travis, J., van den Brink, R. L., Thawani, S., Schwabe, L., Donner, T. H.",
      "published_date": "2025-12-21T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 150,
      "reading_time": 1,
      "created_at": "2025-12-22T08:32:51.748331+00:00",
      "updated_at": "2025-12-22T08:32:51.748332+00:00"
    },
    {
      "id": "8ab2b96d1c7b0130c3df15577b54574d",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.17.694588v1?rss=1",
      "title": "Early Post-Stimulus Activity Negatively Predicts P300 Amplitude: A Single-Trial Analysis of the Auditory Oddball Task",
      "content": "The P300 event-related potential is a core index of attention and context updating, yet the trial-by-trial factors that modulate its amplitude remain incompletely characterized. This study tested whether early post-stimulus signal magnitude in the sensory window (0 150 ms) predicts subsequent P300 amplitude (300 600 ms) at the single-trial level. Using data from the ERP CORE auditory oddball dataset (N = 40 participants; 1,661 accepted trials), early activity was quantified as root mean square (RMS) amplitude at electrode Fz. A linear mixed-effects model revealed a statistically reliable negative association between early RMS and P300 amplitude at Pz ({beta} = -0.064, SE = 0.0245, z = -2.61, p = 0.0085). However, early RMS explained minimal trial-level variance (R2 = 0.0042), indicating a modest effect. Model diagnostics confirmed adequate assumptions for inference (Shapiro-Wilk W = 0.9995, p = 0.9690). Exploratory complexity measures (permutation entropy, Lempel / Ziv) were not predictive. Because RMS reflects both signal magnitude and within-trial variability, the findings are most conservatively interpreted as evidence that higher early signal energy is associated with slightly reduced P300 amplitude, possibly reflecting resource competition, refractory effects, or state-dependent processing. The results provide methodologically rigorous evidence for a small but reliable coupling between early and late ERP components, while highlighting the importance of distinguishing amplitude-based measures from trial-to-trial variability. Independent replication and control analyses separating mean amplitude from dispersion are needed to clarify the underlying mechanism.",
      "author": "Biber, E.",
      "published_date": "2025-12-21T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 232,
      "reading_time": 1,
      "created_at": "2025-12-22T08:32:51.748297+00:00",
      "updated_at": "2025-12-22T08:32:51.748299+00:00"
    },
    {
      "id": "1da091aabade49785ab73159e68efcea",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.17.694978v1?rss=1",
      "title": "Evidence for dimensional representations and anticipatory dynamics in facial expression perception",
      "content": "Expression recognition relies on the ability to distinguish subtle visual differences across a range of facial expressions. Here, we examine the neural representation of dynamic expressions as reflected by electroencephalography (EEG) data in human adults. We find that a wide range of expressions (i.e., 14 emotional and 10 conversational expressions) can be decoded from neural signals, and that their representational structure evinces the classic dimensions of valence and arousal. Critically, we recover, through EEG-based video reconstruction, dynamic representations whose content succeeds in capturing even fine differences across related expressions (e.g., happy-satiated versus schadenfreude). Further, time-resolved decoding reveals anticipatory dynamics that maximize accuracy before the occurrence of an apex expression in the visual stimulus. These results are validated against behavioral data, which yield static reconstructions consistent with their neural counterparts. Thus, our results shed light on the representational basis of expression recognition and serve to recover the dynamic content of visual experience.",
      "author": "Roberts, T., Liang, Y. Z., Cupchik, G. C., Cant, J. S., Nestor, A.",
      "published_date": "2025-12-21T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 151,
      "reading_time": 1,
      "created_at": "2025-12-22T08:32:51.748257+00:00",
      "updated_at": "2025-12-22T08:32:51.748258+00:00"
    },
    {
      "id": "9f3e1e3b4a29d0f19bb4534998e0c4f0",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.17.694682v1?rss=1",
      "title": "Evidence for an Integrated Bilingual Language System from Discourse Tasks in Aphasia",
      "content": "Background: The extent to which bilingual individuals represent and process their two languages within a shared or partially distinct neural architecture remains a topic of ongoing debate. While both parallel and divergent patterns of impairment have been reported in bilingual aphasia, such findings likely reflect a spectrum of representational overlap influenced by dominance, proficiency, and task demands. Critically, few studies have examined how breakdown manifests across multiple levels of linguistic structure using ecologically valid, discourse-based tasks. Aims: This study investigates whether Spanish-English bilinguals with aphasia exhibit parallel or dissociable patterns of impairment across their two languages, focusing on naturalistic narrative production and fine-grained analysis of error types and code-switching. Methods & Procedures: Thirteen bilingual individuals with aphasia following acquired brain injury produced story retellings in both languages. Speech samples were transcribed and coded for phonological, morphological, syntactic, and semantic errors, and for the word type at which they occurred. Code-switches were also identified and categorized. Analyses included generalized linear modeling and unsupervised clustering. Outcomes & Results: While participants made more errors in their non-dominant language, the structure and distribution of errors were highly similar across languages. Clustering algorithms revealed that impairments were parallel across languages and did not group by language dominance. Code-switching occurred more frequently from the non-dominant to the dominant language, consistent with activation-based lexical selection. Conclusions: Findings support an integrated bilingual language system that spans multiple levels of linguistic representation, modulated by language dominance. Naturalistic discourse tasks allow for richer characterization of bilingual language breakdown and may better inform both theoretical models and clinical management of bilingual aphasia.",
      "author": "Chen, X. J., Marte, M. J., Kiran, S., Blanco-Elorrieta, E.",
      "published_date": "2025-12-21T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 261,
      "reading_time": 1,
      "created_at": "2025-12-22T08:32:51.748212+00:00",
      "updated_at": "2025-12-22T08:32:51.748217+00:00"
    },
    {
      "id": "883daa88e4678b25484b7b53c12cbdf0",
      "url": "https://www.nature.com/articles/s41537-025-00713-y",
      "title": "Disrupted rest-task shift of multi-band electroencephalography complexity in patients with schizophrenia",
      "content": "",
      "author": "",
      "published_date": "2025-12-22T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-12-22T08:32:50.660467+00:00",
      "updated_at": "2025-12-22T08:32:50.660469+00:00"
    },
    {
      "id": "a6dd1b00785c322e27df9b43cf8f9dce",
      "url": "https://qb64phoenix.com/forum/showthread.php?tid=4244",
      "title": "QBasic64 Phoenix 4.3.0 Released",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46352047\">Comments</a>",
      "author": "",
      "published_date": "2025-12-22T07:25:43+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-22T08:32:15.055000+00:00",
      "updated_at": "2025-12-22T08:32:15.055002+00:00"
    },
    {
      "id": "a6dd1b00785c322e27df9b43cf8f9dce",
      "url": "https://qb64phoenix.com/forum/showthread.php?tid=4244",
      "title": "QBasic64 Phoenix 4.3.0 Released",
      "content": "<p>Article URL: <a href=\"https://qb64phoenix.com/forum/showthread.php?tid=4244\">https://qb64phoenix.com/forum/showthread.php?tid=4244</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46352047\">https://news.ycombinator.com/item?id=46352047</a></p>\n<p>Points: 14</p>\n<p># Comments: 2</p>",
      "author": "jandeboevrie",
      "published_date": "2025-12-22T07:25:43+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-22T08:32:13.595799+00:00",
      "updated_at": "2025-12-22T08:32:13.595807+00:00"
    },
    {
      "id": "dcb065be3da7c045e76e71652520acf8",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.17.695034v1?rss=1",
      "title": "Musical training improves planning and robustness of sequence learning",
      "content": "Musicians demonstrate advantages in acquiring motor sequences, showing faster learning and better explicit sequence knowledge than non-musicians. However, it is unclear whether this advantage extends beyond acquisition to the consolidation phase, which is when newly learned skills stabilize and become resistant to interference. Additionally, while interference from executing competing motor tasks is well-established, less is known about whether purely sensory information presented after learning can disrupt consolidation of a bimodal motor sequence. We investigated how post-acquisition sensory interference affects performance of a learned audio-visual sequence, and whether musical training moderates this vulnerability. Participants first learned an explicit sequence in a serial reaction time task using synchronous, informative audio-visual cues. After a brief consolidation period, they were randomly assigned to one of four observational conditions that manipulated the relationship between auditory and visual streams. Motor performance was then reassessed. Post-acquisition sensory interference significantly impaired subsequent motor performance, but this effect was modality-specific: it was driven primarily by manipulations to the task-relevant visual stream, while auditory interference alone had no credible effect. Distributional analysis revealed that learning involved a strategic shift from reactive to anticipatory responding. Critically, participants with musical training made this shift significantly faster than those without, demonstrating a more rapid adoption of predictive motor control. These findings demonstrate that newly formed sensorimotor memories are selectively vulnerable to interference in task-relevant modalities. Furthermore, our work provides a mechanistic explanation for the musician advantage in sequence learning, linking it to faster development of predictive motor strategies during consolidation.",
      "author": "Leow, L.-A., Lum, J. A., Johnson, S., Corti, E., Marinovic, W.",
      "published_date": "2025-12-21T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 247,
      "reading_time": 1,
      "created_at": "2025-12-22T07:25:48.598519+00:00",
      "updated_at": "2025-12-22T08:23:52.249080+00:00",
      "metadata": {
        "processed_at": "2025-12-22T08:23:52.249091+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "b787ddccf8a4f8e916e1a0c67499f068",
      "url": "https://www.nature.com/articles/s41467-025-67825-y",
      "title": "Distinct mechanisms of transcriptomic habituation to repeated stress in the mouse hippocampus",
      "content": "",
      "author": "",
      "published_date": "2025-12-22T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-12-22T07:25:47.414727+00:00",
      "updated_at": "2025-12-22T08:23:52.249095+00:00",
      "metadata": {
        "processed_at": "2025-12-22T08:23:52.249097+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "2af4cf331b6c804bbcb1e1f360135f60",
      "url": "https://xania.org/202512/15-aliasing-in-general",
      "title": "Aliasing",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46286813\">Comments</a>",
      "author": "",
      "published_date": "2025-12-16T10:13:45+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-22T07:25:11.755043+00:00",
      "updated_at": "2025-12-22T08:23:52.249100+00:00",
      "metadata": {
        "processed_at": "2025-12-22T08:23:52.249102+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "b2714e55c74af50dbb67d60618fa33ef",
      "url": "https://www.nature.com/articles/s41467-025-66124-w",
      "title": "Constructing the human brain metabolic connectome with MR spectroscopic imaging reveals cerebral biochemical organization",
      "content": "",
      "author": "",
      "published_date": "2025-12-22T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-12-22T06:37:22.372134+00:00",
      "updated_at": "2025-12-22T08:23:52.249104+00:00",
      "metadata": {
        "processed_at": "2025-12-22T08:23:52.249106+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "c546f5ca7486a3ee8561e9580fa4f35a",
      "url": "https://www.nature.com/articles/s41528-025-00516-2",
      "title": "Injectable eutectogel for high-quality scalp electroencephalogram monitoring",
      "content": "",
      "author": "",
      "published_date": "2025-12-22T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-12-22T06:37:22.372057+00:00",
      "updated_at": "2025-12-22T08:23:52.249108+00:00",
      "metadata": {
        "processed_at": "2025-12-22T08:23:52.249110+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "3f1ebb488349fb06c49746e031fb0bba",
      "url": "https://www.nature.com/articles/s41746-025-02226-5",
      "title": "Distinct visual biases affect humans and artificial intelligence in medical imaging diagnoses",
      "content": "",
      "author": "",
      "published_date": "2025-12-22T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-12-22T06:37:22.372032+00:00",
      "updated_at": "2025-12-22T06:37:22.372037+00:00"
    },
    {
      "id": "667ffa1c9a9374ed8129f366c85a234d",
      "url": "https://lcamtuf.substack.com/p/cursed-circuits-3-true-mathematics",
      "title": "Cursed circuits #3: true mathematics",
      "content": "<p>Article URL: <a href=\"https://lcamtuf.substack.com/p/cursed-circuits-3-true-mathematics\">https://lcamtuf.substack.com/p/cursed-circuits-3-true-mathematics</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46351345\">https://news.ycombinator.com/item?id=46351345</a></p>\n<p>Points: 6</p>\n<p># Comments: 0</p>",
      "author": "zdw",
      "published_date": "2025-12-22T04:34:36+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-22T06:36:45.575583+00:00",
      "updated_at": "2025-12-22T06:36:45.575591+00:00"
    },
    {
      "id": "3cfcf78b4885ae1adbeaf3e32af4d5ca",
      "url": "https://arxiv.org/abs/2512.17354",
      "title": "Implementation of Augmented Reality as an Educational Tool for Practice in Early Childhood",
      "content": "arXiv:2512.17354v1 Announce Type: new \nAbstract: Learning Wudhu for young children requires engaging and interactive media to foster a deep understanding of the worship procedures. This study aims to develop a Wudhu learning application based on Augmented Reality (AR) as an interactive and fun educational medium. The development method used includes the stages of needs analysis, system design, implementation, and testing using Black Box Testing. The system utilizes marker-based tracking to display 3D animations of Wudhu movements in real-time when the camera detects a marker on the printed media. The test results indicate that all main functions run well, and a limited trial on children aged 5-7 years showed an increase in learning interest and a better understanding of the Wudhu sequence. Thus, the application of AR technology is proven effective in improving the quality of basic worship instruction for young children.",
      "author": "Wisnu Uriawan, Muhammad Aditya Hafizh Zahran, Inayah Ayu Deswita, Muhammad Ahsani Taqwim, Ismail Muhammad Ahmadi, Marvi Yoga Pratama",
      "published_date": "2025-12-22T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 141,
      "reading_time": 1,
      "created_at": "2025-12-22T05:26:36.245302+00:00",
      "updated_at": "2025-12-22T06:27:58.227887+00:00",
      "metadata": {
        "processed_at": "2025-12-22T06:27:58.227899+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "742cd0e2c22cd02d6705e7728f0aa740",
      "url": "https://arxiv.org/abs/2512.17228",
      "title": "LUMIA: A Handheld Vision-to-Music System for Real-Time, Embodied Composition",
      "content": "arXiv:2512.17228v1 Announce Type: new \nAbstract: Most digital music tools emphasize precision and control, but often lack support for tactile, improvisational workflows grounded in environmental interaction. Lumia addresses this by enabling users to \"compose through looking\"--transforming visual scenes into musical phrases using a handheld, camera-based interface and large multimodal models. A vision-language model (GPT-4V) analyzes captured imagery to generate structured prompts, which, combined with user-selected instrumentation, guide a text-to-music pipeline (Stable Audio). This real-time process allows users to frame, capture, and layer audio interactively, producing loopable musical segments through embodied interaction. The system supports a co-creative workflow where human intent and model inference shape the musical outcome. By embedding generative AI within a physical device, Lumia bridges perception and composition, introducing a new modality for creative exploration that merges vision, language, and sound. It repositions generative music not as a task of parameter tuning, but as an improvisational practice driven by contextual, sensory engagement.",
      "author": "Chung-Ta Huang, Connie Cheng, Vealy Lai",
      "published_date": "2025-12-22T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 153,
      "reading_time": 1,
      "created_at": "2025-12-22T05:26:36.245272+00:00",
      "updated_at": "2025-12-22T06:27:58.227903+00:00",
      "metadata": {
        "processed_at": "2025-12-22T06:27:58.227905+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "133948a4560b370e5ecaacf4f19ecd0e",
      "url": "https://arxiv.org/abs/2512.17172",
      "title": "PILAR: Personalizing Augmented Reality Interactions with LLM-based Human-Centric and Trustworthy Explanations for Daily Use Cases",
      "content": "arXiv:2512.17172v1 Announce Type: new \nAbstract: Artificial intelligence (AI)-driven augmented reality (AR) systems are becoming increasingly integrated into daily life, and with this growth comes a greater need for explainability in real-time user interactions. Traditional explainable AI (XAI) methods, which often rely on feature-based or example-based explanations, struggle to deliver dynamic, context-specific, personalized, and human-centric insights for everyday AR users. These methods typically address separate explainability dimensions (e.g., when, what, how) with different explanation techniques, resulting in unrealistic and fragmented experiences for seamless AR interactions. To address this challenge, we propose PILAR, a novel framework that leverages a pre-trained large language model (LLM) to generate context-aware, personalized explanations, offering a more intuitive and trustworthy experience in real-time AI-powered AR systems. Unlike traditional methods, which rely on multiple techniques for different aspects of explanation, PILAR employs a unified LLM-based approach that dynamically adapts explanations to the user's needs, fostering greater trust and engagement. We implement the PILAR concept in a real-world AR application (e.g., personalized recipe recommendations), an open-source prototype that integrates real-time object detection, recipe recommendation, and LLM-based personalized explanations of the recommended recipes based on users' dietary preferences. We evaluate the effectiveness of PILAR through a user study with 16 participants performing AR-based recipe recommendation tasks, comparing an LLM-based explanation interface to a traditional template-based one. Results show that the LLM-based interface significantly enhances user performance and experience, with participants completing tasks 40% faster and reporting greater satisfaction, ease of use, and perceived transparency.",
      "author": "Ripan Kumar Kundu, Istiak Ahmed, Khaza Anuarul Hoque",
      "published_date": "2025-12-22T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 244,
      "reading_time": 1,
      "created_at": "2025-12-22T05:26:36.245243+00:00",
      "updated_at": "2025-12-22T06:27:58.227907+00:00",
      "metadata": {
        "processed_at": "2025-12-22T06:27:58.227909+00:00",
        "processing_method": "github_actions"
      }
    }
  ]
}