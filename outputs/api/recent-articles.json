{
  "last_updated": "2026-01-26T22:25:10.027407+00:00",
  "count": 20,
  "articles": [
    {
      "id": "8eb4996ff4a70fcd87abe6415ccdb836",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.24.701470v1?rss=1",
      "title": "Temporal Phase Differences Encode Tactile Motion from Static Vibrotactile Inputs",
      "content": "Motion perception in touch is traditionally attributed to spatially sequential stimulation or skin deformation caused by moving objects. Here, we demonstrate that directional tactile motion can instead be inferred purely from temporal phase differences between two spatially static vibrotactile inputs. Using psychophysical experiments in human participants (n = 54), we show that continuous vibrations delivered to separate fingertips, when offset in phase, evoke a robust and directionally consistent motion percept despite the absence of physical movement. Discrimination performance depended systematically on the temporal phase relationship between stimuli, following a sinusoidal relationship, consistent with a phase-based motion inference mechanism. Vibration amplitude had little influence on perceptual accuracy once stimuli exceeded detection threshold, although higher amplitudes modestly reduced response times. In contrast, envelope dynamics and spatial configuration significantly modulated performance: vibrations with exponential amplitude envelopes - reflecting the natural propagation of mechanical energy through a medium - enhanced phase sensitivity and sped responses, and bimanual stimulation across the two hands improved both accuracy and response time. These findings identify temporal phase integration as a fundamental mechanism for tactile motion perception, analogous to timing-based computations in auditory localisation and visual motion detection. Phase-coded vibrotactile stimulation therefore offers a minimal and efficient strategy for conveying directional motion in haptic interfaces without requiring spatial arrays or moving actuators.",
      "author": "Rezaei, E., Adibi, M.",
      "published_date": "2026-01-26T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 213,
      "reading_time": 1,
      "created_at": "2026-01-26T22:24:40.380493+00:00",
      "updated_at": "2026-01-26T22:24:40.380494+00:00"
    },
    {
      "id": "43c55d6a7fec21e3ca55a7dcb4556eb9",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.24.701475v1?rss=1",
      "title": "Transcriptomic profiling reveals neurophysiological gene candidates underlying vocal evolution in African clawed frogs",
      "content": "Neurophysiologists have discovered many mechanisms underlying the production of animal behaviors in specific species; these involve a collection of neuromuscular systems, neuronal membrane and neural network properties, as well as the hormones and neuromodulators known to modify them. However, the mechanistic basis of behavioral evolution is less well-studied, and causal links between differences in gene expression, cellular mechanisms and species-typical behaviors are rare. Vertebrate vocal behaviors are an excellent system for studying the evolution of behaviors because they are ancient, diverse and readily quantifiable. Xenopus frogs are particularly well-suited to the study of vocal evolution due to the temporal diversity of male advertisement calls between closely related species and the well-described vocal pattern generating circuitry. Here we focus on two species, X. laevis and X. petersii, that diverged 8.5 million years ago and produce advertisement calls with distinct timing. To begin bridging the gap between behavioral and mechanistic diversity in Xenopus vocal behaviors, we performed RNA sequencing of the parabrachial nucleus, a vocal premotor hindbrain area known to encode species-typical temporal patterns in X. laevis and X. petersii. We identified hundreds of differentially expressed genes between the two species, including many genes related to hormone signaling, neuromodulation, neuronal and synaptic functions, ion channels and neurotransmitter receptors. We explore several testable hypotheses emerging from these results that may explain mechanisms by which candidate genes and gene families may contribute to vocal pattern differences between X. laevis and X. petersii.",
      "author": "Barkan, C. L., Binder, L., Davis, B. A., Carbone, L., Zornik, E.",
      "published_date": "2026-01-26T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 238,
      "reading_time": 1,
      "created_at": "2026-01-26T22:24:40.380456+00:00",
      "updated_at": "2026-01-26T22:24:40.380458+00:00"
    },
    {
      "id": "2ffbdc47d88a9e933d57a7038fb06214",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.23.701239v1?rss=1",
      "title": "Opening the black box: a modular approach to spike sorting",
      "content": "Spike sorting is an algorithmic process to extract the activity of individual neurons from extracellular electrophysiology recordings. With the ballooning use of high density probes, such as Neuropixels, this essential processing step is increasingly becoming time consuming and computationally expensive. Although many software tools have been proposed to address spike sorting, they are usually constructed and benchmarked as monolithic 'black boxes', making it difficult to factor out the effects of individual algorithmic steps on the final outcome, especially when varying datasets and parameters. To address this issue, we developed a modular and common framework to develop, benchmark, and assemble the key computational steps that are used in state-of-the-art spike sorting algorithms. Relying on fast and efficient ground truth generation of biophysically plausible recordings, we show that we are able to individually benchmark and precisely quantify the performance of different steps in a spike sorting pipeline (peak detection, feature extraction and clustering, and template matching). We then leverage these results to create a modular component-based spike sorters that can outperform Kilosort4 on large and dense simulated recordings. In addition, we find that the major bottleneck of all modern spike sorting pipelines is in the physical motion of probes, regardless of the drift-correction strategy. The presented component-based spike sorting framework has the potential to foster community engagement in the field by lowering the barrier to contributions, and provides a flexible yet powerful framework to construct end-to-end spike sorting solutions.",
      "author": "Garcia, S., Halcrow, C., Windolf, C., McKenzie, Z. M., Adkisson-Floro, P., Mayorquin, H. R., Dichter, B. K., Buccino, A. P., Yger, P.",
      "published_date": "2026-01-26T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 237,
      "reading_time": 1,
      "created_at": "2026-01-26T22:24:40.380417+00:00",
      "updated_at": "2026-01-26T22:24:40.380419+00:00"
    },
    {
      "id": "c71c89ede3bdfd55e195cd4c9fbea7d2",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.23.701360v1?rss=1",
      "title": "Global brain activity links subcortical degeneration to cortical tau progressively across Braak regions over early Alzheimer disease stages",
      "content": "Alzheimer disease (AD) is characterized by early tau pathology in subcortical neuromodulatory nuclei, followed by progressive cortical tau accumulation; however, the mechanisms linking subcortical dysfunction to cortical tau pathology remain unclear. Using multimodal neuroimaging data from the ADNI cohort, we examined how infra-slow (< 0.1 Hz) global brain (i.e., gBOLD) activity is related to the volume of the nucleus basalis of Meynert (NbM) and cortical tau accumulations in the early stages of AD. NbM degeneration was associated with reduced gBOLD activity and spatially co-localized tau accumulation, appearing in early Braak regions during the preclinical stage, i.e., cognitively unimpaired participants with abnormal CSF markers, and extending to more advanced Braak areas during the prodromal stage, i.e., mild cognitive impairment (MCI) subjects. Our findings suggest that infra-slow gBOLD activity serves as a functional neural mediator linking subcortical degeneration to cortical tau pathology, highlighting a potential functional pathway linking subcortical and cortical pathology in early AD.",
      "author": "Mao, Y., Pan, B., Liu, X.",
      "published_date": "2026-01-26T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 153,
      "reading_time": 1,
      "created_at": "2026-01-26T22:24:40.380372+00:00",
      "updated_at": "2026-01-26T22:24:40.380374+00:00"
    },
    {
      "id": "857761c4e3a014baffdc5da6f2fdbc1a",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.23.701328v1?rss=1",
      "title": "Neuromark Fusion: A Replicable Multimodal Template for Structure-Function Fusion of Brain MRI",
      "content": "Multimodal data fusion is a powerful technique for extracting shared and complementary information about the brain that is captured across neuroimaging modalities. Independent component analysis (ICA)-based approaches are among the most widely utilized methods for multimodal fusion, as they are data-driven, robust to noise, and capable of identifying complex, hidden linkages of varying strengths across high-dimensional datasets. However, the data-driven nature of ICA fusion approaches can make comparisons across analyses difficult without a normative framework in place. In this work, we utilize resting state functional MRI (rsfMRI) and structural MRI (sMRI) scans from >15,000 subjects to generate a normative model of multimodal structure-function linkages that can be used as a template to guide ICA fusions of new datasets. When applying this template in two datasets, resultant components exhibit high correspondence to the template even in small sample sizes, and subject-level loadings from template-derived ICs show significant associations to age.",
      "author": "Duda, M., Baker, B., Turner, J. A., van Erp, T., Calhoun, V.",
      "published_date": "2026-01-26T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 149,
      "reading_time": 1,
      "created_at": "2026-01-26T22:24:40.380331+00:00",
      "updated_at": "2026-01-26T22:24:40.380335+00:00"
    },
    {
      "id": "560d63d83d116e54022be85a2e66c59c",
      "url": "https://blog.korny.info/2026/01/25/refusing-to-use-twitter",
      "title": "Refusing to Use Twitter",
      "content": "<p>Article URL: <a href=\"https://blog.korny.info/2026/01/25/refusing-to-use-twitter\">https://blog.korny.info/2026/01/25/refusing-to-use-twitter</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46771779\">https://news.ycombinator.com/item?id=46771779</a></p>\n<p>Points: 15</p>\n<p># Comments: 2</p>",
      "author": "pavel_lishin",
      "published_date": "2026-01-26T21:27:15+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2026-01-26T22:23:58.818403+00:00",
      "updated_at": "2026-01-26T22:23:58.818411+00:00"
    },
    {
      "id": "5e63a8b7edf381362775317a4a6fa8ee",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.23.701339v1?rss=1",
      "title": "Neural Signatures of Post-Decision Outcome Expectation and Evaluation in Human Sensorimotor Choice Behavior",
      "content": "The concept of embodied sensorimotor decision-making proposes that processes implicated in evaluating sensory inputs and selecting appropriate motor actions unfold partly in cortical regions traditionally associated with movement planning and execution. Reinforcement learning models emphasize the role of reward prediction error (RPE) in optimizing action selection based on decision outcome feedback. However, most evidence for the existence of RPE signals locates them in midline frontal and parietal cortex, and comes from tasks with externally manipulated reward probabilities that create artificial prediction errors. Whether RPE signals are expressed in human cortical motor areas during deterministic (non-probabilistic) tasks remains unclear, and would provide further support for embodied decision-making. We used magnetoencephalography (MEG) to study post-decision neural dynamics in a color discrimination task in selected cortical regions of interest (ROIs). Participants had to press buttons with their left or right index finger in response to checkerboard stimuli with different levels of color evidence for the correct choice. Outcomes were fully determined by participants' choices. Delayed auditory feedback veridically indicated whether their hand choice was correct or not. We observed a robust beta-band (15-29 Hz) rebound after correct outcome feedback, strongest in ventral and dorsal premotor, anterior cingulate and superior parietal ROIs as well as occipital and auditory ROIs, and weakest in the primary motor and somatosensory ROIs. Critically, the rebound magnitude after correct feedback scaled inversely with color evidence strength and associated decision error rates. It was minimal in strong-evidence trials (~0.1% errors) and maximal in weak-evidence trials (~34% errors), resembling a context-sensitive positive RPE signal that was strongest when a correct outcome was least expected. Alpha-band (8-12 Hz) post-feedback rebound increases in weak evidence trials were not as strong as in the beta band and appeared mainly in occipital, superior parietal and posterior cingulate ROIs. After the decision but before feedback, both beta and alpha band power showed sensitivity to the level of sensory evidence on which the decisions had been based, with reduced post-movement rebound or enhanced suppression in trials with weak evidence, suggestive of internally generated outcome expectations. Pre-feedback alpha rebound suppression was strongest in occipital, superior parietal and posterior cingulate ROIs. Pre-feedback beta rebound suppression was not as strong. Together, these findings reveal distinct beta- and alpha-band dynamics that reflect internal pre-feedback outcome expectations and feedback-driven RPE-like outcome assessments. They support distributed cortical mechanisms, including premotor, parietal and cingulate regions, in reward expectation, outcome evaluation, and adaptive control, highlighting a role for motor and associative cortices in embodied decision-making, performance monitoring, and flexible behavior under uncertainty.",
      "author": "Gharesi, N., Kalaska, J. F., Baillet, S.",
      "published_date": "2026-01-26T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 417,
      "reading_time": 2,
      "created_at": "2026-01-26T21:29:50.367605+00:00",
      "updated_at": "2026-01-26T22:17:37.389653+00:00",
      "metadata": {
        "processed_at": "2026-01-26T22:17:37.389662+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "d8b68f473d5d5ac15a2d20597826b1ed",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.23.701333v1?rss=1",
      "title": "A mathematical model of pathology progression in the TgF344-AD rat model of Alzheimer's disease",
      "content": "Alzheimer's disease (AD) is a devastating neurodegenerative disease whose etiology is poorly understood and for which current treatments provide only modest control of symptoms. To better investigate the causes and progression of the disease, the transgenic TgF344-AD rat model has emerged as a crucial tool. In this paper, we collect observations on the accumulation of amyloid-{beta}, changes in neuronal density, and a decline in cognitive performance in TgF344-AD and wild-type rats. We develop a compartmental ordinary differential equation model and determine its parameters by fitting the output to the experimental observations. Our model simulations support the hypothesis that the accumulation of amyloid-{beta} leads to a rapid decline in neuronal density followed by a significant loss in memory and learning ability. Our mathematical model can provide a bridge between AD research in rodent models and the human condition of AD.",
      "author": "Hesketh, M., Hinow, P.",
      "published_date": "2026-01-26T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 139,
      "reading_time": 1,
      "created_at": "2026-01-26T21:29:50.367541+00:00",
      "updated_at": "2026-01-26T22:17:37.389666+00:00",
      "metadata": {
        "processed_at": "2026-01-26T22:17:37.389668+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "dac4b1fd588175280d332b5f3a88e7ae",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.23.701256v1?rss=1",
      "title": "A Population Vector Model of Visual Working Memory for Real-World Scenes",
      "content": "Visual working memory is essential for navigating through and interacting with complex real-world environments. It is therefore important to understand how natural visual inputs - characterized by complex contours, continuously varying feature gradients, and spatial relationships - are represented in working memory. However, most research in this field has focused on simplified arrays of discrete artificial objects, favoring experimental control and modeling simplicity over ecological validity. This has led to quantitative models of working memory that require inputs consisting of easily parsed objects defined by a single value along one or more simple feature dimensions. It is not clear how these models could be updated to represent complex, photograph-like scenes. To overcome this limitation, we introduce a population vector model of working memory that was designed specifically for real-world scenes. This model represents a scene as a noisy vector of neural firing rates across one or more areas of the ventral pathway, as estimated by a deep neural network model. We show that this model can account for both variations in behavioral performance and patterns of brain activity in tasks that require storing naturalistic scenes in working memory. These results demonstrate the viability of our general modeling approach, setting the stage for more sophisticated models that can fully account for the storage of real-world scenes in working memory.",
      "author": "Kiat, J. E., Luck, S. J.",
      "published_date": "2026-01-26T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 218,
      "reading_time": 1,
      "created_at": "2026-01-26T21:29:50.367509+00:00",
      "updated_at": "2026-01-26T22:17:37.389671+00:00",
      "metadata": {
        "processed_at": "2026-01-26T22:17:37.389673+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "e6c79b6d3b07117680cd73247e290364",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.23.701383v1?rss=1",
      "title": "History-dependent ephaptic interactions in paired olfactory receptor neurons",
      "content": "Olfactory sensing begins with the transduction of odors into receptor currents on the dendrites of olfactory receptor neurons (ORNs). In insects and many other arthropods, ORNs are grouped stereotypically in hair-like sensilla on the surface of olfactory organs, enabling mutual inhibition through non-synaptic 'ephaptic' interactions (NSIs). Given the electrical, and therefore virtually instantaneous, nature of NSIs, it has been hypothesized that they contribute to processing fast temporal elements of mixed odor plumes. Here, we present single sensillum recordings and computational modeling that characterize NSIs during short offset dual-odor stimulations in the olfactory sensilla of adult female Drosophila melanogaster. We find in the experiments that the magnitude of inhibition between co-housed ORNs cannot be predicted by their instantaneous activity (firing rate) alone. It is adaptation-dependent, with strong effects only occurring when the inhibited ORN is adapted. This limits the usefulness of NSIs for fast odor processing when ORNs lack time to adapt. We reproduced the observed phenomena in a computational model and use this model to explain how the adaptation-dependence of NSI-mediated inhibition arises from nonlinearities in neural responses. We conclude that NSIs are unlikely to support the encoding of fast temporal dynamics in mixed odor stimuli, instead contributing to slower peripheral processing, supporting roles such as novelty detection. More broadly, we demonstrate how the nonlinear interactions of fairly simple electrical components lead to non-intuitive results, offering insight into the longstanding debate around ephaptic interactions in other systems, such as the mammalian CNS.",
      "author": "Ellison, L., Kemenes, G., Nowotny, T.",
      "published_date": "2026-01-26T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 242,
      "reading_time": 1,
      "created_at": "2026-01-26T21:29:50.367464+00:00",
      "updated_at": "2026-01-26T22:17:37.389675+00:00",
      "metadata": {
        "processed_at": "2026-01-26T22:17:37.389676+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "a18b6158de97ecd6aa5e2472598a7bc4",
      "url": "https://www.wsj.com/business/the-secret-society-of-people-who-know-the-formula-for-wd-40-e9c0ff54",
      "title": "People who know the formula for WD-40",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46771599\">Comments</a>",
      "author": "",
      "published_date": "2026-01-26T21:11:53+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-26T21:29:10.604427+00:00",
      "updated_at": "2026-01-26T22:17:37.389679+00:00",
      "metadata": {
        "processed_at": "2026-01-26T22:17:37.389680+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "a18b6158de97ecd6aa5e2472598a7bc4",
      "url": "https://www.wsj.com/business/the-secret-society-of-people-who-know-the-formula-for-wd-40-e9c0ff54",
      "title": "People who know the formula for WD-40",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46771599\">Comments</a>",
      "author": "",
      "published_date": "2026-01-26T21:11:53+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-26T21:29:10.604427+00:00",
      "updated_at": "2026-01-26T22:17:37.389679+00:00",
      "metadata": {
        "processed_at": "2026-01-26T22:17:37.389680+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "ea48755ec8441df59608c0273e8f73a4",
      "url": "https://www.zackliscio.com/posts/rip-low-code-2014-2025/",
      "title": "RIP Low-Code 2014-2025",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46767440\">Comments</a>",
      "author": "",
      "published_date": "2026-01-26T16:11:28+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-26T21:29:10.604330+00:00",
      "updated_at": "2026-01-26T21:29:10.604332+00:00"
    },
    {
      "id": "a5560c1ab484b945b674d84af7f497fa",
      "url": "https://practical.engineering/blog/2026/1/20/the-hidden-engineering-of-runways",
      "title": "The Hidden Engineering of Runways",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46694193\">Comments</a>",
      "author": "",
      "published_date": "2026-01-20T16:52:52+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-26T21:29:10.604284+00:00",
      "updated_at": "2026-01-26T21:29:10.604286+00:00"
    },
    {
      "id": "d313793ff6dd93974faa50761c46a0c7",
      "url": "https://ourguide.ai",
      "title": "Show HN: Ourguide \u2013 OS wide task guidance system that shows you where to click",
      "content": "<p>Hey! I'm eshaan and I'm building Ourguide -an on-screen task guidance system that can show you where to click step-by-step when you need help.<p>I started building this because whenever I didn\u2019t know how to do something on my computer, I found myself constantly tabbing between chatbots and the app, pasting screenshots, and asking \u201cwhat do I do next?\u201d Ourguide solves this with two modes. In Guide mode, the app overlays your screen and highlights the specific element to click next, eliminating the need to leave your current window. There is also Ask mode, which is a vision-integrated chat that captures your screen context\u2014which you can toggle on and off anytime -so you can ask, \"How do I fix this error?\" without having to explain what \"this\" is.<p>It\u2019s an Electron app that works OS-wide, is vision-based, and isn't restricted to the browser.<p>Figuring out how to show the user where to click was the hardest part of the process. I originally trained a computer vision model with 2300 screenshots to identify and segment all UI elements on a screen and used a VLM to find the correct icon to highlight. While this worked extremely well\u2014better than SOTA grounding models like UI Tars\u2014the latency was just too high. I'll be making that CV+VLM pipeline OSS soon, but for now, I\u2019ve resorted to a simpler implementation that achieves <1s latency.<p>You may ask: if I can show you where to click, why can't I just click too? While trying to build computer-use agents during my job in Palo Alto, I hit the core limitation of today\u2019s computer-use models where benchmarks hover in the mid-50% range (OSWorld). VLMs often know what to do but not what it looks like; without reliable visual grounding, agents misclick and stall. So, I built computer use\u2014without the \"use.\" It provides the visual grounding of an agent but keeps the human in the loop for the actual execution to prevent misclicks.<p>I personally use it for the AWS Console's \"treasure hunt\" UI, like creating a public S3 bucket with specific CORS rules. It\u2019s also been surprisingly helpful for non-technical tasks, like navigating obscure settings in Gradescope or Spotify. Ourguide really works for any task when you\u2019re stuck or don't know what to do.<p>You can download and test Ourguide here: <a href=\"https://ourguide.ai/downloads\" rel=\"nofollow\">https://ourguide.ai/downloads</a><p>The project is still very early, and I\u2019d love your feedback on where it fails, where you think it worked well, and which specific niches you think Ourguide would be most helpful for.</p>\n<hr />\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46769422\">https://news.ycombinator.com/item?id=46769422</a></p>\n<p>Points: 6</p>\n<p># Comments: 1</p>",
      "author": "eshaangulati",
      "published_date": "2026-01-26T18:19:45+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 423,
      "reading_time": 2,
      "created_at": "2026-01-26T21:29:09.489509+00:00",
      "updated_at": "2026-01-26T21:29:09.489511+00:00"
    },
    {
      "id": "fbe8de9f1dc91987e872fbff41c2f58e",
      "url": "https://simonwillison.net/2026/Jan/26/chatgpt-containers/",
      "title": "ChatGPT Containers can now run bash, pip/npm install packages and download files",
      "content": "<p>Article URL: <a href=\"https://simonwillison.net/2026/Jan/26/chatgpt-containers/\">https://simonwillison.net/2026/Jan/26/chatgpt-containers/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46770221\">https://news.ycombinator.com/item?id=46770221</a></p>\n<p>Points: 6</p>\n<p># Comments: 1</p>",
      "author": "simonw",
      "published_date": "2026-01-26T19:19:40+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2026-01-26T20:53:10.316156+00:00",
      "updated_at": "2026-01-26T20:53:10.316157+00:00"
    },
    {
      "id": "61e259c2875f1f44cbe6de07213648bd",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.23.701340v1?rss=1",
      "title": "Oculomotor dance learning task: Implications for audio-visual cued spatial learning",
      "content": "Learning dance of a motor sequence learning involves the coordination of both oculomotor and manual motor systems through the practiced repetition of a fixed sequence of actions, resulting in automatized execution of movement through habit learning. This study aims to address whether a sequence-based learning paradigm centered on the visual-motor system can feasibly be measured while listening to music (Bar and DeSouza 2016). It aims to develop a new visual-motor-based learning paradigm with music, potentially promoting neuroplasticity and creating new interventional tools, building upon prior research that shows behavioural and putative neural changes following dance-based neurorehabilitation in people with Parkinson's disease (Bearss et al. 2024). Eye movements of 10 participants (8 female, 2 male) were tracked using the Eyelink 1000 Plus system during a 68-second eye-dance sequence. The experiment consisted of a learning phase, where participants observed the sequence five times with 30-second breaks, and a performance phase, where they performed the sequence five times from memory on a grey screen without visual cues. Music was incorporated into both phases to aid memorization of the 4 spatial locations. After each performance, the participant was shown a visual reinforcer and asked for their thoughts on how well they executed the dance. A visual reinforcer flashes one of three different colours: red, yellow, or green. Each colour corresponds to how many steps in the dance a participant performed correctly, with key points being: under one third, between one to two thirds, and over two thirds of total steps correct. Participants were scored based on timing of the steps as well for exact (1.00), good (0.66), slightly off (0.33) or missed (0) steps. Data was analyzed using R4.3.1, MATLAB, and Experiment Builder: Data Viewer software. Results showed a significant improvement in performance accuracy between the first session (g1; M = 40%, SD = 7.2%) and the last session (g5; M = 69.7%, SD = 22.8%). A repeated-measures ANOVA revealed a significant main effect of session on performance accuracy, F(4, 36) = 6.99, p < 0.001, 2G = 0.26, indicating that accuracy significantly improved over sessions. Post-hoc Bonferroni comparisons showed that accuracy in later sessions was significantly higher than earlier sessions, suggesting a defined learning curve and consolidation of performance pattern across repeated practice. Similarly, there was significant improvement in timing accuracy between the first session g1; M = 0.29, SD = 0.06) and the fifth session (g5; M = 0.46, SD = 0.12). A repeated-measures ANOVA revealed a significant main effect of session on timing precision, F(4, 36) = 11.67, p < 0.001, 2G = 0.25, indicating significant improvements in temporal control and coordination over sessions. Post-hoc Bonferroni comparisons showed that timing precision significantly improved between early and late sessions (e.g, g1-g4, p <0.01; g1-g5, p < 0.001), suggesting a defined learning curve and increase in precision across repeated practice. These findings suggest that visual-motor-based interventions have the potential to enhance motor and non-motor symptoms like depression and anxiety for neurodegenerative diseases such as Parkinson's Disorder (PD). The results provide a foundation for developing targeted therapies that integrate learning paradigms to improve functional outcomes, warranting further exploration of their long-term efficacy.",
      "author": "Petrovski, M., Beheiry, S., Das, U. U., Rooprai, S., Karimi, A., Simon, J. R., Bar, R. J., DeSouza, J. F.",
      "published_date": "2026-01-26T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 518,
      "reading_time": 2,
      "created_at": "2026-01-26T20:30:05.527896+00:00",
      "updated_at": "2026-01-26T20:30:05.527899+00:00"
    },
    {
      "id": "f3968d6ca1a6621ed2cba328f550039a",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.23.701370v1?rss=1",
      "title": "Impaired Associative Memory, Inference, and Theta Dynamics in Postictal Psychosis of Epilepsy",
      "content": "Postictal psychosis (PIP) is a severe complication occurring in 2% of people with epilepsy (PWE) whose underlying pathophysiology remains poorly understood. Although historically considered separate from other forms of psychosis, newer evidence demonstrates a shared genetic susceptibility. People with schizophrenia are typically impaired at both associative learning and inferring connections between overlapping associations. Successful associative encoding, retrieval, and inference can each be predicted by changes in frontotemporal theta band activity, which is impaired in rodent models and people with schizophrenia. Here, we recorded high-density scalp EEG from PWE with history of PIP and well-matched control participants while they undertook a memory inference task. We found that associative memory and inference were both impaired in the PIP group, despite no difference in item recognition. Moreover, we found disrupted theta activity during memory encoding and the retrieval of inferred associations in PWE with PIP that likely originated from the medial temporal and frontal lobes. These results suggest a pattern of behavioural deficits and altered neural dynamics common to both PIP and schizophrenia. Interpreted in conjunction with previous genetic studies, they may reflect shared neural mechanisms contributing to psychopathology in both conditions and argue that PIP is a model of more general psychoses.",
      "author": "Dworkin, A., Wang, D., Jimenez, D., Ravenscroft, C., Turco, F., Johnson, C., Chowdhury, F. A., Pizarro, J., Walker, M., Balestrini, S., Bush, D., Vivekananda, U.",
      "published_date": "2026-01-26T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 200,
      "reading_time": 1,
      "created_at": "2026-01-26T20:30:05.527809+00:00",
      "updated_at": "2026-01-26T20:30:05.527811+00:00"
    },
    {
      "id": "89f6d50ed8bfe08d8cbc191c05268195",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.23.701367v1?rss=1",
      "title": "Systemic AAV delivery of a calcium indicator in marmosets: functional validation in visual area MT",
      "content": "Functional optical imaging in nonhuman primates provides an important complement to electrophysiological approaches in neuroscience research, but its broader use has been limited by challenges in achieving large-scale, homogeneous expression of genetically encoded reporters, and imaging accessibility in species with gyrencephalic brains with sulci and fissures (e.g., rhesus macaques). Specifically, conventional local intracortical viral injections are invasive and often produce spatially restricted or heterogeneous expression, constraining population-level analyses. Here, we show that systemic intravenous delivery of an adeno-associated virus (AAV) capsid engineered for enhanced blood-brain barrier crossing, AAV.CAP-B10, supports robust and widespread expression of a calcium indicator CAaMP8s in the common marmoset. Intravenous delivery in two marmosets resulted in widespread cortical expression. Using a large cranial window over extrastriate visual area MT (and its satellite areas), we performed widefield single-photon imaging and two-photon cellular-resolution imaging in awake,behaving marmosets to functionally validate activity in this well studied primate visual-motion sensitive cortical area. Population level responses to visual motion and spatial organization measured with widefield imaging, as well as single-cell level motion direction tuning measured with two-photon imaging, were consistent with canonical properties of MT reported in previous electrophysiological studies. Quantitative analyses of lightsheet imaging after whole hemisphere brain clearing further confirmed the broad expression of GCaMP in both cortical and subcortical areas. Together, these results indicate that systemic delivery using AAV.CAP-B10 provides a minimally invasive approach for robust multi-scale functional optical imaging in awake, behaving marmosets.",
      "author": "Chen, P.-S., Rowley, D. P., Rudd, M., Laudano, A., Villa, A. P., Garcia, F., Dong, H.-w., Shay, T. F., Huk, A. C., Steele, A. D., Wekselblatt, J.",
      "published_date": "2026-01-26T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 235,
      "reading_time": 1,
      "created_at": "2026-01-26T20:30:05.527774+00:00",
      "updated_at": "2026-01-26T20:30:05.527776+00:00"
    },
    {
      "id": "03ec6202da4bd0cff73daec2303723aa",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.23.700794v1?rss=1",
      "title": "Temporal Dynamics of EEG Decoding for Continuously Changing Visual Stimuli",
      "content": "Multivariate analyses of M/EEG data are typically performed on neural responses time-locked to discrete stimulus onsets. Such designs usually reveal high decoding performance during the initial transient response (0-500 ms), which subsequently drops to a lower, sustained level. Here, we examined time-resolved EEG decoding of natural scene processing when scenes gradually enter the visual field without a clear onset. We created video sequences in which one scene category (e.g., a beach) smoothly transitioned into another category (e.g., a forest) by blending images from two categories into a single composite panorama and moving a square aperture across it. We then compared EEG decoding for the first scenes within the transitions, which appeared with a sudden onset, to the second scenes, which emerged gradually as the videos progressed. For the first scenes, we observed robust category decoding from 60 ms after onset with a clear peak structure. For the second scene, category decoding was markedly weaker and showed no discernable peak structure. Realigning the appearance of category-diagnostic content for the second scene using deep neural networks did not enhance decoding or recover a peak structure. Further, classifiers trained on the first scene generalized to the second, but with a broad, temporally diffuse pattern, indicating that the second scene did not engage the same hierarchical temporal cascade as the first. Together, these results demonstrate that sudden versus gradual onsets produce distinct temporal decoding dynamics. Insights from onset-based decoding studies, therefore, do not straightforwardly extend to continuous and free-flowing natural stimulation.",
      "author": "Duymaz, I., Engeser, M., Kaiser, D.",
      "published_date": "2026-01-26T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 247,
      "reading_time": 1,
      "created_at": "2026-01-26T20:30:05.527729+00:00",
      "updated_at": "2026-01-26T20:30:05.527734+00:00"
    }
  ]
}