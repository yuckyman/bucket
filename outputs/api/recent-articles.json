{
  "last_updated": "2025-10-24T10:17:06.565253+00:00",
  "count": 20,
  "articles": [
    {
      "id": "3126a4e56a81b2be3ee1af1e1e87dffc",
      "url": "http://ieeexplore.ieee.org/document/11153357",
      "title": "An Emergentist Account of Language in the Brain\u2014Seeking Neural Synergies Behind Human Uniqueness",
      "content": "Cognitive neuroscience has become increasingly open to views of human cognitive faculties as emergent properties\u2014as higher-level products of synergies between brain structures handling qualitatively different functions. This new perspective mitigates claims that cognitive abilities are tied to localized, domain-specific brain systems. In this changing landscape, the neurobiology of language has lagged behind, with virtually no mature theory apt to guide an exploration of language as an emergent function of the human brain. Combining evidence that linguistic processing is distributed across neurocognitive systems supporting (among others) semantic cognition, executive functions, and articulatory-motor control with recent advances in studying neural synergies, we propose a model of language as a deeply synergistic phenomenon that is both decoupled from its lower-level constituents and capable of exerting downward causal powers over them, accounting for its key role in human adaptive behavior. In considering the implications it has in our understanding of the place of language within the broader infrastructure of human behavior, this novel perspective aims to move the neurobiology of language forward in a new era of the cognitive neuroscience.",
      "author": "",
      "published_date": "2025-09-08T13:16:44+00:00",
      "source": "Cognitive Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 176,
      "reading_time": 1,
      "created_at": "2025-10-24T09:41:56.846596+00:00",
      "updated_at": "2025-10-24T10:17:06.457522+00:00",
      "metadata": {
        "processed_at": "2025-10-24T10:17:06.457531+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "c307ab5dab9f6c7578186615c5aa70b9",
      "url": "http://ieeexplore.ieee.org/document/11153359",
      "title": "Impact of Transcutaneous Vagus Nerve Stimulation on Event-related Potentials during a Response Inhibition Task",
      "content": "As an emerging neuromodulation technique, transcutaneous auricular vagus nerve stimulation (taVNS) has shown promise in enhancing cognitive abilities. The present study used a combination of the go/no-go task and the stop-signal task experimental paradigm to examine the cognitive effects of taVNS on participants' EEG measures. Sixty-one healthy participants were randomly assigned to either the stimulation group or the sham group. Participants in the stimulation group received 100 Hz and 25 Hz stimulation in a counterbalanced order. We compared behavioral and EEG data before and after stimulation, and observed significant effects. The findings revealed that a 100-Hz taVNS significantly reduced participants' N2 latency in the stop trial, indicating potential improvement response inhibition. In addition, we noted a decreasing trend in alpha, theta, and delta band power during response inhibition after receiving a 100-Hz taVNS. These results suggest that a 100-Hz taVNS can enhance participants' response inhibition abilities, indicating its potential as a therapeutic approach for modulating cognitive functions.",
      "author": "",
      "published_date": "2025-09-08T13:16:40+00:00",
      "source": "Cognitive Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 157,
      "reading_time": 1,
      "created_at": "2025-10-24T09:41:56.846564+00:00",
      "updated_at": "2025-10-24T10:17:06.457536+00:00",
      "metadata": {
        "processed_at": "2025-10-24T10:17:06.457537+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "4b601b9c934f95d9db5ecc44c2eee1e3",
      "url": "http://ieeexplore.ieee.org/document/11153356",
      "title": "Confidence and Insight into Working Memory Are Shaped by Attention and Recent Performance",
      "content": "Working memory is capacity-limited, and our ability to access information from working memory is variable, but selective attention to working memory contents can improve performance. People are able to make introspective judgments regarding the quality of their memories, and these judgments are linked to objective memory performance. However, it remains unknown whether benefits of internally directed attention on memory performance occur alongside commensurate changes in introspective judgments. Across two experiments, we used retrospective cues (retrocues) during working-memory maintenance to direct attention to items in memory. We then examined their consequence on introspective judgments. In the second experiment, we provided trial-wise feedback on performance. We found that selective attention improved confidence judgments and not just performance of the probed item. We were also able to judge participants' genuine insight into working-memory contents through the correlation between confidence judgments and memory quality. Neurophysiologically, alpha desynchronization correlated first with memory error and then confidence during retrocueing, suggesting a sequential process of attentional enhancement of memory contents and introspective insight. Furthermore, we showed that participants can use feedback on the accuracy of confidence judgments to update their beliefs across time, according to performance. Our results emphasize flexibility in working memory by showing we can selectively modulate our confidence about its contents based on internally directed attention or objective feedback.",
      "author": "",
      "published_date": "2025-09-08T13:16:44+00:00",
      "source": "Cognitive Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 215,
      "reading_time": 1,
      "created_at": "2025-10-24T09:41:56.846535+00:00",
      "updated_at": "2025-10-24T10:17:06.457540+00:00",
      "metadata": {
        "processed_at": "2025-10-24T10:17:06.457542+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "a47557cc5e826f075324e7184c294afd",
      "url": "http://ieeexplore.ieee.org/document/11153351",
      "title": "Perceptual Decoupling Underlies Internal Shielding Benefit during Switches between External and Internal Attention: Evidence from Early Sensory Event-related Potential Components",
      "content": "People need to often switch attention between external and internal sources of information, that is, external and internal attention, respectively. There has been a recent surge of research interest in this type of attentional flexibility, which has revealed that it is characterized by an asymmetrical cost, being larger for switching toward internal than external attention. This cost asymmetry has been explained in terms of an internal shielding benefit, that is, the maintenance of stable internal attention against external interference. Although it is currently unclear how internal information might be shielded from external input during switches, a likely candidate is perceptual decoupling. In this study, we instructed participants to repeat external or internal attention, or to switch between them from trial to trial, while simultaneously recording 64-channel EEG. At the behavioral level, we replicated the switch cost asymmetry. Our ERP analysis provided evidence for three different processing stages. First, participants prepared more strongly for an upcoming internal than external attentional selection, as reflected in the increased contingent negative variation component. Second, during internal trials, participants moreover showed a blunted sensory response, most notable in the P1 and N1 components, reflecting perceptual decoupling. Finally, we found an increased P2 component when switching toward internal attention compared with repeating it, indicating more stable perceptual decoupling on internal repetition trials, in line with an internal shielding benefit. We integrate these findings here with behavioral accounts of the cost asymmetry and conclude that perceptual decoupling provides a potential mechanism for the internal shielding benefit of attention.",
      "author": "",
      "published_date": "2025-09-08T13:16:44+00:00",
      "source": "Cognitive Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 251,
      "reading_time": 1,
      "created_at": "2025-10-24T09:41:56.846501+00:00",
      "updated_at": "2025-10-24T10:17:06.457544+00:00",
      "metadata": {
        "processed_at": "2025-10-24T10:17:06.457546+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "e0899403e0a8c6fb0b591f26e5e5d1b5",
      "url": "http://ieeexplore.ieee.org/document/11153358",
      "title": "Lexical and Information Structure Functions of Prosody and Their Relevance for Spoken Communication: Evidence from Psychometric and Electroencephalographic Data",
      "content": "Prosody not only distinguishes \u201clexical\u201d meaning but also plays a key role in information packaging by highlighting the most relevant constituent of the discourse, namely, \u201cfocus\u201d information. The present study investigated the role of lexical and focus functions of prosody in the coherent interpretation of linguistic input. To this end, we manipulated the correctness of prosodic markers in the context and scrutinized how listeners evaluate these violations\u2014whether they result in lexical or focus anomalies\u2014using psychometric and EEG measures. Psychometric data from 40 participants indicated that prosodic violations were judged as incorrect by the listeners both at the lexical and focus levels, with focus level violations leading to lower correctness scores than lexical level violations, and combined violations receiving the lowest scores. EEG data from 20 participants documented a strong N400 effect (350\u2013550 msec) in response to combined violations, and a late posterior negativity (600\u2013900 msec) present only for combined violations and focus-level violations. Consistent with the psychometric data, the EEG data suggest that prosodic violations at the focus level result in higher costs for comprehension than prosodic violations at the lexical level, whereas combined prosodic violations most significantly disrupt the interpretation. Taken together, these findings suggest that the language comprehension system is sensitive to accurate representations of both lexical and information structure prosody, and benefits from the interaction between them; however, they are weighted differently based on their relevance for a functioning spoken communication.",
      "author": "",
      "published_date": "2025-09-08T13:16:44+00:00",
      "source": "Cognitive Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 234,
      "reading_time": 1,
      "created_at": "2025-10-24T09:41:56.846464+00:00",
      "updated_at": "2025-10-24T10:17:06.457548+00:00",
      "metadata": {
        "processed_at": "2025-10-24T10:17:06.457549+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "7c4031974efdff1e7f6c52ab82a8e379",
      "url": "http://ieeexplore.ieee.org/document/11153363",
      "title": "Musical Structure Influences the Perception of Sound Location",
      "content": "The perception of multilayered auditory stimuli, such as music or speech, relies on the integration of progressively more complex and abstract features as they are processed along the auditory pathway. To investigate whether higher-level musical structure modulates auditory perception or merely the interpretation of perceived information, we examined the interaction between sound location\u2014a low-level feature\u2014and musical phrases, which are structures spanning across seconds and require temporal integration of information within continuous stimuli. This was to observe whether musical phrase boundaries modulate pre-attentive and explicit sensitivity to the location changes. Participants listened to melodies with randomized location changes and either actively reported detection of change or passively listened while EEG data were collected. Analysis of mismatch negativity responses revealed significantly larger amplitudes for location changes occurring at phrase boundaries, suggesting that musical grouping enhances the perceptual salience of these changes, conveyed by physically identical cues. Behaviorally, participants showed no difference in sensitivity but were more likely to report location changes at phrase boundaries, even when no change occurred. These findings demonstrate that higher-level musical structure modulates pre-attentive auditory processing and influences perception of spatial location. This effect appears to rely on fundamental auditory mechanisms rather than musical expertise, highlighting the dynamic interaction between abstract musical structure and low-level sensory processing.",
      "author": "",
      "published_date": "2025-09-08T13:16:44+00:00",
      "source": "Cognitive Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 209,
      "reading_time": 1,
      "created_at": "2025-10-24T09:41:56.846419+00:00",
      "updated_at": "2025-10-24T09:41:56.846424+00:00"
    },
    {
      "id": "698a3967478d4ba61f5711c9117ea7e6",
      "url": "https://www.embs.org/uncategorized/call-for-applications-ieee-tmrb-editor-in-chief-search/",
      "title": "Call for Applications: IEEE T-MRB Editor in Chief Search",
      "content": "<p>The post <a href=\"https://www.embs.org/uncategorized/call-for-applications-ieee-tmrb-editor-in-chief-search/\">Call for Applications: IEEE T-MRB Editor in Chief Search</a> appeared first on <a href=\"https://www.embs.org\">IEEE EMBS</a>.</p>",
      "author": "Deidre Artis",
      "published_date": "2025-04-03T14:16:16+00:00",
      "source": "Embs",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 18,
      "reading_time": 1,
      "created_at": "2025-10-24T09:41:55.281134+00:00",
      "updated_at": "2025-10-24T09:41:55.281136+00:00"
    },
    {
      "id": "b8aa5ddba7bb20ef66176b84e3e9d225",
      "url": "https://arxiv.org/abs/2510.20276",
      "title": "From Generation to Attribution: Music AI Agent Architectures for the Post-Streaming Era",
      "content": "arXiv:2510.20276v1 Announce Type: cross \nAbstract: Generative AI is reshaping music creation, but its rapid growth exposes structural gaps in attribution, rights management, and economic models. Unlike past media shifts, from live performance to recordings, downloads, and streaming, AI transforms the entire lifecycle of music, collapsing boundaries between creation, distribution, and monetization. However, existing streaming systems, with opaque and concentrated royalty flows, are ill-equipped to handle the scale and complexity of AI-driven production. We propose a content-based Music AI Agent architecture that embeds attribution directly into the creative workflow through block-level retrieval and agentic orchestration. Designed for iterative, session-based interaction, the system organizes music into granular components (Blocks) stored in BlockDB; each use triggers an Attribution Layer event for transparent provenance and real-time settlement. This framework reframes AI from a generative tool into infrastructure for a Fair AI Media Platform. By enabling fine-grained attribution, equitable compensation, and participatory engagement, it points toward a post-streaming paradigm where music functions not as a static catalog but as a collaborative and adaptive ecosystem.",
      "author": "Wonil Kim, Hyeongseok Wi, Seungsoon Park, Taejun Kim, Sangeun Keum, Keunhyoung Kim, Taewan Kim, Jongmin Jung, Taehyoung Kim, Gaetan Guerrero, Mael Le Goff, Julie Po, Dongjoo Moon, Juhan Nam, Jongpil Lee",
      "published_date": "2025-10-24T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 169,
      "reading_time": 1,
      "created_at": "2025-10-24T09:41:53.973673+00:00",
      "updated_at": "2025-10-24T09:41:53.973674+00:00"
    },
    {
      "id": "c3a27d01636ee17a503a3203081459d4",
      "url": "https://arxiv.org/abs/2510.20255",
      "title": "Towards AI Agents for Course Instruction in Higher Education: Early Experiences from the Field",
      "content": "arXiv:2510.20255v1 Announce Type: cross \nAbstract: This article presents early findings from designing, deploying and evaluating an AI-based educational agent deployed as the primary instructor in a graduate-level Cloud Computing course at IISc. We detail the design of a Large Language Model (LLM)-driven Instructor Agent, and introduce a pedagogical framework that integrates the Instructor Agent into the course workflow for actively interacting with the students for content delivery, supplemented by the human instructor to offer the course structure and undertake question--answer sessions. We also propose an analytical framework that evaluates the Agent--Student interaction transcripts using interpretable engagement metrics of topic coverage, topic depth and turn-level elaboration. We report early experiences on how students interact with the Agent to explore concepts, clarify doubts and sustain inquiry-driven dialogue during live classroom sessions. We also report preliminary analysis on our evaluation metrics applied across two successive instructional modules that reveals patterns of engagement evolution, transitioning from broad conceptual exploration to deeper, focused inquiry. These demonstrate how structured integration of conversational AI agents can foster reflective learning, offer a reproducible methodology for studying engagement in authentic classroom settings, and support scalable, high-quality higher education.",
      "author": "Yogesh Simmhan, Varad Kulkarni",
      "published_date": "2025-10-24T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 189,
      "reading_time": 1,
      "created_at": "2025-10-24T09:41:53.973645+00:00",
      "updated_at": "2025-10-24T09:41:53.973646+00:00"
    },
    {
      "id": "6bfad30e4eabeeaf6b5051642db94e19",
      "url": "https://arxiv.org/abs/2510.19938",
      "title": "Designing a Secure and Resilient Distributed Smartphone Participant Data Collection System",
      "content": "arXiv:2510.19938v1 Announce Type: cross \nAbstract: Real-world health studies require continuous and secure data collection from mobile and wearable devices. We introduce MotionPI, a smartphone-based system designed to collect behavioral and health data through sensors and surveys with minimal interaction from participants. The system integrates passive data collection (such as GPS and wristband motion data) with Ecological Momentary Assessment (EMA) surveys, which can be triggered randomly or based on physical activity. MotionPI is designed to work under real-life constraints, including limited battery life, weak or intermittent cellular connection, and minimal user supervision. It stores data both locally and on a secure cloud server, with encrypted transmission and storage. It integrates through Bluetooth Low Energy (BLE) into wristband devices that store raw data and communicate motion summaries and trigger events. MotionPI demonstrates a practical solution for secure and scalable mobile data collection in cyber-physical health studies.",
      "author": "Foad Namjoo, Neng Wan, Devan Mallory, Yuyi Chang, Nithin Sugavanam, Long Yin Lee, Ning Xiong, Emre Ertin, Jeff M. Phillips",
      "published_date": "2025-10-24T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 144,
      "reading_time": 1,
      "created_at": "2025-10-24T09:41:53.973615+00:00",
      "updated_at": "2025-10-24T09:41:53.973616+00:00"
    },
    {
      "id": "0355cbae8cbcc77ba0ad0721fb1af98b",
      "url": "https://arxiv.org/abs/2510.19894",
      "title": "The Risks of Industry Influence in Tech Research",
      "content": "arXiv:2510.19894v1 Announce Type: cross \nAbstract: Emerging information technologies like social media, search engines, and AI can have a broad impact on public health, political institutions, social dynamics, and the natural world. It is critical to develop a scientific understanding of these impacts to inform evidence-based technology policy that minimizes harm and maximizes benefits. Unlike most other global-scale scientific challenges, however, the data necessary for scientific progress are generated and controlled by the same industry that might be subject to evidence-based regulation. Moreover, technology companies historically have been, and continue to be, a major source of funding for this field. These asymmetries in information and funding raise significant concerns about the potential for undue industry influence on the scientific record. In this Perspective, we explore how technology companies can influence our scientific understanding of their products. We argue that science faces unique challenges in the context of technology research that will require strengthening existing safeguards and constructing wholly new ones.",
      "author": "Joseph Bak-Coleman, Cailin O'Connor, Carl Bergstrom, Jevin West",
      "published_date": "2025-10-24T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 159,
      "reading_time": 1,
      "created_at": "2025-10-24T09:41:53.973589+00:00",
      "updated_at": "2025-10-24T09:41:53.973590+00:00"
    },
    {
      "id": "5beb5036efa08958377d69b14c7a0d03",
      "url": "https://arxiv.org/abs/2510.19850",
      "title": "Prompt Decorators: A Declarative and Composable Syntax for Reasoning, Formatting, and Control in LLMs",
      "content": "arXiv:2510.19850v1 Announce Type: cross \nAbstract: Large Language Models (LLMs) are central to reasoning, writing, and decision-support workflows, yet users lack consistent control over how they reason and express outputs. Conventional prompt engineering relies on verbose natural-language instructions, limiting reproducibility, modularity, and interpretability. This paper introduces Prompt Decorators, a declarative, composable syntax that governs LLM behavior through compact control tokens such as +++Reasoning, +++Tone(style=formal), and +++Import(topic=\"Systems Thinking\"). Each decorator modifies a behavioral dimension, such as reasoning style, structure, or tone, without changing task content. The framework formalizes twenty core decorators organized into two functional families (Cognitive & Generative and Expressive & Systemic), each further decomposed into subcategories that govern reasoning, interaction, expression, and session-control. It defines a unified syntax, scoping model, and deterministic processing pipeline enabling predictable and auditable behavior composition. By decoupling task intent from execution behavior, Prompt Decorators create a reusable and interpretable interface for prompt design. Illustrative use cases demonstrate improved reasoning transparency, reduced prompt complexity, and standardized model behavior across domains. The paper concludes with implications for interoperability, behavioral consistency, and the development of declarative interfaces for scalable AI systems.",
      "author": "Mostapha Kalami Heris",
      "published_date": "2025-10-24T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 183,
      "reading_time": 1,
      "created_at": "2025-10-24T09:41:53.973561+00:00",
      "updated_at": "2025-10-24T09:41:53.973562+00:00"
    },
    {
      "id": "7b0db120fda2b79656b01d9559f18d19",
      "url": "https://arxiv.org/abs/2510.20743",
      "title": "Empathic Prompting: Non-Verbal Context Integration for Multimodal LLM Conversations",
      "content": "arXiv:2510.20743v1 Announce Type: new \nAbstract: We present Empathic Prompting, a novel framework for multimodal human-AI interaction that enriches Large Language Model (LLM) conversations with implicit non-verbal context. The system integrates a commercial facial expression recognition service to capture users' emotional cues and embeds them as contextual signals during prompting. Unlike traditional multimodal interfaces, empathic prompting requires no explicit user control; instead, it unobtrusively augments textual input with affective information for conversational and smoothness alignment. The architecture is modular and scalable, allowing integration of additional non-verbal modules. We describe the system design, implemented through a locally deployed DeepSeek instance, and report a preliminary service and usability evaluation (N=5). Results show consistent integration of non-verbal input into coherent LLM outputs, with participants highlighting conversational fluidity. Beyond this proof of concept, empathic prompting points to applications in chatbot-mediated communication, particularly in domains like healthcare or education, where users' emotional signals are critical yet often opaque in verbal exchanges.",
      "author": "Lorenzo Stacchio, Andrea Ubaldi, Alessandro Galdelli, Maurizio Mauri, Emanuele Frontoni, Andrea Gaggioli",
      "published_date": "2025-10-24T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 155,
      "reading_time": 1,
      "created_at": "2025-10-24T09:41:53.973529+00:00",
      "updated_at": "2025-10-24T09:41:53.973531+00:00"
    },
    {
      "id": "79a6b4051c2dc840e5dfef567d9f8503",
      "url": "https://arxiv.org/abs/2510.20738",
      "title": "Optimizing Feature Ordering in Radar Charts for Multi-Profile Comparison",
      "content": "arXiv:2510.20738v1 Announce Type: new \nAbstract: Radar charts are widely used to visualize multivariate data and compare multiple profiles across features. However, the visual clarity of radar charts can be severely compromised when feature values alternate drastically in magnitude around the circle, causing areas to collapse, which misrepresents relative differences. In the present work we introduce a permutation optimization strategy that reorders features to minimize polygon ``spikiness'' across multiple profiles simultaneously. The method is combinatorial (exhaustive search) for moderate numbers of features and uses a lexicographic minimax criterion that first considers overall smoothness (mean jump) and then the largest single jump as a tie-breaker. This preserves more global information and produces visually balanced arrangements. We discuss complexity, practical bounds, and relations to existing approaches that either change the visualization (e.g., OrigamiPlot) or learn orderings (e.g., Versatile Ordering Network). An example with two profiles and $p=6$ features (before/after ordering) illustrates the qualitative improvement.\n  Keywords: data visualization, radar charts, combinatorial optimization, minimax optimization, feature ordering",
      "author": "Albert Dorador",
      "published_date": "2025-10-24T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 162,
      "reading_time": 1,
      "created_at": "2025-10-24T09:41:53.973502+00:00",
      "updated_at": "2025-10-24T09:41:53.973503+00:00"
    },
    {
      "id": "9ed419f11ce66b597b412c885ff6c28d",
      "url": "https://arxiv.org/abs/2510.20409",
      "title": "Designing Intent Communication for Agent-Human Collaboration",
      "content": "arXiv:2510.20409v1 Announce Type: new \nAbstract: As autonomous agents, from self-driving cars to virtual assistants, become increasingly present in everyday life, safe and effective collaboration depends on human understanding of agents' intentions. Current intent communication approaches are often rigid, agent-specific, and narrowly scoped, limiting their adaptability across tasks, environments, and user preferences. A key gap remains: existing models of what to communicate are rarely linked to systematic choices of how and when to communicate, preventing the development of generalizable, multi-modal strategies. In this paper, we introduce a multidimensional design space for intent communication structured along three dimensions: Transparency (what is communicated), Abstraction (when), and Modality (how). We apply this design space to three distinct human-agent collaboration scenarios: (a) bystander interaction, (b) cooperative tasks, and (c) shared control, demonstrating its capacity to generate adaptable, scalable, and cross-domain communication strategies. By bridging the gap between intent content and communication implementation, our design space provides a foundation for designing safer, more intuitive, and more transferable agent-human interactions.",
      "author": "Yi Li, Francesco Chiossi, Helena Anna Frijns, Jan Leusmann, Julian Rasch, Robin Welsch, Philipp Wintersberger, Florian Michahelles, Albrecht Schmidt",
      "published_date": "2025-10-24T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 163,
      "reading_time": 1,
      "created_at": "2025-10-24T09:41:53.973473+00:00",
      "updated_at": "2025-10-24T09:41:53.973475+00:00"
    },
    {
      "id": "e797e0fa9b1ed16dbdf9d4ea4f6bc6a9",
      "url": "https://arxiv.org/abs/2510.20123",
      "title": "\"Learning Together\": AI-Mediated Support for Parental Involvement in Everyday Learning",
      "content": "arXiv:2510.20123v1 Announce Type: new \nAbstract: Family learning takes place in everyday routines where children and caregivers read, practice, and develop new skills together. Although AI is increasingly present in learning environments, most systems remain child-centered and overlook the collaborative, distributed nature of family education. This paper investigates how AI can mediate family collaboration by addressing tensions of coordination, uneven workloads, and parental mediation. From a formative study with families using AI in daily learning, we identified challenges in responsibility sharing and recognition of contributions. Building on these insights, we designed FamLearn, an LLM-powered prototype that distributes tasks, visualizes contributions, and provides individualized support. A one-week field study with 11 families shows how this prototype can ease caregiving burdens, foster recognition, and enrich shared learning experiences. Our findings suggest that LLMs can move beyond the role of tutor to act as family mediators - balancing responsibilities, scaffolding intergenerational participation, and strengthening the relational fabric of family learning.",
      "author": "Yao Li, Jingyi Xie, Ya-Fang Ling, He Zhang, Ge Wang, Gaojian Huang, Rui Yu, Si Chen",
      "published_date": "2025-10-24T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 156,
      "reading_time": 1,
      "created_at": "2025-10-24T09:41:53.973444+00:00",
      "updated_at": "2025-10-24T09:41:53.973446+00:00"
    },
    {
      "id": "bda162227975e734dd3d52016a287f8c",
      "url": "https://arxiv.org/abs/2510.20039",
      "title": "Beyond One-Way Influence: Bidirectional Opinion Dynamics in Multi-Turn Human-LLM Interactions",
      "content": "arXiv:2510.20039v1 Announce Type: new \nAbstract: Large language model (LLM)-powered chatbots are increasingly used for opinion exploration. Prior research examined how LLMs alter user views, yet little work extended beyond one-way influence to address how user input can affect LLM responses and how such bi-directional influence manifests throughout the multi-turn conversations. This study investigates this dynamic through 50 controversial-topic discussions with participants (N=266) across three conditions: static statements, standard chatbot, and personalized chatbot. Results show that human opinions barely shifted, while LLM outputs changed more substantially, narrowing the gap between human and LLM stance. Personalization amplified these shifts in both directions compared to the standard setting. Analysis of multi-turn conversations further revealed that exchanges involving participants' personal stories were most likely to trigger stance changes for both humans and LLMs. Our work highlights the risk of over-alignment in human-LLM interaction and the need for careful design of personalized chatbots to more thoughtfully and stably align with users.",
      "author": "Yuyang Jiang, Longjie Guo, Yuchen Wu, Aylin Caliskan, Tanu Mitra, Hua Shen",
      "published_date": "2025-10-24T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 156,
      "reading_time": 1,
      "created_at": "2025-10-24T09:41:53.973405+00:00",
      "updated_at": "2025-10-24T09:41:53.973410+00:00"
    },
    {
      "id": "b9f15b336673b983603e02a651d0416a",
      "url": "https://arxiv.org/abs/2510.13894",
      "title": "Bayes or Heisenberg: Who(se) Rules?",
      "content": "arXiv:2510.13894v2 Announce Type: replace \nAbstract: Although quantum systems are generally described by quantum state vectors, we show that in certain cases their measurement processes can be reformulated as probabilistic equations expressed in terms of probabilistic state vectors. These probabilistic representations can, in turn, be approximated by the neural network dynamics of the Tensor Brain (TB) model.\n  The Tensor Brain is a recently proposed framework for modeling perception and memory in the brain, providing a biologically inspired mechanism for efficiently integrating generated symbolic representations into reasoning processes.",
      "author": "Volker Tresp, Hang Li, Federico Harjes, Yunpu Ma",
      "published_date": "2025-10-24T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 86,
      "reading_time": 1,
      "created_at": "2025-10-24T09:41:52.907338+00:00",
      "updated_at": "2025-10-24T09:41:52.907339+00:00"
    },
    {
      "id": "c836a936a5950633cace3ba6c0216560",
      "url": "https://arxiv.org/abs/2510.05815",
      "title": "Multiscale dynamical characterization of cortical brain states: from synchrony to asynchrony",
      "content": "arXiv:2510.05815v2 Announce Type: replace \nAbstract: The cerebral cortex spontaneously displays different patterns of activity that evolve over time according to the brain state. Sleep, wakefulness, resting states, and attention are examples of a wide spectrum of physiological states that can be sustained by the same structural network. Furthermore, additional states are generated by drugs (e.g., different levels of anesthesia) or by pathological conditions (e.g., brain lesions, disorders of consciousness). While the significance of understanding brain states in relation to brain dynamics and behavior has become increasingly evident over the past two decades, a unified definition of brain states remains elusive. In this review, we focus on two extremes of this spectrum: synchronous versus asynchronous states. These functional states predominantly underlie unconsciousness and consciousness, respectively, although exceptions exist. Our aim is to integrate data from different levels into a multiscale understanding, ranging from local circuits to whole-brain dynamics, including properties such as cortical complexity, functional connectivity, synchronization, wave propagation, and excitatory-inhibitory balance that vary across states and characterize them. Experimental and clinical data, as well as computational models (at micro-, meso-, and macrocortical levels) associated with the discussed brain states, are made available to readers.",
      "author": "Maria V. Sanchez-Vives, Arnau Manasanch, Andrea Pigorini, Alessandro Arena, Alessandra Camassa, Bj{\\o}rn Erik Juel, Leonardo Dalla Porta, Cristiano Capone, Chiara De Luca, Giulia De Bonis, Jennifer Goldman, Maria Sacha, Andrea Galluzzi, Antonio Pazienti, Ezequiel Mikulan, Johann F Storm, Pier Stanislao Paolucci, Marcello Massimini, Maurizio Mattia, Alain Destexhe",
      "published_date": "2025-10-24T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 194,
      "reading_time": 1,
      "created_at": "2025-10-24T09:41:52.907316+00:00",
      "updated_at": "2025-10-24T09:41:52.907317+00:00"
    },
    {
      "id": "18c3956474ab3f153d578b0b62211f6f",
      "url": "https://arxiv.org/abs/2509.12162",
      "title": "Quantifying Mental States in Work Environment: Mathematical Perspectives",
      "content": "arXiv:2509.12162v2 Announce Type: replace \nAbstract: We introduce a novel framework for quantifying mental and emotional states over time by combining virtual reality (VR) exposure with EEG recordings. Participants experienced a stress-inducing work scenario in VR, originally designed as a training tool for bank employees, providing a controlled proxy for high-stakes situations. This setup enables integration of subjective emotional self-assessments with objective neural data, from which an algorithm was efficiently used to infer emotional states. Building on these measurements, we propose possible mathematical models to capture the temporal dynamics of mental states, offering a quantitative approach to studying emotional processing and informing adaptive training in complex environments.",
      "author": "Aymen Balti, Assane Wade, Abdelatif Oujbara, M. A.,  Aziz-Alaoui, Hicham Bellarabi, Frederic Dutertre, Benjamin Ambrosio",
      "published_date": "2025-10-24T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 106,
      "reading_time": 1,
      "created_at": "2025-10-24T09:41:52.907285+00:00",
      "updated_at": "2025-10-24T09:41:52.907287+00:00"
    }
  ]
}