{
  "last_updated": "2025-12-08T05:24:58.762810+00:00",
  "count": 20,
  "articles": [
    {
      "id": "ecc1715f7857497b3a5d36f3a3aa8eb5",
      "url": "https://arxiv.org/abs/2512.05176",
      "title": "Towards A Cultural Intelligence and Values Inferences Quality Benchmark for Community Values and Common Knowledge",
      "content": "arXiv:2512.05176v1 Announce Type: cross \nAbstract: Large language models (LLMs) have emerged as a powerful technology, and thus, we have seen widespread adoption and use on software engineering teams. Most often, LLMs are designed as \"general purpose\" technologies meant to represent the general population. Unfortunately, this often means alignment with predominantly Western Caucasian narratives and misalignment with other cultures and populations that engage in collaborative innovation. In response to this misalignment, there have been recent efforts centered on the development of \"culturally-informed\" LLMs, such as ChatBlackGPT, that are capable of better aligning with historically marginalized experiences and perspectives. Despite this progress, there has been little effort aimed at supporting our ability to develop and evaluate culturally-informed LLMs. A recent effort proposed an approach for developing a national alignment benchmark that emphasizes alignment with national social values and common knowledge. However, given the range of cultural identities present in the United States (U.S.), a national alignment benchmark is an ineffective goal for broader representation. To help fill this gap in this US context, we propose a replication study that translates the process used to develop KorNAT, a Korean National LLM alignment benchmark, to develop CIVIQ, a Cultural Intelligence and Values Inference Quality benchmark centered on alignment with community social values and common knowledge. Our work provides a critical foundation for research and development aimed at cultural alignment of AI technologies in practice.",
      "author": "Brittany Johnson, Erin Reddick, Angela D. R. Smith",
      "published_date": "2025-12-08T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 230,
      "reading_time": 1,
      "created_at": "2025-12-08T05:24:38.209265+00:00",
      "updated_at": "2025-12-08T05:24:38.209266+00:00"
    },
    {
      "id": "dfa26a9fc14bebcee5d9308b3e064fc7",
      "url": "https://arxiv.org/abs/2512.05536",
      "title": "Eye of the Beholder: Towards Measuring Visualization Complexity",
      "content": "arXiv:2512.05536v1 Announce Type: new \nAbstract: Constructing expressive and legible visualizations is a key activity for visualization designers. While numerous design guidelines exist, research on how specific graphical features affect perceived visual complexity remains limited. In this paper, we report on a crowdsourced study to collect human ratings of perceived complexity for diverse visualizations. Using these ratings as ground truth, we then evaluated three methods to estimate this perceived complexity: image analysis metrics, multilinear regression using manually coded visualization features, and automated feature extraction using a large language model (LLM). Image complexity metrics showed no correlation with human-perceived visualization complexity. Manual feature coding produced a reasonable predictive model but required substantial effort. In contrast, a zero-shot LLM (GPT-4o mini) demonstrated strong capabilities in both rating complexity and extracting relevant features. Our findings suggest that visualization complexity is truly in the eye of the beholder, yet can be effectively approximated using zero-shot LLM prompting, offering a scalable approach for evaluating the complexity of visualizations. The dataset and code for the study and data analysis can be found at https://osf.io/w85a4/",
      "author": "Johannes Ellemose, Niklas Elmqvist",
      "published_date": "2025-12-08T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 177,
      "reading_time": 1,
      "created_at": "2025-12-08T05:24:38.209230+00:00",
      "updated_at": "2025-12-08T05:24:38.209232+00:00"
    },
    {
      "id": "b0c803378f86b1d2ea93f99c5f5095a8",
      "url": "https://arxiv.org/abs/2512.05519",
      "title": "User Negotiations of Authenticity, Ownership, and Governance on AI-Generated Video Platforms: Evidence from Sora",
      "content": "arXiv:2512.05519v1 Announce Type: new \nAbstract: As AI-generated video platforms rapidly advance, ethical challenges such as copyright infringement emerge. This study examines how users make sense of AI-generated videos on OpenAI's Sora by conducting a qualitative content analysis of user comments. Through a thematic analysis, we identified four dynamics that characterize how users negotiate authenticity, authorship, and platform governance on Sora. First, users acted as critical evaluators of realism, assessing micro-details such as lighting, shadows, fluid motion, and physics to judge whether AI-generated scenes could plausibly exist. Second, users increasingly shifted from passive viewers to active creators, expressing curiosity about prompts, techniques, and creative processes. Text prompts were perceived as intellectual property, generating concerns about plagiarism and remixing norms. Third, users reported blurred boundaries between real and synthetic media, worried about misinformation, and even questioned the authenticity of other commenters, suspecting bot-generated engagement. Fourth, users contested platform governance: some perceived moderation as inconsistent or opaque, while others shared tactics for evading prompt censorship through misspellings, alternative phrasing, emojis, or other languages. Despite this, many users also enforced ethical norms by discouraging the misuse of real people's images or disrespectful content. Together, these patterns highlighted how AI-mediated platforms complicate notions of reality, creativity, and rule-making in emerging digital ecosystems. Based on the findings, we discuss governance challenges in Sora and how user negotiations inform future platform governance.",
      "author": "Bohui Shen, Shrikar Bhatta, Alex Ireebanije, Zexuan Liu, Abhinav Choudhry, Ece Gumusel, Kyrie Zhixuan Zhou",
      "published_date": "2025-12-08T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 225,
      "reading_time": 1,
      "created_at": "2025-12-08T05:24:38.209199+00:00",
      "updated_at": "2025-12-08T05:24:38.209201+00:00"
    },
    {
      "id": "cd434a461637e004eda5bc776d1cdc23",
      "url": "https://arxiv.org/abs/2512.05506",
      "title": "When Scaffolding Breaks: Investigating Student Interaction with LLM-Based Writing Support in Real-Time K-12 EFL Classrooms",
      "content": "arXiv:2512.05506v1 Announce Type: new \nAbstract: Large language models (LLMs) are promising tools for scaffolding students' English writing skills, but their effectiveness in real-time K-12 classrooms remains underexplored. Addressing this gap, our study examines the benefits and limitations of using LLMs as real-time learning support, considering how classroom constraints, such as diverse proficiency levels and limited time, affect their effectiveness. We conducted a deployment study with 157 eighth-grade students in a South Korean middle school English class over six weeks. Our findings reveal that while scaffolding improved students' ability to compose grammatically correct sentences, this step-by-step approach demotivated lower-proficiency students and increased their system reliance. We also observed challenges to classroom dynamics, where extroverted students often dominated the teacher's attention, and the system's assistance made it difficult for teachers to identify struggling students. Based on these findings, we discuss design guidelines for integrating LLMs into real-time writing classes as inclusive educational tools.",
      "author": "Junho Myung, Hyunseung Lim, Hana Oh, Hyoungwook Jin, Nayeon Kang, So-Yeon Ahn, Hwajung Hong, Alice Oh, Juho Kim",
      "published_date": "2025-12-08T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 151,
      "reading_time": 1,
      "created_at": "2025-12-08T05:24:38.209165+00:00",
      "updated_at": "2025-12-08T05:24:38.209167+00:00"
    },
    {
      "id": "3db79f17aa81b9688de0a715208b6eea",
      "url": "https://arxiv.org/abs/2512.05450",
      "title": "Classification and taxonomy of mobile application usability issues",
      "content": "arXiv:2512.05450v1 Announce Type: new \nAbstract: Despite years of research on testing the usability of mobile applications, our understanding of the issues their users experience still remains fragmented and underexplored. While most earlier studies has provided interesting insights, they have varying limitations in methodology, input diversity, and depth of analysis.On the contrary, this study employs a triangulation strategy, using two research methods (systematic literature review and interview) and two data sources (scholarly literature and expert knowledge) to explore the traits underlying usability issues. Our study contributes to the field of human-computer interaction (HCI) by presenting a catalog of 16 usability issue categories, enriched with corresponding keywords and extended into a taxonomy, as well as a novel three-tier app-user-resource (AUR) classification system. At the first app level, usability issues arise from user interface design, as well as from efficiency, errors, and operability. At the second user level, they influence cognitive load, effectiveness, ease of use, learnability, memorability, and understandability. At the third resource level, usability issues stem from network quality and hardware, such as battery life, CPU speed, physical device button size and availability, RAM capacity, and screen size. The root cause of the usability issues is the user interface design. Detailed findings and takeaways for both researchers and practitioners are also discussed. Further research could focus on developing a measurement model for the identified variables to confirm the direction and strength of their relationships with perceived usability. Software vendors can also benefit by updating existing quality assurance programs, reviews and audits tools, as well as testing checklists.",
      "author": "Pawel Weichbroth",
      "published_date": "2025-12-08T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 256,
      "reading_time": 1,
      "created_at": "2025-12-08T05:24:38.209130+00:00",
      "updated_at": "2025-12-08T05:24:38.209131+00:00"
    },
    {
      "id": "b33f48c969ca3701c24f9442babb77b0",
      "url": "https://arxiv.org/abs/2512.05438",
      "title": "EXR: An Interactive Immersive EHR Visualization in Extended Reality",
      "content": "arXiv:2512.05438v1 Announce Type: new \nAbstract: This paper presents the design and implementation of an Extended Reality (XR) platform for immersive, interactive visualization of Electronic Health Records (EHRs). The system extends beyond conventional 2D interfaces by visualizing both structured and unstructured patient data into a shared 3D environment, enabling intuitive exploration and real-time collaboration. The modular infrastructure integrates FHIR-based EHR data with volumetric medical imaging and AI-generated segmentation, ensuring interoperability with modern healthcare systems. The platform's capabilities are demonstrated using synthetic EHR datasets and computed tomography (CT)-derived spine models processed through an AI-powered segmentation pipeline. This work suggests that such integrated XR solutions could form the foundation for next-generation clinical decision-support tools, where advanced data infrastructures are directly accessible in an interactive and spatially rich environment.",
      "author": "Benoit Marteau, Shaun Q. Y. Tan, Jieru Li, Andrew Hornback, Yishan Zhong, Shaunna Wang, Christian Lowson, Jason Woloff, Joshua M. Pahys, Steven W. Hwang, Coleman Hilton, May D. Wang",
      "published_date": "2025-12-08T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 125,
      "reading_time": 1,
      "created_at": "2025-12-08T05:24:38.209093+00:00",
      "updated_at": "2025-12-08T05:24:38.209095+00:00"
    },
    {
      "id": "e7c9301c8e49b9e7d4dbd534ee2575c9",
      "url": "https://arxiv.org/abs/2512.05433",
      "title": "From Vision to Touch: Bridging Visual and Tactile Principles for Accessible Data Representation",
      "content": "arXiv:2512.05433v1 Announce Type: new \nAbstract: Tactile graphics are widely used to present maps and statistical diagrams to blind and low vision (BLV) people, with accessibility guidelines recommending their use for graphics where spatial relationships are important. Their use is expected to grow with the advent of commodity refreshable tactile displays. However, in stark contrast to visual information graphics, we lack a clear understanding of the benefits that well-designed tactile information graphics offer over text descriptions for BLV people. To address this gap, we introduce a framework considering the three components of encoding, perception and cognition to examine the known benefits for visual information graphics and explore their applicability to tactile information graphics. This work establishes a preliminary theoretical foundation for the tactile-first design of information graphics and identifies future research avenues.",
      "author": "Kim Marriott, Matthew Butler, Leona Holloway, Bill Jolley, Bongshin Lee, Bruce Maguire, Danielle Albers Szafir",
      "published_date": "2025-12-08T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 131,
      "reading_time": 1,
      "created_at": "2025-12-08T05:24:38.209066+00:00",
      "updated_at": "2025-12-08T05:24:38.209068+00:00"
    },
    {
      "id": "5e5e17bec499b502319964c8eff33ee9",
      "url": "https://arxiv.org/abs/2512.05397",
      "title": "Simulating Life Paths with Digital Twins: AI-Generated Future Selves Influence Decision-Making and Expand Human Choice",
      "content": "arXiv:2512.05397v1 Announce Type: new \nAbstract: Major life transitions demand high-stakes decisions, yet people often struggle to imagine how their future selves will live with the consequences. To support this limited capacity for mental time travel, we introduce AI-enabled digital twins that have ``lived through'' simulated life scenarios. Rather than predicting optimal outcomes, these simulations extend prospective cognition by making alternative futures vivid enough to support deliberation without assuming which path is best. We evaluate this idea in a randomized controlled study (N=192) using multimodal synthesis - facial age progression, voice cloning, and large language model dialogue - to create personalized avatars representing participants 30 years forward. Young adults 18 to 28 years old described pending binary decisions and were assigned to guided imagination or one of four avatar conditions: single-option, balanced dual-option, or expanded three-option with a system-generated novel alternative. Results showed asymmetric effects: single-sided avatars increased shifts toward the presented option, while balanced presentation produced movement toward both. Introducing a system-generated third option increased adoption of this new alternative compared to control, suggesting that AI-generated future selves can expand choice by surfacing paths that might otherwise go unnoticed. Participants rated evaluative reasoning and eudaimonic meaning-making as more important than emotional or visual vividness. Perceived persuasiveness and baseline agency predicted decision change. These findings advance understanding of AI-mediated episodic prospection and raise questions about autonomy in AI-augmented decisions.",
      "author": "Rachel Poonsiriwong, Chayapatr Archiwaranguprok, Constanze Albrecht, Peggy Yin, Nattavudh Powthavee, Hal Hershfield, Monchai Lertsutthiwong, Kavin Winson, Pat Pataranutaporn",
      "published_date": "2025-12-08T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 228,
      "reading_time": 1,
      "created_at": "2025-12-08T05:24:38.209039+00:00",
      "updated_at": "2025-12-08T05:24:38.209041+00:00"
    },
    {
      "id": "d44ba204f5c9f6cf1d76e9b2cbafb028",
      "url": "https://arxiv.org/abs/2512.05389",
      "title": "CLIO: A Tour Guide Robot with Co-speech Actions for Visual Attention Guidance and Enhanced User Engagement",
      "content": "arXiv:2512.05389v1 Announce Type: new \nAbstract: While audio guides can offer rich information about an exhibit, it is challenging for visitors to focus on specific exhibit details based only on the verbal description. We present \\textit{CLIO}, a tour guide robot with co-speech actions to direct visitors' visual attention and thus enhance the overall user engagement in a guided tour. \\textit{CLIO} is equipped with designed actions to engage visitors. It builds eye contact with the visitor through tracking a visitor's face and blinking its eyes, or orient their attention by its head movement and laser pointer. We further use a Large Language Model (LLM) to coordinate the designed actions with a given narrative script for exhibition. We conducted a user study to evaluate the \\textit{CLIO} system in a mock-up exhibition of historical photographs. We collected feedback from questionnaires and quantitative data from a mobile eye tracker. Experimental results validated that the engaging actions are well designed and demonstrated its efficacy in guiding visual attention of the visitors. It was evidenced that \\textit{CLIO} achieved an enhanced engagement compared to the baseline system with only audio guidance.",
      "author": "Yuxuan Chen, Ian Leong Ting Lo, Bao Guo, Netitorn Kawmali, Chun Kit Chan, Ruoyu Wang, Jia Pan, Lei Yang",
      "published_date": "2025-12-08T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 183,
      "reading_time": 1,
      "created_at": "2025-12-08T05:24:38.209003+00:00",
      "updated_at": "2025-12-08T05:24:38.209004+00:00"
    },
    {
      "id": "3677782a33d9508433bccf38cc16ec17",
      "url": "https://arxiv.org/abs/2512.05310",
      "title": "Systematically Evaluating Equivalent Purpose for Digital Maps",
      "content": "arXiv:2512.05310v1 Announce Type: new \nAbstract: Digital geographic maps remain largely inaccessible to blind and low-vision individuals (BLVIs), despite global legislation adopting the Web Content Accessibility Guidelines (WCAG). A critical gap exists in defining \"equivalent purpose\" for maps under WCAG Success Criterion 1.1.1, which requires that non-text content provide a text alternative that serves the \"equivalent purpose\". This paper proposes a systematic framework for evaluating map accessibility, called the Map Equivalent-Purpose Framework (MEP Framework), defining purpose through three items (Generalized, Spatial Information, and Spatial Relationships), and establishing 15 measurable criteria for equivalent information communication. Eight text map representations were evaluated against visual map baselines using the proposed MEP Framework. Results show that legacy methods such as tables and turn-by-turn directions fail to meet the MEP Framework criteria, while Audiom Maps, Multi User Domain (MUD) Maps, and Audio Descriptions meet the criteria. The evaluation highlights the necessity of holistic, systematic approaches to ensure non-visual maps convey all generalized spatial information and relationships present in visual maps. The MEP Framework provides a replicable methodology for comprehensively assessing digital map accessibility, clarifying WCAG's \"equivalent purpose\", and guiding compliant and usable map creation. Compliant maps will support BLVIs' participation in map-dependent professions and civic engagement.",
      "author": "Brandon Biggs, David Sloan, Brett Oppegaard, Nicholas A. Giudice, James M. Coughlan, Bruce N. Walker",
      "published_date": "2025-12-08T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 200,
      "reading_time": 1,
      "created_at": "2025-12-08T05:24:38.208966+00:00",
      "updated_at": "2025-12-08T05:24:38.208970+00:00"
    },
    {
      "id": "8defd01de24098a6a35929709b75f97f",
      "url": "https://arxiv.org/abs/2512.05718",
      "title": "Emergence of Language in the Developing Brain",
      "content": "arXiv:2512.05718v1 Announce Type: new \nAbstract: A few million words suffice for children to acquire language. Yet, the brain mechanisms underlying this unique ability remain poorly understood. To address this issue, we investigate neural activity recorded from over 7,400 electrodes implanted in the brains of 46 children, teenagers, and adults for epilepsy monitoring, as they listened to an audiobook version of \"The Little Prince\". We then train neural encoding and decoding models using representations, derived either from linguistic theory or from large language models, to map the location, dynamics and development of the language hierarchy in the brain. We find that a broad range of linguistic features is robustly represented across the cortex, even in 2-5-year-olds. Crucially, these representations evolve with age: while fast phonetic features are already present in the superior temporal gyrus of the youngest individuals, slower word-level representations only emerge in the associative cortices of older individuals. Remarkably, this neuro-developmental trajectory is spontaneously captured by large language models: with training, these AI models learned representations that can only be identified in the adult human brain. Together, these findings reveal the maturation of language representations in the developing brain and show that modern AI systems provide a promising tool to model the neural bases of language acquisition.",
      "author": "Linnea Evanson, Christine Bulteau, Mathilde Chipaux, Georg Dorfm\\\"uller, Sarah Ferrand-Sorbets, Emmanuel Raffo, Sarah Rosenberg, Pierre Bourdillon, Jean-R\\'emi King",
      "published_date": "2025-12-08T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 208,
      "reading_time": 1,
      "created_at": "2025-12-08T05:24:37.141113+00:00",
      "updated_at": "2025-12-08T05:24:37.141114+00:00"
    },
    {
      "id": "9f92b16709353905c34856f63bf72cb3",
      "url": "https://arxiv.org/abs/2512.05528",
      "title": "Decoding Selective Auditory Attention to Musical Elements in Ecologically Valid Music Listening",
      "content": "arXiv:2512.05528v1 Announce Type: new \nAbstract: Art has long played a profound role in shaping human emotion, cognition, and behavior. While visual arts such as painting and architecture have been studied through eye tracking, revealing distinct gaze patterns between experts and novices, analogous methods for auditory art forms remain underdeveloped. Music, despite being a pervasive component of modern life and culture, still lacks objective tools to quantify listeners' attention and perceptual focus during natural listening experiences. To our knowledge, this is the first attempt to decode selective attention to musical elements using naturalistic, studio-produced songs and a lightweight consumer-grade EEG device with only four electrodes. By analyzing neural responses during real world like music listening, we test whether decoding is feasible under conditions that minimize participant burden and preserve the authenticity of the musical experience. Our contributions are fourfold: (i) decoding music attention in real studio-produced songs, (ii) demonstrating feasibility with a four-channel consumer EEG, (iii) providing insights for music attention decoding, and (iv) demonstrating improved model ability over prior work. Our findings suggest that musical attention can be decoded not only for novel songs but also across new subjects, showing performance improvements compared to existing approaches under our tested conditions. These findings show that consumer-grade devices can reliably capture signals, and that neural decoding in music could be feasible in real-world settings. This paves the way for applications in education, personalized music technologies, and therapeutic interventions.",
      "author": "Taketo Akama, Zhuohao Zhang, Tsukasa Nagashima, Takagi Yutaka, Shun Minamikawa, Natalia Polouliakh",
      "published_date": "2025-12-08T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 236,
      "reading_time": 1,
      "created_at": "2025-12-08T05:24:37.141080+00:00",
      "updated_at": "2025-12-08T05:24:37.141082+00:00"
    },
    {
      "id": "78c853d8849f6f0500a62b3c660b71e2",
      "url": "https://arxiv.org/abs/2512.05500",
      "title": "SSDLabeler: Realistic semi-synthetic data generation for multi-label artifact classification in EEG",
      "content": "arXiv:2512.05500v1 Announce Type: new \nAbstract: EEG recordings are inherently contaminated by artifacts such as ocular, muscular, and environmental noise, which obscure neural activity and complicate preprocessing. Artifact classification offers advantages in stability and transparency, providing a viable alternative to ICA-based methods that enable flexible use alongside human inspections and across various applications. However, artifact classification is limited by its training data as it requires extensive manual labeling, which cannot fully cover the diversity of real-world EEG. Semi-synthetic data (SSD) methods have been proposed to address this limitation, but prior approaches typically injected single artifact types using ICA components or required separately recorded artifact signals, reducing both the realism of the generated data and the applicability of the method. To overcome these issues, we introduce SSDLabeler, a framework that generates realistic, annotated SSDs by decomposing real EEG with ICA, epoch-level artifact verification using RMS and PSD criteria, and reinjecting multiple artifact types into clean data. When applied to train a multi-label artifact classifier, it improved accuracy on raw EEG across diverse conditions compared to prior SSD and raw EEG training, establishing a scalable foundation for artifact handling that captures the co-occurrence and complexity of real EEG.",
      "author": "Taketo Akama, Akima Connelly, Shun Minamikawa, Natalia Polouliakh",
      "published_date": "2025-12-08T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 195,
      "reading_time": 1,
      "created_at": "2025-12-08T05:24:37.141044+00:00",
      "updated_at": "2025-12-08T05:24:37.141045+00:00"
    },
    {
      "id": "ab86e88f4dc72551c2552505673b08cb",
      "url": "https://arxiv.org/abs/2512.05252",
      "title": "Competition, stability, and functionality in excitatory-inhibitory neural circuits",
      "content": "arXiv:2512.05252v1 Announce Type: new \nAbstract: Energy-based models have become a central paradigm for understanding computation and stability in both theoretical neuroscience and machine learning. However, the energetic framework typically relies on symmetry in synaptic or weight matrices - a constraint that excludes biologically realistic systems such as excitatory-inhibitory (E-I) networks. When symmetry is relaxed, the classical notion of a global energy landscape fails, leaving the dynamics of asymmetric neural systems conceptually unanchored. In this work, we extend the energetic framework to asymmetric firing rate networks, revealing an underlying game-theoretic structure for the neural dynamics in which each neuron is an agent that seeks to minimize its own energy. In addition, we exploit rigorous stability principles from network theory to study regulation and balancing of neural activity in E-I networks. We combine the novel game-energetic interpretation and the stability results to revisit standard frameworks in theoretical neuroscience, such as the Wilson-Cowan and lateral inhibition models. These insights allow us to study cortical columns of lateral inhibition microcircuits as contrast enhancer - with the ability to selectively sharpen subtle differences in the environment through hierarchical excitation-inhibition interplay. Our results bridge energetic and game-theoretic views of neural computation, offering a pathway toward the systematic engineering of biologically grounded, dynamically stable neural architectures.",
      "author": "Simone Betteti, William Retnaraj, Alexander Davydov, Jorge Cort\\'es, Francesco Bullo",
      "published_date": "2025-12-08T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 209,
      "reading_time": 1,
      "created_at": "2025-12-08T05:24:37.141005+00:00",
      "updated_at": "2025-12-08T05:24:37.141009+00:00"
    },
    {
      "id": "a23a31d4290c8ad43874888df90371da",
      "url": "https://www.abc.net.au/news/2025-12-05/australian-working-from-home-mental-health-impacts-tracked/106096688",
      "title": "Impacts of working from home on mental health tracked in study of Australians",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46153822\">Comments</a>",
      "author": "",
      "published_date": "2025-12-04T22:11:19+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-08T04:53:53.960908+00:00",
      "updated_at": "2025-12-08T04:53:53.960910+00:00"
    },
    {
      "id": "ddfff7ebc1281782beb9a35b3c93971c",
      "url": "https://www.damnsmalllinux.org/",
      "title": "Damn Small Linux",
      "content": "<p>Article URL: <a href=\"https://www.damnsmalllinux.org/\">https://www.damnsmalllinux.org/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46187387\">https://news.ycombinator.com/item?id=46187387</a></p>\n<p>Points: 7</p>\n<p># Comments: 1</p>",
      "author": "grubbs",
      "published_date": "2025-12-08T01:47:11+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-08T04:53:52.615272+00:00",
      "updated_at": "2025-12-08T04:53:52.615273+00:00"
    },
    {
      "id": "1ceb9d690f90262f446c9f47b722a001",
      "url": "https://247wallst.com/investing/2025/11/25/palantir-could-be-the-most-overvalued-company-that-ever-existed/",
      "title": "Palantir Could Be the Most Overvalued Company That Ever Existed",
      "content": "<p>Article URL: <a href=\"https://247wallst.com/investing/2025/11/25/palantir-could-be-the-most-overvalued-company-that-ever-existed/\">https://247wallst.com/investing/2025/11/25/palantir-could-be-the-most-overvalued-company-that-ever-existed/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46188451\">https://news.ycombinator.com/item?id=46188451</a></p>\n<p>Points: 4</p>\n<p># Comments: 0</p>",
      "author": "Anon84",
      "published_date": "2025-12-08T04:45:20+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-08T04:53:52.615221+00:00",
      "updated_at": "2025-12-08T04:53:52.615229+00:00"
    },
    {
      "id": "7b642de21bbacc9b4ce76cc372ead747",
      "url": "https://turtletoy.net/",
      "title": "Turtletoy",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46138459\">Comments</a>",
      "author": "",
      "published_date": "2025-12-03T18:57:08+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-08T04:07:20.877195+00:00",
      "updated_at": "2025-12-08T04:29:58.109228+00:00",
      "metadata": {
        "processed_at": "2025-12-08T04:29:58.109237+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "2d7472beebd02a461001301f2e954616",
      "url": "https://www.thepavement.xyz/p/the-era-of-jobs-is-ending",
      "title": "The era of jobs is ending",
      "content": "<p>Article URL: <a href=\"https://www.thepavement.xyz/p/the-era-of-jobs-is-ending\">https://www.thepavement.xyz/p/the-era-of-jobs-is-ending</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46186900\">https://news.ycombinator.com/item?id=46186900</a></p>\n<p>Points: 20</p>\n<p># Comments: 12</p>",
      "author": "SturgeonsLaw",
      "published_date": "2025-12-08T00:23:45+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-08T04:07:19.605130+00:00",
      "updated_at": "2025-12-08T04:29:58.109241+00:00",
      "metadata": {
        "processed_at": "2025-12-08T04:29:58.109244+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "33000ea9ce4b38a72e8be121ebf8fc02",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.03.692236v1?rss=1",
      "title": "S100A8/A9 Inhibition Reduces Splenic Myelopoiesis and Improves Outcomes After Stroke",
      "content": "Background: Neutrophils are among the earliest immune cells to infiltrate the ischemic brain and contribute to secondary neuronal damage. The alarmin S100 calcium-binding protein A8/A9 (S100A8/A9), predominantly released by neutrophils, is upregulated during this process. Although the bone marrow is recognised as the principal site of neutrophil production via myelopoiesis, the role of the spleen as an immune-responsive organ remains incompletely understood. Methods: In this study, we employed a transient middle cerebral artery occlusion (MCAO) model in male C57Bl/6 mice and examined immune responses 24 hours post-stroke in the blood, bone marrow and spleen using flow cytometry. To understand the role of S100A8/A9 in modulating stroke-induced myelopoiesis, we administered a small molecule inhibitor of S100A8/A9, ABR-215757, before and after stroke. Results: Neutrophils and S100A8/A9 were found in the infarcted brain tissue. Interestingly, we observed a marked increase in splenic neutrophils, accompanied by an expansion of myeloid progenitors, indicating activation of extramedullary myelopoiesis. Given our previous work showing that S100A8/A9 promotes myelopoiesis, we pharmacologically inhibited S100A8/A9 to determine if this would modulate stroke-induced myelopoiesis. Treatment with ABR-215757 at 24 hours post-stroke led to reduced splenic myelopoiesis, reversed neutrophilia, enhanced forelimb grip strength, and a one-third reduction in infarct size. Conclusion: These findings identify the spleen as a key contributor to neutrophil production following stroke and suggest that targeting S100A8/A9 may attenuate post-stroke inflammation and improve neurological recovery.",
      "author": "Kim, H. A., Al-Sharea, A., Chu, H., Tang, S.-C., Rupasinghe, S. A., Zhang, S. R., Nagareddy, P. R., Drummond, G. R., Arumugam, T. V., Murphy, A. J., Sobey, C. G., Lee, M. K.",
      "published_date": "2025-12-07T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 226,
      "reading_time": 1,
      "created_at": "2025-12-08T03:23:13.295483+00:00",
      "updated_at": "2025-12-08T04:29:58.109246+00:00",
      "metadata": {
        "processed_at": "2025-12-08T04:29:58.109248+00:00",
        "processing_method": "github_actions"
      }
    }
  ]
}