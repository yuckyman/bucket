{
  "last_updated": "2025-11-18T03:14:20.902291+00:00",
  "count": 20,
  "articles": [
    {
      "id": "7c5dcb8fe1b702e4c1ec4de6b76b172c",
      "url": "https://www.biorxiv.org/content/10.1101/2025.11.17.688831v1?rss=1",
      "title": "Combinatorial Cell-Adhesion and Activity Codes Instruct Cortical Modality Identity",
      "content": "The emergence of functional sensory modalities requires precise cortical arealization and thalamocortical connectivity. While early morphogen gradients broadly initiate cortical patterning, how sensory identity is specified and refined within these territories remains unclear. Using single-nucleus RNA sequencing and spatial transcriptomics, we reveal distinct modality-specific identity genes in primary somatosensory and visual cortices at early stages. These genes are enriched in thalamo-recipient layers and linked to neuronal activity and cell adhesion. Disrupting early thalamic activity alters both cortical activity and the expression of a subset of these genes, demonstrating a causal role for thalamic input in sensory modality acquisition. Remarkably, a core set of identity genes is already differentially expressed embryonically, before thalamic innervation, and encodes cell-adhesion profiles matching those of sensory thalamus, potentially enabling homophilic interactions. Our findings support a two-step model: cortical cell-adhesion codes prime modality-specific thalamocortical targeting, which is subsequently refined by patterned thalamic activity to establish functional cortical modalities.",
      "author": "Guillamon-Vivancos, T., Puche-Aroca, L., Wang, L., Vandael, D., Torres, D., Anibal-Martinez, M., Fuentes-Jurado, I., Martini, F., Lopez-Bendito, G.",
      "published_date": "2025-11-17T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 152,
      "reading_time": 1,
      "created_at": "2025-11-18T03:13:48.738481+00:00",
      "updated_at": "2025-11-18T03:13:48.738483+00:00"
    },
    {
      "id": "04188d9a1436550b0f95943b8319b512",
      "url": "https://www.biorxiv.org/content/10.1101/2025.11.17.688834v1?rss=1",
      "title": "Unmixing the Psychedelic Connectome: Brain Network Traits of Psilocybin",
      "content": "Psilocybin induces profound alterations in consciousness, yet prevailing neural models often describe a monolithic change in brain connectivity that may not fully capture the multifaceted nature of the psychedelic state. To test the hypothesis of a composite neural state, this study applied a robust, data-driven framework, Connectome Independent Component Analysis (connICA) with multi-level resampling, to resting-state fMRI data from healthy volunteers. The analysis decomposed connectomes into statistically independent functional connectivity traits (\"FC-Traits\"), revealing a primary trait whose expression was significantly modulated by plasma psilocin concentration, providing a whole-cortical signature of the drug's physiological action. Crucially, a second, distinct trait was also isolated, which independently associated with impaired performance on a visual divergent thinking task. These findings demonstrate that the acute psilocybin state is a composite of co-occurring neural processes. This validates the application of a decompositional connectomic framework to move beyond global descriptions and successfully disentangle the specific neural patterns underlying distinct pharmacological and cognitive correlates.",
      "author": "Bhavaraju, K. P., Mason, N. L., Mallaroni, P., Heinke, D., Toennes, S., Ramaekers, J., Amico, E.",
      "published_date": "2025-11-17T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 156,
      "reading_time": 1,
      "created_at": "2025-11-18T03:13:48.738445+00:00",
      "updated_at": "2025-11-18T03:13:48.738448+00:00"
    },
    {
      "id": "81b47a1434c580f472ae559eb1341cad",
      "url": "https://www.biorxiv.org/content/10.1101/2025.11.17.688832v1?rss=1",
      "title": "Connecting the dots - Recognition of artificial and natural shapes relies on representing points of high information",
      "content": "Physiological and psychophysical evidence suggests that the visual system represents object outlines based on prominent curvature features, in particular regions of extreme curvature (such as convex maxima and concave minima). Curvature extrema often coincide with points of high information content (surprisal, in information-theoretic terms). However, this relationship is only correlational. To date, no study has directly compared the role of curvature extrema with the role of surprisal itself. Does the visual system selectively encode curvature extrema because they tend to be informative-because they are heuristic proxies for high-surprisal points along the contour-or does it directly encode informative points that happen often to be located at curvature extrema? We addressed this question in a series of shape-matching experiments, testing how curvature extrema and information content contribute to recognition. Observers (N = 7) matched a smooth test shape to one of two re-scaled shapes (target and distractor) constructed by connecting, with straight lines, points corresponding to (i) curvature maxima, (ii) both curvature maxima and minima, or (iii) points of maximum surprisal. A baseline condition used identical test and target shapes. Stimuli included artificial shapes composed of compound radial frequency patterns and natural shapes (animal outlines), the latter enabling us to disentangle curvature and information effects by restricting sampled points. Recognition performance was higher for natural than artificial shapes (95% vs. ~86%). Performance for shapes containing a few points of high information matched performance on trials containing all curvature extrema and baseline trials. It also exceeded performance for shapes with curvature maxima alone (65% vs. ~90%). These findings suggest that shape representation emphasizes features with high informational content rather than curvature extrema per se.",
      "author": "Schmidtmann, G., Baker, N., Lande, K. J., Schmidt, F.",
      "published_date": "2025-11-17T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 271,
      "reading_time": 1,
      "created_at": "2025-11-18T03:13:48.738405+00:00",
      "updated_at": "2025-11-18T03:13:48.738409+00:00"
    },
    {
      "id": "a89cc9d9bab0838b2e06072add1ef2ed",
      "url": "http://doi.org/10.1037/cns0000335",
      "title": "A shared perceptual inference for cross-modally induced illusions of self-attribution.",
      "content": "The representation of our own body is malleable. Evidence indicates that multisensory stimulation can trigger an illusory sense of ownership over a fake hand, a partner\u2019s face, or a virtual body. Despite our understanding of the processes supporting the construction of bodily self, we know less about the processes that trigger illusory ownership of nonbody attributes (e.g., voice during articulation) and about whether multisensory stimulation can drive a shared inference across distinct attributes. Here, we compared the classic rubber hand illusion with another multisensory illusion that elicits a sense of ownership over a stranger\u2019s voice during talking. We observed that, given congruent multisensory input, the degree to which one perceived the sense of ownership over the fake hand predicted the degree to which one perceived the sense of ownership over the stranger\u2019s voice, after controlling for task demand and suggestibility. Thus, our results provide evidence for a shared inference supporting subjective sense of self across fundamentally different attributes. We suggest that individual reliance on multisensory signals to drive such an inference can be further explored. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2022-08-25T00:00:00+00:00",
      "source": "Clinical Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 184,
      "reading_time": 1,
      "created_at": "2025-11-18T03:13:16.473208+00:00",
      "updated_at": "2025-11-18T03:13:16.473210+00:00"
    },
    {
      "id": "fa250840ddf6808c93613cad856c7c25",
      "url": "http://doi.org/10.1037/cns0000353",
      "title": "Unmuting lucid dreams: Speech decoding and vocalization in real time.",
      "content": "Since the 1970s, scientists have been searching for ways to communicate with people in lucid dreams (LDs), during which it is possible to maintain consciousness. Previously, dreamers could hear sounds from reality and respond with some simple signals, but they could not speak back. In this study, facial surface electromyography (EMG) was tested as a proof of concept for unmuting people in LDs. Remmyo, an EMG distinctive constructed language, was used. The software was developed to translate facial EMG impulses into Remmyo sounds and letters, translate words into English, and digitally vocalize the final text in English. Four LD practitioners were trained to pronounce a short phrase or a word in Remmyo and were then asked to achieve the same task in LDs under polysomnographic observation. LDs were verified by preagreed eye movements in rapid eye movement (REM) sleep. Four volunteers tried to speak in Remmyo in 15 LDs. Due to software failures, mispronunciations, and missing sounds, the decoding efficiency in real time or in recordings ranged from 13% to 81%. The first phrase and word heard from sleeping people were \u201cno war\u201d and \u201cfreedom.\u201d The later was automatically translated and vocalized in English in real time for 11 times. Despite controversial results, the study shows that, with further development, people could possibly talk in LDs and could be heard in reality with the help of EMG sensors. To achieve this goal, a range of possible obstacles is discussed. This technology could provide opportunities for LD studies and their practical applications. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2023-03-13T00:00:00+00:00",
      "source": "Clinical Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 260,
      "reading_time": 1,
      "created_at": "2025-11-18T03:13:16.473172+00:00",
      "updated_at": "2025-11-18T03:13:16.473174+00:00"
    },
    {
      "id": "3cace5c5d9bdc4eeebb05365c3e99538",
      "url": "http://doi.org/10.1037/cns0000402",
      "title": "Creating a world in the head: The conscious apprehension of neural content originating from internal sources.",
      "content": "Klein et al. (2023) argued that the evolutionary transition from respondent to agent during the Cambrian explosion would be a promising vantage point from which to gain insight into the evolution of organic sentience. They focused on how increased competition for resources\u2014in consequence of the proliferation of new, neurally sophisticated life-forms\u2014made awareness of the external world (in the service of agentic acts) an adaptive priority. The explanatory scope of Klein et al. (2023) was limited to consideration of the conscious apprehension of externally sourced content\u2014that is, content delivered from the sensory registration of objects occupying phenomenal space. But consciousness\u2014at least for humans\u2014takes its objects from internal as well as external sources. In the present article, we extend their analysis to the question of how internally sourced content (i.e., mental states) became the object of conscious apprehension. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2024-09-09T00:00:00+00:00",
      "source": "Clinical Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 145,
      "reading_time": 1,
      "created_at": "2025-11-18T03:13:16.473127+00:00",
      "updated_at": "2025-11-18T03:13:16.473129+00:00"
    },
    {
      "id": "4dc92cbf63e410e4d59f6ffd2f7dec90",
      "url": "http://doi.org/10.1037/cns0000406",
      "title": "Not all minds think alike: Examining the impact of time and task on visual and verbal thought.",
      "content": "Research suggests that individuals have different phenomenological experiences across various tasks. However, little is known about how these experiences vary by task or over time. This study examined participants\u2019 experiences of task-unrelated thoughts (i.e., TUTs), visual, and verbal thoughts across two experimental sessions and two different tasks. In addition, we examined relations between participants\u2019 thoughts and key individual difference factors. In Session 1, participants (<em>n</em> = 85) engaged in a focused-attention meditation and a reading task, then completed a second identical session with a new text. Throughout both tasks, participants were prompted to report on the characteristics of their thoughts. Participants\u2019 ratings of TUT, visual, and verbal thoughts were subject to change over time. Furthermore, on average, participants visualized more and had fewer TUTs while reading compared to meditation; however, no task difference was found for verbal-thinking reports. This suggests that visual imagery is more malleable than verbal-thinking. There was a strong negative correlation between visual and verbal thoughts, suggesting that at any given time, individuals\u2019 thoughts tended to be either predominantly visual or verbal. Finally, individual differences in the tendency to become immersed in narratives and motivation to engage with other people\u2019s perspectives (i.e., mind-reading motivation) were related to higher reports of visual imagery during reading, whereas verbal-thinking was negatively associated with mind-reading motivation and unrelated to TUT. Overall, this study revealed that individuals\u2019 phenomenological experiences vary during tasks and across time, providing a foundation for future work to examine why and how variability in these phenomenological experiences emerge. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2024-10-14T00:00:00+00:00",
      "source": "Clinical Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 259,
      "reading_time": 1,
      "created_at": "2025-11-18T03:13:16.473093+00:00",
      "updated_at": "2025-11-18T03:13:16.473095+00:00"
    },
    {
      "id": "b36a06d4938612ca6e9dff53b652c239",
      "url": "https://www.reddit.com/r/Python/comments/1ozr7d7/so_what_do_you_use_when/",
      "title": "' \" \"\"\" So, what do you use when? \"\"\" \" '",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>I realized I have kind of an idiosyncratic way of deciding which quotation form to use as the outermost quotations in any particular situation, which is:</p> <ul> <li>Multiline, &quot;&quot;&quot;.</li> <li>If the string is intended to be human-visible, &quot;.</li> <li>If the string is not intended to be human-visible, '.</li> </ul> <p>I've done this for so long I hadn't quite realized this is just a convention I made up. How do you decide?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/MisterHarvest\"> /u/MisterHarvest </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1ozr7d7/so_what_do_you_use_when/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1ozr7d7/so_what_do_you_use_when/\">[comments]</a></span>",
      "author": "/u/MisterHarvest",
      "published_date": "2025-11-17T20:22:23+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 92,
      "reading_time": 1,
      "created_at": "2025-11-18T03:13:08.516010+00:00",
      "updated_at": "2025-11-18T03:13:08.516011+00:00"
    },
    {
      "id": "e8de5557095876ed3e9ed3de200098f8",
      "url": "https://www.windowslatest.com/2025/11/18/windows-11-to-add-an-ai-agent-that-runs-in-background-with-access-to-personal-folders-warns-of-security-risk/",
      "title": "Windows 11 adds AI agent that runs in background with access to personal folders",
      "content": "<p>Article URL: <a href=\"https://www.windowslatest.com/2025/11/18/windows-11-to-add-an-ai-agent-that-runs-in-background-with-access-to-personal-folders-warns-of-security-risk/\">https://www.windowslatest.com/2025/11/18/windows-11-to-add-an-ai-agent-that-runs-in-background-with-access-to-personal-folders-warns-of-security-risk/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=45959795\">https://news.ycombinator.com/item?id=45959795</a></p>\n<p>Points: 108</p>\n<p># Comments: 80</p>",
      "author": "jinxmeta",
      "published_date": "2025-11-17T23:47:27+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-11-18T03:13:05.883130+00:00",
      "updated_at": "2025-11-18T03:13:05.883131+00:00"
    },
    {
      "id": "855d6dc2fb8e893269479497db872a70",
      "url": "https://unbuffered.stream/gemini-personal-context/",
      "title": "I caught Google Gemini using my data and then covering it up",
      "content": "<p>Article URL: <a href=\"https://unbuffered.stream/gemini-personal-context/\">https://unbuffered.stream/gemini-personal-context/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=45960293\">https://news.ycombinator.com/item?id=45960293</a></p>\n<p>Points: 116</p>\n<p># Comments: 29</p>",
      "author": "JakaJancar",
      "published_date": "2025-11-18T01:11:34+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-11-18T03:13:05.883107+00:00",
      "updated_at": "2025-11-18T03:13:05.883109+00:00"
    },
    {
      "id": "3bec6fc7eafe119e1424c5650c708f09",
      "url": "https://www.pcgamer.com/gaming-industry/legendary-game-designer-programmer-space-invaders-champion-and-lgbtq-trailblazer-rebecca-heineman-has-died/",
      "title": "Rebecca Heineman has died",
      "content": "<p>Article URL: <a href=\"https://www.pcgamer.com/gaming-industry/legendary-game-designer-programmer-space-invaders-champion-and-lgbtq-trailblazer-rebecca-heineman-has-died/\">https://www.pcgamer.com/gaming-industry/legendary-game-designer-programmer-space-invaders-champion-and-lgbtq-trailblazer-rebecca-heineman-has-died/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=45960368\">https://news.ycombinator.com/item?id=45960368</a></p>\n<p>Points: 67</p>\n<p># Comments: 8</p>",
      "author": "shdon",
      "published_date": "2025-11-18T01:25:54+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-11-18T03:13:05.883076+00:00",
      "updated_at": "2025-11-18T03:13:05.883084+00:00"
    },
    {
      "id": "86b524dea62a675641cd4dee21ccb303",
      "url": "https://www.biorxiv.org/content/10.1101/2025.11.17.688805v1?rss=1",
      "title": "Micro-/nano-plastics accentuate Parkinson's Disease-relevant phenotypes in a Drosophila model",
      "content": "Micro- and nano-plastic (MNP) particles are a ubiquitous environmental contaminant that are increasingly bioaccumulating in human tissues, particularly the brain. MNPs induce mitochondrial defects, oxidative stress, inflammatory responses and neurotoxicity in cellular and organismal models. This raises the possibility that MNP exposure could cause or exacerbate neurological conditions associated with these pathological phenomena. Parkinson's Disease (PD), a common movement disorder characterised by degeneration of striatal dopaminergic neurons, and associated with mitochondrial dysfunction, represents such a condition. We therefore hypothesised that MNP exposure might interact with PD risk mutations affecting mitochondrial fidelity. We used a fruit fly model of PRKN-dependent PD associated with defects in mitophagy, a mitochondrial quality control pathway, to test this hypothesis. We found that ingestion of MNPs at concentrations tolerated by wild-type controls selectively enhanced PD-relevant phenotypes - including progressive dopaminergic neurodegeneration, movement defects, and sleep disruption - in this model of PD. Our data suggest that defects in mitochondrial quality control can increase vulnerability to MNP exposure, and more broadly, that MNPs may synergistically interact with existing genetic risk factors to worsen neurological disease.",
      "author": "Lowe, S. A., jepson, j.",
      "published_date": "2025-11-17T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 178,
      "reading_time": 1,
      "created_at": "2025-11-18T01:39:56.668120+00:00",
      "updated_at": "2025-11-18T03:08:56.453069+00:00",
      "metadata": {
        "processed_at": "2025-11-18T03:08:56.453079+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "f0864d9a9ac18256b74b04db4e763a93",
      "url": "https://www.biorxiv.org/content/10.1101/2025.11.17.688824v1?rss=1",
      "title": "Insular error network enables self-correcting intracranial brain-computer interface",
      "content": "Error recognition is fundamental to adaptive behavior, enabling rapid compensatory action when outcomes deviate from expectations. Central to this function are neural circuits for performance monitoring, encoding cognitive signals that could support more reliable neural interfaces. Here, we recorded intracranial electroencephalography (iEEG) in epilepsy patients to enable a motor brain-computer interface (BCI) while sampling error-related activity across a distributed network. Our work reveals high-frequency population dynamics emerging in the anterior insula and propagating to the prefrontal cortex as the interface fails to follow the user's intention. We identify spatially organized insular responses to error processing and movement feedback, highlighting it as a heterogeneous hub linking action and outcome. Real-time integration of error responses enables a self-correcting neural interface that enhances usability by reducing the need for manual user intervention. Together, our work demonstrates a human intracranial BCI harnessing insular brain activity, integrating cognitive processes directly into device control.",
      "author": "Weger, P., Ottenhoff, M. C., Verwoert, M., Gimple, S. V., Ostrowski, L., Colon, A., Wagner, L., van Dijk, J. P., Temel, Y., Kubben, P., Herff, C.",
      "published_date": "2025-11-17T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 148,
      "reading_time": 1,
      "created_at": "2025-11-18T01:39:56.668085+00:00",
      "updated_at": "2025-11-18T03:08:56.453083+00:00",
      "metadata": {
        "processed_at": "2025-11-18T03:08:56.453085+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "abc321538c2d49aec8be07b660e12888",
      "url": "https://www.biorxiv.org/content/10.1101/2025.11.17.688806v1?rss=1",
      "title": "An inhibitory feedback circuit mediating sleep need and sensory gating in Drosophila",
      "content": "Many animals integrate sensory information during the day and sleep at night. How sensory processing during wakefulness contributes to making an organism tired at night, however, remains elusive. Here, we investigate the role of excitatory helicon cells in Drosophila (ExR1), a distinct neural population dedicated to processing sensory information. Using combined optogenetics and voltage imaging, we show that helicon cells excite sleep-promoting R3m ring neurons and trigger a subsequent autoinhibition of R3m via voltage- and Ca2+-gated K+ channels such as Slowpoke. Investigating the flies' sleep patterns, we found that blocking synaptic output from helicon as well as RNAi-mediated knockdown of Slowpoke in R3m reduces sleep quality and leads to loss of nocturnal sleep, indicating that sleep need is generated via this route. Further, we show that excitation of R3m induces feedback inhibition of helicon cells via ionotropic GABA receptors. Knockdown of the ionotropic GABA receptor subunit Rdl in helicon cells increases sleep latency and causes sleep loss at the beginning of the night. We show that inhibition via Rdl facilitates nocturnal slow-wave activity which forms a sensory filter and prevents sleep disruption through auditory stimuli. We therefore uncover an inhibitory feedback circuit, in which neurons processing sensory information directly activate sleep promoting neurons to generate sleep need. At night, this sleep need is then converted into actual sleep, facilitated by the formation of a neural filter that stabilizes sleep/wake transition.",
      "author": "Brodersen, C. B., Wibroe, J., Shakespeare, L. M., Owald, D., Krohn, K., Raccuglia, D.",
      "published_date": "2025-11-17T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 230,
      "reading_time": 1,
      "created_at": "2025-11-18T01:39:56.668043+00:00",
      "updated_at": "2025-11-18T03:08:56.453087+00:00",
      "metadata": {
        "processed_at": "2025-11-18T03:08:56.453089+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "ad2afdced5ff481ec5c2fe471b7a6b18",
      "url": "https://3nt3.de/blog/reversing-fs7-comms",
      "title": "Show HN: Reversing a Cinema Camera's Peripherals Port",
      "content": "<a href=\"https://news.ycombinator.com/item?id=45888805\">Comments</a>",
      "author": "",
      "published_date": "2025-11-11T15:57:48+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-11-18T01:39:20.290654+00:00",
      "updated_at": "2025-11-18T03:08:56.453091+00:00",
      "metadata": {
        "processed_at": "2025-11-18T03:08:56.453093+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "cda6c2aed4e90a3d62bf0840ead876d2",
      "url": "https://github.com/kaushiksrini/parqeye",
      "title": "Show HN: Parqeye \u2013 A CLI tool to visualize and inspect Parquet files",
      "content": "<p>I built a Rust-based CLI/terminal UI for inspecting Parquet files\u2014data, metadata, and row-group-level structure\u2014right from the terminal. If someone sent me a Parquet file, I used to open DuckDB or Polars just to see what was inside. Now I can do it with one command.<p>Repo: <a href=\"https://github.com/kaushiksrini/parqeye\" rel=\"nofollow\">https://github.com/kaushiksrini/parqeye</a></p>\n<hr />\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=45959780\">https://news.ycombinator.com/item?id=45959780</a></p>\n<p>Points: 20</p>\n<p># Comments: 5</p>",
      "author": "kaushiksrini",
      "published_date": "2025-11-17T23:45:42+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 59,
      "reading_time": 1,
      "created_at": "2025-11-18T01:39:18.964173+00:00",
      "updated_at": "2025-11-18T03:08:56.453097+00:00",
      "metadata": {
        "processed_at": "2025-11-18T03:08:56.453099+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "a8adb8e21ba8ade167865b32c18747a2",
      "url": "http://ieeexplore.ieee.org/document/11235877",
      "title": "Separate Timescales for Spatial and Anatomical Information Processing of Body Stimuli",
      "content": "Observing different body stimuli can influence the speed and accuracy of our responses. Prior work indicates this effect is influenced by factors such as spatial congruence and perspective. We hypothesized that the influence of these factors would vary depending on the amount of time that participants had to process visual stimuli. Experiment 1 was a RT task (n = 29) with stimuli varying in spatial congruence (congruent, incongruent, neutral), perspective (first- or third-person), and stimulus type (body or control). Experiment 2 (n = 50) used the same stimuli in a \u201cForced Response\u201d paradigm, which controlled the time participants had to prepare a response. This allowed us to assess responses as a function of preparation time. Experiment 1 showed effects of spatial congruence, with longer RTs and more errors for spatially incongruent stimuli. This effect was greater for body stimuli. Experiment 2 showed that spatial information was processed faster than anatomical information, inducing incorrect responses at short preparation times for spatially incongruent body stimuli. There was little-to-no corresponding effect for control stimuli. Both experiments also showed weak-to-no effects of perspective, which appear to have been driven by spatial congruence. Our results indicate that spatial information is processed faster than anatomical information during observation of body stimuli. These data are consistent with the dual visual streams hypothesis, whereby spatial information would be processed rapidly via the dorsal stream, whereas anatomical processing would occur later via the ventral stream. These data also indicate differences in processing between body and control stimuli.",
      "author": "",
      "published_date": "2025-11-07T13:16:23+00:00",
      "source": "Cognitive Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 248,
      "reading_time": 1,
      "created_at": "2025-11-17T23:40:26.845495+00:00",
      "updated_at": "2025-11-18T01:11:08.017226+00:00",
      "metadata": {
        "processed_at": "2025-11-18T01:11:08.017237+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "fb588439a33dbfe3eb0b3edf79a54446",
      "url": "http://ieeexplore.ieee.org/document/11235874",
      "title": "Transient Inhibition of the Posterior Parietal Cortex Affects Action-related But Not Action-unrelated Visual Processing during Path Integration",
      "content": "Path integration refers to the ability to monitor self-motion cues to keep track of changes in position and orientation. This function is often assumed to rely predominantly on medial temporal lobe structures containing grid, place, and head direction cells. Recent evidence, however, suggests that key navigational computations may occur outside this system, for example, in posterior parietal areas. Here, we adopted a novel perspective derived from animal research and examined whether human path integration relies on processing streams in the posterior parietal cortex (PPC), depending on the involvement of actively controlled motion as opposed to passive perception of visual optic flow. We compared the effects of inhibiting the PPC via TMS on two path integration tasks in a virtual reality, only one of which involved active control of a visually simulated forward movement. Behavioral performance showed that distance judgments were selectively affected in the action-related path integration task. This finding shows that the processing of actively controlled motion depends on computations in the PPC, whereas passive processing of optic flow is largely independent of the PPC computations. Our results reinforce the hypothesis that the PPC plays a critical role for the integration of goal locations and self-positional signals within an egocentric frame of reference. In addition to the medial temporal lobe, the posterior parietal system is recruited during tasks involving actively controlled movements, whereas medial temporal computations are sufficient for passive monitoring of positional changes.",
      "author": "",
      "published_date": "2025-11-07T13:16:23+00:00",
      "source": "Cognitive Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 235,
      "reading_time": 1,
      "created_at": "2025-11-17T23:40:26.845444+00:00",
      "updated_at": "2025-11-18T01:11:08.017240+00:00",
      "metadata": {
        "processed_at": "2025-11-18T01:11:08.017242+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "531780bd9b4422343606f0da4ea82642",
      "url": "https://www.sciencedirect.com/science/article/pii/S0006899325005633?dgcid=rss_sd_all",
      "title": "Apprehending relational events: The visual world paradigm and the interplay of event perception and language",
      "content": "<p>Publication date: 15 December 2025</p><p><b>Source:</b> Brain Research, Volume 1869</p><p>Author(s): Alon Hafri, John C. Trueswell</p>",
      "author": "",
      "published_date": null,
      "source": "Brain Research",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 14,
      "reading_time": 1,
      "created_at": "2025-11-17T23:40:18.563993+00:00",
      "updated_at": "2025-11-18T01:11:08.017244+00:00",
      "metadata": {
        "processed_at": "2025-11-18T01:11:08.017246+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "ec58c9d93da22407b29699efdf988196",
      "url": "https://www.nature.com/articles/s42003-025-08944-6",
      "title": "Wanting what hurts: D1 dopamine neuronal stimulation in CeA is sufficient to induce maladaptive attraction",
      "content": "",
      "author": "",
      "published_date": "2025-11-17T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-11-17T23:40:12.431092+00:00",
      "updated_at": "2025-11-18T01:11:08.017248+00:00",
      "metadata": {
        "processed_at": "2025-11-18T01:11:08.017250+00:00",
        "processing_method": "github_actions"
      }
    }
  ]
}