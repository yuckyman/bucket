{
  "last_updated": "2026-01-13T05:28:02.957849+00:00",
  "count": 20,
  "articles": [
    {
      "id": "7f81d3c0232aabe3edaeb7c4c9558e97",
      "url": "https://arxiv.org/abs/2601.06516",
      "title": "Pareto-Optimal Model Selection for Low-Cost, Single-Lead EMG Control in Embedded Systems",
      "content": "arXiv:2601.06516v1 Announce Type: new \nAbstract: Consumer-grade biosensors offer a cost-effective alternative to medical-grade electromyography (EMG) systems, reducing hardware costs from thousands of dollars to approximately $13. However, these low-cost sensors introduce significant signal instability and motion artifacts. Deploying machine learning models on resource-constrained edge devices like the ESP32 presents a challenge: balancing classification accuracy with strict latency (<100ms) and memory (<320KB) constraints. Using a single-subject dataset comprising 1,540 seconds of raw data (1.54M data points, segmented into ~1,300 one-second windows), I evaluate 18 model architectures, ranging from statistical heuristics to deep transfer learning (ResNet50) and custom hybrid networks (MaxCRNN). While my custom \"MaxCRNN\" (Inception + Bi-LSTM + Attention) achieved the highest safety (99% Precision) and robustness, I identify Random Forest (74% accuracy) as the Pareto-optimal solution for embedded control on legacy microcontrollers. I demonstrate that reliable, low-latency EMG control is feasible on commodity hardware, with Deep Learning offering a path to near-perfect reliability on modern Edge AI accelerators.",
      "author": "Carl Vincent Ladres Kho",
      "published_date": "2026-01-13T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 158,
      "reading_time": 1,
      "created_at": "2026-01-13T05:27:44.310537+00:00",
      "updated_at": "2026-01-13T05:27:44.310539+00:00"
    },
    {
      "id": "b17cd82407ae3aadbdace1bb1e3b9e7b",
      "url": "https://arxiv.org/abs/2601.06402",
      "title": "Spatiotemporal Change-Points in Development Discourse: Insights from Social Media in Low-Resource Contexts",
      "content": "arXiv:2601.06402v1 Announce Type: new \nAbstract: This study investigates the spatiotemporal evolution of development discourse in low-resource settings. Analyzing more than two years of geotagged X data from Zambia, we introduce a mixed-methods pipeline utilizing topic modeling, change-point detection, and qualitative coding to identify critical shifts in public debate. We identify seven recurring themes, including public health challenges and frustration with government policy, shaped by regional events and national interventions. Notably, we detect discourse changepoints linked to the COVID19 pandemic and a geothermal project, illustrating how online conversations mirror policy flashpoints. Our analysis distinguishes between the ephemeral nature of acute crises like COVID19 and the persistent, structural reorientations driven by long-term infrastructure projects. We conceptualize \"durable discourse\" as sustained narrative engagement with development issues. Contributing to HCI and ICTD, we examine technology's socioeconomic impact, providing practical implications and future work for direct local engagement.",
      "author": "Woojin Jung, Charles Chear, Andrew H. Kim, Vatsal Shah, Tawfiq Ammari",
      "published_date": "2026-01-13T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 143,
      "reading_time": 1,
      "created_at": "2026-01-13T05:27:44.310505+00:00",
      "updated_at": "2026-01-13T05:27:44.310506+00:00"
    },
    {
      "id": "721e39367f7188cac12c27477bfa58ee",
      "url": "https://arxiv.org/abs/2601.06364",
      "title": "Human-in-the-Loop Interactive Report Generation for Chronic Disease Adherence",
      "content": "arXiv:2601.06364v1 Announce Type: new \nAbstract: Chronic disease management requires regular adherence feedback to prevent avoidable hospitalizations, yet clinicians lack time to produce personalized patient communications. Manual authoring preserves clinical accuracy but does not scale; AI generation scales but can undermine trust in patient-facing contexts. We present a clinician-in-the-loop interface that constrains AI to data organization and preserves physician oversight through recognition-based review. A single-page editor pairs AI-generated section drafts with time-aligned visualizations, enabling inline editing with visual evidence for each claim. This division of labor (AI organizes, clinician decides) targets both efficiency and accountability. In a pilot with three physicians reviewing 24 cases, AI successfully generated clinically personalized drafts matching physicians' manual authoring practice (overall mean 4.86/10 vs. 5.0/10 baseline), requiring minimal physician editing (mean 8.3\\% content modification) with zero safety-critical issues, demonstrating effective automation of content generation. However, review time remained comparable to manual practice, revealing an accountability paradox: in high-stakes clinical contexts, professional responsibility requires complete verification regardless of AI accuracy. We contribute three interaction patterns for clinical AI collaboration: bounded generation with recognition-based review via chart-text pairing, automated urgency flagging that analyzes vital trends and adherence patterns with fail-safe escalation for missed critical monitoring tasks, and progressive disclosure controls that reduce cognitive load while maintaining oversight. These patterns indicate that clinical AI efficiency requires not only accurate models, but also mechanisms for selective verification that preserve accountability.",
      "author": "Xiaotian Zhang, Jinhong Yu, Pengwei Yan, Le Jiang, Xingyi Shen, Mumo Cheng, Xiaozhong Liu",
      "published_date": "2026-01-13T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 230,
      "reading_time": 1,
      "created_at": "2026-01-13T05:27:44.310476+00:00",
      "updated_at": "2026-01-13T05:27:44.310477+00:00"
    },
    {
      "id": "c6d4e5601c3236e7c00f3e3c3e5c62a5",
      "url": "https://arxiv.org/abs/2601.06033",
      "title": "How Generative AI Empowers Attackers and Defenders Across the Trust & Safety Landscape",
      "content": "arXiv:2601.06033v1 Announce Type: new \nAbstract: Generative AI (GenAI) is a powerful technology poised to reshape Trust & Safety. While misuse by attackers is a growing concern, its defensive capacity remains underexplored. This paper examines these effects through a qualitative study with 43 Trust & Safety experts across five domains: child safety, election integrity, hate and harassment, scams, and violent extremism. Our findings characterize a landscape in which GenAI empowers both attackers and defenders. GenAI dramatically increases the scale and speed of attacks, lowering the barrier to entry for creating harmful content, including sophisticated propaganda and deepfakes. Conversely, defenders envision leveraging GenAI to detect and mitigate harmful content at scale, conduct investigations, deploy persuasive counternarratives, improve moderator wellbeing, and offer user support. This work provides a strategic framework for understanding GenAI's impact on Trust & Safety and charts a path for its responsible use in creating safer online environments.",
      "author": "Patrick Gage Kelley, Steven Rousso-Schindler, Renee Shelby, Kurt Thomas, Allison Woodruff",
      "published_date": "2026-01-13T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 148,
      "reading_time": 1,
      "created_at": "2026-01-13T05:27:44.310441+00:00",
      "updated_at": "2026-01-13T05:27:44.310442+00:00"
    },
    {
      "id": "e56f3e54d193ef21dbd1c1e51e3e3841",
      "url": "https://arxiv.org/abs/2601.06032",
      "title": "Applied Theory of Mind and Large Language Models - how good is ChatGPT at solving social vignettes?",
      "content": "arXiv:2601.06032v1 Announce Type: new \nAbstract: The rapid development of language-based artificial intelligence (AI) offers new possibilities for psychotherapy and assistive systems, particularly benefitting autistic individuals who often respond well to technology. Parents of autistic persons emphasize the importance of appropriate and context-specific communication behavior. This study investigated whether GPT-3.5 Turbo and GPT-4, as language-based AI applications, are fundamentally capable of replicating this type of adequate communication behavior in the form of applied Theory of Mind (ToM). GPT-3.5 Turbo and GPT-4 were evaluated on three established higher-order ToM tasks: the Faux Pas Test, the Social Stories Questionnaire, and the Story Comprehension Test in English and German. Two independent raters scored response accuracy based on standardized manuals. In addition, responses were rated for epistemic markers as indicators of uncertainty. GPT's results were compared to human neurotypical and neurodivergent samples from previous own and others' research. GPT-4 achieved near human accuracy on the Faux Pas Test and outperformed GPT-3.5 Turbo and individuals with autistic traits. On the Social Stories Questionnaire, GPT-4 scored comparable to neurotypical adults, while GPT-3.5 Turbo remained well below. In the Story Comprehension Test, GPT-4 reached scores that exceeded neurotypical adult and adolescent benchmarks. However, GPT-4 used epistemic markers in up to 42% of responses. GPT-4 shows encouraging performance in complex higher-order ToM tasks and may offer future potential as an assistive tool for individuals with (and without) social communication difficulties. Its ability to interpret complex social situations is promising; however, the frequent use of uncertainty markers highlights the need for further study for assistive use and possibly further refinement to ensure consistent and reliable support in real-world use.",
      "author": "Anna Katharina Holl-Etten, Nina Schnaderbeck, Elizaveta Kosareva, Leonhard Aron Prattke, Ralph Krueger, Lisa Marie Warner, Nora C. Vetter",
      "published_date": "2026-01-13T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 269,
      "reading_time": 1,
      "created_at": "2026-01-13T05:27:44.310412+00:00",
      "updated_at": "2026-01-13T05:27:44.310414+00:00"
    },
    {
      "id": "e052cc061cb1eec51ed0a7d6746ba2b4",
      "url": "https://arxiv.org/abs/2601.06031",
      "title": "Beyond Clicking:A Step Towards Generalist GUI Grounding via Text Dragging",
      "content": "arXiv:2601.06031v1 Announce Type: new \nAbstract: Graphical user interface (GUI) grounding, the process of mapping human instructions to GUI actions, serves as a fundamental basis to autonomous GUI agents. While existing grounding models achieve promising performance to simulate the mouse click action on various click-based benchmarks, another essential mode of mouse interaction, namely dragging, remains largely underexplored. Yet, dragging the mouse to select and manipulate textual content represents a prevalent and important usage in practical GUI scenarios. To narrow this gap, we first introduce GUI-Drag, a diverse dataset of 161K text dragging examples synthesized through a scalable pipeline. To support systematic and robust evaluation, we further construct ScreenDrag, a benchmark with 5,333 examples spanning three levels of interface context, together with three dedicated metrics designed for assessing text dragging capability. Models trained on GUI-Drag with an efficient continual training strategy achieve substantial improvements on ScreenDrag, while preserving the original click-based performance on ScreenSpot, ScreenSpot-v2, and OSWorld-G. Our work encourages further research on broader GUI grounding beyond just clicking and paves way toward a truly generalist GUI grounding model. All benchmark, data, checkpoints, and code are open-sourced and available at https://osu-nlp-group.github.io/GUI-Drag.",
      "author": "Zeyi Liao, Yadong Lu, Boyu Gou, Huan Sun, Ahmed Awadallah",
      "published_date": "2026-01-13T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 189,
      "reading_time": 1,
      "created_at": "2026-01-13T05:27:44.310375+00:00",
      "updated_at": "2026-01-13T05:27:44.310376+00:00"
    },
    {
      "id": "291e80729673a48a079a4ec6b4929401",
      "url": "https://arxiv.org/abs/2601.06030",
      "title": "From Augmentation to Symbiosis: A Review of Human-AI Collaboration Frameworks, Performance, and Perils",
      "content": "arXiv:2601.06030v1 Announce Type: new \nAbstract: This paper offers a concise, 60-year synthesis of human-AI collaboration, from Licklider's ``man-computer symbiosis\" (AI as colleague) and Engelbart's ``augmenting human intellect\" (AI as tool) to contemporary poles: Human-Centered AI's ``supertool\" and Symbiotic Intelligence's mutual-adaptation model. We formalize the mechanism for effective teaming as a causal chain: Explainable AI (XAI) -> co-adaptation -> shared mental models (SMMs). A meta-analytic ``performance paradox\" is then examined: human-AI teams tend to show negative synergy in judgment/decision tasks (underperforming AI alone) but positive synergy in content creation and problem formulation. We trace failures to the algorithm-in-the-loop dynamic, aversion/bias asymmetries, and cumulative cognitive deskilling. We conclude with a unifying framework--combining extended-self and dual-process theories--arguing that durable gains arise when AI functions as an internalized cognitive component, yielding a unitary human-XAI symbiotic agency. This resolves the paradox and delineates a forward agenda for research and practice.",
      "author": "Richard Jiarui Tong",
      "published_date": "2026-01-13T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 145,
      "reading_time": 1,
      "created_at": "2026-01-13T05:27:44.310343+00:00",
      "updated_at": "2026-01-13T05:27:44.310344+00:00"
    },
    {
      "id": "3795e7ed4e2302107ca2ee1e1142be36",
      "url": "https://arxiv.org/abs/2601.06029",
      "title": "A Recommendation System-Based Framework for Enhancing Human-Machine Collaboration in Industrial Timetabling Rescheduling: Application in Preventive Maintenance",
      "content": "arXiv:2601.06029v1 Announce Type: new \nAbstract: Industrial timetabling is a critical task for decision-makers across various sectors to ensure efficient system operation. In real-world settings, it remains challenging because unexpected events often disrupt execution. When such events arise, effective rescheduling and collaboration between humans and machines becomes essential. This paper presents a recommendation system-based framework for handling rescheduling challenges, built on Timefold, a powerful AI-driven planning engine. Our experimental study evaluates nine instances inspired by a realworld preventive maintenance use case, aiming to identify the heuristic that best balances solution quality and computing time to support near-optimal decisionmaking when rescheduling is required due to unexpected events during operational days. Finally, we illustrate the complete process of our recommendation system through a simple use case.",
      "author": "K\\'evin Ducharlet, Liwen Zhang, Sara Maqrot, Houssem Saidi",
      "published_date": "2026-01-13T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 123,
      "reading_time": 1,
      "created_at": "2026-01-13T05:27:44.310314+00:00",
      "updated_at": "2026-01-13T05:27:44.310315+00:00"
    },
    {
      "id": "a77f5121b5790d16d994b34bfde45ef2",
      "url": "https://arxiv.org/abs/2601.06028",
      "title": "Leveraging Foundation Models for Calibration-Free c-VEP BCIs",
      "content": "arXiv:2601.06028v1 Announce Type: new \nAbstract: Foundation Models (FMs) have surged in popularity over the past five years, with applications spanning fields from computer vision to natural language processing. Brain-Computer Interfaces (BCIs) have also gained momentum due to their potential to support individuals with complex disabilities. Among BCI paradigms, code-modulated Visual Evoked Potentials (c-VEPs) remain relatively understudied, despite offering high information transfer rates and large selection target capacities. However, c-VEP systems require lengthy calibration sessions, limiting their practicality outside of laboratory settings. In this study, we use a FM for the first time to eliminate the need for lengthy calibration in c-VEP BCI systems. We evaluated two approaches: (1) a truly calibration-free approach requiring no subject-specific data, and (2) a limited calibration approach, where we assessed the benefit of incorporating incremental amounts of calibration data. In both cases, a classification head is trained on data from other subjects. For a new subject, no calibration data is required in the calibration-free setup, making the c-VEP system effectively plug-and-play. The proposed method was tested on two c-VEP datasets. For the calibration-free approach, the average accuracy on the first dataset (n = 17) was 68.8% +/- 17.6%, comparable to the full-calibration performance reported in the original study (66.2% +/- 13.8%), which required approximately 11 minutes of calibration. On the second dataset (n = 12), the calibration-free accuracy was 71.8% +/- 20.2%, versus 93.7% +/- 5.5% from the original study, which required around 3.5 minutes. A limited-calibration approach using only 20% of the subject's data (approximately 43 seconds) yielded 92% +/- 5.2% accuracy. These results indicate that our FM-based approach can effectively eliminate or significantly reduce the need for lengthy calibration in c-VEP BCIs.",
      "author": "Mohammadreza Behboodi, Eli Kinney-Lang, Ali Etemad, Adam Kirton, Hatem Abou-Zeid",
      "published_date": "2026-01-13T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 279,
      "reading_time": 1,
      "created_at": "2026-01-13T05:27:44.310284+00:00",
      "updated_at": "2026-01-13T05:27:44.310286+00:00"
    },
    {
      "id": "7e97286f1940857620fbfe036d84fb35",
      "url": "https://arxiv.org/abs/2601.06027",
      "title": "AI-Assisted Authoring for Transparent, Data-Driven Documents",
      "content": "arXiv:2601.06027v1 Announce Type: new \nAbstract: We introduce _transparent documents_, interactive web-based scholarly articles which allow readers to explore the relationship to the underlying data by hovering over fragments of text, and present an LLM-based tool for authoring transparent documents, building on recent developments in data provenance for general-purpose programming languages. As a target platform, our implementation uses Fluid, an open source programming language with a provenance-tracking runtime. Our agent-based tool supports a human author during the creation of transparent documents, identifying fragments of text which can be computed from data, such as numerical values selected from records or computed by aggregations like sum and mean, comparatives and superlatives like _better than_ and _largest_, trend-adjectives like _growing_, and similar quantitative or semi-quantitative phrases, and then attempts to synthesise a suitable Fluid query over the data which generates the target string. The resulting expression is inserted into the article's web page, turning the static text fragment into an interactable data-driven element able to reveal the data that underwrites the natural language claim. We evaluate our approach on a subset of SciGen, an open source dataset consisting of tables from scientific articles and their corresponding descriptions, which we extend with hand-generated counterfactual test cases to evaluate how well machine-generated expressions generalise. Our results show that gpt4o is often able to synthesise compound expressions extensionally compatible with our gold solutions.",
      "author": "Alfonso Piscitelli, Cristina David, Mattia De Rosa, Ali Mohammed, Federico Nanni, Jacob Pake, Roly Perera, Jessy Sodimu, Chenyiqiu Zheng",
      "published_date": "2026-01-13T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 226,
      "reading_time": 1,
      "created_at": "2026-01-13T05:27:44.310234+00:00",
      "updated_at": "2026-01-13T05:27:44.310239+00:00"
    },
    {
      "id": "d8964037b0dfd91f74fafab9f20b0165",
      "url": "https://arxiv.org/abs/2512.12802",
      "title": "A Disproof of Large Language Model Consciousness: The Necessity of Continual Learning for Consciousness",
      "content": "arXiv:2512.12802v2 Announce Type: replace \nAbstract: Scientific theories of consciousness should be falsifiable and non-trivial. Recent research has given us formal tools to analyze these requirements of falsifiability and non-triviality for theories of consciousness. Surprisingly, many contemporary theories of consciousness fail to pass this bar, including theories based on causal structure but also (as I demonstrate) theories based on function. Herein I show these requirements of falsifiability and non-triviality especially constrain the potential consciousness of contemporary Large Language Models (LLMs) because of their proximity to systems that are equivalent to LLMs in terms of input/output function; yet, for these functionally equivalent systems, there cannot be any falsifiable and non-trivial theory of consciousness that judges them conscious. This forms the basis of a disproof of contemporary LLM consciousness. I then show a positive result, which is that theories of consciousness based on (or requiring) continual learning do satisfy the stringent formal constraints for a theory of consciousness in humans. Intriguingly, this work supports a hypothesis: If continual learning is linked to consciousness in humans, the current limitations of LLMs (which do not continually learn) are intimately tied to their lack of consciousness.",
      "author": "Erik Hoel",
      "published_date": "2026-01-13T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 190,
      "reading_time": 1,
      "created_at": "2026-01-13T05:27:43.228190+00:00",
      "updated_at": "2026-01-13T05:27:43.228191+00:00"
    },
    {
      "id": "86eb1726f8f1502abb9e6f18d9551450",
      "url": "https://arxiv.org/abs/2508.06514",
      "title": "Synthetic Data Generation for Classifying Electrophysiological and Morpho-Electrophysiological Neurons from Mouse Visual Cortex",
      "content": "arXiv:2508.06514v2 Announce Type: replace \nAbstract: The accurate classification of neuronal cell types is central to decoding brain function, yet remains hindered by data scarcity and cellular heterogeneity. Here, we benchmarked classical and deep generative synthetic data augmentation strategies -- including SMOTE, GANs, VAEs, Normalizing Flows, and DDPMs -- for supervised classification of both electrophysiological (e-type) and morpho-electrophysiological (mee-type) neuron types from the mouse visual cortex. Using a curated dataset annotated with 48 electrophysiological and 24 morphological features, we established baseline classifiers and introduced synthetic data generated by each method. Our results demonstrate that SMOTE-based augmentation yields the highest classification accuracies (absolute gains of 0.16 for e-types, 0.12 for mee-types), outperforming deep generative models. GANs approached similar performance when hyperparameters and sample sizes were optimized, but were more sensitive to model specification. In addition, we benchmarked synthetic neuron fidelity by comparing mean absolute errors between synthetic and real class profiles against the natural phenotypic variability observed between real neuronal classes.",
      "author": "Xavier Vasques, Laura Cif",
      "published_date": "2026-01-13T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 159,
      "reading_time": 1,
      "created_at": "2026-01-13T05:27:43.228158+00:00",
      "updated_at": "2026-01-13T05:27:43.228160+00:00"
    },
    {
      "id": "efce1b6a48b2d56181bdac897cfad6ce",
      "url": "https://arxiv.org/abs/2403.16933",
      "title": "Backpropagation through space, time, and the brain",
      "content": "arXiv:2403.16933v4 Announce Type: replace \nAbstract: How physical networks of neurons, bound by spatio-temporal locality constraints, can perform efficient credit assignment, remains, to a large extent, an open question. In machine learning, the answer is almost universally given by the error backpropagation algorithm, through both space and time. However, this algorithm is well-known to rely on biologically implausible assumptions, in particular with respect to spatio-temporal (non-)locality. Alternative forward-propagation models such as real-time recurrent learning only partially solve the locality problem, but only at the cost of scaling, due to prohibitive storage requirements. We introduce Generalized Latent Equilibrium (GLE), a computational framework for fully local spatio-temporal credit assignment in physical, dynamical networks of neurons. We start by defining an energy based on neuron-local mismatches, from which we derive both neuronal dynamics via stationarity and parameter dynamics via gradient descent. The resulting dynamics can be interpreted as a real-time, biologically plausible approximation of backpropagation through space and time in deep cortical networks with continuous-time neuronal dynamics and continuously active, local synaptic plasticity. In particular, GLE exploits the morphology of dendritic trees to enable more complex information storage and processing in single neurons, as well as the ability of biological neurons to phase-shift their output rate with respect to their membrane potential, which is essential in both directions of information propagation. For the forward computation, it enables the mapping of time-continuous inputs to neuronal space, effectively performing a spatio-temporal convolution. For the backward computation, it permits the temporal inversion of feedback signals, which consequently approximate the adjoint variables necessary for useful parameter updates.",
      "author": "Benjamin Ellenberger, Paul Haider, Jakob Jordan, Kevin Max, Ismael Jaras, Laura Kriener, Federico Benitez, Mihai A. Petrovici",
      "published_date": "2026-01-13T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 259,
      "reading_time": 1,
      "created_at": "2026-01-13T05:27:43.228129+00:00",
      "updated_at": "2026-01-13T05:27:43.228130+00:00"
    },
    {
      "id": "b98ee2fea67a1e22b6526f3e7eac4fa1",
      "url": "https://arxiv.org/abs/2601.07830",
      "title": "Optimal Learning Rate Schedule for Balancing Effort and Performance",
      "content": "arXiv:2601.07830v1 Announce Type: cross \nAbstract: Learning how to learn efficiently is a fundamental challenge for biological agents and a growing concern for artificial ones. To learn effectively, an agent must regulate its learning speed, balancing the benefits of rapid improvement against the costs of effort, instability, or resource use. We introduce a normative framework that formalizes this problem as an optimal control process in which the agent maximizes cumulative performance while incurring a cost of learning. From this objective, we derive a closed-form solution for the optimal learning rate, which has the form of a closed-loop controller that depends only on the agent's current and expected future performance. Under mild assumptions, this solution generalizes across tasks and architectures and reproduces numerically optimized schedules in simulations. In simple learning models, we can mathematically analyze how agent and task parameters shape learning-rate scheduling as an open-loop control solution. Because the optimal policy depends on expectations of future performance, the framework predicts how overconfidence or underconfidence influence engagement and persistence, linking the control of learning speed to theories of self-regulated learning. We further show how a simple episodic memory mechanism can approximate the required performance expectations by recalling similar past learning experiences, providing a biologically plausible route to near-optimal behaviour. Together, these results provide a normative and biologically plausible account of learning speed control, linking self-regulated learning, effort allocation, and episodic memory estimation within a unified and tractable mathematical framework.",
      "author": "Valentina Njaradi, Rodrigo Carrasco-Davis, Peter E. Latham, Andrew Saxe",
      "published_date": "2026-01-13T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 237,
      "reading_time": 1,
      "created_at": "2026-01-13T05:27:43.228092+00:00",
      "updated_at": "2026-01-13T05:27:43.228094+00:00"
    },
    {
      "id": "5f98f00a1819f51f153824659698961c",
      "url": "https://arxiv.org/abs/2601.06991",
      "title": "Continuous Energy Landscape Model for Analyzing Brain State Transitions",
      "content": "arXiv:2601.06991v1 Announce Type: cross \nAbstract: Energy landscape models characterize neural dynamics by assigning energy values to each brain state that reflect their stability or probability of occurrence. The conventional energy landscape models rely on binary brain state representation, where each region is considered either active or inactive based on some signal threshold. However, this binarization leads to significant information loss and an exponential increase in the number of possible brain states, making the calculation of energy values infeasible for large numbers of brain regions. To overcome these limitations, we propose a novel continuous energy landscape framework that employs Graph Neural Networks (GNNs) to learn a continuous precision matrix directly from functional MRI (fMRI) signals, preserving the full range of signal values during energy landscape computation. We validated our approach using both synthetic data and real-world fMRI datasets from brain tumor patients. Our results on synthetic data generated from a switching linear dynamical system (SLDS) and a Kuramoto model show that the continuous energy model achieved higher likelihood and more accurate recovery of basin geometry, state occupancy, and transition dynamics than conventional binary energy landscape models. In addition, results from the fMRI dataset indicate a 0.27 increase in AUC for predicting working memory and executive function, along with a 0.35 improvement in explained variance (R2) for predicting reaction time. These findings highlight the advantages of utilizing the full signal values in energy landscape models for capturing neuronal dynamics, with strong implications for diagnosing and monitoring neurological disorders.",
      "author": "Triet M. Tran, Seyed Majid Razavi, Dee H. Wu, Sina Khanmohammadi",
      "published_date": "2026-01-13T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 246,
      "reading_time": 1,
      "created_at": "2026-01-13T05:27:43.228057+00:00",
      "updated_at": "2026-01-13T05:27:43.228059+00:00"
    },
    {
      "id": "fff796e2fe9e7af8ddf99a52835b9049",
      "url": "https://arxiv.org/abs/2601.06134",
      "title": "DeeperBrain: A Neuro-Grounded EEG Foundation Model Towards Universal BCI",
      "content": "arXiv:2601.06134v1 Announce Type: cross \nAbstract: Electroencephalography (EEG) foundation models hold significant promise for universal Brain-Computer Interfaces (BCIs). However, existing approaches often rely on end-to-end fine-tuning and exhibit limited efficacy under frozen-probing protocols, lacking the intrinsic universality required for broad generalization. This limitation stems from adapting general-purpose sequence architectures that overlook the biophysical and dynamical principles of neural activity. To bridge this gap, we propose DeeperBrain, a neuro-grounded foundation model integrating domain-specific inductive biases into its model design and learning objectives. Architecturally, DeeperBrain incorporates a volume conduction-aware channel encoding to model spatial mixing via 3D geometry, and a neurodynamics-aware temporal encoding capturing slow adaptations using oscillatory and exponential bases. For pretraining, we introduce a dual-objective strategy combining Masked EEG Reconstruction (MER) for local fidelity and Neurodynamics Statistics Prediction (NSP). NSP enforces alignment with macroscopic brain states by predicting interpretable order parameters, including spectral power, functional connectivity, cross-frequency coupling, and dynamic complexity. Extensive experiments demonstrate that DeeperBrain achieves state-of-the-art or highly competitive performance under end-to-end fine-tuning. Crucially, it maintains superior efficacy under a rigorous frozen-probing protocol, verifying that embedding neuroscientific first principles endows learned representations with the intrinsic universality essential for universal BCI. The code will be publicly available.",
      "author": "Jiquan Wang, Sha Zhao, Yangxuan Zhou, Yiming Kang, Shijian Li, Gang Pan",
      "published_date": "2026-01-13T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 197,
      "reading_time": 1,
      "created_at": "2026-01-13T05:27:43.228020+00:00",
      "updated_at": "2026-01-13T05:27:43.228022+00:00"
    },
    {
      "id": "83d27772d2bb4750aada3822410d04d6",
      "url": "https://arxiv.org/abs/2601.07591",
      "title": "Charting the velocity of brain growth and development",
      "content": "arXiv:2601.07591v1 Announce Type: new \nAbstract: Brain charts have emerged as a highly useful approach for understanding brain development and aging on the basis of brain imaging and have shown substantial utility in describing typical and atypical brain development with respect to a given reference model. However, all existing models are fundamentally cross-sectional and cannot capture change over time at the individual level. We address this using velocity centiles, which directly map change over time and can be overlaid onto cross-sectionally derived population centiles. We demonstrate this by modelling rates of change for 24062 scans from 10795 healthy individuals with up to 8 longitudinal measurements across the lifespan. We provide a method to detect individual deviations from a stable trajectory, generalising the notion of thrive lines, which are used in pediatric medicine to declare failure to thrive. Using this approach, we predict transition from mild cognitive impairment to dementia more accurately than by using either time point alone, replicated across two datasets. Last, by taking into account multiple time points, we improve the sensitivity of velocity models for predicting the future trajectory of brain change. This highlights the value of predicting change over time and makes a fundamental step towards precision medicine.",
      "author": "Johanna M. M. Bayer, Augustijn A. A. de Boer, Barbora Rehak-Bucova, Charlotte J. Fraza, Tobias Banaschewski, Gareth J. Barker, Arun L. W. Bokde, Ruediger Bruehl, Sylvane Desrivieres, Herta Flor, Hugh Garavan, Penny Gowland, Antoine Grigis, Andreas Heinz, Herve Lemaitre, Jean-Luc Martinot, Marie-Laure Paillere Martinot, Eric Artigues, Frauke Nees, Dimitri Papadopoulos Orfanos, Tomas Paus, Luise Poustka, Michael N. Smolka, Nathalie Holz, Nilakshi Vaidya, Henrik Walter, Robert Whelan, Paul Wirsching, Gunter Schumann, Alzheimers Disease Neuroimaging Initiative, Nina Kraguljac, Christian F. Beckmann, Andre F. Marquand",
      "published_date": "2026-01-13T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 201,
      "reading_time": 1,
      "created_at": "2026-01-13T05:27:43.227988+00:00",
      "updated_at": "2026-01-13T05:27:43.227989+00:00"
    },
    {
      "id": "2883525f11d412cd15360ee245767402",
      "url": "https://arxiv.org/abs/2601.07215",
      "title": "Neuronal Spike Trains as Functional-Analytic Distributions: Representation, Analysis, and Significance",
      "content": "arXiv:2601.07215v1 Announce Type: new \nAbstract: The action potential constitutes the digital component of the signaling dynamics of neurons. But the biophysical nature of the full time course of the action potential associated with changes in membrane potential is fundamentally and mathematically distinct from its representation as a discrete set of events that encode when action potentials triggered in a collection spike trains. In this paper, we rigorously explore from first principles the transition and modeling from the standard biophysical picture of a single action potential to its representation as a spike in a spike train. In particular, we adopt a functional-analytic framework, using Schwartz distribution theory to represent spike trains as generalized Dirac delta functions acting on smooth test functions. We then show how and why this representation transcends a purely descriptive formalism to support deep downstream analysis and modeling of spike train neural dynamics in a mathematically consistent way.",
      "author": "Gabriel A. Silva",
      "published_date": "2026-01-13T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 150,
      "reading_time": 1,
      "created_at": "2026-01-13T05:27:43.227954+00:00",
      "updated_at": "2026-01-13T05:27:43.227956+00:00"
    },
    {
      "id": "7f1fc01197e6838db3eee04f176229e7",
      "url": "https://arxiv.org/abs/2601.06531",
      "title": "Learning Principles for Overcoming Non-ideal Factors in Brain",
      "content": "arXiv:2601.06531v1 Announce Type: new \nAbstract: The human brain's computational prowess emerges not despite but because of its inherent \"non-ideal factors\"-noise, heterogeneity, structural irregularities, decentralized plasticity, systemic errors, and chaotic dynamics-challenging classical neuroscience's idealized models. These traits, long dismissed as flaws, are evolutionary adaptations that endow the brain with robustness, creativity, and adaptability. Classical frameworks falter under the brain's complexity: simulating 86 billion neurons and 100 trillion synapses is intractable, stochastic neurotransmitter release confounds signal interpretation, and the absence of global idealized models invalidates deterministic learning frameworks. Technological gaps further obscure whole-brain dynamics, revealing a disconnect between biological reality and computational abstraction.",
      "author": "Da-Zheng Feng, Hao-Xuan Du",
      "published_date": "2026-01-13T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 101,
      "reading_time": 1,
      "created_at": "2026-01-13T05:27:43.227923+00:00",
      "updated_at": "2026-01-13T05:27:43.227925+00:00"
    },
    {
      "id": "0106f6f6b0633922a09791b074c343a1",
      "url": "https://arxiv.org/abs/2601.06257",
      "title": "Gamma2Patterns: Deep Cognitive Attention Region Identification and Gamma-Alpha Pattern Analysis",
      "content": "arXiv:2601.06257v1 Announce Type: new \nAbstract: Deep cognitive attention is characterized by heightened gamma oscillations and coordinated visual behavior. Despite the physiological importance of these mechanisms, computational studies rarely synthesize these modalities or identify the neural regions most responsible for sustained focus. To address this gap, this work introduces Gamma2Patterns, a multimodal framework that characterizes deep cognitive attention by leveraging complementary Gamma and Alpha band EEG activity alongside Eye-tracking measurements. Using the SEED-IV dataset [1], we extract spectral power, burst-based temporal dynamics, and fixation-saccade-pupil signals across 62 channels or electrodes to analyze how neural activation differs between high-focus (Gamma-dominant) and low-focus (Alpha-dominant) states. Our findings reveal that frontopolar, temporal, anterior frontal, and parieto-occipital regions exhibit the strongest Gamma power and burst rates, indicating their dominant role in deep attentional engagement, while Eye-tracking signals confirm complementary contributions from frontal, frontopolar, and frontotemporal regions. Furthermore, we show that Gamma power and burst duration provide more discriminative markers of deep focus than Alpha power alone, demonstrating their value for attention decoding. Collectively, these results establish a multimodal, evidence-based map of cortical regions and oscillatory signatures underlying deep focus, providing a neurophysiological foundation for future brain-inspired attention mechanisms in AI systems.",
      "author": "Sobhana Jahan, Saydul Akbar Murad, Nick Rahimi, Noorbakhsh Amiri Golilarz",
      "published_date": "2026-01-13T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 196,
      "reading_time": 1,
      "created_at": "2026-01-13T05:27:43.227891+00:00",
      "updated_at": "2026-01-13T05:27:43.227895+00:00"
    }
  ]
}