{
  "last_updated": "2026-01-24T23:42:58.112406+00:00",
  "count": 20,
  "articles": [
    {
      "id": "77db3477c8d22ebbd43d1cb7c510512e",
      "url": "https://fmhy.net/posts/jan-2026",
      "title": "Monthly Updates [January]",
      "content": "<div class=\"info custom-block\"><p class=\"custom-block-title\">INFO</p>\n<p>These update threads only contains major updates. If you're interested\nin seeing all minor changes you can follow our\n<a href=\"https://github.com/fmhy/FMHYedit/commits/main\" rel=\"noreferrer\" target=\"_blank\">Commits Page</a> on GitHub or\n<a href=\"https://redd.it/17f8msf\" rel=\"noreferrer\" target=\"_blank\">Updates Channel</a> in Discord.</p>\n</div>\n<h1 id=\"wiki-updates\" tabindex=\"-1\">Wiki Updates <a class=\"header-anchor\" href=\"#wiki-updates\"></a></h1>\n<ul>\n<li>\n<p>Added <strong><a href=\"https://ffmhy.pages.dev/\" rel=\"noreferrer\" target=\"_blank\">Alternative Frontend</a></strong> of FMHY with totally different design. This pulls from the official source, so it will stay synced with new edits. It also has a <a href=\"https://i.ibb.co/fVkHqhRP/image.png\" rel=\"noreferrer\" target=\"_blank\">random site</a> / <a href=\"https://i.imgur.com/p4Mxs8y.png\" rel=\"noreferrer\" target=\"_blank\">2</a> button that works per page. Note the front page for this has been removed, and it now directs to the wiki itself. Thank you to nw for making this.</p>\n</li>\n<li>\n<p>Added <strong><a href=\"https://fmhy.net/other/backups\" rel=\"noreferrer\" target=\"_blank\">3 New Instances</a></strong> to our Backups Page. (Samidy, JBugel, ArtistGrid.)</p>\n</li>\n<li>\n<p>Added <strong><a href=\"https://i.ibb.co/Ps8vDJL0/image.png\" rel=\"noreferrer\" target=\"_blank\">Catppuccin</a></strong> / <a href=\"https://i.imgur.com/558l4gH.png\" rel=\"noreferrer\" target=\"_blank\">2</a> as a option in our color picker. Thank you to Samidy for doing this.</p>\n</li>\n<li>\n<p>Added new section for <a href=\"https://fmhy.net/reading#textbooks\" rel=\"noreferrer\" target=\"_blank\">Textbooks</a>.</p>\n</li>\n<li>\n<p>Added new section for <a href=\"https://fmhy.net/file-tools#file-info-metadata\" rel=\"noreferrer\" target=\"_blank\">File Info / Metadata</a>.</p>\n</li>\n<li>\n<p>Merged Linux + Mac Torrent Clients into <a href=\"https://fmhy.net/torrenting#torrent-clients\" rel=\"noreferrer\" target=\"_blank\">Main Section</a>, and added labels + platform icons. <a href=\"https://i.ibb.co/fV1zdt44/Untitled.jpg\" rel=\"noreferrer\" target=\"_blank\">Before vs After</a> / <a href=\"https://i.imgur.com/THLiMqL.jpeg\" rel=\"noreferrer\" target=\"_blank\">2</a></p>\n</li>\n<li>\n<p>Re-ordered <a href=\"https://fmhy.net/reading#light-novels\" rel=\"noreferrer\" target=\"_blank\">Light Novel Sites</a> based on library size and UI, added labels, removed small libraries, and starred two that stood out (NovelCool + WuxiaClick). <a href=\"https://i.ibb.co/DSRfsrM/Untitled.png\" rel=\"noreferrer\" target=\"_blank\">Before vs After</a> / <a href=\"https://i.imgur.com/IMRUQoo.png\" rel=\"noreferrer\" target=\"_blank\">2</a></p>\n</li>\n<li>\n<p>Debloated <a href=\"https://fmhy.net/audio#curated-recommendations\" rel=\"noreferrer\" target=\"_blank\">Audio Recommendation</a> section + added new section for <a href=\"https://fmhy.net/audio#song-artist-discovery\" rel=\"noreferrer\" target=\"_blank\">Song / Artist Discovery</a>. <a href=\"https://i.ibb.co/zTDNZgr9/Untitled.png\" rel=\"noreferrer\" target=\"_blank\">Before vs After</a> / <a href=\"https://i.imgur.com/V6h0mQx.png\" rel=\"noreferrer\" target=\"_blank\">2</a></p>\n</li>\n<li>\n<p>Added Labels to both <a href=\"https://fmhy.net/linux-macos#cli-cheat-sheets\" rel=\"noreferrer\" target=\"_blank\">Linux Cheat Sheets</a> + <a href=\"https://fmhy.net/linux-macos#linux-distros\" rel=\"noreferrer\" target=\"_blank\">Linux Distros</a>, thank you to <a href=\"https://github.com/fmhy/edit/commit/9a9cd6dd47027ac63370b453ec86a943cdc0b9d6\" rel=\"noreferrer\" target=\"_blank\">helxop</a>. <a href=\"https://ibb.co/gMD8mKbw\" rel=\"noreferrer\" target=\"_blank\">Before vs After</a> / <a href=\"https://i.imgur.com/hqqLsCB.png\" rel=\"noreferrer\" target=\"_blank\">2</a></p>\n</li>\n<li>\n<p>Revamped our <a href=\"https://i.ibb.co/JjpzRXL7/image.png\" rel=\"noreferrer\" target=\"_blank\">Feedback Window</a> / <a href=\"https://i.imgur.com/nODLPVM.png\" rel=\"noreferrer\" target=\"_blank\">2</a> to try to improve its look. Thank you to Samidy for doing this.</p>\n</li>\n<li>\n<p>Added a backup / frontend for our <a href=\"https://fmhy-grading.pages.dev/\" rel=\"noreferrer\" target=\"_blank\">Grading Page</a>, and moved both our <a href=\"https://fmhy.net/other/backups\" rel=\"noreferrer\" target=\"_blank\">Backup</a> + <a href=\"https://fmhy.net/other/FAQ\" rel=\"noreferrer\" target=\"_blank\">FAQ</a> pages to our website instead of reddit/github. Thank you to Roi Goat + Samidy for doing this.</p>\n</li>\n<li>\n<p>Improved our <a href=\"https://github.com/fmhy/edit/pull/4386\" rel=\"noreferrer\" target=\"_blank\">theme handler</a>, which will help us more easily switch or add themes in the future (like halloween, christmas, etc.) Thank you to Land for doing this.</p>\n</li>\n<li>\n<p>Added 360 Total Security to unsafe sites. If you install any of their apps, it will keep giving the user popups to install their &quot;toolbox,&quot; or will install it without consent if you use clean, repair, or optimize options. Once installed, the toolbox will then <a href=\"https://en.wikipedia.org/wiki/Criticism_of_Qihoo_360#Malicious_promotion\" rel=\"noreferrer\" target=\"_blank\">modify your default apps</a> (such as your browser) and switch them all to 360 options.</p>\n</li>\n</ul>\n<hr />\n<h1 id=\"stars-added-\u2b50\" tabindex=\"-1\">Stars Added \u2b50 <a class=\"header-anchor\" href=\"#stars-added-\u2b50\"></a></h1>\n<ul>\n<li>\n<p>Starred <a href=\"https://fmhy.net/video#download-sites\" rel=\"noreferrer\" target=\"_blank\">DDLBase</a> in Video Download, has both 4K + 1080p content, uses only fast hosts, has huge library.</p>\n</li>\n<li>\n<p>Starred <a href=\"https://fmhy.net/video#anime-streaming\" rel=\"noreferrer\" target=\"_blank\">Anime Realms</a> in Anime Streaming. Good sources, nice UI, auto-next, custom player, multi-language.</p>\n</li>\n<li>\n<p>Starred <a href=\"https://fmhy.net/audio#telegram-bots\" rel=\"noreferrer\" target=\"_blank\">Music Hunters</a> in Telegram Audio Bots. Supports lots of sites, has good quality, easy to use.</p>\n</li>\n<li>\n<p>Starred <a href=\"https://fmhy.net/gaming#download-games\" rel=\"noreferrer\" target=\"_blank\">AstralGames </a> in Game Downloading, big library, fast hosts, pre-installs, allows requests.</p>\n</li>\n<li>\n<p>Starred <a href=\"https://fmhy.net/reading#manga\" rel=\"noreferrer\" target=\"_blank\">Comix</a> in Manga Sites, big library, allows uploads, nice UI, will be adding more languages soon.</p>\n</li>\n<li>\n<p>Starred <a href=\"https://fmhy.net/audio#streaming-sites\" rel=\"noreferrer\" target=\"_blank\">Monochrome</a> in Audio Streaming, no-signup needed, multi API integrations, last.fm integration, customizable, big library.</p>\n</li>\n<li>\n<p>Starred <a href=\"https://fmhy.net/video\" rel=\"noreferrer\" target=\"_blank\">Rive, Aether, Willow, and FlyX</a> in Streaming. These have nice custom players, lots of features, fast streams, and impressive UIs.</p>\n</li>\n<li>\n<p>Starred <a href=\"https://fmhy.net/video#live-sports\" rel=\"noreferrer\" target=\"_blank\">StreamSports99</a> in Live Sports, has fast servers and solid UI.</p>\n</li>\n<li>\n<p>Starred <a href=\"https://fmhy.net/social-media-tools#twitter-x-customization\" rel=\"noreferrer\" target=\"_blank\">Control Panel for Twitter</a> Twitter/X Customization, adds a lot of extra features, lets you hide sections you don't use, improves UI, and much more.</p>\n</li>\n<li>\n<p>Starred <a href=\"https://fmhy.net/file-tools#file-hosts\" rel=\"noreferrer\" target=\"_blank\">Rootz</a> File Hosts, good speed, 25GB per file, lasts 15 days after last download.</p>\n</li>\n<li>\n<p>Starred <a href=\"https://fmhy.net/ai#image-generation\" rel=\"noreferrer\" target=\"_blank\">PigenAI</a> in Image Gen, has unlimited Imagen 4, Qwen, and Nano Banana.</p>\n</li>\n<li>\n<p>Starred <a href=\"https://fmhy.net/mobile#ios-streaming\" rel=\"noreferrer\" target=\"_blank\">Nuvio</a> in iOS Streaming, this uses Stremio Plugins, and has less limits than the &quot;Lite&quot; version currently available on iOS.</p>\n</li>\n<li>\n<p>Starred <a href=\"https://fmhy.net/mobile#android-torrenting\" rel=\"noreferrer\" target=\"_blank\">Flud</a> in Android Torrenting, allows binding, well maintained, ads can easily be blocked via DNS.</p>\n</li>\n<li>\n<p>Starred <a href=\"https://fmhy.net/misc#physical-health\" rel=\"noreferrer\" target=\"_blank\">Sleeping Guide</a> in Physical Health, sleep hygiene / science guide, seems to be well received so far, curated by Dan.</p>\n</li>\n<li>\n<p>Starred <a href=\"https://fmhy.net/gaming#remakes-recreations\" rel=\"noreferrer\" target=\"_blank\">OpenMW</a> in Remakes / Recreations, complete ground up reimplementation of Morrowind, <a href=\"https://wiki.openmw.org/index.php?title=Bethesda_Emails\" rel=\"noreferrer\" target=\"_blank\">approved by Bethesda</a> themselves.</p>\n</li>\n<li>\n<p>Starred <a href=\"https://fmhy.net/gaming#remakes-recreations\" rel=\"noreferrer\" target=\"_blank\">Clone Hero</a> in Remakes / Recreations, feature-rich Guitar Hero clone, thousands of songs + playlists, no lag, works with all guitar controllers, and supports midi drum kits.</p>\n</li>\n<li>\n<p>Starred <a href=\"https://fmhy.net/gaming#party-multiplayer\" rel=\"noreferrer\" target=\"_blank\">Gidd</a> in Multiplayer Browser Games, has quality versions of things like monopoly, geoguessr, card games, etc.</p>\n</li>\n<li>\n<p>Starred <a href=\"https://fmhy.net/system-tools#virtual-machines\" rel=\"noreferrer\" target=\"_blank\">QEMU</a> in Virtual Machines, performs well on non-windows systems, best used with Virt-Manager or Vagrantup.</p>\n</li>\n<li>\n<p>Starred <a href=\"https://fmhy.net/file-tools#file-backup\" rel=\"noreferrer\" target=\"_blank\">Restic</a> in File Backup, easy to use, multi-platform, performed well in benchmarks.</p>\n</li>\n<li>\n<p>Starred <a href=\"https://fmhy.net/ai#coding-ais\" rel=\"noreferrer\" target=\"_blank\">Gemini CLI</a> in Coding AIs, this seems to have some of the best limits as of now.</p>\n</li>\n</ul>\n<hr />\n<h1 id=\"things-removed\" tabindex=\"-1\">Things Removed <a class=\"header-anchor\" href=\"#things-removed\"></a></h1>\n<ul>\n<li>\n<p>Removed CrocDB as they've been <a href=\"https://i.ibb.co/RpDvJFgf/image.png\" rel=\"noreferrer\" target=\"_blank\">hit by DMCA</a> / <a href=\"https://i.imgur.com/iSV0MHq.png\" rel=\"noreferrer\" target=\"_blank\">2</a>.</p>\n</li>\n<li>\n<p>Removed IcebergCharts website as they've been <a href=\"https://i.ibb.co/XxMMwqDk/image.png\" rel=\"noreferrer\" target=\"_blank\">hacked a few times now</a> / <a href=\"https://i.imgur.com/MkvElvr.png\" rel=\"noreferrer\" target=\"_blank\">2</a>, and can't figure out why its happening. We may re-add in future if they figure it out. Note that we'll keep the subreddit in its place for now.</p>\n</li>\n<li>\n<p>Removed CanvasBlocker as its Firefox only, and FF has this built in now, it can also apparently make fingerprinting worse in some cases, and isn't maintained well anymore.</p>\n</li>\n<li>\n<p>Removed FTV and WAC from Live Sports as both are now gone.</p>\n</li>\n<li>\n<p>Removed Foxified as its suddenly <a href=\"https://i.ibb.co/4RzPsQ8Z/image.png\" rel=\"noreferrer\" target=\"_blank\">filling results with ads</a> / <a href=\"https://i.imgur.com/AjBMdfX.png\" rel=\"noreferrer\" target=\"_blank\">2</a>.</p>\n</li>\n<li>\n<p>Unstarred OnTheSpot as it will be losing Spotify Support soon.</p>\n</li>\n<li>\n<p>Unstarred Windsurf in Coding AIs as its limits and free models aren't as good anymore.</p>\n</li>\n</ul>",
      "author": "",
      "published_date": "2026-01-01T00:00:00+00:00",
      "source": "Fmhy",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 1122,
      "reading_time": 5,
      "created_at": "2026-01-24T23:41:48.927473+00:00",
      "updated_at": "2026-01-24T23:41:48.927479+00:00"
    },
    {
      "id": "26da94320919aca79c6f893cdc353a63",
      "url": "https://www.reddit.com/r/Python/comments/1qm1swm/score_exacte_fifa_virtuelle_24_4x4/",
      "title": "Score exacte FIFA virtuelle 24 4x4",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>Je veux que mon application soit installable et une application de pronostic FIFA virtuelle 24 4x4 dans le jeux. Sur les c\u00f4tes donne par le bookmaker 1XBET selons les histoires des scores exacte du dernier \u00e9v\u00e9nement et leurs c\u00f4tes, et une fois que je lui donne les c\u00f4tes de v1 et V2 qu'il puisse me g\u00e9n\u00e9r\u00e9 automatiquement les scores exacte et une probabilit\u00e9 rassurant par AI</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/No_Marsupial9443\"> /u/No_Marsupial9443 </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1qm1swm/score_exacte_fifa_virtuelle_24_4x4/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1qm1swm/score_exacte_fifa_virtuelle_24_4x4/\">[comments]</a></span>",
      "author": "/u/No_Marsupial9443",
      "published_date": "2026-01-24T22:59:52+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 87,
      "reading_time": 1,
      "created_at": "2026-01-24T23:41:47.554969+00:00",
      "updated_at": "2026-01-24T23:41:47.554971+00:00"
    },
    {
      "id": "548f3cd93de572165bbbf83d05d2a9f4",
      "url": "https://www.reddit.com/r/Python/comments/1qm1uz3/web_scraping_change_detection_scrapes_the/",
      "title": "Web scraping - change detection (scrapes the underlying APIs not just raw selectors)",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>I was recently building a RAG pipeline where I needed to extract web data at scale. I found that many of the LLM scrapers that generate markdown are way too noisy for vector DBs and are extremely expensive.</p> <p><strong>What My Project Does</strong><br /> I ended up releasing what I built for myself: it's an easy way to run large scale web scraping jobs and only get changes to content you've already scraped. It can fully automate API calls or just extract raw HTML.</p> <p>Scraping lots of data is hard to orchestrate, requires antibot handling, proxies, etc. I built all of this into the platform so you can just point it to a URL, extract what data you want in JSON, and then track the changes to the content.</p> <p><strong>Target Audience</strong></p> <p>Anyone running scraping jobs in production - whether that's mass data extraction or monitoring job boards, price changes, etc. </p> <p><strong>Comparison</strong></p> <p>Tools like firecrawl and others use full browsers - this is slow and why these services are so expensive. This tool finds the underlying APIs or extracts the raw HTML with only requests - it's much faster and allows us to deterministically monitor for changes because we are only pulling out relevant data. </p> <p>The entire app runs through our python SDK! </p> <p>sdk: <a href=\"https://github.com/reverse/meter-sdk\">https://github.com/reverse/meter-sdk</a> </p> <p>homepage: <a href=\"https://meter.sh\">https://meter.sh</a> </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Ready-Interest-1024\"> /u/Ready-Interest-1024 </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1qm1uz3/web_scraping_change_detection_scrapes_the/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1qm1uz3/web_scraping_change_detection_scrapes_the/\">[comments]</a></span>",
      "author": "/u/Ready-Interest-1024",
      "published_date": "2026-01-24T23:01:57+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 243,
      "reading_time": 1,
      "created_at": "2026-01-24T23:21:03.345126+00:00",
      "updated_at": "2026-01-24T23:21:03.345127+00:00"
    },
    {
      "id": "6d0f6b6f41334f236a55497487dd4c32",
      "url": "https://www.reddit.com/r/Python/comments/1qm1kxu/how_i_went_down_a_massive_rabbit_hole_and_ended/",
      "title": "How I went down a massive rabbit hole and ended up building 4 libraries",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>A few months ago, I was in between jobs and hacking on a personal project just for fun. I built one of those automated video generators using an LLM. You know the type: the LLM writes a script, TTS narrates it, stock footage is grabbed, and it's all stitched together. Nothing revolutionary, just a fun experiment.</p> <p>I hit a wall when I wanted to add subtitles. I didn't want boring static text; I wanted styled, animated captions (like the ones you see on social media). I started researching Python libraries to do this easily, but I couldn't find anything &quot;plug-and-play.&quot; Everything seemed to require a lot of manual logic for positioning and styling.</p> <p>During my research, I stumbled upon a YouTube video called <em>&quot;Shortrocity EP6: Styling Captions Better with MoviePy&quot;</em>. At around the 44:00 mark, the creator said something that stuck with me: <em>&quot;I really wish I could do this like in CSS, that would be the best.&quot;</em></p> <p>That was the spark. I thought, <em>why not?</em> Why not render the subtitles using HTML/CSS (where styling is easy) and then burn them into the video?</p> <p>I implemented this idea using Playwright (using a headless browser) to render the HTML+CSS and then get the images. It worked, and I packaged it into a tool called <strong>pycaps</strong>. However, as I started testing it, it just felt wrong. I was spinning up an entire, heavy web browser instance just to render a few words on a transparent background. It felt incredibly wasteful and inefficient.</p> <p>I spent a good amount of time trying to optimize this setup. I implemented aggressive caching for Playwright and even wrote a custom rendering solution using OpenCV inside <code>pycaps</code> to avoid MoviePy and speed things up. It worked, but I still couldn't shake the feeling that I was using a sledgehammer to crack a nut.</p> <p>So, I did what any reasonable developer trying to avoid &quot;real work&quot; would do: I decided to solve these problems by building my own dedicated tools.</p> <p>First, weeks after releasing <code>pycaps</code>, I couldn't stop thinking about generating text images without the overhead of a browser. That led to <strong>pictex</strong>. Initially, it was just a library to render text using Skia (PICture + TEXt). Honestly, that first version was enough for what <code>pycaps</code> needed. But I fell into another rabbit hole. I started thinking, <em>&quot;What about having two texts with different styles? What about positioning text relative to other elements?&quot;</em> I went way beyond the original scope and integrated Taffy to support a full Flexbox-like architecture, turning it into a generic rendering engine.</p> <p>Then, to connect my original CSS templates from <code>pycaps</code> with this new engine, I wrote <strong>html2pic</strong>, which acts as a bridge, translating HTML/CSS directly into <code>pictex</code> render calls.</p> <p>Finally, I went back to my original AI video generator project. I remembered the custom OpenCV solution I had hacked together inside <code>pycaps</code> earlier. I decided to extract that logic into a standalone library called <strong>movielite</strong>. Just like with <code>pictex</code>, I couldn't help myself. I didn't simply extract the code. Instead, I ended up over-engineering it completely. I added Numba for JIT compilation and polished the API to make it a generic, high-performance video editor, far exceeding the simple needs of my original script.</p> <p><strong>Long story short:</strong> I tried to add subtitles to a video, and I ended up maintaining four different open-source libraries. The original &quot;AI Video Generator&quot; project is barely finished, and honestly, now that I have a full-time job and these four repos to maintain, it will probably never be finished. But hey, at least the subtitles render fast now.</p> <p>If anyone is interested in the tech stack that came out of this madness, or has dealt with similar performance headaches, here are the repos:</p> <ul> <li> <strong>pictex</strong> (The graphics engine): <a href=\"https://github.com/francozanardi/pictex\">https://github.com/francozanardi/pictex</a></li> <li> <strong>movielite</strong> (The video editor): <a href=\"https://github.com/francozanardi/movielite\">https://github.com/francozanardi/movielite</a></li> <li> <strong>html2pic</strong> (The HTML/CSS to image tool): <a href=\"https://github.com/francozanardi/html2pic\">https://github.com/francozanardi/html2pic</a></li> <li> <strong>pycaps</strong> (The subtitle tool that started it all): <a href=\"https://github.com/francozanardi/pycaps\">https://github.com/francozanardi/pycaps</a></li> </ul> <hr /> <p><strong>What My Project Does</strong></p> <p>This is a suite of four interconnected libraries designed for high-performance video and image generation in Python: * <strong>pictex:</strong> Generates images programmatically using Skia and Taffy (Flexbox), allowing for complex layouts without a browser. * <strong>pycaps:</strong> Automatically generates animated subtitles for videos using Whisper for transcription and CSS for styling. * <strong>movielite:</strong> A lightweight video editing library optimized with Numba/OpenCV for fast frame-by-frame processing. * <strong>html2pic:</strong> Converts HTML/CSS to images by translating markup into <code>pictex</code> render calls.</p> <p><strong>Target Audience</strong></p> <p>Developers working on video automation, content creation pipelines, or anyone needing to render text/HTML to images efficiently without the overhead of Selenium or Playwright. While they started as hobby projects, they are stable enough for use in automation scripts.</p> <p><strong>Comparison</strong></p> <ul> <li> <strong>pictex/html2pic vs. Selenium/Playwright:</strong> Unlike headless browsers, this stack does not require a browser engine. It renders directly using Skia, making it significantly faster and lighter on memory for generating images.</li> <li> <strong>movielite vs. MoviePy:</strong> MoviePy is excellent and feature-rich, but <code>movielite</code> focuses on performance using Numba JIT compilation and OpenCV.</li> <li> <strong>pycaps vs. Auto-subtitle tools:</strong> Most tools offer limited styling, <code>pycaps</code> allows CSS styling while maintaining a good performance.</li> </ul> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/_unknownProtocol\"> /u/_unknownProtocol </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1qm1kxu/how_i_went_down_a_massive_rabbit_hole_and_ended/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1qm1kxu/how_i_went_down_a_massive_rabbit_hole_and_ended/\">[comments]</a></span>",
      "author": "/u/_unknownProtocol",
      "published_date": "2026-01-24T22:50:51+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 877,
      "reading_time": 4,
      "created_at": "2026-01-24T23:21:03.344958+00:00",
      "updated_at": "2026-01-24T23:21:03.344960+00:00"
    },
    {
      "id": "24165d369db806bbc89ffe920086f0f1",
      "url": "https://mynorthwest.com/local/amazon-layoffs-14000-jobs-at-risk/4192118",
      "title": "Amazon braces for another major round of layoffs, 14,000 jobs at risk",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46748603\">Comments</a>",
      "author": "",
      "published_date": "2026-01-24T22:59:45+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-24T23:21:02.009238+00:00",
      "updated_at": "2026-01-24T23:21:02.009239+00:00"
    },
    {
      "id": "24165d369db806bbc89ffe920086f0f1",
      "url": "https://mynorthwest.com/local/amazon-layoffs-14000-jobs-at-risk/4192118",
      "title": "Amazon braces for another major round of layoffs, 14,000 jobs at risk",
      "content": "<p>Article URL: <a href=\"https://mynorthwest.com/local/amazon-layoffs-14000-jobs-at-risk/4192118\">https://mynorthwest.com/local/amazon-layoffs-14000-jobs-at-risk/4192118</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46748603\">https://news.ycombinator.com/item?id=46748603</a></p>\n<p>Points: 19</p>\n<p># Comments: 4</p>",
      "author": "niuzeta",
      "published_date": "2026-01-24T22:59:45+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2026-01-24T23:21:00.663380+00:00",
      "updated_at": "2026-01-24T23:21:00.663387+00:00"
    },
    {
      "id": "7895939116a617cfeb97b8721303d331",
      "url": "https://arstechnica.com/security/2026/01/wiper-malware-targeted-poland-energy-grid-but-failed-to-knock-out-electricity/",
      "title": "Poland's energy grid was targeted by never-before-seen wiper malware",
      "content": "<p>Article URL: <a href=\"https://arstechnica.com/security/2026/01/wiper-malware-targeted-poland-energy-grid-but-failed-to-knock-out-electricity/\">https://arstechnica.com/security/2026/01/wiper-malware-targeted-poland-energy-grid-but-failed-to-knock-out-electricity/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46747827\">https://news.ycombinator.com/item?id=46747827</a></p>\n<p>Points: 19</p>\n<p># Comments: 0</p>",
      "author": "Bender",
      "published_date": "2026-01-24T21:24:13+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2026-01-24T22:44:19.598335+00:00",
      "updated_at": "2026-01-24T22:44:19.598342+00:00"
    },
    {
      "id": "80d1f642eb4da0958753076107ac0cbe",
      "url": "http://daniellakens.blogspot.com/2025/07/easily-download-files-from-open-science.html",
      "title": "Easily download files from the Open Science Framework with Papercheck",
      "content": "<p>Researchers\nincreasingly use the <a href=\"https://osf.io/\">Open Science Framework</a> (OSF) to share files, such as data\nand code underlying scientific publications, or presentations and materials for\nscientific workshops. The OSF is an amazing service that has contributed\nimmensely to a changed research culture where psychologists share data, code, and\nmaterials. We are very grateful it exists.</p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">But it is\nnot always the most user-friendly. Specifically, downloading files from the OSF\nis a bigger hassle than we (<a href=\"https://debruine.github.io/\">Lisa DeBruine</a>\nand <a href=\"https://www.tue.nl/en/research/researchers/daniel-lakens/\">Daniel\nLakens</a>, the developers of Papercheck) would like it to be. Downloading individual\nfiles is so complex, <a href=\"https://bsky.app/profile/malte.the100.ci/post/3lpf4s6spns2i\">Malte Elson</a>\nrecently posted this meme on Bluesky. </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"NL\"><!--[if gte vml 1]><v:shapetype\n id=\"_x0000_t75\" coordsize=\"21600,21600\" o:spt=\"75\" o:preferrelative=\"t\"\n path=\"m@4@5l@4@11@9@11@9@5xe\" filled=\"f\" stroked=\"f\">\n <v:stroke joinstyle=\"miter\"/>\n <v:formulas>\n  <v:f eqn=\"if lineDrawn pixelLineWidth 0\"/>\n  <v:f eqn=\"sum @0 1 0\"/>\n  <v:f eqn=\"sum 0 0 @1\"/>\n  <v:f eqn=\"prod @2 1 2\"/>\n  <v:f eqn=\"prod @3 21600 pixelWidth\"/>\n  <v:f eqn=\"prod @3 21600 pixelHeight\"/>\n  <v:f eqn=\"sum @0 0 1\"/>\n  <v:f eqn=\"prod @6 1 2\"/>\n  <v:f eqn=\"prod @7 21600 pixelWidth\"/>\n  <v:f eqn=\"sum @8 21600 0\"/>\n  <v:f eqn=\"prod @7 21600 pixelHeight\"/>\n  <v:f eqn=\"sum @10 21600 0\"/>\n </v:formulas>\n <v:path o:extrusionok=\"f\" gradientshapeok=\"t\" o:connecttype=\"rect\"/>\n <o:lock v:ext=\"edit\" aspectratio=\"t\"/>\n</v:shapetype><v:shape id=\"_x0000_i1026\" type=\"#_x0000_t75\" style='width:453.75pt;\n height:276pt;visibility:visible;mso-wrap-style:square'>\n <v:imagedata src=\"file:///C:/Users/DLakens/AppData/Local/Temp/msohtmlclip1/01/clip_image001.jpg\"\n  o:title=\"\"/>\n</v:shape><![endif]--><!--[if !vml]--><img border=\"0\" height=\"368\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEinS5tFoL5qX14Z2OcgT1APMZLGlghAD3BfBhSnJ9pleVbJyRFUFLShqReS2j7SXGozmLMcVQkoM62UhneJDtH4yx3NRnXOkVZZi-Dm-OPwbGaidxr2raF9wzjx5fU92nfPpE3jmGfwZEwHS1WGSB4gUfRfV3XWjOC2-lCjOYR108h3fwORIHOnqxIX9m8\" width=\"605\" /><!--[endif]--></span><span lang=\"EN-US\"></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\"><span>&nbsp;</span></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">Not only is\nthe download button for files difficult to find, but downloading all files\nrelated to a project can be surprisingly effortful. It is possible to download\nall files in a zip folder that will be called \u2018osfstorage-archive.zip\u2019 when\ndownloaded. But as the OSF supports a nested folder structure, you might miss a\nfolder, and you will quickly end up with \u2018osfstorage-archive (1).zip\u2019, \u2018osfstorage-archive\n(2).zip\u2019, etc. Unzipping these archives creates a lot of files without the\norganized folder structure, in folders with meaningless names, making it\ndifficult to understand where files are. </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<h2 style=\"text-align: left;\"><b><span lang=\"EN-US\">The\nosf_file_download function in Papercheck </span></b></h2>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">We have added\na new function to our R package \u2018<a href=\"https://scienceverse.github.io/papercheck/\">Papercheck</a>\u2019 that will download all files and\nfolders in an OSF repository. It saves all files by recreating the folder\nstructure from the OSF in your download folder. Just install Papercheck, load\nthe library, and use the osf_file_download function to grab all files on the OSF:</span></p><p class=\"MsoNormal\"><span lang=\"EN-US\"><br /></span></p>\n\n<div style=\"text-align: left;\"><span style=\"font-family: courier;\"><b><span lang=\"EN-US\">devtools::install_github(\"scienceverse/papercheck\")<br /></span></b><b><span lang=\"EN-US\">library(papercheck)<br /></span></b><b><span lang=\"EN-US\">osf_file_download(\"6nt4v\")</span></b></span></div>\n\n\n\n\n\n<p class=\"MsoNormal\"><b><span lang=\"EN-US\">&nbsp;</span></b></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">All files\nwill be downloaded to your working directory. </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">Are you feeling\nFOMO for missing out on the <a href=\"https://www.kcl.ac.uk/events/open-research-summer-school-2025\">King Open\nResearch Summer School</a> that is going on these days, where <a href=\"https://research.tue.nl/en/persons/sajedeh-rasti\">Sajedeh Rasti</a> talked\nabout Preregistration, and <a href=\"https://research.tue.nl/en/persons/cristian-mesquida-caldentey\">Cristian\nMesquida</a> will give a workshop on using Papercheck? Well, at least it is\nvery easy to download all the files they have shared on the OSF and look at the\npresentations: </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\"><span style=\"font-family: courier;\">osf_file_download(\"b7es8\")</span></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">In the\noutput, we see that by default large files (more than 10mb) are omitted. <span><!--[if gte vml 1]><v:shape id=\"Picture_x0020_1\"\n o:spid=\"_x0000_i1025\" type=\"#_x0000_t75\" alt=\"A screenshot of a computer&#10;&#10;AI-generated content may be incorrect.\"\n style='width:453.75pt;height:292.5pt;visibility:visible;mso-wrap-style:square'>\n <v:imagedata src=\"file:///C:/Users/DLakens/AppData/Local/Temp/msohtmlclip1/01/clip_image003.png\"\n  o:title=\"A screenshot of a computer&#10;&#10;AI-generated content may be incorrect\"/>\n</v:shape><![endif]--><!--[if !vml]--><img alt=\"A screenshot of a computer\n\nAI-generated content may be incorrect.\" border=\"0\" height=\"390\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEj2jH76ywmEeLzL43u6gJl7GKR2lEGlhYS0LOXRPMMovOsJEVdXyamYCvmq96ez3p_GXHLoFz4JDyAKHlARK9pSy8QfzVa7yt1_uEg_H9IJfKgunnYWUwlROXABNcU6TvrA0_hx0KPZfj00b3Cb-Wn_7Bf3sFu9JApZoClcWoh_Vfl5bk1GQVZUH1tuGao\" width=\"605\" /><!--[endif]--></span></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">If you want\nto download all files, regardless of the size, then set the parameter to ignore\nthe maximum file size: </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\"><span style=\"font-family: courier;\">osf_file_download(\"b7es8\",\nmax_file_size = NULL)</span></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">Sometimes\nyou might want to download all files but ignore the file structure on the OSF,\nto just have all the files in one folder. Setting the parameter ignore_folder_structure\n= TRUE will give you all the files on the OSF in a single folder. By default, files will be downloaded into your working directory, but you can also specify\nwhere you want the files to be saved. </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\"><span style=\"font-family: courier;\">osf_file_download(\"6nt4v\",\nignore_folder_structure = TRUE, download_to = \"C:\\\\test_download\")</span></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">We hope\nthis function will make it easier for reviewers to access all supplementary\nfiles stored on the OSF during peer review, and for researchers who want to re-use\ndata, code, or materials shared on the OSF by downloading all the files they\nneed easily. Make sure to install the latest version of Papercheck (0.0.0.9050)\nto get access to this new function. Papercheck is still in active development,\nso report any bugs on <a href=\"https://github.com/scienceverse/papercheck\">GitHub</a>.</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>",
      "author": "noreply@blogger.com (Daniel Lakens)",
      "published_date": "2025-07-22T09:53:00+00:00",
      "source": "Twenty Percent Statistician",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 765,
      "reading_time": 3,
      "created_at": "2026-01-24T22:22:06.329461+00:00",
      "updated_at": "2026-01-24T22:22:06.329463+00:00"
    },
    {
      "id": "54057d6dc7bedcf4b83b2c29f3353136",
      "url": "https://www.metropolitanreview.org/p/the-writers-came-at-night",
      "title": "The Writers Came at Night",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46747777\">Comments</a>",
      "author": "",
      "published_date": "2026-01-24T21:19:35+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-24T22:21:06.155437+00:00",
      "updated_at": "2026-01-24T22:21:06.155439+00:00"
    },
    {
      "id": "54057d6dc7bedcf4b83b2c29f3353136",
      "url": "https://www.metropolitanreview.org/p/the-writers-came-at-night",
      "title": "The Writers Came at Night",
      "content": "<p>Article URL: <a href=\"https://www.metropolitanreview.org/p/the-writers-came-at-night\">https://www.metropolitanreview.org/p/the-writers-came-at-night</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46747777\">https://news.ycombinator.com/item?id=46747777</a></p>\n<p>Points: 10</p>\n<p># Comments: 0</p>",
      "author": "ctoth",
      "published_date": "2026-01-24T21:19:35+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2026-01-24T22:21:04.797087+00:00",
      "updated_at": "2026-01-24T22:21:04.797096+00:00"
    },
    {
      "id": "3d370217cb4a351bb54e7854066e15c3",
      "url": "https://erpinfo.org/blog/2024/2/4/optimal-filters",
      "title": "New Papers: Optimal Filter Settings for ERP Research",
      "content": "<p class=\"\">Zhang, G., Garrett, D. R., &amp; Luck, S. J. (in press). Optimal filters for ERP research I: A general approach for selecting filter settings. <em>Psychophysiology</em>. <a href=\"https://doi.org/10.1111/psyp.14531\"><span>https://doi.org/10.1111/psyp.14531</span></a> [<a href=\"https://www.researchgate.net/publication/377773270_Optimal_filters_for_ERP_research_I_A_general_approach_for_selecting_filter_settings\"><span>preprint</span></a>]</p><p class=\"\">Zhang, G., Garrett, D. R., &amp; Luck, S. J. (in press). Optimal filters for ERP research II: Recommended settings for seven common ERP components. <em>Psychophysiology</em>. <a href=\"https://doi.org/10.1111/psyp.14530\"><span>https://doi.org/10.1111/psyp.14530</span></a> [<a href=\"https://www.researchgate.net/publication/377766656_Optimal_filters_for_ERP_research_II_Recommended_settings_for_seven_common_ERP_components\"><span>preprint</span></a>]</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1490\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/d64086cc-e3b4-457d-89df-08d9b3f96439/Filter_Table.png?format=1000w\" width=\"2062\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">What filter settings should you apply to your ERP data? If your filters are too weak to attenuate the noise in your data, your effects may not be statistically significant. If your filters are too strong, they may create artifactual peaks that lead you to draw bogus conclusions.</p><p class=\"\">For years, I have been recommending a bandpass of 0.1\u201330 Hz for most cognitive and affective research in neurotypical young adults. In this kind of research, I have found that filtering from 0.1\u201330 Hz usually does a good job of minimizing noise while creating minimal waveform distortion. </p><p class=\"\">However, this recommendation was based on a combination of informal observations from many experimental paradigms and a careful examination of a couple paradigms, so it was a bit hand-wavy. In addition, the optimal filter settings will depend on the waveshape of the ERP effects and the nature of the noise in a given study, so I couldn\u2019t make any specific recommendations about other experimental paradigms and participant populations. Moreover, different filter settings may be optimal for different scoring methods (e.g., mean amplitude vs. peak amplitude vs. peak latency).</p><p class=\"\">Guanghui Zhang, David Garrett, and I spent the last year focusing on this issue. First we developed a general method that can be used to determine the optimal filter settings for a given dataset and scoring method (see <a href=\"https://doi.org/10.1111/psyp.14531\"><span>this paper</span></a>). Then we applied this method to the <a href=\"https://doi.org/10.1016/j.neuroimage.2020.117465\"><span>ERP CORE</span></a> data to determine the optimal filter settings for the N170, MMN, P3b, N400, N2pc, LRP, and ERN components in neurotypical young adults (see <a href=\"https://doi.org/10.1111/psyp.14530\"><span>this paper</span></a> and the table above).</p><p class=\"\">If you are doing research with these components (or similar components) in neurotypical young adults, you can simply use the filter settings that we identified. If you are using a very different paradigm or testing a very different subject population, you can apply our method to your own data to find the optimal settings. We added some new tools to <a href=\"https://github.com/ucdavis/erplab\"><span>ERPLAB Toolbox</span></a> to make this easier.</p><p class=\"\">One thing that we discovered was that our old recommendation of 0.1\u201330 Hz does a good job of avoiding filter artifacts but is overly conservative for some components. For example, we can raise the low end to 0.5 Hz when measuring N2pc and MMN amplitudes, which gets rid of more noise without producing problematic waveform distortions. And we can go all the way up to 0.9 Hz for the N170 component. However, later/slower components like P3b and N400 require lower cutoffs (no higher than 0.2 Hz).</p><p class=\"\">You might be wondering how we defined the \u201coptimal\u201d filter settings. At one level, the answer is simple: The optimal filter is the one that maximizes the signal-to-noise ratio without producing too much waveform distortion. The complexities arise in quantifying the signal-to-noise ratio, quantifying the waveform distortion, and deciding how much waveform distortion is \u201ctoo much\u201d. We believe we have found reasonably straightforward and practical solutions to these problems, which you can read about in the published papers.</p>",
      "author": "Steve Luck",
      "published_date": "2024-02-04T23:46:20+00:00",
      "source": "Erp Boot Camp",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 568,
      "reading_time": 2,
      "created_at": "2026-01-24T21:41:30.544020+00:00",
      "updated_at": "2026-01-24T22:15:47.015591+00:00",
      "metadata": {
        "processed_at": "2026-01-24T22:15:47.015600+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "b3cd4fc4257e4deef4e24f2c3cdd8b67",
      "url": "https://brain.ieee.org/publications/neuroethics-framework/education/education-social-and-cultural-issues/education-social-and-cultural-issues/",
      "title": "Education: Social and Cultural Issues",
      "content": "Devices that therapeutically aid users with cognitive and learning disabilities/differences should not be equally applied to a general population seeking learning advantages. It must not be assumed that therapies able to improve cognition for mental and cognitive disorders (such as executive control and working memory) would work similarly on nondisabled people linearly to improve their cognition above standard levels. Although ...",
      "author": "Adriel Carridice",
      "published_date": "2025-02-05T15:45:23+00:00",
      "source": "Brain",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 61,
      "reading_time": 1,
      "created_at": "2026-01-24T21:41:28.002326+00:00",
      "updated_at": "2026-01-24T22:15:47.015604+00:00",
      "metadata": {
        "processed_at": "2026-01-24T22:15:47.015606+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "1348eff8059203eea8f1cf0c47dfeafd",
      "url": "https://brain.ieee.org/podcasts/qa-with-dr-richard-carson-professor-of-biomedical-engineering-and-radiology-biomedical-imaging-yale-university-and-yale-school-of-medicine/",
      "title": "Q&A with Dr. Richard Carson, Professor of Biomedical Engineering and Radiology & Biomedical Imaging, Yale University and Yale School of Medicine",
      "content": "",
      "author": "Adriel Carridice",
      "published_date": "2025-11-04T18:24:59+00:00",
      "source": "Brain",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2026-01-24T21:41:28.002120+00:00",
      "updated_at": "2026-01-24T22:15:47.015609+00:00",
      "metadata": {
        "processed_at": "2026-01-24T22:15:47.015610+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "bad5757f306a00dd069fd23d649636a6",
      "url": "http://ieeexplore.ieee.org/document/10856219",
      "title": "IEEE Reviews in Biomedical Engineering (R-BME)",
      "content": "null",
      "author": "",
      "published_date": "2025-01-28T13:17:19+00:00",
      "source": "Reviews Biomedical Engineering",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 1,
      "reading_time": 1,
      "created_at": "2026-01-24T21:41:23.134703+00:00",
      "updated_at": "2026-01-24T22:15:47.015612+00:00",
      "metadata": {
        "processed_at": "2026-01-24T22:15:47.015614+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "b0ff9136da8fd557aa84d6fd9dd317d5",
      "url": "https://www.sciencedirect.com/science/article/pii/S0306452225012369?dgcid=rss_sd_all",
      "title": "Investigations on the effects of SH2B2 on Parkinson\u2019s disease based on its <em>in vivo</em> and <em>in vitro</em> neurotoxic model",
      "content": "<p>Publication date: 5 March 2026</p><p><b>Source:</b> Neuroscience, Volume 596</p><p>Author(s): Lihui Zhao, Ke Han, Lifeng Sun</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroscience Journal",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 14,
      "reading_time": 1,
      "created_at": "2026-01-24T21:41:12.639199+00:00",
      "updated_at": "2026-01-24T22:15:47.015619+00:00",
      "metadata": {
        "processed_at": "2026-01-24T22:15:47.015620+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "c03b847f5fac00dacfbc3f8912ce96ed",
      "url": "https://www.sciencedirect.com/science/article/pii/S0306452225012266?dgcid=rss_sd_all",
      "title": "Advances in how the peripheral immune system interacts with the brain in health and disease",
      "content": "<p>Publication date: 5 March 2026</p><p><b>Source:</b> Neuroscience, Volume 596</p><p>Author(s): Victor Manuel Ruiz-Rodr\u00edguez, Ares Orlando Cuellar-Santoyo, Ana Mar\u00eda Estrada-S\u00e1nchez</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroscience Journal",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 17,
      "reading_time": 1,
      "created_at": "2026-01-24T21:20:22.387656+00:00",
      "updated_at": "2026-01-24T21:20:22.387658+00:00"
    },
    {
      "id": "b7e4fdb3d226ba2874eddb3a8c00b216",
      "url": "https://www.reddit.com/r/Python/comments/1qlx02c/generate_openai_embeddings_locally_with_minilm/",
      "title": "Generate OpenAI Embeddings Locally with MiniLM ( 70x Cost Saving / Speed Improvement )",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>[This is my 2nd attempt at a post here; dear moderators, I am not an AI! ... at least I don't think I am ]</p> <p><strong>What My Project Does:</strong> <a href=\"https://medium.com/@ace0278/generate-openai-style-embeddings-locally-with-minilm-adapter-f43ec9c3b7da\">EmbeddingAdapters </a>is a Python library for translating between embedding model vector spaces.</p> <p>It provides plug-and-play adapters that map embeddings produced by one model into the vector space of another \u2014 locally or via provider APIs \u2014 enabling cross-model retrieval, routing, interoperability, and migration <strong>without re-embedding an existing corpus</strong>.</p> <p>If a vector index is already built using one embedding model, embedding-adapters allows it to be queried using another, without rebuilding the index.</p> <p><strong>Target Audience</strong>: Anyone who is a developer or startup, if you have a mobile app and you want to run ultra fast on-device RAG with provider level quality, use this. If you want to save money on embeddings over millions of queries, use this. If you want to sample embedding spaces you don't have access to - gemini mongo etc. - use this.</p> <p><strong>Comparison:</strong> There is no comparable library that specializes in this</p> <p><strong>Why I Made This:</strong> This solved a serious pain point for me, but I also realized that we could extend it greatly as a community. Each time a new model is added to the library, it permits a new connection\u2014you can effectively walk across different model spaces. Chain these adapters together and you can do some really interesting things.</p> <p>For example, you could go from OpenAI \u2192 MiniLM (you may not think you want to do that, but consider the cost savings of being able to interact with MiniLM embeddings as if they were OpenAI).</p> <p>I know this doesn\u2019t sound possible, but it is. The adapters reinterpret the semantic signals already present in these models. It won\u2019t work for every input text, but by pairing each adapter with a confidence score, you can effectively route between a provider and a local model. This cuts costs dramatically and significantly speeds up query embedding generation.</p> <p><strong>GitHub:</strong><br /> <a href=\"https://github.com/PotentiallyARobot/EmbeddingAdapters/\">https://github.com/PotentiallyARobot/EmbeddingAdapters/</a></p> <p><strong>PyPI:</strong><br /> <a href=\"https://pypi.org/project/embedding-adapters/\">https://pypi.org/project/embedding-adapters/</a></p> <h1>Example</h1> <p>Generate an OpenAI embedding locally from minilm+adapter:</p> <pre><code>pip install embedding-adapters embedding-adapters embed \\ --source sentence-transformers/all-MiniLM-L6-v2 \\ --target openai/text-embedding-3-small \\ --flavor large \\ --text &quot;where are restaurants with a hamburger near me&quot; </code></pre> <p>The command returns:</p> <ul> <li>an embedding in the target (OpenAI) space</li> <li>a confidence / quality score estimating adapter reliability</li> </ul> <h1>Model Input</h1> <p>At inference time, the adapter\u2019s <strong>only input is an embedding vector</strong> from a source model.<br /> No text, tokens, prompts, or provider embeddings are used.</p> <p>A pure <strong>vector \u2192 vector</strong> mapping is sufficient to recover most of the retrieval behavior of larger proprietary embedding models for in-domain queries.</p> <h1>Benchmark results</h1> <p><strong>Dataset:</strong> SQuAD (8,000 Q/A pairs)</p> <p><strong>Latency (answer embeddings):</strong></p> <ul> <li>MiniLM embed: <strong>1.08 s</strong></li> <li>Adapter transform: <strong>0.97 s</strong></li> <li>OpenAI API embed: <strong>40.29 s</strong></li> </ul> <p>\u2248 <strong>70\u00d7 faster</strong> for local MiniLM + adapter vs OpenAI API calls.</p> <p><strong>Retrieval quality (Recall@10):</strong></p> <ul> <li>MiniLM \u2192 MiniLM: <strong>10.32%</strong></li> <li>Adapter \u2192 Adapter: <strong>15.59%</strong></li> <li>Adapter \u2192 OpenAI: <strong>16.93%</strong></li> <li>OpenAI \u2192 OpenAI: <strong>18.26%</strong></li> </ul> <p>Bootstrap difference (OpenAI \u2212 Adapter \u2192 OpenAI): <strong>~1.34%</strong></p> <p>For in-domain queries, the MiniLM \u2192 OpenAI adapter recovers ~<strong>93%</strong> of OpenAI retrieval performance and substantially outperforms MiniLM-only baselines.</p> <h1>How it works (high level)</h1> <p>Each adapter is trained on a <strong>restricted domain</strong>, allowing it to specialize in interpreting the semantic signals of smaller models and projecting them into higher-dimensional provider spaces while preserving retrieval-relevant structure.</p> <p>A quality score is provided to determine whether an input is well-covered by the adapter\u2019s training distribution.</p> <h1>Practical uses in Python applications</h1> <ul> <li>Query an existing vector index built with one embedding model using another</li> <li>Operate mixed vector indexes and route queries to the most effective embedding space</li> <li>Reduce cost and latency by embedding locally for in-domain queries</li> <li>Evaluate embedding providers before committing to a full re-embed</li> <li>Gradually migrate between embedding models</li> <li>Handle provider outages or rate limits gracefully</li> <li>Run RAG pipelines in air-gapped or restricted environments</li> <li>Maintain a stable \u201ccanonical\u201d embedding space while changing edge models</li> </ul> <h1>Supported adapters</h1> <ul> <li>MiniLM \u2194 OpenAI</li> <li>OpenAI \u2194 Gemini</li> <li>E5 \u2194 MiniLM</li> <li>E5 \u2194 OpenAI</li> <li>E5 \u2194 Gemini</li> <li>MiniLM \u2194 Gemini</li> </ul> <p>The project is under active development, with ongoing work on additional adapter pairs, domain specialization, evaluation tooling, and training efficiency.</p> <p>Please Like/Upvote</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Interesting-Town-433\"> /u/Interesting-Town-433 </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1qlx02c/generate_openai_embeddings_locally_with_minilm/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1qlx02c/generate_openai_embeddings_locally_with_minilm/\">[comments]</a></span>",
      "author": "/u/Interesting-Town-433",
      "published_date": "2026-01-24T19:53:55+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 722,
      "reading_time": 3,
      "created_at": "2026-01-24T21:19:38.798652+00:00",
      "updated_at": "2026-01-24T21:19:38.798654+00:00"
    },
    {
      "id": "34057d2cf16cc6a248c6c8b4cce339df",
      "url": "https://www.ycombinator.com/companies/gym-class-by-irl-studios/jobs/ywXHGBv-design-engineer-senior-staff-principal",
      "title": "First Design Engineer Hire \u2013 Build Games at Gym Class (YC W22)",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46747625\">Comments</a>",
      "author": "",
      "published_date": "2026-01-24T21:01:02+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-24T21:19:37.463149+00:00",
      "updated_at": "2026-01-24T21:19:37.463150+00:00"
    },
    {
      "id": "1c7eab55c441d6f48946b3c764c12eb4",
      "url": "https://m24tom.com/bye-bye-gmail/show",
      "title": "Bye Bye Gmail",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46746946\">Comments</a>",
      "author": "",
      "published_date": "2026-01-24T19:44:52+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-24T21:19:37.463090+00:00",
      "updated_at": "2026-01-24T21:19:37.463091+00:00"
    },
    {
      "id": "9eebf62669c90dcbaa4e008159f45867",
      "url": "https://micahcantor.com/blog/bluesky-comment-section.html",
      "title": "I added a Bluesky comment section to my blog",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46747366\">Comments</a>",
      "author": "",
      "published_date": "2026-01-24T20:33:40+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-24T21:19:37.463047+00:00",
      "updated_at": "2026-01-24T21:19:37.463050+00:00"
    }
  ]
}