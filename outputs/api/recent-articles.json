{
  "last_updated": "2025-12-22T18:33:49.349935+00:00",
  "count": 20,
  "articles": [
    {
      "id": "ab36e344df973e259b9992fca04c6788",
      "url": "https://www.sciencedirect.com/science/article/pii/S0006899325006699?dgcid=rss_sd_all",
      "title": "Differential neural activity and connectivity patterns in rats with and without noise-induced tinnitus",
      "content": "<p>Publication date: 1 February 2026</p><p><b>Source:</b> Brain Research, Volume 1872</p><p>Author(s): Nian Li, Liqin Zhang, Xu Tian, Yang Zhao, Guodong Feng, Zhiqiang Gao</p>",
      "author": "",
      "published_date": null,
      "source": "Brain Research",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 21,
      "reading_time": 1,
      "created_at": "2025-12-22T18:33:23.634649+00:00",
      "updated_at": "2025-12-22T18:33:23.634650+00:00"
    },
    {
      "id": "c4ef8084a62bbb1ef2d181c6f3d3e71b",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.19.695358v1?rss=1",
      "title": "Synaptotagmin-7 is required for synchronous but not asynchronous facilitation of glutamate release at cortical boutons",
      "content": "Short-term synaptic plasticity and the kinetics of neurotransmitter release vary widely across synapses, but population measurements obscure the mechanisms that generate this diversity. While the Ca2+ sensor Synaptotagmin-7 (Syt7) has been implicated in facilitation, vesicle replenishment and asynchronous vesicle exocytosis, its precise contributions to these processes remain debated. We used quantal-resolution imaging to measure synchronous and asynchronous glutamate release at individual cortical boutons in wild type and Syt7-/- neurons. Stratifying boutons by release efficacy and applying failure-based analysis to isolate trials where the first action potential evoked no release allowed us to separate facilitation from vesicle depletion. Syt7 deletion selectively eliminated activity-dependent facilitation of synchronous release but left facilitation of asynchronous release intact, although its overall magnitude was reduced. We further show that synchronous and asynchronous events arise from functionally distinct vesicle populations. These findings demonstrate that activity-dependent facilitation of synchronous and asynchronous exocytosis are mechanistically separable, enabling synapses to independently tune distinct temporal components of neurotransmission.",
      "author": "Kotzadimitriou, D., Langley, H., McGowan, E., R.F. Mendonca, P., Tagliatti, E., Timofeeva, Y., Krishnakumar, S. S., Volynski, K. E.",
      "published_date": "2025-12-22T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 157,
      "reading_time": 1,
      "created_at": "2025-12-22T18:33:19.225012+00:00",
      "updated_at": "2025-12-22T18:33:19.225014+00:00"
    },
    {
      "id": "e7993309cb8f60624ffdb6f0ee255356",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.17.694878v1?rss=1",
      "title": "Human and generative AI integrate visual cues differently in a shape completion task",
      "content": "In amodal completion observers perceive complete objects despite partial occlusion. When two object parts are divided by an occluder, completion can result in perceiving one or two objects. This phenomenon involves both lower-level cues (e.g., symmetry, contour continuity) and higher-level cues (e.g., prior knowledge). Experiment 1 investigates how occluder size, familiarity, and symmetry affect human completions using a drawing task. Narrow occluders and asymmetry promote single-shape completions, while familiarity and (global) symmetry promote two-shape interpretations. Good continuation emerges as the strongest cue, with symmetry and familiarity playing increasingly important roles as occluder width increases. Experiment 2 compares human performance with three state-of-the-art generative AI models. Models often generated creative but non-compliant outputs, altering even unoccluded regions. We restricted analysis to instruction-following generations, identified through ratings by naive observers. Among compliant outputs, models showed some human-like biases (e.g., more two-shape completions for wide occluders), but failed with higher-level cues. They did not use symmetry to guide completions and showed reversed familiarity effects. Our findings highlight differences between human and AI completions. Humans integrate low- and high-level cues, whereas compliant outputs from the AI models rely primarily on low-level pattern continuation. Current AI models lack the flexible integration of multiple representational levels that characterize human perception. This work establishes an analytical framework for evaluating whether next-generation models achieve more human-like visual reasoning.",
      "author": "Adams, J., Serriere, L., Kothen, M. J., Smorczewskaa, M. B., Schmidt, F., Morgenstern, Y.",
      "published_date": "2025-12-22T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 220,
      "reading_time": 1,
      "created_at": "2025-12-22T18:33:19.224971+00:00",
      "updated_at": "2025-12-22T18:33:19.224976+00:00"
    },
    {
      "id": "fba845953773a23b490df3eca194bb41",
      "url": "https://www.reddit.com/r/Python/comments/1psxub1/servy_43_released_turn_any_python_app_into_a/",
      "title": "Servy 4.3 released, Turn any Python app into a native Windows service",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>It's been four months since the announcement of Servy, and Servy 4.3 is finally here.</p> <p>The community response has been amazing: 940+ stars on GitHub and 12,000+ downloads.</p> <p>If you haven't seen Servy before, it's a Windows tool that turns any Python app (or other executable) into a native Windows service. You just set the Python executable path, add your script and arguments, choose the startup type, working directory, and environment variables, configure any optional parameters, click install, and you're done. Servy comes with a desktop app, a CLI, PowerShell integration, and a manager app for monitoring services in real time.</p> <p>In this release (4.3), I've added/improved:</p> <ul> <li>Digitally signed all executables and installers with a trusted code-signing certificate provided by the SignPath Foundation for maximum trust and security</li> <li>Fixed multiple false-positive detections from AV engines (SecureAge, DeepInstinct, and others)</li> <li>Reduced executable and installer sizes as much as technically possible</li> <li>Added date-based log rotation for stdout/stderr and max rotations to limit the number of rotated log files to keep</li> <li>Added custom installation options for advanced users</li> <li>New GUI enhancements and improvements</li> <li>Detailed documentation</li> <li>Bug fixes</li> </ul> <p>Check it out on GitHub: <a href=\"https://github.com/aelassas/servy\">https://github.com/aelassas/servy</a></p> <p>Demo video here: <a href=\"https://www.youtube.com/watch?v=biHq17j4RbI\">https://www.youtube.com/watch?v=biHq17j4RbI</a></p> <p>Python sample: <a href=\"https://github.com/aelassas/servy/wiki/Examples-&amp;-Recipes#run-a-python-script-as-a-service\">Examples &amp; Recipes</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/AdUnhappy5308\"> /u/AdUnhappy5308 </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1psxub1/servy_43_released_turn_any_python_app_into_a/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1psxub1/servy_43_released_turn_any_python_app_into_a/\">[comments]</a></span>",
      "author": "/u/AdUnhappy5308",
      "published_date": "2025-12-22T11:59:24+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 225,
      "reading_time": 1,
      "created_at": "2025-12-22T18:32:38.845579+00:00",
      "updated_at": "2025-12-22T18:32:38.845581+00:00"
    },
    {
      "id": "2573c6bb8775f8ebf070912eecd9bb44",
      "url": "https://www.reddit.com/r/Python/comments/1psjsnu/aiologic_culsans_a_way_to_make_multithreaded/",
      "title": "aiologic & culsans: a way to make multithreaded asyncio safe",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>Hello to everyone reading this. In this post, while it is still 2025, I will tell you about two of my libraries that you probably do not know about - <a href=\"https://github.com/x42005e1f/aiologic\">aiologic</a> &amp; <a href=\"https://github.com/x42005e1f/culsans\">culsans</a>. The irony here is that even though they are both over a year old, I keep coming across discussions in which my solutions are considered non-existent (at least, they are not mentioned, and the problems discussed remain unsolved). That is why I wrote this post - to introduce you to my libraries and the tasks they are able to solve, in order to try once again to make them more recognizable.</p> <h1>What My Projects Do</h1> <p>Both libraries provide synchronization/communication primitives (such as locks, queues, capacity limiters) that are both async-aware and thread-aware/thread-safe, and can work in different environments within a single process. Whether it is regular threads, asyncio tasks, or even gevent greenlets. For example, with <code>aiologic.Lock</code>, you can synchronize access to a shared resource for different asyncio event loops running in different threads, without blocking the event loop (which may be relevant for free-threading):</p> <pre><code>#!/usr/bin/env python3 import asyncio from concurrent.futures import ThreadPoolExecutor from aiologic import Lock lock = Lock() THREADS = 4 TASKS = 4 TIME = 1.0 async def work() -&gt; None: async with lock: # some CPU-bound or IO-bound work await asyncio.sleep(TIME / (THREADS * TASKS)) async def main() -&gt; None: async with asyncio.TaskGroup() as tg: for _ in range(TASKS): tg.create_task(work()) if __name__ == &quot;__main__&quot;: with ThreadPoolExecutor(THREADS) as executor: for _ in range(THREADS): executor.submit(asyncio.run, main()) # program will end in &lt;TIME&gt; seconds </code></pre> <p>The same can be achieved using <code>aiologic.synchronized()</code>, a universal decorator that is an async-aware alternative to <a href=\"https://wrapt.readthedocs.io/en/master/examples.html#thread-synchronization\"><code>wrapt.synchronized()</code></a>, which will use <code>aiologic.RLock</code> (reentrant lock) under the hood by default:</p> <pre><code>#!/usr/bin/env python3 import asyncio from concurrent.futures import ThreadPoolExecutor from aiologic import synchronized THREADS = 4 TASKS = 4 TIME = 1.0 @synchronized async def work(*, recursive: bool = True) -&gt; None: if recursive: await work(recursive=False) else: # some CPU-bound or IO-bound work await asyncio.sleep(TIME / (THREADS * TASKS)) async def main() -&gt; None: async with asyncio.TaskGroup() as tg: for _ in range(TASKS): tg.create_task(work()) if __name__ == &quot;__main__&quot;: with ThreadPoolExecutor(THREADS) as executor: for _ in range(THREADS): executor.submit(asyncio.run, main()) # program will end in &lt;TIME&gt; seconds </code></pre> <p>Want to notify a task from another thread that an action has been completed? No problem, just use <code>aiologic.Event</code>:</p> <pre><code>#!/usr/bin/env python3 import asyncio from concurrent.futures import ThreadPoolExecutor from aiologic import Event TIME = 1.0 async def producer(event: Event) -&gt; None: # some CPU-bound or IO-bound work await asyncio.sleep(TIME) event.set() async def consumer(event: Event) -&gt; None: await event print(&quot;done!&quot;) if __name__ == &quot;__main__&quot;: with ThreadPoolExecutor(2) as executor: executor.submit(asyncio.run, producer(event := Event())) executor.submit(asyncio.run, consumer(event)) # program will end in &lt;TIME&gt; seconds </code></pre> <p>If you ensure that only one task will wait for the event and only once, you can also use low-level events as a more lightweight alternative for the same purpose (this may be convenient for creating your own future objects; note that they also have <code>cancelled()</code> method!):</p> <pre><code>#!/usr/bin/env python3 import asyncio from concurrent.futures import ThreadPoolExecutor from aiologic import Flag from aiologic.lowlevel import AsyncEvent, Event, create_async_event TIME = 1.0 async def producer(event: Event, holder: Flag[str]) -&gt; None: # some CPU-bound or IO-bound work await asyncio.sleep(TIME) holder.set(&quot;done!&quot;) event.set() async def consumer(event: AsyncEvent, holder: Flag[str]) -&gt; None: await event print(&quot;result:&quot;, repr(holder.get())) if __name__ == &quot;__main__&quot;: with ThreadPoolExecutor(2) as executor: executor.submit(asyncio.run, producer( event := create_async_event(), holder := Flag[str](), )) executor.submit(asyncio.run, consumer(event, holder)) # program will end in &lt;TIME&gt; seconds </code></pre> <p>What about communication between tasks? Well, you can use <code>aiologic.SimpleQueue</code> as the fastest blocking queue in simple cases:</p> <pre><code>#!/usr/bin/env python3 import asyncio from concurrent.futures import ThreadPoolExecutor from aiologic import SimpleQueue ITERATIONS = 100 TIME = 1.0 async def producer(queue: SimpleQueue[int]) -&gt; None: for i in range(ITERATIONS): # some CPU-bound or IO-bound work await asyncio.sleep(TIME / ITERATIONS) queue.put(i) async def consumer(queue: SimpleQueue[int]) -&gt; None: for i in range(ITERATIONS): value = await queue.async_get() assert value == i print(&quot;done!&quot;) if __name__ == &quot;__main__&quot;: with ThreadPoolExecutor(2) as executor: executor.submit(asyncio.run, producer(queue := SimpleQueue[int]())) executor.submit(asyncio.run, consumer(queue)) # program will end in &lt;TIME&gt; seconds </code></pre> <p>And if you need some additional features and/or compatibility with the standard queues, then <code>culsans.Queue</code> is here to help:</p> <pre><code>#!/usr/bin/env python3 import asyncio from concurrent.futures import ThreadPoolExecutor from culsans import AsyncQueue, Queue ITERATIONS = 100 TIME = 1.0 async def producer(queue: AsyncQueue[int]) -&gt; None: for i in range(ITERATIONS): # some CPU-bound or IO-bound work await asyncio.sleep(TIME / ITERATIONS) await queue.put(i) await queue.join() print(&quot;done!&quot;) async def consumer(queue: AsyncQueue[int]) -&gt; None: for i in range(ITERATIONS): value = await queue.get() assert value == i queue.task_done() if __name__ == &quot;__main__&quot;: with ThreadPoolExecutor(2) as executor: executor.submit(asyncio.run, producer(queue := Queue[int]().async_q)) executor.submit(asyncio.run, consumer(queue)) # program will end in &lt;TIME&gt; seconds </code></pre> <p>It may seem that aiologic &amp; culsans only work with asyncio. In fact, they also support Curio, Trio, AnyIO, and also greenlet-based eventlet and gevent libraries, and you can also interact not only with tasks, but also with native threads:</p> <pre><code>#!/usr/bin/env python3 import time import gevent from aiologic import CapacityLimiter CONCURRENCY = 2 THREADS = 8 TASKS = 8 TIME = 1.0 limiter = CapacityLimiter(CONCURRENCY) def sync_work() -&gt; None: with limiter: # some CPU-bound work time.sleep(TIME * CONCURRENCY / (THREADS + TASKS)) def green_work() -&gt; None: with limiter: # some IO-bound work gevent.sleep(TIME * CONCURRENCY / (THREADS + TASKS)) if __name__ == &quot;__main__&quot;: threadpool = gevent.get_hub().threadpool gevent.joinall([ *(threadpool.spawn(sync_work) for _ in range(THREADS)), *(gevent.spawn(green_work) for _ in range(TASKS)), ]) # program will end in &lt;TIME&gt; seconds </code></pre> <p>Within a single thread with different libraries as well:</p> <pre><code>#!/usr/bin/env python3 import trio import trio_asyncio from aiologic import Condition TIME = 1.0 async def producer(cond: Condition) -&gt; None: # Trio-flavored async with cond: # some IO-bound work await trio.sleep(TIME) if not cond.waiting: await cond cond.notify() @trio_asyncio.aio_as_trio async def consumer(cond: Condition) -&gt; None: # asyncio-flavored async with cond: if cond.waiting: cond.notify() await cond print(&quot;done!&quot;) async def main() -&gt; None: async with trio.open_nursery() as nursery: nursery.start_soon(producer, cond := Condition()) nursery.start_soon(consumer, cond) if __name__ == &quot;__main__&quot;: trio_asyncio.run(main) # program will end in &lt;TIME&gt; seconds </code></pre> <p>And, even more uniquely, some aiologic primitives also work from inside signal handlers and destructors:</p> <pre><code>#!/usr/bin/env python3 import time import weakref import curio from aiologic import CountdownEvent, Flag from aiologic.lowlevel import enable_signal_safety TIME = 1.0 async def main() -&gt; None: event = CountdownEvent(2) flag1 = Flag() flag2 = Flag() await curio.spawn_thread(lambda flag: time.sleep(TIME / 2), flag1) await curio.spawn_thread(lambda flag: time.sleep(TIME), flag2) weakref.finalize(flag1, enable_signal_safety(event.down)) weakref.finalize(flag2, enable_signal_safety(event.down)) del flag1 del flag2 assert not event await event print(&quot;done!&quot;) if __name__ == &quot;__main__&quot;: curio.run(main) # program will end in &lt;TIME&gt; seconds </code></pre> <p>If that is not enough for you, I suggest you try the primitives yourself in the use cases that interest you. Maybe you will even find a use for them that I have not seen myself. And of course, these are far from all the declared features, and the documentation describes much more. However, the latter is still under development...</p> <h1>Performance</h1> <p>Quite a lot of focus (perhaps even too much) has been placed on performance. After all, no matter how impressive the capabilities of general solutions may be, if they cannot compete with more specialized solutions, you will subconsciously avoid using the former whenever possible. Therefore, both libraries have a number of relevant features.</p> <p>First, all unused primitives consume significantly less memory, just like asyncio primitives (remember, my primitives are also thread-aware). As an example, this has the following interesting effect: all queues consume significantly less memory than standard ones (even compared to asyncio queues). Here are <a href=\"https://github.com/microsoft/agent-lightning/issues/372#issuecomment-3615552472\">some old measurements</a> (to make them more actual, add about half a kilobyte to <code>aiologic.Queue</code> and <code>aiologic.SimpleQueue</code>):</p> <pre><code>&gt;&gt;&gt; sizeof(collections.deque) 760 &gt;&gt;&gt; sizeof(queue.SimpleQueue) 72 # see https://github.com/python/cpython/issues/140025 &gt;&gt;&gt; sizeof(queue.Queue) 3730 &gt;&gt;&gt; sizeof(asyncio.Queue) 3346 &gt;&gt;&gt; sizeof(janus.Queue) 7765 &gt;&gt;&gt; sizeof(culsans.Queue) 2152 &gt;&gt;&gt; sizeof(aiologic.Queue) 680 &gt;&gt;&gt; sizeof(aiologic.SimpleQueue) 448 &gt;&gt;&gt; sizeof(aiologic.SimpleLifoQueue) 376 &gt;&gt;&gt; sizeof(aiologic.lowlevel.lazydeque) 128 </code></pre> <p>This is true not only for unused queues, but also for partially used ones. For example, queues whose length has not yet reached maxsize will consume less memory, since the wait queue for put operations will not yet be in demand.</p> <p>Second, all aiologic primitives rely on effectively atomic operations (operations that cannot be interrupted due to the GIL and for which free-threading uses per-object locks). This makes almost all aiologic primitives faster than threading and queue primitives on PyPy, as shown in the example with semaphores:</p> <pre><code>threads = 1, value = 1: aiologic.Semaphore: 943246964 ops 100.00% fairness threading.Semaphore: 8507624 ops 100.00% fairness 110.9x speedup! threads = 2, value = 1: aiologic.Semaphore: 581026516 ops 99.99% fairness threading.Semaphore: 7664169 ops 99.87% fairness 75.8x speedup! threads = 3, value = 2: aiologic.Semaphore: 522027692 ops 99.97% fairness threading.Semaphore: 15161 ops 84.71% fairness 34431.2x speedup! threads = 5, value = 3: aiologic.Semaphore: 518826453 ops 99.89% fairness threading.Semaphore: 9075 ops 71.92% fairness 57173.9x speedup! ... threads = 233, value = 144: aiologic.Semaphore: 521016536 ops 99.24% fairness threading.Semaphore: 4872 ops 63.53% fairness 106944.9x speedup! threads = 377, value = 233: aiologic.Semaphore: 522805870 ops 99.04% fairness threading.Semaphore: 3567 ops 80.30% fairness 146564.5x speedup! ... </code></pre> <p>The benchmark is <a href=\"https://gist.github.com/x42005e1f/149d3994d5f7bd878def71d5404e6ea4\">publicly available</a>, and you can run your own measurements on your hardware with the interpreter you are interested in (for example, in free-threading you will also see a difference in favor of aiologic). So if you do not believe it, try it yourself.</p> <p><em>(Note: on a large number of threads, each pass will take longer due to the square problem mentioned in the next paragraph; perhaps the benchmark should be improved at some point...)</em></p> <p>Third, there are a number of details regarding timeouts, fairness, and the square problem. For these, I recommend reading the &quot;Performance&quot; section of the aiologic documentation.</p> <h1>Comparison</h1> <p>Strictly speaking, there are no real alternatives. But here is a comparison with some similar ones:</p> <ul> <li><a href=\"https://github.com/aio-libs/janus\">Janus</a> - provides only queues, supports only asyncio and regular threads, only one event loop, creates new tasks for non-blocking calls. The project is rarely maintained.</li> <li><a href=\"https://github.com/dabeaz/curio\">Curio</a>'s universal synchronization - provides only queues and events, supports only asyncio, Curio, and regular threads, uses the same methods for different environments, but has issues. The project was officially abandoned on December 21, 2025.</li> <li><a href=\"https://github.com/gleero/python-threadsafe-async\">python-threadsafe-async</a> - provides only events and channels, supports only asyncio and threads, uses not the most successful design solutions. The project has been inactive since March 2024.</li> <li><a href=\"https://github.com/dano/aioprocessing\">aioprocessing</a> - provides many primitives, but only supports asyncio, and due to multiprocessing support, it has far from the best performance and some limitations (for example, queues serialize all items and suffer from <a href=\"https://github.com/orgs/python/projects/14/views/1?filterQuery=queue\"><code>multiprocessing.Queue</code> issues</a>). The project has been inactive since September 2022.</li> </ul> <p>You can learn a little more in the &quot;Why?&quot; section of the aiologic documentation.</p> <h1>Target Audience</h1> <p>Python developers, of course. But there are some nuances:</p> <ol> <li>Development status - alpha. The API is still being refined, so incompatible changes are possible. If you do not rely exclusively on high-level interfaces (available from the top-level package), it may be good practice to pin the dependent version to the current and next minor aka major release (non-deprecated + deprecated but not removed).</li> <li>Documentation is still under development (in particular, aiologic currently has placeholders in many docstrings). At the same time, if you use any AI tools, they will most likely not understand the library well due to its exotic nature (a good example of this is DeepWiki). If you need a reliable information source here and now, you should take a look at GitHub Discussions (or alternative communication channels).</li> <li>Since I am (and will likely remain) the sole developer and maintainer, there is a very serious bus factor. Therefore, since the latest versions, I have been trying to enrich the source code with detailed comments so that the libraries can at least be maintained in a viable state in forks, but there is still a lot of work to be done in this area.</li> </ol> <p>I rely on theoretical analysis of my solutions and proactive bug fixing, so all provided functionality should be reliable and work as expected (even with weak test coverage). The libraries are already in use, so I think they are suitable for production.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/x42005e1f\"> /u/x42005e1f </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1psjsnu/aiologic_culsans_a_way_to_make_multithreaded/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1psjsnu/aiologic_culsans_a_way_to_make_multithreaded/\">[comments]</a></span>",
      "author": "/u/x42005e1f",
      "published_date": "2025-12-21T23:05:34+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2031,
      "reading_time": 10,
      "created_at": "2025-12-22T18:32:38.845543+00:00",
      "updated_at": "2025-12-22T18:32:38.845545+00:00"
    },
    {
      "id": "fc7fb65f0cdff810f5fc52d7ceeb2985",
      "url": "https://www.reddit.com/r/Python/comments/1psv340/spikard_v050_released/",
      "title": "Spikard v0.5.0 Released",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>Hi peeps,</p> <p>I'm glad to announce that <a href=\"https://github.com/Goldziher/spikard\">Spikard</a> v0.5.0 has been released. This is the first version I consider fully functional across all supported languages.</p> <h2>What is Spikard?</h2> <p>Spikard is a <em>polyglot web toolkit</em> written in Rust and available for multiple languages:</p> <ul> <li>Rust</li> <li>Python (3.10+)</li> <li>TypeScript (Node/Bun)</li> <li>TypeScript (WASM - Deno/Edge)</li> <li>PHP (8.2+)</li> <li>Ruby (3.4+)</li> </ul> <h2>Why Spikard?</h2> <p>I had a few reasons for building this:</p> <p>I am the original author of <a href=\"https://litestar.dev/\">Litestar</a> (no longer involved after v2), and I have a thing for web frameworks. Following the work done by <a href=\"https://github.com/sparckles/Robyn\">Robyn</a> to create a Python framework with a Rust runtime (Actix in their case), I always wanted to experiment with that idea.</p> <p>I am also the author of <a href=\"https://github.com/Goldziher/html-to-markdown\">html-to-markdown</a>. When I rewrote it in Rust, I created bindings for multiple languages from a single codebase. That opened the door to a genuinely polyglot web stack.</p> <p>Finally, there is the actual pain point. I work in multiple languages across different client projects. In Python I use Litestar, Sanic, FastAPI, Django, Flask, etc. In TypeScript I use Express, Fastify, and NestJS. In Go I use Gin, Fiber, and Echo. Each framework has pros and cons (and some are mostly cons). It would be better to have one standard toolkit that is correct (standards/IETF-aligned), robust, and fast across languages.</p> <p>That is what Spikard aims to be.</p> <h2>Why &quot;Toolkit&quot;?</h2> <p>The end goal is a toolkit, not just an HTTP framework. Today, Spikard exposes an HTTP framework built on <a href=\"https://github.com/tokio-rs/axum\">axum</a> and the Tokio + Tower ecosystems in Rust, which provides:</p> <ol> <li>An extremely high-performance core that is robust and battle-tested</li> <li>A wide and deep ecosystem of extensions and middleware</li> </ol> <p>This currently covers HTTP use cases (REST, JSON-RPC, WebSockets) plus OpenAPI, AsyncAPI, and OpenRPC code generation.</p> <p>The next step is to cover queues and task managers (RabbitMQ, Kafka, NATS) and CloudEvents interoperability, aiming for a full toolkit. A key inspiration here is <a href=\"https://watermill.io/\">Watermill</a> in Go.</p> <h2>Current Features and Capabilities</h2> <ul> <li>REST with typed routing (e.g. <code>/users/{id:uuid}</code>)</li> <li>JSON-RPC 2.0 over HTTP and WebSocket</li> <li>HTTP/1.1 and HTTP/2</li> <li>Streaming responses, SSE, and WebSockets</li> <li>Multipart file uploads, URL-encoded and JSON bodies</li> <li>Tower-HTTP middleware stack (compression, rate limiting, timeouts, request IDs, CORS, auth, static files)</li> <li>JSON Schema validation (Draft 2020-12) with structured error payloads (RFC 9457)</li> <li>Lifecycle hooks (<code>onRequest</code>, <code>preValidation</code>, <code>preHandler</code>, <code>onResponse</code>, <code>onError</code>)</li> <li>Dependency injection across bindings</li> <li>Codegen: OpenAPI 3.1, AsyncAPI 2.x/3.x, OpenRPC 1.3.2</li> <li>Fixture-driven E2E tests across all bindings (400+ scenarios)</li> <li>Benchmark + profiling harness in CI</li> </ul> <p>Language-specific validation integrations:</p> <ul> <li>Python: msgspec (required), with optional detection of Pydantic v2, attrs, dataclasses</li> <li>TypeScript: Zod</li> <li>Ruby: dry-schema / dry-struct detection when present</li> <li>PHP: native validation with PSR-7 interfaces</li> <li>Rust: serde + schemars</li> </ul> <h2>Roadmap to v1.0.0</h2> <p><strong>Core:</strong> - Protobuf + protoc integration - GraphQL (queries, mutations, subscriptions) - Plugin/extension system</p> <p><strong>DX:</strong> - MCP server and AI tooling integration - Expanded documentation site and example apps</p> <p><strong>Post-1.0 targets:</strong> - HTTP/3 (QUIC) - CloudEvents support - Queue protocols (AMQP, Kafka, etc.)</p> <h2>Benchmarks</h2> <p>We run continuous benchmarks + profiling in CI. Everything is measured on GitHub-hosted machines across multiple iterations and normalized for relative comparison.</p> <p>Latest comparative run (2025-12-20, Linux x86_64, AMD EPYC 7763 2c/4t, 50 concurrency, 10s, oha):</p> <ul> <li>spikard-rust: 55,755 avg RPS (1.00 ms avg latency)</li> <li>spikard-node: 24,283 avg RPS (2.22 ms avg latency)</li> <li>spikard-php: 20,176 avg RPS (2.66 ms avg latency)</li> <li>spikard-python: 11,902 avg RPS (4.41 ms avg latency)</li> <li>spikard-wasm: 10,658 avg RPS (5.70 ms avg latency)</li> <li>spikard-ruby: 8,271 avg RPS (6.50 ms avg latency)</li> </ul> <p>Full artifacts for that run are committed under <code>snapshots/benchmarks/20397054933</code> in the repo.</p> <h2>Development Methodology</h2> <p>Spikard is, for the most part, &quot;vibe coded.&quot; I am saying that openly. The tools used are Codex (OpenAI) and Claude Code (Anthropic). How do I keep quality high? By following an outside-in approach inspired by TDD.</p> <p>The first major asset added was an extensive set of fixtures (JSON files that follow a schema I defined). These cover the range of HTTP framework behavior and were derived by inspecting the test suites of multiple frameworks and relevant IETF specs.</p> <p>Then I built an E2E test generator that uses the fixtures to generate suites for each binding. That is the TDD layer.</p> <p>On top of that, I follow BDD in the literal sense: Benchmark-Driven Development. There is a profiling + benchmarking harness that tracks regressions and guides optimization.</p> <p>With those in place, the code evolved via ADRs (Architecture Decision Records) in <code>docs/adr</code>. The Rust core came first; bindings were added one by one as E2E tests passed. Features were layered on top of that foundation.</p> <h2>Getting Involved</h2> <p>If you want to get involved, there are a few ways:</p> <ol> <li>Join the <a href=\"https://discord.gg/wb8SEWvM\">Kreuzberg Discord</a></li> <li>Use Spikard and report issues, feature requests, or API feedback</li> <li>Help spread the word (always helpful)</li> <li>Contribute: refactors, improvements, tests, docs</li> </ol> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Goldziher\"> /u/Goldziher </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1psv340/spikard_v050_released/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1psv340/spikard_v050_released/\">[comments]</a></span>",
      "author": "/u/Goldziher",
      "published_date": "2025-12-22T09:08:10+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 825,
      "reading_time": 4,
      "created_at": "2025-12-22T18:32:38.845346+00:00",
      "updated_at": "2025-12-22T18:32:38.845348+00:00"
    },
    {
      "id": "0589d91a521505e1d79734512e366d9f",
      "url": "https://www.reddit.com/r/Python/comments/1psekfi/stinkiest_code_youve_ever_written/",
      "title": "Stinkiest code you've ever written?",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>Hi, I was going through my github just for fun looking at like OLD projects of mine and I found this absolute gem from when I started and didn't know what a Class was. </p> <p>essentially I was trying to build a clicker game using FreeSimpleGUI (why????) and I needed to display various things on the windows/handle clicks etc etc and found this absolute unit. A 400 line create_main_window() function with like 5 other nested sub functions that handle events on the other windows \ud83d\ude2d\ud83d\ude2d </p> <p>Anyone else have any examples of complete buffoonery from lack of experience? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Sad-Sun4611\"> /u/Sad-Sun4611 </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1psekfi/stinkiest_code_youve_ever_written/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1psekfi/stinkiest_code_youve_ever_written/\">[comments]</a></span>",
      "author": "/u/Sad-Sun4611",
      "published_date": "2025-12-21T19:18:21+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 120,
      "reading_time": 1,
      "created_at": "2025-12-22T18:32:38.845240+00:00",
      "updated_at": "2025-12-22T18:32:38.845242+00:00"
    },
    {
      "id": "ca3da8d7f2e15090e30aa412ab8650ed",
      "url": "https://www.reddit.com/r/Python/comments/1pswh1o/pyreqwest_an_extremely_fast_gilfree_featurerich/",
      "title": "pyreqwest: An extremely fast, GIL-free, feature-rich HTTP client for Python, fully written in Rust",
      "content": "<!-- SC_OFF --><div class=\"md\"><p><strong>What My Project Does</strong></p> <p>I am sharing <a href=\"https://github.com/MarkusSintonen/pyreqwest\">pyreqwest</a>, a high-performance HTTP client for Python based on the robust Rust <code>reqwest</code> crate.</p> <p>I built this because I wanted the fluent, extensible interface design of <code>reqwest</code> available in Python, but with the performance benefits of a compiled language. It is designed to be a &quot;batteries-included&quot; solution that doesn't compromise on speed or developer ergonomics.</p> <p><strong>Key Features:</strong></p> <ul> <li><strong>Performance:</strong> It allows for Python free-threading (GIL-free) and includes automatic zstd/gzip/brotli/deflate decompression.</li> <li><strong>Dual Interface:</strong> Provides both Asynchronous and Synchronous clients with nearly identical interfaces.</li> <li><strong>Modern Python:</strong> Fully type-safe with complete type hints.</li> <li><strong>Safety:</strong> Full test coverage, no <code>unsafe</code> Rust code, and zero Python-side dependencies.</li> <li><strong>Customization:</strong> Highly customizable via middleware and custom JSON serializers.</li> <li><strong>Testing:</strong> Built-in mocking utilities and support for connecting directly to ASGI apps.</li> </ul> <p><strong>All standard HTTP features are supported:</strong></p> <ul> <li>HTTP/1.1 and HTTP/2</li> <li>TLS/HTTPS via <code>rustls</code></li> <li>Connection pooling, streaming, and multipart forms</li> <li>Cookie management, proxies, redirects, and timeouts</li> <li>Automatic charset detection and decoding</li> </ul> <p><strong>Target Audience</strong></p> <ul> <li>Developers working in high-concurrency scenarios who need maximum throughput and low latency.</li> <li>Teams looking for a single, type-safe library that handles both sync and async use cases.</li> <li>Rust developers working in Python who miss the ergonomics of <code>reqwest</code>.</li> </ul> <p><strong>Comparison</strong></p> <p>I have benchmarked <code>pyreqwest</code> against the most popular Python HTTP clients. You can view the full benchmarks <a href=\"https://github.com/MarkusSintonen/pyreqwest/blob/main/docs/benchmarks.md\">here</a>.</p> <ul> <li><strong>vs Httpx:</strong> While <code>httpx</code> is the standard for modern async Python, <code>pyreqwest</code> aims to solve performance bottlenecks inherent in pure-Python implementations (specifically regarding connection pooling and request handling issues <code>httpx</code>/<code>httpcore</code> have) while offering similarly modern API.</li> <li><strong>vs Aiohttp:</strong> <code>pyreqwest</code> supports HTTP/2 out of the box (which <code>aiohttp</code> lacks) and provides a synchronous client variant, making it more versatile for different contexts.</li> <li><strong>vs Urllib3:</strong> <code>pyreqwest</code> offers a modern async interface and better developer ergonomics with fully typed interfaces</li> </ul> <p><a href=\"https://github.com/MarkusSintonen/pyreqwest\">https://github.com/MarkusSintonen/pyreqwest</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/pyreqwest\"> /u/pyreqwest </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1pswh1o/pyreqwest_an_extremely_fast_gilfree_featurerich/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1pswh1o/pyreqwest_an_extremely_fast_gilfree_featurerich/\">[comments]</a></span>",
      "author": "/u/pyreqwest",
      "published_date": "2025-12-22T10:36:53+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 327,
      "reading_time": 1,
      "created_at": "2025-12-22T18:32:38.845199+00:00",
      "updated_at": "2025-12-22T18:32:38.845204+00:00"
    },
    {
      "id": "eae20f60fe657ea26e568d74172aa281",
      "url": "https://hengefinder.rcdis.co/#learn",
      "title": "Henge Finder",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46356320\">Comments</a>",
      "author": "",
      "published_date": "2025-12-22T17:32:18+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-22T18:32:37.499233+00:00",
      "updated_at": "2025-12-22T18:32:37.499235+00:00"
    },
    {
      "id": "71e4f0e65c91b155d7afc38956047f89",
      "url": "https://www.forbes.com/sites/thomasbrewster/2025/12/16/ai-bathroom-monitors-welcome-to-americas-new-surveillance-high-schools/",
      "title": "AI Bathroom Monitors? Welcome to America's New Surveillance High Schools",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46356603\">Comments</a>",
      "author": "",
      "published_date": "2025-12-22T17:53:46+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-22T18:32:37.499214+00:00",
      "updated_at": "2025-12-22T18:32:37.499216+00:00"
    },
    {
      "id": "f6d9c0ccc70a8ff2be244ec69b2c4292",
      "url": "https://github.com/anthropics/claude-code/blob/main/CHANGELOG.md",
      "title": "Claude Code gets native LSP support",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46355165\">Comments</a>",
      "author": "",
      "published_date": "2025-12-22T15:59:01+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-22T18:32:37.499135+00:00",
      "updated_at": "2025-12-22T18:32:37.499137+00:00"
    },
    {
      "id": "f6d9c0ccc70a8ff2be244ec69b2c4292",
      "url": "https://github.com/anthropics/claude-code/blob/main/CHANGELOG.md",
      "title": "Claude Code gets native LSP support",
      "content": "<p>Article URL: <a href=\"https://github.com/anthropics/claude-code/blob/main/CHANGELOG.md\">https://github.com/anthropics/claude-code/blob/main/CHANGELOG.md</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46355165\">https://news.ycombinator.com/item?id=46355165</a></p>\n<p>Points: 37</p>\n<p># Comments: 10</p>",
      "author": "JamesSwift",
      "published_date": "2025-12-22T15:59:01+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-22T18:32:36.383020+00:00",
      "updated_at": "2025-12-22T18:32:36.383022+00:00"
    },
    {
      "id": "53e654afcf14c05ce4429154cc5e5ba1",
      "url": "https://skilldeliver.com/your-supabase-is-public",
      "title": "Your Supabase Is Public",
      "content": "<p>Article URL: <a href=\"https://skilldeliver.com/your-supabase-is-public\">https://skilldeliver.com/your-supabase-is-public</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46355345\">https://news.ycombinator.com/item?id=46355345</a></p>\n<p>Points: 7</p>\n<p># Comments: 1</p>",
      "author": "skilldeliver",
      "published_date": "2025-12-22T16:14:43+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-22T18:32:36.382991+00:00",
      "updated_at": "2025-12-22T18:32:36.382993+00:00"
    },
    {
      "id": "2ff7b7ee4f0a9b660f81140a190f6c99",
      "url": "https://apnews.com/article/white-house-website-youtube-livestream-88d79b896ca6e5ecea33f3bf3e5c9278",
      "title": "Mystery as YouTube creator's finance livestream appears on White House website",
      "content": "<p>Article URL: <a href=\"https://apnews.com/article/white-house-website-youtube-livestream-88d79b896ca6e5ecea33f3bf3e5c9278\">https://apnews.com/article/white-house-website-youtube-livestream-88d79b896ca6e5ecea33f3bf3e5c9278</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46355879\">https://news.ycombinator.com/item?id=46355879</a></p>\n<p>Points: 10</p>\n<p># Comments: 2</p>",
      "author": "randycupertino",
      "published_date": "2025-12-22T16:55:43+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-22T18:32:36.382972+00:00",
      "updated_at": "2025-12-22T18:32:36.382974+00:00"
    },
    {
      "id": "eae20f60fe657ea26e568d74172aa281",
      "url": "https://hengefinder.rcdis.co/#learn",
      "title": "Henge Finder",
      "content": "<p>Article URL: <a href=\"https://hengefinder.rcdis.co/#learn\">https://hengefinder.rcdis.co/#learn</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46356320\">https://news.ycombinator.com/item?id=46356320</a></p>\n<p>Points: 9</p>\n<p># Comments: 0</p>",
      "author": "recursecenter",
      "published_date": "2025-12-22T17:32:18+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-22T18:32:36.382894+00:00",
      "updated_at": "2025-12-22T18:32:36.382896+00:00"
    },
    {
      "id": "71e4f0e65c91b155d7afc38956047f89",
      "url": "https://www.forbes.com/sites/thomasbrewster/2025/12/16/ai-bathroom-monitors-welcome-to-americas-new-surveillance-high-schools/",
      "title": "AI Bathroom Monitors? Welcome to America's New Surveillance High Schools",
      "content": "<p>Article URL: <a href=\"https://www.forbes.com/sites/thomasbrewster/2025/12/16/ai-bathroom-monitors-welcome-to-americas-new-surveillance-high-schools/\">https://www.forbes.com/sites/thomasbrewster/2025/12/16/ai-bathroom-monitors-welcome-to-americas-new-surveillance-high-schools/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46356603\">https://news.ycombinator.com/item?id=46356603</a></p>\n<p>Points: 27</p>\n<p># Comments: 6</p>",
      "author": "pseudolus",
      "published_date": "2025-12-22T17:53:46+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-22T18:32:36.382862+00:00",
      "updated_at": "2025-12-22T18:32:36.382872+00:00"
    },
    {
      "id": "25229e8004db6f09523c609498df3f55",
      "url": "https://reason.com/2025/12/19/jimmy-lai-is-a-martyr-for-freedom/",
      "title": "Jimmy Lai Is a Martyr for Freedom",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46355888\">Comments</a>",
      "author": "",
      "published_date": "2025-12-22T16:56:35+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-22T17:42:59.513408+00:00",
      "updated_at": "2025-12-22T18:24:05.319536+00:00",
      "metadata": {
        "processed_at": "2025-12-22T18:24:05.319547+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "25229e8004db6f09523c609498df3f55",
      "url": "https://reason.com/2025/12/19/jimmy-lai-is-a-martyr-for-freedom/",
      "title": "Jimmy Lai Is a Martyr for Freedom",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46355888\">Comments</a>",
      "author": "",
      "published_date": "2025-12-22T16:56:35+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-22T17:42:59.513408+00:00",
      "updated_at": "2025-12-22T18:24:05.319536+00:00",
      "metadata": {
        "processed_at": "2025-12-22T18:24:05.319547+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "a1944e7520cd7a4dbd6dbe85af1a5f3b",
      "url": "https://www.billboard.com/business/streaming/spotify-music-library-leak-1236143970/",
      "title": "Spotify reportedly investigating Anna's Archive's scraping of their library",
      "content": "<p>Article URL: <a href=\"https://www.billboard.com/business/streaming/spotify-music-library-leak-1236143970/\">https://www.billboard.com/business/streaming/spotify-music-library-leak-1236143970/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46355793\">https://news.ycombinator.com/item?id=46355793</a></p>\n<p>Points: 12</p>\n<p># Comments: 5</p>",
      "author": "ikamm",
      "published_date": "2025-12-22T16:50:22+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-22T17:42:58.164027+00:00",
      "updated_at": "2025-12-22T18:24:05.319551+00:00",
      "metadata": {
        "processed_at": "2025-12-22T18:24:05.319553+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "f817b65d1cc9680ccdb9be0b44859605",
      "url": "https://www.youtube.com/watch?v=vU1-uiUlHTo",
      "title": "Benn Jordan \u2013 This Flock Camera Leak Is Like Netflix for Stalkers [video]",
      "content": "<p>Article URL: <a href=\"https://www.youtube.com/watch?v=vU1-uiUlHTo\">https://www.youtube.com/watch?v=vU1-uiUlHTo</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46356182\">https://news.ycombinator.com/item?id=46356182</a></p>\n<p>Points: 19</p>\n<p># Comments: 2</p>",
      "author": "SamInTheShell",
      "published_date": "2025-12-22T17:19:44+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-22T17:42:58.163957+00:00",
      "updated_at": "2025-12-22T18:24:05.319562+00:00",
      "metadata": {
        "processed_at": "2025-12-22T18:24:05.319564+00:00",
        "processing_method": "github_actions"
      }
    }
  ]
}