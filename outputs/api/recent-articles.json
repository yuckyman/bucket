{
  "last_updated": "2025-12-01T05:30:45.842764+00:00",
  "count": 20,
  "articles": [
    {
      "id": "f6eab692632bce25de96677d43399fe5",
      "url": "https://arxiv.org/abs/2511.22809",
      "title": "AI summaries in online search influence users' attitudes",
      "content": "arXiv:2511.22809v1 Announce Type: new \nAbstract: This study examined how AI-generated summaries, which have become visually prominent in online search results, affect how users think about different issues. In a preregistered randomized controlled experiment, participants (N = 2,004) viewed mock search result pages varying in the presence (vs. absence), placement (top vs. middle), and stance (benefit-framed vs. harm-framed) of AI-generated summaries across four publicly debated topics. Compared to a no-summary control group, participants exposed to AI-generated summaries reported issue attitudes, behavioral intentions, and policy support that aligned more closely with the AI summary stance. The summaries placed at the top of the page produced stronger shifts in users' issue attitudes (but not behavioral intentions or policy support) than those placed at the middle of the page. We also observed moderating effects from issue familiarity and general trust toward AI. In addition, users perceived the AI summaries more useful when it emphasized health harms versus benefits. These findings suggest that AI-generated search summaries can significantly shape public perceptions, raising important implications for the design and regulation of AI-integrated information ecosystems.",
      "author": "Yiwei Xu, Saloni Dash, Sungha Kang, Wang Liao, Emma S. Spiro",
      "published_date": "2025-12-01T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 178,
      "reading_time": 1,
      "created_at": "2025-12-01T05:30:25.728456+00:00",
      "updated_at": "2025-12-01T05:30:25.728458+00:00"
    },
    {
      "id": "4e0a738ac3e5d679c2e7de07f6255ec7",
      "url": "https://arxiv.org/abs/2511.22789",
      "title": "Learning Programming in Informal Spaces: Using Emotion as a Lens to Understand Novice Struggles on r/learnprogramming",
      "content": "arXiv:2511.22789v1 Announce Type: new \nAbstract: Novice programmers experience emotional difficulties in informal online learning environments, where confusion and frustration can hinder motivation and learning outcomes. This study investigates novice programmers' emotional experiences in informal settings, identifies the causes of emotional struggle, and explores design opportunities for affect-aware support systems. We manually annotated 1,500 posts from r/learnprogramming using the Learning-Centered Emotions framework and conducted clustering and axial coding. Confusion, curiosity, and frustration were the most common emotions, often co-occurring and associated with early learning stages. Positive emotions were relatively rare. The primary emotional triggers included ambiguous errors, unclear learning pathways, and misaligned learning resources. We identify five key areas where novice programmers need support in informal learning spaces: stress relief and resilient motivation, topic explanation and resource recommendation, strategic decision-making and learning guidance, technical support, and acknowledgment of their challenges. Our findings highlight the need for intelligent, affect-sensitive mechanisms that provide timely support aligned with learners' emotional states.",
      "author": "Alif Al Hasan, Subarna Saha, Mia Mohammad Imran",
      "published_date": "2025-12-01T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 157,
      "reading_time": 1,
      "created_at": "2025-12-01T05:30:25.728426+00:00",
      "updated_at": "2025-12-01T05:30:25.728427+00:00"
    },
    {
      "id": "878e0f68080a9461aedb5018e3c4b230",
      "url": "https://arxiv.org/abs/2511.22746",
      "title": "Epistemic Fragility in Large Language Models: Prompt Framing Systematically Modulates Misinformation Correction",
      "content": "arXiv:2511.22746v1 Announce Type: new \nAbstract: As large language models (LLMs) rapidly displace traditional expertise, their capacity to correct misinformation has become a core concern. We investigate the idea that prompt framing systematically modulates misinformation correction - something we term 'epistemic fragility'. We manipulated prompts by open-mindedness, user intent, user role, and complexity. Across ten misinformation domains, we generated 320 prompts and elicited 2,560 responses from four frontier LLMs, which were coded for strength of misinformation correction and rectification strategy use. Analyses showed that creative intent, expert role, and closed framing led to a significant reduction in correction likelihood and effectiveness of used strategy. We also found striking model differences: Gemini 2.5 Pro had 74% lower odds of strong correction than Claude Sonnet 4.5. These findings highlight epistemic fragility as an important structural property of LLMs, challenging current guardrails and underscoring the need for alignment strategies that prioritize epistemic integrity over conversational compliance.",
      "author": "Sekoul Krastev, Hilary Sweatman, Anni Sternisko, Steve Rathje",
      "published_date": "2025-12-01T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 152,
      "reading_time": 1,
      "created_at": "2025-12-01T05:30:25.728397+00:00",
      "updated_at": "2025-12-01T05:30:25.728398+00:00"
    },
    {
      "id": "fc7cbda485e86879b5246c4f5099300e",
      "url": "https://arxiv.org/abs/2511.22617",
      "title": "A race to belief: How Evidence Accumulation shapes trust in AI and Human informants",
      "content": "arXiv:2511.22617v1 Announce Type: new \nAbstract: The integration of artificial intelligence into everyday decision-making has reshaped patterns of selective trust, yet the cognitive mechanisms behind context-dependent preferences for AI versus human informants remain unclear. We applied a Bayesian Hierarchical Sequential Sampling Model (HSSM) to analyze how 102 Colombian university students made trust decisions across 30 epistemic (factual) and social (interpersonal) scenarios.\n  Results show that context-dependent trust is primarily driven by differences in drift rate (v), the rate of evidence accumulation, rather than initial bias (z) or response caution (a). Epistemic scenarios produced strong negative drift rates (mean v = -1.26), indicating rapid evidence accumulation favoring AI, whereas social scenarios yielded positive drift rates (mean v = 0.70) favoring humans. Starting points were near neutral (z = 0.52), indicating minimal prior bias.\n  Drift rate showed a strong within-subject association with signed confidence (Fisher-z-averaged r = 0.736; 95 percent bootstrap CI 0.699 to 0.766; 97.8 percent of individual correlations positive, N = 93), suggesting that model-derived evidence accumulation closely mirrors participants' moment-to-moment confidence. These dynamics may help explain the fragility of AI trust: in epistemic domains, rapid but low-vigilance evidence processing may promote uncalibrated reliance on AI that collapses quickly after errors.\n  Interpreted through epistemic vigilance theory, the results indicate that domain-specific vigilance mechanisms modulate evidence accumulation. The findings inform AI governance by highlighting the need for transparency features that sustain vigilance without sacrificing efficiency, offering a mechanistic account of selective trust in human-AI collaboration.",
      "author": "Johan Sebasti\\'an Galindez-Acosta, Juan Jos\\'e Giraldo-Huertas",
      "published_date": "2025-12-01T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 242,
      "reading_time": 1,
      "created_at": "2025-12-01T05:30:25.728367+00:00",
      "updated_at": "2025-12-01T05:30:25.728369+00:00"
    },
    {
      "id": "2d48defa131636cca59f2ebcaae7b5e3",
      "url": "https://arxiv.org/abs/2511.22420",
      "title": "MATCH: Engineering Transparent and Controllable Conversational XAI Systems through Composable Building Blocks",
      "content": "arXiv:2511.22420v1 Announce Type: new \nAbstract: While the increased integration of AI technologies into interactive systems enables them to solve an increasing number of tasks, the black-box problem of AI models continues to spread throughout the interactive system as a whole. Explainable AI (XAI) techniques can make AI models more accessible by employing post-hoc methods or transitioning to inherently interpretable models. While this makes individual AI models clearer, the overarching system architecture remains opaque. This challenge not only pertains to standard XAI techniques but also to human examination and conversational XAI approaches that need access to model internals to interpret them correctly and completely. To this end, we propose conceptually representing such interactive systems as sequences of structural building blocks. These include the AI models themselves, as well as control mechanisms grounded in literature. The structural building blocks can then be explained through complementary explanatory building blocks, such as established XAI techniques like LIME and SHAP. The flow and APIs of the structural building blocks form an unambiguous overview of the underlying system, serving as a communication basis for both human and automated agents, thus aligning human and machine interpretability of the embedded AI models. In this paper, we present our flow-based approach and a selection of building blocks as MATCH: a framework for engineering Multi-Agent Transparent and Controllable Human-centered systems. This research contributes to the field of (conversational) XAI by facilitating the integration of interpretability into existing interactive systems.",
      "author": "Sebe Vanbrabant, Gustavo Rovelo Ruiz, Davy Vanacken",
      "published_date": "2025-12-01T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 239,
      "reading_time": 1,
      "created_at": "2025-12-01T05:30:25.728329+00:00",
      "updated_at": "2025-12-01T05:30:25.728331+00:00"
    },
    {
      "id": "afa86122b6e978a7299ca6f4d1a9f6c8",
      "url": "https://arxiv.org/abs/2511.22352",
      "title": "Engineering Trustworthy Automation: Design Principles and Evaluation for AutoML Tools for Novices",
      "content": "arXiv:2511.22352v1 Announce Type: new \nAbstract: AutoML systems targeting novices often prioritize algorithmic automation over usability, leaving gaps in users' understanding, trust, and end-to-end workflow support. To address these issues, we propose an abstract pipeline that covers data intake, guided configuration, training, evaluation, and inference. To examine the abstract pipeline, we report a user study where we assess trust, understandability, and UX of a prototype implementation. In a 24-participant study, all participants successfully built their own models, UEQ ratings were positive, yet experienced users reported higher trust and understanding than novices. Based on this study, we propose four design principles to improve the design of AutoML systems targeting novices: (P1) support first-model success to enhance user self-efficacy, (P2) provide explanations to help users form correct mental models and develop appropriate levels of reliance, (P3) provide abstractions and context-aware assistance to keep users in their zone of proximal development, and (P4) ensure predictability and safeguards to strengthen users' sense of control.",
      "author": "Jarne Thys, Davy Vanacken, Gustavo Rovelo Ruiz",
      "published_date": "2025-12-01T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 159,
      "reading_time": 1,
      "created_at": "2025-12-01T05:30:25.728273+00:00",
      "updated_at": "2025-12-01T05:30:25.728275+00:00"
    },
    {
      "id": "661986deaad7e5db6a4ab36a68547983",
      "url": "https://arxiv.org/abs/2511.22337",
      "title": "HandyLabel: Towards Post-Processing to Real-Time Annotation Using Skeleton Based Hand Gesture Recognition",
      "content": "arXiv:2511.22337v1 Announce Type: new \nAbstract: The success of machine learning is deeply linked to the availability of high-quality training data, yet retrieving and manually labeling new data remains a time-consuming and error-prone process. Traditional annotation tools, such as Label Studio, often require post-processing, where users label data after it has been recorded. Post-processing is highly time-consuming and labor-intensive, especially with large datasets, and may lead to erroneous annotations due to the difficulty of subjects' memory tasks when labeling cognitive activities such as emotions or comprehension levels. In this work, we introduce HandyLabel, a real-time annotation tool that leverages hand gesture recognition to map hand signs for labeling. The application enables users to customize gesture mappings through a web-based interface, allowing for real-time annotations. To ensure the performance of HandyLabel, we evaluate several hand gesture recognition models on an open-source hand sign (HaGRID) dataset, with and without skeleton-based preprocessing. We discovered that ResNet50 with preprocessed skeleton-based images performs an F1-score of 0.923. To validate the usability of HandyLabel, a user study was conducted with 46 participants. The results suggest that 88.9% of participants preferred HandyLabel over traditional annotation tools.",
      "author": "Sachin Kumar Singh, Ko Watanabe, Brian Moser, Andreas Dengel",
      "published_date": "2025-12-01T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 188,
      "reading_time": 1,
      "created_at": "2025-12-01T05:30:25.728243+00:00",
      "updated_at": "2025-12-01T05:30:25.728244+00:00"
    },
    {
      "id": "8e3c77a6f42e77ea8561b9930c8a51d7",
      "url": "https://arxiv.org/abs/2511.22269",
      "title": "Investigating AI in Peer Support via Multi-Module System-Driven Embodied Conversational Agents",
      "content": "arXiv:2511.22269v1 Announce Type: new \nAbstract: Young people's mental well-being is a global concern, with peer support playing a key role in daily emotional regulation. Conversational agents are increasingly viewed as promising tools for delivering accessible, personalised peer support, particularly where professional counselling is limited. However, existing systems often suffer from rigid input formats, scripted responses, and limited emotional sensitivity. The emergence of large language models introduces new possibilities for generating flexible, context-aware, and empathetic responses. To explore how individuals with psychological training perceive such systems in peer support contexts, we developed an LLM-based multi-module system to drive embodied conversational agents informed by Cognitive Behavioral Therapy (CBT). In a user study (N=10), we qualitatively examined participants' perceptions, focusing on trust, response quality, workflow integration, and design opportunities for future mental well-being support systems.",
      "author": "Ruoyu Wen, Xiaoli Wu, Kunal Gupta, Simon Hoermann, Mark Billinghurst, Alaeddin Nassani, Dwain Allan, Thammathip Piumsomboon",
      "published_date": "2025-12-01T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 132,
      "reading_time": 1,
      "created_at": "2025-12-01T05:30:25.728206+00:00",
      "updated_at": "2025-12-01T05:30:25.728208+00:00"
    },
    {
      "id": "528f3110f57220116998e1459422df20",
      "url": "https://arxiv.org/abs/2511.22056",
      "title": "EAST: Environment-Aware Stylized Transition Along the Reality-Virtuality Continuum",
      "content": "arXiv:2511.22056v1 Announce Type: new \nAbstract: In the Virtual Reality (VR) gaming industry, maintaining immersion during real-world interruptions remains a challenge, particularly during transitions along the reality-virtuality continuum (RVC). Existing methods tend to rely on digital replicas or simple visual transitions, neglecting to address the aesthetic discontinuities between real and virtual environments, especially in highly stylized VR games. This paper introduces the Environment-Aware Stylized Transition (EAST) framework, which employs a novel style-transferred 3D Gaussian Splatting (3DGS) technique to transfer real-world interruptions into the virtual environment with seamless aesthetic consistency. Rather than merely transforming the real world into game-like visuals, EAST minimizes the disruptive impact of interruptions by integrating real-world elements within the framework. Qualitative user studies demonstrate significant enhancements in cognitive comfort and emotional continuity during transitions, while quantitative experiments highlight EAST's ability to maintain visual coherence across diverse VR styles.",
      "author": "Fengze Li, Jieming Ma, Kan Liu, Xiaohan Zhang, Yangle Liu, Yue Li",
      "published_date": "2025-12-01T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 140,
      "reading_time": 1,
      "created_at": "2025-12-01T05:30:25.728176+00:00",
      "updated_at": "2025-12-01T05:30:25.728178+00:00"
    },
    {
      "id": "287e5336a3209e178de9d5e7eeb7de03",
      "url": "https://arxiv.org/abs/2511.21994",
      "title": "When Are Reactive Notebooks Not Reactive?",
      "content": "arXiv:2511.21994v1 Announce Type: new \nAbstract: Computational notebooks are convenient for programmers, but can easily become confusing and inconsistent due to the ability to incrementally edit a program that is running. Recent reactive notebook systems, such as Ipyflow, Marimo and Observable, strive to keep notebook state in sync with the current cell code by re-executing a minimal set of cells upon modification. However, each system defines reactivity a different way. Additionally, within any definition, we find simple notebook modifications that can break each system. Overall, these inconsistencies make it difficult for users to construct a mental model of their reactive notebook's implementation. This paper proposes Rex, a fine-grained test suite to discuss and assess reactivity capabilities within reactive notebook systems. We evaluate Rex on three existing reactive notebook systems and classify their failures with the aims of (i) helping programmers understand when reactivity fails and (ii) helping notebook implementations improve.",
      "author": "Megan Zheng, Will Crichton, Akshay Narayan, Deepti Raghavan, Nikos Vasilakis",
      "published_date": "2025-12-01T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 149,
      "reading_time": 1,
      "created_at": "2025-12-01T05:30:25.728139+00:00",
      "updated_at": "2025-12-01T05:30:25.728143+00:00"
    },
    {
      "id": "599d9582cef13fb736ce8672f3a51cf1",
      "url": "https://arxiv.org/abs/2511.09506",
      "title": "A thermoinformational formulation for the description of neuropsychological systems",
      "content": "arXiv:2511.09506v2 Announce Type: replace \nAbstract: Complex systems produce high-dimensional signals that lack macroscopic variables analogous to entropy, temperature, or free energy. This work introduces a thermoinformational formulation that derives entropy, internal energy, temperature, and Helmholtz free energy directly from empirical microstate distributions of arbitrary datasets. The approach provides a data-driven description of how a system reorganizes, exchanges information, and moves between stable and unstable states. Applied to dual-EEG recordings from mother-infant dyads performing the A-not-B task, the formulation captures increases in informational heat during switches and errors, and reveals that correct choices arise from more stable, low-temperature states. In an independent optogenetic dam-pup experiment, the same variables separate stimulation conditions and trace coherent trajectories in thermodynamic state space. Across both human and rodent systems, this thermoinformational formulation yields compact and physically interpretable macroscopic variables that generalize across species, modalities, and experimental paradigms.",
      "author": "George-Rafael Domenikos, Victoria Leong",
      "published_date": "2025-12-01T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 142,
      "reading_time": 1,
      "created_at": "2025-12-01T05:30:24.582075+00:00",
      "updated_at": "2025-12-01T05:30:24.582076+00:00"
    },
    {
      "id": "6c143d1aaf888fb3ea501ea1a2c86e7b",
      "url": "https://arxiv.org/abs/2509.10650",
      "title": "On a Geometry of Interbrain Networks",
      "content": "arXiv:2509.10650v3 Announce Type: replace \nAbstract: Effective analysis in neuroscience benefits significantly from robust conceptual frameworks. Traditional metrics of interbrain synchrony in social neuroscience typically depend on fixed, correlation-based approaches, restricting their explanatory capacity to descriptive observations. Inspired by the successful integration of geometric insights in network science, we propose leveraging discrete geometry to examine the dynamic reconfigurations in neural interactions during social exchanges. Unlike conventional synchrony approaches, our method interprets inter-brain connectivity changes through the evolving geometric structures of neural networks. This geometric framework is realized through a pipeline that identifies critical transitions in network connectivity using entropy metrics derived from curvature distributions. By doing so, we significantly enhance the capacity of hyperscanning methodologies to uncover underlying neural mechanisms in interactive social behavior.",
      "author": "Nicol\\'as Hinrichs, Noah Guzm\\'an, Melanie Weber",
      "published_date": "2025-12-01T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 123,
      "reading_time": 1,
      "created_at": "2025-12-01T05:30:24.582046+00:00",
      "updated_at": "2025-12-01T05:30:24.582047+00:00"
    },
    {
      "id": "c92a75950bc29c37fa01d6036dbb6b0e",
      "url": "https://arxiv.org/abs/2503.02636",
      "title": "YARE-GAN: Yet Another Resting State EEG-GAN",
      "content": "arXiv:2503.02636v4 Announce Type: replace \nAbstract: Resting-state EEG offers a non-invasive view of spontaneous brain activity, yet the extraction of meaningful patterns is often constrained by limited availability of high-quality data, and heavy reliance on manually engineered EEG features. Generative Adversarial Networks (GANs) offer not only a means to synthesize and augment neural signals, but also a promising way for learning meaningful representations directly from raw data, a dual capability that remains largely unexplored in EEG research. In this study, we introduce a scalable GAN-based framework for resting-state EEG that serves this dual role: 1) synthesis and 2) unsupervised feature extraction. The generated time series closely replicate key statistical and spectral properties of real EEG, as validated through both visual and quantitative evaluations. Importantly, we demonstrate that the model's learned representations can be repurposed for a downstream gender classification task, achieving higher out-of-sample accuracy than models trained directly on EEG signals and performing comparably to recent EEG foundation models, while using significantly less data and computational resources. These findings highlight the potential of generative models to serve as both neural signal generators and unsupervised feature extractors, paving the way for more data-efficient, architecture-driven approaches to EEG analysis with reduced reliance on manual feature engineering. The implementation code for this study is available at: https://github.com/Yeganehfrh/YARE-GAN.",
      "author": "Yeganeh Farahzadi, Morteza Ansarinia, Zoltan Kekecs",
      "published_date": "2025-12-01T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 213,
      "reading_time": 1,
      "created_at": "2025-12-01T05:30:24.582019+00:00",
      "updated_at": "2025-12-01T05:30:24.582020+00:00"
    },
    {
      "id": "8922bb43eda833579de338a49715be3f",
      "url": "https://arxiv.org/abs/2308.15477",
      "title": "Observing hidden neuronal states in experiments",
      "content": "arXiv:2308.15477v3 Announce Type: replace \nAbstract: In this article we demonstrate a general protocol for constructing systematically experimental steady-state bifurcation diagrams for electrophysiologically active cells. We perform our experiments on entorhinal cortex neurons, both excitatory (pyramidal neurons) and inhibitiory (interneurons). A slowly ramped voltage-clamp electrophysiology protocol serves as closed-loop feedback controlled experiment for the subsequent current-clamp open-loop protocol on the same cell. In this way, the voltage-clamped experiment determines dynamically stable and unstable (hidden) steady states of the current-clamp experiment. The transitions between observable steady states and observable spiking states in the current-clamp experiment provide partial evidence for stability and bifurcations of the steady states. This technique for completing steady-state bifurcation diagrams in a model-independent way expands support for model validation to otherwise inaccessible regions of the phase space. Overlaying the voltage-clamp and current-clamp protocols leads to an experimental validation of the classical slow-fast dissection method introduced by J. Rinzel in the 1980s and routinely applied ever since in order to analyse slow-fast neuronal models. Our approach opens doors to observing further complex hidden states with more advanced control strategies, allowing to control real cells beyond pharmacological manipulations.",
      "author": "Dmitry Amakhin, Anton Chizhov, Guillaume Girier, Mathieu Desroches, Jan Sieber, Serafim Rodrigues",
      "published_date": "2025-12-01T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 187,
      "reading_time": 1,
      "created_at": "2025-12-01T05:30:24.581986+00:00",
      "updated_at": "2025-12-01T05:30:24.581987+00:00"
    },
    {
      "id": "30824215e27d1e79c4d24eef130f0b81",
      "url": "https://arxiv.org/abs/2511.22870",
      "title": "Scalable Diffusion Transformer for Conditional 4D fMRI Synthesis",
      "content": "arXiv:2511.22870v1 Announce Type: cross \nAbstract: Generating whole-brain 4D fMRI sequences conditioned on cognitive tasks remains challenging due to the high-dimensional, heterogeneous BOLD dynamics across subjects/acquisitions and the lack of neuroscience-grounded validation. We introduce the first diffusion transformer for voxelwise 4D fMRI conditional generation, combining 3D VQ-GAN latent compression with a CNN-Transformer backbone and strong task conditioning via AdaLN-Zero and cross-attention. On HCP task fMRI, our model reproduces task-evoked activation maps, preserves the inter-task representational structure observed in real data (RSA), achieves perfect condition specificity, and aligns ROI time-courses with canonical hemodynamic responses. Performance improves predictably with scale, reaching task-evoked map correlation of 0.83 and RSA of 0.98, consistently surpassing a U-Net baseline on all metrics. By coupling latent diffusion with a scalable backbone and strong conditioning, this work establishes a practical path to conditional 4D fMRI synthesis, paving the way for future applications such as virtual experiments, cross-site harmonization, and principled augmentation for downstream neuroimaging models.",
      "author": "Jungwoo Seo, David Keetae Park, Shinjae Yoo, Jiook Cha",
      "published_date": "2025-12-01T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 156,
      "reading_time": 1,
      "created_at": "2025-12-01T05:30:24.581953+00:00",
      "updated_at": "2025-12-01T05:30:24.581955+00:00"
    },
    {
      "id": "81b95eee7cdd7908172260deda6154b3",
      "url": "https://arxiv.org/abs/2511.22828",
      "title": "Fast dynamical similarity analysis",
      "content": "arXiv:2511.22828v1 Announce Type: cross \nAbstract: To understand how neural systems process information, it is often essential to compare one circuit with another, one brain with another, or data with a model. Traditional similarity measures ignore the dynamical processes underlying neural representations. Dynamical similarity methods offer a framework to compare the temporal structure of dynamical systems by embedding their (possibly) nonlinear dynamics into a globally linear space and there computing conjugacy metrics. However, identifying the best embedding and computing these metrics can be computationally slow. Here we introduce fast Dynamical Similarity Analysis (fastDSA), which is computationally far more efficient than previous methods while maintaining their accuracy and robustness. FastDSA introduces two key components that boost efficiency: (1) automatic selection of the effective model order of the Hankel (delay) embedding from the data via a data-driven singular-value threshold that identifies the informative subspace and discards noise to lower computational cost without sacrificing signal, and (2) a novel optimization procedure and objective, which replaces the slow exact orthogonality constraint in finding a minimal distance between dynamics matrices with a lightweight process to keep the search close to the space of orthogonal transformations. We demonstrate that fastDSA is at least an order of magnitude faster than the previous methods. Furthermore, we demonstrate that fastDSA has the properties of its ancestor, including its invariances and sensitivities to system dynamics. FastDSA, therefore, provides a computationally efficient and accurate method for dynamical similarity analysis.",
      "author": "Arman Behrad, Mitchell Ostrow, Mohammad Taha Fakharian, Ila Fiete, Christian Beste, Shervin Safavi",
      "published_date": "2025-12-01T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 237,
      "reading_time": 1,
      "created_at": "2025-12-01T05:30:24.581922+00:00",
      "updated_at": "2025-12-01T05:30:24.581924+00:00"
    },
    {
      "id": "3372882380c5647aeb6c80539ee8fb0f",
      "url": "https://arxiv.org/abs/2511.21940",
      "title": "Deep Learning Architectures for Code-Modulated Visual Evoked Potentials Detection",
      "content": "arXiv:2511.21940v1 Announce Type: cross \nAbstract: Non-invasive Brain-Computer Interfaces (BCIs) based on Code-Modulated Visual Evoked Potentials (C-VEPs) require highly robust decoding methods to address temporal variability and session-dependent noise in EEG signals. This study proposes and evaluates several deep learning architectures, including convolutional neural networks (CNNs) for 63-bit m-sequence reconstruction and classification, and Siamese networks for similarity-based decoding, alongside canonical correlation analysis (CCA) baselines. EEG data were recorded from 13 healthy adults under single-target flicker stimulation. The proposed deep models significantly outperformed traditional approaches, with distance-based decoding using Earth Mover's Distance (EMD) and constrained EMD showing greater robustness to latency variations than Euclidean and Mahalanobis metrics. Temporal data augmentation with small shifts further improved generalization across sessions. Among all models, the multi-class Siamese network achieved the best overall performance with an average accuracy of 96.89%, demonstrating the potential of data-driven deep architectures for reliable, single-trial C-VEP decoding in adaptive non-invasive BCI systems.",
      "author": "Kiran Nair, Hubert Cecotti",
      "published_date": "2025-12-01T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 151,
      "reading_time": 1,
      "created_at": "2025-12-01T05:30:24.581887+00:00",
      "updated_at": "2025-12-01T05:30:24.581888+00:00"
    },
    {
      "id": "e715dc1bf1047865387ded5fae2bfa10",
      "url": "https://arxiv.org/abs/2511.21848",
      "title": "Massively Parallel Imitation Learning of Mouse Forelimb Musculoskeletal Reaching Dynamics",
      "content": "arXiv:2511.21848v1 Announce Type: cross \nAbstract: The brain has evolved to effectively control the body, and in order to understand the relationship we need to model the sensorimotor transformations underlying embodied control. As part of a coordinated effort, we are developing a general-purpose platform for behavior-driven simulation modeling high fidelity behavioral dynamics, biomechanics, and neural circuit architectures underlying embodied control. We present a pipeline for taking kinematics data from the neuroscience lab and creating a pipeline for recapitulating those natural movements in a biomechanical model. We implement a imitation learning framework to perform a dexterous forelimb reaching task with a musculoskeletal model in a simulated physics environment. The mouse arm model is currently training at faster than 1 million training steps per second due to GPU acceleration with JAX and Mujoco-MJX. We present results that indicate that adding naturalistic constraints on energy and velocity lead to simulated musculoskeletal activity that better predict real EMG signals. This work provides evidence to suggest that energy and control constraints are critical to modeling musculoskeletal motor control.",
      "author": "Eric Leonardis, Akira Nagamori, Ayesha Thanawalla, Yuanjia Yang, Joshua Park, Hutton Saunders, Eiman Azim, Talmo Pereira",
      "published_date": "2025-12-01T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 172,
      "reading_time": 1,
      "created_at": "2025-12-01T05:30:24.581857+00:00",
      "updated_at": "2025-12-01T05:30:24.581859+00:00"
    },
    {
      "id": "ca31078e0734482b938758886e6d8522",
      "url": "https://arxiv.org/abs/2511.22848",
      "title": "Short-term plasticity recalls forgotten memories through a trampoline mechanism",
      "content": "arXiv:2511.22848v1 Announce Type: new \nAbstract: We analyze continuous Hopfield associative memories augmented by additional, rapid short-term associative synaptic plasticity. Through the cavity method, we determine the boundary between the retrieval and forgetting, or spin-glass phase, of the network as a function of the fraction of stored memories and the neuronal gain. We find that short-term synaptic plasticity yields marginal improvements in critical memory capacity. However, through dynamical mean field theory, backed by extensive numerical simulations, we find that short-term synaptic plasticity has a dramatic impact on memory retrieval above the critical capacity. When short-term synaptic plasticity is turned on, the combined neuronal and synaptic dynamics descends a high-dimensional energy landscape over both neurons and synapses. The energy landscape over neurons alone is thus dynamic, and is lowered in the vicinity of recent neuronal patterns visited by the network, just like the surface of a trampoline is lowered in the vicinity of regions recently visited by a heavy ball. This trampoline-like reactivity of the neuronal energy landscape to short-term plasticity in synapses can lead to the recall of stored memories that would otherwise have been forgotten. This occurs because the dynamics without short-term plasticity transiently moves towards a stored memory before departing away from it. Thus short-term plasticity, operating during the transient, lowers the energy in the vicinity of the stored memory, eventually trapping the combined neuronal and synaptic dynamics at a fixed point close to the stored memory. In this manner, short-term plasticity enables the recall of memories that would otherwise be forgotten, by trapping transients that would otherwise escape. We furthermore find an optimal time constant for short-term synaptic plasticity, matched to the transient dynamics, to empower recall of forgotten memories.",
      "author": "Martina Del Gaudio, Federico Ghimenti, Surya Ganguli",
      "published_date": "2025-12-01T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 282,
      "reading_time": 1,
      "created_at": "2025-12-01T05:30:24.581824+00:00",
      "updated_at": "2025-12-01T05:30:24.581827+00:00"
    },
    {
      "id": "ec8a44fdefacf8b5b3cf084246e61e62",
      "url": "https://arxiv.org/abs/2511.22050",
      "title": "Integrative characterization of the topography of V4 neural codes using deep learning approaches",
      "content": "arXiv:2511.22050v1 Announce Type: new \nAbstract: Area V4 is a mid-level stage of the macaque ventral visual stream, known to encode intermediate visual features such as color, curvature, corners, texture, three-dimensional (3D) solids, and local form. Classical neurophysiological studies have typically examined these dimensions in isolation, contrasting V4 selectivity for shape versus texture, 3D solid surfaces versus two-dimensional (2D) flat patterns, or object form versus texture. Yet how these tunings relate to one another within individual neurons, and how they are jointly organized across the cortical surface, remain unknown. For instance, does a neuron selective for 2D contour-defined shape prefer 3D solid surfaces or 2D flat surfaces? How are preferences for such heterogeneous attributes arranged in a common topographic map? To address these questions, we leverage V4 \"digital twins\" -- deep neural network models fitted to large-scale, wide-field calcium imaging data comprising tens of thousands of natural images. These digital twins allow us to systematically probe not only the stimulus dimensions explored in earlier studies, but also new, multidimensional stimulus sets that reveal additional aspects of the V4 code. In this study, we find that neural pixels preferring 2D contour-defined shapes also tend to prefer 3D surface shape defined by shading or texture gradients and by object form. In contrast, pixels preferring 2D texture tend to prefer flat surfaces defined by uniform texture or reflectance. We propose that this division of labor suggests that V4 may decompose the encoding of geometrical shape and surface appearance of visual stimuli into distinct populations of neurons, organized as interleaved clusters in the V4 topographic map.",
      "author": "Yingjue Bian, Tianye Wang, Shiming Tang, Tai Sing Lee",
      "published_date": "2025-12-01T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 261,
      "reading_time": 1,
      "created_at": "2025-12-01T05:30:24.581776+00:00",
      "updated_at": "2025-12-01T05:30:24.581780+00:00"
    }
  ]
}