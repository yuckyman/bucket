{
  "last_updated": "2025-12-16T17:49:14.712595+00:00",
  "count": 20,
  "articles": [
    {
      "id": "7f7383292b5f231321c44f48a84ca2bf",
      "url": "https://resources.github.com/actions/2026-pricing-changes-for-github-actions/",
      "title": "Pricing Changes for GitHub Actions",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46291156\">Comments</a>",
      "author": "",
      "published_date": "2025-12-16T17:12:02+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-16T17:48:03.921104+00:00",
      "updated_at": "2025-12-16T17:48:03.921106+00:00"
    },
    {
      "id": "7f7383292b5f231321c44f48a84ca2bf",
      "url": "https://resources.github.com/actions/2026-pricing-changes-for-github-actions/",
      "title": "Pricing Changes for GitHub Actions",
      "content": "<p>Article URL: <a href=\"https://resources.github.com/actions/2026-pricing-changes-for-github-actions/\">https://resources.github.com/actions/2026-pricing-changes-for-github-actions/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46291156\">https://news.ycombinator.com/item?id=46291156</a></p>\n<p>Points: 10</p>\n<p># Comments: 2</p>",
      "author": "kevin-david",
      "published_date": "2025-12-16T17:12:02+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-16T17:48:02.567160+00:00",
      "updated_at": "2025-12-16T17:48:02.567162+00:00"
    },
    {
      "id": "307671786156803b09edaa9705ffbb17",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.12.694050v1?rss=1",
      "title": "People report having consistent idiosyncratic diets of imagined sensations when they re-experience the past, and pre-experience the future",
      "content": "To some extent, humans can re-experience the sensations of past events and pre-experience the future. These capacities are inter-related. But there are substantial individual differences. At the extremes, small minorities of people report that they either cannot have imagined experiences at all, or that their imagined sensations are as real to them as their actual experiences of the physical world. We wanted to know if such individual differences are uniform across different types of imagined experience (e.g. vision, audio, taste and smell), or if people generally have idiosyncratic patterns of different types (vision, audio, taste and smell) of imagined experiences. We find that people report having idiosyncratic diets of different types of imagined sensation, characterised by differences in salience. One person might have more salient imagined visual than taste experiences, while another reports the reverse. Moreover, these propensities are consistent across peoples attempts to re-experience the past, and to pre-experience the future, and they predict peoples experience and usage of different types of imagined sensation in their everyday lives.",
      "author": "Arnold, D. H., Bouyer, L. N., Saurels, B. W., Schwarzkopf, D. S.",
      "published_date": "2025-12-16T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 169,
      "reading_time": 1,
      "created_at": "2025-12-16T17:24:55.980903+00:00",
      "updated_at": "2025-12-16T17:24:55.980905+00:00"
    },
    {
      "id": "865bb4fb6df43e59662df4eae14d8639",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.12.694043v1?rss=1",
      "title": "An Interactive Brain Atlas of Knowledge",
      "content": "Biomedical knowledge about the brain increases every day, with a rapidly growing number of scientific publications, datasets, and software tools. While this informational plethora is not merely comprehensible by human beings, recent developments in information science and computational linguistics aim to make this knowledge programmatically accessible by literature mining. However, integrating these semantic methods into neuroimaging standards remains insufficient, hindering researchers from unraveling their full potential. Therefore, we developed the semantic meta-analysis platform The Virtual Brain adapter of semantics (TVBase) that projects biomedical knowledge preserved in over 36 million scientific articles onto a 3D standardized brain. The literature-mining platform SCAIView was used to extract ontologically defined biomedical entities and their associations with brain anatomy from the PubMed database. By querying a specific concept, the association strength with each anatomical term was calculated using entropy. To project the data onto a standardized brain, we created a unique transformation matrix that links over 800 anatomical terms to voxel coordinates of a parcellated standard brain. This novel method of knowledge projection extracts region-specific information about biomedical concepts from the literature to support translational multi-scale approaches to computational neuroscience. The multi-purpose software framework TVBase is openly available as a Python library. It aims for hypothesis-free neuroimaging pattern interpretation, hypothesis generation, and applications in personalized medicine.",
      "author": "Stefanovski, L., Bu\u0308lau, K., Martin, L., Langford, C., Palmer, J., Sacks, M., Deger, L., Pille, M., Schirner, M., Meier, J., Neudorfer, C., Horn, A., Solodkin, A., Thirion, B., Hofmann-Apitius, M., Jacobs, M., Tom Kodamullil, A., for the Alzheimer's Disease Neuroimaging Initiative,, Ritter, P.",
      "published_date": "2025-12-16T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 211,
      "reading_time": 1,
      "created_at": "2025-12-16T17:24:55.980870+00:00",
      "updated_at": "2025-12-16T17:24:55.980871+00:00"
    },
    {
      "id": "f38769bb46e85ec3d3ec660d77ac913b",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.12.694045v1?rss=1",
      "title": "Projection-specific Routing of Odor Information in the Olfactory Cortex",
      "content": "Sensory processing in the mammalian cortex relies on extensive feedforward and feedback connections, yet how information is routed along these pathways remains poorly understood. Here, we examined the functional properties of feedback and feedforward neurons in the mouse olfactory (piriform) cortex. We selectively labeled neurons projecting to the olfactory bulb (OB, feedback) or medial prefrontal cortex (mPFC, feedforward) and recorded their activity during passive odor exposure and learning of an odor discrimination task. We found that odor identity and reward associations were encoded by OB-projecting ensembles early during odor exposure, whereas mPFC-projecting neurons encoded this information later, aligned with behavioral responses. Moreover, mPFC-projecting neurons maintained a stable representation of valence across days, while OB-projecting neurons exhibited pronounced plasticity. Together, these findings reveal that odor information is selectively routed through feedforward and feedback pathways and suggest that the functional properties of piriform neurons mirror the computational demands of their downstream targets.",
      "author": "Daste, S., Pham, T. H., Seppo, M., Andre, A., Srinivasan, S., Xiao, J., Sattin, A., Nardin, C., Fellin, T., Franks, K., Dyer, E., Fleischmann, A.",
      "published_date": "2025-12-16T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 150,
      "reading_time": 1,
      "created_at": "2025-12-16T17:24:55.980830+00:00",
      "updated_at": "2025-12-16T17:24:55.980832+00:00"
    },
    {
      "id": "98a51e51ceaf056f5cf97edf32f29b14",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.12.693971v1?rss=1",
      "title": "DfE-DB: A systematic database of 3.8 million human decisions across multiple experience-based tasks",
      "content": "Learning from experience is central to human decision making, yet research on experience-based choice remains fragmented across paradigms and disciplines. We present the Decision-from-Experience Database (DfE-DB), a standardized, openly accessible resource comprising 3.8 million trial-level decisions from 11,921 participants across 168 studies and 13 paradigms. By harmonizing raw behavioral data and classifying studies along 13 key design features, the database enables quantitative comparisons previously obscured by heterogeneous task and data structures. Using this resource, we show that choice tendencies--toward higher risk, expected value, or experienced mean--vary substantially across paradigms and are strongly shaped by core design features such as feedback type, outcome structure, stationarity, and sampling. These features explain substantial cross-study variability and reveal underexplored paradigm variants. DfE-DB provides the empirical infrastructure necessary to test the generality of behavioral phenomena and computational models, fostering a more integrated science of decisions from experience.",
      "author": "Yang, Y., Spektor, M., Thoma, A. I., Hertwig, R., Wulff, D. U.",
      "published_date": "2025-12-16T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 142,
      "reading_time": 1,
      "created_at": "2025-12-16T17:24:55.980792+00:00",
      "updated_at": "2025-12-16T17:24:55.980796+00:00"
    },
    {
      "id": "0c9327be13f51e21067bd12d7c027288",
      "url": "https://www.reddit.com/r/Python/comments/1po3kbe/fly_through_data_validation_with_pyreflys_new/",
      "title": "Fly through data validation with Pyrefly\u2019s new Pydantic integration",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>Pyrefly's Pydantic integration aims to provide a seamless, out-of-the-box experience, allowing you to statically validate your Pydantic code as you type, rather than solely at runtime. No plugins or manual configuration required!</p> <p>Supporting third-party packages like Pydantic in a language server or type checker is a non-trivial challenge. Unlike the Python standard library, third-party packages may introduce their own conventions, dynamic behaviors, and runtime logic that can be difficult to analyze statically. Many type checkers either require plugins (like Mypy\u2019s Pydantic plugin) or offer only limited support for these types of projects. At the time of writing, Mypy is currently the only other major typechecker that provides robust support for Pydantic.</p> <p>Full blog post: <a href=\"https://pyrefly.org/blog/pyrefly-pydantic/\">https://pyrefly.org/blog/pyrefly-pydantic/</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/BeamMeUpBiscotti\"> /u/BeamMeUpBiscotti </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1po3kbe/fly_through_data_validation_with_pyreflys_new/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1po3kbe/fly_through_data_validation_with_pyreflys_new/\">[comments]</a></span>",
      "author": "/u/BeamMeUpBiscotti",
      "published_date": "2025-12-16T14:39:07+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 137,
      "reading_time": 1,
      "created_at": "2025-12-16T17:24:16.661477+00:00",
      "updated_at": "2025-12-16T17:24:16.661479+00:00"
    },
    {
      "id": "15335fe1d658e864376b3a196d0f663e",
      "url": "https://github.com/Lab700xOrg/aisbom",
      "title": "AIsbom \u2013 open-source CLI to detect \"Pickle Bombs\" in PyTorch models",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46290113\">Comments</a>",
      "author": "",
      "published_date": "2025-12-16T15:55:45+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-16T17:24:15.393585+00:00",
      "updated_at": "2025-12-16T17:24:15.393587+00:00"
    },
    {
      "id": "201f8b9c7d545d028a0315cfed7d827e",
      "url": "https://www.ycombinator.com/companies/artie/jobs/HyaHWUs-senior-enterprise-ae",
      "title": "Artie (YC S23) Is Hiring Senior Enterprise AES",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46291011\">Comments</a>",
      "author": "",
      "published_date": "2025-12-16T17:00:57+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-16T17:24:15.393527+00:00",
      "updated_at": "2025-12-16T17:24:15.393528+00:00"
    },
    {
      "id": "a43419c3562f47d54677a0bafc0604d5",
      "url": "https://fvwm95.sourceforge.net/",
      "title": "FVWM-95",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46291172\">Comments</a>",
      "author": "",
      "published_date": "2025-12-16T17:13:07+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-16T17:24:15.393468+00:00",
      "updated_at": "2025-12-16T17:24:15.393470+00:00"
    },
    {
      "id": "d8b771f254299ecc9bf00e7b1405aa82",
      "url": "https://alpr.watch/",
      "title": "Track Surveillance (Flock Cameras) Tech in Local Government Meetings",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46290916\">Comments</a>",
      "author": "",
      "published_date": "2025-12-16T16:54:19+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-16T17:24:15.393400+00:00",
      "updated_at": "2025-12-16T17:24:15.393404+00:00"
    },
    {
      "id": "15335fe1d658e864376b3a196d0f663e",
      "url": "https://github.com/Lab700xOrg/aisbom",
      "title": "AIsbom \u2013 open-source CLI to detect \"Pickle Bombs\" in PyTorch models",
      "content": "<p>Article URL: <a href=\"https://github.com/Lab700xOrg/aisbom\">https://github.com/Lab700xOrg/aisbom</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46290113\">https://news.ycombinator.com/item?id=46290113</a></p>\n<p>Points: 20</p>\n<p># Comments: 6</p>",
      "author": "lab700xdev",
      "published_date": "2025-12-16T15:55:45+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-16T17:24:14.021114+00:00",
      "updated_at": "2025-12-16T17:24:14.021116+00:00"
    },
    {
      "id": "76bba95e06429d9fbd08fcf3db80e028",
      "url": "https://www.theregister.com/2025/12/16/apple_dma_complaint/",
      "title": "Devs say Apple still flouting EU's Digital Markets Act six months on",
      "content": "<p>Article URL: <a href=\"https://www.theregister.com/2025/12/16/apple_dma_complaint/\">https://www.theregister.com/2025/12/16/apple_dma_complaint/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46290320\">https://news.ycombinator.com/item?id=46290320</a></p>\n<p>Points: 21</p>\n<p># Comments: 6</p>",
      "author": "paulatreides",
      "published_date": "2025-12-16T16:09:48+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-16T17:24:14.021094+00:00",
      "updated_at": "2025-12-16T17:24:14.021096+00:00"
    },
    {
      "id": "d8b771f254299ecc9bf00e7b1405aa82",
      "url": "https://alpr.watch/",
      "title": "Track Surveillance (Flock Cameras) Tech in Local Government Meetings",
      "content": "<p>Article URL: <a href=\"https://alpr.watch/\">https://alpr.watch/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46290916\">https://news.ycombinator.com/item?id=46290916</a></p>\n<p>Points: 24</p>\n<p># Comments: 2</p>",
      "author": "theamk",
      "published_date": "2025-12-16T16:54:19+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-16T17:24:14.021073+00:00",
      "updated_at": "2025-12-16T17:24:14.021074+00:00"
    },
    {
      "id": "201f8b9c7d545d028a0315cfed7d827e",
      "url": "https://www.ycombinator.com/companies/artie/jobs/HyaHWUs-senior-enterprise-ae",
      "title": "Artie (YC S23) Is Hiring Senior Enterprise AES",
      "content": "<p>Article URL: <a href=\"https://www.ycombinator.com/companies/artie/jobs/HyaHWUs-senior-enterprise-ae\">https://www.ycombinator.com/companies/artie/jobs/HyaHWUs-senior-enterprise-ae</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46291011\">https://news.ycombinator.com/item?id=46291011</a></p>\n<p>Points: 0</p>\n<p># Comments: 0</p>",
      "author": "j-cheong",
      "published_date": "2025-12-16T17:00:57+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-16T17:24:14.021044+00:00",
      "updated_at": "2025-12-16T17:24:14.021050+00:00"
    },
    {
      "id": "adaf88f86d96d927e2f686a82a0adbfb",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.15.694497v1?rss=1",
      "title": "HDAC3 inhibition harnesses learning-induced neurobiological mechanisms to enhance signal-in-noise responsivity in auditory cortex and behavior",
      "content": "Auditory learning enables sound-guided behavior and sound-specific enhancements in auditory cortical (AC) processing. Background noise can also alter sound-specific auditory responsivity. Yet, the potential enhancing effects of learning on AC processing in noise is unknown. Pharmacological inhibition of histone deacetylase 3 (HDAC3) by RGFP966 has been shown to improve AC coding when administered during various auditory learning paradigms. Here, adult rats (Sprague-Dawley males) were trained in ideal quiet conditions to learn a tone-reward associative task while treated with RGFP966 (TRAINED+RGFP966, n = 6) to determine if learning-related effects on AC could support tone-signal detection in a later background noise challenge. RGFP966 accelerated sound-reward learning relative to a trained but untreated group of rats (TRAINED, n = 5), though all animals ultimately reached equivalent high levels of performance prior to testing. Training produced a sound-specific enhancement in AC responses evoked by the signal tone, and a sound-general effect that suppressed responses during steady-state noise, relative to untrained rats (NAIVE, n = 7). Effects were strongest when training was with RGFP966 administration and scaled with increasing signal-to-noise (SNR). High levels of background noise abolished sound-specific enhancements in tone-signal evoked AC activity, yet the general suppressive effect to noise was maintained. Remarkably, behavioral responses to the signal tone in different SNRs recapitulated AC patterns of tone-evoked responding. Overall, rapid auditory learning facilitated by RGFP966 yields AC plasticity that can improve signal detection. Learning-induced mechanisms appear to shape cortical decoding mechanisms that selectively enhance representations of signal sounds and suppress the effects of background noise.",
      "author": "Atesyakar, N., Bieszczad, K.",
      "published_date": "2025-12-16T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 251,
      "reading_time": 1,
      "created_at": "2025-12-16T16:31:48.145192+00:00",
      "updated_at": "2025-12-16T16:31:48.145197+00:00"
    },
    {
      "id": "666d74c8155d3b4e5e4fdfb5f5a1d2cd",
      "url": "https://www.wsj.com/economy/jobs/jobs-report-october-november-2025-unemployment-economy-7f6eea90",
      "title": "U.S. unemployment rose in November despite job gains",
      "content": "<p>Article URL: <a href=\"https://www.wsj.com/economy/jobs/jobs-report-october-november-2025-unemployment-economy-7f6eea90\">https://www.wsj.com/economy/jobs/jobs-report-october-november-2025-unemployment-economy-7f6eea90</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46288673\">https://news.ycombinator.com/item?id=46288673</a></p>\n<p>Points: 46</p>\n<p># Comments: 8</p>",
      "author": "JumpCrisscross",
      "published_date": "2025-12-16T14:11:08+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-16T16:31:04.167857+00:00",
      "updated_at": "2025-12-16T16:31:04.167859+00:00"
    },
    {
      "id": "0098661aa92250b181effea40c30e99d",
      "url": "https://www.wsj.com/tech/ai/ceos-to-keep-spending-on-ai-despite-spotty-returns-2eaeb6b",
      "title": "CEOs to Keep Spending on AI, Despite Spotty Returns",
      "content": "<p>Article URL: <a href=\"https://www.wsj.com/tech/ai/ceos-to-keep-spending-on-ai-despite-spotty-returns-2eaeb6b\">https://www.wsj.com/tech/ai/ceos-to-keep-spending-on-ai-despite-spotty-returns-2eaeb6b</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46289160\">https://news.ycombinator.com/item?id=46289160</a></p>\n<p>Points: 17</p>\n<p># Comments: 5</p>",
      "author": "1vuio0pswjnm7",
      "published_date": "2025-12-16T14:46:52+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-16T16:31:04.167810+00:00",
      "updated_at": "2025-12-16T16:31:04.167819+00:00"
    },
    {
      "id": "80d1f642eb4da0958753076107ac0cbe",
      "url": "http://daniellakens.blogspot.com/2025/07/easily-download-files-from-open-science.html",
      "title": "Easily download files from the Open Science Framework with Papercheck",
      "content": "<p>Researchers\nincreasingly use the <a href=\"https://osf.io/\">Open Science Framework</a> (OSF) to share files, such as data\nand code underlying scientific publications, or presentations and materials for\nscientific workshops. The OSF is an amazing service that has contributed\nimmensely to a changed research culture where psychologists share data, code, and\nmaterials. We are very grateful it exists.</p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">But it is\nnot always the most user-friendly. Specifically, downloading files from the OSF\nis a bigger hassle than we (<a href=\"https://debruine.github.io/\">Lisa DeBruine</a>\nand <a href=\"https://www.tue.nl/en/research/researchers/daniel-lakens/\">Daniel\nLakens</a>, the developers of Papercheck) would like it to be. Downloading individual\nfiles is so complex, <a href=\"https://bsky.app/profile/malte.the100.ci/post/3lpf4s6spns2i\">Malte Elson</a>\nrecently posted this meme on Bluesky. </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"NL\"><!--[if gte vml 1]><v:shapetype\n id=\"_x0000_t75\" coordsize=\"21600,21600\" o:spt=\"75\" o:preferrelative=\"t\"\n path=\"m@4@5l@4@11@9@11@9@5xe\" filled=\"f\" stroked=\"f\">\n <v:stroke joinstyle=\"miter\"/>\n <v:formulas>\n  <v:f eqn=\"if lineDrawn pixelLineWidth 0\"/>\n  <v:f eqn=\"sum @0 1 0\"/>\n  <v:f eqn=\"sum 0 0 @1\"/>\n  <v:f eqn=\"prod @2 1 2\"/>\n  <v:f eqn=\"prod @3 21600 pixelWidth\"/>\n  <v:f eqn=\"prod @3 21600 pixelHeight\"/>\n  <v:f eqn=\"sum @0 0 1\"/>\n  <v:f eqn=\"prod @6 1 2\"/>\n  <v:f eqn=\"prod @7 21600 pixelWidth\"/>\n  <v:f eqn=\"sum @8 21600 0\"/>\n  <v:f eqn=\"prod @7 21600 pixelHeight\"/>\n  <v:f eqn=\"sum @10 21600 0\"/>\n </v:formulas>\n <v:path o:extrusionok=\"f\" gradientshapeok=\"t\" o:connecttype=\"rect\"/>\n <o:lock v:ext=\"edit\" aspectratio=\"t\"/>\n</v:shapetype><v:shape id=\"_x0000_i1026\" type=\"#_x0000_t75\" style='width:453.75pt;\n height:276pt;visibility:visible;mso-wrap-style:square'>\n <v:imagedata src=\"file:///C:/Users/DLakens/AppData/Local/Temp/msohtmlclip1/01/clip_image001.jpg\"\n  o:title=\"\"/>\n</v:shape><![endif]--><!--[if !vml]--><img border=\"0\" height=\"368\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEinS5tFoL5qX14Z2OcgT1APMZLGlghAD3BfBhSnJ9pleVbJyRFUFLShqReS2j7SXGozmLMcVQkoM62UhneJDtH4yx3NRnXOkVZZi-Dm-OPwbGaidxr2raF9wzjx5fU92nfPpE3jmGfwZEwHS1WGSB4gUfRfV3XWjOC2-lCjOYR108h3fwORIHOnqxIX9m8\" width=\"605\" /><!--[endif]--></span><span lang=\"EN-US\"></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\"><span>&nbsp;</span></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">Not only is\nthe download button for files difficult to find, but downloading all files\nrelated to a project can be surprisingly effortful. It is possible to download\nall files in a zip folder that will be called \u2018osfstorage-archive.zip\u2019 when\ndownloaded. But as the OSF supports a nested folder structure, you might miss a\nfolder, and you will quickly end up with \u2018osfstorage-archive (1).zip\u2019, \u2018osfstorage-archive\n(2).zip\u2019, etc. Unzipping these archives creates a lot of files without the\norganized folder structure, in folders with meaningless names, making it\ndifficult to understand where files are. </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<h2 style=\"text-align: left;\"><b><span lang=\"EN-US\">The\nosf_file_download function in Papercheck </span></b></h2>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">We have added\na new function to our R package \u2018<a href=\"https://scienceverse.github.io/papercheck/\">Papercheck</a>\u2019 that will download all files and\nfolders in an OSF repository. It saves all files by recreating the folder\nstructure from the OSF in your download folder. Just install Papercheck, load\nthe library, and use the osf_file_download function to grab all files on the OSF:</span></p><p class=\"MsoNormal\"><span lang=\"EN-US\"><br /></span></p>\n\n<div style=\"text-align: left;\"><span style=\"font-family: courier;\"><b><span lang=\"EN-US\">devtools::install_github(\"scienceverse/papercheck\")<br /></span></b><b><span lang=\"EN-US\">library(papercheck)<br /></span></b><b><span lang=\"EN-US\">osf_file_download(\"6nt4v\")</span></b></span></div>\n\n\n\n\n\n<p class=\"MsoNormal\"><b><span lang=\"EN-US\">&nbsp;</span></b></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">All files\nwill be downloaded to your working directory. </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">Are you feeling\nFOMO for missing out on the <a href=\"https://www.kcl.ac.uk/events/open-research-summer-school-2025\">King Open\nResearch Summer School</a> that is going on these days, where <a href=\"https://research.tue.nl/en/persons/sajedeh-rasti\">Sajedeh Rasti</a> talked\nabout Preregistration, and <a href=\"https://research.tue.nl/en/persons/cristian-mesquida-caldentey\">Cristian\nMesquida</a> will give a workshop on using Papercheck? Well, at least it is\nvery easy to download all the files they have shared on the OSF and look at the\npresentations: </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\"><span style=\"font-family: courier;\">osf_file_download(\"b7es8\")</span></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">In the\noutput, we see that by default large files (more than 10mb) are omitted. <span><!--[if gte vml 1]><v:shape id=\"Picture_x0020_1\"\n o:spid=\"_x0000_i1025\" type=\"#_x0000_t75\" alt=\"A screenshot of a computer&#10;&#10;AI-generated content may be incorrect.\"\n style='width:453.75pt;height:292.5pt;visibility:visible;mso-wrap-style:square'>\n <v:imagedata src=\"file:///C:/Users/DLakens/AppData/Local/Temp/msohtmlclip1/01/clip_image003.png\"\n  o:title=\"A screenshot of a computer&#10;&#10;AI-generated content may be incorrect\"/>\n</v:shape><![endif]--><!--[if !vml]--><img alt=\"A screenshot of a computer\n\nAI-generated content may be incorrect.\" border=\"0\" height=\"390\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEj2jH76ywmEeLzL43u6gJl7GKR2lEGlhYS0LOXRPMMovOsJEVdXyamYCvmq96ez3p_GXHLoFz4JDyAKHlARK9pSy8QfzVa7yt1_uEg_H9IJfKgunnYWUwlROXABNcU6TvrA0_hx0KPZfj00b3Cb-Wn_7Bf3sFu9JApZoClcWoh_Vfl5bk1GQVZUH1tuGao\" width=\"605\" /><!--[endif]--></span></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">If you want\nto download all files, regardless of the size, then set the parameter to ignore\nthe maximum file size: </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\"><span style=\"font-family: courier;\">osf_file_download(\"b7es8\",\nmax_file_size = NULL)</span></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">Sometimes\nyou might want to download all files but ignore the file structure on the OSF,\nto just have all the files in one folder. Setting the parameter ignore_folder_structure\n= TRUE will give you all the files on the OSF in a single folder. By default, files will be downloaded into your working directory, but you can also specify\nwhere you want the files to be saved. </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\"><span style=\"font-family: courier;\">osf_file_download(\"6nt4v\",\nignore_folder_structure = TRUE, download_to = \"C:\\\\test_download\")</span></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">We hope\nthis function will make it easier for reviewers to access all supplementary\nfiles stored on the OSF during peer review, and for researchers who want to re-use\ndata, code, or materials shared on the OSF by downloading all the files they\nneed easily. Make sure to install the latest version of Papercheck (0.0.0.9050)\nto get access to this new function. Papercheck is still in active development,\nso report any bugs on <a href=\"https://github.com/scienceverse/papercheck\">GitHub</a>.</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>",
      "author": "noreply@blogger.com (Daniel Lakens)",
      "published_date": "2025-07-22T09:53:00+00:00",
      "source": "Twenty Percent Statistician",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 765,
      "reading_time": 3,
      "created_at": "2025-12-16T15:46:50.028623+00:00",
      "updated_at": "2025-12-16T16:22:28.431832+00:00",
      "metadata": {
        "processed_at": "2025-12-16T16:22:28.431840+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "5cf06dd1c8477abb17ef4e5c3b5426e0",
      "url": "https://erpinfo.org/blog/2021/12/22/applications-2023",
      "title": "Applications now being accepted for UC-Davis/SDSU ERP Boot Camp, July 31 \u2013 August 9, 2023",
      "content": "<p class=\"\">The next 10-day ERP Boot Camp will be held July 31 \u2013 August 9, 2023 in San Diego, California. We are now taking applications, which will be due by April 1, 2023. <a href=\"https://erpinfo.org/summer-boot-camp\">Click here</a> for more information.</p><p class=\"\">We are currently planning to hold this workshop as an in-person event. However, these plans are subject to change as the COVID-19 pandemic evolves. If the event is held in person, we will require that everyone is fully vaccinated, and we will also implement any other safety measures that are warranted at the time of the workshop.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"980\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/1609175691205-RTD3XM69YGOFMVP23U6T/Boot_Camp_Logo.png?format=1000w\" width=\"1148\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>",
      "author": "Steve Luck",
      "published_date": "2023-01-16T18:31:57+00:00",
      "source": "Erp Boot Camp",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 108,
      "reading_time": 1,
      "created_at": "2025-12-16T15:46:47.560564+00:00",
      "updated_at": "2025-12-16T16:22:28.431846+00:00",
      "metadata": {
        "processed_at": "2025-12-16T16:22:28.431849+00:00",
        "processing_method": "github_actions"
      }
    }
  ]
}