{
  "last_updated": "2025-09-11T04:24:17.257730+00:00",
  "count": 20,
  "articles": [
    {
      "id": "6a78ace4c736083f37ec2330b4f03b5f",
      "url": "https://arxiv.org/abs/2509.08539",
      "title": "Motion-Based User Identification across XR and Metaverse Applications by Deep Classification and Similarity Learning",
      "content": "arXiv:2509.08539v1 Announce Type: new \nAbstract: This paper examines the generalization capacity of two state-of-the-art classification and similarity learning models in reliably identifying users based on their motions in various Extended Reality (XR) applications. We developed a novel dataset containing a wide range of motion data from 49 users in five different XR applications: four XR games with distinct tasks and action patterns, and an additional social XR application with no predefined task sets. The dataset is used to evaluate the performance and, in particular, the generalization capacity of the two models across applications. Our results indicate that while the models can accurately identify individuals within the same application, their ability to identify users across different XR applications remains limited. Overall, our results provide insight into current models generalization capabilities and suitability as biometric methods for user verification and identification. The results also serve as a much-needed risk assessment of hazardous and unwanted user identification in XR and Metaverse applications. Our cross-application XR motion dataset and code are made available to the public to encourage similar research on the generalization of motion-based user identification in typical Metaverse application use cases.",
      "author": "Lukas Schach, Christian Rack, Ryan P. McMahan, Marc Erich Latoschik",
      "published_date": "2025-09-11T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 189,
      "reading_time": 1,
      "created_at": "2025-09-11T04:23:56.618091+00:00",
      "updated_at": "2025-09-11T04:23:56.618092+00:00"
    },
    {
      "id": "cbca39a58874b315212cdaef9205bfc0",
      "url": "https://arxiv.org/abs/2509.08514",
      "title": "Bias in the Loop: How Humans Evaluate AI-Generated Suggestions",
      "content": "arXiv:2509.08514v1 Announce Type: new \nAbstract: Human-AI collaboration increasingly drives decision-making across industries, from medical diagnosis to content moderation. While AI systems promise efficiency gains by providing automated suggestions for human review, these workflows can trigger cognitive biases that degrade performance. We know little about the psychological factors that determine when these collaborations succeed or fail. We conducted a randomized experiment with 2,784 participants to examine how task design and individual characteristics shape human responses to AI-generated suggestions. Using a controlled annotation task, we manipulated three factors: AI suggestion quality in the first three instances, task burden through required corrections, and performance-based financial incentives. We collected demographics, attitudes toward AI, and behavioral data to assess four performance metrics: accuracy, correction activity, overcorrection, and undercorrection. Two patterns emerged that challenge conventional assumptions about human-AI collaboration. First, requiring corrections for flagged AI errors reduced engagement and increased the tendency to accept incorrect suggestions, demonstrating how cognitive shortcuts influence collaborative outcomes. Second, individual attitudes toward AI emerged as the strongest predictor of performance, surpassing demographic factors. Participants skeptical of AI detected errors more reliably and achieved higher accuracy, while those favorable toward automation exhibited dangerous overreliance on algorithmic suggestions. The findings reveal that successful human-AI collaboration depends not only on algorithmic performance but also on who reviews AI outputs and how review processes are structured. Effective human-AI collaborations require consideration of human psychology: selecting diverse evaluator samples, measuring attitudes, and designing workflows that counteract cognitive biases.",
      "author": "Jacob Beck, Stephanie Eckman, Christoph Kern, Frauke Kreuter",
      "published_date": "2025-09-11T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 242,
      "reading_time": 1,
      "created_at": "2025-09-11T04:23:56.618060+00:00",
      "updated_at": "2025-09-11T04:23:56.618061+00:00"
    },
    {
      "id": "7c61ff75c8a5a742af2ce4e8c7c0f204",
      "url": "https://arxiv.org/abs/2509.08459",
      "title": "Printegrated Circuits: Personal Fabrication of 3D Printed Devices with Embedded PCBs",
      "content": "arXiv:2509.08459v1 Announce Type: new \nAbstract: Consumer-level multi-material 3D printing with conductive thermoplastics enables fabrication of interactive elements for bespoke tangible devices. However, large feature sizes, high resistance materials, and limitations of printable control circuitry mean that deployable devices cannot be printed without post-print assembly steps. To address these challenges, we present Printegrated Circuits, a technique that uses traditional electronics as material to 3D print self-contained interactive objects. Embedded PCBs are placed into recesses during a pause in the print, and through a process we term \\textit{Prinjection}, conductive filament is injected into their plated-through holes. This automatically creates reliable electrical and mechanical contact, eliminating the need for manual wiring or bespoke connectors. We describe the custom machine code generation that supports our approach, and characterise its electrical and mechanical properties. With our 6 demonstrations, we highlight how the Printegrated Circuits process fits into existing design and prototyping workflows as well as informs future research agendas.",
      "author": "Oliver Child, Ollie Hanton, Jack Dawson, Steve Hodges, Mike Fraser",
      "published_date": "2025-09-11T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 154,
      "reading_time": 1,
      "created_at": "2025-09-11T04:23:56.618019+00:00",
      "updated_at": "2025-09-11T04:23:56.618021+00:00"
    },
    {
      "id": "dd9ecfa353dbf5c36757a8d7874f519c",
      "url": "https://arxiv.org/abs/2509.08444",
      "title": "GlyphWeaver: Unlocking Glyph Design Creativity with Uniform Glyph DSL and AI",
      "content": "arXiv:2509.08444v1 Announce Type: new \nAbstract: Expressive glyph visualizations provide a powerful and versatile means to represent complex multivariate data through compact visual encodings, but creating custom glyphs remains challenging due to the gap between design creativity and technical implementation. We present GlyphWeaver, a novel interactive system to enable an easy creation of expressive glyph visualizations. Our system comprises three key components: a glyph domain-specific language (GDSL), a GDSL operation management mechanism, and a multimodal interaction interface. The GDSL is a hierarchical container model, where each container is independent and composable, providing a rigorous yet practical foundation for complex glyph visualizations. The operation management mechanism restricts modifications of the GDSL to atomic operations, making it accessible without requiring direct coding. The multimodal interaction interface enables direct manipulation, natural language commands, and parameter adjustments. A multimodal large language model acts as a translator, converting these inputs into GDSL operations. GlyphWeaver significantly lowers the barrier for designers, who often do not have extensive programming skills, to create sophisticated glyph visualizations. A case study and user interviews with 13 participants confirm its substantial gains in design efficiency and effectiveness of producing creative glyph visualizations.",
      "author": "Can Liu, Shiwei Chen, Zhibang Jiang, Yong Wang",
      "published_date": "2025-09-11T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 190,
      "reading_time": 1,
      "created_at": "2025-09-11T04:23:56.617990+00:00",
      "updated_at": "2025-09-11T04:23:56.617992+00:00"
    },
    {
      "id": "d465e969e01804609fdff1762cfcc021",
      "url": "https://arxiv.org/abs/2509.08404",
      "title": "HyperMOOC: Augmenting MOOC Videos with Concept-based Embedded Visualizations",
      "content": "arXiv:2509.08404v1 Announce Type: new \nAbstract: Massive Open Online Courses (MOOCs) have become increasingly popular worldwide. However, learners primarily rely on watching videos, easily losing knowledge context and reducing learning effectiveness. We propose HyperMOOC, a novel approach augmenting MOOC videos with concept-based embedded visualizations to help learners maintain knowledge context. Informed by expert interviews and literature review, HyperMOOC employs multi-glyph designs for different knowledge types and multi-stage interactions for deeper understanding. Using a timeline-based radial visualization, learners can grasp cognitive paths of concepts and navigate courses through hyperlink-based interactions. We evaluated HyperMOOC through a user study with 36 MOOC learners and interviews with two instructors. Results demonstrate that HyperMOOC enhances learners' learning effect and efficiency on MOOCs, with participants showing higher satisfaction and improved course understanding compared to traditional video-based learning approaches.",
      "author": "Li Ye, Lei Wang, Lihong Cai, Ruiqi Yu, Yong Wang, Yigang Wang, Wei Chen, Zhiguang Zhou",
      "published_date": "2025-09-11T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 131,
      "reading_time": 1,
      "created_at": "2025-09-11T04:23:56.617959+00:00",
      "updated_at": "2025-09-11T04:23:56.617960+00:00"
    },
    {
      "id": "676bc1789355a4f0ef520e6bc6804f07",
      "url": "https://arxiv.org/abs/2509.08357",
      "title": "Personalized Inhibition Training with Eye-Tracking: Enhancing Student Learning and Teacher Assessment in Educational Games",
      "content": "arXiv:2509.08357v1 Announce Type: new \nAbstract: Eye tracking (ET) can help to understand visual attention and cognitive processes in interactive environments. This study presents a comprehensive eye-tracking analysis framework of the Inhibitory Control Game, named the ReStroop game, which is an educational intervention aimed at improving inhibitory control skills in children through a recycling-themed sorting task, for educational assessment that processes raw gaze data through unified algorithms for fixation detection, performance evaluation, and personalized intervention planning. The system employs dual-threshold eye movement detection (I-VT and advanced clustering), comprehensive Area of Interest (AOI) analysis, and evidence-based risk assessment to transform gaze patterns into actionable educational insights. We evaluated this framework across three difficulty levels and revealed critical attention deficits, including low task relevance, elevated attention scatter, and compromised processing efficiency. The multi-dimensional risk assessment identified high to moderate risk levels, triggering personalized interventions including focus training, attention regulation support, and environmental modifications. The system successfully distinguishes between adaptive learning and cognitive overload, providing early warning indicators for educational intervention. Results demonstrate the system's effectiveness in objective attention assessment, early risk identification, and the generation of evidence-based recommendations for students, teachers, and specialists, supporting data-driven educational decision-making and personalized learning approaches.",
      "author": "Abdul Rehman, Ilona Heldal, Diana Stilwell, Paula Costa Ferreira, Jerry Chun-Wei Lin",
      "published_date": "2025-09-11T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 198,
      "reading_time": 1,
      "created_at": "2025-09-11T04:23:56.617931+00:00",
      "updated_at": "2025-09-11T04:23:56.617933+00:00"
    },
    {
      "id": "d2244f0e0693fcf44adc5a52ed33f34f",
      "url": "https://arxiv.org/abs/2509.08353",
      "title": "An Adaptive Scoring Framework for Attention Assessment in NDD Children via Serious Games",
      "content": "arXiv:2509.08353v1 Announce Type: new \nAbstract: This paper introduces an innovative adaptive scoring framework for children with Neurodevelopmental Disorders (NDD) that is attributed to the integration of multiple metrics, such as spatial attention patterns, temporal engagement, and game performance data, to create a comprehensive assessment of learning that goes beyond traditional game scoring. The framework employs a progressive difficulty adaptation method, which focuses on specific stimuli for each level and adjusts weights dynamically to accommodate increasing cognitive load and learning complexity. Additionally, it includes capabilities for temporal analysis, such as detecting engagement periods, providing rewards for sustained attention, and implementing an adaptive multiplier framework based on performance levels. To avoid over-rewarding high performers while maximizing improvement potential for students who are struggling, the designed framework features an adaptive temporal impact framework that adjusts performance scales accordingly. We also established a multi-metric validation framework using Mean Absolute Error (MAE), Root Mean Square Error (RMSE), Pearson correlation, and Spearman correlation, along with defined quality thresholds for assessing deployment readiness in educational settings. This research bridges the gap between technical eye-tracking metrics and educational insights by explicitly mapping attention patterns to learning behaviors, enabling actionable pedagogical interventions.",
      "author": "Abdul Rehman, Ilona Heldal, Cristina Costescu, Carmen David, Jerry Chun-Wei Lin",
      "published_date": "2025-09-11T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 193,
      "reading_time": 1,
      "created_at": "2025-09-11T04:23:56.617899+00:00",
      "updated_at": "2025-09-11T04:23:56.617900+00:00"
    },
    {
      "id": "f1ef1c9951f379b8d956def045981115",
      "url": "https://arxiv.org/abs/2509.08213",
      "title": "A Priest, a Rabbi, and an Atheist Walk Into an Error Bar: Religious Meditations on Uncertainty Visualization",
      "content": "arXiv:2509.08213v1 Announce Type: new \nAbstract: In this provocation, we suggest that much (although not all) current uncertainty visualization simplifies the myriad forms of uncertainty into error bars around an estimate. This apparent simplification into error bars comes only as a result of a vast metaphysics around uncertainty and probability underlying modern statistics. We use examples from religion to present alternative views of uncertainty (metaphysical or otherwise) with the goal of enriching our conception of what kind of uncertainties we ought to visualize, and what kinds of people we might be visualizing those uncertainties for.",
      "author": "Michael Correll, Lane Harrison",
      "published_date": "2025-09-11T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 94,
      "reading_time": 1,
      "created_at": "2025-09-11T04:23:56.617866+00:00",
      "updated_at": "2025-09-11T04:23:56.617868+00:00"
    },
    {
      "id": "fc92b8c2d5d2154ede7b5d5bfa022bdb",
      "url": "https://arxiv.org/abs/2509.08203",
      "title": "Componentization: Decomposing Monolithic LLM Responses into Manipulable Semantic Units",
      "content": "arXiv:2509.08203v1 Announce Type: new \nAbstract: Large Language Models (LLMs) often produce monolithic text that is hard to edit in parts, which can slow down collaborative workflows. We present componentization, an approach that decomposes model outputs into modular, independently editable units while preserving context. We describe Modular and Adaptable Output Decomposition (MAOD), which segments responses into coherent components and maintains links among them, and we outline the Component-Based Response Architecture (CBRA) as one way to implement this idea. Our reference prototype, MAODchat, uses a microservices design with state-machine-based decomposition agents, vendor-agnostic model adapters, and real-time component manipulation with recomposition.\n  In an exploratory study with four participants from academic, engineering, and product roles, we observed that component-level editing aligned with several common workflows and enabled iterative refinement and selective reuse. Participants also mentioned possible team workflows. Our contributions are: (1) a definition of componentization for transforming monolithic outputs into manipulable units, (2) CBRA and MAODchat as a prototype architecture, (3) preliminary observations from a small user study, (4) MAOD as an algorithmic sketch for semantic segmentation, and (5) example Agent-to-Agent protocols for automated decomposition. We view componentization as a promising direction for turning passive text consumption into more active, component-level collaboration.",
      "author": "Ryan Lingo, Rajeev Chhajer, Martin Arroyo, Luka Brkljacic, Ben Davis, Nithin Santhanam",
      "published_date": "2025-09-11T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 199,
      "reading_time": 1,
      "created_at": "2025-09-11T04:23:56.617840+00:00",
      "updated_at": "2025-09-11T04:23:56.617842+00:00"
    },
    {
      "id": "570efa6f363544b569e7e449b757fe43",
      "url": "https://arxiv.org/abs/2509.08108",
      "title": "Understanding the Video Content Creation Journey of Creators with Sensory Impairment in Kenya",
      "content": "arXiv:2509.08108v1 Announce Type: new \nAbstract: Video content creation offers vital opportunities for expression and participation, yet remains largely inaccessible to creators with sensory impairments, especially in low-resource settings. We conducted interviews with 20 video creators with visual and hearing impairments in Kenya to examine their tools, challenges, and collaborative practices. Our findings show that accessibility barriers and infrastructural limitations shape video creation as a staged, collaborative process involving trusted human partners and emerging AI tools. Across workflows, creators actively negotiated agency and trust, maintaining creative control while bridging sensory gaps. We discuss the need for flexible, interdependent collaboration models, inclusive human-AI workflows, and diverse storytelling practices. This work broadens accessibility research in HCI by examining how technology and social factors intersect in low-resource contexts, suggesting ways to better support disabled creators globally.",
      "author": "Lan Xiao, Maryam Bandukda, Franklin Mingzhe Li, Mark Colley, Catherine Holloway",
      "published_date": "2025-09-11T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 132,
      "reading_time": 1,
      "created_at": "2025-09-11T04:23:56.617797+00:00",
      "updated_at": "2025-09-11T04:23:56.617801+00:00"
    },
    {
      "id": "e1171c53fdb22efae2cbee26718893f5",
      "url": "https://arxiv.org/abs/2306.13802",
      "title": "Using topological data analysis to compare inter-subject variability across resting state functional MRI brain representations",
      "content": "arXiv:2306.13802v3 Announce Type: replace-cross \nAbstract: In neuroimaging, extensive post-processing of resting-state functional MRI (rfMRI) data is necessary for its application and investigation in relation to brain-behavior associations. Such post-processing is used to derive brain representations, lower dimensional feature sets used for brain-behavior association studies. A brain representation involves a choice of dimension reduction (a parcellation into regions or networks) and a choice of feature type, such as spatial topography, connectivity matrix, amplitude. However, widespread variability in rfMRI brain representations has hindered both reproducibility and knowledge accumulation across the field. Brain representation choice effects measurements of inter-subject variability, which muddies the comparison and integration of findings. We leveraged persistent homology on the subject-space topologies induced by 34 different brain representations to enable direct comparison of brain representations in the context of individual differences. Our findings reveal the importance of considering feature type when comparing results derived from different brain representations, suggesting best practices for assessing the replicability and generalizability of brain-behavior research in rfMRI data.",
      "author": "Ty Easley, Kevin Freese, Elizabeth Munch, Janine Bijsterbosch",
      "published_date": "2025-09-11T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 164,
      "reading_time": 1,
      "created_at": "2025-09-11T04:23:55.485529+00:00",
      "updated_at": "2025-09-11T04:23:55.485531+00:00"
    },
    {
      "id": "7f02bf86f51ffecf7e6b74d7cc41e6e9",
      "url": "https://arxiv.org/abs/2509.06810",
      "title": "Reward function compression facilitates goal-dependent reinforcement learning",
      "content": "arXiv:2509.06810v2 Announce Type: replace \nAbstract: Reinforcement learning agents learn from rewards, but humans can uniquely assign value to novel, abstract outcomes in a goal-dependent manner. However, this flexibility is cognitively costly, making learning less efficient. Here, we propose that goal-dependent learning is initially supported by a capacity-limited working memory system. With consistent experience, learners create a \"compressed\" reward function (a simplified rule defining the goal) which is then transferred to long-term memory and applied automatically upon receiving feedback. This process frees up working memory resources, boosting learning efficiency. We test this theory across six experiments. Consistent with our predictions, our findings demonstrate that learning is parametrically impaired by the size of the goal space, but improves when the goal space structure allows for compression. We also find faster reward processing to correlate with better learning performance, supporting the idea that as goal valuation becomes more automatic, more resources are available for learning. We leverage computational modeling to support this interpretation. Our work suggests that efficient goal-directed learning relies on compressing complex goal information into a stable reward function, shedding light on the cognitive mechanisms of human motivation. These findings generate new insights into the neuroscience of intrinsic motivation and could help improve behavioral techniques that support people in achieving their goals.",
      "author": "Gaia Molinaro, Anne G. E. Collins",
      "published_date": "2025-09-11T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 211,
      "reading_time": 1,
      "created_at": "2025-09-11T04:23:55.485469+00:00",
      "updated_at": "2025-09-11T04:23:55.485470+00:00"
    },
    {
      "id": "46025760cff1cabf2e37d70360a9c3ec",
      "url": "https://arxiv.org/abs/2503.06286",
      "title": "A 7T fMRI dataset of synthetic images for out-of-distribution modeling of vision",
      "content": "arXiv:2503.06286v2 Announce Type: replace \nAbstract: Large-scale datasets of brain responses such as the Natural Scenes Dataset (NSD) are boosting computational neuroscience research by enabling models of the brain with performances beyond what was possible just a decade ago. However, these datasets lack out-of-distribution (OOD) components, which are crucial for the development of more robust models. Here, we address this limitation by releasing NSD-synthetic, a dataset consisting of 7T fMRI responses from the same eight NSD participants for 284 synthetic images. We show that NSD-synthetic's fMRI responses reliably encode stimulus-related information and are OOD with respect to NSD. Furthermore, we provide a proof of principle that OOD generalization tests on NSD-synthetic reveal differences between models of the brain that are not detected with the original NSD data; we demonstrate that the degree of OOD (quantified as the distance between a set of responses and the training data used for modeling) is predictive of the magnitude of model failures; and we show that the concept of OOD is not restricted to artificial stimuli but can be usefully applied even within the domain of naturalistic stimuli. These results showcase how NSD-synthetic enables OOD generalization tests that facilitate the development of more robust models of visual processing and the formulation of more accurate theories of human vision.",
      "author": "Alessandro T. Gifford, Radoslaw M. Cichy, Thomas Naselaris, Kendrick Kay",
      "published_date": "2025-09-11T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 213,
      "reading_time": 1,
      "created_at": "2025-09-11T04:23:55.485436+00:00",
      "updated_at": "2025-09-11T04:23:55.485437+00:00"
    },
    {
      "id": "b97b6c8cdb5bdfa2aff53d9a69a0cacf",
      "url": "https://arxiv.org/abs/2509.08779",
      "title": "ADHDeepNet From Raw EEG to Diagnosis: Improving ADHD Diagnosis through Temporal-Spatial Processing, Adaptive Attention Mechanisms, and Explainability in Raw EEG Signals",
      "content": "arXiv:2509.08779v1 Announce Type: cross \nAbstract: Attention Deficit Hyperactivity Disorder (ADHD) is a common brain disorder in children that can persist into adulthood, affecting social, academic, and career life. Early diagnosis is crucial for managing these impacts on patients and the healthcare system but is often labor-intensive and time-consuming. This paper presents a novel method to improve ADHD diagnosis precision and timeliness by leveraging Deep Learning (DL) approaches and electroencephalogram (EEG) signals. We introduce ADHDeepNet, a DL model that utilizes comprehensive temporal-spatial characterization, attention modules, and explainability techniques optimized for EEG signals. ADHDeepNet integrates feature extraction and refinement processes to enhance ADHD diagnosis. The model was trained and validated on a dataset of 121 participants (61 ADHD, 60 Healthy Controls), employing nested cross-validation for robust performance. The proposed two-stage methodology uses a 10-fold cross-subject validation strategy. Initially, each iteration optimizes the model's hyper-parameters with inner 2-fold cross-validation. Then, Additive Gaussian Noise (AGN) with various standard deviations and magnification levels is applied for data augmentation. ADHDeepNet achieved 100% sensitivity and 99.17% accuracy in classifying ADHD/HC subjects. To clarify model explainability and identify key brain regions and frequency bands for ADHD diagnosis, we analyzed the learned weights and activation patterns of the model's primary layers. Additionally, t-distributed Stochastic Neighbor Embedding (t-SNE) visualized high-dimensional data, aiding in interpreting the model's decisions. This study highlights the potential of DL and EEG in enhancing ADHD diagnosis accuracy and efficiency.",
      "author": "Ali Amini, Mohammad Alijanpour, Behnam Latifi, Ali Motie Nasrabadi",
      "published_date": "2025-09-11T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 233,
      "reading_time": 1,
      "created_at": "2025-09-11T04:23:55.485403+00:00",
      "updated_at": "2025-09-11T04:23:55.485405+00:00"
    },
    {
      "id": "cfe7e03f4a5f0f377b53f6df8e972abd",
      "url": "https://arxiv.org/abs/2509.08442",
      "title": "Spherical Brownian Bridge Diffusion Models for Conditional Cortical Thickness Forecasting",
      "content": "arXiv:2509.08442v1 Announce Type: cross \nAbstract: Accurate forecasting of individualized, high-resolution cortical thickness (CTh) trajectories is essential for detecting subtle cortical changes, providing invaluable insights into neurodegenerative processes and facilitating earlier and more precise intervention strategies. However, CTh forecasting is a challenging task due to the intricate non-Euclidean geometry of the cerebral cortex and the need to integrate multi-modal data for subject-specific predictions. To address these challenges, we introduce the Spherical Brownian Bridge Diffusion Model (SBDM). Specifically, we propose a bidirectional conditional Brownian bridge diffusion process to forecast CTh trajectories at the vertex level of registered cortical surfaces. Our technical contribution includes a new denoising model, the conditional spherical U-Net (CoS-UNet), which combines spherical convolutions and dense cross-attention to integrate cortical surfaces and tabular conditions seamlessly. Compared to previous approaches, SBDM achieves significantly reduced prediction errors, as demonstrated by our experiments based on longitudinal datasets from the ADNI and OASIS. Additionally, we demonstrate SBDM's ability to generate individual factual and counterfactual CTh trajectories, offering a novel framework for exploring hypothetical scenarios of cortical development.",
      "author": "Ivan Stoyanov, Fabian Bongratz, Christian Wachinger",
      "published_date": "2025-09-11T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 173,
      "reading_time": 1,
      "created_at": "2025-09-11T04:23:55.485367+00:00",
      "updated_at": "2025-09-11T04:23:55.485369+00:00"
    },
    {
      "id": "24c94d857030488e43b0e7090c4fcd4f",
      "url": "https://arxiv.org/abs/2509.08188",
      "title": "ArtifactGen: Benchmarking WGAN-GP vs Diffusion for Label-Aware EEG Artifact Synthesis",
      "content": "arXiv:2509.08188v1 Announce Type: cross \nAbstract: Artifacts in electroencephalography (EEG) -- muscle, eye movement, electrode, chewing, and shiver -- confound automated analysis yet are costly to label at scale. We study whether modern generative models can synthesize realistic, label-aware artifact segments suitable for augmentation and stress-testing. Using the TUH EEG Artifact (TUAR) corpus, we curate subject-wise splits and fixed-length multi-channel windows (e.g., 250 samples) with preprocessing tailored to each model (per-window min--max for adversarial training; per-recording/channel $z$-score for diffusion). We compare a conditional WGAN-GP with a projection discriminator to a 1D denoising diffusion model with classifier-free guidance, and evaluate along three axes: (i) fidelity via Welch band-power deltas ($\\Delta\\delta,\\ \\Delta\\theta,\\ \\Delta\\alpha,\\ \\Delta\\beta$), channel-covariance Frobenius distance, autocorrelation $L_2$, and distributional metrics (MMD/PRD); (ii) specificity via class-conditional recovery with lightweight $k$NN/classifiers; and (iii) utility via augmentation effects on artifact recognition. In our setting, WGAN-GP achieves closer spectral alignment and lower MMD to real data, while both models exhibit weak class-conditional recovery, limiting immediate augmentation gains and revealing opportunities for stronger conditioning and coverage. We release a reproducible pipeline -- data manifests, training configurations, and evaluation scripts -- to establish a baseline for EEG artifact synthesis and to surface actionable failure modes for future work.",
      "author": "Hritik Arasu, Faisal R Jahangiri",
      "published_date": "2025-09-11T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 201,
      "reading_time": 1,
      "created_at": "2025-09-11T04:23:55.485336+00:00",
      "updated_at": "2025-09-11T04:23:55.485337+00:00"
    },
    {
      "id": "8a344c71ff23f0f479f09609d969aba5",
      "url": "https://arxiv.org/abs/2509.08179",
      "title": "Computational modelling of Parkinson's disease: A multiscale approach with deep brain stimulation and stochastic noise",
      "content": "arXiv:2509.08179v1 Announce Type: new \nAbstract: Multiscale modelling presents a multifaceted perspective into understanding the mechanisms of the brain and how neurodegenerative disorders like Parkinson's disease (PD) manifest and evolve over time. In this study, we propose a novel co-simulation multiscale approach that unifies both micro- and macroscales to more rigorously capture brain dynamics. The presented design considers the electrodiffusive activity across the brain and in the network defined by the cortex, basal ganglia, and thalamus that is implicated in the mechanics of PD, as well as the contribution of presynaptic inputs in the highlighted regions. The application of DBS and its effects, along with the inclusion of stochastic noise are also examined. We found that the thalamus exhibits large, fluctuating spiking in both the deterministic and stochastic conditions, suggesting that noise contributes primarily to neural variability, rather than driving the overall spiking activity. Ultimately, this work intends to provide greater insights into the dynamics of PD and the brain which can eventually be converted into clinical use.",
      "author": "Aaron Herrera, Hina Shaheen",
      "published_date": "2025-09-11T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 167,
      "reading_time": 1,
      "created_at": "2025-09-11T04:23:55.485301+00:00",
      "updated_at": "2025-09-11T04:23:55.485302+00:00"
    },
    {
      "id": "e7df058588ace873a58b225fdeb8c49b",
      "url": "https://arxiv.org/abs/2509.07999",
      "title": "The Computational Foundations of Collective Intelligence",
      "content": "arXiv:2509.07999v1 Announce Type: new \nAbstract: Why do collectives outperform individuals when solving some problems? Fundamentally, collectives have greater computational resources with more sensory information, more memory, more processing capacity, and more ways to act. While greater resources present opportunities, there are also challenges in coordination and cooperation inherent in collectives with distributed, modular structures. Despite these challenges, we show how collective resource advantages lead directly to well-known forms of collective intelligence including the wisdom of the crowd, collective sensing, division of labour, and cultural learning. Our framework also generates testable predictions about collective capabilities in distributed reasoning and context-dependent behavioural switching. Through case studies of animal navigation and decision-making, we demonstrate how collectives leverage their computational resources to solve problems not only more effectively than individuals, but by using qualitatively different problem-solving strategies.",
      "author": "Charlie Pilgrim, Joe Morford, Elizabeth Warren, M\\'elisande Aellen, Christopher Krupenye, Richard P Mann, Dora Biro",
      "published_date": "2025-09-11T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 133,
      "reading_time": 1,
      "created_at": "2025-09-11T04:23:55.485267+00:00",
      "updated_at": "2025-09-11T04:23:55.485270+00:00"
    },
    {
      "id": "ad5738689222789c16007914f43c49e6",
      "url": "https://arxiv.org/abs/2509.07991",
      "title": "DLGE: Dual Local-Global Encoding for Generalizable Cross-BCI-Paradigm",
      "content": "arXiv:2509.07991v1 Announce Type: new \nAbstract: Deep learning models have been frequently used to decode a single brain-computer interface (BCI) paradigm based on electroencephalography (EEG). It is challenging to decode multiple BCI paradigms using one model due to diverse barriers, such as different channel configurations and disparate task-related representations. In this study, we propose Dual Local-Global Encoder (DLGE), enabling the classification across different BCI paradigms. To address the heterogeneity in EEG channel configurations across paradigms, we employ an anatomically inspired brain-region partitioning and padding strategy to standardize EEG channel configuration. In the proposed model, the local encoder is designed to learn shared features across BCI paradigms within each brain region based on time-frequency information, which integrates temporal attention on individual channels with spatial attention among channels for each brain region. These shared features are subsequently aggregated in the global encoder to form respective paradigm-specific feature representations. Three BCI paradigms (motor imagery, resting state, and driving fatigue) were used to evaluate the proposed model. The results demonstrate that our model is capable of processing diverse BCI paradigms without retraining and retuning, achieving average macro precision, recall, and F1-score of 60.16\\%, 59.88\\%, and 59.56\\%, respectively. We made an initial attempt to develop a general model for cross-BCI-paradigm classification, avoiding retraining or redevelopment for each paradigm. This study paves the way for the development of an effective but simple model for cross-BCI-paradigm decoding, which might benefit the design of portable devices for universal BCI decoding.",
      "author": "Jingyuan Wang, Junhua Li",
      "published_date": "2025-09-11T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 241,
      "reading_time": 1,
      "created_at": "2025-09-11T04:23:55.485217+00:00",
      "updated_at": "2025-09-11T04:23:55.485221+00:00"
    },
    {
      "id": "96b7d9231d304b2696790e52c347c6d4",
      "url": "http://www.jneurosci.org/cgi/content/short/45/36/etwij45362025?rss=1",
      "title": "This Week in The Journal",
      "content": "",
      "author": "McKeon, P.",
      "published_date": "2025-09-03T16:30:27+00:00",
      "source": "Journal Neuroscience This Week",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-09-11T04:23:41.570526+00:00",
      "updated_at": "2025-09-11T04:23:41.570531+00:00"
    }
  ]
}