{
  "last_updated": "2025-11-03T23:20:09.773313+00:00",
  "count": 20,
  "articles": [
    {
      "id": "132617f2b94f5ea5b582533813eac545",
      "url": "https://arxiv.org/abs/2510.27247",
      "title": "Reconstructing Unseen Sentences from Speech-related Biosignals for Open-vocabulary Neural Communication",
      "content": "arXiv:2510.27247v1 Announce Type: new \nAbstract: Brain-to-speech (BTS) systems represent a groundbreaking approach to human communication by enabling the direct transformation of neural activity into linguistic expressions. While recent non-invasive BTS studies have largely focused on decoding predefined words or sentences, achieving open-vocabulary neural communication comparable to natural human interaction requires decoding unconstrained speech. Additionally, effectively integrating diverse signals derived from speech is crucial for developing personalized and adaptive neural communication and rehabilitation solutions for patients. This study investigates the potential of speech synthesis for previously unseen sentences across various speech modes by leveraging phoneme-level information extracted from high-density electroencephalography (EEG) signals, both independently and in conjunction with electromyography (EMG) signals. Furthermore, we examine the properties affecting phoneme decoding accuracy during sentence reconstruction and offer neurophysiological insights to further enhance EEG decoding for more effective neural communication solutions. Our findings underscore the feasibility of biosignal-based sentence-level speech synthesis for reconstructing unseen sentences, highlighting a significant step toward developing open-vocabulary neural communication systems adapted to diverse patient needs and conditions. Additionally, this study provides meaningful insights into the development of communication and rehabilitation solutions utilizing EEG-based decoding technologies.",
      "author": "Deok-Seon Kim, Seo-Hyun Lee, Kang Yin, Seong-Whan Lee",
      "published_date": "2025-11-03T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 186,
      "reading_time": 1,
      "created_at": "2025-11-03T23:19:48.645354+00:00",
      "updated_at": "2025-11-03T23:19:48.645355+00:00"
    },
    {
      "id": "28da4e96a6cfa2767843c8adecf8847c",
      "url": "https://arxiv.org/abs/2510.27126",
      "title": "AURA: A Reinforcement Learning Framework for AI-Driven Adaptive Conversational Surveys",
      "content": "arXiv:2510.27126v1 Announce Type: new \nAbstract: Conventional online surveys provide limited personalization, often resulting in low engagement and superficial responses. Although AI survey chatbots improve convenience, most are still reactive: they rely on fixed dialogue trees or static prompt templates and therefore cannot adapt within a session to fit individual users, which leads to generic follow-ups and weak response quality. We address these limitations with AURA (Adaptive Understanding through Reinforcement Learning for Assessment), a reinforcement learning framework for AI-driven adaptive conversational surveys. AURA quantifies response quality using a four-dimensional LSDE metric (Length, Self-disclosure, Emotion, and Specificity) and selects follow-up question types via an epsilon-greedy policy that updates the expected quality gain within each session. Initialized with priors extracted from 96 prior campus-climate conversations (467 total chatbot-user exchanges), the system balances exploration and exploitation across 10-15 dialogue exchanges, dynamically adapting to individual participants in real time. In controlled evaluations, AURA achieved a +0.12 mean gain in response quality and a statistically significant improvement over non-adaptive baselines (p=0.044, d=0.66), driven by a 63% reduction in specification prompts and a 10x increase in validation behavior. These results demonstrate that reinforcement learning can give survey chatbots improved adaptivity, transforming static questionnaires into interactive, self-improving assessment systems.",
      "author": "Jinwen Tang, Yi Shang",
      "published_date": "2025-11-03T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 201,
      "reading_time": 1,
      "created_at": "2025-11-03T23:19:48.645323+00:00",
      "updated_at": "2025-11-03T23:19:48.645324+00:00"
    },
    {
      "id": "7f0c72e3347a62e3075d23e89fa41f13",
      "url": "https://arxiv.org/abs/2510.27075",
      "title": "Functional connectivity guided deep neural network for decoding high-level visual imagery",
      "content": "arXiv:2510.27075v1 Announce Type: new \nAbstract: This study introduces a pioneering approach in brain-computer interface (BCI) technology, featuring our novel concept of high-level visual imagery for non-invasive electroencephalography (EEG)-based communication. High-level visual imagery, as proposed in our work, involves the user engaging in the mental visualization of complex upper limb movements. This innovative approach significantly enhances the BCI system, facilitating the extension of its applications to more sophisticated tasks such as EEG-based robotic arm control. By leveraging this advanced form of visual imagery, our study opens new horizons for intricate and intuitive mind-controlled interfaces. We developed an advanced deep learning architecture that integrates functional connectivity metrics with a convolutional neural network-image transformer. This framework is adept at decoding subtle user intentions, addressing the spatial variability in high-level visual tasks, and effectively translating these into precise commands for robotic arm control. Our comprehensive offline and pseudo-online evaluations demonstrate the framework's efficacy in real-time applications, including the nuanced control of robotic arms. The robustness of our approach is further validated through leave-one-subject-out cross-validation, marking a significant step towards versatile, subject-independent BCI applications. This research highlights the transformative impact of advanced visual imagery and deep learning in enhancing the usability and adaptability of BCI systems, particularly in robotic arm manipulation.",
      "author": "Byoung-Hee Kwon, Minji Lee, Seong-Whan Lee",
      "published_date": "2025-11-03T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 206,
      "reading_time": 1,
      "created_at": "2025-11-03T23:19:48.645290+00:00",
      "updated_at": "2025-11-03T23:19:48.645292+00:00"
    },
    {
      "id": "5f169c0079f6947abc058a09d38680da",
      "url": "https://arxiv.org/abs/2510.27058",
      "title": "Adaptive Human-Computer Interaction Strategies Through Reinforcement Learning in Complex",
      "content": "arXiv:2510.27058v1 Announce Type: new \nAbstract: This study addresses the challenges of dynamics and complexity in intelligent human-computer interaction and proposes a reinforcement learning-based optimization framework to improve long-term returns and overall experience. Human-computer interaction is modeled as a Markov decision process, with state space, action space, reward function, and discount factor defined to capture the dynamics of user input, system feedback, and interaction environment. The method combines policy function, value function, and advantage function, updates parameters through policy gradient, and continuously adjusts during interaction to balance immediate feedback and long-term benefits. To validate the framework, multimodal dialog and scene-aware datasets are used as the experimental platform, with multiple sensitivity experiments conducted on key factors such as discount factor, exploration rate decay, environmental noise, and data imbalance. Evaluation is carried out using cumulative reward, average episode reward, convergence speed, and task success rate. Results show that the proposed method outperforms existing approaches across several metrics, achieving higher task completion while maintaining strategy stability. Comparative experiments further confirm its advantages in interaction efficiency and long-term return, demonstrating the significant value of reinforcement learning in optimizing human-computer interaction.",
      "author": "Rui Liu, Yifan Zhuang, Runsheng Zhang",
      "published_date": "2025-11-03T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 185,
      "reading_time": 1,
      "created_at": "2025-11-03T23:19:48.645248+00:00",
      "updated_at": "2025-11-03T23:19:48.645250+00:00"
    },
    {
      "id": "f95c15971d8e7eb1742856d5b8cf3ca1",
      "url": "https://arxiv.org/abs/2510.26999",
      "title": "AIOT based Smart Education System: A Dual Layer Authentication and Context-Aware Tutoring Framework for Learning Environments",
      "content": "arXiv:2510.26999v1 Announce Type: new \nAbstract: The AIoT-Based Smart Education System integrates Artificial Intelligence and IoT to address persistent challenges in contemporary classrooms: attendance fraud, lack of personalization, student disengagement, and inefficient resource use. The unified platform combines four core modules: (1) a dual-factor authentication system leveraging RFID-based ID scans and WiFi verification for secure, fraud-resistant attendance; (2) an AI-powered assistant that provides real-time, context-aware support and dynamic quiz generation based on instructor-supplied materials; (3) automated test generators to streamline adaptive assessment and reduce administrative overhead; and (4) the EcoSmart Campus module, which autonomously regulates classroom lighting, air quality, and temperature using IoT sensors and actuators. Simulated evaluations demonstrate the system's effectiveness in delivering robust real-time monitoring, fostering inclusive engagement, preventing fraudulent practices, and supporting operational scalability. Collectively, the AIoT-Based Smart Education System offers a secure, adaptive, and efficient learning environment, providing a scalable blueprint for future educational innovation and improved student outcomes through the synergistic application of artificial intelligence and IoT technologies.",
      "author": "Adithya Neelakantan, Pratik Satpute, Prerna Shinde, Tejas Manjunatha Devang",
      "published_date": "2025-11-03T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 162,
      "reading_time": 1,
      "created_at": "2025-11-03T23:19:48.645209+00:00",
      "updated_at": "2025-11-03T23:19:48.645214+00:00"
    },
    {
      "id": "00f155be5f18ff0de0c92c12a984202d",
      "url": "https://arxiv.org/abs/2510.25998",
      "title": "Integrated Information Theory: A Consciousness-First Approach to What Exists",
      "content": "arXiv:2510.25998v2 Announce Type: replace \nAbstract: This overview of integrated information theory (IIT) emphasizes IIT's \"consciousness-first\" approach to what exists. Consciousness demonstrates to each of us that something exists--experience--and reveals its essential properties--the axioms of phenomenal existence. IIT formulates these properties operationally, yielding the postulates of physical existence. To exist intrinsically or absolutely, an entity must have cause-effect power upon itself, in a specific, unitary, definite and structured manner. IIT's explanatory identity claims that an entity's cause-effect structure accounts for all properties of an experience--essential and accidental--with no additional ingredients. These include the feeling of spatial extendedness, temporal flow, of objects binding general concepts with particular configurations of features, and of qualia such as colors and sounds. IIT's intrinsic ontology has implications for understanding meaning, perception, and free will, for assessing consciousness in patients, infants, other species, and artifacts, and for reassessing our place in nature.",
      "author": "Giulio Tononi, Melanie Boly",
      "published_date": "2025-11-03T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 145,
      "reading_time": 1,
      "created_at": "2025-11-03T23:19:47.568249+00:00",
      "updated_at": "2025-11-03T23:19:47.568251+00:00"
    },
    {
      "id": "91736a226890ae83546a878670eacf04",
      "url": "https://arxiv.org/abs/2501.04139",
      "title": "Anomalous contrast as an adaptive violation of the Talbot-Plateau law",
      "content": "arXiv:2501.04139v2 Announce Type: replace \nAbstract: Purpose: To better understand anomalous contrast mechanisms that allow flicker-fused stimuli to be visible even when they provide the same average luminance as background. Method: Stimulus flicker was used to elicit differential activation of ON and OFF retinal channels at frequencies above the flicker-fusion threshold. Providing balanced light energy to ON and OFF channels will normally cause the stimulus to vanish into the background. Results: We used ultra-brief bright pulses, combined with ultra-long dark pulses, to elicit \"anomalous contrast\" that rendered the stimulus visible, even though it had the same average luminance as the background. The duration and intensity of flicker components were varied to gain insight into the conditions that would elicit this effect. Conclusions: Anomalous contrast displays violated the Talbot-Plateau law, but in doing so, provided an adaptive way to register and signal contours that matched background luminance. These findings contribute additional details about this visual adaptation, and we discuss how the retinal circuitry provides for stimulus visibility.",
      "author": "Ernest Greene, Jack Morrison",
      "published_date": "2025-11-03T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 165,
      "reading_time": 1,
      "created_at": "2025-11-03T23:19:47.568220+00:00",
      "updated_at": "2025-11-03T23:19:47.568222+00:00"
    },
    {
      "id": "2fd3e0ad4e0cfdb509b43f78c4273bfe",
      "url": "https://arxiv.org/abs/2510.27366",
      "title": "A Sensing Whole Brain Zebrafish Foundation Model for Neuron Dynamics and Behavior",
      "content": "arXiv:2510.27366v1 Announce Type: new \nAbstract: Neural dynamics underlie behaviors from memory to sleep, yet identifying mechanisms for higher-order phenomena (e.g., social interaction) is experimentally challenging. Existing whole-brain models often fail to scale to single-neuron resolution, omit behavioral readouts, or rely on PCA/conv pipelines that miss long-range, non-linear interactions. We introduce a sparse-attention whole-brain foundation model (SBM) for larval zebrafish that forecasts neuron spike probabilities conditioned on sensory stimuli and links brain state to behavior. SBM factorizes attention across neurons and along time, enabling whole-brain scale and interpretability. On a held-out subject, it achieves mean absolute error <0.02 with calibrated predictions and stable autoregressive rollouts. Coupled to a permutation-invariant behavior head, SBM enables gradient-based synthesis of neural patterns that elicit target behaviors. This framework supports rapid, behavior-grounded exploration of complex neural phenomena.",
      "author": "Sam Fatehmanesh Vegas, Matt Thomson, James Gornet, David Prober",
      "published_date": "2025-11-03T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 131,
      "reading_time": 1,
      "created_at": "2025-11-03T23:19:47.568190+00:00",
      "updated_at": "2025-11-03T23:19:47.568192+00:00"
    },
    {
      "id": "d33e39dd01c669199a7c3c9889b17153",
      "url": "https://arxiv.org/abs/2510.26955",
      "title": "Neurons as Detectors of Coherent Sets in Sensory Dynamics",
      "content": "arXiv:2510.26955v1 Announce Type: new \nAbstract: We model sensory streams as observations from high-dimensional stochastic dynamical systems and conceptualize sensory neurons as self-supervised learners of compact representations of such dynamics. From prior experience, neurons learn coherent sets-regions of stimulus state space whose trajectories evolve cohesively over finite times-and assign membership indices to new stimuli. Coherent sets are identified via spectral clustering of the stochastic Koopman operator (SKO), where the sign pattern of a subdominant singular function partitions the state space into minimally coupled regions. For multivariate Ornstein-Uhlenbeck processes, this singular function reduces to a linear projection onto the dominant singular vector of the whitened state-transition matrix. Encoding this singular vector as a receptive field enables neurons to compute membership indices via the projection sign in a biologically plausible manner. Each neuron detects either a predictive coherent set (stimuli with common futures) or a retrospective coherent set (stimuli with common pasts), suggesting a functional dichotomy among neurons. Since neurons lack access to explicit dynamical equations, the requisite singular vectors must be estimated directly from data, for example, via past-future canonical correlation analysis on lag-vector representations-an approach that naturally extends to nonlinear dynamics. This framework provides a novel account of neuronal temporal filtering, the ubiquity of rectification in neural responses, and known functional dichotomies. Coherent-set clustering thus emerges as a fundamental computation underlying sensory processing and transferable to bio-inspired artificial systems.",
      "author": "Joshua L. Pughe-Sanford, Xuehao Ding, Jason J. Moore, Anirvan M. Sengupta, Charles Epstein, Philip Greengard, Dmitri B. Chklovskii",
      "published_date": "2025-11-03T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 228,
      "reading_time": 1,
      "created_at": "2025-11-03T23:19:47.568161+00:00",
      "updated_at": "2025-11-03T23:19:47.568163+00:00"
    },
    {
      "id": "beeb4d26b871a178b90767b13ed20cd4",
      "url": "https://arxiv.org/abs/2510.26804",
      "title": "EARS-UDE: Evaluating Auditory Response in Sensory Overload with Universal Differential Equations",
      "content": "arXiv:2510.26804v1 Announce Type: new \nAbstract: Auditory sensory overload affects 50-70% of individuals with Autism Spectrum Disorder (ASD), yet existing approaches, such as mechanistic models (Hodgkin Huxley type, Wilson Cowan, excitation inhibition balance), clinical tools (EEG/MEG, Sensory Profile scales), and ML methods (Neural ODEs, predictive coding), either assume fixed parameters or lack interpretability, missing autism heterogeneity. We present a Scientific Machine Learning approach using Universal Differential Equations (UDEs) to model sensory adaptation dynamics in autism. Our framework combines ordinary differential equations grounded in biophysics with neural networks to capture both mechanistic understanding and individual variability. We demonstrate that UDEs achieve a 90.8% improvement over pure Neural ODEs while using 73.5% fewer parameters. The model successfully recovers physiological parameters within the 2% error and provides a quantitative risk assessment for sensory overload, predicting 17.2% risk for pulse stimuli with specific temporal patterns. This framework establishes foundations for personalized, evidence-based interventions in autism, with direct applications to wearable technology and clinical practice.",
      "author": "Miheer Salunke, Prathamesh Dinesh Joshi, Raj Abhijit Dandekar, Rajat Dandekar, Sreedath Panat",
      "published_date": "2025-11-03T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 159,
      "reading_time": 1,
      "created_at": "2025-11-03T23:19:47.568116+00:00",
      "updated_at": "2025-11-03T23:19:47.568120+00:00"
    },
    {
      "id": "10e7cbd7a57cdb9572fe7ed61cfa90d5",
      "url": "https://www.sciencedirect.com/science/article/pii/S1053811925005610?dgcid=rss_sd_all",
      "title": "Test-retest reproducibility of structural and proxy estimates of brain connectivity at rest",
      "content": "<p>Publication date: 15 November 2025</p><p><b>Source:</b> NeuroImage, Volume 322</p><p>Author(s): Aldana Lizarraga, Arianna Sala, Kathrin Koch, Igor Yakushev</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroimage",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 16,
      "reading_time": 1,
      "created_at": "2025-11-03T23:19:39.625584+00:00",
      "updated_at": "2025-11-03T23:19:39.625586+00:00"
    },
    {
      "id": "d0f334a39a923038fcb68d0cbee9dd73",
      "url": "https://www.sciencedirect.com/science/article/pii/S1053811925005592?dgcid=rss_sd_all",
      "title": "Neurocognitive mechanisms of age-related decline in global motion perception",
      "content": "<p>Publication date: 15 November 2025</p><p><b>Source:</b> NeuroImage, Volume 322</p><p>Author(s): Yaxi Hong, Ting Liu, Dan Luo, Ziliang Zhu, Shizhen Yan, Hua Jin</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroimage",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 20,
      "reading_time": 1,
      "created_at": "2025-11-03T23:19:39.625564+00:00",
      "updated_at": "2025-11-03T23:19:39.625566+00:00"
    },
    {
      "id": "2e04813de5c8b36c4e83691d63f5fc4d",
      "url": "https://www.sciencedirect.com/science/article/pii/S1053811925005580?dgcid=rss_sd_all",
      "title": "Disrupted temporal structure of the M/EEG meta-states sequencing in Alzheimer\u2019s disease",
      "content": "<p>Publication date: 15 November 2025</p><p><b>Source:</b> NeuroImage, Volume 322</p><p>Author(s): Marina Sandon\u00eds-Fern\u00e1ndez, Pablo N\u00fa\u00f1ez, Miguel A. Tola-Arribas, M\u00f3nica Cano, Hideyuki Hoshi, Yoshihito Shigihara, Jes\u00fas Poza, Carlos G\u00f3mez</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroimage",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 25,
      "reading_time": 1,
      "created_at": "2025-11-03T23:19:39.625544+00:00",
      "updated_at": "2025-11-03T23:19:39.625545+00:00"
    },
    {
      "id": "22408adb7ebf0bcd0820733cf6724f30",
      "url": "https://www.sciencedirect.com/science/article/pii/S1053811925005361?dgcid=rss_sd_all",
      "title": "Paired-pulse TMS of premotor cortex produces non-linear suppressive effects on neural activity in the targeted network - a TMS-fMRI study",
      "content": "<p>Publication date: 15 November 2025</p><p><b>Source:</b> NeuroImage, Volume 322</p><p>Author(s): Laerke Gebser Krohne, Sofus Nygaard, Maud Eline Ottenheijm, Marie Louise Liu, Axel Thielscher, Hartwig Roman Siebner, Kristoffer Hougaard Madsen</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroimage",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 27,
      "reading_time": 1,
      "created_at": "2025-11-03T23:19:39.625521+00:00",
      "updated_at": "2025-11-03T23:19:39.625522+00:00"
    },
    {
      "id": "8e7b842b68dc3a543261fe911bf6e1cf",
      "url": "https://www.biorxiv.org/content/10.1101/2025.11.01.686013v1?rss=1",
      "title": "Simultaneous detection and estimation in olfactory sensing",
      "content": "The mammalian olfactory system shows an exceptional ability for rapid and accurate decoding of both the identity and concentration of odorants. Previous works have used the theory of compressed sensing to elucidate the algorithmic basis for this capability: decoding odor information from the responses of a restricted repertoire of receptors is possible because only a few relevant odorants are present in any given sensory scene. However, existing circuit models for olfactory decoding still cannot contend with the complexity of naturalistic olfactory scenes; they are limited to detection of a handful of odorants. Here, we propose a model for olfactory compressed sensing inspired by simultaneous localization and mapping algorithms in navigation: the set of odors that are present in a given scene, and the concentration of those present odors, are inferred separately. To enable rapid inference of odor presence in a biologically-plausible recurrent circuit, our model leverages the framework of Mirrored Langevin Dynamics, which gives a general recipe for sampling from constrained distributions using rate-based dynamics. This results in a recurrent circuit model that can accurately infer presence and concentration at scale and can be mapped onto the primary cell types of the olfactory bulb. This framework offers a path towards circuit models---for olfactory sensing and beyond---that both perform well in naturalistic environments and make experimentally-testable predictions for neural response dynamics.",
      "author": "Jiang, C., He, M. Y., Murthy, V. N., Pehlevan, C., Zavatone-Veth, J. A., Masset, P.",
      "published_date": "2025-11-03T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 220,
      "reading_time": 1,
      "created_at": "2025-11-03T23:19:38.489424+00:00",
      "updated_at": "2025-11-03T23:19:38.489425+00:00"
    },
    {
      "id": "c95169174fa117466c3bd3160d4532c7",
      "url": "https://www.biorxiv.org/content/10.1101/2025.11.01.686029v1?rss=1",
      "title": "Functional clusters for shape, texture, and motion encoding in macaque V2",
      "content": "Macaque primary visual cortex (V1) exhibits exquisite columnar organization, while midlevel area V4 does not. Here we investigated the functional organization and representational bases of intervening area V2 with high-density Neuropixels recordings and a variety of visual stimuli: shape, texture, drifting grating, and translational motion patches. We observed dense clusters of similarly tuned neurons often spanning ~500 micrometer for shape and motion stimuli, and larger for texture stimuli, consistent with a columnar structure. In terms of representational bases, V2 responses were largely explained by stimulus features based on local image statistics: shape tuning is well-modeled by a linear combination of orientation filters, and direction selectivity is stronger with surface compared to object motion, in striking contrast to V4. Overall, our results support the progression from columns to sparse clusters as neuronal representations transform from encoding local features and feature conjunctions in V1/V2 to a high-dimensional object-based code in V4.",
      "author": "Kim, T., Kamath, R., Hatanaka, G., Namima, T., Dylla, C., Bair, W., Pasupathy, A.",
      "published_date": "2025-11-03T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 149,
      "reading_time": 1,
      "created_at": "2025-11-03T23:19:38.489376+00:00",
      "updated_at": "2025-11-03T23:19:38.489381+00:00"
    },
    {
      "id": "e66e27c122824aa7df7f4967ba27405c",
      "url": "https://www.nature.com/articles/s41598-025-22194-w",
      "title": "Mild hypoxia adversely impacts human vestibular function",
      "content": "",
      "author": "",
      "published_date": "2025-11-03T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-11-03T23:19:36.668823+00:00",
      "updated_at": "2025-11-03T23:19:36.668825+00:00"
    },
    {
      "id": "bff7aaf533c4b8fb4340f1cde4a8c146",
      "url": "https://www.nature.com/articles/s44328-025-00058-7",
      "title": "Injectable ultrasonic metagels for intracranial monitoring",
      "content": "",
      "author": "",
      "published_date": "2025-11-03T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-11-03T23:19:36.668786+00:00",
      "updated_at": "2025-11-03T23:19:36.668788+00:00"
    },
    {
      "id": "a980cfa408e3908da7d812906e42abb6",
      "url": "https://www.nature.com/articles/s41598-025-22229-2",
      "title": "PARP1-TRPM2-PKC cascade distinctly regulates reactive astrogliosis and clasmatodendrosis through NF-\u03baB and AKT pathways in the hippocampus of chronic epilepsy rats",
      "content": "",
      "author": "",
      "published_date": "2025-11-03T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-11-03T23:19:36.668729+00:00",
      "updated_at": "2025-11-03T23:19:36.668731+00:00"
    },
    {
      "id": "34943af7e6a6fadcb07c1693c80cdf81",
      "url": "https://www.nature.com/articles/s41598-025-22321-7",
      "title": "Depression in mice causes decreased neuronal excitability and enhanced frequency adaptation in medial prefrontal cortex pyramidal neurons",
      "content": "",
      "author": "",
      "published_date": "2025-11-03T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-11-03T23:19:36.668651+00:00",
      "updated_at": "2025-11-03T23:19:36.668653+00:00"
    }
  ]
}