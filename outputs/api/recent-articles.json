{
  "last_updated": "2025-12-22T19:19:57.489964+00:00",
  "count": 20,
  "articles": [
    {
      "id": "d19014dfde24831da73ad4f815de300b",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.18.695288v1?rss=1",
      "title": "From Stability to Complexity: A Systematic Review of Long-term Divergence Exponents in Nonlinear Gait Analysis",
      "content": "Background Divergence exponents (DE), or maximum Lyapunov exponents, computed from stride-to-stride fluctuations have traditionally been interpreted as measures of gait stability. However, evidence suggests this measure may also reflect gait complexity and automaticity. This systematic review evaluated examined empirical support for reinterpreting long-term DE as a complexity measure. Methods We systematically searched Web of Science databases through August 2024 for studies applying Rosenstein's algorithm to human gait. We systematically extracted experimental conditions, and participant characteristics from each study. Study quality was assessed using a framework evaluating analytical rigor, outcome reporting, and sample size adequacy. We conducted a meta-analysis examining correlations between long-term DEs and detrended fluctuation analysis (DFA) scaling exponents, and synthesized evidence from perturbation (environmental disturbances), cueing (external rhythmic stimuli), and between-subject (clinical vs control) studies. Results Fifty-six studies published between 2000 and 2024 met inclusion criteria, with 43% achieving high overall quality scores. Meta-analysis from six datasets (209 participants) revealed a positive correlation between long-term DE and DFA scaling exponents (r=0.64, 95% CI 0.34 to 0.82; I{superscript 2}=82%). Perturbation studies consistently showed and increased short-term DE (lower local stability) while simultaneously decreasing long-term DE by up to 64%. External auditory and visual cueing interventions induced long-term DE decreases (up to -86%) while minimally affecting short-term DEs. Between-subject comparisons revealed heterogeneous patterns, with clinical populations exhibiting both increases and decreases in long-term DE depending on pathology. Conclusions Converging meta-analytic and experimental evidence supports reinterpreting long-term DE as the Attractor Complexity Index--a measure of gait complexity and automaticity rather than stability. Reduced long-term DE during controlled gait conditions reflects suppression of low-frequency variations in gait variability, which constrains phase space exploration and accelerates divergence curve saturation. The measure's sensitivity to prefrontal cortex engagement and attentional demands reveals that long-term DE captures the degree of gait automaticity, with lower values indicating a shift from automatic subcortical control to executive function-mediated regulation. This attention-dependent control reorganization explains patterns observed in aging, clinical populations, and experimental perturbations. This paradigm shift establishes long-term DE as a complementary biomarker for motor-cognitive aspects of gait control, with implications for fall risk assessment, disease monitoring, and rehabilitation evaluation.",
      "author": "Torrent, J., Coquaux, R., Terrier, P.",
      "published_date": "2025-12-22T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 351,
      "reading_time": 1,
      "created_at": "2025-12-22T19:19:28.167426+00:00",
      "updated_at": "2025-12-22T19:19:28.167428+00:00"
    },
    {
      "id": "4a0a70cb9fe3dd9e5d6bfd584c6e82b5",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.17.694940v1?rss=1",
      "title": "A Naturalistic Study on the Combined Neural and Psychological Effects of Psilocybin and Compassion Focused Imagery",
      "content": "Psilocybin is a classic psychedelic drug known to alter subjective experience and elicit long-term psychological changes, enhancing cognitive flexibility and reducing rigid self-related beliefs. Combined with compassion motivational primes that involve generating mental representations of compassion, it may increase the potential for activating the care-affiliative motivational systems, linked to several important biopsychosocial processes underpinning social safeness, social connection and mental wellbeing. We investigated the synergetic effects of psilocybin and compassion imagery with self-reported questionnaires and functional resonance imaging data (fMRI) in a sample of 105 participants. Participants were primed with either attention to breathing or a short compassion focused imagery prime. We found a long-term synergetic effect of compassion imagery and psilocybin on cognitive absorption, as well as changes relative to baseline self-compassion and decentering. Based on functional interactions between attentional, executive and default mode networks, fMRI-based classifiers detected participant engagement in compassion focused imagery before psilocybin intake and distinguished compassion imagery vs. attention to breathing priming only the high dose of psilocybin. Our results support the potential for synergistic effects from combinations of psilocybin and compassion-based interventions to induce long-term psychological changes, reshaping the functional organization of large-scale brain networks. Future confirmatory studies of our exploratory analyses should be conducted to determine whether the combination of psilocybin and compassion-based practices promotes increases in caring and contemplative abilities, enhanced psychological flexibility and well-being.",
      "author": "Pallavicini, C., Llobenes, L., Cavanna, F., de la Fuente, L. A., Muller, S. A., Costa, M. I., Gumiy, N., Bruno, N., D'Amelio, T., Basran, J., Plowright, P., Stolkiner, A., Namias, M., Gilbert, P., Tagliazucchi, E.",
      "published_date": "2025-12-22T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 223,
      "reading_time": 1,
      "created_at": "2025-12-22T19:19:28.167371+00:00",
      "updated_at": "2025-12-22T19:19:28.167372+00:00"
    },
    {
      "id": "2ef5f9858a6ed4f4afb659f3a1f8df9a",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.18.695278v1?rss=1",
      "title": "Frontoamygdala hyperconnectivity predicts autonomic dysregulation and persisting symptoms in sports-related concussion",
      "content": "OBJECTIVE: We investigated longitudinal trajectories of resting-state fMRI (rsfMRI), autonomic function, and symptoms after sport-related concussion (SRC). BACKGROUND: Limbic circuitry may be particularly vulnerable to traumatic brain injury (TBI), which could explain the affective and autonomic dysfunction some patients develop. Relatively few studies have performed longitudinal rsfMRI analyses in concussion and fewer have combined imaging with autonomic and symptom data. We leveraged published limbic rsfMRI networks centered on the amygdala that include central autonomic structures in frontal and temporal lobes and their visceromotor targets. We hypothesized that frontoamygdala connectivity would differentiate athletes with SRC from matched, in-sport controls (ISC), predict autonomic function, and predict symptom recovery. DESIGN/METHODS: Using independent-samples t-tests, we compared rsfMRI connectivity strength in amygdala networks in college athletes with SRC (SRC: n=31, female=14) at three time points after concussion (T1[&le;]4 days, T2=10-14 days, T3=60-90 days) and healthy, matched controls without a concussion in the same sport (ISC: n=36, female=17). RESULTS: SRC athletes showed significantly greater frontoamygdala connectivity compared to ISCs at the acute and subacute post-injury time points (T1 p=0.003, T2 p=0.014) that normalized to control-level connectivity by the chronic time point (T3 p=0.182). When testing whether autonomic function interacts with network connectivity trajectory, we found that opposing trajectories of frontoamygdala connectivity between SRC athletes with higher versus lower acute heart rate variability (HRV), as measured by pNN50 (percentage of intervals between successive normal sinus beats greater than 50ms). SRC athletes with higher HRV acutely post-injury had significantly greater acute frontoamygdala connectivity compared to ISCs at T1; connectivity in these high-HRV SRC athletes normalized to control level over time (T1 p=0.001, T2 p=0.055, T3 p=0.576). SRC athletes with lower HRV acutely post-injury had control-level frontoamygdala connectivity at T1; connectivity in these low-HRV SRC athletes significantly exceeded control-level connectivity at T3 (T1 p=0.429, T2 p=0.050, T3 p=0.002). Furthermore, those SRC athletes with the greatest frontoamygdala connectivity at T3, had the most persistent symptoms on the graded symptom checklist at T3 (r=0.635, p=0.001). Differences in diffusion-tensor-imaging-based measures of structural connectivity in the uncinate fasciculus, the fiber bundle most critical to our frontoamygdala network, could not account for these relationships. CONCLUSIONS: These results suggest that increased connectivity in amygdala circuitry acutely after a concussion and its normalization over time may be protective or compensatory; acute measures of amygdala network connectivity and measures of HRV may be valuable biomarkers for predicting symptom persistence.",
      "author": "Bickart, K., Kashou, A. W., Sheridan, C. A., Lin, A., Dennis, E., Brown, A., Hamilton, R., Giza, C., Choe, M.",
      "published_date": "2025-12-22T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 392,
      "reading_time": 1,
      "created_at": "2025-12-22T19:19:28.167334+00:00",
      "updated_at": "2025-12-22T19:19:28.167336+00:00"
    },
    {
      "id": "3fce66412b29d47d370694d61d552075",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.18.695210v1?rss=1",
      "title": "Presynaptic Actin Nanostructures: A Reproducibility Case Study",
      "content": "In an effort to assess the reproducibility of bioimage analyses in current publications, we took part in a Global BioImage Analysts' Society (GloBIAS) initiative to try and reproduce results from published articles. We attempted to reproduce core findings from the work of Bingham et al., which investigates the actin organisation in presynaptic structures by using diffraction-limited and super-resolution microscopy. While the original paper unveiled clear biological insight, it lacked sufficient detail in the bioimage analysis methodological approach, limiting the depth of reproducibility we could achieve. Through frequent contacts with the corresponding author, we managed to replicate qualitative aspects of the analysis of actin nanostructures in bead-induced presynapses. We performed image reconstruction from super-resolution microscopy data, automatic image registration and visual inspection, followed by manual annotation of structures of interest in ~35 images. Our experience with this exercise highlights the importance of transparent data sharing and accessibility, as well as the need to adhere to bioimage analysis standards that ensure the reproducibility of nowadays complex biological image analysis studies. It also shows how crucial interdisciplinary collaboration is, since many biology labs are simply unaware of these standards, which are often easy to implement and would likely be widely adopted if their value was better understood or known",
      "author": "Theart, R. P., Levet, F., Hernandez-Herrera, P., Leterrier, C., de la Ballina, L. R.",
      "published_date": "2025-12-22T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 206,
      "reading_time": 1,
      "created_at": "2025-12-22T19:19:28.167275+00:00",
      "updated_at": "2025-12-22T19:19:28.167277+00:00"
    },
    {
      "id": "3505d6ba268df519fa0b359f157b70ff",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.18.694748v1?rss=1",
      "title": "Telomerase mRNA-Lipid nanoparticles attenuate neuroinflammation after traumatic brain injury in mice",
      "content": "Traumatic brain injury (TBI) is a leading cause of chronic neurological disability, yet no disease-modifying therapy exists. Emerging evidence indicates that TBI activates cellular aging programs, including telomere erosion and persistent inflammation, that contribute to progressive neurodegeneration. Telomerase reverse transcriptase (TERT) preserves telomere homeostasis and provides cytoprotective effects in the central nervous system, but has not been therapeutically targeted after TBI. Here, we developed an mRNA nanotherapy consisting of mouse TERT mRNA encapsulated in lipid nanoparticles (mTERT-LNPs) and evaluated it in a controlled cortical impact model of moderate TBI. We first established that TBI transiently disrupts TERT biology, with reduced cortical TERT mRNA and shortened telomeres at 3 days post-injury (dpi), followed by partial recovery by 14 dpi. mTERT-LNPs were well tolerated in vitro and in vivo. Following intravenous delivery in the acute post-injury window, LNPs localized to the injured brain and displayed expected peripheral biodistribution. A single systemic dose increased cortical TERT mRNA and protein and partially restored telomere length at 3 dpi. TERT mRNA delivery significantly reduced Iba1+ microglial activation and suppressed pro-inflammatory cytokines, with modest increases in anti-inflammatory markers. Systemically, mTERT-LNPs lowered serum C-reactive protein and malondialdehyde, indicating reduced peripheral inflammation and oxidative stress, without adverse effects on body weight or peripheral organ histology. Several outcomes showed sex-dependent patterns. Collectively, these data provide the first in vivo evidence that telomerase therapy can modulate telomere biology and neuroinflammation after TBI, supporting mRNA-LNP-mediated TERT restoration as a scalable, mechanistically grounded strategy for disease modification in TBI and related disorders.",
      "author": "Kara, G., Holcomb, M., Tiwari, A., Flinn, H., Eimer, T., Marshall, A., Burke, M., Park, P., Court, K., Cooke, J. P., Godin, B., Villapol, S.",
      "published_date": "2025-12-22T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 250,
      "reading_time": 1,
      "created_at": "2025-12-22T19:19:28.167230+00:00",
      "updated_at": "2025-12-22T19:19:28.167235+00:00"
    },
    {
      "id": "869eb5db1a080181ed8aea049053bef0",
      "url": "https://www.nature.com/articles/s41593-025-02157-0",
      "title": "Phosphorylated tau exhibits antimicrobial activity capable of neutralizing herpes simplex virus 1 infectivity in human neurons",
      "content": "<p>Nature Neuroscience, Published online: 17 December 2025; <a href=\"https://www.nature.com/articles/s41593-025-02157-0\">doi:10.1038/s41593-025-02157-0</a></p>The authors found that the Alzheimer\u2019s disease-associated protein tau, widely considered pathogenic when hyperphosphorylated, has a natural function as part of the innate immune system in the brain and can protect against herpes simplex virus 1.",
      "author": "Rudolph E. Tanzi",
      "published_date": "2025-12-17T00:00:00+00:00",
      "source": "Nature Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 44,
      "reading_time": 1,
      "created_at": "2025-12-22T19:19:25.602146+00:00",
      "updated_at": "2025-12-22T19:19:25.602147+00:00"
    },
    {
      "id": "959a3e4899df3eab73eb0ef4b3685aca",
      "url": "https://www.frontiersin.org/articles/10.3389/fncom.2025.1718778",
      "title": "From generative AI to the brain: five takeaways",
      "content": "The big strides seen in generative AI are not based on somewhat obscure algorithms, but due to clearly defined generative principles. The resulting concrete implementations have proven themselves in large numbers of applications. We suggest that it is imperative to thoroughly investigate which of these generative principles may be operative also in the brain, and hence relevant for cognitive neuroscience. In addition, ML research led to a range of interesting characterizations of neural information processing systems. We discuss five examples, the shortcomings of world modeling, the generation of thought processes, attention, neural scaling laws, and quantization, that illustrate how much neuroscience could potentially learn from ML research.",
      "author": "Claudius Gros",
      "published_date": "2025-11-24T00:00:00+00:00",
      "source": "Frontiers Computational Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 107,
      "reading_time": 1,
      "created_at": "2025-12-22T19:19:18.963527+00:00",
      "updated_at": "2025-12-22T19:19:18.963529+00:00"
    },
    {
      "id": "c13d5532481827beeb958f3b696e11c0",
      "url": "https://www.frontiersin.org/articles/10.3389/fnbot.2025.1696824",
      "title": "A novel intelligent physiotherapy robot based on dynamic acupoint recognition method",
      "content": "BackgroundPhysiotherapy robots offer a feasible and promising solution for achieving safe and efficient treatment. Among these, acupoint recognition is the core component that ensures the precision of physiotherapy robots. Although the research on the acupoint recognition such as hand and ear has been extensive, the accurate location of acupoints on the back of the human body still faces great challenges due to the lack of significant external features.MethodsThis paper designs a two-stage acupoint recognition method, which is achieved through the cooperation of two detection networks. First, a lightweight RTMDet network is used to extract the effective back range from the image, and then the acupoint coordinates are inferred from the extracted back range, reducing the inference consumption caused by invalid information. In addition, the RTMPose network based on the SimCC framework converts the acupoint coordinate regression problem into a classification problem of sub-pixel block subregions on the X and Y axes by performing sub-pixel-level segmentation of images, significantly improving detection speed and accuracy. Meanwhile, the multi-layer feature fusion of CSPNeXt enhances feature extraction capabilities. Then, we designed a physiotherapy interaction interface. Through the three-dimensional coordinates of the acupoints, we independently planned the physiotherapy task path of the physiotherapy robot.ResultsWe conducted performance tests on the acupoint recognition system and physiotherapy task planning in the physiotherapy robot system. The experiments have proven our effectiveness, achieving a recall of 90.17% on human datasets, with a detection error of around 5.78\u202fmm. At the same time, it can accurately identify different back postures and achieve an inference speed of 30 FPS on a 4070Ti GPU. Finally, we conducted continuous physiotherapy tasks on multiple acupoints for the user.ConclusionThe experimental results demonstrate the significant advantages and broad application potential of this method in improving the accuracy and reliability of autonomous acupoint recognition by physiotherapy robots.",
      "author": "Shuoyu Wang",
      "published_date": "2025-11-24T00:00:00+00:00",
      "source": "Frontiers Neurorobotics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 299,
      "reading_time": 1,
      "created_at": "2025-12-22T19:19:16.032443+00:00",
      "updated_at": "2025-12-22T19:19:16.032445+00:00"
    },
    {
      "id": "f35ad65c2f2bc793878cc29a7b1defb3",
      "url": "https://www.reddit.com/r/Python/comments/1pslvex/project_raxhes_a_branchfree_execution_model_for/",
      "title": "[Project] RAX-HES \u2013 A branch-free execution model for ultra-fast, deterministic VMs",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019ve been working on <strong>RAX-HES</strong>, an experimental execution model focused on <strong>raw interpreter-level throughput and deterministic performance</strong>. (currently only a Python/Java-to-RAX-HES compiler exists.)</p> <p><strong>RAX-HES is not a programming language.</strong></p> <p>It\u2019s a VM execution model built around a <strong>fixed-width, slot-based instruction format</strong> designed to eliminate common sources of runtime overhead found in traditional bytecode engines.</p> <p>The core idea is simple:</p> <p>make instruction decoding <em>constant-time</em>, remove unpredictable control flow, and keep execution mechanically straightforward.</p> <p><strong>What makes RAX-HES different:</strong></p> <pre><code>\u2022 **Fixed-width, slot-based instructions** \u2022 **Constant-time decoding** \u2022 **Branch-free dispatch** (no polymorphic opcodes) \u2022 **Cache-aligned, predictable execution paths** \u2022 **Instructions are pre-validated and typed** \u2022 **No stack juggling** \u2022 **No dynamic dispatch** \u2022 **No JIT, no GC, no speculative optimizations** </code></pre> <p>Instead of relying on increasingly complex runtime layers, RAX-HES redefines the contract between compiler and VM to favor <strong>determinism, structural simplicity, and predictable performance</strong>.</p> <p>It\u2019s <strong>not meant to replace native code or GPU workloads</strong> \u2014 the goal is a <strong>high-throughput, low-latency execution foundation</strong> for languages and systems that benefit from stable, interpreter-level performance.</p> <p>This is <strong>very early and experimental</strong>, but I\u2019d love feedback from people interested in:</p> <pre><code>\u2022 virtual machines \u2022 compiler design \u2022 low-level execution models \u2022 performance-oriented interpreters </code></pre> <p>Repo (very fresh):</p> <p>\ud83d\udc49 <a href=\"https://github.com/CrimsonDemon567/RAXPython\">https://github.com/CrimsonDemon567/RAXPython</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Dry_Philosophy_6825\"> /u/Dry_Philosophy_6825 </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1pslvex/project_raxhes_a_branchfree_execution_model_for/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1pslvex/project_raxhes_a_branchfree_execution_model_for/\">[comments]</a></span>",
      "author": "/u/Dry_Philosophy_6825",
      "published_date": "2025-12-22T00:42:19+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 225,
      "reading_time": 1,
      "created_at": "2025-12-22T19:18:51.617085+00:00",
      "updated_at": "2025-12-22T19:18:51.617087+00:00"
    },
    {
      "id": "c3e7baeede9f89bca8a57ae3ab9c6c6d",
      "url": "https://ammil.industries/i-know-you-didnt-write-this/",
      "title": "I know you didn't write this",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46357194\">Comments</a>",
      "author": "",
      "published_date": "2025-12-22T18:39:30+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-22T19:18:50.326410+00:00",
      "updated_at": "2025-12-22T19:18:50.326425+00:00"
    },
    {
      "id": "3fd7f621363b0c7becef9411541c32ab",
      "url": "https://www.404media.co/flock-exposed-its-ai-powered-cameras-to-the-internet-we-tracked-ourselves/",
      "title": "Flock Exposed Its AI-Powered Cameras to the Internet. We Tracked Ourselves",
      "content": "<p><a href=\"https://archive.ph/IWMKe\" rel=\"nofollow\">https://archive.ph/IWMKe</a></p>\n<hr />\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46355548\">https://news.ycombinator.com/item?id=46355548</a></p>\n<p>Points: 59</p>\n<p># Comments: 27</p>",
      "author": "chaps",
      "published_date": "2025-12-22T16:31:40+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 14,
      "reading_time": 1,
      "created_at": "2025-12-22T19:18:49.092663+00:00",
      "updated_at": "2025-12-22T19:18:49.092664+00:00"
    },
    {
      "id": "6a8af5336d2f3e71d4f2edeea2edf75b",
      "url": "https://www.jeffgeerling.com/blog/2025/nist-was-5-\u03bcs-utc-after-last-weeks-power-cut",
      "title": "NIST was 5 \u03bcs off UTC after last week's power cut",
      "content": "<p>Article URL: <a href=\"https://www.jeffgeerling.com/blog/2025/nist-was-5-\u03bcs-utc-after-last-weeks-power-cut\">https://www.jeffgeerling.com/blog/2025/nist-was-5-\u03bcs-utc-after-last-weeks-power-cut</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46355949\">https://news.ycombinator.com/item?id=46355949</a></p>\n<p>Points: 15</p>\n<p># Comments: 10</p>",
      "author": "jtokoph",
      "published_date": "2025-12-22T17:01:28+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-22T19:18:49.092602+00:00",
      "updated_at": "2025-12-22T19:18:49.092603+00:00"
    },
    {
      "id": "c3e7baeede9f89bca8a57ae3ab9c6c6d",
      "url": "https://ammil.industries/i-know-you-didnt-write-this/",
      "title": "I know you didn't write this",
      "content": "<p>Article URL: <a href=\"https://ammil.industries/i-know-you-didnt-write-this/\">https://ammil.industries/i-know-you-didnt-write-this/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46357194\">https://news.ycombinator.com/item?id=46357194</a></p>\n<p>Points: 39</p>\n<p># Comments: 27</p>",
      "author": "cjlm",
      "published_date": "2025-12-22T18:39:30+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-22T19:18:49.092512+00:00",
      "updated_at": "2025-12-22T19:18:49.092522+00:00"
    },
    {
      "id": "ab36e344df973e259b9992fca04c6788",
      "url": "https://www.sciencedirect.com/science/article/pii/S0006899325006699?dgcid=rss_sd_all",
      "title": "Differential neural activity and connectivity patterns in rats with and without noise-induced tinnitus",
      "content": "<p>Publication date: 1 February 2026</p><p><b>Source:</b> Brain Research, Volume 1872</p><p>Author(s): Nian Li, Liqin Zhang, Xu Tian, Yang Zhao, Guodong Feng, Zhiqiang Gao</p>",
      "author": "",
      "published_date": null,
      "source": "Brain Research",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 21,
      "reading_time": 1,
      "created_at": "2025-12-22T18:33:23.634649+00:00",
      "updated_at": "2025-12-22T18:33:23.634650+00:00"
    },
    {
      "id": "c4ef8084a62bbb1ef2d181c6f3d3e71b",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.19.695358v1?rss=1",
      "title": "Synaptotagmin-7 is required for synchronous but not asynchronous facilitation of glutamate release at cortical boutons",
      "content": "Short-term synaptic plasticity and the kinetics of neurotransmitter release vary widely across synapses, but population measurements obscure the mechanisms that generate this diversity. While the Ca2+ sensor Synaptotagmin-7 (Syt7) has been implicated in facilitation, vesicle replenishment and asynchronous vesicle exocytosis, its precise contributions to these processes remain debated. We used quantal-resolution imaging to measure synchronous and asynchronous glutamate release at individual cortical boutons in wild type and Syt7-/- neurons. Stratifying boutons by release efficacy and applying failure-based analysis to isolate trials where the first action potential evoked no release allowed us to separate facilitation from vesicle depletion. Syt7 deletion selectively eliminated activity-dependent facilitation of synchronous release but left facilitation of asynchronous release intact, although its overall magnitude was reduced. We further show that synchronous and asynchronous events arise from functionally distinct vesicle populations. These findings demonstrate that activity-dependent facilitation of synchronous and asynchronous exocytosis are mechanistically separable, enabling synapses to independently tune distinct temporal components of neurotransmission.",
      "author": "Kotzadimitriou, D., Langley, H., McGowan, E., R.F. Mendonca, P., Tagliatti, E., Timofeeva, Y., Krishnakumar, S. S., Volynski, K. E.",
      "published_date": "2025-12-22T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 157,
      "reading_time": 1,
      "created_at": "2025-12-22T18:33:19.225012+00:00",
      "updated_at": "2025-12-22T18:33:19.225014+00:00"
    },
    {
      "id": "e7993309cb8f60624ffdb6f0ee255356",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.17.694878v1?rss=1",
      "title": "Human and generative AI integrate visual cues differently in a shape completion task",
      "content": "In amodal completion observers perceive complete objects despite partial occlusion. When two object parts are divided by an occluder, completion can result in perceiving one or two objects. This phenomenon involves both lower-level cues (e.g., symmetry, contour continuity) and higher-level cues (e.g., prior knowledge). Experiment 1 investigates how occluder size, familiarity, and symmetry affect human completions using a drawing task. Narrow occluders and asymmetry promote single-shape completions, while familiarity and (global) symmetry promote two-shape interpretations. Good continuation emerges as the strongest cue, with symmetry and familiarity playing increasingly important roles as occluder width increases. Experiment 2 compares human performance with three state-of-the-art generative AI models. Models often generated creative but non-compliant outputs, altering even unoccluded regions. We restricted analysis to instruction-following generations, identified through ratings by naive observers. Among compliant outputs, models showed some human-like biases (e.g., more two-shape completions for wide occluders), but failed with higher-level cues. They did not use symmetry to guide completions and showed reversed familiarity effects. Our findings highlight differences between human and AI completions. Humans integrate low- and high-level cues, whereas compliant outputs from the AI models rely primarily on low-level pattern continuation. Current AI models lack the flexible integration of multiple representational levels that characterize human perception. This work establishes an analytical framework for evaluating whether next-generation models achieve more human-like visual reasoning.",
      "author": "Adams, J., Serriere, L., Kothen, M. J., Smorczewskaa, M. B., Schmidt, F., Morgenstern, Y.",
      "published_date": "2025-12-22T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 220,
      "reading_time": 1,
      "created_at": "2025-12-22T18:33:19.224971+00:00",
      "updated_at": "2025-12-22T18:33:19.224976+00:00"
    },
    {
      "id": "fba845953773a23b490df3eca194bb41",
      "url": "https://www.reddit.com/r/Python/comments/1psxub1/servy_43_released_turn_any_python_app_into_a/",
      "title": "Servy 4.3 released, Turn any Python app into a native Windows service",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>It's been four months since the announcement of Servy, and Servy 4.3 is finally here.</p> <p>The community response has been amazing: 940+ stars on GitHub and 12,000+ downloads.</p> <p>If you haven't seen Servy before, it's a Windows tool that turns any Python app (or other executable) into a native Windows service. You just set the Python executable path, add your script and arguments, choose the startup type, working directory, and environment variables, configure any optional parameters, click install, and you're done. Servy comes with a desktop app, a CLI, PowerShell integration, and a manager app for monitoring services in real time.</p> <p>In this release (4.3), I've added/improved:</p> <ul> <li>Digitally signed all executables and installers with a trusted code-signing certificate provided by the SignPath Foundation for maximum trust and security</li> <li>Fixed multiple false-positive detections from AV engines (SecureAge, DeepInstinct, and others)</li> <li>Reduced executable and installer sizes as much as technically possible</li> <li>Added date-based log rotation for stdout/stderr and max rotations to limit the number of rotated log files to keep</li> <li>Added custom installation options for advanced users</li> <li>New GUI enhancements and improvements</li> <li>Detailed documentation</li> <li>Bug fixes</li> </ul> <p>Check it out on GitHub: <a href=\"https://github.com/aelassas/servy\">https://github.com/aelassas/servy</a></p> <p>Demo video here: <a href=\"https://www.youtube.com/watch?v=biHq17j4RbI\">https://www.youtube.com/watch?v=biHq17j4RbI</a></p> <p>Python sample: <a href=\"https://github.com/aelassas/servy/wiki/Examples-&amp;-Recipes#run-a-python-script-as-a-service\">Examples &amp; Recipes</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/AdUnhappy5308\"> /u/AdUnhappy5308 </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1psxub1/servy_43_released_turn_any_python_app_into_a/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1psxub1/servy_43_released_turn_any_python_app_into_a/\">[comments]</a></span>",
      "author": "/u/AdUnhappy5308",
      "published_date": "2025-12-22T11:59:24+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 225,
      "reading_time": 1,
      "created_at": "2025-12-22T18:32:38.845579+00:00",
      "updated_at": "2025-12-22T18:32:38.845581+00:00"
    },
    {
      "id": "2573c6bb8775f8ebf070912eecd9bb44",
      "url": "https://www.reddit.com/r/Python/comments/1psjsnu/aiologic_culsans_a_way_to_make_multithreaded/",
      "title": "aiologic & culsans: a way to make multithreaded asyncio safe",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>Hello to everyone reading this. In this post, while it is still 2025, I will tell you about two of my libraries that you probably do not know about - <a href=\"https://github.com/x42005e1f/aiologic\">aiologic</a> &amp; <a href=\"https://github.com/x42005e1f/culsans\">culsans</a>. The irony here is that even though they are both over a year old, I keep coming across discussions in which my solutions are considered non-existent (at least, they are not mentioned, and the problems discussed remain unsolved). That is why I wrote this post - to introduce you to my libraries and the tasks they are able to solve, in order to try once again to make them more recognizable.</p> <h1>What My Projects Do</h1> <p>Both libraries provide synchronization/communication primitives (such as locks, queues, capacity limiters) that are both async-aware and thread-aware/thread-safe, and can work in different environments within a single process. Whether it is regular threads, asyncio tasks, or even gevent greenlets. For example, with <code>aiologic.Lock</code>, you can synchronize access to a shared resource for different asyncio event loops running in different threads, without blocking the event loop (which may be relevant for free-threading):</p> <pre><code>#!/usr/bin/env python3 import asyncio from concurrent.futures import ThreadPoolExecutor from aiologic import Lock lock = Lock() THREADS = 4 TASKS = 4 TIME = 1.0 async def work() -&gt; None: async with lock: # some CPU-bound or IO-bound work await asyncio.sleep(TIME / (THREADS * TASKS)) async def main() -&gt; None: async with asyncio.TaskGroup() as tg: for _ in range(TASKS): tg.create_task(work()) if __name__ == &quot;__main__&quot;: with ThreadPoolExecutor(THREADS) as executor: for _ in range(THREADS): executor.submit(asyncio.run, main()) # program will end in &lt;TIME&gt; seconds </code></pre> <p>The same can be achieved using <code>aiologic.synchronized()</code>, a universal decorator that is an async-aware alternative to <a href=\"https://wrapt.readthedocs.io/en/master/examples.html#thread-synchronization\"><code>wrapt.synchronized()</code></a>, which will use <code>aiologic.RLock</code> (reentrant lock) under the hood by default:</p> <pre><code>#!/usr/bin/env python3 import asyncio from concurrent.futures import ThreadPoolExecutor from aiologic import synchronized THREADS = 4 TASKS = 4 TIME = 1.0 @synchronized async def work(*, recursive: bool = True) -&gt; None: if recursive: await work(recursive=False) else: # some CPU-bound or IO-bound work await asyncio.sleep(TIME / (THREADS * TASKS)) async def main() -&gt; None: async with asyncio.TaskGroup() as tg: for _ in range(TASKS): tg.create_task(work()) if __name__ == &quot;__main__&quot;: with ThreadPoolExecutor(THREADS) as executor: for _ in range(THREADS): executor.submit(asyncio.run, main()) # program will end in &lt;TIME&gt; seconds </code></pre> <p>Want to notify a task from another thread that an action has been completed? No problem, just use <code>aiologic.Event</code>:</p> <pre><code>#!/usr/bin/env python3 import asyncio from concurrent.futures import ThreadPoolExecutor from aiologic import Event TIME = 1.0 async def producer(event: Event) -&gt; None: # some CPU-bound or IO-bound work await asyncio.sleep(TIME) event.set() async def consumer(event: Event) -&gt; None: await event print(&quot;done!&quot;) if __name__ == &quot;__main__&quot;: with ThreadPoolExecutor(2) as executor: executor.submit(asyncio.run, producer(event := Event())) executor.submit(asyncio.run, consumer(event)) # program will end in &lt;TIME&gt; seconds </code></pre> <p>If you ensure that only one task will wait for the event and only once, you can also use low-level events as a more lightweight alternative for the same purpose (this may be convenient for creating your own future objects; note that they also have <code>cancelled()</code> method!):</p> <pre><code>#!/usr/bin/env python3 import asyncio from concurrent.futures import ThreadPoolExecutor from aiologic import Flag from aiologic.lowlevel import AsyncEvent, Event, create_async_event TIME = 1.0 async def producer(event: Event, holder: Flag[str]) -&gt; None: # some CPU-bound or IO-bound work await asyncio.sleep(TIME) holder.set(&quot;done!&quot;) event.set() async def consumer(event: AsyncEvent, holder: Flag[str]) -&gt; None: await event print(&quot;result:&quot;, repr(holder.get())) if __name__ == &quot;__main__&quot;: with ThreadPoolExecutor(2) as executor: executor.submit(asyncio.run, producer( event := create_async_event(), holder := Flag[str](), )) executor.submit(asyncio.run, consumer(event, holder)) # program will end in &lt;TIME&gt; seconds </code></pre> <p>What about communication between tasks? Well, you can use <code>aiologic.SimpleQueue</code> as the fastest blocking queue in simple cases:</p> <pre><code>#!/usr/bin/env python3 import asyncio from concurrent.futures import ThreadPoolExecutor from aiologic import SimpleQueue ITERATIONS = 100 TIME = 1.0 async def producer(queue: SimpleQueue[int]) -&gt; None: for i in range(ITERATIONS): # some CPU-bound or IO-bound work await asyncio.sleep(TIME / ITERATIONS) queue.put(i) async def consumer(queue: SimpleQueue[int]) -&gt; None: for i in range(ITERATIONS): value = await queue.async_get() assert value == i print(&quot;done!&quot;) if __name__ == &quot;__main__&quot;: with ThreadPoolExecutor(2) as executor: executor.submit(asyncio.run, producer(queue := SimpleQueue[int]())) executor.submit(asyncio.run, consumer(queue)) # program will end in &lt;TIME&gt; seconds </code></pre> <p>And if you need some additional features and/or compatibility with the standard queues, then <code>culsans.Queue</code> is here to help:</p> <pre><code>#!/usr/bin/env python3 import asyncio from concurrent.futures import ThreadPoolExecutor from culsans import AsyncQueue, Queue ITERATIONS = 100 TIME = 1.0 async def producer(queue: AsyncQueue[int]) -&gt; None: for i in range(ITERATIONS): # some CPU-bound or IO-bound work await asyncio.sleep(TIME / ITERATIONS) await queue.put(i) await queue.join() print(&quot;done!&quot;) async def consumer(queue: AsyncQueue[int]) -&gt; None: for i in range(ITERATIONS): value = await queue.get() assert value == i queue.task_done() if __name__ == &quot;__main__&quot;: with ThreadPoolExecutor(2) as executor: executor.submit(asyncio.run, producer(queue := Queue[int]().async_q)) executor.submit(asyncio.run, consumer(queue)) # program will end in &lt;TIME&gt; seconds </code></pre> <p>It may seem that aiologic &amp; culsans only work with asyncio. In fact, they also support Curio, Trio, AnyIO, and also greenlet-based eventlet and gevent libraries, and you can also interact not only with tasks, but also with native threads:</p> <pre><code>#!/usr/bin/env python3 import time import gevent from aiologic import CapacityLimiter CONCURRENCY = 2 THREADS = 8 TASKS = 8 TIME = 1.0 limiter = CapacityLimiter(CONCURRENCY) def sync_work() -&gt; None: with limiter: # some CPU-bound work time.sleep(TIME * CONCURRENCY / (THREADS + TASKS)) def green_work() -&gt; None: with limiter: # some IO-bound work gevent.sleep(TIME * CONCURRENCY / (THREADS + TASKS)) if __name__ == &quot;__main__&quot;: threadpool = gevent.get_hub().threadpool gevent.joinall([ *(threadpool.spawn(sync_work) for _ in range(THREADS)), *(gevent.spawn(green_work) for _ in range(TASKS)), ]) # program will end in &lt;TIME&gt; seconds </code></pre> <p>Within a single thread with different libraries as well:</p> <pre><code>#!/usr/bin/env python3 import trio import trio_asyncio from aiologic import Condition TIME = 1.0 async def producer(cond: Condition) -&gt; None: # Trio-flavored async with cond: # some IO-bound work await trio.sleep(TIME) if not cond.waiting: await cond cond.notify() @trio_asyncio.aio_as_trio async def consumer(cond: Condition) -&gt; None: # asyncio-flavored async with cond: if cond.waiting: cond.notify() await cond print(&quot;done!&quot;) async def main() -&gt; None: async with trio.open_nursery() as nursery: nursery.start_soon(producer, cond := Condition()) nursery.start_soon(consumer, cond) if __name__ == &quot;__main__&quot;: trio_asyncio.run(main) # program will end in &lt;TIME&gt; seconds </code></pre> <p>And, even more uniquely, some aiologic primitives also work from inside signal handlers and destructors:</p> <pre><code>#!/usr/bin/env python3 import time import weakref import curio from aiologic import CountdownEvent, Flag from aiologic.lowlevel import enable_signal_safety TIME = 1.0 async def main() -&gt; None: event = CountdownEvent(2) flag1 = Flag() flag2 = Flag() await curio.spawn_thread(lambda flag: time.sleep(TIME / 2), flag1) await curio.spawn_thread(lambda flag: time.sleep(TIME), flag2) weakref.finalize(flag1, enable_signal_safety(event.down)) weakref.finalize(flag2, enable_signal_safety(event.down)) del flag1 del flag2 assert not event await event print(&quot;done!&quot;) if __name__ == &quot;__main__&quot;: curio.run(main) # program will end in &lt;TIME&gt; seconds </code></pre> <p>If that is not enough for you, I suggest you try the primitives yourself in the use cases that interest you. Maybe you will even find a use for them that I have not seen myself. And of course, these are far from all the declared features, and the documentation describes much more. However, the latter is still under development...</p> <h1>Performance</h1> <p>Quite a lot of focus (perhaps even too much) has been placed on performance. After all, no matter how impressive the capabilities of general solutions may be, if they cannot compete with more specialized solutions, you will subconsciously avoid using the former whenever possible. Therefore, both libraries have a number of relevant features.</p> <p>First, all unused primitives consume significantly less memory, just like asyncio primitives (remember, my primitives are also thread-aware). As an example, this has the following interesting effect: all queues consume significantly less memory than standard ones (even compared to asyncio queues). Here are <a href=\"https://github.com/microsoft/agent-lightning/issues/372#issuecomment-3615552472\">some old measurements</a> (to make them more actual, add about half a kilobyte to <code>aiologic.Queue</code> and <code>aiologic.SimpleQueue</code>):</p> <pre><code>&gt;&gt;&gt; sizeof(collections.deque) 760 &gt;&gt;&gt; sizeof(queue.SimpleQueue) 72 # see https://github.com/python/cpython/issues/140025 &gt;&gt;&gt; sizeof(queue.Queue) 3730 &gt;&gt;&gt; sizeof(asyncio.Queue) 3346 &gt;&gt;&gt; sizeof(janus.Queue) 7765 &gt;&gt;&gt; sizeof(culsans.Queue) 2152 &gt;&gt;&gt; sizeof(aiologic.Queue) 680 &gt;&gt;&gt; sizeof(aiologic.SimpleQueue) 448 &gt;&gt;&gt; sizeof(aiologic.SimpleLifoQueue) 376 &gt;&gt;&gt; sizeof(aiologic.lowlevel.lazydeque) 128 </code></pre> <p>This is true not only for unused queues, but also for partially used ones. For example, queues whose length has not yet reached maxsize will consume less memory, since the wait queue for put operations will not yet be in demand.</p> <p>Second, all aiologic primitives rely on effectively atomic operations (operations that cannot be interrupted due to the GIL and for which free-threading uses per-object locks). This makes almost all aiologic primitives faster than threading and queue primitives on PyPy, as shown in the example with semaphores:</p> <pre><code>threads = 1, value = 1: aiologic.Semaphore: 943246964 ops 100.00% fairness threading.Semaphore: 8507624 ops 100.00% fairness 110.9x speedup! threads = 2, value = 1: aiologic.Semaphore: 581026516 ops 99.99% fairness threading.Semaphore: 7664169 ops 99.87% fairness 75.8x speedup! threads = 3, value = 2: aiologic.Semaphore: 522027692 ops 99.97% fairness threading.Semaphore: 15161 ops 84.71% fairness 34431.2x speedup! threads = 5, value = 3: aiologic.Semaphore: 518826453 ops 99.89% fairness threading.Semaphore: 9075 ops 71.92% fairness 57173.9x speedup! ... threads = 233, value = 144: aiologic.Semaphore: 521016536 ops 99.24% fairness threading.Semaphore: 4872 ops 63.53% fairness 106944.9x speedup! threads = 377, value = 233: aiologic.Semaphore: 522805870 ops 99.04% fairness threading.Semaphore: 3567 ops 80.30% fairness 146564.5x speedup! ... </code></pre> <p>The benchmark is <a href=\"https://gist.github.com/x42005e1f/149d3994d5f7bd878def71d5404e6ea4\">publicly available</a>, and you can run your own measurements on your hardware with the interpreter you are interested in (for example, in free-threading you will also see a difference in favor of aiologic). So if you do not believe it, try it yourself.</p> <p><em>(Note: on a large number of threads, each pass will take longer due to the square problem mentioned in the next paragraph; perhaps the benchmark should be improved at some point...)</em></p> <p>Third, there are a number of details regarding timeouts, fairness, and the square problem. For these, I recommend reading the &quot;Performance&quot; section of the aiologic documentation.</p> <h1>Comparison</h1> <p>Strictly speaking, there are no real alternatives. But here is a comparison with some similar ones:</p> <ul> <li><a href=\"https://github.com/aio-libs/janus\">Janus</a> - provides only queues, supports only asyncio and regular threads, only one event loop, creates new tasks for non-blocking calls. The project is rarely maintained.</li> <li><a href=\"https://github.com/dabeaz/curio\">Curio</a>'s universal synchronization - provides only queues and events, supports only asyncio, Curio, and regular threads, uses the same methods for different environments, but has issues. The project was officially abandoned on December 21, 2025.</li> <li><a href=\"https://github.com/gleero/python-threadsafe-async\">python-threadsafe-async</a> - provides only events and channels, supports only asyncio and threads, uses not the most successful design solutions. The project has been inactive since March 2024.</li> <li><a href=\"https://github.com/dano/aioprocessing\">aioprocessing</a> - provides many primitives, but only supports asyncio, and due to multiprocessing support, it has far from the best performance and some limitations (for example, queues serialize all items and suffer from <a href=\"https://github.com/orgs/python/projects/14/views/1?filterQuery=queue\"><code>multiprocessing.Queue</code> issues</a>). The project has been inactive since September 2022.</li> </ul> <p>You can learn a little more in the &quot;Why?&quot; section of the aiologic documentation.</p> <h1>Target Audience</h1> <p>Python developers, of course. But there are some nuances:</p> <ol> <li>Development status - alpha. The API is still being refined, so incompatible changes are possible. If you do not rely exclusively on high-level interfaces (available from the top-level package), it may be good practice to pin the dependent version to the current and next minor aka major release (non-deprecated + deprecated but not removed).</li> <li>Documentation is still under development (in particular, aiologic currently has placeholders in many docstrings). At the same time, if you use any AI tools, they will most likely not understand the library well due to its exotic nature (a good example of this is DeepWiki). If you need a reliable information source here and now, you should take a look at GitHub Discussions (or alternative communication channels).</li> <li>Since I am (and will likely remain) the sole developer and maintainer, there is a very serious bus factor. Therefore, since the latest versions, I have been trying to enrich the source code with detailed comments so that the libraries can at least be maintained in a viable state in forks, but there is still a lot of work to be done in this area.</li> </ol> <p>I rely on theoretical analysis of my solutions and proactive bug fixing, so all provided functionality should be reliable and work as expected (even with weak test coverage). The libraries are already in use, so I think they are suitable for production.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/x42005e1f\"> /u/x42005e1f </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1psjsnu/aiologic_culsans_a_way_to_make_multithreaded/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1psjsnu/aiologic_culsans_a_way_to_make_multithreaded/\">[comments]</a></span>",
      "author": "/u/x42005e1f",
      "published_date": "2025-12-21T23:05:34+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2031,
      "reading_time": 10,
      "created_at": "2025-12-22T18:32:38.845543+00:00",
      "updated_at": "2025-12-22T18:32:38.845545+00:00"
    },
    {
      "id": "fc7fb65f0cdff810f5fc52d7ceeb2985",
      "url": "https://www.reddit.com/r/Python/comments/1psv340/spikard_v050_released/",
      "title": "Spikard v0.5.0 Released",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>Hi peeps,</p> <p>I'm glad to announce that <a href=\"https://github.com/Goldziher/spikard\">Spikard</a> v0.5.0 has been released. This is the first version I consider fully functional across all supported languages.</p> <h2>What is Spikard?</h2> <p>Spikard is a <em>polyglot web toolkit</em> written in Rust and available for multiple languages:</p> <ul> <li>Rust</li> <li>Python (3.10+)</li> <li>TypeScript (Node/Bun)</li> <li>TypeScript (WASM - Deno/Edge)</li> <li>PHP (8.2+)</li> <li>Ruby (3.4+)</li> </ul> <h2>Why Spikard?</h2> <p>I had a few reasons for building this:</p> <p>I am the original author of <a href=\"https://litestar.dev/\">Litestar</a> (no longer involved after v2), and I have a thing for web frameworks. Following the work done by <a href=\"https://github.com/sparckles/Robyn\">Robyn</a> to create a Python framework with a Rust runtime (Actix in their case), I always wanted to experiment with that idea.</p> <p>I am also the author of <a href=\"https://github.com/Goldziher/html-to-markdown\">html-to-markdown</a>. When I rewrote it in Rust, I created bindings for multiple languages from a single codebase. That opened the door to a genuinely polyglot web stack.</p> <p>Finally, there is the actual pain point. I work in multiple languages across different client projects. In Python I use Litestar, Sanic, FastAPI, Django, Flask, etc. In TypeScript I use Express, Fastify, and NestJS. In Go I use Gin, Fiber, and Echo. Each framework has pros and cons (and some are mostly cons). It would be better to have one standard toolkit that is correct (standards/IETF-aligned), robust, and fast across languages.</p> <p>That is what Spikard aims to be.</p> <h2>Why &quot;Toolkit&quot;?</h2> <p>The end goal is a toolkit, not just an HTTP framework. Today, Spikard exposes an HTTP framework built on <a href=\"https://github.com/tokio-rs/axum\">axum</a> and the Tokio + Tower ecosystems in Rust, which provides:</p> <ol> <li>An extremely high-performance core that is robust and battle-tested</li> <li>A wide and deep ecosystem of extensions and middleware</li> </ol> <p>This currently covers HTTP use cases (REST, JSON-RPC, WebSockets) plus OpenAPI, AsyncAPI, and OpenRPC code generation.</p> <p>The next step is to cover queues and task managers (RabbitMQ, Kafka, NATS) and CloudEvents interoperability, aiming for a full toolkit. A key inspiration here is <a href=\"https://watermill.io/\">Watermill</a> in Go.</p> <h2>Current Features and Capabilities</h2> <ul> <li>REST with typed routing (e.g. <code>/users/{id:uuid}</code>)</li> <li>JSON-RPC 2.0 over HTTP and WebSocket</li> <li>HTTP/1.1 and HTTP/2</li> <li>Streaming responses, SSE, and WebSockets</li> <li>Multipart file uploads, URL-encoded and JSON bodies</li> <li>Tower-HTTP middleware stack (compression, rate limiting, timeouts, request IDs, CORS, auth, static files)</li> <li>JSON Schema validation (Draft 2020-12) with structured error payloads (RFC 9457)</li> <li>Lifecycle hooks (<code>onRequest</code>, <code>preValidation</code>, <code>preHandler</code>, <code>onResponse</code>, <code>onError</code>)</li> <li>Dependency injection across bindings</li> <li>Codegen: OpenAPI 3.1, AsyncAPI 2.x/3.x, OpenRPC 1.3.2</li> <li>Fixture-driven E2E tests across all bindings (400+ scenarios)</li> <li>Benchmark + profiling harness in CI</li> </ul> <p>Language-specific validation integrations:</p> <ul> <li>Python: msgspec (required), with optional detection of Pydantic v2, attrs, dataclasses</li> <li>TypeScript: Zod</li> <li>Ruby: dry-schema / dry-struct detection when present</li> <li>PHP: native validation with PSR-7 interfaces</li> <li>Rust: serde + schemars</li> </ul> <h2>Roadmap to v1.0.0</h2> <p><strong>Core:</strong> - Protobuf + protoc integration - GraphQL (queries, mutations, subscriptions) - Plugin/extension system</p> <p><strong>DX:</strong> - MCP server and AI tooling integration - Expanded documentation site and example apps</p> <p><strong>Post-1.0 targets:</strong> - HTTP/3 (QUIC) - CloudEvents support - Queue protocols (AMQP, Kafka, etc.)</p> <h2>Benchmarks</h2> <p>We run continuous benchmarks + profiling in CI. Everything is measured on GitHub-hosted machines across multiple iterations and normalized for relative comparison.</p> <p>Latest comparative run (2025-12-20, Linux x86_64, AMD EPYC 7763 2c/4t, 50 concurrency, 10s, oha):</p> <ul> <li>spikard-rust: 55,755 avg RPS (1.00 ms avg latency)</li> <li>spikard-node: 24,283 avg RPS (2.22 ms avg latency)</li> <li>spikard-php: 20,176 avg RPS (2.66 ms avg latency)</li> <li>spikard-python: 11,902 avg RPS (4.41 ms avg latency)</li> <li>spikard-wasm: 10,658 avg RPS (5.70 ms avg latency)</li> <li>spikard-ruby: 8,271 avg RPS (6.50 ms avg latency)</li> </ul> <p>Full artifacts for that run are committed under <code>snapshots/benchmarks/20397054933</code> in the repo.</p> <h2>Development Methodology</h2> <p>Spikard is, for the most part, &quot;vibe coded.&quot; I am saying that openly. The tools used are Codex (OpenAI) and Claude Code (Anthropic). How do I keep quality high? By following an outside-in approach inspired by TDD.</p> <p>The first major asset added was an extensive set of fixtures (JSON files that follow a schema I defined). These cover the range of HTTP framework behavior and were derived by inspecting the test suites of multiple frameworks and relevant IETF specs.</p> <p>Then I built an E2E test generator that uses the fixtures to generate suites for each binding. That is the TDD layer.</p> <p>On top of that, I follow BDD in the literal sense: Benchmark-Driven Development. There is a profiling + benchmarking harness that tracks regressions and guides optimization.</p> <p>With those in place, the code evolved via ADRs (Architecture Decision Records) in <code>docs/adr</code>. The Rust core came first; bindings were added one by one as E2E tests passed. Features were layered on top of that foundation.</p> <h2>Getting Involved</h2> <p>If you want to get involved, there are a few ways:</p> <ol> <li>Join the <a href=\"https://discord.gg/wb8SEWvM\">Kreuzberg Discord</a></li> <li>Use Spikard and report issues, feature requests, or API feedback</li> <li>Help spread the word (always helpful)</li> <li>Contribute: refactors, improvements, tests, docs</li> </ol> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Goldziher\"> /u/Goldziher </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1psv340/spikard_v050_released/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1psv340/spikard_v050_released/\">[comments]</a></span>",
      "author": "/u/Goldziher",
      "published_date": "2025-12-22T09:08:10+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 825,
      "reading_time": 4,
      "created_at": "2025-12-22T18:32:38.845346+00:00",
      "updated_at": "2025-12-22T18:32:38.845348+00:00"
    },
    {
      "id": "0589d91a521505e1d79734512e366d9f",
      "url": "https://www.reddit.com/r/Python/comments/1psekfi/stinkiest_code_youve_ever_written/",
      "title": "Stinkiest code you've ever written?",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>Hi, I was going through my github just for fun looking at like OLD projects of mine and I found this absolute gem from when I started and didn't know what a Class was. </p> <p>essentially I was trying to build a clicker game using FreeSimpleGUI (why????) and I needed to display various things on the windows/handle clicks etc etc and found this absolute unit. A 400 line create_main_window() function with like 5 other nested sub functions that handle events on the other windows \ud83d\ude2d\ud83d\ude2d </p> <p>Anyone else have any examples of complete buffoonery from lack of experience? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Sad-Sun4611\"> /u/Sad-Sun4611 </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1psekfi/stinkiest_code_youve_ever_written/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1psekfi/stinkiest_code_youve_ever_written/\">[comments]</a></span>",
      "author": "/u/Sad-Sun4611",
      "published_date": "2025-12-21T19:18:21+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 120,
      "reading_time": 1,
      "created_at": "2025-12-22T18:32:38.845240+00:00",
      "updated_at": "2025-12-22T18:32:38.845242+00:00"
    }
  ]
}