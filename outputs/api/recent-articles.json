{
  "last_updated": "2026-01-08T11:44:08.875443+00:00",
  "count": 20,
  "articles": [
    {
      "id": "55852b727088ea2ba7a232b9120b6145",
      "url": "https://www.sciencedirect.com/science/article/pii/S1053811926000194?dgcid=rss_sd_all",
      "title": "VSSI-TBM: A variational sparse source imaging method based on time basis matrix",
      "content": "<p>Publication date: Available online 7 January 2026</p><p><b>Source:</b> NeuroImage</p><p>Author(s): Tianyu Gao, Jin Ding, Wen Li, Fulong Wang, Yujie Ma, Ruonan Wang, Yang Gao, Xiaolin Ning</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroimage",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 24,
      "reading_time": 1,
      "created_at": "2026-01-08T11:43:40.776864+00:00",
      "updated_at": "2026-01-08T11:43:40.776865+00:00"
    },
    {
      "id": "0d3663f7cf6eb284c0edade1a83c599f",
      "url": "https://www.sciencedirect.com/science/article/pii/S1053811926000170?dgcid=rss_sd_all",
      "title": "Evidence for dimensional representations and anticipatory dynamics in facial expression perception",
      "content": "<p>Publication date: Available online 7 January 2026</p><p><b>Source:</b> NeuroImage</p><p>Author(s): Tyler Roberts, Yong Zhong Liang, Gerald C. Cupchik, Jonathan S. Cant, Adrian Nestor</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroimage",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 21,
      "reading_time": 1,
      "created_at": "2026-01-08T11:43:40.776845+00:00",
      "updated_at": "2026-01-08T11:43:40.776847+00:00"
    },
    {
      "id": "5c6095c962a15bbad3e14cad6acc2c21",
      "url": "https://www.sciencedirect.com/science/article/pii/S1053811926000200?dgcid=rss_sd_all",
      "title": "Functional Gradient Alteration and Structural Remodeling in Postpartum Women",
      "content": "<p>Publication date: Available online 7 January 2026</p><p><b>Source:</b> NeuroImage</p><p>Author(s): Shiyu Xia, Xinyu Zhao, Bin Lv, Yuanyuan Gan, Yukun Kang, Jiang Long, Fang Liu, Xiao Hu, Guolin He, Haoyang Xing, Bochao Cheng</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroimage",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 30,
      "reading_time": 1,
      "created_at": "2026-01-08T11:43:40.776827+00:00",
      "updated_at": "2026-01-08T11:43:40.776829+00:00"
    },
    {
      "id": "06a409136eb1bfbf6a249980ebeb3790",
      "url": "https://www.sciencedirect.com/science/article/pii/S1053811926000236?dgcid=rss_sd_all",
      "title": "ALPS Index and Choroid Plexus Volume as Indirect MRI Biomarkers of Glymphatic Function for Predicting Cognitive Decline in Parkinson\u2019s Disease",
      "content": "<p>Publication date: Available online 7 January 2026</p><p><b>Source:</b> NeuroImage</p><p>Author(s): Xiuhang Ruan, Shuwen Bu, Yuting Li, Riyu Guo, Mengfan Wang, Xiaofei Huang, Ting Wang, Mengyan Li, Xinhua Wei</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroimage",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 26,
      "reading_time": 1,
      "created_at": "2026-01-08T11:43:40.776790+00:00",
      "updated_at": "2026-01-08T11:43:40.776791+00:00"
    },
    {
      "id": "ee4ece3d563ca81864b405dfdf1a58e7",
      "url": "https://www.sciencedirect.com/science/article/pii/S1053811926000248?dgcid=rss_sd_all",
      "title": "Multimodal MRI data fusion reveals distinct structural, functional and neurochemical correlates of depression in patients with Parkinson's disease",
      "content": "<p>Publication date: Available online 7 January 2026</p><p><b>Source:</b> NeuroImage</p><p>Author(s): Xiaorong Hou, Jiajian Zhang, Junhong Duan, Yafei Song, Xuxiong Tang, Ziwei Gong, Ziwen Li, Zhineng Kang, Yunchen Huang, Jingqi He, Xiaoxia Zhou, Beisha Tang, Yin Liu, Lifang Lei</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroimage",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 36,
      "reading_time": 1,
      "created_at": "2026-01-08T11:43:40.776771+00:00",
      "updated_at": "2026-01-08T11:43:40.776772+00:00"
    },
    {
      "id": "98e26142917dfb98a7caa0c63b775417",
      "url": "https://www.reddit.com/r/Python/comments/1q6p0kl/i_made_a_cli_word_puzzle_creatorplayer_in_python/",
      "title": "I made a CLI word puzzle creator/player in python.",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>I've created my first python project, a game that allows you to make and play word puzzles like those from WordScapes, using json files.</p> <ul> <li><strong>What My Project Does</strong>: It's a puzzle creator and player. There are currently twelve sample levels you can play. </li> <li><strong>Target Audience</strong>: People who like the word puzzle games like WordScapes, but also want to be able to create their own levels.</li> <li><strong>Comparison</strong>: I'm not aware of any project like this one.</li> </ul> <p>Repo:<a href=\"https://github.com/ebignumber/python-words\">https://github.com/ebignumber/python-words</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ebignumber\"> /u/ebignumber </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1q6p0kl/i_made_a_cli_word_puzzle_creatorplayer_in_python/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1q6p0kl/i_made_a_cli_word_puzzle_creatorplayer_in_python/\">[comments]</a></span>",
      "author": "/u/ebignumber",
      "published_date": "2026-01-07T19:27:06+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 101,
      "reading_time": 1,
      "created_at": "2026-01-08T11:43:03.047976+00:00",
      "updated_at": "2026-01-08T11:43:03.047978+00:00"
    },
    {
      "id": "54defc47631c10de56ee57edee9e69dd",
      "url": "https://www.reddit.com/r/Python/comments/1q6q9hj/unit_testing_the_performance_of_your_code/",
      "title": "Unit testing the performance of your code",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>I've been thinking about how you would unit test code performance, and come up with:</p> <ol> <li>Big-O scaling, which I wrote an article about here: <a href=\"https://pythonspeed.com/articles/big-o-tests/\">https://pythonspeed.com/articles/big-o-tests/</a></li> <li>Algorithmic efficiency more broadly, so measuring your code's speed in a way that is more than just scalability but is mostly fairly agnostic to hardware. This can be done in unit tests with things like Cachegrind/Callgrind, which simulate a CPU very minimally, and therefore can give you CPU instruction counts that are consistent across machines. And then combine that with snapshot testing and some wiggle room to take noise (e.g. from Python randomized hash seed) into account. Hope to write an article about this too eventually.</li> <li>The downside of the second approach is that it won't tell you about performance improvements or regressions that rely on CPU functionality like instruction-level parallelism. This is mostly irrelevant to pure Python code, but can come up with compiled Python extensions. This requires more elaborate setups because you're starting to rely on CPU features and different models are different. The simplest way I know of is in a PR: on a single machine (or GitHub Action run), run a benchmark in on `main`, run it on your branch, compare the difference.</li> </ol> <p>Any other ideas?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/itamarst\"> /u/itamarst </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1q6q9hj/unit_testing_the_performance_of_your_code/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1q6q9hj/unit_testing_the_performance_of_your_code/\">[comments]</a></span>",
      "author": "/u/itamarst",
      "published_date": "2026-01-07T20:13:10+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 229,
      "reading_time": 1,
      "created_at": "2026-01-08T11:43:03.047950+00:00",
      "updated_at": "2026-01-08T11:43:03.047952+00:00"
    },
    {
      "id": "d315369c9bfa21d98d851588723d489c",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.06.697873v1?rss=1",
      "title": "A Glycaemia-Prolonging Carbohydrate Gel Reduces Hunger and Cognitive Fatigue During Prolonged Esports Play",
      "content": "Prolonged esports play can induce cognitive fatigue by placing sustained demands on executive control, decision-making, and stress regulation. Since the brain relies primarily on glucose as an immediate energy source, we hypothesized that a carbohydrate gel designed to prolong post-ingestion glycaemia stabilizes interstitial glucose, attenuates hunger and cognitive fatigue, and helps preserve performance during extended esports play. Eleven healthy young men completed a randomized, double-blind crossover study with two sessions in which they ingested one of two carbohydrate gels matched for total energy and total carbohydrate but differing in carbohydrate composition (high-fructose corn syrup [HFCS]-dominant vs maltodextrin [MDX]-dominant) before gameplay. Interstitial glucose was monitored continuously, while hunger, salivary cortisol, pupil diameter, executive function, and in-game performance were assessed repeatedly. Compared with the control (HFCS-dominant) condition, the glycaemia-prolonging formulation maintained higher interstitial glucose levels during the later phase of gameplay, blunted the progressive increase in hunger, and attenuated cortisol responses. These physiological and subjective advantages were accompanied by better executive control and more adaptive defensive behaviors in-game, including fewer fouls and more interceptions. In contrast, pupil diameter, an index of global arousal, remained unchanged across conditions, suggesting that benefits were not driven by altered arousal but by improved glycaemic stability and appetite regulation. These findings indicate that a carbohydrate formulation that prolongs glycaemia can reduce hunger-linked cognitive fatigue and support task-relevant behavior during prolonged esports play. This low-burden nutritional strategy may help sustain mental performance during prolonged digital activities that impose high cognitive demands.",
      "author": "Matsui, T., Takahashi, S., Yamaguchi, T., Funabashi, D., Imada, T., Shimizu, H.",
      "published_date": "2026-01-08T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 243,
      "reading_time": 1,
      "created_at": "2026-01-08T11:22:26.931255+00:00",
      "updated_at": "2026-01-08T11:22:26.931260+00:00"
    },
    {
      "id": "df0d21166377df051e1fc37e28682878",
      "url": "https://www.reddit.com/r/Python/comments/1q6d3qd/mlship_zeroconfig_ml_model_serving_across/",
      "title": "mlship \u2013 Zero-config ML model serving across frameworks",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019ve watched a lot of students and working developers struggle with the same problem:<br /> they learn scikit-learn, PyTorch, TensorFlow, and HuggingFace - but <em>each framework has a completely different deployment story</em>.</p> <p>Flask/FastAPI for sklearn, TorchServe for PyTorch, TF Serving for TensorFlow, transformers-serve for HuggingFace - all with different configs and mental models.</p> <p>So I built <strong>mlship</strong>, a small Python CLI that turns <em>any</em> ML model into a REST API with a single command:</p> <pre><code>mlship serve model.pkl </code></pre> <p>No Docker. No YAML. No framework-specific server code.</p> <h1>What My Project Does</h1> <p><code>mlship</code> automatically detects the model type and serves it as a local HTTP API with:</p> <ul> <li><code>POST /predict</code> \u2013 inference</li> <li><code>GET /health</code> \u2013 health check</li> <li><code>/docs</code> \u2013 auto-generated Swagger UI</li> </ul> <p>Supported today:</p> <ul> <li>scikit-learn (<code>.pkl</code>, <code>.joblib</code>)</li> <li>PyTorch (<code>.pt</code>, <code>.pth</code> via TorchScript)</li> <li>TensorFlow (<code>.h5</code>, <code>.keras</code>, SavedModel)</li> <li>HuggingFace models (local or directly from the Hub)</li> </ul> <p>The goal is to make <em>deployment feel the same</em> regardless of the training framework.</p> <h1>Installation</h1> <pre><code>pip install mlship </code></pre> <p>(Optional extras are available for specific frameworks.)</p> <h1>Example</h1> <p>Serving a HuggingFace model directly from the Hub:</p> <pre><code>mlship serve distilbert-base-uncased-finetuned-sst-2-english --source huggingface </code></pre> <p>Test it:</p> <pre><code>curl -X POST http://localhost:8000/predict \\ -H &quot;Content-Type: application/json&quot; \\ -d '{&quot;features&quot;: &quot;This product is amazing!&quot;}' </code></pre> <p>No model download, no custom server code.</p> <h1>Target Audience</h1> <p>mlship is aimed at:</p> <ul> <li>Students learning ML deployment</li> <li>Data scientists prototyping models locally</li> <li>Educators teaching framework-agnostic ML systems</li> <li>Developers who want a quick, inspectable API around a model</li> </ul> <p>It is <strong>not</strong> meant to replace full production ML platforms - it\u2019s intentionally local-first and simple.</p> <h1>Why This Exists (Motivation)</h1> <p>Most ML tooling optimizes for:</p> <ul> <li>training</li> <li>scaling</li> <li>orchestration</li> </ul> <p>But a huge amount of friction exists <em>before</em> that - just getting a model behind an API to test, demo, or teach.</p> <p>mlship focuses on:</p> <ul> <li>reducing deployment fragmentation</li> <li>minimizing configuration</li> <li>making ML systems feel more like regular software services</li> </ul> <h1>Project Status</h1> <ul> <li>Open source (MIT)</li> <li>Early but usable</li> <li>Actively developed</li> <li>Known rough edges</li> </ul> <p>I\u2019m actively looking for feedback and contributors, especially around:</p> <ul> <li>XGBoost / LightGBM support</li> <li>GPU handling</li> <li>More HuggingFace task types</li> </ul> <h1>Links</h1> <ul> <li><strong>GitHub:</strong> <a href=\"https://github.com/sudhanvalabs/mlship\">https://github.com/sudhanvalabs/mlship</a></li> <li><strong>Quick Start:</strong> <a href=\"https://github.com/sudhanvalabs/mlship/blob/main/QUICKSTART.md\">https://github.com/sudhanvalabs/mlship/blob/main/QUICKSTART.md</a></li> <li><strong>PyPI:</strong> <a href=\"https://pypi.org/project/mlship/\">https://pypi.org/project/mlship/</a></li> <li><strong>Why mlship</strong>: <a href=\"https://github.com/sudhanvalabs/mlship/blob/main/WHY_MLSHIP.md\">https://github.com/sudhanvalabs/mlship/blob/main/WHY_MLSHIP.md</a></li> </ul> <p>I\u2019d really appreciate:</p> <ul> <li>practical feedback</li> <li>edge cases you run into</li> <li>suggestions on where the abstraction breaks down</li> </ul> <p>Thanks for reading!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/peshwar9\"> /u/peshwar9 </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1q6d3qd/mlship_zeroconfig_ml_model_serving_across/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1q6d3qd/mlship_zeroconfig_ml_model_serving_across/\">[comments]</a></span>",
      "author": "/u/peshwar9",
      "published_date": "2026-01-07T11:36:55+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 410,
      "reading_time": 2,
      "created_at": "2026-01-08T11:21:50.728782+00:00",
      "updated_at": "2026-01-08T11:21:50.728784+00:00"
    },
    {
      "id": "c89d2ad698747e7dcffde4a37776f9ab",
      "url": "https://www.nature.com/articles/s41593-025-02191-y",
      "title": "Rethinking the role of position in cortical function",
      "content": "<p>Nature Neuroscience, Published online: 08 January 2026; <a href=\"https://www.nature.com/articles/s41593-025-02191-y\">doi:10.1038/s41593-025-02191-y</a></p>Abnormally located cortical neurons, displaced in developing mice lacking cortical Eml1, retain their molecular identities, form appropriate connections and build functional sensory maps. Most strikingly, these misplaced neurons can drive behavior by themselves \u2014 showing that brain function depends on how neurons connect, and to what, more than where they live.",
      "author": "",
      "published_date": "2026-01-08T00:00:00+00:00",
      "source": "Nature Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 59,
      "reading_time": 1,
      "created_at": "2026-01-08T10:51:47.396158+00:00",
      "updated_at": "2026-01-08T10:51:47.396162+00:00"
    },
    {
      "id": "cb985508c82ff275099651880c945849",
      "url": "https://iopscience.iop.org/article/10.1088/1741-2552/ae2e8c",
      "title": "Neuropacify: a method to transform and match a patient\u2019s intracranial EEG to their NeuroPace RNS system data",
      "content": "Objective. Closed-loop responsive neurostimulators, such as the NeuroPace responsive neurostimulation (RNS) system, continuously monitor brain activity and deliver electrical stimulation in response to abnormal electrographic activity in patients with drug-resistant epilepsy. Practical technical constraints limit the temporal resolution of these devices, reducing the quality of EEG recordings. Approach. In this work, we introduce a novel technique to convert high-resolution intracranial electroencephalography (iEEG) obtained from inpatient monitoring into the same format, parameters, and resolution produced by the RNS system, allowing direct comparison of iEEG with RNS system data. We validated this technique using data from patients who had both iEEG and RNS. Electrodes from the iEEG and RNS system were co-registered onto the same 3D coordinate grid, and vector math was applied to determine the iEEG electrodes closest to the operational RNS electrodes. Main results. Through spectral analysis, we derived a transfer function that accounts for all filtering and data processing produced by the RNS system. Comparison of the recorded data using visual and spectral analysis from iEEG and RNS confirmed that EEG characteristics were correctly transformed by the filtering function, allowing analysis of how iEEG signals would appear within the RNS system. We demonstrate two examples from the extreme edges of the spectra, showing how DC shifts and high frequency oscillations would be transformed by the RNS. We provide a tutorial to tune this method to local device parameters, a process that can be applied to other devices as well. Significance. This tool allows researchers and clinicians to extract EEG biomarkers from high-resolution iEEG and determine if/how they can be detected in lower-resolution RNS. This provides an opportunity to develop patient-specific seizure detection parameters and investigate the long-term effects of neurostimulation therapy.",
      "author": "Grant Barkelew, Kathleen Kish, Zachary T Sanger, Raghav Varshney, Sarah Dykstra, David Brang, Theoden I Netoff and William C Stacey",
      "published_date": "2026-01-08T00:00:00+00:00",
      "source": "Journal Neural Engineering",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 282,
      "reading_time": 1,
      "created_at": "2026-01-08T10:51:35.131833+00:00",
      "updated_at": "2026-01-08T10:51:35.131837+00:00"
    },
    {
      "id": "a668eff328603c5780f8e2b42a4f50bc",
      "url": "https://en.wikipedia.org/wiki/Audio_induction_loop",
      "title": "Anyone have experiences with Audio Induction Loops?",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46492401\">Comments</a>",
      "author": "",
      "published_date": "2026-01-04T21:23:27+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-08T10:51:13.090072+00:00",
      "updated_at": "2026-01-08T10:51:13.090073+00:00"
    },
    {
      "id": "feff8a1ee194ff9f73450f00f3b9ca2f",
      "url": "https://www.sciencedirect.com/science/article/pii/S0306452225012357?dgcid=rss_sd_all",
      "title": "Altered cerebral thyroid hormone, WNT and NOTCH signalling and impaired myelination following intrauterine growth restriction in rats",
      "content": "<p>Publication date: 16 February 2026</p><p><b>Source:</b> Neuroscience, Volume 595</p><p>Author(s): Aminath Azhan, Angela L. Cumberland, Ginevra Chincarini, Mikaela Barresi, Nadia Hale, David H. Rowitch, Flora Wong, David W. Walker, Mary Tolcos</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroscience Journal",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 29,
      "reading_time": 1,
      "created_at": "2026-01-08T10:27:11.386928+00:00",
      "updated_at": "2026-01-08T10:27:11.386939+00:00"
    },
    {
      "id": "f824183e4879a5585cdc7061c6f9f627",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.07.698224v1?rss=1",
      "title": "Modular presynaptic assemblages scale to postsynaptic partner number",
      "content": "Behavioral diversification can arise through, and is constrained by, evolutionary and inter-individual differences in neural circuit development. Moreover, alteration of focal neural parameters changes the environment in which cells connect into circuits. In the mushroom body, an associative learning center of arthropods, the number of principal Kenyon cells varies widely across species and among individuals. How such variation is developmentally accommodated by projection neurons, which provide sensory input to Kenyon cells, is not understood. In Drosophila melanogaster, we previously demonstrated that projection neurons scale their presynaptic bouton number to Kenyon cell population size. Here, we identify the developmental mechanisms underlying this input flexibility. Boutons arise from projection neuron axonal collaterals; we find that a projection neuron's collateral number is subtype-specific and serves as the substrate through which bouton number scales to Kenyon cell population size. Independent of projection neuron identity or Kenyon cell number, individual collaterals most often produce just one bouton, suggesting collaterals are modular cell biological bouton units. Developing projection neurons initially overproduce nascent collaterals in the early pupa. The set of nascent collaterals that mature and eventually bear boutons is conditional on Kenyon cell number, thereby executing scaling. Finally, early boutons bear filopodia that frequently contact neighboring projection neuron processes, suggesting that bouton-bouton interactions contribute to shaping these structures.",
      "author": "Punal, V. M., Thornton-Kolbe, E. M., Dhillon, J., Rogow, J. A., Clowney, E. J.",
      "published_date": "2026-01-08T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 212,
      "reading_time": 1,
      "created_at": "2026-01-08T10:27:07.641326+00:00",
      "updated_at": "2026-01-08T10:27:07.641328+00:00"
    },
    {
      "id": "2e1980f0de20dda9284d0bc4201a649f",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.07.698021v1?rss=1",
      "title": "The modular nature of long-association pathways in the human brain",
      "content": "Human brain functions are organized within large-scale networks, yet the long-range structural pathways that support them remain only partly understood. Diffusion MRI tractography has enabled non-invasive mapping of these connections but its low resolution has also contributed to a view of white matter association bundles as monolithic entities linking distant cortical regions. This contrasts with anatomical studies in non-human primates and humans, which show these bundles act as conduits for complex systems of short- and long-range projections. Here we investigate the dorsal branch of the superior longitudinal fasciculus (SLF-I), the proposed structural backbone of the dorsal attention network, whose anatomy in humans is debated. Using anatomic tracing, polarization-sensitive optical coherence tomography, and in vivo and ex vivo diffusion MRI, we reconstruct the SLF-I across species, modalities, and scales. High resolution tractography (<750 m), consistent with tracer and PS-OCT data, reveals multiple fiber systems of varying lengths rather than uniform parieto-frontal connections observed at more conventional resolution (1.5 mm). Comparative analyses show a consistent organization: the SLF-I carries short-range cortico-cortical projections rostral to area 6 and longer, layered connections extending to parietal regions, while direct parieto-frontal connectivity is mostly supported by the adjacent cingulum bundle. These findings reconcile our understanding of the SLF-I across the scales of non-invasive neuroimaging and invasive anatomic studies and provide an updated framework for future investigations of large-scale networks in health and disease.",
      "author": "Maffei, C., Celestine, M. R., Gong, T., Jones, R., Dann, E., Lehman, J., Augustinack, J., Wang, H., Haber, S. N., Yendiki, A.",
      "published_date": "2026-01-08T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 227,
      "reading_time": 1,
      "created_at": "2026-01-08T10:27:07.641289+00:00",
      "updated_at": "2026-01-08T10:27:07.641291+00:00"
    },
    {
      "id": "888c6744126df2de3790815970ae69ca",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.07.698095v1?rss=1",
      "title": "Temporal order of activations and interactions during arithmetic calculations measured by intracranial electrophysiological recordings in the human brain",
      "content": "Arithmetic requires complex and fast processes orchestrated within a large-scale network spanning multiple brain regions. However, reports on the network's temporal dynamics are scarce. Here, we present data from intracranial EEG (iEEG) of 20 subjects (epilepsy surgery candidates) performing a sequential three-operand arithmetic task. Utilizing the high temporal and spatial resolution of iEEG, we analysed changes in high-gamma band (HGB; 52-120 Hz) activity and functional connectivity assessed by phase-locking value (PLV) in the delta (0.1-3 Hz) and theta (3-7 Hz) frequency bands. Strong and transient HGB activations peaked first in the ventral occipito-temporal cortex, followed by a more gradual increase in the lateral parietal, sensorimotor, and frontal cortices, accompanied by deactivations in default mode network areas. The connectivity patterns were more extensive during calculation than number recognition, with the theta PLV peaking ~150 ms earlier than the delta PLV. Earliest connectivity appeared, surprisingly, between ventral temporal and frontal regions at ~100-200 ms, evolving into a robust pattern among key network nodes at ~200-400 ms after the presentation of each operand. The presented results elucidate information flow within the putative arithmetic network during calculation in the human brain, offering high-temporal-resolution insights into its functional architecture.",
      "author": "Kalinova, M., Kerkova, B., Kalina, A., Pytelova, V., Amlerova, J., Janca, R., Jezdik, P., Krysl, D., Kudr, M., Krsek, P., Marusic, P., Hammer, J.",
      "published_date": "2026-01-08T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 194,
      "reading_time": 1,
      "created_at": "2026-01-08T10:27:07.641230+00:00",
      "updated_at": "2026-01-08T10:27:07.641232+00:00"
    },
    {
      "id": "e08e32c01561571c5a5e4e74d0a70103",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.07.695461v1?rss=1",
      "title": "Talking avatars can differentially modulate cortical speech tracking in the high and in the low delta band",
      "content": "In noisy listening environments, visual cues from a speaker's face can significantly boost speech comprehension. The underlying audiovisual integration in the brain involves neural tracking of audiovisual speech features. Moreover, lip reading in silence is associated with tracking of the speech envelope in the low-delta frequency band (0.5 - 1 Hz). Recently, digital avatars have emerged that can support speech comprehension. Yet, it remains unclear how the human brain integrates such artificial visual signals with natural speech. Here, we employed magnetoencephalography (MEG) to measure the neural response to a natural video, an avatar generated by deep neural networks, and a degraded video serving as a control. We demonstrate that the avatar can enhance speech-in-noise comprehension to a similar degree as the degraded video, although less than the natural video. We further identify a late response at 600 ms in the neural tracking of the auditory cortex in the high delta band (1 - 4 Hz) that predicts audiovisual speech comprehension. In contrast, we found that neural tracking in the low delta band is related to silent lip-reading performance. Importantly, the tracking in the low delta band evoked by the avatars is much weaker and occurs earlier than that elicited by the other audiovisual stimuli. Neural tracking in the theta band (4 - 8 Hz) is not involved in audiovisual integration. Our results show that the low delta band and the high delta band play clearly distinct roles in visual-only and audiovisual speech processing, and suggest potential avenues for further boosting the abilities of avatars to support speech comprehension.",
      "author": "Riegel, J., Schu\u0308ller, A., Jehn, C., Wissmann, A., Zeiler, S., Kolossa, D., Reichenbach, T.",
      "published_date": "2026-01-08T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 258,
      "reading_time": 1,
      "created_at": "2026-01-08T10:27:07.641195+00:00",
      "updated_at": "2026-01-08T10:27:07.641197+00:00"
    },
    {
      "id": "4a0c9a202d141357aee0dbc009143d11",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.07.698044v1?rss=1",
      "title": "Neural representations supporting generalization under continual learning",
      "content": "Abstraction and generalization are essential for flexible decision-making in novel situations. Recent work in humans and monkeys has shown how abstract variables are encoded by the representational geometry of neural population activity. However, these observations--which are typically made after learning has converged--demonstrate the product of abstraction, but not the process by which abstract knowledge is learned: how are the inputs from concrete experiences transformed into abstract knowledge, and how do neural circuits perform these operations and relay this knowledge? To address these questions, we developed a factorized model of temporal abstraction that builds on the successor representation. The model disentangles the contributions of different levels of abstract learning--from stimulus-stimulus associations to a generalizable task schema--in the form of a factorized prediction error that relates the change in relational knowledge to a predicted change in representational geometry on each trial. We fit the model to the behavior of human participants performing a context-dependent decision task during fMRI. The model captured the learning dynamics at multiple timescales, including the increasing contribution of generalization as participants transferred abstracted relational knowledge between novel task instances. In fMRI, BOLD activity in hippocampus--where, in past work, abstract knowledge was represented after learning--was increasingly attributed to the acquisition of abstract knowledge based on generalization. A similar temporal pattern was observed in entorhinal cortex, a putative source of low-dimensional structural information, and orbitofrontal cortex (OFC), which may depend on relational knowledge to represent state relationships as a cognitive map that guides choices. Indeed, individual variation in the generalization signal in OFC correlated with behavioral performance on key trials that required relational knowledge. Our findings show how the brain regions previously shown to represent abstract knowledge after learning also support the process of abstraction as it evolves from learning concrete associations to a generalizable schema. Our approach offers a computational framework for disentangling the operations driving abstract learning and probing their neural correlates in the dynamics of representational geometry.",
      "author": "Kimmel, D. L., Stachenfeld, K. L., Kriegeskorte, N., Fusi, S., Salzman, C. D., Shohamy, D.",
      "published_date": "2026-01-08T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 320,
      "reading_time": 1,
      "created_at": "2026-01-08T10:27:07.641156+00:00",
      "updated_at": "2026-01-08T10:27:07.641158+00:00"
    },
    {
      "id": "69105b0b3a343ac41d5a67d71c17aeb3",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.07.697914v1?rss=1",
      "title": "Mapping subcortical fear pathways in the human brain: thalamo-amygdala connections revealed by high-resolution tractography",
      "content": "Influential models of emotion have postulated the existence of several direct subcortical pathways, or ''low roads'', that convey fast sensory thalamic inputs to the amygdala for affective processing. In rodents and non-human primates, specific thalamo-amygdala connections have been identified and linked to fear responses. These connections mainly originate in three thalamic nuclear groups (posterior, intralaminar, and medial) and project to the basolateral amygdala (BLA). However, the existence of similar thalamo-amygdala pathways in humans remains uncertain. Here, aiming to reproduce subcortical amygdala connections previously described in the non-human animal literature, we mapped those tracts in 113 human participants of either sex. We implemented an advanced high-resolution tractography protocol optimized for reliably tracing axonal pathways through regions with complex white-matter architecture. We reconstructed white matter tracts connecting thalamic nuclei to the BLA, and assessed their test-retest reproducibility to evaluate their anatomical plausibility. Among posterior thalamic nuclei, projections from the medial geniculate nucleus and the medial and inferior pulvinar to the BLA emerged as the strongest and most robust thalamo-amygdala pathways. In turn, the mediodorsal nucleus within the medial group exhibited a prominent connection to the BLA, with a high number of streamlines and moderate-to-high reliability across sessions. Finally, intralaminar thalamic nuclei (parafascicular, central medial, and centromedian) showed consistent connections to the BLA, albeit with higher intrasubject variability and moderate-to-low reproducibility. Together, these findings provide a unifying anatomical framework for multiple direct thalamo-amygdala pathways in the human brain, and suggest the existence of distinct evolutionarily conserved routes for subcortical affective processing.",
      "author": "Kosteletou-Kassotaki, E., Mengxing, L., Cinca-Tomas, M. T., Paz-Alonso, P. M., Dominguez-Borras, J.",
      "published_date": "2026-01-08T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 248,
      "reading_time": 1,
      "created_at": "2026-01-08T10:27:07.641108+00:00",
      "updated_at": "2026-01-08T10:27:07.641110+00:00"
    },
    {
      "id": "4a0c953bbd52970e7f246fc0935dceac",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.07.698102v1?rss=1",
      "title": "Attention modulates neural representations of acoustic, categorical, and identity features in a task-dependent manner",
      "content": "Aims The human auditory system represents sounds at multiple levels, from low-level acoustic features to abstract category- and object-level information. Although selective auditory attention enables listening in complex soundscapes, it remains unclear which representational levels are modulated by attention and how this depends on scene structure. Using fMRI, representational similarity analysis (RSA), and cross-experiment decoding, this study examined how attention modulates neural representations of sound features under different competitive listening conditions. Methods Twenty participants completed an fMRI experiment involving three selective attention conditions: one sound presented alone, three overlapping sounds from different categories, and three overlapping sounds from the same category. Neural activation patterns were compared to models of multiple low-level acoustic and abstract sound features using RSA, with covariance between models statistically removed to isolate unique representations. Attentional modulation was quantified by contrasting representations of attended and ignored sound features, and cross-experiment decoding was used to assess object-identity representations. Conclusions Low-level acoustic features were robustly represented in early auditory cortex, whereas abstract sound features were broadly represented along temporal and frontal regions of the auditory ventral stream. Attentional modulation was task-dependent: when competing sounds could not be distinguished by category, attention enhanced low-level acoustic feature processing, whereas in cross-category scenes attention primarily targeted abstract category-level representations. Object-identity representations were modulated by attention across both scene types, with category-specific differences. These findings demonstrate that auditory attention flexibly targets the representational level most informative for resolving competition in complex soundscapes.",
      "author": "Varis, O., Muukkonen, I., Wikman, P.",
      "published_date": "2026-01-08T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 239,
      "reading_time": 1,
      "created_at": "2026-01-08T10:27:07.641061+00:00",
      "updated_at": "2026-01-08T10:27:07.641066+00:00"
    }
  ]
}