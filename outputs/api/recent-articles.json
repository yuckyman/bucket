{
  "last_updated": "2025-11-27T16:19:00.809253+00:00",
  "count": 20,
  "articles": [
    {
      "id": "80d1f642eb4da0958753076107ac0cbe",
      "url": "http://daniellakens.blogspot.com/2025/07/easily-download-files-from-open-science.html",
      "title": "Easily download files from the Open Science Framework with Papercheck",
      "content": "<p>Researchers\nincreasingly use the <a href=\"https://osf.io/\">Open Science Framework</a> (OSF) to share files, such as data\nand code underlying scientific publications, or presentations and materials for\nscientific workshops. The OSF is an amazing service that has contributed\nimmensely to a changed research culture where psychologists share data, code, and\nmaterials. We are very grateful it exists.</p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">But it is\nnot always the most user-friendly. Specifically, downloading files from the OSF\nis a bigger hassle than we (<a href=\"https://debruine.github.io/\">Lisa DeBruine</a>\nand <a href=\"https://www.tue.nl/en/research/researchers/daniel-lakens/\">Daniel\nLakens</a>, the developers of Papercheck) would like it to be. Downloading individual\nfiles is so complex, <a href=\"https://bsky.app/profile/malte.the100.ci/post/3lpf4s6spns2i\">Malte Elson</a>\nrecently posted this meme on Bluesky. </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"NL\"><!--[if gte vml 1]><v:shapetype\n id=\"_x0000_t75\" coordsize=\"21600,21600\" o:spt=\"75\" o:preferrelative=\"t\"\n path=\"m@4@5l@4@11@9@11@9@5xe\" filled=\"f\" stroked=\"f\">\n <v:stroke joinstyle=\"miter\"/>\n <v:formulas>\n  <v:f eqn=\"if lineDrawn pixelLineWidth 0\"/>\n  <v:f eqn=\"sum @0 1 0\"/>\n  <v:f eqn=\"sum 0 0 @1\"/>\n  <v:f eqn=\"prod @2 1 2\"/>\n  <v:f eqn=\"prod @3 21600 pixelWidth\"/>\n  <v:f eqn=\"prod @3 21600 pixelHeight\"/>\n  <v:f eqn=\"sum @0 0 1\"/>\n  <v:f eqn=\"prod @6 1 2\"/>\n  <v:f eqn=\"prod @7 21600 pixelWidth\"/>\n  <v:f eqn=\"sum @8 21600 0\"/>\n  <v:f eqn=\"prod @7 21600 pixelHeight\"/>\n  <v:f eqn=\"sum @10 21600 0\"/>\n </v:formulas>\n <v:path o:extrusionok=\"f\" gradientshapeok=\"t\" o:connecttype=\"rect\"/>\n <o:lock v:ext=\"edit\" aspectratio=\"t\"/>\n</v:shapetype><v:shape id=\"_x0000_i1026\" type=\"#_x0000_t75\" style='width:453.75pt;\n height:276pt;visibility:visible;mso-wrap-style:square'>\n <v:imagedata src=\"file:///C:/Users/DLakens/AppData/Local/Temp/msohtmlclip1/01/clip_image001.jpg\"\n  o:title=\"\"/>\n</v:shape><![endif]--><!--[if !vml]--><img border=\"0\" height=\"368\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEinS5tFoL5qX14Z2OcgT1APMZLGlghAD3BfBhSnJ9pleVbJyRFUFLShqReS2j7SXGozmLMcVQkoM62UhneJDtH4yx3NRnXOkVZZi-Dm-OPwbGaidxr2raF9wzjx5fU92nfPpE3jmGfwZEwHS1WGSB4gUfRfV3XWjOC2-lCjOYR108h3fwORIHOnqxIX9m8\" width=\"605\" /><!--[endif]--></span><span lang=\"EN-US\"></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\"><span>&nbsp;</span></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">Not only is\nthe download button for files difficult to find, but downloading all files\nrelated to a project can be surprisingly effortful. It is possible to download\nall files in a zip folder that will be called \u2018osfstorage-archive.zip\u2019 when\ndownloaded. But as the OSF supports a nested folder structure, you might miss a\nfolder, and you will quickly end up with \u2018osfstorage-archive (1).zip\u2019, \u2018osfstorage-archive\n(2).zip\u2019, etc. Unzipping these archives creates a lot of files without the\norganized folder structure, in folders with meaningless names, making it\ndifficult to understand where files are. </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<h2 style=\"text-align: left;\"><b><span lang=\"EN-US\">The\nosf_file_download function in Papercheck </span></b></h2>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">We have added\na new function to our R package \u2018<a href=\"https://scienceverse.github.io/papercheck/\">Papercheck</a>\u2019 that will download all files and\nfolders in an OSF repository. It saves all files by recreating the folder\nstructure from the OSF in your download folder. Just install Papercheck, load\nthe library, and use the osf_file_download function to grab all files on the OSF:</span></p><p class=\"MsoNormal\"><span lang=\"EN-US\"><br /></span></p>\n\n<div style=\"text-align: left;\"><span style=\"font-family: courier;\"><b><span lang=\"EN-US\">devtools::install_github(\"scienceverse/papercheck\")<br /></span></b><b><span lang=\"EN-US\">library(papercheck)<br /></span></b><b><span lang=\"EN-US\">osf_file_download(\"6nt4v\")</span></b></span></div>\n\n\n\n\n\n<p class=\"MsoNormal\"><b><span lang=\"EN-US\">&nbsp;</span></b></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">All files\nwill be downloaded to your working directory. </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">Are you feeling\nFOMO for missing out on the <a href=\"https://www.kcl.ac.uk/events/open-research-summer-school-2025\">King Open\nResearch Summer School</a> that is going on these days, where <a href=\"https://research.tue.nl/en/persons/sajedeh-rasti\">Sajedeh Rasti</a> talked\nabout Preregistration, and <a href=\"https://research.tue.nl/en/persons/cristian-mesquida-caldentey\">Cristian\nMesquida</a> will give a workshop on using Papercheck? Well, at least it is\nvery easy to download all the files they have shared on the OSF and look at the\npresentations: </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\"><span style=\"font-family: courier;\">osf_file_download(\"b7es8\")</span></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">In the\noutput, we see that by default large files (more than 10mb) are omitted. <span><!--[if gte vml 1]><v:shape id=\"Picture_x0020_1\"\n o:spid=\"_x0000_i1025\" type=\"#_x0000_t75\" alt=\"A screenshot of a computer&#10;&#10;AI-generated content may be incorrect.\"\n style='width:453.75pt;height:292.5pt;visibility:visible;mso-wrap-style:square'>\n <v:imagedata src=\"file:///C:/Users/DLakens/AppData/Local/Temp/msohtmlclip1/01/clip_image003.png\"\n  o:title=\"A screenshot of a computer&#10;&#10;AI-generated content may be incorrect\"/>\n</v:shape><![endif]--><!--[if !vml]--><img alt=\"A screenshot of a computer\n\nAI-generated content may be incorrect.\" border=\"0\" height=\"390\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEj2jH76ywmEeLzL43u6gJl7GKR2lEGlhYS0LOXRPMMovOsJEVdXyamYCvmq96ez3p_GXHLoFz4JDyAKHlARK9pSy8QfzVa7yt1_uEg_H9IJfKgunnYWUwlROXABNcU6TvrA0_hx0KPZfj00b3Cb-Wn_7Bf3sFu9JApZoClcWoh_Vfl5bk1GQVZUH1tuGao\" width=\"605\" /><!--[endif]--></span></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">If you want\nto download all files, regardless of the size, then set the parameter to ignore\nthe maximum file size: </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\"><span style=\"font-family: courier;\">osf_file_download(\"b7es8\",\nmax_file_size = NULL)</span></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">Sometimes\nyou might want to download all files but ignore the file structure on the OSF,\nto just have all the files in one folder. Setting the parameter ignore_folder_structure\n= TRUE will give you all the files on the OSF in a single folder. By default, files will be downloaded into your working directory, but you can also specify\nwhere you want the files to be saved. </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\"><span style=\"font-family: courier;\">osf_file_download(\"6nt4v\",\nignore_folder_structure = TRUE, download_to = \"C:\\\\test_download\")</span></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">We hope\nthis function will make it easier for reviewers to access all supplementary\nfiles stored on the OSF during peer review, and for researchers who want to re-use\ndata, code, or materials shared on the OSF by downloading all the files they\nneed easily. Make sure to install the latest version of Papercheck (0.0.0.9050)\nto get access to this new function. Papercheck is still in active development,\nso report any bugs on <a href=\"https://github.com/scienceverse/papercheck\">GitHub</a>.</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>",
      "author": "noreply@blogger.com (Daniel Lakens)",
      "published_date": "2025-07-22T09:53:00+00:00",
      "source": "Twenty Percent Statistician",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 765,
      "reading_time": 3,
      "created_at": "2025-11-27T15:43:11.557542+00:00",
      "updated_at": "2025-11-27T16:19:00.699152+00:00",
      "metadata": {
        "processed_at": "2025-11-27T16:19:00.699163+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "5cf06dd1c8477abb17ef4e5c3b5426e0",
      "url": "https://erpinfo.org/blog/2021/12/22/applications-2023",
      "title": "Applications now being accepted for UC-Davis/SDSU ERP Boot Camp, July 31 \u2013 August 9, 2023",
      "content": "<p class=\"\">The next 10-day ERP Boot Camp will be held July 31 \u2013 August 9, 2023 in San Diego, California. We are now taking applications, which will be due by April 1, 2023. <a href=\"https://erpinfo.org/summer-boot-camp\">Click here</a> for more information.</p><p class=\"\">We are currently planning to hold this workshop as an in-person event. However, these plans are subject to change as the COVID-19 pandemic evolves. If the event is held in person, we will require that everyone is fully vaccinated, and we will also implement any other safety measures that are warranted at the time of the workshop.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"980\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/1609175691205-RTD3XM69YGOFMVP23U6T/Boot_Camp_Logo.png?format=1000w\" width=\"1148\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>",
      "author": "Steve Luck",
      "published_date": "2023-01-16T18:31:57+00:00",
      "source": "Erp Boot Camp",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 108,
      "reading_time": 1,
      "created_at": "2025-11-27T15:43:09.075860+00:00",
      "updated_at": "2025-11-27T16:19:00.699170+00:00",
      "metadata": {
        "processed_at": "2025-11-27T16:19:00.699172+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "bd7398ecbbd90ecd3269866b2fd3744f",
      "url": "https://erpinfo.org/blog/2023/6/23/decoding-webinar",
      "title": "ERP Decoding for Everyone: Software and Webinar",
      "content": "<p class=\"\"><strong>You can access the recording </strong><a href=\"https://video.ucdavis.edu/media/Virtual+ERP+Boot+CampA+Decoding+for+Everyone%2C+July+25+2023/1_lmwj6bu0\"><strong>here</strong></a><strong>.<br />You can access the final PDF of the slides </strong><a href=\"https://ucdavis.box.com/s/flf9gzeo12rz2jhxptih7xjl0omka2k7\"><strong>here</strong></a><strong>. <br />You can access the data </strong><a href=\"https://doi.org/10.18115/D5KS6S\"><strong>here</strong></a><strong>.</strong></p><p class=\"\">fMRI research has used decoding methods for over 20 years. These methods make it possible to decode what an individual is perceiving or holding in working memory on the basis of the pattern of BOLD activity across voxels. Remarkably, these methods can also be applied to ERP data, using the pattern of voltage across electrode sites rather than the pattern of activity across voxels to decode the information being represented by the brain (<a href=\"https://erpinfo.org/blog/2018/9/16/decoding\">see this previous blog post</a>). For example, ERPs can be used to decode the identity of a face that is being perceived, the emotional valence of a scene, the identity and semantic category of a word, and the features of an object that is being maintained in working memory. Moreover, decoding methods can be more sensitive than traditional methods for detecting conventional ERP effects (e.g., whether a word is semantically related or unrelated to a previous word in an N400 paradigm).</p><p class=\"\">So far, these methods have mainly been used by a small set of experts. We aim to change that with the upcoming Version 10 of <a href=\"https://erpinfo.org/erplab\">ERPLAB Toolbox</a>. This version of ERPLAB will contain an ERP decoding tool that makes it trivially easy for anyone who knows how to do conventional ERP processing to take advantage of the power of decoding. It should be available in mid-July at <a href=\"https://github.com/ucdavis/erplab/releases\">our GitHub site</a>. You can join the <a href=\"https://github.com/ucdavis/erplab/wiki/ERPLAB-email-list\">ERPLAB email list</a> to receive an announcement when this version is released. Please do not contact us with questions until it has been released and you have tried using it.</p><p class=\"\">On July 25, 2023, we will hold a 2-hour Zoom webinar to explain how decoding works at a conceptual level and show how to implement in ERPLAB Toolbox. The webinar will begin at 9:00 AM Pacific Time (California), 12:00 PM Eastern Time (New York), 5:00 PM British Summer Time (London), 6:00 PM Central European Summer Time (Berlin). </p><p class=\"\">The webinar is co-sponsored by the <a href=\"https://erpinfo.org/the-erp-boot-camp\">ERP Boot Camp</a> and the <a href=\"https://sprweb.org\">Society for Psychophysiological Research</a>. It is completely free, but you must register in advance at <a href=\"https://ucdavis.zoom.us/meeting/register/tJUrc-CtpzorEtBSmZXJINOlLJB9ZR0evpr4\">https://ucdavis.zoom.us/meeting/register/tJUrc-CtpzorEtBSmZXJINOlLJB9ZR0evpr4</a>. Once you register, you will receive an email with your own individual Zoom link. </p><p class=\"\">We will make a recording available a few days after the webinar on the <a href=\"https://erpinfo.org\">ERPinfo.org</a> web site.</p><p class=\"\">Please direct any questions about the webinar to <a href=\"mailto:erpbootcamp@gmail.com\">erpbootcamp@gmail.com</a>.</p>",
      "author": "Steve Luck",
      "published_date": "2023-06-23T21:05:26+00:00",
      "source": "Erp Boot Camp",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 420,
      "reading_time": 2,
      "created_at": "2025-11-27T15:43:09.075832+00:00",
      "updated_at": "2025-11-27T16:19:00.699175+00:00",
      "metadata": {
        "processed_at": "2025-11-27T16:19:00.699177+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "409d71208f2a1aa3d6048234954b8e51",
      "url": "https://www.sciencedirect.com/science/article/pii/S0306452225011157?dgcid=rss_sd_all",
      "title": "A hyperexcited basolateral amygdala complex state determines the hippocampal structural plasticity associated with the reconsolidation of a fear memory",
      "content": "<p>Publication date: 9 January 2026</p><p><b>Source:</b> Neuroscience, Volume 592</p><p>Author(s): Mar\u00eda Candela Sosa, Ramiro Comas Mutis, Melisa Riva Gargiulo, Irene Delia Martijena, Crhistian Luis Bender, Gast\u00f3n Diego Calfa</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroscience Journal",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 26,
      "reading_time": 1,
      "created_at": "2025-11-27T15:42:51.756321+00:00",
      "updated_at": "2025-11-27T16:19:00.699179+00:00",
      "metadata": {
        "processed_at": "2025-11-27T16:19:00.699181+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "ecf1276cfb1b592a6d881c4dd471be33",
      "url": "https://www.sciencedirect.com/science/article/pii/S030645222501125X?dgcid=rss_sd_all",
      "title": "In vitro identification of kainic acid-induced, concentration-dependent responses in human cortical neuronal networks",
      "content": "<p>Publication date: 9 January 2026</p><p><b>Source:</b> Neuroscience, Volume 592</p><p>Author(s): Lotta Isosaari, Oskari Kulta, Satu J\u00e4ntti, Andrey Vinogradov, Elena Perez Morrissey, Ina Woods, Rachel Stewart, Jouni Sirvi\u00f6, Fikret Emre Kapucu, Jochen H.M. Prehn, Susanna Narkilahti</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroscience Journal",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 33,
      "reading_time": 1,
      "created_at": "2025-11-27T15:42:51.756164+00:00",
      "updated_at": "2025-11-27T16:19:00.699183+00:00",
      "metadata": {
        "processed_at": "2025-11-27T16:19:00.699185+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "4b11e46560dc5a82a154c422489e93a5",
      "url": "https://www.sciencedirect.com/science/article/pii/S0306452225011236?dgcid=rss_sd_all",
      "title": "Electroacupuncture alleviates chemotherapy-induced peripheral neuropathy and anxiety by reducing TRPC6/PKC-dependent activation of glutamatergic neurons in the paraventricular thalamic nucleus",
      "content": "<p>Publication date: 9 January 2026</p><p><b>Source:</b> Neuroscience, Volume 592</p><p>Author(s): Yi-Yang Jiang, Xue Li, Feng-Xian Hu, Dan-Ni Wang, Ji-Miao Zang, Zhen-Ling Liu, Fei Xu, Wen-Qiang Cui</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroscience Journal",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 24,
      "reading_time": 1,
      "created_at": "2025-11-27T15:42:51.756129+00:00",
      "updated_at": "2025-11-27T15:42:51.756138+00:00"
    },
    {
      "id": "75dd4a6dfd52f06cf99dd684f3e4f692",
      "url": "https://github.com/vac-architector/VAC-Memory-System/blob/main/LOGICA_MOE_STORY.md",
      "title": "What Happens When You Train Pure Logic Without Knowledge: 15-Expert Moe",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46069919\">Comments</a>",
      "author": "",
      "published_date": "2025-11-27T15:07:51+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-11-27T15:42:11.022651+00:00",
      "updated_at": "2025-11-27T15:42:11.022652+00:00"
    },
    {
      "id": "75dd4a6dfd52f06cf99dd684f3e4f692",
      "url": "https://github.com/vac-architector/VAC-Memory-System/blob/main/LOGICA_MOE_STORY.md",
      "title": "What Happens When You Train Pure Logic Without Knowledge: 15-Expert Moe",
      "content": "<p>Article URL: <a href=\"https://github.com/vac-architector/VAC-Memory-System/blob/main/LOGICA_MOE_STORY.md\">https://github.com/vac-architector/VAC-Memory-System/blob/main/LOGICA_MOE_STORY.md</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46069919\">https://news.ycombinator.com/item?id=46069919</a></p>\n<p>Points: 8</p>\n<p># Comments: 1</p>",
      "author": "ViktorKuz",
      "published_date": "2025-11-27T15:07:51+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-11-27T15:42:09.632382+00:00",
      "updated_at": "2025-11-27T15:42:09.632390+00:00"
    },
    {
      "id": "df3d7dd5cbf543c4ba39ff691b1adae8",
      "url": "https://www.biorxiv.org/content/10.1101/2025.11.25.690444v1?rss=1",
      "title": "Synaptopodin KO rat for assessing the dendritic spine apparatus and axonal cisternal organelle in synaptic plasticity, development, and behavior",
      "content": "The actin-binding protein synaptopodin (Synpo) regulates the cytoskeleton and intracellular Ca2+ and is important for long-term potentiation (LTP) and learning. The inconsistent onset age for LTP in mice makes their Synpo knockout (KO) a suboptimal developmental model. Hence, we generated Synpo KO rats using CRISPR-Cas9. Synpo KO rats are viable with reduced body weight and bone length after postnatal days (P)35-P45. Their basal kidney function is normal. 3D reconstruction from electron microscopy reveals the absence of the Synpo-dependent dendritic spine apparatus and cisternal organelles in the axon initial segment (AIS), which may contribute to reduced LTP in the KO rat. Inhibitory synapses in the wild-type AIS appear preferentially clustered near cisternal organelles - a pattern disrupted in the KO, where synapses appear more uniformly distributed. The consistent developmental profile of LTP in the rat makes this KO a robust model to assess Synpo function in development, synaptic plasticity, and behavior.",
      "author": "Kuwajima, M., Ostrovskaya, O. I., Kirk, L. M., Alario, A., Yin, W., Singh, S., Xaymongkhol, A., Li, A., Prasad, E., Harris, K. M.",
      "published_date": "2025-11-27T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 150,
      "reading_time": 1,
      "created_at": "2025-11-27T15:22:36.246861+00:00",
      "updated_at": "2025-11-27T15:22:36.246863+00:00"
    },
    {
      "id": "0ad63a424d2283a17db5b4713aac1442",
      "url": "https://www.biorxiv.org/content/10.1101/2025.11.25.690410v1?rss=1",
      "title": "Nutrient stress activates Rab5b-mediated autophagy to remodel the synaptic proteome",
      "content": "Synaptic proteostasis is crucial for maintaining neuronal function and plasticity, yet how synapses adapt to metabolic stress remains poorly understood. Here, we show that nutrient deprivation, particularly serum withdrawal, induces robust autophagy-dependent remodeling of the synaptic proteome, while mTORC1 inhibition has more limited effects. Nutrient stress rapidly activates autophagy both globally and at synapses, with synaptic autophagy peaking within 1-2 hours of serum withdrawal. Mechanistically, we uncover that the LC3 lipidation complex (ATG5-ATG12-ATG16L1) is recruited to synapses via Rab5b-positive endosomes in a dynein-dependent manner. Live imaging reveals enhanced Rab5b-ATG16L1 co-trafficking and increased ATG5 mobility upon serum withdrawal, supporting a model of spatiotemporally controlled autophagy precursor delivery to synaptic compartments. Functionally, nutrient deprivation acutely dampens neuronal excitability in vitro, while a two-week fasting-mimicking diet in vivo triggers synaptic proteome remodeling that overlaps with starvation-induced autophagy cargo. In contrast, restriction of mTORC1-activating amino acids fails to induce comparable synaptic changes, suggesting that synaptic autophagy is regulated by nutrient signals beyond mTORC1. Our findings define a Rab5b-mediated trafficking mechanism that couples nutrient sensing to localized synaptic degradation, providing new insight into how neurons preserve proteostasis under metabolic challenge.",
      "author": "Overhoff, M., Ickert, L., Marten, S., Hill, A., Tellkamp, F., Ludwig, S. L., Antczak, P., Koehler, F., Mueller, R.-U., Krueger, M., Kononenko, N.",
      "published_date": "2025-11-27T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 185,
      "reading_time": 1,
      "created_at": "2025-11-27T15:22:36.246822+00:00",
      "updated_at": "2025-11-27T15:22:36.246827+00:00"
    },
    {
      "id": "a6436433d818ec815c29cc0067714739",
      "url": "https://github.com/chr15m/runprompt",
      "title": "Show HN: Runprompt \u2013 run .prompt files from the command line",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46069556\">Comments</a>",
      "author": "",
      "published_date": "2025-11-27T14:26:35+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-11-27T15:21:54.777181+00:00",
      "updated_at": "2025-11-27T15:21:54.777183+00:00"
    },
    {
      "id": "b18b88bcdae57b867a10bded1479b7fa",
      "url": "https://www.uncoveralpha.com/p/the-chip-made-for-the-ai-inference",
      "title": "TPUs vs. GPUs and why Google is positioned to win AI race in the long term",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46069048\">Comments</a>",
      "author": "",
      "published_date": "2025-11-27T13:28:34+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-11-27T15:21:54.777161+00:00",
      "updated_at": "2025-11-27T15:21:54.777163+00:00"
    },
    {
      "id": "9cd07b06b640612c48709d8e51db4e5a",
      "url": "https://www.devas.life/dont-be-a-scary-old-guy-my-40s-survival-strategy-with-charm/",
      "title": "Don't be a scary old guy: My 40s survival strategy with charm",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46069743\">Comments</a>",
      "author": "",
      "published_date": "2025-11-27T14:48:02+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-11-27T15:21:54.777141+00:00",
      "updated_at": "2025-11-27T15:21:54.777142+00:00"
    },
    {
      "id": "132dee8447d0cac5086b2b170b385015",
      "url": "https://github.com/MartenBE/mkslides",
      "title": "Show HN: MkSlides \u2013 Markdown to slides with a similar workflow to MkDocs",
      "content": "<p>As a teacher, we keep our slides as markdown files in git repos and want to build these automatically so they can be viewed online (or offline if needed). To achieve this, I have created MkSlides. This tool converts all markdown in a folder to slides generated with Reveal.js.\nThe workflow is very similar to MkDocs.<p>Install: `pip install mkslides`<p>Building slides: `mkslides build`<p>Live preview during editing: `mkslides serve`<p>Comparison with other tools like marp, slidev, ...:<p>- This tool is a single command and easy to integrate in CI/CD pipelines.<p>- It only needs Python.<p>- The workflow is also very similar to MkDocs, which makes it easy to combine the two in a single GitHub/GitLab repo.<p>- Generates an index landing page for multiple slideshows in a folder which is really convenient if you have e.g. a slideshow per chapter.<p>- It is lightweight.<p>- Everything is IaC.</p>\n<hr />\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46068847\">https://news.ycombinator.com/item?id=46068847</a></p>\n<p>Points: 4</p>\n<p># Comments: 0</p>",
      "author": "MartenBE",
      "published_date": "2025-11-27T13:00:17+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 152,
      "reading_time": 1,
      "created_at": "2025-11-27T15:21:53.616825+00:00",
      "updated_at": "2025-11-27T15:21:53.616827+00:00"
    },
    {
      "id": "b18b88bcdae57b867a10bded1479b7fa",
      "url": "https://www.uncoveralpha.com/p/the-chip-made-for-the-ai-inference",
      "title": "TPUs vs. GPUs and why Google is positioned to win AI race in the long term",
      "content": "<p>Article URL: <a href=\"https://www.uncoveralpha.com/p/the-chip-made-for-the-ai-inference\">https://www.uncoveralpha.com/p/the-chip-made-for-the-ai-inference</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46069048\">https://news.ycombinator.com/item?id=46069048</a></p>\n<p>Points: 5</p>\n<p># Comments: 0</p>",
      "author": "vegasbrianc",
      "published_date": "2025-11-27T13:28:34+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-11-27T15:21:53.616793+00:00",
      "updated_at": "2025-11-27T15:21:53.616795+00:00"
    },
    {
      "id": "a6436433d818ec815c29cc0067714739",
      "url": "https://github.com/chr15m/runprompt",
      "title": "Show HN: Runprompt \u2013 run .prompt files from the command line",
      "content": "<p>I built a single-file Python script that lets you run LLM prompts from the command line with templating, structured outputs, and the ability to chain prompts together.<p>When I discovered Google's Dotprompt format (frontmatter + Handlebars templates), I realized it was perfect for something I'd been wanting: treating prompts as first-class programs you can pipe together Unix-style. Google uses Dotprompt in Firebase Genkit and I wanted something simpler - just run a .prompt file directly on the command line.<p>Here's what it looks like:<p>---\nmodel: anthropic/claude-sonnet-4-20250514\noutput:\n  format: json\n  schema:\n    sentiment: string, positive/negative/neutral\n    confidence: number, 0-1 score\n---\nAnalyze the sentiment of: {{STDIN}}<p>Running it:<p>cat reviews.txt | ./runprompt sentiment.prompt | jq '.sentiment'<p>The things I think are interesting:<p>* Structured output schemas: Define JSON schemas in the frontmatter using a simple `field: type, description` syntax. The LLM reliably returns valid JSON you can pipe to other tools.<p>* Prompt chaining: Pipe JSON output from one prompt as template variables into the next. This makes it easy to build multi-step agentic workflows as simple shell pipelines.<p>* Zero dependencies: It's a single Python file that uses only stdlib. Just curl it down and run it.<p>* Provider agnostic: Works with Anthropic, OpenAI, Google AI, and OpenRouter (which gives you access to dozens of models through one API key).<p>You can use it to automate things like extracting structured data from unstructured text, generating reports from logs, and building small agentic workflows without spinning up a whole framework.<p>Would love your feedback, and PRs are most welcome!</p>\n<hr />\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46069556\">https://news.ycombinator.com/item?id=46069556</a></p>\n<p>Points: 7</p>\n<p># Comments: 0</p>",
      "author": "chr15m",
      "published_date": "2025-11-27T14:26:35+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 256,
      "reading_time": 1,
      "created_at": "2025-11-27T15:21:53.616761+00:00",
      "updated_at": "2025-11-27T15:21:53.616769+00:00"
    },
    {
      "id": "a18c1c5531715c9745605fd693b97b5b",
      "url": "https://www.reddit.com/r/Python/comments/1p7mltu/raypy_a_python_interface_to_the_rayforcedb/",
      "title": "RayPy, a Python interface to the RayforceDB columnar database reaches beta",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>RayPy is a Python interface to the RayforceDB columnar database. RayforceDB is a ultrafast columnar vector database and Rayfall vector language implementation. More info, documentation and Github link: <a href=\"https://raypy.rayforcedb.com/\">https://raypy.rayforcedb.com/</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/vsovietov\"> /u/vsovietov </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1p7mltu/raypy_a_python_interface_to_the_rayforcedb/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1p7mltu/raypy_a_python_interface_to_the_rayforcedb/\">[comments]</a></span>",
      "author": "/u/vsovietov",
      "published_date": "2025-11-26T23:13:10+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 51,
      "reading_time": 1,
      "created_at": "2025-11-27T14:44:48.175659+00:00",
      "updated_at": "2025-11-27T14:44:48.175660+00:00"
    },
    {
      "id": "f7c48c151fbdd67aa9137c3cfd22d34b",
      "url": "https://www.thepost.co.nz/business/360897298/crypto-investors-face-tax-crackdown-70-non-compliant",
      "title": "Crypto investors face tax crackdown as 70% non-compliant",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46069408\">Comments</a>",
      "author": "",
      "published_date": "2025-11-27T14:09:39+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-11-27T14:44:46.830653+00:00",
      "updated_at": "2025-11-27T14:44:46.830659+00:00"
    },
    {
      "id": "f7c48c151fbdd67aa9137c3cfd22d34b",
      "url": "https://www.thepost.co.nz/business/360897298/crypto-investors-face-tax-crackdown-70-non-compliant",
      "title": "Crypto investors face tax crackdown as 70% non-compliant",
      "content": "<p>Article URL: <a href=\"https://www.thepost.co.nz/business/360897298/crypto-investors-face-tax-crackdown-70-non-compliant\">https://www.thepost.co.nz/business/360897298/crypto-investors-face-tax-crackdown-70-non-compliant</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46069408\">https://news.ycombinator.com/item?id=46069408</a></p>\n<p>Points: 20</p>\n<p># Comments: 5</p>",
      "author": "gochuks",
      "published_date": "2025-11-27T14:09:39+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-11-27T14:44:45.731720+00:00",
      "updated_at": "2025-11-27T14:44:45.731728+00:00"
    },
    {
      "id": "3d370217cb4a351bb54e7854066e15c3",
      "url": "https://erpinfo.org/blog/2024/2/4/optimal-filters",
      "title": "New Papers: Optimal Filter Settings for ERP Research",
      "content": "<p class=\"\">Zhang, G., Garrett, D. R., &amp; Luck, S. J. (in press). Optimal filters for ERP research I: A general approach for selecting filter settings. <em>Psychophysiology</em>. <a href=\"https://doi.org/10.1111/psyp.14531\"><span>https://doi.org/10.1111/psyp.14531</span></a> [<a href=\"https://www.researchgate.net/publication/377773270_Optimal_filters_for_ERP_research_I_A_general_approach_for_selecting_filter_settings\"><span>preprint</span></a>]</p><p class=\"\">Zhang, G., Garrett, D. R., &amp; Luck, S. J. (in press). Optimal filters for ERP research II: Recommended settings for seven common ERP components. <em>Psychophysiology</em>. <a href=\"https://doi.org/10.1111/psyp.14530\"><span>https://doi.org/10.1111/psyp.14530</span></a> [<a href=\"https://www.researchgate.net/publication/377766656_Optimal_filters_for_ERP_research_II_Recommended_settings_for_seven_common_ERP_components\"><span>preprint</span></a>]</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1490\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/d64086cc-e3b4-457d-89df-08d9b3f96439/Filter_Table.png?format=1000w\" width=\"2062\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">What filter settings should you apply to your ERP data? If your filters are too weak to attenuate the noise in your data, your effects may not be statistically significant. If your filters are too strong, they may create artifactual peaks that lead you to draw bogus conclusions.</p><p class=\"\">For years, I have been recommending a bandpass of 0.1\u201330 Hz for most cognitive and affective research in neurotypical young adults. In this kind of research, I have found that filtering from 0.1\u201330 Hz usually does a good job of minimizing noise while creating minimal waveform distortion. </p><p class=\"\">However, this recommendation was based on a combination of informal observations from many experimental paradigms and a careful examination of a couple paradigms, so it was a bit hand-wavy. In addition, the optimal filter settings will depend on the waveshape of the ERP effects and the nature of the noise in a given study, so I couldn\u2019t make any specific recommendations about other experimental paradigms and participant populations. Moreover, different filter settings may be optimal for different scoring methods (e.g., mean amplitude vs. peak amplitude vs. peak latency).</p><p class=\"\">Guanghui Zhang, David Garrett, and I spent the last year focusing on this issue. First we developed a general method that can be used to determine the optimal filter settings for a given dataset and scoring method (see <a href=\"https://doi.org/10.1111/psyp.14531\"><span>this paper</span></a>). Then we applied this method to the <a href=\"https://doi.org/10.1016/j.neuroimage.2020.117465\"><span>ERP CORE</span></a> data to determine the optimal filter settings for the N170, MMN, P3b, N400, N2pc, LRP, and ERN components in neurotypical young adults (see <a href=\"https://doi.org/10.1111/psyp.14530\"><span>this paper</span></a> and the table above).</p><p class=\"\">If you are doing research with these components (or similar components) in neurotypical young adults, you can simply use the filter settings that we identified. If you are using a very different paradigm or testing a very different subject population, you can apply our method to your own data to find the optimal settings. We added some new tools to <a href=\"https://github.com/ucdavis/erplab\"><span>ERPLAB Toolbox</span></a> to make this easier.</p><p class=\"\">One thing that we discovered was that our old recommendation of 0.1\u201330 Hz does a good job of avoiding filter artifacts but is overly conservative for some components. For example, we can raise the low end to 0.5 Hz when measuring N2pc and MMN amplitudes, which gets rid of more noise without producing problematic waveform distortions. And we can go all the way up to 0.9 Hz for the N170 component. However, later/slower components like P3b and N400 require lower cutoffs (no higher than 0.2 Hz).</p><p class=\"\">You might be wondering how we defined the \u201coptimal\u201d filter settings. At one level, the answer is simple: The optimal filter is the one that maximizes the signal-to-noise ratio without producing too much waveform distortion. The complexities arise in quantifying the signal-to-noise ratio, quantifying the waveform distortion, and deciding how much waveform distortion is \u201ctoo much\u201d. We believe we have found reasonably straightforward and practical solutions to these problems, which you can read about in the published papers.</p>",
      "author": "Steve Luck",
      "published_date": "2024-02-04T23:46:20+00:00",
      "source": "Erp Boot Camp",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 568,
      "reading_time": 2,
      "created_at": "2025-11-27T14:22:10.942673+00:00",
      "updated_at": "2025-11-27T14:22:10.942676+00:00"
    }
  ]
}