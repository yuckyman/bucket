{
  "last_updated": "2025-10-21T21:38:07.326003+00:00",
  "count": 20,
  "articles": [
    {
      "id": "c547c0bc93be4231792f392e14271335",
      "url": "https://github.com/raysan5/raylib/blob/master/src/external/rlsw.h",
      "title": "rlsw \u2013 Raylib software OpenGL renderer in less than 5k LOC",
      "content": "<a href=\"https://news.ycombinator.com/item?id=45661638\">Comments</a>",
      "author": "",
      "published_date": "2025-10-21T21:00:10+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-10-21T21:36:53.222117+00:00",
      "updated_at": "2025-10-21T21:36:53.222119+00:00"
    },
    {
      "id": "cf6dd6fecd7440873aa66f6ea0989c80",
      "url": "https://getrover.substack.com/p/how-we-rewrote-openfga-in-pure-postgres",
      "title": "We rewrote OpenFGA in pure Postgres",
      "content": "<p>Article URL: <a href=\"https://getrover.substack.com/p/how-we-rewrote-openfga-in-pure-postgres\">https://getrover.substack.com/p/how-we-rewrote-openfga-in-pure-postgres</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=45661547\">https://news.ycombinator.com/item?id=45661547</a></p>\n<p>Points: 3</p>\n<p># Comments: 0</p>",
      "author": "wbadart",
      "published_date": "2025-10-21T20:52:44+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-10-21T21:36:51.806858+00:00",
      "updated_at": "2025-10-21T21:36:51.806860+00:00"
    },
    {
      "id": "c547c0bc93be4231792f392e14271335",
      "url": "https://github.com/raysan5/raylib/blob/master/src/external/rlsw.h",
      "title": "rlsw \u2013 Raylib software OpenGL renderer in less than 5k LOC",
      "content": "<p>Article URL: <a href=\"https://github.com/raysan5/raylib/blob/master/src/external/rlsw.h\">https://github.com/raysan5/raylib/blob/master/src/external/rlsw.h</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=45661638\">https://news.ycombinator.com/item?id=45661638</a></p>\n<p>Points: 8</p>\n<p># Comments: 0</p>",
      "author": "fschuett",
      "published_date": "2025-10-21T21:00:10+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-10-21T21:36:51.806824+00:00",
      "updated_at": "2025-10-21T21:36:51.806835+00:00"
    },
    {
      "id": "9f45f8c2861e617af197ebba9f4c9f0a",
      "url": "https://www.biorxiv.org/content/10.1101/2025.10.20.683510v1?rss=1",
      "title": "Pro-endometriosis macrophage release of IL-33 is key for endometriosis pain and lesion formation",
      "content": "Endometriosis is a painful gynecological inflammatory disease affecting up to 10% of females. When released by sensory neurons, calcitonin gene-related peptide (CGRP) shapes immunity, a process known as neuroimmune communication. We previously showed that nociceptor-derived CGRP polarizes macrophages into pro-endometriosis macrophages (PEMs) that mediates endometrial epithelial (endo-epi) cell growth and pain. However, the key mediators involved in this PEM-induced cell growth were unknown. Using unbiased approaches, we discovered that nociceptor-derived CGRP induces IL-33 production by PEMs. IL-33 binding to its receptor ST2 is key for endometriotic lesion growth and pain during endometriosis in mice as anti-IL-33 antibody treatment reduced evoked and spontaneous pain as well as lesion size. Chemical or genetic ablation of nociceptors or macrophages also resulted in lower levels of lesion IL-33, demonstrating a neuroimmune-driven mechanism for IL-33 production during endometriosis. In humans, we found that IL-33 is correlated with increased number of glands and fibrosis in lesions and that IL-33 expression in macrophages is also associated with genetic risk of endometriosis. We also provided evidence that suggests a dual role for IL-33 in endometriosis, in which, it is initially required for lesion formation and later for lesion maintenance only, and associated pain. Therefore, targeting IL-33/ST2 signaling may effectively treat endometriosis pain.",
      "author": "Fattori, V., S. Rasquel-Oliveira, F., Ochoa, S., Graf, E., Bazzano, M. V., Aung, T., Vural, M., Kohl, C., Solano, M. E., da Silva, M. D. V., Heintz, O. K., Brierley, S. M., Verri, W. A., Haerteis, S., Castro, J., Lawrenson, K., Rogers, M. S.",
      "published_date": "2025-10-21T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 204,
      "reading_time": 1,
      "created_at": "2025-10-21T21:18:46.295818+00:00",
      "updated_at": "2025-10-21T21:18:46.295820+00:00"
    },
    {
      "id": "6224301468f5496313e75a46ecc50501",
      "url": "https://www.biorxiv.org/content/10.1101/2025.10.20.683540v1?rss=1",
      "title": "Spatial learning in multi-scale environments: Roles of hippocampus, orbitofrontal cortex, and retrosplenial cortex",
      "content": "Navigation cognition involves the learning of multi-scale environments and the formation of cognitive maps. How do humans build cognitive maps in multi-scale environments? Cognitive maps are thought to be organized hierarchically, with local representations for subareas and global representations for the entire environment. However, it remains unclear how spatial learning influences the representations of multi-scale environments and their underlying neural mechanisms across different levels of representation. In the current study, we built a virtual environment (VE) with four orthogonally positioned rectangular rooms, each containing eight objects at the corners. Twenty-three healthy subjects completed a four-session spatial memory experiment conducted over two weeks. We measured their brain activity by using BOLD-fMRI at two stages: pre-learning stage and post-learning, when they were judging the relative direction between the objects within the VE. We found that with the progression of learning, the subjects shifted from relying on local, directional cues to using more global representations of the environment. At the neural level, the hippocampus (HIP), retrosplenial cortex (RSC), and orbitofrontal cortex (OFC) played distinct roles in encoding spatial information across the two learning stages. Specifically, after learning, the HIP shifted from local to global representations, while the RSC and OFC supported the integration of spatial information across these representational levels. In addition, the anterior cingulate cortex was involved in forming global representations, facilitating efficient spatial processing as learning advanced. These findings revealed how spatial learning leads to adaptive shifts in brain activity, contributing to the formation of cognitive maps in complex, multi-scale environments.",
      "author": "Qiu, Y., Zheng, S., Li, H., Lin, S., Huang, R.",
      "published_date": "2025-10-21T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 250,
      "reading_time": 1,
      "created_at": "2025-10-21T21:18:46.295781+00:00",
      "updated_at": "2025-10-21T21:18:46.295783+00:00"
    },
    {
      "id": "6fd81194d6fd6a65149b1a3b3fd449f3",
      "url": "https://www.biorxiv.org/content/10.1101/2025.10.20.683534v1?rss=1",
      "title": "Visual Attention in Peripersonal Space",
      "content": "Bringing the hand near a visual stimulus enhances visual processing. This effect is linked to peripersonal space (PPS), the body-centered region where visual and proprioceptive information interact. Despite extensive behavioral evidence, the neural basis of this interaction in early visual cortex remains unclear. In this study, we investigated how hand proximity modulates orientation selectivity in area V2 by recording single-neuron responses from two rhesus monkeys. The monkeys performed a fixation task while their hand was positioned near a visual stimulus while either being visible or occluded, and compared with when the hand was away from the stimulus. When the near hand was visible, neural firing rates in V2 were significantly higher, accompanied by sharper orientation tuning. In contrast, occluding the hand broadened orientation tuning compared to when the hand was away. These effects emerged rapidly after stimulus onset and were coherent across the population, demonstrating that PPS is actively prioritized during visual processing. Together, the findings reveal two complementary (feedback) signals in V2: a congruence-driven enhancement when visual and proprioceptive inputs align, and a mismatch-driven suppression when they conflict, indicating that V2 integrates multisensory cues to encode PPS and support action-relevant visual processing.",
      "author": "Ramezanpour, H., Kehoe, D. H., Perry, C. J., Fallah, M.",
      "published_date": "2025-10-21T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 193,
      "reading_time": 1,
      "created_at": "2025-10-21T21:18:46.295731+00:00",
      "updated_at": "2025-10-21T21:18:46.295735+00:00"
    },
    {
      "id": "252cced1a8d9e880aea7975daf75492c",
      "url": "https://home.csulb.edu/~cwallis/382/readings/482/searle.minds.brains.programs.bbs.1980.pdf",
      "title": "Minds, brains, and programs (1980) [pdf]",
      "content": "<a href=\"https://news.ycombinator.com/item?id=45564821\">Comments</a>",
      "author": "",
      "published_date": "2025-10-13T05:01:11+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-10-21T21:18:11.425524+00:00",
      "updated_at": "2025-10-21T21:18:11.425525+00:00"
    },
    {
      "id": "6d028d769007957329236e8761b33332",
      "url": "https://disco.cloud/blog/how-idealistorg-replaced-a-3000mo-heroku-bill-with-a-55-server/",
      "title": "Replacing a $3000/mo Heroku bill with a $55/mo server",
      "content": "<a href=\"https://news.ycombinator.com/item?id=45661253\">Comments</a>",
      "author": "",
      "published_date": "2025-10-21T20:28:15+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-10-21T21:18:11.425363+00:00",
      "updated_at": "2025-10-21T21:18:11.425367+00:00"
    },
    {
      "id": "6d028d769007957329236e8761b33332",
      "url": "https://disco.cloud/blog/how-idealistorg-replaced-a-3000mo-heroku-bill-with-a-55-server/",
      "title": "Replacing a $3000/mo Heroku bill with a $55/mo server",
      "content": "<p>Article URL: <a href=\"https://disco.cloud/blog/how-idealistorg-replaced-a-3000mo-heroku-bill-with-a-55-server/\">https://disco.cloud/blog/how-idealistorg-replaced-a-3000mo-heroku-bill-with-a-55-server/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=45661253\">https://news.ycombinator.com/item?id=45661253</a></p>\n<p>Points: 90</p>\n<p># Comments: 40</p>",
      "author": "jryio",
      "published_date": "2025-10-21T20:28:15+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-10-21T21:18:09.968221+00:00",
      "updated_at": "2025-10-21T21:18:09.968229+00:00"
    },
    {
      "id": "2ca84d0b59d26237203f4aca34b9609a",
      "url": "https://www.nature.com/articles/d44224-025-00029-3",
      "title": "Revealing hidden genomic variation in Parkinson\u2019s and related disorders",
      "content": "",
      "author": "",
      "published_date": "2025-10-21T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-10-21T20:43:42.566741+00:00",
      "updated_at": "2025-10-21T20:43:42.566747+00:00"
    },
    {
      "id": "553153cc6a2a6e7818d1c8f7c97c02b8",
      "url": "https://doomsday.march1studios.com/",
      "title": "Doomsday Scoreboard",
      "content": "<a href=\"https://news.ycombinator.com/item?id=45661084\">Comments</a>",
      "author": "",
      "published_date": "2025-10-21T20:14:22+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-10-21T20:43:02.935020+00:00",
      "updated_at": "2025-10-21T20:43:02.935022+00:00"
    },
    {
      "id": "bf0b692a35e84602e484eb95ffcb01cd",
      "url": "https://www.reddit.com/r/Python/comments/1ocg3p5/python_pest_a_port_of_rusts_pest/",
      "title": "Python Pest - A port of Rust's pest",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>I recently released Python Pest, a port of the Rust pest parsing library.</p> <h1>What My Project Does</h1> <p>Python Pest is a declarative PEG parser generator for Python, ported from Rust's Pest. You write grammars instead of hand-coding parsing logic, and it builds parse trees automatically.</p> <p>Define a grammar using Pest version 2 syntax, like this:</p> <pre><code>jsonpath = _{ SOI ~ jsonpath_query ~ EOI } jsonpath_query = _{ root_identifier ~ segments } segments = _{ (S ~ segment)* } root_identifier = _{ &quot;$&quot; } segment = _{ | child_segment | descendant_segment } // snip </code></pre> <p>And traverse parse trees using <a href=\"https://peps.python.org/pep-0636/\">structural pattern matching</a>, like this:</p> <pre><code>def parse_segment(self, segment: Pair) -&gt; Segment: match segment: case Pair(Rule.CHILD_SEGMENT, [inner]): return ChildSegment(segment, self.parse_segment_inner(inner)) case Pair(Rule.DESCENDANT_SEGMENT, [inner]): return RecursiveDescentSegment(segment, self.parse_segment_inner(inner)) case Pair(Rule.NAME_SEGMENT, [inner]) | Pair(Rule.INDEX_SEGMENT, [inner]): return ChildSegment(segment, [self.parse_selector(inner)]) case _: raise JSONPathSyntaxError(&quot;expected a segment&quot;, segment) </code></pre> <p>See <a href=\"https://jg-rp.github.io/python-pest/\">docs</a>, <a href=\"https://github.com/jg-rp/python-pest\">GitHub</a> and <a href=\"https://pypi.org/project/python-pest/\">PyPi</a> for a complete example.</p> <h1>Target Audience</h1> <ul> <li>Python developers who need to parse custom languages, data formats, or DSLs.</li> <li>Anyone interested in grammar-first design over hand-coded parsers.</li> <li>Developers curious about leveraging Python's match/case for tree-walking.</li> </ul> <h1>Comparison</h1> <p>Parsimonious is another general purpose, pure Python parser package that reads parsing expression grammars. Python Pest differs in grammar syntax and subsequent tree traversal technique, preferring external iteration of parse trees instead of defining a visitor.</p> <h1>Feedback</h1> <p>I'd appreciate any feedback, especially your thoughts on the trade-off between declarative grammars and performance in Python. Does the clarity and maintainability make up for slower execution compared to hand-tuned parsers?</p> <p>GitHub: <a href=\"https://github.com/jg-rp/python-pest\">https://github.com/jg-rp/python-pest</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Hefty-Pianist-1958\"> /u/Hefty-Pianist-1958 </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1ocg3p5/python_pest_a_port_of_rusts_pest/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1ocg3p5/python_pest_a_port_of_rusts_pest/\">[comments]</a></span>",
      "author": "/u/Hefty-Pianist-1958",
      "published_date": "2025-10-21T15:31:24+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 279,
      "reading_time": 1,
      "created_at": "2025-10-21T20:23:13.334255+00:00",
      "updated_at": "2025-10-21T20:23:13.334257+00:00"
    },
    {
      "id": "d8165e7dcd20fe2b28296ac64140db58",
      "url": "https://www.reddit.com/r/Python/comments/1ochltx/ids_project_in_python/",
      "title": "IDS Project in Python",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>Hello everyone,</p> <p>I recently uploaded a repository to GitHub where I created an IDS in Python. I would appreciate any feedback and suggestions for improvement.</p> <p><a href=\"https://github.com/javisys/IDS-Python\">https://github.com/javisys/IDS-Python</a></p> <p>Thank you very much, best regards.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Javi_16018\"> /u/Javi_16018 </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1ochltx/ids_project_in_python/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1ochltx/ids_project_in_python/\">[comments]</a></span>",
      "author": "/u/Javi_16018",
      "published_date": "2025-10-21T16:28:08+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 54,
      "reading_time": 1,
      "created_at": "2025-10-21T20:23:13.334216+00:00",
      "updated_at": "2025-10-21T20:23:13.334217+00:00"
    },
    {
      "id": "af862a7d19af6182f39654c5288eda97",
      "url": "https://techcrunch.com/2025/10/18/wikipedia-says-traffic-is-falling-due-to-ai-search-summaries-and-social-video/",
      "title": "Wikipedia says traffic is falling due to AI search summaries and social video",
      "content": "<a href=\"https://news.ycombinator.com/item?id=45651485\">Comments</a>",
      "author": "",
      "published_date": "2025-10-21T01:29:03+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-10-21T20:23:11.649183+00:00",
      "updated_at": "2025-10-21T20:23:11.649185+00:00"
    },
    {
      "id": "fcf08af52efe2975d48967f9b9ec1cd7",
      "url": "https://www.cnn.com/2025/10/20/science/nasa-spacex-moon-landing-contract-sean-duffy",
      "title": "NASA chief suggests SpaceX may be booted from moon mission",
      "content": "<a href=\"https://news.ycombinator.com/item?id=45655188\">Comments</a>",
      "author": "",
      "published_date": "2025-10-21T12:58:43+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-10-21T20:23:11.649126+00:00",
      "updated_at": "2025-10-21T20:23:11.649128+00:00"
    },
    {
      "id": "c2319578819743fdf0159bf723bcb1b5",
      "url": "https://erpinfo.org/blog/2024/3/5/changes-to-the-2024-erp-boot-camp",
      "title": "Important Changes to the 2024 ERP Boot Camp",
      "content": "<p class=\"\">We are disappointed to announce that we will not be holding a regular 10-day ERP Boot Camp this summer.</p><p class=\"\">We have held Boot Camps nearly every summer since 2007, supported by a series of generous grants from NIMH that allowed us to provide scholarships for all attendees. Unfortunately, although our recent renewal proposal received extremely positive reviews and scores, we were recently given the surprising and disappointing news that the renewal will not be funded this year. We believe that the ERP Boot Camp provides essential training to the field, and we will continue to pursue financial support to continue holding 10-day ERP Boot Camps in the future. </p><p class=\"\">In the meantime, we have partial funding that will allow us to hold a 5-day ERP Boot Camp this summer from July 8-12, 2024 in Davis, California. The workshop will include 5-days of lectures and activities on EEG and ERP measures, including practical and theoretical issues.</p><p class=\"\">Unfortunately, we will not be able to provide scholarships to pay for travel and lodging costs, and we must charge a registration fee. We are very sorry if this causes a hardship. </p><p class=\"\">We are no longer taking applications through our application portal. Instead of a competitive application process, we will simply accept the first 30 people who complete the registration process and pay the registration fee. This provides an opportunity to attend for individuals who might otherwise not make it through our ordinary application process, which is highly competitive. </p><p class=\"\">The registration fee will be $1000 (or $900 for people who register by April 15). The registration fee will cover 6 nights in a single occupancy hotel room (arriving July 7 and departing July 13), daily breakfast at the hotel, a catered lunch for each day of the workshop, and a group dinner. <strong>You must pay the registration fee with a credit card when you register.</strong> There are no exceptions to the registration fee policy.</p><p class=\"\"><strong>Registration is now open</strong> at <a href=\"https://na.eventscloud.com/793175\">https://na.eventscloud.com/793175</a>.</p><p class=\"\">Given that we will accept the first 30 registrants, we encourage you to register as soon as possible. <strong>Registration will close on May 20</strong>, but we anticipate that the workshop will be filled up long before then. </p><p class=\"\">You must pay for your own transportation to Davis. Davis is approximately 20 minutes away from the Sacramento Airport (SMF). You can take the <a href=\"https://www.davisairporter.com/\" target=\"_blank\">Davis Airporter</a> shuttle service or a rideshare service from SMF to Davis. If you are coming from outside North America, you may want to fly into the San Francisco airport (SFO), which is 135 km (84 miles) from Davis. We recommend taking the <a href=\"https://www.davisairporter.com/\" target=\"_blank\">Davis Airporter</a> from SFO to Davis.</p>",
      "author": "Steve Luck",
      "published_date": "2024-03-05T19:34:57+00:00",
      "source": "Erp Boot Camp",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 444,
      "reading_time": 2,
      "created_at": "2025-10-21T19:41:07.418056+00:00",
      "updated_at": "2025-10-21T20:17:03.698760+00:00",
      "metadata": {
        "processed_at": "2025-10-21T20:17:03.698770+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "d1b3a64c1957f2b048e1e94f5d37c6e5",
      "url": "https://erpinfo.org/blog/2024/3/15/registration-full",
      "title": "Registration is now full for the 2024 ERP Boot Camp",
      "content": "<p class=\"\">The demand for the<a href=\"https://erpinfo.org/2024-erp-boot-camp\"> 2024 ERP Boot Camp</a> was far beyond our expectations, and we reached our maximum registration of 30 people within one day. We already have a waiting list of over 30 people, so we have closed the registration site.</p><p class=\"\">We realize that this is very disappointing to many people. We hope to offer another workshop like this next summer, or possibly earlier.</p><p class=\"\">If you would like to get announcements about upcoming boot camps and webinars, you should <a href=\"https://erpinfo.org/bootcamp-email-list\">join our email list</a>.</p><p class=\"\">You may also consider hosting a <a href=\"https://erpinfo.org/mini-erp-boot-camps\">Mini ERP Boot Camp</a> at your institution (in person or over Zoom).</p>",
      "author": "Steve Luck",
      "published_date": "2024-03-16T15:14:42+00:00",
      "source": "Erp Boot Camp",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 106,
      "reading_time": 1,
      "created_at": "2025-10-21T19:41:07.418006+00:00",
      "updated_at": "2025-10-21T20:17:03.698774+00:00",
      "metadata": {
        "processed_at": "2025-10-21T20:17:03.698776+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "e1385798428586a67ced89a895faeb47",
      "url": "https://erpinfo.org/blog/2024/6/10/erp-core-decoding-paper",
      "title": "New Paper: Using Multivariate Pattern Analysis to Increase Effect Sizes for ERP Amplitude Comparisons",
      "content": "<p class=\"\">Carrasco, C. D., Bahle, B., Simmons, A. M., &amp; Luck, S. J. (2024). Using multivariate pattern analysis to increase effect sizes for event-related potential analyses. Psychophysiology, 61, e14570. <a href=\"https://doi.org/10.1111/psyp.14570\">https://doi.org/10.1111/psyp.14570</a> [<a href=\"https://doi.org/10.1101/2023.11.07.566051\">preprint</a>]</p><p class=\"\">Multivariate pattern analysis (MVPA) can be used to \u201cdecode\u201d subtle information from ERP signals, such as which of several faces a participant is perceiving or the orientation that someone is holding in working memory (see <a href=\"https://erpinfo.org/blog/2018/9/16/decoding\">this previous blog post</a>). This approach is so powerful that we started wondering whether it might also give us greater statistical power in more typical experiments where the goal is to determine whether an ERP component differs in amplitude across experimental conditions. For example, might we more easily be able to tell if N400 amplitude is different between two different classes of words by using decoding? If so, that might make it possible to detect effects that would otherwise be too small to be significant.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"688\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/08f353c7-f484-4e87-b5d3-a256fe1206e2/N170_ES.png?format=1000w\" width=\"971\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">To address this question, we compared decoding with the conventional ERP analysis approach with using the 6 experimental paradigms in the <a href=\"https://doi.org/10.18115/D5JW4R\">ERP CORE</a>. In the conventional ERP analysis, we measured the mean amplitude during the standard measurement window from each participant in the two conditions of the paradigm (e.g., faces versus cars for N170, deviants versus standards for MMN). We quantified the magnitude of the difference between conditions using Cohen\u2019s <em>dz</em> (the variant of Cohen\u2019s <em>d</em> corresponding to a paired <em>t</em> test). For example, the effect size in the conventional ERP comparison of faces versus cars in the N170 paradigm was approximately 1.7 (see the figure).</p><p class=\"\">We also applied decoding to each paradigm. For example, in the N170 paradigm, we trained a support vector machine (SVM) to distinguish between ERPs elicited by faces and ERPs elicited by cars. This was done separately for each subject, and we converted the decoding accuracy into Cohen\u2019s <em>dz</em> so that it could be compared with the <em>dz</em> from the conventional ERP analysis. As you can see from the bar labeled SVM in the figure above, the effect size for the SVM-based decoding analysis was almost twice as large as the effect size for the conventional ERP analysis. That\u2019s a huge difference!</p><p class=\"\">We found a similar benefit for SVM-based decoding over conventional ERP analyses in 7 of the 10 cases we tested (see the figure below). In the other 3 cases, the ERP and SVM effects were approximately equivalent. So, there doesn\u2019t seem to be a downside to using decoding, at least in terms of effect size. But there can be a big benefit.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1371\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/d16f0782-7205-4d50-95e1-c6729cbc153e/All_Components.png?format=1000w\" width=\"4641\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">Because decoding has many possible benefits, we\u2019ve added it into <a href=\"ERPLAB Toolbox\">ERPLAB Toolbox</a>. It\u2019s super easy to use, and we\u2019ve created <a href=\"https://erpinfo.org/blog/2023/6/23/decoding-webinar\">detailed documentation and a video</a> to explain how it works at a conceptual level and to show you how to use it.</p><p class=\"\">We encourage you to apply it to your own data. It may give you the power to detect effects that are too small to be detected with conventional ERP analyses.</p>",
      "author": "Steve Luck",
      "published_date": "2024-06-10T18:01:45+00:00",
      "source": "Erp Boot Camp",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 525,
      "reading_time": 2,
      "created_at": "2025-10-21T19:41:07.417979+00:00",
      "updated_at": "2025-10-21T20:17:03.698778+00:00",
      "metadata": {
        "processed_at": "2025-10-21T20:17:03.698780+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "906f73f5c36ba087882a0ad17e01fc20",
      "url": "https://erpinfo.org/blog/2024/6/11/erplab-studio",
      "title": "New software package: ERPLAB Studio",
      "content": "<p class=\"\">We are excited to announce the release of a new EEG/ERP analysis package, <a href=\"https://github.com/ucdavis/erplab/releases\">ERPLAB Studio</a>. We think it\u2019s a huge improvement over the classic EEGLAB user interface. See our cheesy <a href=\"https://www.youtube.com/watch?v=lIaKVQ9DD6E\">\u201cadvertisement\u201d video</a> to get a quick overview. </p><p class=\"\">Rather than operating as an EEGLAB plugin, ERPLAB Studio is a standalone Matlab program that provides a more efficient and user-friendly interface to the most commonly used EEGLAB and ERPLAB routines.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1080\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/c874d4ec-5186-4de9-981b-58010c7a06e1/Interface.jpeg?format=1000w\" width=\"1920\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">With ERPLAB Studio, you automatically see the EEG or ERP waveforms as soon as you load a file. And as soon as you perform an operation, you see what the new EEG/ERP looks like. For example, when you filter the data, you immediately see the filtered waveforms.</p><p class=\"\">You can even select multiple datasets and apply an operation like artifact detection on all of them in one step. And then you can immediately see the results, such as which EEG epochs have been marked with artifacts.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1080\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/b45f514d-2d21-4a5a-8be6-f3a8ff99c388/Artifacts.jpeg?format=1000w\" width=\"1920\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">We give you access to EEGLAB\u2019s ICA-based artifact correction tools, but with a nice bonus. You can plot the ICA activations in the same window with the EEG data, making it easy to see which ICA components correspond to specific artifacts such as eyeblinks.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1080\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/8bc191da-9040-4042-ae9c-550cd98def7d/ICA.jpeg?format=1000w\" width=\"1920\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">The program has an EEG tab for processing continuous and epoched EEG data, and an ERP tab for processing averaged ERPs.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1080\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/84bdd9df-b02e-4fc5-83b9-1139a91938f5/Tabs.jpg?format=1000w\" width=\"1920\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">The automatic ERP plotting makes it easy for you to view the data laid out according to the electrode locations. And we have an Advanced Waveform Viewer that can make publication-quality plots.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1080\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/a932631f-fc30-415f-b11d-660d2bf90da5/ERP.jpeg?format=1000w\" width=\"1920\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">ERPLAB Studio is mainly just a new user interface. Under the hood, we\u2019re running the same EEGLAB and ERPLAB routines you\u2019ve always used. And scripting is identical.</p><p class=\"\">ERPLAB Studio is included in <a href=\"https://github.com/ucdavis/erplab/releases\">version 11 and higher of ERPLAB</a>. You simply follow our <a href=\"https://github.com/ucdavis/erplab/wiki/installation\">download/installation instructions</a> and then type estudio from the Matlab command line. </p><p class=\"\">If you\u2019re new to ERPLAB, we strongly recommend that you go through our <a href=\"https://github.com/ucdavis/erplab/wiki/ERPLAB-Studio-Tutorial\" target=\"_blank\">tutorial</a> before starting to process your own data. </p><p class=\"\">If you already know how to use the original version of ERPLAB (which we now call ERPLAB Classic), you can quickly learn how to use ERPLAB Studio with our <a href=\"https://ucdavis.box.com/s/i4jfv22gv6rj9t5obctuk6yaruxqomcc\">Transition Guide</a>.</p><p class=\"\">We also have a <a href=\"https://github.com/ucdavis/erplab/wiki/ERPLAB-Studio-Manual\">manual</a> that describes every feature in detail. </p>",
      "author": "Steve Luck",
      "published_date": "2024-06-12T02:02:16+00:00",
      "source": "Erp Boot Camp",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 444,
      "reading_time": 2,
      "created_at": "2025-10-21T19:41:07.417906+00:00",
      "updated_at": "2025-10-21T20:17:03.698782+00:00",
      "metadata": {
        "processed_at": "2025-10-21T20:17:03.698783+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "79d603b3db5911be59b9e07e11acc674",
      "url": "https://erpinfo.org/blog/2024/6/28/recording-and-slides-now-available-for-erplab-studio-webinar",
      "title": "Recording and slides now available for ERPLAB Studio webinar",
      "content": "<p class=\"\">We held a webinar to demonstration ERPLAB Studio on 28 June 2024.</p><p class=\"\"><a href=\"https://youtu.be/k-nGv00rTP8\">Click here</a> to access a recording.</p><p class=\"\"><a href=\"https://ucdavis.box.com/s/4fseqz6327dtuouauj12rgvivy1d1nmo\">Click here </a>to access a PDF of the slides.</p>",
      "author": "Steve Luck",
      "published_date": "2024-06-28T22:21:45+00:00",
      "source": "Erp Boot Camp",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 30,
      "reading_time": 1,
      "created_at": "2025-10-21T19:41:07.417845+00:00",
      "updated_at": "2025-10-21T20:17:03.698786+00:00",
      "metadata": {
        "processed_at": "2025-10-21T20:17:03.698787+00:00",
        "processing_method": "github_actions"
      }
    }
  ]
}