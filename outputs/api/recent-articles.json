{
  "last_updated": "2026-01-29T06:40:08.959933+00:00",
  "count": 20,
  "articles": [
    {
      "id": "3df256d524e3fc7842bdb6b5772d75c7",
      "url": "https://www.sciencedirect.com/science/article/pii/S0006899326000223?dgcid=rss_sd_all",
      "title": "Genetics of Autism Spectrum Disorder underscores the role of altered spontaneous neuronal activity as a catalyst for the neurodevelopmental anomalies",
      "content": "<p>Publication date: 15 March 2026</p><p><b>Source:</b> Brain Research, Volume 1875</p><p>Author(s): Sarani Dey, Abhijit Das</p>",
      "author": "",
      "published_date": null,
      "source": "Brain Research",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2026-01-29T06:08:01.032684+00:00",
      "updated_at": "2026-01-29T06:40:08.847018+00:00",
      "metadata": {
        "processed_at": "2026-01-29T06:40:08.847029+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "2b5e21d5c9d66628fd1b2e60407de021",
      "url": "https://www.sciencedirect.com/science/article/pii/S0006899326000260?dgcid=rss_sd_all",
      "title": "The oral-gut-brain axis in periodontitis: microbial signaling in systemic and neuroinflammatory disease",
      "content": "<p>Publication date: 15 March 2026</p><p><b>Source:</b> Brain Research, Volume 1875</p><p>Author(s): V. Pravin, Chitra Vellapandian, V. Naveen Kumar</p>",
      "author": "",
      "published_date": null,
      "source": "Brain Research",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 16,
      "reading_time": 1,
      "created_at": "2026-01-29T06:08:01.032665+00:00",
      "updated_at": "2026-01-29T06:40:08.847033+00:00",
      "metadata": {
        "processed_at": "2026-01-29T06:40:08.847035+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "29eedc82df2c87e25f86837177f4003c",
      "url": "https://www.sciencedirect.com/science/article/pii/S1053811926000613?dgcid=rss_sd_all",
      "title": "A watershed algorithm GUI for personalized fMRI-guided rTMS target",
      "content": "<p>Publication date: 15 February 2026</p><p><b>Source:</b> NeuroImage, Volume 327</p><p>Author(s): Zi-Jian Feng, Ziyu Wei, Liquan Hong, Hongli Fang, Yu Han, Peifeng Yang, Dongsheng Lv, Yu-Feng Zang</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroimage",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 24,
      "reading_time": 1,
      "created_at": "2026-01-29T06:07:57.566491+00:00",
      "updated_at": "2026-01-29T06:40:08.847038+00:00",
      "metadata": {
        "processed_at": "2026-01-29T06:40:08.847039+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "6e6ce3e7a4bd63e3be884b39f3175024",
      "url": "https://www.frontiersin.org/articles/10.3389/fnbot.2025.1757770",
      "title": "Editorial: Machine learning and applied neuroscience, volume II",
      "content": "",
      "author": "Ganesh R. Naik",
      "published_date": "2026-01-20T00:00:00+00:00",
      "source": "Frontiers Neurorobotics",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2026-01-29T06:07:43.011517+00:00",
      "updated_at": "2026-01-29T06:40:08.847041+00:00",
      "metadata": {
        "processed_at": "2026-01-29T06:40:08.847043+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "5b46d7cf0b0030cf012f7c2d1d5b3185",
      "url": "http://doi.org/10.1037/drm0000321",
      "title": "The significance of dreams and dreaming in the traditional culture of Luo people in Kenya.",
      "content": "This article comprises two parts. Part I deals with Augustine Nwoye\u2019s classification of dreams in Africa, a theoretical background that has been used here purposively to explain the significance of dreams and dreaming to the Luo people in Kenya. This article is therefore deliberately anchored on Nwoye\u2019s African theoretical framework on dreams and dreaming. Part II of this article examines different types of dreams from the cultural perspective of the Luo traditional community, dreams that exemplify Nwoye\u2019s tripartite division of dreams and their sources. This article is particularly concerned with the meaning and significance of dreams and dreaming and what cultural practices and beliefs about dreams and dreaming might reveal about the ethical, epistemological, and metaphysical worldview of the Luo. Culturally, dreams serve various functions such as: sourcing names, counseling, healing, communication with ancestral spirits, mourning, solving personal and societal problems, prediction, divination, and fortune-telling, among many other pertinent issues. Dreams have social, cultural, epistemological, and metaphysical functions. These functions have been articulated in this article, \u201cThe Significance of Dreams and Dreaming.\u201d This article is one among only a few publications on the topic concerning the value of dreams and dreaming in the beliefs, customs, traditions, and beliefs of this community, the Luo in Kenya. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2025-10-23T00:00:00+00:00",
      "source": "Dreaming",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 214,
      "reading_time": 1,
      "created_at": "2026-01-29T06:07:21.069593+00:00",
      "updated_at": "2026-01-29T06:40:08.847045+00:00",
      "metadata": {
        "processed_at": "2026-01-29T06:40:08.847047+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "1ae6031e74c73097b0df3bb0bb283568",
      "url": "https://xmake.io/",
      "title": "Xmake: A cross-platform build utility based on Lua",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46753037\">Comments</a>",
      "author": "",
      "published_date": "2026-01-25T11:12:47+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-29T06:07:15.156225+00:00",
      "updated_at": "2026-01-29T06:07:15.156227+00:00"
    },
    {
      "id": "698a3967478d4ba61f5711c9117ea7e6",
      "url": "https://www.embs.org/uncategorized/call-for-applications-ieee-tmrb-editor-in-chief-search/",
      "title": "Call for Applications: IEEE T-MRB Editor in Chief Search",
      "content": "<p>The post <a href=\"https://www.embs.org/uncategorized/call-for-applications-ieee-tmrb-editor-in-chief-search/\">Call for Applications: IEEE T-MRB Editor in Chief Search</a> appeared first on <a href=\"https://www.embs.org\">IEEE EMBS</a>.</p>",
      "author": "Deidre Artis",
      "published_date": "2025-04-03T14:16:16+00:00",
      "source": "Embs",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 18,
      "reading_time": 1,
      "created_at": "2026-01-29T05:30:01.428550+00:00",
      "updated_at": "2026-01-29T05:30:01.428552+00:00"
    },
    {
      "id": "6180193191d50495d0300d3fd016ab1d",
      "url": "https://arxiv.org/abs/2601.20437",
      "title": "Remember Me, Not Save Me: A Collective Memory System for Evolving Virtual Identities in Augmented Reality",
      "content": "arXiv:2601.20437v1 Announce Type: new \nAbstract: This paper presents \"Remember Me, Not Save Me,\" an AR & AI system enabling virtual citizens to develop personality through collective dialogue. Core innovations include: Dynamic Collective Memory (DCM) model with narrative tension mechanisms for handling contradictory memories; State-Reflective Avatar for ambient explainability; and Geo-Cultural Context Anchoring for local identity. Deployed at the 2024 Jinan Biennale, the system demonstrated stable personality emergence (ISTP type via Apply Magic Sauce analysis) from over 2,500 public interactions. We provide a framework for designing evolving digital entities that transform collective memory into coherent identity.",
      "author": "Tongzhou Yu, Han Lin",
      "published_date": "2026-01-29T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 95,
      "reading_time": 1,
      "created_at": "2026-01-29T05:29:59.737183+00:00",
      "updated_at": "2026-01-29T05:29:59.737185+00:00"
    },
    {
      "id": "fb4d929277c2838353d4042260dd1014",
      "url": "https://arxiv.org/abs/2601.20402",
      "title": "GuideAI: A Real-time Personalized Learning Solution with Adaptive Interventions",
      "content": "arXiv:2601.20402v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have emerged as powerful learning tools, but they lack awareness of learners' cognitive and physiological states, limiting their adaptability to the user's learning style. Contemporary learning techniques primarily focus on structured learning paths, knowledge tracing, and generic adaptive testing but fail to address real-time learning challenges driven by cognitive load, attention fluctuations, and engagement levels. Building on findings from a formative user study (N=66), we introduce GuideAI, a multi-modal framework that enhances LLM-driven learning by integrating real-time biosensory feedback including eye gaze tracking, heart rate variability, posture detection, and digital note-taking behavior. GuideAI dynamically adapts learning content and pacing through cognitive optimizations (adjusting complexity based on learning progress markers), physiological interventions (breathing guidance and posture correction), and attention-aware strategies (redirecting focus using gaze analysis). Additionally, GuideAI supports diverse learning modalities, including text-based, image-based, audio-based, and video-based instruction, across varied knowledge domains. A preliminary study (N = 25) assessed GuideAI's impact on knowledge retention and cognitive load through standardized assessments. The results show statistically significant improvements in both problem-solving capability and recall-based knowledge assessments. Participants also experienced notable reductions in key NASA-TLX measures including mental demand, frustration levels, and effort, while simultaneously reporting enhanced perceived performance. These findings demonstrate GuideAI's potential to bridge the gap between current LLM-based learning systems and individualized learner needs, paving the way for adaptive, cognition-aware education at scale.",
      "author": "Ananya Shukla, Chaitanya Modi, Satvik Bajpai, Siddharth Siddharth",
      "published_date": "2026-01-29T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 231,
      "reading_time": 1,
      "created_at": "2026-01-29T05:29:59.737157+00:00",
      "updated_at": "2026-01-29T05:29:59.737159+00:00"
    },
    {
      "id": "0e1d7543db212c9352df4608d8275258",
      "url": "https://arxiv.org/abs/2601.20311",
      "title": "DiagLink: A Dual-User Diagnostic Assistance System by Synergizing Experts with LLMs and Knowledge Graphs",
      "content": "arXiv:2601.20311v1 Announce Type: new \nAbstract: The global shortage and uneven distribution of medical expertise continue to hinder equitable access to accurate diagnostic care. While existing intelligent diagnostic system have shown promise, most struggle with dual-user interaction, and dynamic knowledge integration -- limiting their real-world applicability. In this study, we present DiagLink, a dual-user diagnostic assistance system that synergizes large language models (LLMs), knowledge graphs (KGs), and medical experts to support both patients and physicians. DiagLink uses guided dialogues to elicit patient histories, leverages LLMs and KGs for collaborative reasoning, and incorporates physician oversight for continuous knowledge validation and evolution. The system provides a role-adaptive interface, dynamically visualized history, and unified multi-source evidence to improve both trust and usability. We evaluate DiagLink through user study, use cases and expert interviews, demonstrating its effectiveness in improving user satisfaction and diagnostic efficiency, while offering insights for the design of future AI-assisted diagnostic systems.",
      "author": "Zihan Zhou, Yinan Liu, Yuyang Xie, Bin Wang, Xiaochun Yang, Zezheng Feng",
      "published_date": "2026-01-29T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 150,
      "reading_time": 1,
      "created_at": "2026-01-29T05:29:59.737118+00:00",
      "updated_at": "2026-01-29T05:29:59.737119+00:00"
    },
    {
      "id": "44064db91b264ca87ac6cb864ac5139b",
      "url": "https://arxiv.org/abs/2601.20194",
      "title": "An Autonomous Agent Framework for Feature-Label Extraction from Device Dialogues and Automatic Multi-Dimensional Device Hosting Planning Based on Large Language Models",
      "content": "arXiv:2601.20194v1 Announce Type: new \nAbstract: With the deep integration of artificial intelligence and smart home technologies, the intelligent transformation of traditional household appliances has become an inevitable trend. This paper presents AirAgent--an LLM-driven autonomous agent framework designed for home air systems. Leveraging a voice-based dialogue interface, AirAgent autonomously and personally manages indoor air quality through comprehensive perception, reasoning, and control. The framework innovatively adopts a two-layer cooperative architecture: Memory-Based Tag Extraction and Reasoning-Driven Planning. First, a dynamic memory tag extraction module continuously updates personalized user profiles. Second, a reasoning-planning model integrates real-time environmental sensor data, user states, and domain-specific prior knowledge (e.g., public health guidelines) to generate context-aware decisions. To support both interpretability and execution, we design a semi-streaming output mechanism that uses special tokens to segment the model's output stream in real time, simultaneously producing human-readable Chain-of-Thought explanations and structured, device-executable control commands. The system handles planning across 25 distinct complex dimensions while satisfying more than 20 customized constraints. As a result, AirAgent endows home air systems with proactive perception, service, and orchestration capabilities, enabling seamless, precise, and personalized air management responsive to dynamic indoor and outdoor conditions. Experimental results demonstrate up to 94.9 percent accuracy and more than 20 percent improvement in user experience metrics compared to competing commercial solutions.",
      "author": "Huichao Men, Yizhen Hu, Yu Gao, Xiaofeng Mou, Yi Xu, Xinhua Xiao",
      "published_date": "2026-01-29T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 212,
      "reading_time": 1,
      "created_at": "2026-01-29T05:29:59.737088+00:00",
      "updated_at": "2026-01-29T05:29:59.737090+00:00"
    },
    {
      "id": "eba703a43f6d49fd92907ad0aee9508a",
      "url": "https://arxiv.org/abs/2601.20161",
      "title": "Supporting Informed Self-Disclosure: Design Recommendations for Presenting AI-Estimates of Privacy Risks to Users",
      "content": "arXiv:2601.20161v1 Announce Type: new \nAbstract: People candidly discuss sensitive topics online under the perceived safety of anonymity; yet, for many, this perceived safety is tenuous, as miscalibrated risk perceptions can lead to over-disclosure. Recent advances in Natural Language Processing (NLP) afford an unprecedented opportunity to present users with quantified disclosure-based re-identification risk (i.e., \"population risk estimates\", PREs). How can PREs be presented to users in a way that promotes informed decision-making, mitigating risk without encouraging unnecessary self-censorship? Using design fictions and comic-boarding, we story-boarded five design concepts for presenting PREs to users and evaluated them through an online survey with N = 44 Reddit users. We found participants had detailed conceptions of how PREs may impact risk awareness and motivation, but envisioned needing additional context and support to effectively interpret and act on risks. We distill our findings into four key design recommendations for how best to present users with quantified privacy risks to support informed disclosure decision-making.",
      "author": "Isadora Krsek, Meryl Ye, Wei Xu, Alan Ritter, Laura Dabbish, Sauvik Das",
      "published_date": "2026-01-29T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 158,
      "reading_time": 1,
      "created_at": "2026-01-29T05:29:59.737054+00:00",
      "updated_at": "2026-01-29T05:29:59.737056+00:00"
    },
    {
      "id": "d85f6b40aec9d5cacede17b73e63166e",
      "url": "https://arxiv.org/abs/2601.20100",
      "title": "Taming Toxic Talk: Using chatbots to intervene with users posting toxic comments",
      "content": "arXiv:2601.20100v1 Announce Type: new \nAbstract: Generative AI chatbots have proven surprisingly effective at persuading people to change their beliefs and attitudes in lab settings. However, the practical implications of these findings are not yet clear. In this work, we explore the impact of rehabilitative conversations with generative AI chatbots on users who share toxic content online. Toxic behaviors -- like insults or threats of violence, are widespread in online communities. Strategies to deal with toxic behavior are typically punitive, such as removing content or banning users. Rehabilitative approaches are rarely attempted, in part due to the emotional and psychological cost of engaging with aggressive users. In collaboration with seven large Reddit communities, we conducted a large-scale field experiment (N=893) to invite people who had recently posted toxic content to participate in conversations with AI chatbots. A qualitative analysis of the conversations shows that many participants engaged in good faith and even expressed remorse or a desire to change. However, we did not observe a significant change in toxic behavior in the following month compared to a control group. We discuss possible explanations for our findings, as well as theoretical and practical implications based on our results.",
      "author": "Jeremy Foote, Deepak Kumar, Bedadyuti Jha, Ryan Funkhouser, Loizos Bitsikokos, Hitesh Goel, Hsuen-Chi Chiu",
      "published_date": "2026-01-29T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 196,
      "reading_time": 1,
      "created_at": "2026-01-29T05:29:59.737024+00:00",
      "updated_at": "2026-01-29T05:29:59.737025+00:00"
    },
    {
      "id": "997f9672b5e967541bd5879df383c81d",
      "url": "https://arxiv.org/abs/2601.20086",
      "title": "Evaluating Actionability in Explainable AI",
      "content": "arXiv:2601.20086v1 Announce Type: new \nAbstract: A core assumption of Explainable AI (XAI) is that explanations are useful to users -- that is, users will do something with the explanations. Prior work, however, does not clearly connect the information provided in explanations to user actions to evaluate effectiveness. In this paper, we articulate this connection. We conducted a formative study through 14 interviews with end users in education and medicine. We contribute a catalog of information and associated actions. Our catalog maps 12 categories of information that participants described relying on to take 60 different actions. We show how AI Creators can use the catalog's specificity and breadth to articulate how they expect information in their explanations to lead to user actions and test their assumptions. We use an exemplar XAI system to illustrate this approach. We conclude by discussing how our catalog expands the design space for XAI systems to support actionability.",
      "author": "Gennie Mansi, Julia Kim, Mark Riedl",
      "published_date": "2026-01-29T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 152,
      "reading_time": 1,
      "created_at": "2026-01-29T05:29:59.736991+00:00",
      "updated_at": "2026-01-29T05:29:59.736993+00:00"
    },
    {
      "id": "24c8145368d8335073baff360aa38482",
      "url": "https://arxiv.org/abs/2601.20085",
      "title": "Editrail: Understanding AI Usage by Visualizing Student-AI Interaction in Code",
      "content": "arXiv:2601.20085v1 Announce Type: new \nAbstract: Programming instructors have diverse philosophies about integrating generative AI into their classes. Some encourage students to use AI, while others restrict or forbid it. Regardless of their approach, all instructors benefit from understanding how their students actually use AI while writing code. Such insight helps instructors assess whether AI use aligns with their pedagogical goals, enables timely intervention when they find unproductive usage patterns, and establishes effective policies for AI use. However, our survey with programming instructors found that many instructors lack visibility into how students use AI in their code-writing processes. To address this challenge, we introduce Editrail, an interactive system that enables instructors to track students' AI usage, create personalized assessments, and provide timely interventions, all within the workflow of monitoring coding histories. We found that Editrail enables instructors to detect AI use that conflicts with pedagogical goals accurately and to determine when and which students require intervention.",
      "author": "Ashley Ge Zhang, Yan-Ru Jhou, Yinuo Yang, Shamita Rao, Maryam Arab, Yan Chen, Steve Oney",
      "published_date": "2026-01-29T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 155,
      "reading_time": 1,
      "created_at": "2026-01-29T05:29:59.736958+00:00",
      "updated_at": "2026-01-29T05:29:59.736960+00:00"
    },
    {
      "id": "ed53e05f9c30e40812d7dd1e5ea04e47",
      "url": "https://arxiv.org/abs/2601.20080",
      "title": "Locatability and Locatability Robustness of Visual Variables in Single Target Localization",
      "content": "arXiv:2601.20080v1 Announce Type: new \nAbstract: Finding a particular object in a display is important for viewers in many visualizations, for example, when reacting to brushing or to a highlighted object. This can be enabled by making the target object different in one of the visual variables that determine the object's appearance; for example, by changing its color or size. Certain interpretations of the visual search literature have promoted the view that using visual variables such as hue-often labeled as preattentive-would make the target object automatically \"popout,\" implying that an object can be located almost instantly, regardless of the number of objects in the display. In this paper we present a study that serves as a bridge between the extensive visual search literature and visualization, establishing empirical base measurements for the localization task. By testing displays with up to hundreds of objects, we are able to show that none of the common visual variables is immune to the increase in the number of objects. We also provide the first empirically informed comparisons between visual variables for this task in the context of visualization, and show how different visual variables have varying robustness with respect to two additional dimensions: the location of the target and the overall visual arrangement (layout). A free copy of this paper and all supplemental materials are available on our online repository: https://osf.io/z68ak/overview.",
      "author": "Wei Wei, Miguel A. Nacenta, Michelle F. Miranda, Charles Perin",
      "published_date": "2026-01-29T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 225,
      "reading_time": 1,
      "created_at": "2026-01-29T05:29:59.736906+00:00",
      "updated_at": "2026-01-29T05:29:59.736909+00:00"
    },
    {
      "id": "9968c6d968394a674b0c0eb059645ea9",
      "url": "https://arxiv.org/abs/2601.20010",
      "title": "Treating symptoms or root causes: How does information about causal mechanisms affect interventions?",
      "content": "arXiv:2601.20010v1 Announce Type: new \nAbstract: When deciding how to solve complex problems, it seems important not only to know whether an intervention is helpful but also to understand why. Therefore, the present study investigated whether explicit information about causal mechanisms enables people to distinguish between multiple interventions. It was hypothesised that mechanism information helps them appreciate indirect interventions that treat the root causes of a problem instead of just fixing its symptoms. This was investigated in an experimental hoof trimming scenario in which participants evaluated various interventions. To do so, they received causal diagrams with different types of causal information and levels of mechanistic detail. While detailed mechanism information and its embedding in the context of other influences made participants less sceptical towards indirect interventions, the effects were quite small. Moreover, it did not mitigate participants' robust preference for interventions that only fix a problem's symptoms. Taken together, the findings suggest that in order to help people choose sustainable interventions, it is not sufficient to make information about causal mechanisms available.",
      "author": "Romy M\\\"uller",
      "published_date": "2026-01-29T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 171,
      "reading_time": 1,
      "created_at": "2026-01-29T05:29:59.736861+00:00",
      "updated_at": "2026-01-29T05:29:59.736865+00:00"
    },
    {
      "id": "447bcdf02499d9edc897e2500d144ae4",
      "url": "https://arxiv.org/abs/2601.20480",
      "title": "An explainable framework for the relationship between dementia and glucose metabolism patterns",
      "content": "arXiv:2601.20480v1 Announce Type: cross \nAbstract: High-dimensional neuroimaging data presents challenges for assessing neurodegenerative diseases due to complex non-linear relationships. Variational Autoencoders (VAEs) can encode scans into lower-dimensional latent spaces capturing disease-relevant features. We propose a semi-supervised VAE framework with a flexible similarity regularization term that aligns selected latent variables with clinical or biomarker measures of dementia progression. This allows adapting the similarity metric and supervised variables to specific goals or available data. We demonstrate the approach using PET scans from the Alzheimer's Disease Neuroimaging Initiative (ADNI), guiding the first latent dimension to align with a cognitive score. Using this supervised latent variable, we generate average reconstructions across levels of cognitive impairment. Voxel-wise GLM analysis reveals reduced metabolism in key regions, mainly the hippocampus, and within major Resting State Networks, particularly the Default Mode and Central Executive Networks. The remaining latent variables encode affine transformations and intensity variations, capturing confounds such as inter-subject variability and site effects. Our framework effectively extracts disease-related patterns aligned with established Alzheimer's biomarkers, offering an interpretable and adaptable tool for studying neurodegenerative progression.",
      "author": "C. V\\'azquez-Garc\\'ia, F. J. Mart\\'inez-Murcia, F. Segovia Rom\\'an, A. Forte, J. Ram\\'irez, I. Ill\\'an, A. Hern\\'andez-Segura, C. Jim\\'enez-Mesa, Juan M. G\\'orriz",
      "published_date": "2026-01-29T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 177,
      "reading_time": 1,
      "created_at": "2026-01-29T05:29:58.636157+00:00",
      "updated_at": "2026-01-29T05:29:58.636159+00:00"
    },
    {
      "id": "a7850001dd81b0560a8b2d76452c8270",
      "url": "https://arxiv.org/abs/2601.20236",
      "title": "Implications of temporal sampling in voltage imaging microscopy",
      "content": "arXiv:2601.20236v1 Announce Type: cross \nAbstract: Significance: Voltage imaging microscopy has emerged as a powerful tool to investigate neural activity both in vivo and in vitro. Various imaging approaches have been developed, including point-scanning, line-scanning and wide-field microscopes, however the effects of their different temporal sampling methods on signal fidelity have not yet been fully investigated. Aim: To provide an analysis of the inherent advantages and disadvantages of temporal sampling in scanning and wide-field microscopes and their effect on the fidelity of voltage spike detection. Approach: We develop a mathematical framework based on a mixture of analytical modeling and computer simulations with Monte-Carlo approaches. Results: Scanning microscopes outperform wide-field microscopes in low signal-to-noise conditions and when only a small subset of spikes needs to be detected. Wide-field microscopes outperform scanning microscopes when the measurement is temporally undersampled and a large fraction of the spikes needs to be detected. Both modalities converge in performance as sampling increases and the frame rate reaches the decay rate of the voltage indicator. Conclusions: Our work provides guidance for the selection of optimal temporal sampling parameters for voltage imaging. Most importantly it advises against using scanning voltage imaging microscopes at frame rates below 500 Hz.",
      "author": "Jakub Czuchnowski, Jerome Mertz",
      "published_date": "2026-01-29T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 199,
      "reading_time": 1,
      "created_at": "2026-01-29T05:29:58.636123+00:00",
      "updated_at": "2026-01-29T05:29:58.636125+00:00"
    },
    {
      "id": "2f9ea4909179e03057524dabd8c9628b",
      "url": "https://arxiv.org/abs/2601.20447",
      "title": "Assembling the Mind's Mosaic: Towards EEG Semantic Intent Decoding",
      "content": "arXiv:2601.20447v1 Announce Type: new \nAbstract: Enabling natural communication through brain-computer interfaces (BCIs) remains one of the most profound challenges in neuroscience and neurotechnology. While existing frameworks offer partial solutions, they are constrained by oversimplified semantic representations and a lack of interpretability. To overcome these limitations, we introduce Semantic Intent Decoding (SID), a novel framework that translates neural activity into natural language by modeling meaning as a flexible set of compositional semantic units. SID is built on three core principles: semantic compositionality, continuity and expandability of semantic space, and fidelity in reconstruction. We present BrainMosaic, a deep learning architecture implementing SID. BrainMosaic decodes multiple semantic units from EEG/SEEG signals using set matching and then reconstructs coherent sentences through semantic-guided reconstruction. This approach moves beyond traditional pipelines that rely on fixed-class classification or unconstrained generation, enabling a more interpretable and expressive communication paradigm. Extensive experiments on multilingual EEG and clinical SEEG datasets demonstrate that SID and BrainMosaic offer substantial advantages over existing frameworks, paving the way for natural and effective BCI-mediated communication.",
      "author": "Jiahe Li, Junru Chen, Fanqi Shen, Jialan Yang, Jada Li, Zhizhang Yuan, Baowen Cheng, Meng Li, Yang Yang",
      "published_date": "2026-01-29T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 170,
      "reading_time": 1,
      "created_at": "2026-01-29T05:29:58.636084+00:00",
      "updated_at": "2026-01-29T05:29:58.636088+00:00"
    }
  ]
}