{
  "last_updated": "2026-01-05T03:51:03.626491+00:00",
  "count": 20,
  "articles": [
    {
      "id": "eb99afbf44b79cf266312c85904181fc",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.04.697049v1?rss=1",
      "title": "Snipers under stress: mentally simulated motor actions are resistant to acute stress in police officers",
      "content": "Motor imagery (MI) is a sensorimotor process allowing to mentally simulate a motor action and is widely used to enhance performance in domains such as rehabilitation, sport, and professional training. Although MI is increasingly incorporated into stress-management interventions, the reciprocal relationship, that is, the effect of acute stress on MI remain paradoxically poorly understood, particularly in ecologically valid settings. The present study investigated this issue in professional police officers performing physically and mentally a precise handgun manipulation task under graded stress conditions (psychological stress). Fourteen participants was exposed to controlled, work-related stress scenarios designed to closely reflect real operational demands, while stress markers and temporal features of executed and imagined movements were recorded. Our results clearly indicate that motor imagery was preserved despite significant increases in stress levels, as the temporal characteristics of both executed and imagined movements remained stable across experimental conditions. These findings indicate that MI is resilient to acute psychosocial stress and support its relevance as a reliable training and performance-optimization tool in high-demand occupational settings.",
      "author": "Monier, H., Grospretre, S., gueugneau, n.",
      "published_date": "2026-01-04T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 169,
      "reading_time": 1,
      "created_at": "2026-01-05T01:58:40.646395+00:00",
      "updated_at": "2026-01-05T03:51:03.521025+00:00",
      "metadata": {
        "processed_at": "2026-01-05T03:51:03.521034+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "26ba4f933eb13bc59665501411f5051d",
      "url": "https://www.reddit.com/r/Python/comments/1q3ecap/generating_graphs_and_jsons_with_vlrgg_tournaments/",
      "title": "Generating graphs and jsons with vlrgg tournaments",
      "content": "<!-- SC_OFF --><div class=\"md\"><h1>What My Project Does</h1> <p>A Python tool that scrapes <strong>Valorant player stats from</strong> <a href=\"http://VLR.gg\"><strong>VLR.gg</strong></a> and exports clean <strong>JSON files</strong> with <strong>KDA and player images</strong>.<br /> It also includes a <strong>bar graph generator</strong> to visualize and compare players across <strong>career-wide stats or specific tournaments</strong> (single or multiple events).</p> <h1>Target Audience</h1> <p>Primarily for <strong>developers, analysts, and Valorant fans</strong> who want to analyze <a href=\"http://VLR.gg\">VLR.gg</a> data locally.<br /> It\u2019s a <strong>personal / educational project</strong>, not meant for production-scale scraping.</p> <h1>Comparison</h1> <p>Unlike most <a href=\"http://VLR.gg\">VLR.gg</a> scrapers, this project:</p> <ul> <li>Supports <strong>career-based and tournament-based</strong> stats</li> <li>Can scrape <strong>multiple tournaments at once</strong></li> <li>Extracts <strong>player profile images</strong></li> <li>Includes a built-in <strong>visual graph generator</strong> instead of only raw data</li> </ul> <p><a href=\"https://github.com/MateusVega/vlrgg-stats-scraper\">https://github.com/MateusVega/vlrgg-stats-scraper</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Stock-Loquat111\"> /u/Stock-Loquat111 </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1q3ecap/generating_graphs_and_jsons_with_vlrgg_tournaments/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1q3ecap/generating_graphs_and_jsons_with_vlrgg_tournaments/\">[comments]</a></span>",
      "author": "/u/Stock-Loquat111",
      "published_date": "2026-01-04T02:53:52+00:00",
      "source": "Reddit Python",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 136,
      "reading_time": 1,
      "created_at": "2026-01-05T01:57:59.966480+00:00",
      "updated_at": "2026-01-05T03:51:03.521038+00:00",
      "metadata": {
        "processed_at": "2026-01-05T03:51:03.521040+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "26f15f2dc00801d44e361a5bc13a4f96",
      "url": "https://www.dampfkraft.com/showa-100.html",
      "title": "The Showa Hundred Year Problem",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46440997\">Comments</a>",
      "author": "",
      "published_date": "2025-12-31T03:35:58+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-05T01:57:58.641175+00:00",
      "updated_at": "2026-01-05T03:51:03.521043+00:00",
      "metadata": {
        "processed_at": "2026-01-05T03:51:03.521044+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "7170c824cb5edc82590e7ad1302327c4",
      "url": "https://warontherocks.com/2015/11/millennium-challenge-the-real-story-of-a-corrupted-military-exercise-and-its-legacy/",
      "title": "Millennium Challenge: A corrupted military exercise and its legacy (2015)",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46493623\">Comments</a>",
      "author": "",
      "published_date": "2026-01-04T23:43:48+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-05T01:57:58.641138+00:00",
      "updated_at": "2026-01-05T03:51:03.521047+00:00",
      "metadata": {
        "processed_at": "2026-01-05T03:51:03.521048+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "42a2db2f56e2a1a117e8ddf968928af5",
      "url": "https://chuanqisun.github.io/quantum-tunnel/",
      "title": "Show HN: Quantum Tunnel",
      "content": "<p>Article URL: <a href=\"https://chuanqisun.github.io/quantum-tunnel/\">https://chuanqisun.github.io/quantum-tunnel/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46493533\">https://news.ycombinator.com/item?id=46493533</a></p>\n<p>Points: 13</p>\n<p># Comments: 4</p>",
      "author": "osmoscraft",
      "published_date": "2026-01-04T23:31:31+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2026-01-05T01:57:57.403312+00:00",
      "updated_at": "2026-01-05T03:51:03.521050+00:00",
      "metadata": {
        "processed_at": "2026-01-05T03:51:03.521052+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "7170c824cb5edc82590e7ad1302327c4",
      "url": "https://warontherocks.com/2015/11/millennium-challenge-the-real-story-of-a-corrupted-military-exercise-and-its-legacy/",
      "title": "Millennium Challenge: A corrupted military exercise and its legacy (2015)",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46493623\">Comments</a>",
      "author": "",
      "published_date": "2026-01-04T23:43:48+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-05T01:57:58.641138+00:00",
      "updated_at": "2026-01-05T03:51:03.521047+00:00",
      "metadata": {
        "processed_at": "2026-01-05T03:51:03.521048+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "d3c0ea6ae21b4d3688367ae171918fa8",
      "url": "https://www.sciencedirect.com/science/article/pii/S0006899325006857?dgcid=rss_sd_all",
      "title": "Functional connectivity and graphical topological properties of the visual cortical network of minimally conscious state (MCS) patients",
      "content": "<p>Publication date: 15 February 2026</p><p><b>Source:</b> Brain Research, Volume 1873</p><p>Author(s): Zina Li, Jichan Nian, Shuiyan Li, Zhiqing Deng, Hang Wu, Haili Zhong, Xiyan Huang, Pengmin Qin, Jinhui Wang, Qiuyou Xie, Juan Chen</p>",
      "author": "",
      "published_date": null,
      "source": "Brain Research",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 31,
      "reading_time": 1,
      "created_at": "2026-01-04T23:42:27.131771+00:00",
      "updated_at": "2026-01-05T01:23:23.001629+00:00",
      "metadata": {
        "processed_at": "2026-01-05T01:23:23.001638+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "4516c6195696476bdf9a42aed6c320aa",
      "url": "https://www.sciencedirect.com/science/article/pii/S0006899325006833?dgcid=rss_sd_all",
      "title": "A systematic review of the effect of pulse parameters of next-generation TMS devices on corticospinal excitability and neuroplasticity",
      "content": "<p>Publication date: 15 February 2026</p><p><b>Source:</b> Brain Research, Volume 1873</p><p>Author(s): Desmond Agboada, Roman Rethwilm, Manuel Kuder, Wolfgang Mack, Wolfgang Seiberl</p>",
      "author": "",
      "published_date": null,
      "source": "Brain Research",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 19,
      "reading_time": 1,
      "created_at": "2026-01-04T23:42:27.131712+00:00",
      "updated_at": "2026-01-05T01:23:23.001642+00:00",
      "metadata": {
        "processed_at": "2026-01-05T01:23:23.001644+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "de64d79148bdd53306aab5f92ee8e278",
      "url": "https://www.frontiersin.org/articles/10.3389/fncom.2025.1704350",
      "title": "Common characteristics of variants linked to autism spectrum disorder in the WAVE regulatory complex",
      "content": "Six variants associated with autism spectrum disorder (ASD) abnormally activate the WASP-family Verprolin-homologous protein (WAVE) regulatory complex (WRC), a critical regulator of actin dynamics. This abnormal activation may contribute to the pathogenesis of this disorder. Using molecular dynamics (MD) simulations, we recently investigated the structural dynamics of wild-type (WT) WRC and R87C, A455P, and Q725R WRC disease-linked variants. Here, by extending MD simulations to I664M, E665K, and D724H WRC, we suggest that all of the mutations weaken the interactions and affect intra-complex allosteric communication between the WAVE1 active C-terminal region (ACR) and the rest of the complex. This might contribute to an abnormal complex activation, a hallmark of WRC-linked ASD. In addition, all mutants but I664M destabilize the ACR V-helix and increase the participation of ACR in large-scale movements. All these features may also abnormally influence the inactive WRC toward a dysfunctional state. We hypothesize that small-molecule ligands counteracting these effects may help restore normal WRC regulation in ASD-related variants.",
      "author": "Paolo Carloni",
      "published_date": "2025-11-12T00:00:00+00:00",
      "source": "Frontiers Computational Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 160,
      "reading_time": 1,
      "created_at": "2026-01-04T23:42:12.810188+00:00",
      "updated_at": "2026-01-05T01:23:23.001646+00:00",
      "metadata": {
        "processed_at": "2026-01-05T01:23:23.001648+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "699e9378a1ca54067c5e179fc4c87842",
      "url": "https://www.frontiersin.org/articles/10.3389/fncom.2025.1685586",
      "title": "Simplex polynomial in complex networks and its applications to compute the Euler characteristic",
      "content": "In algebraic topology, a k-dimensional simplex is defined as a convex polytope consisting of k + 1 vertices. If spatial dimensionality is not considered, it corresponds to the complete graph with k + 1 vertices in graph theory. The alternating sum of the number of simplices across dimensions yields a topological invariant known as the Euler characteristic, which has gained significant attention due to its widespread application in fields such as topology, homology theory, complex systems, and biology. The most common method for calculating the Euler characteristic is through simplicial decomposition and the Euler\u2013Poincar\u00e9 formula. In this study, we introduce a new \u201csubgraph\u201d polynomial, termed the simplex polynomial, and explore some of its properties. Using those properties, we provide a new method for computing the Euler characteristic and prove the existence of the Euler characteristic as an arbitrary integer by constructing the corresponding simplicial complex structure. When the Euler characteristic is 1, we determined a class of corresponding simplicial complex structures. Moreover, for three common network structures, we present the recurrence relations for their simplex polynomials and their corresponding Euler characteristics. Finally, at the end of this study, three basic questions are raised for the interested readers to study deeply.",
      "author": "Haixing Zhao",
      "published_date": "2025-11-26T00:00:00+00:00",
      "source": "Frontiers Computational Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 200,
      "reading_time": 1,
      "created_at": "2026-01-04T23:42:12.810086+00:00",
      "updated_at": "2026-01-05T01:23:23.001650+00:00",
      "metadata": {
        "processed_at": "2026-01-05T01:23:23.001652+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "0776e62e75431e1a553ad13fcb6c12e2",
      "url": "https://www.frontiersin.org/articles/10.3389/fncom.2025.1647462",
      "title": "A neural network model combining the successor representation and actor-critic methods reveals effective biological use of the representation",
      "content": "In learning goal-directed behavior, state representation is important for adapting to the environment and achieving goals. A predictive state representation called successive representation (SR) has recently attracted attention as a candidate for state representation in animal brains, especially in the hippocampus. The relationship between the SR and the animal brain has been studied, and several neural network models for computing the SR have been proposed based on the findings. However, studies on implementation of the SR involving action selection have not yet advanced significantly. Therefore, we explore possible mechanisms by which the SR is utilized biologically for action selection and learning optimal action policies. The actor-critic architecture is a promising model of animal behavioral learning in terms of its correspondence to the anatomy and function of the basal ganglia, so it is suitable for our purpose. In this study, we construct neural network models for behavioral learning using the SR. By using them to perform reinforcement learning, we investigate their properties. Specifically, we investigated the effect of using different state representations for the actor and critic in the actor-critic method, and also compared the actor-critic method with Q-learning and SARSA. We found the difference between the effect of using the SR for the actor and the effect of using the SR for the critic in the actor-critic method, and observed that using the SR in conjunction with one-hot encoding makes it possible to learn with the benefits of both representations. These results suggest the possibility that the striatum can learn using multiple state representations complementarily.",
      "author": "Kenji Morita",
      "published_date": "2025-11-26T00:00:00+00:00",
      "source": "Frontiers Computational Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 255,
      "reading_time": 1,
      "created_at": "2026-01-04T23:42:12.810050+00:00",
      "updated_at": "2026-01-05T01:23:23.001654+00:00",
      "metadata": {
        "processed_at": "2026-01-05T01:23:23.001656+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "8bec92d361ee3c15eab323f1288a063d",
      "url": "https://www.frontiersin.org/articles/10.3389/fncom.2025.1699179",
      "title": "State-dependent filtering as a mechanism toward visual robustness",
      "content": "Robustness, defined as a system's ability to maintain functional reliability in the face of perturbations, is achieved through its capacity to filter external disturbances using internal priors encoded in its structure and states. While biophysical neural networks are widely recognized for their robustness, the precise mechanisms underlying this resilience remain poorly understood. In this study, we explore how orientation-selective neurons arranged in a one-dimensional ring network respond to perturbations, with the aim of uncovering insights into the robustness of visual subsystems in the brain. By analyzing the steady-state dynamics of a rate-based network, we characterize how the activation state of neurons influences the network's response to disturbances. Our results demonstrate that the activation state of neurons, rather than their firing rates alone, governs the network's sensitivity to perturbations. We further show that lateral connectivity modulates this effect by shaping the response profile across spatial frequency components. These findings suggest a state-dependent filtering mechanism that contributes to the robustness of visual circuits, offering theoretical insight into how different components of perturbations are selectively modulated within the network.",
      "author": "Yaoyu Zhang",
      "published_date": "2025-12-10T00:00:00+00:00",
      "source": "Frontiers Computational Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 176,
      "reading_time": 1,
      "created_at": "2026-01-04T23:42:12.809892+00:00",
      "updated_at": "2026-01-04T23:42:12.809893+00:00"
    },
    {
      "id": "63022d1bdc6d9b1938f28ac79ff063e0",
      "url": "https://www.frontiersin.org/articles/10.3389/fnhum.2025.1594106",
      "title": "Leveraging transcranial ultrasound stimulation to enhance self-regulation in emotion and sleep",
      "content": "This Perspective article discusses the emerging potential of transcranial ultrasound stimulation (TUS) as a non-invasive neuromodulatory technique for enhancing self-regulatory processes, particularly emotion and sleep regulation, in healthy individuals. Offering high spatial precision and the ability to target both cortical and deep brain regions, TUS uses focused ultrasound waves to induce acute and delayed effects on brain activity. We propose that combining TUS with neurofeedback methods and/or specific cognitive training exercises may capitalise on these neuroplastic effects, thereby augmenting and prolonging their impact to support lasting improvements in self-regulation. We focus on the domains of sleep and emotion regulation, where such an integrated approach may strengthen resilience and promote healthier functioning in the general population. Our aim is to highlight the potential of TUS-based integrated interventions for supporting mental health and well-being in non-clinical populations and to outline key directions for future research.",
      "author": "Elsa Fouragnan",
      "published_date": "2025-12-19T00:00:00+00:00",
      "source": "Frontiers Human Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 143,
      "reading_time": 1,
      "created_at": "2026-01-04T23:42:11.338306+00:00",
      "updated_at": "2026-01-04T23:42:11.338307+00:00"
    },
    {
      "id": "6309fe51366e561677734ca5a0b65f2e",
      "url": "https://www.frontiersin.org/articles/10.3389/fnbot.2025.1706626",
      "title": "IAP-TransUNet: integration of the attention mechanism and pyramid pooling for medical image segmentation",
      "content": "IntroductionThe combination of CNN and Transformer has attracted much attention for medical image segmentation due to its superior performance at present. However, the segmentation performance is affected by limitations such as the local receptive field and static weights of CNN convolution operations, as well as insufficient information exchange between Transformer local regions.MethodsTo address these issues, an integrated attention mechanism and pyramid pooling network is proposed in this paper. Firstly, an efficient channel attention mechanism is embedded into CNN to extract more comprehensive image features. Then, CBAM_ASPP module is introduced into the bottleneck layer to obtain multi-scale context information. Finally, in order to address the limitations of traditional convolution, depthwise separable convolution is used to achieve a lightweight network.ResultsThe experiments based on the Synapse multi organ segmentation dataset and ACDC dataset showed that the proposed IAP-TransUNet achieved Dice similarity coefficients (DSCs) of 78.85% and 90.46%, respectively. Compared with the state-of-the-art method, for the Synapse multi organ segmentation dataset, the Hausdorff distance was reduced by 2.92%. For the ACDC dataset, the segmentation accuracy of the left ventricle, myocardium, and right ventricle was improved by 0.14%, 1.89%, and 0.23%, respectively.DiscussionThe experimental results demonstrate that the proposed network has improved the effectiveness and shows strong performance on both CT and MRI data, which suggests its potential for generalization across different medical imaging modalities.",
      "author": "Quan Liu",
      "published_date": "2025-12-01T00:00:00+00:00",
      "source": "Frontiers Neurorobotics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 219,
      "reading_time": 1,
      "created_at": "2026-01-04T23:42:09.907838+00:00",
      "updated_at": "2026-01-04T23:42:09.907840+00:00"
    },
    {
      "id": "93d4f700e0aae9a6263822cab2b038cf",
      "url": "http://doi.org/10.1037/pmu0000299",
      "title": "Capturing coordination and intentionality in joint musical improvisation.",
      "content": "Humans collaborate with each other on a wide variety of tasks that are often largely improvised and unscripted. In this study, we investigated the dynamics of coordination in a joint musical improvisation task, what the effect of intentions is on coordination, and how musicians propagate these intentions. To quantify coordination within musical trios, we derived per-musician time series of acoustic features to which we applied effective transfer entropy (ETE) and empirical dynamic modeling (EDM), two methods derived from complex systems science. Using ETE allowed us to investigate coordination as directional information flow between musicians, whereas through EDM we conceptualized coordination as the predictability of a complex system. We found that both techniques, when applied to root-mean-square (RMS) amplitude time series, could be used to distinguish coordinating from noncoordinating musicians. Various other feature\u2013technique combinations, such as fractal dimension\u2013ETE and Tonnetz distance\u2013EDM, were also viable. Our results further suggest that coordination improves as an intention gets more shared, that is, as more musicians in the joint improvisation have the same intention. Lastly, we found evidence suggesting that musicians increase the predictability of their playing when seeking to end a performance, though our results did not provide an indication that this was done with the intention of improving coordination with partners. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2023-08-03T00:00:00+00:00",
      "source": "Psychomusicology",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 217,
      "reading_time": 1,
      "created_at": "2026-01-04T23:41:54.348912+00:00",
      "updated_at": "2026-01-04T23:41:54.348914+00:00"
    },
    {
      "id": "bbe0f805e4fabfb0ac2476417484aef4",
      "url": "http://ieeexplore.ieee.org/document/10946856",
      "title": "Enhancing Video Experiences for DHH Individuals Through Sound-Inspired Motion Caption-Based Spatiotemporal Tacton",
      "content": "When deaf and hard of hearing (DHH) individuals watch videos, captions are essential for them to understand the linguistic content. Current captions, however, are not suitable for conveying non-verbal sound information, such as background music, sound effects, or speech nuances. In this paper, we designed a multimodal system, Motion Caption Haptic System (MCHS), that enables DHH individuals to encounter sounds in videos through animated caption and spatiotemporal vibration patterns, supporting a more vivid and immersive experience. We elaborately designed motion captions and spatiotemporal haptic patterns for representative sound effects and spoken emotions to work well together through surveys from 27 DHH and 64 hearing participants. An evaluation with 19 DHH individuals demonstrated the capabilities and potential of the MCHS to improve their video viewing experience, along with a discussion of important issues that need to be addressed when designing multimodal captioning systems for the DHH viewers.",
      "author": "",
      "published_date": "2025-04-01T13:17:18+00:00",
      "source": "Transactions Haptics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 146,
      "reading_time": 1,
      "created_at": "2026-01-04T23:21:35.801030+00:00",
      "updated_at": "2026-01-04T23:21:35.801031+00:00"
    },
    {
      "id": "609521b013e1243f77b1eaa5e01eab3e",
      "url": "http://ieeexplore.ieee.org/document/10965524",
      "title": "VibTac: A High-Resolution High-Bandwidth Tactile Sensing Finger for Multi-Modal Perception in Robotic Manipulation",
      "content": "Tactile sensing is pivotal for enhancing robot manipulation abilities by providing crucial feedback for localized information. However, existing sensors often lack the necessary resolution and bandwidth required for intricate tasks. To address this gap, we introduce VibTac, a novel multi-modal tactile sensing finger designed to offer high-resolution and high-bandwidth tactile sensing simultaneously. VibTac seamlessly integrates vision-based and vibration-based tactile sensing modes to achieve high-resolution and high-bandwidth tactile sensing respectively, leveraging a streamlined human-inspired design for versatility in tasks. This paper outlines the key design elements of VibTac and its fabrication methods, highlighting the significance of the Elastomer Gel Pad (EGP) in its sensing mechanism. The sensor's multi-modal performance is validated through 3D reconstruction and spectral analysis to discern tactile stimuli effectively. In experimental trials, VibTac demonstrates its efficacy by achieving over 90% accuracy in insertion tasks involving objects emitting distinct sounds, such as ethernet connectors. Leveraging vision-based tactile sensing for object localization and employing a deep learning model for \u201cclick\u201d sound classification, VibTac showcases its robustness in real-world scenarios.",
      "author": "",
      "published_date": "2025-04-15T13:16:45+00:00",
      "source": "Transactions Haptics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 169,
      "reading_time": 1,
      "created_at": "2026-01-04T23:21:35.801001+00:00",
      "updated_at": "2026-01-04T23:21:35.801002+00:00"
    },
    {
      "id": "42247a9e793d9dae5103ccfc54fc3b5e",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.02.697327v1?rss=1",
      "title": "Evaluating and Classifying Gentleness in VR-Based Surgical Simulation: A VR+fNIRS Study",
      "content": "Gentleness, defined as the ability to handle tissues delicately and minimize unnecessary force, is a key indicator of surgical proficiency. Objective and real-time assessment of gentleness in virtual reality (VR)-based training can enhance the understanding of both psychomotor and cognitive aspects of surgical skill. This study evaluates and classifies participants gentleness during VR-based surgical simulations using fNIRS-derived hemodynamic features. We trained and compared several machine learning models to assess performance. Twenty-three volunteers with no prior laparoscopic experience performed a virtual reality-based laparoscopic double-grasper task while hemodynamic activity over frontal and motor cortical areas was recorded using eighteen fNIRS channels. Alongside fNIRS, we collected subjective workload (NASA-TLX), error numbers, and a VR gentleness score. This task involves using two grasper tools simultaneously to perform the tissue like balloon manipulation in a VR environment. We extracted temporal features (slope, RMS, standard deviation) and trained machine learning models to classify performance levels based on cortical activation. Labels were binarized as low vs. high using median splits for the gentleness score. Models were evaluated with stratified 5-fold cross-validation and summarized by accuracy. Results showed stronger right-frontal HbO activity and increased left-motor HbR responses in the low-performance group, suggesting greater cognitive effort and less efficient motor strategies during VR-based laparoscopic manipulation. Across classifiers and feature sets, slope-based features consistently outperformed variability- and amplitude-based metrics. Among the tested models, HbR slope features achieved the best overall classification performance, with the highest accuracy obtained using K-Nearest Neighbor and Random Forest classifiers (accuracy {approx} 0.89, AUC up to 0.97). These findings demonstrate that fNIRS-derived hemodynamic dynamics can reliably discriminate between high and low VR performance levels, supporting their potential use in automated performance assessment and neuroadaptive feedback frameworks for VR-based surgical training.",
      "author": "Sanli, S., Keles, H. O.",
      "published_date": "2026-01-04T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 284,
      "reading_time": 1,
      "created_at": "2026-01-04T23:21:16.331660+00:00",
      "updated_at": "2026-01-04T23:21:16.331662+00:00"
    },
    {
      "id": "3a9a78f8a19dd3283fbdf2a3d79bb820",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.04.697560v1?rss=1",
      "title": "When exploration replaces storage: how eye movements shape visual working memory",
      "content": "Visual working memory (VWM) is traditionally studied while constraining eye movements and limiting access to visual input, yet in natural vision humans constantly explore and resample their environment. Only a few studies have examined VWM utilization when participants were allowed to interact with the environment and found that participants often preferred to resample their environment rather than rely on VWM storage. However, since eye movements were not controlled in these studies, the link between VWM utilization and free visual exploration remained unknown. In two experiments (N = 40), we investigated how visual exploration shapes reliance on VWM versus perceptual input. Participants searched for a common target across two item sets and could either store multiple items for comparison or repeatedly resample the sets by switching between them. Results revealed that when switching was achieved through eye movements, participants consistently relied more on visual resampling and less on VWM; in contrast, when switching required a manual response, they shifted toward greater VWM use. This pattern persisted even when peripheral input was equated, suggesting that natural exploration through eye movements reduces the cognitive cost of acquiring visual information, leading to a strategic reduction in VWM use. Our findings challenge fixation-based approaches to VWM research and highlight the importance of studying cognition under ecological viewing conditions.",
      "author": "Qais, R., Knight, R., Yuval-Greenberg, S.",
      "published_date": "2026-01-04T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 213,
      "reading_time": 1,
      "created_at": "2026-01-04T23:21:16.331608+00:00",
      "updated_at": "2026-01-04T23:21:16.331613+00:00"
    },
    {
      "id": "fca62ea89e4642259308a4cccd8727ef",
      "url": "https://www.frontiersin.org/articles/10.3389/fnhum.2025.1628840",
      "title": "Gender perception of pareidolia faces in emergency department patients: the influence of physician gender",
      "content": "BackgroundThe assessment of gender perception influenced by ambiguous facial cues in patients requiring emergency medical attention remains ambiguous. Pareidolia faces represent unconscious errors in facial recognition, wherein a wide array of visual attributes contribute to the interpretation of facial features. This study aims to explore the mechanisms underlying gender perception in individuals undergoing emergency medical treatment, employing an innovative digital pareidolia assessment to evaluate gender perception within the context of face pareidolia.MethodsFifty adult patients treated by a female physician in the green triage zone participated in the study. Target images consisted of face pareidolia images, while non-target images were scrambled. All images were standardized for size, tone, and light intensity. Patients instructed the pareidolia images and were asked if they discerned a face; if they answered \u2018No,\u2019 the next image was shown. If they saw a face, they identified the associated gender. Their responses and reaction times were systematically recorded digitally.ResultsOur findings revealed that, regardless of wait times, patients were significantly more likely to identify pareidolia faces as male rather than female, especially after being examined by a female physician. Additionally, male patients exhibited slightly longer reaction times than females when responding to pareidolia images.ConclusionThe outcomes of this investigation provide critical insights into the influence of pareidolia on gender perception of faces in the emergency department setting. It underscores the notion that gender biases, which arise from both biological and sociocultural factors, can affect the dynamics of patient-physician interactions.",
      "author": "Nilg\u00fcn Altunta\u015f",
      "published_date": "2025-12-19T00:00:00+00:00",
      "source": "Frontiers Human Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 239,
      "reading_time": 1,
      "created_at": "2026-01-04T23:21:05.747020+00:00",
      "updated_at": "2026-01-04T23:21:05.747022+00:00"
    }
  ]
}