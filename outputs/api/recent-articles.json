{
  "last_updated": "2025-12-12T07:45:05.421571+00:00",
  "count": 20,
  "articles": [
    {
      "id": "ab3e53bffeaa5abdcc5d72d24f8c4b4f",
      "url": "https://lucassifoni.info/blog/miniscope-tiny-telescope/",
      "title": "The tiniest yet real telescope I've built",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46241763\">Comments</a>",
      "author": "",
      "published_date": "2025-12-12T07:35:49+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-12T07:43:58.091862+00:00",
      "updated_at": "2025-12-12T07:43:58.091864+00:00"
    },
    {
      "id": "f77528a0ee2d349949c472d9248cd6f5",
      "url": "https://www.frontiersin.org/articles/10.3389/fnins.2025.1689655",
      "title": "Ocular diagnostics and occipital neurovascular coupling in ocular hypertension and open angle glaucoma",
      "content": "IntroductionThe relationship between glaucoma and neurovascular coupling in the visual cortex has yet to be fully explored and understood. This study employs the time-domain (TD) functional near-infrared spectroscopy (fNIRS) technique to noninvasively monitor the hemodynamic response function (HRF) in the visual cortex.Methods203 eyes (104 subjects, 46 females, 58 males): 44 with ocular hypertension (OHT), 38 with open-angle glaucoma (OAG), 54 with normal tension glaucoma (NTG), and 67 without abnormal/pathologic condition, were analyzed. All subjects had a complete eye examination, including Goldmann tonometry, computerized visual field optical coherence tomography, pattern electroretinogram, and visual evoked potentials. Visual cortex HRF was assessed by TD-fNIRS using a standard stimulation protocol (reversed checkerboard at 10\u202fHz). Multivariate statistical analysis was performed to obtain groups (clusters) of eyes based on the respective TD-fNIRS parameters. The relationships between the clusters and the diagnostic groups were assessed by comparing the distributions of the former ones among healthy, hypertensive and glaucomatous eyes.ResultsWe found six clusters of eyes, five representing eyes with consistent measurements of HRF amplitudes across acquisition channels (left/right hemisphere) and repeated stimuli, distinguished by distinct magnitudes of neurovascular coupling. The sixth cluster included all the cases of incoherent HRF patterns. Evidence of a different distribution between glaucomatous and healthy eyes was found (p\u202f=\u202f0.0009), suggesting that high levels of neurovascular coupling are less likely to be observed in NTG and OAG groups.ConclusionOccipital TD-fNIRS could be fruitfully implemented in a clinical setting to provide significant and easy-to-get insights on neurovascular dynamics, supporting the differential diagnosis of glaucomatous patients. Our findings highlight the importance of the underappreciated correlates between glaucoma and overall neurologic status.",
      "author": "Giuseppe Marano",
      "published_date": "2025-12-12T00:00:00+00:00",
      "source": "Frontiers Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 266,
      "reading_time": 1,
      "created_at": "2025-12-12T06:35:09.755662+00:00",
      "updated_at": "2025-12-12T06:35:09.755664+00:00"
    },
    {
      "id": "ea527069c0b8458f187b71a237d3f878",
      "url": "https://www.frontiersin.org/articles/10.3389/fnins.2025.1716204",
      "title": "A hybrid Spiking Neural Network\u2013Transformer architecture for motor imagery and sleep apnea detection",
      "content": "IntroductionMotor imagery (MI) classification and sleep apnea (SA) detection are two critical tasks in brain-computer interface (BCI) and biomedical signal analysis. Traditional deep learning models have shown promise in these domains, but often struggle with temporal sparsity and energy efficiency, especially in real-time or embedded applications.MethodsIn this study, we propose SpiTranNet, a novel architecture that deeply integrates Spiking Neural Networks (SNNs) with Transformers through Spiking Multi-Head Attention (SMHA), where spiking neurons replace standard activation functions within the attention mechanism. This integration enables biologically plausible temporal processing and energy-efficient computations while maintaining global contextual modeling capabilities. The model is evaluated across three physiological datasets, including one electroencephalography (EEG) dataset for MI classification and two electrocardiography (ECG) datasets for SA detection.ResultsExperimental results demonstrate that the hybrid SNN-Transformer model achieves competitive accuracy compared to conventional machine learning and deep learning models.DiscussionThis work highlights the potential of neuromorphic-inspired architectures for robust and efficient biomedical signal processing across diverse physiological tasks.",
      "author": "Roman Mou\u010dek",
      "published_date": "2025-12-12T00:00:00+00:00",
      "source": "Frontiers Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 156,
      "reading_time": 1,
      "created_at": "2025-12-12T06:35:09.755620+00:00",
      "updated_at": "2025-12-12T06:35:09.755622+00:00"
    },
    {
      "id": "59b25e5b9c844980eacfafeb26e7cf86",
      "url": "https://www.frontiersin.org/articles/10.3389/fnins.2025.1695464",
      "title": "Isogenic iPSC-derived CTBP1 mutant neuronal cells exhibit neurodevelopmental defects",
      "content": "Hypotonia, ataxia, developmental delay, and tooth enamel defects syndrome (HADDTS) is a recently identified disorder linked to a heterozygous mutation in the C-terminal Binding Protein 1 (CTBP1) transcriptional corepressor. The predominant mutation (p.R342W) is located within the major protein binding cleft (PXDLS), crucial for CtBP1\u2019s interaction with transcriptional regulatory proteins. To investigate the mutation\u2019s functional consequences, we generated isogenic induced pluripotent cell lines (iPSCs) carrying the CTBP1 mutation in heterozygous and homozygous conditions using the CRISPR/Cas9 editing method. The transcriptional profile of iPSC-derived early neurons from the isogenic wild type and CTBP1 heterozygous and homozygous mutants was determined by genome-wide RNA sequencing. The RNA-Seq data revealed downregulation of several key transcription factors, with homozygous mutations causing more pronounced downregulation compared to heterozygous mutations. Isogenic mutant neural stem cells (NSCs) exhibited reduced adhesion and migration, along with dysregulated calcium signaling, while mutant neurons showed premature neurite outgrowth. Together, our transcriptomic and biological results provide novel insights into the role and mechanism of CTBP1 p.R342W mutation in the defective neurodevelopmental processes.",
      "author": "Uthayashanker R. Ezekiel",
      "published_date": "2025-12-12T00:00:00+00:00",
      "source": "Frontiers Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 169,
      "reading_time": 1,
      "created_at": "2025-12-12T06:35:09.755589+00:00",
      "updated_at": "2025-12-12T06:35:09.755591+00:00"
    },
    {
      "id": "4934ca990bfd879c0bf9b06da408137c",
      "url": "https://www.frontiersin.org/articles/10.3389/fnins.2025.1720978",
      "title": "Central auditory processing is altered after traumatic brain injury in Tanzanian adults",
      "content": "Traumatic brain injury (TBI) damages pathways throughout the brain and is a significant global health concern, particularly in low- and middle-income countries, where the incidence is high and long-term deficits are prevalent. This study explores the utility of central auditory processing (CAP) testing as a marker of previous TBI. Seventy individuals with a history of moderate to severe TBI (msTBI) were matched by age and sex to 46 healthy controls in Dar es Salaam, Tanzania. Participants underwent comprehensive behavioral CAP testing, including tests of speech-in-noise ability, temporal resolution, and dichotic listening. Multivariate logistic regression showed the Triple Digit Test (TDT) (p\u202f<\u202f0.001) significantly predicted msTBI status, independent of age and peripheral hearing ability. Elastic net modeling supported these findings, highlighting TDT performance as the most robust predictor of msTBI history. A history of msTBI is associated with poorer CAP performance, particularly on speech-in-noise tests. These tests could serve as accessible, resource-efficient tools for assessing brain function related to TBI in clinical and resource-limited settings. Studies in larger, more diverse populations are needed to explore their predictive utility for long-term cognitive outcomes after TBI.",
      "author": "Jay C. Buckey",
      "published_date": "2025-12-12T00:00:00+00:00",
      "source": "Frontiers Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 184,
      "reading_time": 1,
      "created_at": "2025-12-12T06:35:09.755552+00:00",
      "updated_at": "2025-12-12T06:35:09.755554+00:00"
    },
    {
      "id": "a0023bf2cca42abb4cce3cc0c8c9705a",
      "url": "https://www.frontiersin.org/articles/10.3389/fnins.2025.1720961",
      "title": "The interaction of regulated forms of cell death in the pathogenesis of severe facial paralysis and potential therapeutic strategies",
      "content": "Neuronal cell death plays a central role in the pathogenesis of facial paralysis. In the constructed severe facial paralysis model, axonal damage becomes the key factor triggering retrograde neuronal degeneration, resulting in a large number of neuronal deaths, which seriously affects the function of the facial nerve. The basic fibroblast growth factor exhibits strong neuroprotective ability and can significantly reduce the neuronal mortality rate, providing a strong guarantee for neuronal survival. Viral infection is also an important pathogenic factor that cannot be ignored. Viruses such as herpes simplex virus type 1 can trigger neuroinflammation through the immune response, further exacerbating nerve damage. However, recent studies have also brought hope. Neural reconstruction techniques, targeted drugs, and stem cell therapies hold potential value in promoting the recovery of damaged neural functions. These research results reveal that multiple factors affect the survival and function of neurons in facial paralysis through different pathways, laying a theoretical foundation for targeted treatment against neuronal death. In the future, based on these mechanisms, developing new therapies will bring new treatment opportunities for patients with severe facial paralysis, potentially improving their prognosis and significantly enhancing their quality of life, with important clinical value.",
      "author": "Jicheng Zhang",
      "published_date": "2025-12-12T00:00:00+00:00",
      "source": "Frontiers Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 195,
      "reading_time": 1,
      "created_at": "2025-12-12T06:35:09.755502+00:00",
      "updated_at": "2025-12-12T06:35:09.755507+00:00"
    },
    {
      "id": "bea71b1842764aad20b841c7ea675f62",
      "url": "https://www.reddit.com/r/Python/comments/1pkk4ff/democratizing_python_a_transpiler_for_nonenglish/",
      "title": "Democratizing Python: a transpiler for non\u2011English communities (and for kids)",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>A few months ago, an 11\u2011year\u2011old in my family asked me what I do for work. I explained programming, and he immediately wanted to try it. But Python is full of English keywords, which makes it harder for kids who don\u2019t speak English yet.</p> <p>So I built <strong>multilang-python</strong>: a small transpiler that lets you write Python in your own language (French, German, Spanish\u2026 even local languages like Arabic, Ewe, Mina and so on). It then translates everything back into normal Python and runs.</p> <pre><code># multilang-python: fr fonction calculer_mon_age(annee_naissance): age = 2025 - annee_naissance retourner age annee = saisir(&quot;Entrez votre ann\u00e9e de naissance : &quot;) age = calculer_mon_age(entier(annee)) afficher(f&quot;Vous avez {age} ans.&quot;) </code></pre> <p>becomes standard Python with <code>def</code>, <code>return</code>, <code>input</code>, <code>print</code>.</p> <p>\ud83c\udfaf Goal: make coding more accessible for kids and beginners who don\u2019t speak English.</p> <p>Repo: <a href=\"https://github.com/fless-lab/multilang-python\">multilang-python</a></p> <p>Note : You can add your own dialect if you want...</p> <p>How do u think this can help in your community ?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Accomplished-Land820\"> /u/Accomplished-Land820 </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1pkk4ff/democratizing_python_a_transpiler_for_nonenglish/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1pkk4ff/democratizing_python_a_transpiler_for_nonenglish/\">[comments]</a></span>",
      "author": "/u/Accomplished-Land820",
      "published_date": "2025-12-12T05:40:42+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 180,
      "reading_time": 1,
      "created_at": "2025-12-12T06:34:43.928983+00:00",
      "updated_at": "2025-12-12T06:34:43.928984+00:00"
    },
    {
      "id": "073f338769e5d005035bc6326b83a6e7",
      "url": "https://www.washingtonpost.com/lifestyle/2025/12/05/karl-bushby-walk-around-world/",
      "title": "He set out to walk around the world. After 27 years, his quest is nearly over",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46182874\">Comments</a>",
      "author": "",
      "published_date": "2025-12-07T16:26:45+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-12T06:34:42.654933+00:00",
      "updated_at": "2025-12-12T06:34:42.654934+00:00"
    },
    {
      "id": "0adbf76a60a38e99e1fe333e7ad9a143",
      "url": "https://www.danieleteti.it/post/html-first-frameworks-htmx-revolution-en/#building-with-html-instead-of-fighting-with-javascript-layers-",
      "title": "The HTML-First Approach: Why Htmx and Lightweight Frameworks Are Revolutionizin",
      "content": "<p>Article URL: <a href=\"https://www.danieleteti.it/post/html-first-frameworks-htmx-revolution-en/#building-with-html-instead-of-fighting-with-javascript-layers-\">https://www.danieleteti.it/post/html-first-frameworks-htmx-revolution-en/#building-with-html-instead-of-fighting-with-javascript-layers-</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46239445\">https://news.ycombinator.com/item?id=46239445</a></p>\n<p>Points: 10</p>\n<p># Comments: 0</p>",
      "author": "todsacerdoti",
      "published_date": "2025-12-12T00:37:42+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-12T05:46:13.534540+00:00",
      "updated_at": "2025-12-12T06:26:09.044074+00:00",
      "metadata": {
        "processed_at": "2025-12-12T06:26:09.044083+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "5e148265dd0f3ead7b90275271106ab2",
      "url": "https://arxiv.org/abs/2512.10110",
      "title": "Generate-Then-Validate: A Novel Question Generation Approach Using Small Language Models",
      "content": "arXiv:2512.10110v1 Announce Type: cross \nAbstract: We explore the use of small language models (SLMs) for automatic question generation as a complement to the prevalent use of their large counterparts in learning analytics research. We present a novel question generation pipeline that leverages both the text generation and the probabilistic reasoning abilities of SLMs to generate high-quality questions. Adopting a \"generate-then-validate\" strategy, our pipeline first performs expansive generation to create an abundance of candidate questions and refine them through selective validation based on novel probabilistic reasoning. We conducted two evaluation studies, one with seven human experts and the other with a large language model (LLM), to assess the quality of the generated questions. Most judges (humans or LLMs) agreed that the generated questions had clear answers and generally aligned well with the intended learning objectives. Our findings suggest that an SLM can effectively generate high-quality questions when guided by a well-designed pipeline that leverages its strengths.",
      "author": "Yumou Wei, John Stamper, Paulo F. Carvalho",
      "published_date": "2025-12-12T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 155,
      "reading_time": 1,
      "created_at": "2025-12-12T05:24:15.356971+00:00",
      "updated_at": "2025-12-12T06:26:09.044088+00:00",
      "metadata": {
        "processed_at": "2025-12-12T06:26:09.044090+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "637fe6fb1dfe3cd73e15fa20257e4084",
      "url": "https://arxiv.org/abs/2512.10065",
      "title": "Linear socio-demographic representations emerge in Large Language Models from indirect cues",
      "content": "arXiv:2512.10065v1 Announce Type: cross \nAbstract: We investigate how LLMs encode sociodemographic attributes of human conversational partners inferred from indirect cues such as names and occupations. We show that LLMs develop linear representations of user demographics within activation space, wherein stereotypically associated attributes are encoded along interpretable geometric directions. We first probe residual streams across layers of four open transformer-based LLMs (Magistral 24B, Qwen3 14B, GPT-OSS 20B, OLMo2-1B) prompted with explicit demographic disclosure. We show that the same probes predict demographics from implicit cues: names activate census-aligned gender and race representations, while occupations trigger representations correlated with real-world workforce statistics. These linear representations allow us to explain demographic inferences implicitly formed by LLMs during conversation. We demonstrate that these implicit demographic representations actively shape downstream behavior, such as career recommendations. Our study further highlights that models that pass bias benchmark tests may still harbor and leverage implicit biases, with implications for fairness when applied at scale.",
      "author": "Paul Bouchaud, Pedro Ramaciotti",
      "published_date": "2025-12-12T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 155,
      "reading_time": 1,
      "created_at": "2025-12-12T05:24:15.356942+00:00",
      "updated_at": "2025-12-12T06:26:09.044092+00:00",
      "metadata": {
        "processed_at": "2025-12-12T06:26:09.044094+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "34304dc9d156c05cfd5da8ddae14b0d2",
      "url": "https://arxiv.org/abs/2512.10058",
      "title": "Mind the Gap! Pathways Towards Unifying AI Safety and Ethics Research",
      "content": "arXiv:2512.10058v1 Announce Type: cross \nAbstract: While much research in artificial intelligence (AI) has focused on scaling capabilities, the accelerating pace of development makes countervailing work on producing harmless, \"aligned\" systems increasingly urgent. Yet research on alignment has diverged along two largely parallel tracks: safety--centered on scaled intelligence, deceptive or scheming behaviors, and existential risk--and ethics--focused on present harms, the reproduction of social bias, and flaws in production pipelines. Although both communities warn of insufficient investment in alignment, they disagree on what alignment means or ought to mean. As a result, their efforts have evolved in relative isolation, shaped by distinct methodologies, institutional homes, and disciplinary genealogies.\n  We present a large-scale, quantitative study showing the structural split between AI safety and AI ethics. Using a bibliometric and co-authorship network analysis of 6,442 papers from twelve major ML and NLP conferences (2020-2025), we find that over 80% of collaborations occur within either the safety or ethics communities, and cross-field connectivity is highly concentrated: roughly 5% of papers account for more than 85% of bridging links. Removing a small number of these brokers sharply increases segregation, indicating that cross-disciplinary exchange depends on a handful of actors rather than broad, distributed collaboration. These results show that the safety-ethics divide is not only conceptual but institutional, with implications for research agendas, policy, and venues. We argue that integrating technical safety work with normative ethics--via shared benchmarks, cross-institutional venues, and mixed-method methodologies--is essential for building AI systems that are both robust and just.",
      "author": "Dani Roytburg, Beck Miller",
      "published_date": "2025-12-12T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 247,
      "reading_time": 1,
      "created_at": "2025-12-12T05:24:15.356913+00:00",
      "updated_at": "2025-12-12T06:26:09.044096+00:00",
      "metadata": {
        "processed_at": "2025-12-12T06:26:09.044098+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "f60ee20cca667440802aac5f2786980b",
      "url": "https://arxiv.org/abs/2512.09932",
      "title": "Suzume-chan: Your Personal Navigator as an Embodied Information Hub",
      "content": "arXiv:2512.09932v1 Announce Type: cross \nAbstract: Access to expert knowledge often requires real-time human communication. Digital tools improve access to information but rarely create the sense of connection needed for deep understanding. This study addresses this issue using Social Presence Theory, which explains how a feeling of \"being together\" enhances communication. An \"Embodied Information Hub\" is proposed as a new way to share knowledge through physical and conversational interaction. The prototype, Suzume-chan, is a small, soft AI agent running locally with a language model and retrieval-augmented generation (RAG). It learns from spoken explanations and responds through dialogue, reducing psychological distance and making knowledge sharing warmer and more human-centered.",
      "author": "Maya Grace Torii, Takahito Murakami, Shuka Koseki, Yoichi Ochiai",
      "published_date": "2025-12-12T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 107,
      "reading_time": 1,
      "created_at": "2025-12-12T05:24:15.356875+00:00",
      "updated_at": "2025-12-12T06:26:09.044100+00:00",
      "metadata": {
        "processed_at": "2025-12-12T06:26:09.044102+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "246648cffd19dac9d5a8c65ec237eb29",
      "url": "https://arxiv.org/abs/2512.09931",
      "title": "ExaCraft: Dynamic Learning Context Adaptation for Personalized Educational Examples",
      "content": "arXiv:2512.09931v1 Announce Type: cross \nAbstract: Learning is most effective when it's connected to relevant, relatable examples that resonate with learners on a personal level. However, existing educational AI tools don't focus on generating examples or adapting to learners' changing understanding, struggles, or growing skills. We've developed ExaCraft, an AI system that generates personalized examples by adapting to the learner's dynamic context. Through the Google Gemini AI and Python Flask API, accessible via a Chrome extension, ExaCraft combines user-defined profiles (including location, education, profession, and complexity preferences) with real-time analysis of learner behavior. This ensures examples are both culturally relevant and tailored to individual learning needs. The system's core innovation is its ability to adapt to five key aspects of the learning context: indicators of struggle, mastery patterns, topic progression history, session boundaries, and learning progression signals. Our demonstration will show how ExaCraft's examples evolve from basic concepts to advanced technical implementations, responding to topic repetition, regeneration requests, and topic progression patterns in different use cases.",
      "author": "Akaash Chatterjee (Indian Institute of Technology Jodhpur), Suman Kundu (Indian Institute of Technology Jodhpur)",
      "published_date": "2025-12-12T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 165,
      "reading_time": 1,
      "created_at": "2025-12-12T05:24:15.356848+00:00",
      "updated_at": "2025-12-12T05:24:15.356850+00:00"
    },
    {
      "id": "b2f67bf2bd4bdcb2db92ee9f2f6c94ae",
      "url": "https://arxiv.org/abs/2512.10918",
      "title": "CompanionCast: A Multi-Agent Conversational AI Framework with Spatial Audio for Social Co-Viewing Experiences",
      "content": "arXiv:2512.10918v1 Announce Type: new \nAbstract: Social presence is central to the enjoyment of watching content together, yet modern media consumption is increasingly solitary. We investigate whether multi-agent conversational AI systems can recreate the dynamics of shared viewing experiences across diverse content types. We present CompanionCast, a general framework for orchestrating multiple role-specialized AI agents that respond to video content using multimodal inputs, speech synthesis, and spatial audio. Distinctly, CompanionCast integrates an LLM-as-a-Judge module that iteratively scores and refines conversations across five dimensions (relevance, authenticity, engagement, diversity, personality consistency). We validate this framework through sports viewing, a domain with rich dynamics and strong social traditions, where a pilot study with soccer fans suggests that multi-agent interaction improves perceived social presence compared to solo viewing. We contribute: (1) a generalizable framework for orchestrating multi-agent conversations around multimodal video content, (2) a novel evaluator-agent pipeline for conversation quality control, and (3) exploratory evidence of increased social presence in AI-mediated co-viewing. We discuss challenges and future directions for applying this approach to diverse viewing contexts including entertainment, education, and collaborative watching experiences.",
      "author": "Yiyang Wang, Chen Chen, Tica Lin, Vishnu Raj, Josh Kimball, Alex Cabral, Josiah Hester",
      "published_date": "2025-12-12T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 178,
      "reading_time": 1,
      "created_at": "2025-12-12T05:24:15.356818+00:00",
      "updated_at": "2025-12-12T05:24:15.356819+00:00"
    },
    {
      "id": "93276278ba05c7e2b111e6049e86ccfa",
      "url": "https://arxiv.org/abs/2512.10257",
      "title": "Reject or Not?: A Benchmark for Voice Assistant Query Rejection in Smart Home Scenario and an Improved Method Based on LLMs",
      "content": "arXiv:2512.10257v1 Announce Type: new \nAbstract: In smart-home voice assistant scenario, deciding whether to accept or reject a user query is the first step before any downstream processing. To address the limited query-rejection capability of current voice assistants, this paper presents the first Chinese-oriented open-source benchmark and evaluation suite for smart homes, together with a personalized query-rejection method based on large language models. On the data side, we construct the first multimodal query-rejection dataset tailored for domestic scenarios, containing 11,913 manually labeled text-speech pairs that systematically cover twelve typical dialogue types (e.g., chit-chat, non-human sounds, valid commands, ambiguous references, device-irrelevant requests). Fine-grained labels, conversational context and multi-turn information are provided to support both zero-shot and fine-tuning evaluations across language and multimodal large models. On the method side, we propose a three-tier collaborative architecture: first, a Qwen-2.5-3B adapter fine-tuned to model family-agnostic semantic boundaries; second, a dynamic household-level historical dialogue module to capture personalized habits; third, a household-specific RAG knowledge base that explicitly memorizes and revises past false-rejection cases. Experiments show that the proposed approach significantly outperforms zero-shot and fine-tuned general LLMs on the constructed dataset, with pronounced gains in rejection accuracy for family-specific expressions and complex multi-turn scenarios. This work provides a reproducible data foundation, evaluation standard and extensible technical framework for reliability research in smart-home voice interaction.",
      "author": "Huichao Men, Yizhen Hu, Yingyang He, Yu Gao, Xiaofeng Mou, Yi Xu",
      "published_date": "2025-12-12T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 217,
      "reading_time": 1,
      "created_at": "2025-12-12T05:24:15.356785+00:00",
      "updated_at": "2025-12-12T05:24:15.356787+00:00"
    },
    {
      "id": "572d170170bf86e9aea3b2f7de3ced85",
      "url": "https://arxiv.org/abs/2512.10234",
      "title": "InFerActive: Towards Scalable Human Evaluation of Large Language Models through Interactive Inference",
      "content": "arXiv:2512.10234v1 Announce Type: new \nAbstract: Human evaluation remains the gold standard for evaluating outputs of Large Language Models (LLMs). The current evaluation paradigm reviews numerous individual responses, leading to significant scalability challenges. LLM outputs can be more efficiently represented as a tree structure, reflecting their autoregressive generation process and stochastic token selection. However, conventional tree visualization cannot scale to the exponentially large trees generated by modern sampling methods of LLMs. To address this problem, we present InFerActive, an interactive inference system for scalable human evaluation. InFerActive enables on-demand exploration through probability-based filtering and evaluation features, while bridging the semantic gap between computational tokens and human-readable text through adaptive visualization techniques. Through a technical evaluation and user study (N=12), we demonstrate that InFerActive significantly improves evaluation efficiency and enables more comprehensive assessment of model behavior. We further conduct expert case studies that demonstrate InFerActive's practical applicability and potential for transforming LLM evaluation workflows.",
      "author": "Junhyeong Hwangbo, Soohyun Lee, Minsoo Cheong, Hyeon Jeon, Jinwook Seo",
      "published_date": "2025-12-12T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 152,
      "reading_time": 1,
      "created_at": "2025-12-12T05:24:15.356745+00:00",
      "updated_at": "2025-12-12T05:24:15.356747+00:00"
    },
    {
      "id": "5c8db1c2419d80b9f1dcbc61291c4875",
      "url": "https://arxiv.org/abs/2512.10196",
      "title": "HyFinBall: a Hybrid User Interface for Coordinated 2D+3D Visualization in Semi-Immersive VR",
      "content": "arXiv:2512.10196v1 Announce Type: new \nAbstract: Sophisticated 3D visualization applications usually provide coordinated 2D and 3D views. Normally 3D input device is used for 3D tasks since they perform better than traditional 2D input devices. However, they do not perform better for 2D tasks. This paper presents a bimanual hybrid user interface that supports four interaction modes: a dual 6-degree-of-freedom (DOF) input device mode, a dual planar constrained 3DOF input device mode, a dual 2-finger multi-touch mode, and 3D hand and finger gestures. The application is a multi-dimensional visualization with coordinated 3D and 2D views on a desktop VR system. The input devices are buttonballs with seamless switching between 3D and 2D device modes, as well as between free-hand finger input and device usage. The 3D and 2D device mode switch automatically switches a buttonball's visual representation between a 3D cursor and a 2D cursor while changing the available user interaction techniques between 3D and 2D interaction techniques to interact with the coordinated views. The paper also provides two formal user studies to evaluate HyFinBall for various dimensional tasks, including 3D, 2D, and cross-dimensional tasks. Our experimental results show the benefits of the HyFinBall interface for cross-dimensional tasks that require 3D and 2D interactions.",
      "author": "Isaac Cho, Zachary Wartell",
      "published_date": "2025-12-12T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 203,
      "reading_time": 1,
      "created_at": "2025-12-12T05:24:15.356714+00:00",
      "updated_at": "2025-12-12T05:24:15.356716+00:00"
    },
    {
      "id": "c69bcb50d68d8be4e0dac001c144f3d6",
      "url": "https://arxiv.org/abs/2512.10172",
      "title": "Offscript: Automated Auditing of Instruction Adherence in LLMs",
      "content": "arXiv:2512.10172v1 Announce Type: new \nAbstract: Large Language Models (LLMs) and generative search systems are increasingly used for information seeking by diverse populations with varying preferences for knowledge sourcing and presentation. While users can customize LLM behavior through custom instructions and behavioral prompts, no mechanism exists to evaluate whether these instructions are being followed effectively. We present Offscript, an automated auditing tool that efficiently identifies potential instruction following failures in LLMs. In a pilot study analyzing custom instructions sourced from Reddit, Offscript detected potential deviations from instructed behavior in 86.4% of conversations, 22.2% of which were confirmed as material violations through human review. Our findings suggest that automated auditing serves as a viable approach for evaluating compliance to behavioral instructions related to information seeking.",
      "author": "Nicholas Clark, Ryan Bai, Tanu Mitra",
      "published_date": "2025-12-12T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 123,
      "reading_time": 1,
      "created_at": "2025-12-12T05:24:15.356672+00:00",
      "updated_at": "2025-12-12T05:24:15.356678+00:00"
    },
    {
      "id": "bafd3e4b8432b24bbc745812beb5ada4",
      "url": "https://arxiv.org/abs/2507.01098",
      "title": "Proof of a perfect platonic representation hypothesis",
      "content": "arXiv:2507.01098v2 Announce Type: replace-cross \nAbstract: In this note, we elaborate on and explain in detail the proof given by Ziyin et al. (2025) of the ``perfect\" Platonic Representation Hypothesis (PRH) for the embedded deep linear network model (EDLN). We show that if trained with the stochastic gradient descent (SGD), two EDLNs with different widths and depths and trained on different data will become Perfectly Platonic, meaning that every possible pair of layers will learn the same representation up to a rotation. Because most of the global minima of the loss function are not Platonic, that SGD only finds the perfectly Platonic solution is rather extraordinary. The proof also suggests at least six ways the PRH can be broken. We also show that in the EDLN model, the emergence of the Platonic representations is due to the same reason as the emergence of progressive sharpening. This implies that these two seemingly unrelated phenomena in deep learning can, surprisingly, have a common cause. Overall, the theory and proof highlight the importance of understanding emergent \"entropic forces\" due to the irreversibility of SGD training and their role in representation learning. The goal of this note is to be instructive while avoiding jargon and lengthy technical details.",
      "author": "Liu Ziyin, Isaac Chuang",
      "published_date": "2025-12-12T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 203,
      "reading_time": 1,
      "created_at": "2025-12-12T05:24:14.152299+00:00",
      "updated_at": "2025-12-12T05:24:14.152301+00:00"
    }
  ]
}