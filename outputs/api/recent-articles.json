{
  "last_updated": "2025-12-30T03:31:01.605630+00:00",
  "count": 20,
  "articles": [
    {
      "id": "bbe0f805e4fabfb0ac2476417484aef4",
      "url": "http://ieeexplore.ieee.org/document/10946856",
      "title": "Enhancing Video Experiences for DHH Individuals Through Sound-Inspired Motion Caption-Based Spatiotemporal Tacton",
      "content": "When deaf and hard of hearing (DHH) individuals watch videos, captions are essential for them to understand the linguistic content. Current captions, however, are not suitable for conveying non-verbal sound information, such as background music, sound effects, or speech nuances. In this paper, we designed a multimodal system, Motion Caption Haptic System (MCHS), that enables DHH individuals to encounter sounds in videos through animated caption and spatiotemporal vibration patterns, supporting a more vivid and immersive experience. We elaborately designed motion captions and spatiotemporal haptic patterns for representative sound effects and spoken emotions to work well together through surveys from 27 DHH and 64 hearing participants. An evaluation with 19 DHH individuals demonstrated the capabilities and potential of the MCHS to improve their video viewing experience, along with a discussion of important issues that need to be addressed when designing multimodal captioning systems for the DHH viewers.",
      "author": "",
      "published_date": "2025-04-01T13:17:18+00:00",
      "source": "Transactions Haptics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 146,
      "reading_time": 1,
      "created_at": "2025-12-30T03:30:48.907447+00:00",
      "updated_at": "2025-12-30T03:30:48.907449+00:00"
    },
    {
      "id": "609521b013e1243f77b1eaa5e01eab3e",
      "url": "http://ieeexplore.ieee.org/document/10965524",
      "title": "VibTac: A High-Resolution High-Bandwidth Tactile Sensing Finger for Multi-Modal Perception in Robotic Manipulation",
      "content": "Tactile sensing is pivotal for enhancing robot manipulation abilities by providing crucial feedback for localized information. However, existing sensors often lack the necessary resolution and bandwidth required for intricate tasks. To address this gap, we introduce VibTac, a novel multi-modal tactile sensing finger designed to offer high-resolution and high-bandwidth tactile sensing simultaneously. VibTac seamlessly integrates vision-based and vibration-based tactile sensing modes to achieve high-resolution and high-bandwidth tactile sensing respectively, leveraging a streamlined human-inspired design for versatility in tasks. This paper outlines the key design elements of VibTac and its fabrication methods, highlighting the significance of the Elastomer Gel Pad (EGP) in its sensing mechanism. The sensor's multi-modal performance is validated through 3D reconstruction and spectral analysis to discern tactile stimuli effectively. In experimental trials, VibTac demonstrates its efficacy by achieving over 90% accuracy in insertion tasks involving objects emitting distinct sounds, such as ethernet connectors. Leveraging vision-based tactile sensing for object localization and employing a deep learning model for \u201cclick\u201d sound classification, VibTac showcases its robustness in real-world scenarios.",
      "author": "",
      "published_date": "2025-04-15T13:16:45+00:00",
      "source": "Transactions Haptics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 169,
      "reading_time": 1,
      "created_at": "2025-12-30T03:30:48.907417+00:00",
      "updated_at": "2025-12-30T03:30:48.907418+00:00"
    },
    {
      "id": "6e5289b1927a2560a61773b58736ef16",
      "url": "http://ieeexplore.ieee.org/document/10955171",
      "title": "Age-Related Impact in Illusory Torque Cues Induced by Asymmetric Vibrations",
      "content": "Illusory pulling sensations in the translational or rotational direction are induced by asymmetric vibrations applied to the fingertips. Although previous studies have discussed the involvement of mechanoreceptors associated with skin deformation and spatial processing in the parietal association cortex in the generation of illusory cues, the precise mechanism underlying this phenomenon remains unclear. In this study, we aimed to indirectly estimate the contribution of mechanoreceptors to the perception of illusory pulling torque cues by examining the relationship between vibration thresholds and the properties of these illusions, leveraging the known decline in cutaneous sensation sensitivity associated with aging (N = 40). Our results revealed an age-related increase in vibration thresholds, which is consistent with previous research. While male participants showed consistent sensitivity to illusory pulling cues across age groups, female participants exhibited a decline in sensitivity with age. Moreover, we observed only weak or no correlations between the vibration thresholds and the sensitivity of the illusory pulling cue. Although we were unable to identify any findings that explain the contribution of mechanoreceptors, we discovered a gender difference in the sensitivity to induced illusions among older individuals. These findings offer valuable insights for elucidating the mechanism underlying the illusion.",
      "author": "",
      "published_date": "2025-04-07T13:17:32+00:00",
      "source": "Transactions Haptics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 197,
      "reading_time": 1,
      "created_at": "2025-12-30T03:30:48.907380+00:00",
      "updated_at": "2025-12-30T03:30:48.907382+00:00"
    },
    {
      "id": "7cd5915b404adde9692f79fbf455044d",
      "url": "http://ieeexplore.ieee.org/document/11037651",
      "title": "A Force/Torque Taxonomy for Classifying States During Physical Co-Manipulation",
      "content": "Achieving seamless human-robot collaboration requires a deeper understanding of how agents manage and communicate forces during shared tasks. Force interactions during collaborative manipulation are inherently complex, especially when considering how they evolve over time. To address this complexity, we propose a taxonomy of decomposed force and torque components, providing a structured framework for examining haptic communication and informing the development of robots capable of performing meaningful collaborative manipulation tasks with human partners. We propose a standardized terminology for force decomposition and classification, bridging the varied language in previous literature in the field, and conduct a review of physical human-human interaction and haptic communication. The proposed taxonomy allows for a more effective and nuanced discussion of important force combinations that we expect to occur during collaborative manipulation (between human-human or human-robot teams). We also include example scenarios to illustrate the value of the proposed taxonomy in describing interactions between agents.",
      "author": "",
      "published_date": "2025-06-17T13:16:38+00:00",
      "source": "Transactions Haptics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 149,
      "reading_time": 1,
      "created_at": "2025-12-30T03:30:48.907341+00:00",
      "updated_at": "2025-12-30T03:30:48.907343+00:00"
    },
    {
      "id": "bffad7ff78c038ce61497f8206575f26",
      "url": "http://ieeexplore.ieee.org/document/11045422",
      "title": "Haptic Relocation Away From the Fingertip: Where, Why, and How",
      "content": "Tactile haptic devices are often designed to render meaningful, complex, and realistic touch-based information on users\u2019 skin. While fingertips and hands are the most preferred body locations to render haptic feedback, recent trends allow such feedback to be extended to alternative body locations (e.g., wrist, arm, torso, foot) for various scenarios due to reasons such as wearability and needs of the application. In this paper, I address the new concept of haptic relocation. It refers to scenarios in which the expected feedback is related to the fingertips but rendered on a different body location instead \u2013 e.g., contact forces registered by two robotic fingers during teleoperation rendered to the users\u2019 wrist instead of the fingers. I investigated the design choices of wearable haptic devices for haptic relocation concerning different body locations, targeted applications, and actuator selection. I discuss approaches and design choices from the literature by speculating on the possible reasons, and conclude the paper by highlighting some challenges and issues to be mindful of in the future. This paper will guide engineers and researchers in searching for alternative haptic rendering solutions \u2013 especially when fingers and hands are not available for haptic interaction.",
      "author": "",
      "published_date": "2025-06-20T13:16:43+00:00",
      "source": "Transactions Haptics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 194,
      "reading_time": 1,
      "created_at": "2025-12-30T03:30:48.907293+00:00",
      "updated_at": "2025-12-30T03:30:48.907295+00:00"
    },
    {
      "id": "654c67a50800e0d8df1eb841fa063ae1",
      "url": "http://ieeexplore.ieee.org/document/10918829",
      "title": "Tactile\u2013Thermal Interactions: Cooperation and Competition",
      "content": "This review focuses on the interactions between the cutaneous senses, and in particular touch and temperature, as these are the most relevant for developing skin-based display technologies for use in virtual reality (VR) and for designing multimodal haptic devices. A broad spectrum of research is reviewed ranging from studies that have examined the mechanisms involved in thermal intensification and tactile masking, to more applied work that has focused on implementing thermal-tactile illusions such as thermal referral and illusory wetness in VR environments. Research on these tactile-thermal illusions has identified the differences between the senses of cold and warmth in terms of their effects on the perception of object properties and the prevalence of the perceptual experiences elicited. They have also underscored the fundamental spatial and temporal differences between the tactile and thermal senses. The wide-ranging body of research on compound sensations such as wetness and stickiness has highlighted the mechanisms involved in sensing moisture and provided a framework for measuring these sensations in a variety of contexts. Although the interactions between the two senses are complex, it is clear that the addition of thermal inputs to a tactile display enhances both user experience and enables novel sensory experiences.",
      "author": "",
      "published_date": "2025-03-10T13:16:41+00:00",
      "source": "Transactions Haptics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 198,
      "reading_time": 1,
      "created_at": "2025-12-30T03:30:48.907251+00:00",
      "updated_at": "2025-12-30T03:30:48.907253+00:00"
    },
    {
      "id": "604cffaea5736d8c2935253598862e29",
      "url": "http://ieeexplore.ieee.org/document/11174044",
      "title": "Twenty Years of World Haptics: Retrospective and Future Directions",
      "content": "null",
      "author": "",
      "published_date": "2025-09-19T13:16:57+00:00",
      "source": "Transactions Haptics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 1,
      "reading_time": 1,
      "created_at": "2025-12-30T03:30:48.907208+00:00",
      "updated_at": "2025-12-30T03:30:48.907210+00:00"
    },
    {
      "id": "460944d48a0336e2f9e40b05044f1888",
      "url": "https://www.nature.com/articles/s41598-025-28193-1",
      "title": "Depth perception changes following adaptation to cue-dependent invariants",
      "content": "",
      "author": "",
      "published_date": "2025-12-30T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-12-30T03:30:29.178923+00:00",
      "updated_at": "2025-12-30T03:30:29.178927+00:00"
    },
    {
      "id": "5869c13d78dee7f7112e8c8a15c53ea3",
      "url": "https://www.nature.com/articles/s41593-025-02186-9",
      "title": "Psychedelic research must be grounded in pharmacology",
      "content": "<p>Nature Neuroscience, Published online: 24 December 2025; <a href=\"https://www.nature.com/articles/s41593-025-02186-9\">doi:10.1038/s41593-025-02186-9</a></p>Psychedelic science is growing rapidly and offers great promise for exciting new therapies, but this rapid growth has brought growing pains. These include a lack of appreciation of the history of the field and what has already been accomplished, and a lack of understanding of the pharmacology of psychedelics and 5-HT2A receptors. These gaps must be recognized, acknowledged and addressed in order for the field to advance responsibly.",
      "author": "Charles D. Nichols",
      "published_date": "2025-12-24T00:00:00+00:00",
      "source": "Nature Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 76,
      "reading_time": 1,
      "created_at": "2025-12-30T03:30:27.248556+00:00",
      "updated_at": "2025-12-30T03:30:27.248557+00:00"
    },
    {
      "id": "fb829df1116d9f752289fa772234a4ee",
      "url": "https://iopscience.iop.org/article/10.1088/1741-2552/ae2715",
      "title": "Medtronic Percept\u2122 recorded LFP pre-processing to remove noise and cardiac signals from neural recordings",
      "content": "Chronic brain sensing devices, such as the Medtronic Percept\u2122 or Neuropace RNS system, record local field potentials (LFPs) that may be vulnerable to interference and noise due to hardware limitations, environmental factors, movement, stimulation, cardiac signals, and analytical procedures. Although onboard hardware filters can attenuate some unwanted signals, additional processing is often required. Here we demonstrate that cardiac artifacts significantly alter the power spectral density (PSD) of neural activity within the theta (4\u20138 Hz), alpha (8\u201312 Hz), and beta (12\u201330 Hz) bands. We introduce a time-domain template subtraction method specifically designed to remove QRS complex cardiac artifacts. Separately, we describe techniques for transforming time domain data to the frequency domain and mitigating transient artifacts by estimating background neural activity\u2014either through window rejection based on PSD characteristics or via principal component analysis. Finally, we present an approach to isolate oscillatory neural activity by subtracting the aperiodic 1/f component from the power spectrum by fitting the fitting oscillations and one over F logarithmic function. While filter selection must be tailored to the specific device and participant environment to avoid over-filtering, these interference and noise mitigation strategies are crucial for ensuring the integrity of LFP recordings.",
      "author": "Zachary T Sanger, Steffen Ventz, Robert A McGovern III and Theoden I Netoff",
      "published_date": "2025-12-24T00:00:00+00:00",
      "source": "Journal Neural Engineering",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 193,
      "reading_time": 1,
      "created_at": "2025-12-30T03:30:08.782306+00:00",
      "updated_at": "2025-12-30T03:30:08.782308+00:00"
    },
    {
      "id": "a8c2d5cb04d96aaadc48d2adf196f678",
      "url": "https://fmhy.net/posts/FCC",
      "title": "Fight Chat Control \ud83d\udd12",
      "content": "<h3 id=\"the-eu-still-wants-to-scan-your-private-messages-and-photos\" tabindex=\"-1\">The EU (still) wants to scan your private messages and photos. <a class=\"header-anchor\" href=\"#the-eu-still-wants-to-scan-your-private-messages-and-photos\"></a></h3>\n<p>The &quot;Chat Control&quot; proposal would mandate scanning of all private digital communications, including encrypted messages and photos. This threatens fundamental privacy rights and digital security for all EU citizens.</p>\n<p>Every photo, every message, every file you send will be automatically scanned\u2014without your consent or suspicion. This is not about catching criminals. It is <em><strong>mass surveillance</strong></em> imposed on all 450 million citizens of the European Union.</p>\n<p>EU politicians <em>exempt themselves</em> from this surveillance under &quot;professional secrecy&quot; rules. They get privacy. You and your family do not. If you're in the EU, please consider contacting Members of the European Parliament (MEPs) using the info provided on the site below:</p>\n<h1 id=\"https-fightchatcontrol-eu\" tabindex=\"-1\"><a href=\"https://fightchatcontrol.eu/\" rel=\"noreferrer\" target=\"_blank\">https://fightchatcontrol.eu/</a> <a class=\"header-anchor\" href=\"#https-fightchatcontrol-eu\"></a></h1>\n<p>There is also a change.org petition <a href=\"https://stopchatcontrol.eu/\" rel=\"noreferrer\" target=\"_blank\">here</a> if you'd like to sign it.</p>\n<p>Discussion: <a href=\"https://redd.it/1n840p9\" rel=\"noreferrer\" target=\"_blank\">https://redd.it/1n840p9</a></p>",
      "author": "",
      "published_date": "2025-09-04T00:00:00+00:00",
      "source": "Fmhy",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 153,
      "reading_time": 1,
      "created_at": "2025-12-30T03:29:45.708576+00:00",
      "updated_at": "2025-12-30T03:29:45.708578+00:00"
    },
    {
      "id": "017d3702aeeb918742228495affeb381",
      "url": "https://fmhy.net/posts/WWH",
      "title": "Why We're Here \ud83e\udd0d",
      "content": "<p>People always want to know what the point of life is. Why are they on earth? What are we doing here? Whats our purpose? <em>Whats the point?</em></p>\n<p>For most of my life, I didn't really have any answer, but as I got older, I realized, things weren't about me. I took a step back, and recognized a much bigger picture we're all apart of, and I now know exactly why we're here on earth.</p>\n<p>As a human, you have a powerful ability, to calm, heal, and help those around you. You have the ability to protect both the people in our world, and the planet itself from harm and distress.</p>\n<p>I know there is a huge amount of pain in our world, a lot of anger, a lot of sadness, and believe me when I say, I share the same feelings. However I believe its important that we each learn to <em><strong>harness that energy into things that are positive and kind</strong></em>, not negative or evil.</p>\n<p>Remember that a lot of who you are, is your ability to experience things outside of yourself, <em>including other humans.</em> They are a direct and immediate part of your own reality. Treat their struggles and woes as if they were your own, don't leave people behind, don't leave people unloved. As frustrating as the world can be, it is worth protecting, it is worth loving, it is worth healing together.</p>\n<hr />\n<ul>\n<li>\n<p><em>&quot;Life is a beautiful, magnificent thing, even to a jellyfish... The trouble is you won't fight. You've given in, continually dwelling on sickness and death. But there's something just as inevitable as death, and that's life. Life, life, life. Think of all the power that's in the universe, moving the earth, growing the trees. That's the same power within you if you only have the courage and the will to use it.&quot;</em> - Charlie Chaplin, Limelight 1952</p>\n</li>\n<li>\n<p><em>&quot;The wise man beholds all beings in the Self, and the Self in all beings; for that reason, he does not hate anyone.&quot;</em> - Isa Upanishad</p>\n</li>\n</ul>",
      "author": "",
      "published_date": "2025-09-11T00:00:00+00:00",
      "source": "Fmhy",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 346,
      "reading_time": 1,
      "created_at": "2025-12-30T03:29:45.708539+00:00",
      "updated_at": "2025-12-30T03:29:45.708542+00:00"
    },
    {
      "id": "c99d006ddbfd960ca35d72629c149385",
      "url": "https://github.com/kenryu42/claude-code-safety-net",
      "title": "Show HN: A Claude Code plugin that catch destructive Git and filesystem commands",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46388882\">Comments</a>",
      "author": "",
      "published_date": "2025-12-26T03:14:07+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-30T03:29:43.063157+00:00",
      "updated_at": "2025-12-30T03:29:43.063158+00:00"
    },
    {
      "id": "4247413a1fb68dda710ce3a3280bc2cb",
      "url": "https://baecher.dev/stdout/incremental-backups-of-gmail-takeouts/",
      "title": "Incremental Backups of Gmail Takeouts",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46384153\">Comments</a>",
      "author": "",
      "published_date": "2025-12-25T12:59:55+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-30T03:29:43.063115+00:00",
      "updated_at": "2025-12-30T03:29:43.063116+00:00"
    },
    {
      "id": "059ccc095ad8b2136b31d057c096b8cc",
      "url": "https://media.ccc.de/v/39c3-hacking-washing-machines",
      "title": "Hacking Washing Machines [video]",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46428496\">Comments</a>",
      "author": "",
      "published_date": "2025-12-30T01:40:49+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-30T03:29:43.062996+00:00",
      "updated_at": "2025-12-30T03:29:43.062998+00:00"
    },
    {
      "id": "059ccc095ad8b2136b31d057c096b8cc",
      "url": "https://media.ccc.de/v/39c3-hacking-washing-machines",
      "title": "Hacking Washing Machines [video]",
      "content": "<p>Article URL: <a href=\"https://media.ccc.de/v/39c3-hacking-washing-machines\">https://media.ccc.de/v/39c3-hacking-washing-machines</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46428496\">https://news.ycombinator.com/item?id=46428496</a></p>\n<p>Points: 26</p>\n<p># Comments: 4</p>",
      "author": "clausecker",
      "published_date": "2025-12-30T01:40:49+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-30T03:29:41.957593+00:00",
      "updated_at": "2025-12-30T03:29:41.957595+00:00"
    },
    {
      "id": "b442e5feeb30da633637c7525cb29ce7",
      "url": "https://www.coverlettermaker.co",
      "title": "Show HN: Cover letter generator with Ollama/local LLMs (Open source)",
      "content": "<p>I built an open source web app that generates cover letters using local AI models (Ollama, LM Studio, vLLM, etc.) so your resume and job application data never leaves your machine.<p>No placeholders. No typing. Letters are ready to copy and paste.<p>The workflow is:\n1. Upload your resume (PDF) - it gets parsed and cached in your browser.\n2. Paste the job description\n3. Get a personalized cover letter in ~5 seconds<p>It connects to any OpenAI-compatible local LLM endpoint. I use it with Ollama + llama3.2, but it works with any local model server.<p>Key features:\n- 100% local and private depending on the LLM of your choice\n- Smart resume parsing with pdf-parse\n- Multi-language support (you can add more languages)\n- Editable output with one-click copy<p>I made this because I was tired of wasting time with writing letters while applying for jobs. All other tools I tried weren't as quick as I wanted because I still needed to modify the letters to replace placeholders.<p>I also didn't find any tool that let's me use my local LLM for free, and I didn't want to pay for ChatGPT/Claude API calls for every job application.<p>The output quality is good, and it can bypass some AI detectors.<p>It's open source too and free to use. You can self-host it or run it locally in development mode.<p>GitHub: <a href=\"https://github.com/stanleyume/coverlettermaker\" rel=\"nofollow\">https://github.com/stanleyume/coverlettermaker</a><p>Cheers :)</p>\n<hr />\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46428699\">https://news.ycombinator.com/item?id=46428699</a></p>\n<p>Points: 11</p>\n<p># Comments: 11</p>",
      "author": "stanyy",
      "published_date": "2025-12-30T02:11:03+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 236,
      "reading_time": 1,
      "created_at": "2025-12-30T03:29:41.957561+00:00",
      "updated_at": "2025-12-30T03:29:41.957570+00:00"
    },
    {
      "id": "81ebe366d326368cd64299af40ed8034",
      "url": "http://ieeexplore.ieee.org/document/11318113",
      "title": "Development and Kinematics Optimization of a Human-Compatible Rope-Driven Ankle Rehabilitation Robot Based on Foot-Ankle IFHA Identification",
      "content": "To address the mismatch between current ankle rehabilitation robots and natural human motion, which affects rehabilitation efficacy, this paper uses screw theory and motion capture experiments to identify the instantaneous finite helical motion axis (IFHA) of the human ankle joint. It determines the distribution law of the IFHA and twist pitch (TP) of the ankle, and designs a human-machine motion compatible rope-driven ankle joint rehabilitation robot that meets the needs of human ankle joint rehabilitation. Firstly, human ankle motion trajectories are captured using the VICON system and IMU, and the experimental data are processed according to screw theory to obtain the distribution law of the IFHA and the range of TP. Secondly, the ankle joint's motion characteristics from the experiment inform the constraint characteristics of the rehabilitation mechanism, which are then mapped into a novel parallel rope-driven ankle rehabilitation robot to meet rehabilitation needs. Thirdly, the kinematic model of the novel mechanism is established, and its kinematic performance and singular configurations are analyzed based on the motion/force transmission index, guiding the optimization of the driving rope layout and mechanism scale parameters. Finally, an experimental platform is built to validate the human-machine motion compatibility, safety, comfort, and effectiveness of the rehabilitation robot.",
      "author": "",
      "published_date": "2025-12-29T13:17:56+00:00",
      "source": "Transactions Biomedical Engineering",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 201,
      "reading_time": 1,
      "created_at": "2025-12-30T01:48:14.231278+00:00",
      "updated_at": "2025-12-30T03:24:06.843981+00:00",
      "metadata": {
        "processed_at": "2025-12-30T03:24:06.843991+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "755f2e75bf9f701e6cbb3e2e5e345b01",
      "url": "http://ieeexplore.ieee.org/document/11024015",
      "title": "GONet: A Generalizable Deep Learning Model for Glaucoma Detection",
      "content": "Glaucomatous optic neuropathy (GON), affecting an estimated 64.3 million people globally, causes irreversible vision loss when not detected early. Traditional diagnosis requires time-consuming ophthalmic examinations by specialists. Recent deep learning models for automating GON detection from colour fundus photographs (CFP) have shown promise but often suffer from limited generalizability across different ethnicities, disease groups and examination settings. To address these limitations, we introduce GONet, a robust deep learning model developed using seven independent datasets, including over 119\u2009000 CFPs with gold-standard annotations and from patients of diverse geographic backgrounds. GONet consists of a DINOv2 pre-trained self-supervised vision transformer fine-tuned using a multisource domain strategy. GONet demonstrated high out-of-distribution generalizability, with an AUC of 0.88-0.99 in target domains. GONet performance was similar or superior to state-of-the-art works and the cup-to-disc ratio, by up to 18.4%. GONet is available via Lirot.ai (www.aimlab-technion.com/lirot-ai). We also contribute a new dataset consisting of 747 CFPs with GON labels as open access, available at https://doi.org/10.13026/pdxv-m215.",
      "author": "",
      "published_date": "2025-06-04T13:17:30+00:00",
      "source": "Transactions Biomedical Engineering",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 159,
      "reading_time": 1,
      "created_at": "2025-12-30T01:48:14.231244+00:00",
      "updated_at": "2025-12-30T03:24:06.843995+00:00",
      "metadata": {
        "processed_at": "2025-12-30T03:24:06.844000+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "22fa3baa23d216508d6f8da74e548308",
      "url": "http://ieeexplore.ieee.org/document/11023078",
      "title": "Phase Correction of MR Spectroscopic Imaging Data Using Model-Based Signal Estimation and Extrapolation",
      "content": "Objective: To develop an effective method for phase correction of magnetic resonance spectroscopic imaging (MRSI) data. Methods: In many MRSI applications, it is desirable to generate absorption-mode spectra, which requires correction of phase errors in the measured MRSI data. Conventional phase correction methods are sensitive to measurement noise and baseline distortion, often resulting in distorted absorption-mode spectra from MRSI data with low-SNR and long acquisition dead time. This paper proposed a novel model-based method for improved phase correction of MRSI data. The proposed method determined the zeroth-order phase and acquisition dead time using a Lorentzian-based spectral model and performed signal extrapolation using a generalized series model. Absorption-mode spectra were then generated from the phase-corrected and extrapolated MRSI data. Results: The proposed method was evaluated using both simulated data and experimental data acquired from human subjects in multi-nuclei (31P, 2H, and 1H) MRSI experiments. Simulation results demonstrated improved parameter estimation accuracy by the proposed method under various noise levels and dead times. The proposed method also consistently generated high-quality absorption-mode spectra with minimal spectral distortions from experimental data. The proposed method was compared with state-of-the-art methods (including the entropy method and LCModel method) and showed more robust phase correction performance with less spectral distortions. Conclusion: This paper introduced a novel method for phase correction of MRSI data. Results from simulated and in vivo data demonstrated that high-quality absorption-mode spectra could be obtained using the proposed method. Significance: This method will provide a useful tool for processing MRSI data.",
      "author": "",
      "published_date": "2025-06-04T13:17:30+00:00",
      "source": "Transactions Biomedical Engineering",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 247,
      "reading_time": 1,
      "created_at": "2025-12-30T01:48:14.231210+00:00",
      "updated_at": "2025-12-30T03:24:06.844003+00:00",
      "metadata": {
        "processed_at": "2025-12-30T03:24:06.844005+00:00",
        "processing_method": "github_actions"
      }
    }
  ]
}