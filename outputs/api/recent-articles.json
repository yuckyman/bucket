{
  "last_updated": "2025-12-19T05:46:51.422408+00:00",
  "count": 20,
  "articles": [
    {
      "id": "bbe0f805e4fabfb0ac2476417484aef4",
      "url": "http://ieeexplore.ieee.org/document/10946856",
      "title": "Enhancing Video Experiences for DHH Individuals Through Sound-Inspired Motion Caption-Based Spatiotemporal Tacton",
      "content": "When deaf and hard of hearing (DHH) individuals watch videos, captions are essential for them to understand the linguistic content. Current captions, however, are not suitable for conveying non-verbal sound information, such as background music, sound effects, or speech nuances. In this paper, we designed a multimodal system, Motion Caption Haptic System (MCHS), that enables DHH individuals to encounter sounds in videos through animated caption and spatiotemporal vibration patterns, supporting a more vivid and immersive experience. We elaborately designed motion captions and spatiotemporal haptic patterns for representative sound effects and spoken emotions to work well together through surveys from 27 DHH and 64 hearing participants. An evaluation with 19 DHH individuals demonstrated the capabilities and potential of the MCHS to improve their video viewing experience, along with a discussion of important issues that need to be addressed when designing multimodal captioning systems for the DHH viewers.",
      "author": "",
      "published_date": "2025-04-01T13:17:18+00:00",
      "source": "Transactions Haptics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 146,
      "reading_time": 1,
      "created_at": "2025-12-19T05:46:39.320402+00:00",
      "updated_at": "2025-12-19T05:46:39.320404+00:00"
    },
    {
      "id": "609521b013e1243f77b1eaa5e01eab3e",
      "url": "http://ieeexplore.ieee.org/document/10965524",
      "title": "VibTac: A High-Resolution High-Bandwidth Tactile Sensing Finger for Multi-Modal Perception in Robotic Manipulation",
      "content": "Tactile sensing is pivotal for enhancing robot manipulation abilities by providing crucial feedback for localized information. However, existing sensors often lack the necessary resolution and bandwidth required for intricate tasks. To address this gap, we introduce VibTac, a novel multi-modal tactile sensing finger designed to offer high-resolution and high-bandwidth tactile sensing simultaneously. VibTac seamlessly integrates vision-based and vibration-based tactile sensing modes to achieve high-resolution and high-bandwidth tactile sensing respectively, leveraging a streamlined human-inspired design for versatility in tasks. This paper outlines the key design elements of VibTac and its fabrication methods, highlighting the significance of the Elastomer Gel Pad (EGP) in its sensing mechanism. The sensor's multi-modal performance is validated through 3D reconstruction and spectral analysis to discern tactile stimuli effectively. In experimental trials, VibTac demonstrates its efficacy by achieving over 90% accuracy in insertion tasks involving objects emitting distinct sounds, such as ethernet connectors. Leveraging vision-based tactile sensing for object localization and employing a deep learning model for \u201cclick\u201d sound classification, VibTac showcases its robustness in real-world scenarios.",
      "author": "",
      "published_date": "2025-04-15T13:16:45+00:00",
      "source": "Transactions Haptics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 169,
      "reading_time": 1,
      "created_at": "2025-12-19T05:46:39.320372+00:00",
      "updated_at": "2025-12-19T05:46:39.320374+00:00"
    },
    {
      "id": "6e5289b1927a2560a61773b58736ef16",
      "url": "http://ieeexplore.ieee.org/document/10955171",
      "title": "Age-Related Impact in Illusory Torque Cues Induced by Asymmetric Vibrations",
      "content": "Illusory pulling sensations in the translational or rotational direction are induced by asymmetric vibrations applied to the fingertips. Although previous studies have discussed the involvement of mechanoreceptors associated with skin deformation and spatial processing in the parietal association cortex in the generation of illusory cues, the precise mechanism underlying this phenomenon remains unclear. In this study, we aimed to indirectly estimate the contribution of mechanoreceptors to the perception of illusory pulling torque cues by examining the relationship between vibration thresholds and the properties of these illusions, leveraging the known decline in cutaneous sensation sensitivity associated with aging (N = 40). Our results revealed an age-related increase in vibration thresholds, which is consistent with previous research. While male participants showed consistent sensitivity to illusory pulling cues across age groups, female participants exhibited a decline in sensitivity with age. Moreover, we observed only weak or no correlations between the vibration thresholds and the sensitivity of the illusory pulling cue. Although we were unable to identify any findings that explain the contribution of mechanoreceptors, we discovered a gender difference in the sensitivity to induced illusions among older individuals. These findings offer valuable insights for elucidating the mechanism underlying the illusion.",
      "author": "",
      "published_date": "2025-04-07T13:17:32+00:00",
      "source": "Transactions Haptics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 197,
      "reading_time": 1,
      "created_at": "2025-12-19T05:46:39.320336+00:00",
      "updated_at": "2025-12-19T05:46:39.320337+00:00"
    },
    {
      "id": "7cd5915b404adde9692f79fbf455044d",
      "url": "http://ieeexplore.ieee.org/document/11037651",
      "title": "A Force/Torque Taxonomy for Classifying States During Physical Co-Manipulation",
      "content": "Achieving seamless human-robot collaboration requires a deeper understanding of how agents manage and communicate forces during shared tasks. Force interactions during collaborative manipulation are inherently complex, especially when considering how they evolve over time. To address this complexity, we propose a taxonomy of decomposed force and torque components, providing a structured framework for examining haptic communication and informing the development of robots capable of performing meaningful collaborative manipulation tasks with human partners. We propose a standardized terminology for force decomposition and classification, bridging the varied language in previous literature in the field, and conduct a review of physical human-human interaction and haptic communication. The proposed taxonomy allows for a more effective and nuanced discussion of important force combinations that we expect to occur during collaborative manipulation (between human-human or human-robot teams). We also include example scenarios to illustrate the value of the proposed taxonomy in describing interactions between agents.",
      "author": "",
      "published_date": "2025-06-17T13:16:38+00:00",
      "source": "Transactions Haptics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 149,
      "reading_time": 1,
      "created_at": "2025-12-19T05:46:39.320302+00:00",
      "updated_at": "2025-12-19T05:46:39.320303+00:00"
    },
    {
      "id": "bffad7ff78c038ce61497f8206575f26",
      "url": "http://ieeexplore.ieee.org/document/11045422",
      "title": "Haptic Relocation Away From the Fingertip: Where, Why, and How",
      "content": "Tactile haptic devices are often designed to render meaningful, complex, and realistic touch-based information on users\u2019 skin. While fingertips and hands are the most preferred body locations to render haptic feedback, recent trends allow such feedback to be extended to alternative body locations (e.g., wrist, arm, torso, foot) for various scenarios due to reasons such as wearability and needs of the application. In this paper, I address the new concept of haptic relocation. It refers to scenarios in which the expected feedback is related to the fingertips but rendered on a different body location instead \u2013 e.g., contact forces registered by two robotic fingers during teleoperation rendered to the users\u2019 wrist instead of the fingers. I investigated the design choices of wearable haptic devices for haptic relocation concerning different body locations, targeted applications, and actuator selection. I discuss approaches and design choices from the literature by speculating on the possible reasons, and conclude the paper by highlighting some challenges and issues to be mindful of in the future. This paper will guide engineers and researchers in searching for alternative haptic rendering solutions \u2013 especially when fingers and hands are not available for haptic interaction.",
      "author": "",
      "published_date": "2025-06-20T13:16:43+00:00",
      "source": "Transactions Haptics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 194,
      "reading_time": 1,
      "created_at": "2025-12-19T05:46:39.320270+00:00",
      "updated_at": "2025-12-19T05:46:39.320272+00:00"
    },
    {
      "id": "654c67a50800e0d8df1eb841fa063ae1",
      "url": "http://ieeexplore.ieee.org/document/10918829",
      "title": "Tactile\u2013Thermal Interactions: Cooperation and Competition",
      "content": "This review focuses on the interactions between the cutaneous senses, and in particular touch and temperature, as these are the most relevant for developing skin-based display technologies for use in virtual reality (VR) and for designing multimodal haptic devices. A broad spectrum of research is reviewed ranging from studies that have examined the mechanisms involved in thermal intensification and tactile masking, to more applied work that has focused on implementing thermal-tactile illusions such as thermal referral and illusory wetness in VR environments. Research on these tactile-thermal illusions has identified the differences between the senses of cold and warmth in terms of their effects on the perception of object properties and the prevalence of the perceptual experiences elicited. They have also underscored the fundamental spatial and temporal differences between the tactile and thermal senses. The wide-ranging body of research on compound sensations such as wetness and stickiness has highlighted the mechanisms involved in sensing moisture and provided a framework for measuring these sensations in a variety of contexts. Although the interactions between the two senses are complex, it is clear that the addition of thermal inputs to a tactile display enhances both user experience and enables novel sensory experiences.",
      "author": "",
      "published_date": "2025-03-10T13:16:41+00:00",
      "source": "Transactions Haptics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 198,
      "reading_time": 1,
      "created_at": "2025-12-19T05:46:39.320227+00:00",
      "updated_at": "2025-12-19T05:46:39.320229+00:00"
    },
    {
      "id": "604cffaea5736d8c2935253598862e29",
      "url": "http://ieeexplore.ieee.org/document/11174044",
      "title": "Twenty Years of World Haptics: Retrospective and Future Directions",
      "content": "null",
      "author": "",
      "published_date": "2025-09-19T13:16:57+00:00",
      "source": "Transactions Haptics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 1,
      "reading_time": 1,
      "created_at": "2025-12-19T05:46:39.320181+00:00",
      "updated_at": "2025-12-19T05:46:39.320183+00:00"
    },
    {
      "id": "a8c2d5cb04d96aaadc48d2adf196f678",
      "url": "https://fmhy.net/posts/FCC",
      "title": "Fight Chat Control \ud83d\udd12",
      "content": "<h3 id=\"the-eu-still-wants-to-scan-your-private-messages-and-photos\" tabindex=\"-1\">The EU (still) wants to scan your private messages and photos. <a class=\"header-anchor\" href=\"#the-eu-still-wants-to-scan-your-private-messages-and-photos\"></a></h3>\n<p>The &quot;Chat Control&quot; proposal would mandate scanning of all private digital communications, including encrypted messages and photos. This threatens fundamental privacy rights and digital security for all EU citizens.</p>\n<p>Every photo, every message, every file you send will be automatically scanned\u2014without your consent or suspicion. This is not about catching criminals. It is <em><strong>mass surveillance</strong></em> imposed on all 450 million citizens of the European Union.</p>\n<p>EU politicians <em>exempt themselves</em> from this surveillance under &quot;professional secrecy&quot; rules. They get privacy. You and your family do not. If you're in the EU, please consider contacting Members of the European Parliament (MEPs) using the info provided on the site below:</p>\n<h1 id=\"https-fightchatcontrol-eu\" tabindex=\"-1\"><a href=\"https://fightchatcontrol.eu/\" rel=\"noreferrer\" target=\"_blank\">https://fightchatcontrol.eu/</a> <a class=\"header-anchor\" href=\"#https-fightchatcontrol-eu\"></a></h1>\n<p>There is also a change.org petition <a href=\"https://stopchatcontrol.eu/\" rel=\"noreferrer\" target=\"_blank\">here</a> if you'd like to sign it.</p>\n<p>Discussion: <a href=\"https://redd.it/1n840p9\" rel=\"noreferrer\" target=\"_blank\">https://redd.it/1n840p9</a></p>",
      "author": "",
      "published_date": "2025-09-04T00:00:00+00:00",
      "source": "Fmhy",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 153,
      "reading_time": 1,
      "created_at": "2025-12-19T05:45:41.163018+00:00",
      "updated_at": "2025-12-19T05:45:41.163020+00:00"
    },
    {
      "id": "017d3702aeeb918742228495affeb381",
      "url": "https://fmhy.net/posts/WWH",
      "title": "Why We're Here \ud83e\udd0d",
      "content": "<p>People always want to know what the point of life is. Why are they on earth? What are we doing here? Whats our purpose? <em>Whats the point?</em></p>\n<p>For most of my life, I didn't really have any answer, but as I got older, I realized, things weren't about me. I took a step back, and recognized a much bigger picture we're all apart of, and I now know exactly why we're here on earth.</p>\n<p>As a human, you have a powerful ability, to calm, heal, and help those around you. You have the ability to protect both the people in our world, and the planet itself from harm and distress.</p>\n<p>I know there is a huge amount of pain in our world, a lot of anger, a lot of sadness, and believe me when I say, I share the same feelings. However I believe its important that we each learn to <em><strong>harness that energy into things that are positive and kind</strong></em>, not negative or evil.</p>\n<p>Remember that a lot of who you are, is your ability to experience things outside of yourself, <em>including other humans.</em> They are a direct and immediate part of your own reality. Treat their struggles and woes as if they were your own, don't leave people behind, don't leave people unloved. As frustrating as the world can be, it is worth protecting, it is worth loving, it is worth healing together.</p>\n<hr />\n<ul>\n<li>\n<p><em>&quot;Life is a beautiful, magnificent thing, even to a jellyfish... The trouble is you won't fight. You've given in, continually dwelling on sickness and death. But there's something just as inevitable as death, and that's life. Life, life, life. Think of all the power that's in the universe, moving the earth, growing the trees. That's the same power within you if you only have the courage and the will to use it.&quot;</em> - Charlie Chaplin, Limelight 1952</p>\n</li>\n<li>\n<p><em>&quot;The wise man beholds all beings in the Self, and the Self in all beings; for that reason, he does not hate anyone.&quot;</em> - Isa Upanishad</p>\n</li>\n</ul>",
      "author": "",
      "published_date": "2025-09-11T00:00:00+00:00",
      "source": "Fmhy",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 346,
      "reading_time": 1,
      "created_at": "2025-12-19T05:45:41.162982+00:00",
      "updated_at": "2025-12-19T05:45:41.162983+00:00"
    },
    {
      "id": "d4c2ae8024ded11cd4540b08ac8a8d3d",
      "url": "https://ngrok.com/blog/prompt-caching/",
      "title": "Prompt caching: 10x cheaper LLM tokens, but how?",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46290620\">Comments</a>",
      "author": "",
      "published_date": "2025-12-16T16:32:27+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-19T05:45:38.638261+00:00",
      "updated_at": "2025-12-19T05:45:38.638263+00:00"
    },
    {
      "id": "e0eb0879ea22c78da92134bc86186ae1",
      "url": "https://lwn.net/SubscriberLink/1050174/63aa7da43214c3ce/",
      "title": "The state of the kernel Rust experiment",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46252712\">Comments</a>",
      "author": "",
      "published_date": "2025-12-13T07:14:21+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-19T05:45:38.638242+00:00",
      "updated_at": "2025-12-19T05:45:38.638243+00:00"
    },
    {
      "id": "e69dd9aa23edcba61dee8d0a09c9d5a4",
      "url": "https://arxiv.org/abs/2512.16285",
      "title": "Machines, AI and the past//future of things",
      "content": "arXiv:2512.16285v1 Announce Type: new \nAbstract: This essay explores a techno-artistic experiment that reanimates a 1980s East German typewriter using a contemporary AI language model. Situated at the intersection of media archaeology and speculative design, the project questions dominant narratives of progress by embedding generative AI in an obsolete, tactile interface. Through public exhibitions and aesthetic intervention, we demonstrate how slowness, friction, and material render artificial intelligence not only visible but open to critical inquiry. Drawing on concepts such as zombie media, technostalgia, and speculative design, we argue that reappropriating outdated technologies enables new forms of critical engagement. Erika - the AI-enabled typewriter - functions as both interface and interruption, making space for reflection, irony, and cultural memory. In a moment of accelerated digital abstraction, projects like this foreground the value of deliberate slowness, experiential materiality, and historical depth. We conclude by advocating for a historicist design sensibility that challenges presentism and reorients human-machine interaction toward alternative, perceived futures.",
      "author": "Karola K\\\"opferl, Albrecht Kurze",
      "published_date": "2025-12-19T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 158,
      "reading_time": 1,
      "created_at": "2025-12-19T05:23:35.743570+00:00",
      "updated_at": "2025-12-19T05:23:35.743572+00:00"
    },
    {
      "id": "946f1dc7d48eed6dbdcdde9e07976014",
      "url": "https://arxiv.org/abs/2512.16206",
      "title": "The Agony of Opacity: Foundations for Reflective Interpretability in AI-Mediated Mental Health Support",
      "content": "arXiv:2512.16206v1 Announce Type: new \nAbstract: Throughout history, a prevailing paradigm in mental healthcare has been one in which distressed people may receive treatment with little understanding around how their experience is perceived by their care provider, and in turn, the decisions made by their provider around how treatment will progress. Paralleling this offline model of care, people who seek mental health support from AI chatbots are similarly provided little context for how their expressions of distress are processed by the model, and subsequently, the logic that may underlie model responses. People in severe distress who turn to AI chatbots for support thus find themselves caught between black boxes, with unique forms of agony that arise from these intersecting opacities, including misinterpreting model outputs or attributing greater capabilities to a model than are yet possible, which has led to documented real-world harms. Building on empirical research from clinical psychology and AI safety, alongside rights-oriented frameworks from medical ethics, we describe how the distinct psychological state induced by severe distress can influence chatbot interaction patterns, and argue that this state of mind (combined with differences in how a user might perceive a chatbot compared to a care provider) uniquely necessitates a higher standard of interpretability in comparison to general AI chatbot use. Drawing inspiration from newer interpretable treatment paradigms, we then describe specific technical and interface design approaches that could be used to adapt interpretability strategies from four specific mental health fields (psychotherapy, community-based crisis intervention, psychiatry, and care authorization) to AI models, including consideration of the role of interpretability in the treatment process and tensions that may arise with greater interpretability.",
      "author": "Sachin R. Pendse, Darren Gergle, Rachel Kornfield, Kaylee Kruzan, David Mohr, Jessica Schleider, Jina Suh, Annie Wescott, Jonah Meyerhoff",
      "published_date": "2025-12-19T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 270,
      "reading_time": 1,
      "created_at": "2025-12-19T05:23:35.743540+00:00",
      "updated_at": "2025-12-19T05:23:35.743542+00:00"
    },
    {
      "id": "3af0d2ea1a5c47e03a09fb4b75f3f593",
      "url": "https://arxiv.org/abs/2512.16081",
      "title": "Evaluation of Generative Models for Emotional 3D Animation Generation in VR",
      "content": "arXiv:2512.16081v1 Announce Type: new \nAbstract: Social interactions incorporate nonverbal signals to convey emotions alongside speech, including facial expressions and body gestures. Generative models have demonstrated promising results in creating full-body nonverbal animations synchronized with speech; however, evaluations using statistical metrics in 2D settings fail to fully capture user-perceived emotions, limiting our understanding of model effectiveness. To address this, we evaluate emotional 3D animation generative models within a Virtual Reality (VR) environment, emphasizing user-centric metrics emotional arousal realism, naturalness, enjoyment, diversity, and interaction quality in a real-time human-agent interaction scenario. Through a user study (N=48), we examine perceived emotional quality for three state of the art speech-driven 3D animation methods across two emotions happiness (high arousal) and neutral (mid arousal). Additionally, we compare these generative models against real human expressions obtained via a reconstruction-based method to assess both their strengths and limitations and how closely they replicate real human facial and body expressions. Our results demonstrate that methods explicitly modeling emotions lead to higher recognition accuracy compared to those focusing solely on speech-driven synchrony. Users rated the realism and naturalness of happy animations significantly higher than those of neutral animations, highlighting the limitations of current generative models in handling subtle emotional states. Generative models underperformed compared to reconstruction-based methods in facial expression quality, and all methods received relatively low ratings for animation enjoyment and interaction quality, emphasizing the importance of incorporating user-centric evaluations into generative model development. Finally, participants positively recognized animation diversity across all generative models.",
      "author": "Kiran Chhatre, Renan Guarese, Andrii Matviienko, Christopher Peters",
      "published_date": "2025-12-19T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 246,
      "reading_time": 1,
      "created_at": "2025-12-19T05:23:35.743501+00:00",
      "updated_at": "2025-12-19T05:23:35.743503+00:00"
    },
    {
      "id": "4494464bad20f7f8f8914cdf151fe157",
      "url": "https://arxiv.org/abs/2512.16067",
      "title": "WING: An Adaptive and Gamified Mobile Learning Platform for Neurodivergent Literacy",
      "content": "arXiv:2512.16067v1 Announce Type: new \nAbstract: This paper presents WING, an adaptive and gamified mobile learning platform designed to support literacy development for neurodivergent children. Motivated by the limitations of traditional literacy approaches in addressing diverse cognitive profiles, the platform integrates inclusive Human-Computer Interaction principles, multisensory design, and adaptive learning paths. WING digitally transposes the Alfabetiza\\c{c}\\~ao Adaptada (AFA) method into an interactive mobile environment, combining usability guidelines for neurodivergent users with gamification strategies to enhance engagement and autonomy. The study follows an applied research methodology, encompassing requirements elicitation, inclusive interface design, high-fidelity prototyping, and qualitative and quantitative evaluation planning. Preliminary results include a functional minimum viable product validated through expert feedback and public exhibitions, indicating the feasibility and potential pedagogical impact of the proposed approach. The platform aims to act as a complementary educational tool, promoting accessibility, personalization, and inclusive digital literacy.",
      "author": "Mirella Emily Bezerra Santana, Cau\\~a Otaviano Jord\\~ao, Victor Barbosa dos Santos, Leonardo Jos\\'e Oliveira Ibiapina, Gabriel Moraes da Silva, Marina Robalinho Cavalcanti, Lucas Rodolfo Celestino Farias",
      "published_date": "2025-12-19T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 141,
      "reading_time": 1,
      "created_at": "2025-12-19T05:23:35.743461+00:00",
      "updated_at": "2025-12-19T05:23:35.743462+00:00"
    },
    {
      "id": "bbc8bfcf2df8611fd01daf3fce7340f6",
      "url": "https://arxiv.org/abs/2512.16063",
      "title": "A Multi-Agent Large Language Model Framework for Automated Qualitative Analysis",
      "content": "arXiv:2512.16063v1 Announce Type: new \nAbstract: Understanding patients experiences is essential for advancing patient centered care, especially in chronic diseases that require ongoing communication. However, qualitative thematic analysis, the primary approach for exploring these experiences, remains labor intensive, subjective, and difficult to scale. In this study, we developed a multi agent large language model framework that automates qualitative thematic analysis through three agents (Instructor, Thematizer, CodebookGenerator), named Collaborative Theme Identification Agent (CoTI). We applied CoTI to 12 heart failure patient interviews to analyze their perceptions of medication intensity. CoTI identified key phrases, themes, and codebook that were more similar to those of the senior investigator than both junior investigators and baseline NLP models. We also implemented CoTI into a user-facing application to enable AI human interaction in qualitative analysis. However, collaboration between CoTI and junior investigators provided only marginal gains, suggesting they may overrely on CoTI and limit their independent critical thinking.",
      "author": "Qidi Xu, Nuzha Amjad, Grace Giles, Alexa Cumming, De'angelo Hermesky, Alexander Wen, Min Ji Kwak, Yejin Kim",
      "published_date": "2025-12-19T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 151,
      "reading_time": 1,
      "created_at": "2025-12-19T05:23:35.743431+00:00",
      "updated_at": "2025-12-19T05:23:35.743433+00:00"
    },
    {
      "id": "1c1da2c0b83cdd5e7fc4ce01aa42eeca",
      "url": "https://arxiv.org/abs/2512.16008",
      "title": "Augmented Reality-Based Smart Structural Health Monitoring System With Accurate 3D Model Alignment",
      "content": "arXiv:2512.16008v1 Announce Type: new \nAbstract: Structural Health Monitoring (SHM) has become increasingly critical due to the rapid deterioration of civil infrastructure. Traditional methods involving heavy equipment are costly and time-consuming. Recent SHM approaches use advanced non-contact sensors, IoT, and Augmented Reality (AR) glasses for faster inspections and immersive experiences during inspections. However, current methods lack quantitative damage data, remote collaboration support, and accurate 3D model alignment with the real structure. Recognizing these current challenges, this paper proposes an AR-based system that integrates Building Information Modelling (BIM) visualization and follows a flexible manipulation approach of 3D holograms to improve structural condition assessments. The proposed framework utilizes the Vuforia software development toolkit to enable the automatic alignment of 3D models to the real structure, ensuring successful model alignment to assist users in accurately visualizing damage locations. The framework also enables flexible manipulation of damage locations, making it easier for users to identify multiple damage points in the 3D models. The system is validated through lab-scale and full-scale bridge use cases, with data transfer performance analyzed under 4G and 5G conditions for remote collaboration. This study demonstrates that the proposed AR-based SHM framework successfully aligns 3D models with real structures, allowing users to manually adjust models and damage locations. The experimental results confirm its feasibility for remote collaborative inspections, highlighting significant improvements with 5G networks. Nevertheless, performance under 4G remains acceptable, ensuring reliability even without 5G coverage.",
      "author": "Omar Awadallah, Katarina Grolinger, Ayan Sadhu",
      "published_date": "2025-12-19T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 234,
      "reading_time": 1,
      "created_at": "2025-12-19T05:23:35.743403+00:00",
      "updated_at": "2025-12-19T05:23:35.743404+00:00"
    },
    {
      "id": "4c857d7a7f9265935b55d965301e3674",
      "url": "https://arxiv.org/abs/2512.15944",
      "title": "The Emerging Use of GenAI for UX Research in Software Development: Challenges and Opportunities",
      "content": "arXiv:2512.15944v1 Announce Type: new \nAbstract: The growing adoption of generative AI (GenAI) is reshaping how user experience (UX) research teams conduct qualitative research in software development, creating opportunities to streamline the production of qualitative insights. This paper presents findings from two user studies examining how current practices are challenged by GenAI and offering design implications for future AI assistance. Semi-structured interviews with 21 UX researchers, product managers, and designers reveal challenges of aligning AI capabilities with the interpretive, collaborative nature of qualitative research and tensions between roles. UX researchers expressed limited trust in AI-generated results, while product managers often overestimated AI capabilities, amplifying organizational pressures to accelerate research within agile workflows. In a second study, we validated an AI analysis approach more closely aligned with human analysis processes to address trust issues bottoms-up. We outline interaction patterns and design guidelines for responsibly integrating AI into software development cycles.",
      "author": "Heloisa Candello, Werner Geyer, Siya Kunde, Michael Muller, Daita Sarkar, Jessica He, Mariela Claudia Lanza, Carlos Rosemberg, Gord Davison, Lisa Pelletier",
      "published_date": "2025-12-19T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 148,
      "reading_time": 1,
      "created_at": "2025-12-19T05:23:35.743368+00:00",
      "updated_at": "2025-12-19T05:23:35.743369+00:00"
    },
    {
      "id": "3e5234793b0cb820815fc3dc431c4f49",
      "url": "https://arxiv.org/abs/2512.15941",
      "title": "Non-Stationarity in Brain-Computer Interfaces: An Analytical Perspective",
      "content": "arXiv:2512.15941v1 Announce Type: new \nAbstract: Non-invasive Brain-Computer Interface (BCI) systems based on electroencephalography (EEG) signals suffer from multiple obstacles to reach a wide adoption in clinical settings for communication or rehabilitation. Among these challenges, the non-stationarity of the EEG signal is a key problem as it leads to various changes in the signal. There are changes within a session, across sessions, and across individuals. Variations over time for a given individual must be carefully managed to improve the BCI performance, including its accuracy, reliability, and robustness over time. This review paper presents and discusses the causes of non-stationarity in the EEG signal, along with its consequences for BCI applications, including covariate shift. The paper reviews recent studies on covariate shift, focusing on methods for detecting and correcting this phenomenon. Signal processing and machine learning techniques can be employed to normalize the EEG signal and address the covariate shift.",
      "author": "Hubert Cecotti, Rashmi Mrugank Shah, Raksha Jagadish, Toshihisa Tanaka",
      "published_date": "2025-12-19T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 148,
      "reading_time": 1,
      "created_at": "2025-12-19T05:23:35.743338+00:00",
      "updated_at": "2025-12-19T05:23:35.743340+00:00"
    },
    {
      "id": "efcd1f02384e542355a158f24af96ac2",
      "url": "https://arxiv.org/abs/2512.15918",
      "title": "Management von Sensordaten im Smarthome: Besonderheiten und Ans\\\"atze",
      "content": "arXiv:2512.15918v1 Announce Type: new \nAbstract: A wide variety of simple sensors, e.g. for temperature, light, or humidity, is finding its way into smart homes. There are special features to consider with regard to the data collected by these sensors: a) the nature of the measured data as \"thin but big data\" that needs to be contextualized and interpreted, b) which both algorithms and humans are capable of doing (resulting in comprehensive information in the context of the home, including the recognition of activities, behavior, and health of the residents), and c) uses that lead to interesting positive applications, but also to misuse and implications for privacy. When managing such data, it is necessary to take these special features into account, for which the principles of user experience, human-data interaction, and data protection should be considered together. We present our research tool \"Sensorkit\" and the participatory research approach used with it to collect sensor data in real homes. In our findings, we present identified challenges and explain how we address them through a) meaningful default settings, b) opportunities for users to interact and intervene, and c) life-cycle management of the data. Important aspects include phases before, during, and after the collection, processing, and use of the sensor data, as well as the provision of user-friendly tools and user involvement. Our findings inform beyond the scope of a research project also the development and use of commercial smart home devices and services.",
      "author": "Albrecht Kurze, Karola K\\\"oferl, Andy B\\\"orner",
      "published_date": "2025-12-19T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 240,
      "reading_time": 1,
      "created_at": "2025-12-19T05:23:35.743307+00:00",
      "updated_at": "2025-12-19T05:23:35.743309+00:00"
    }
  ]
}