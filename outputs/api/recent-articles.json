{
  "last_updated": "2026-01-26T22:17:37.494909+00:00",
  "count": 20,
  "articles": [
    {
      "id": "5e63a8b7edf381362775317a4a6fa8ee",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.23.701339v1?rss=1",
      "title": "Neural Signatures of Post-Decision Outcome Expectation and Evaluation in Human Sensorimotor Choice Behavior",
      "content": "The concept of embodied sensorimotor decision-making proposes that processes implicated in evaluating sensory inputs and selecting appropriate motor actions unfold partly in cortical regions traditionally associated with movement planning and execution. Reinforcement learning models emphasize the role of reward prediction error (RPE) in optimizing action selection based on decision outcome feedback. However, most evidence for the existence of RPE signals locates them in midline frontal and parietal cortex, and comes from tasks with externally manipulated reward probabilities that create artificial prediction errors. Whether RPE signals are expressed in human cortical motor areas during deterministic (non-probabilistic) tasks remains unclear, and would provide further support for embodied decision-making. We used magnetoencephalography (MEG) to study post-decision neural dynamics in a color discrimination task in selected cortical regions of interest (ROIs). Participants had to press buttons with their left or right index finger in response to checkerboard stimuli with different levels of color evidence for the correct choice. Outcomes were fully determined by participants' choices. Delayed auditory feedback veridically indicated whether their hand choice was correct or not. We observed a robust beta-band (15-29 Hz) rebound after correct outcome feedback, strongest in ventral and dorsal premotor, anterior cingulate and superior parietal ROIs as well as occipital and auditory ROIs, and weakest in the primary motor and somatosensory ROIs. Critically, the rebound magnitude after correct feedback scaled inversely with color evidence strength and associated decision error rates. It was minimal in strong-evidence trials (~0.1% errors) and maximal in weak-evidence trials (~34% errors), resembling a context-sensitive positive RPE signal that was strongest when a correct outcome was least expected. Alpha-band (8-12 Hz) post-feedback rebound increases in weak evidence trials were not as strong as in the beta band and appeared mainly in occipital, superior parietal and posterior cingulate ROIs. After the decision but before feedback, both beta and alpha band power showed sensitivity to the level of sensory evidence on which the decisions had been based, with reduced post-movement rebound or enhanced suppression in trials with weak evidence, suggestive of internally generated outcome expectations. Pre-feedback alpha rebound suppression was strongest in occipital, superior parietal and posterior cingulate ROIs. Pre-feedback beta rebound suppression was not as strong. Together, these findings reveal distinct beta- and alpha-band dynamics that reflect internal pre-feedback outcome expectations and feedback-driven RPE-like outcome assessments. They support distributed cortical mechanisms, including premotor, parietal and cingulate regions, in reward expectation, outcome evaluation, and adaptive control, highlighting a role for motor and associative cortices in embodied decision-making, performance monitoring, and flexible behavior under uncertainty.",
      "author": "Gharesi, N., Kalaska, J. F., Baillet, S.",
      "published_date": "2026-01-26T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 417,
      "reading_time": 2,
      "created_at": "2026-01-26T21:29:50.367605+00:00",
      "updated_at": "2026-01-26T22:17:37.389653+00:00",
      "metadata": {
        "processed_at": "2026-01-26T22:17:37.389662+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "d8b68f473d5d5ac15a2d20597826b1ed",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.23.701333v1?rss=1",
      "title": "A mathematical model of pathology progression in the TgF344-AD rat model of Alzheimer's disease",
      "content": "Alzheimer's disease (AD) is a devastating neurodegenerative disease whose etiology is poorly understood and for which current treatments provide only modest control of symptoms. To better investigate the causes and progression of the disease, the transgenic TgF344-AD rat model has emerged as a crucial tool. In this paper, we collect observations on the accumulation of amyloid-{beta}, changes in neuronal density, and a decline in cognitive performance in TgF344-AD and wild-type rats. We develop a compartmental ordinary differential equation model and determine its parameters by fitting the output to the experimental observations. Our model simulations support the hypothesis that the accumulation of amyloid-{beta} leads to a rapid decline in neuronal density followed by a significant loss in memory and learning ability. Our mathematical model can provide a bridge between AD research in rodent models and the human condition of AD.",
      "author": "Hesketh, M., Hinow, P.",
      "published_date": "2026-01-26T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 139,
      "reading_time": 1,
      "created_at": "2026-01-26T21:29:50.367541+00:00",
      "updated_at": "2026-01-26T22:17:37.389666+00:00",
      "metadata": {
        "processed_at": "2026-01-26T22:17:37.389668+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "dac4b1fd588175280d332b5f3a88e7ae",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.23.701256v1?rss=1",
      "title": "A Population Vector Model of Visual Working Memory for Real-World Scenes",
      "content": "Visual working memory is essential for navigating through and interacting with complex real-world environments. It is therefore important to understand how natural visual inputs - characterized by complex contours, continuously varying feature gradients, and spatial relationships - are represented in working memory. However, most research in this field has focused on simplified arrays of discrete artificial objects, favoring experimental control and modeling simplicity over ecological validity. This has led to quantitative models of working memory that require inputs consisting of easily parsed objects defined by a single value along one or more simple feature dimensions. It is not clear how these models could be updated to represent complex, photograph-like scenes. To overcome this limitation, we introduce a population vector model of working memory that was designed specifically for real-world scenes. This model represents a scene as a noisy vector of neural firing rates across one or more areas of the ventral pathway, as estimated by a deep neural network model. We show that this model can account for both variations in behavioral performance and patterns of brain activity in tasks that require storing naturalistic scenes in working memory. These results demonstrate the viability of our general modeling approach, setting the stage for more sophisticated models that can fully account for the storage of real-world scenes in working memory.",
      "author": "Kiat, J. E., Luck, S. J.",
      "published_date": "2026-01-26T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 218,
      "reading_time": 1,
      "created_at": "2026-01-26T21:29:50.367509+00:00",
      "updated_at": "2026-01-26T22:17:37.389671+00:00",
      "metadata": {
        "processed_at": "2026-01-26T22:17:37.389673+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "e6c79b6d3b07117680cd73247e290364",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.23.701383v1?rss=1",
      "title": "History-dependent ephaptic interactions in paired olfactory receptor neurons",
      "content": "Olfactory sensing begins with the transduction of odors into receptor currents on the dendrites of olfactory receptor neurons (ORNs). In insects and many other arthropods, ORNs are grouped stereotypically in hair-like sensilla on the surface of olfactory organs, enabling mutual inhibition through non-synaptic 'ephaptic' interactions (NSIs). Given the electrical, and therefore virtually instantaneous, nature of NSIs, it has been hypothesized that they contribute to processing fast temporal elements of mixed odor plumes. Here, we present single sensillum recordings and computational modeling that characterize NSIs during short offset dual-odor stimulations in the olfactory sensilla of adult female Drosophila melanogaster. We find in the experiments that the magnitude of inhibition between co-housed ORNs cannot be predicted by their instantaneous activity (firing rate) alone. It is adaptation-dependent, with strong effects only occurring when the inhibited ORN is adapted. This limits the usefulness of NSIs for fast odor processing when ORNs lack time to adapt. We reproduced the observed phenomena in a computational model and use this model to explain how the adaptation-dependence of NSI-mediated inhibition arises from nonlinearities in neural responses. We conclude that NSIs are unlikely to support the encoding of fast temporal dynamics in mixed odor stimuli, instead contributing to slower peripheral processing, supporting roles such as novelty detection. More broadly, we demonstrate how the nonlinear interactions of fairly simple electrical components lead to non-intuitive results, offering insight into the longstanding debate around ephaptic interactions in other systems, such as the mammalian CNS.",
      "author": "Ellison, L., Kemenes, G., Nowotny, T.",
      "published_date": "2026-01-26T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 242,
      "reading_time": 1,
      "created_at": "2026-01-26T21:29:50.367464+00:00",
      "updated_at": "2026-01-26T22:17:37.389675+00:00",
      "metadata": {
        "processed_at": "2026-01-26T22:17:37.389676+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "a18b6158de97ecd6aa5e2472598a7bc4",
      "url": "https://www.wsj.com/business/the-secret-society-of-people-who-know-the-formula-for-wd-40-e9c0ff54",
      "title": "People who know the formula for WD-40",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46771599\">Comments</a>",
      "author": "",
      "published_date": "2026-01-26T21:11:53+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-26T21:29:10.604427+00:00",
      "updated_at": "2026-01-26T22:17:37.389679+00:00",
      "metadata": {
        "processed_at": "2026-01-26T22:17:37.389680+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "ea48755ec8441df59608c0273e8f73a4",
      "url": "https://www.zackliscio.com/posts/rip-low-code-2014-2025/",
      "title": "RIP Low-Code 2014-2025",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46767440\">Comments</a>",
      "author": "",
      "published_date": "2026-01-26T16:11:28+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-26T21:29:10.604330+00:00",
      "updated_at": "2026-01-26T21:29:10.604332+00:00"
    },
    {
      "id": "a5560c1ab484b945b674d84af7f497fa",
      "url": "https://practical.engineering/blog/2026/1/20/the-hidden-engineering-of-runways",
      "title": "The Hidden Engineering of Runways",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46694193\">Comments</a>",
      "author": "",
      "published_date": "2026-01-20T16:52:52+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-26T21:29:10.604284+00:00",
      "updated_at": "2026-01-26T21:29:10.604286+00:00"
    },
    {
      "id": "d313793ff6dd93974faa50761c46a0c7",
      "url": "https://ourguide.ai",
      "title": "Show HN: Ourguide \u2013 OS wide task guidance system that shows you where to click",
      "content": "<p>Hey! I'm eshaan and I'm building Ourguide -an on-screen task guidance system that can show you where to click step-by-step when you need help.<p>I started building this because whenever I didn\u2019t know how to do something on my computer, I found myself constantly tabbing between chatbots and the app, pasting screenshots, and asking \u201cwhat do I do next?\u201d Ourguide solves this with two modes. In Guide mode, the app overlays your screen and highlights the specific element to click next, eliminating the need to leave your current window. There is also Ask mode, which is a vision-integrated chat that captures your screen context\u2014which you can toggle on and off anytime -so you can ask, \"How do I fix this error?\" without having to explain what \"this\" is.<p>It\u2019s an Electron app that works OS-wide, is vision-based, and isn't restricted to the browser.<p>Figuring out how to show the user where to click was the hardest part of the process. I originally trained a computer vision model with 2300 screenshots to identify and segment all UI elements on a screen and used a VLM to find the correct icon to highlight. While this worked extremely well\u2014better than SOTA grounding models like UI Tars\u2014the latency was just too high. I'll be making that CV+VLM pipeline OSS soon, but for now, I\u2019ve resorted to a simpler implementation that achieves <1s latency.<p>You may ask: if I can show you where to click, why can't I just click too? While trying to build computer-use agents during my job in Palo Alto, I hit the core limitation of today\u2019s computer-use models where benchmarks hover in the mid-50% range (OSWorld). VLMs often know what to do but not what it looks like; without reliable visual grounding, agents misclick and stall. So, I built computer use\u2014without the \"use.\" It provides the visual grounding of an agent but keeps the human in the loop for the actual execution to prevent misclicks.<p>I personally use it for the AWS Console's \"treasure hunt\" UI, like creating a public S3 bucket with specific CORS rules. It\u2019s also been surprisingly helpful for non-technical tasks, like navigating obscure settings in Gradescope or Spotify. Ourguide really works for any task when you\u2019re stuck or don't know what to do.<p>You can download and test Ourguide here: <a href=\"https://ourguide.ai/downloads\" rel=\"nofollow\">https://ourguide.ai/downloads</a><p>The project is still very early, and I\u2019d love your feedback on where it fails, where you think it worked well, and which specific niches you think Ourguide would be most helpful for.</p>\n<hr />\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46769422\">https://news.ycombinator.com/item?id=46769422</a></p>\n<p>Points: 6</p>\n<p># Comments: 1</p>",
      "author": "eshaangulati",
      "published_date": "2026-01-26T18:19:45+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 423,
      "reading_time": 2,
      "created_at": "2026-01-26T21:29:09.489509+00:00",
      "updated_at": "2026-01-26T21:29:09.489511+00:00"
    },
    {
      "id": "a18b6158de97ecd6aa5e2472598a7bc4",
      "url": "https://www.wsj.com/business/the-secret-society-of-people-who-know-the-formula-for-wd-40-e9c0ff54",
      "title": "People who know the formula for WD-40",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46771599\">Comments</a>",
      "author": "",
      "published_date": "2026-01-26T21:11:53+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-26T21:29:10.604427+00:00",
      "updated_at": "2026-01-26T22:17:37.389679+00:00",
      "metadata": {
        "processed_at": "2026-01-26T22:17:37.389680+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "fbe8de9f1dc91987e872fbff41c2f58e",
      "url": "https://simonwillison.net/2026/Jan/26/chatgpt-containers/",
      "title": "ChatGPT Containers can now run bash, pip/npm install packages and download files",
      "content": "<p>Article URL: <a href=\"https://simonwillison.net/2026/Jan/26/chatgpt-containers/\">https://simonwillison.net/2026/Jan/26/chatgpt-containers/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46770221\">https://news.ycombinator.com/item?id=46770221</a></p>\n<p>Points: 6</p>\n<p># Comments: 1</p>",
      "author": "simonw",
      "published_date": "2026-01-26T19:19:40+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2026-01-26T20:53:10.316156+00:00",
      "updated_at": "2026-01-26T20:53:10.316157+00:00"
    },
    {
      "id": "61e259c2875f1f44cbe6de07213648bd",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.23.701340v1?rss=1",
      "title": "Oculomotor dance learning task: Implications for audio-visual cued spatial learning",
      "content": "Learning dance of a motor sequence learning involves the coordination of both oculomotor and manual motor systems through the practiced repetition of a fixed sequence of actions, resulting in automatized execution of movement through habit learning. This study aims to address whether a sequence-based learning paradigm centered on the visual-motor system can feasibly be measured while listening to music (Bar and DeSouza 2016). It aims to develop a new visual-motor-based learning paradigm with music, potentially promoting neuroplasticity and creating new interventional tools, building upon prior research that shows behavioural and putative neural changes following dance-based neurorehabilitation in people with Parkinson's disease (Bearss et al. 2024). Eye movements of 10 participants (8 female, 2 male) were tracked using the Eyelink 1000 Plus system during a 68-second eye-dance sequence. The experiment consisted of a learning phase, where participants observed the sequence five times with 30-second breaks, and a performance phase, where they performed the sequence five times from memory on a grey screen without visual cues. Music was incorporated into both phases to aid memorization of the 4 spatial locations. After each performance, the participant was shown a visual reinforcer and asked for their thoughts on how well they executed the dance. A visual reinforcer flashes one of three different colours: red, yellow, or green. Each colour corresponds to how many steps in the dance a participant performed correctly, with key points being: under one third, between one to two thirds, and over two thirds of total steps correct. Participants were scored based on timing of the steps as well for exact (1.00), good (0.66), slightly off (0.33) or missed (0) steps. Data was analyzed using R4.3.1, MATLAB, and Experiment Builder: Data Viewer software. Results showed a significant improvement in performance accuracy between the first session (g1; M = 40%, SD = 7.2%) and the last session (g5; M = 69.7%, SD = 22.8%). A repeated-measures ANOVA revealed a significant main effect of session on performance accuracy, F(4, 36) = 6.99, p < 0.001, 2G = 0.26, indicating that accuracy significantly improved over sessions. Post-hoc Bonferroni comparisons showed that accuracy in later sessions was significantly higher than earlier sessions, suggesting a defined learning curve and consolidation of performance pattern across repeated practice. Similarly, there was significant improvement in timing accuracy between the first session g1; M = 0.29, SD = 0.06) and the fifth session (g5; M = 0.46, SD = 0.12). A repeated-measures ANOVA revealed a significant main effect of session on timing precision, F(4, 36) = 11.67, p < 0.001, 2G = 0.25, indicating significant improvements in temporal control and coordination over sessions. Post-hoc Bonferroni comparisons showed that timing precision significantly improved between early and late sessions (e.g, g1-g4, p <0.01; g1-g5, p < 0.001), suggesting a defined learning curve and increase in precision across repeated practice. These findings suggest that visual-motor-based interventions have the potential to enhance motor and non-motor symptoms like depression and anxiety for neurodegenerative diseases such as Parkinson's Disorder (PD). The results provide a foundation for developing targeted therapies that integrate learning paradigms to improve functional outcomes, warranting further exploration of their long-term efficacy.",
      "author": "Petrovski, M., Beheiry, S., Das, U. U., Rooprai, S., Karimi, A., Simon, J. R., Bar, R. J., DeSouza, J. F.",
      "published_date": "2026-01-26T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 518,
      "reading_time": 2,
      "created_at": "2026-01-26T20:30:05.527896+00:00",
      "updated_at": "2026-01-26T20:30:05.527899+00:00"
    },
    {
      "id": "f3968d6ca1a6621ed2cba328f550039a",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.23.701370v1?rss=1",
      "title": "Impaired Associative Memory, Inference, and Theta Dynamics in Postictal Psychosis of Epilepsy",
      "content": "Postictal psychosis (PIP) is a severe complication occurring in 2% of people with epilepsy (PWE) whose underlying pathophysiology remains poorly understood. Although historically considered separate from other forms of psychosis, newer evidence demonstrates a shared genetic susceptibility. People with schizophrenia are typically impaired at both associative learning and inferring connections between overlapping associations. Successful associative encoding, retrieval, and inference can each be predicted by changes in frontotemporal theta band activity, which is impaired in rodent models and people with schizophrenia. Here, we recorded high-density scalp EEG from PWE with history of PIP and well-matched control participants while they undertook a memory inference task. We found that associative memory and inference were both impaired in the PIP group, despite no difference in item recognition. Moreover, we found disrupted theta activity during memory encoding and the retrieval of inferred associations in PWE with PIP that likely originated from the medial temporal and frontal lobes. These results suggest a pattern of behavioural deficits and altered neural dynamics common to both PIP and schizophrenia. Interpreted in conjunction with previous genetic studies, they may reflect shared neural mechanisms contributing to psychopathology in both conditions and argue that PIP is a model of more general psychoses.",
      "author": "Dworkin, A., Wang, D., Jimenez, D., Ravenscroft, C., Turco, F., Johnson, C., Chowdhury, F. A., Pizarro, J., Walker, M., Balestrini, S., Bush, D., Vivekananda, U.",
      "published_date": "2026-01-26T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 200,
      "reading_time": 1,
      "created_at": "2026-01-26T20:30:05.527809+00:00",
      "updated_at": "2026-01-26T20:30:05.527811+00:00"
    },
    {
      "id": "89f6d50ed8bfe08d8cbc191c05268195",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.23.701367v1?rss=1",
      "title": "Systemic AAV delivery of a calcium indicator in marmosets: functional validation in visual area MT",
      "content": "Functional optical imaging in nonhuman primates provides an important complement to electrophysiological approaches in neuroscience research, but its broader use has been limited by challenges in achieving large-scale, homogeneous expression of genetically encoded reporters, and imaging accessibility in species with gyrencephalic brains with sulci and fissures (e.g., rhesus macaques). Specifically, conventional local intracortical viral injections are invasive and often produce spatially restricted or heterogeneous expression, constraining population-level analyses. Here, we show that systemic intravenous delivery of an adeno-associated virus (AAV) capsid engineered for enhanced blood-brain barrier crossing, AAV.CAP-B10, supports robust and widespread expression of a calcium indicator CAaMP8s in the common marmoset. Intravenous delivery in two marmosets resulted in widespread cortical expression. Using a large cranial window over extrastriate visual area MT (and its satellite areas), we performed widefield single-photon imaging and two-photon cellular-resolution imaging in awake,behaving marmosets to functionally validate activity in this well studied primate visual-motion sensitive cortical area. Population level responses to visual motion and spatial organization measured with widefield imaging, as well as single-cell level motion direction tuning measured with two-photon imaging, were consistent with canonical properties of MT reported in previous electrophysiological studies. Quantitative analyses of lightsheet imaging after whole hemisphere brain clearing further confirmed the broad expression of GCaMP in both cortical and subcortical areas. Together, these results indicate that systemic delivery using AAV.CAP-B10 provides a minimally invasive approach for robust multi-scale functional optical imaging in awake, behaving marmosets.",
      "author": "Chen, P.-S., Rowley, D. P., Rudd, M., Laudano, A., Villa, A. P., Garcia, F., Dong, H.-w., Shay, T. F., Huk, A. C., Steele, A. D., Wekselblatt, J.",
      "published_date": "2026-01-26T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 235,
      "reading_time": 1,
      "created_at": "2026-01-26T20:30:05.527774+00:00",
      "updated_at": "2026-01-26T20:30:05.527776+00:00"
    },
    {
      "id": "03ec6202da4bd0cff73daec2303723aa",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.23.700794v1?rss=1",
      "title": "Temporal Dynamics of EEG Decoding for Continuously Changing Visual Stimuli",
      "content": "Multivariate analyses of M/EEG data are typically performed on neural responses time-locked to discrete stimulus onsets. Such designs usually reveal high decoding performance during the initial transient response (0-500 ms), which subsequently drops to a lower, sustained level. Here, we examined time-resolved EEG decoding of natural scene processing when scenes gradually enter the visual field without a clear onset. We created video sequences in which one scene category (e.g., a beach) smoothly transitioned into another category (e.g., a forest) by blending images from two categories into a single composite panorama and moving a square aperture across it. We then compared EEG decoding for the first scenes within the transitions, which appeared with a sudden onset, to the second scenes, which emerged gradually as the videos progressed. For the first scenes, we observed robust category decoding from 60 ms after onset with a clear peak structure. For the second scene, category decoding was markedly weaker and showed no discernable peak structure. Realigning the appearance of category-diagnostic content for the second scene using deep neural networks did not enhance decoding or recover a peak structure. Further, classifiers trained on the first scene generalized to the second, but with a broad, temporally diffuse pattern, indicating that the second scene did not engage the same hierarchical temporal cascade as the first. Together, these results demonstrate that sudden versus gradual onsets produce distinct temporal decoding dynamics. Insights from onset-based decoding studies, therefore, do not straightforwardly extend to continuous and free-flowing natural stimulation.",
      "author": "Duymaz, I., Engeser, M., Kaiser, D.",
      "published_date": "2026-01-26T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 247,
      "reading_time": 1,
      "created_at": "2026-01-26T20:30:05.527729+00:00",
      "updated_at": "2026-01-26T20:30:05.527734+00:00"
    },
    {
      "id": "c89d2ad698747e7dcffde4a37776f9ab",
      "url": "https://www.nature.com/articles/s41593-025-02191-y",
      "title": "Rethinking the role of position in cortical function",
      "content": "<p>Nature Neuroscience, Published online: 08 January 2026; <a href=\"https://www.nature.com/articles/s41593-025-02191-y\">doi:10.1038/s41593-025-02191-y</a></p>Abnormally located cortical neurons, displaced in developing mice lacking cortical Eml1, retain their molecular identities, form appropriate connections and build functional sensory maps. Most strikingly, these misplaced neurons can drive behavior by themselves \u2014 showing that brain function depends on how neurons connect, and to what, more than where they live.",
      "author": "",
      "published_date": "2026-01-08T00:00:00+00:00",
      "source": "Nature Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 59,
      "reading_time": 1,
      "created_at": "2026-01-26T20:30:01.791580+00:00",
      "updated_at": "2026-01-26T20:30:01.791582+00:00"
    },
    {
      "id": "704e93957179c44d936aeac519f265d0",
      "url": "https://www.frontiersin.org/articles/10.3389/fncom.2025.1737839",
      "title": "Bridging neuromorphic computing and deep learning for next-generation neural data interpretation",
      "content": "",
      "author": "Zhiyuan Zhu",
      "published_date": "2026-01-08T00:00:00+00:00",
      "source": "Frontiers Computational Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2026-01-26T20:29:54.780642+00:00",
      "updated_at": "2026-01-26T20:29:54.780643+00:00"
    },
    {
      "id": "3061b8e679e36008588c7e3462b5a2f7",
      "url": "https://visualrambling.space/dithering-part-2/",
      "title": "Dithering \u2013 Part 2: The Ordered Dithering",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46770274\">Comments</a>",
      "author": "",
      "published_date": "2026-01-26T19:23:54+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-26T20:29:22.457521+00:00",
      "updated_at": "2026-01-26T20:29:22.457522+00:00"
    },
    {
      "id": "8b3f79354fbfa587a4aa7c0b16397bcd",
      "url": "https://danielsada.tech/blog/ai-lazyslop-and-personal-responsibility/",
      "title": "AI Lazyslop and Personal Responsibility",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46770675\">Comments</a>",
      "author": "",
      "published_date": "2026-01-26T19:56:18+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-26T20:29:22.457403+00:00",
      "updated_at": "2026-01-26T20:29:22.457409+00:00"
    },
    {
      "id": "3061b8e679e36008588c7e3462b5a2f7",
      "url": "https://visualrambling.space/dithering-part-2/",
      "title": "Dithering \u2013 Part 2: The Ordered Dithering",
      "content": "<p>Article URL: <a href=\"https://visualrambling.space/dithering-part-2/\">https://visualrambling.space/dithering-part-2/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46770274\">https://news.ycombinator.com/item?id=46770274</a></p>\n<p>Points: 19</p>\n<p># Comments: 2</p>",
      "author": "ChrisArchitect",
      "published_date": "2026-01-26T19:23:54+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2026-01-26T20:29:21.361052+00:00",
      "updated_at": "2026-01-26T20:29:21.361054+00:00"
    },
    {
      "id": "8b3f79354fbfa587a4aa7c0b16397bcd",
      "url": "https://danielsada.tech/blog/ai-lazyslop-and-personal-responsibility/",
      "title": "AI Lazyslop and Personal Responsibility",
      "content": "<p>Article URL: <a href=\"https://danielsada.tech/blog/ai-lazyslop-and-personal-responsibility/\">https://danielsada.tech/blog/ai-lazyslop-and-personal-responsibility/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46770675\">https://news.ycombinator.com/item?id=46770675</a></p>\n<p>Points: 22</p>\n<p># Comments: 21</p>",
      "author": "dshacker",
      "published_date": "2026-01-26T19:56:18+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2026-01-26T20:29:21.361022+00:00",
      "updated_at": "2026-01-26T20:29:21.361032+00:00"
    }
  ]
}