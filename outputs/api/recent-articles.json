{
  "last_updated": "2025-12-21T18:30:35.192951+00:00",
  "count": 20,
  "articles": [
    {
      "id": "951df1640c5c8172a766ff9895f8231f",
      "url": "https://www.reddit.com/r/Python/comments/1psab2c/i_built_a_python_bytecode_decompiler_covering/",
      "title": "I built a Python bytecode decompiler covering Python 1.0\u20133.14, runs on Node.js",
      "content": "<!-- SC_OFF --><div class=\"md\"><p><strong>What My Project Does</strong></p> <p>depyo is a Python bytecode decompiler that converts .pyc files back to readable Python source. It covers Python versions from 1.0 through 3.14, including modern features:</p> <p>- Pattern matching (match/case)</p> <p>- Exception groups (except*)</p> <p>- Walrus operator (:=)</p> <p>- F-strings</p> <p>- Async/await</p> <p>Quick start:</p> <pre><code>npx depyo file.pyc </code></pre> <p><strong>Target Audience</strong></p> <p>- Security researchers doing malware analysis or reverse engineering</p> <p>- Developers recovering lost source code from .pyc files</p> <p>- Anyone working with legacy Python codebases (yes, Python 1.x still exists in the wild)</p> <p>- CTF players and educators</p> <p>This is a production-ready tool, not a toy project. It has a full test suite covering all supported Python versions.</p> <p><strong>Comparison</strong></p> <table><thead> <tr> <th align=\"left\">Tool</th> <th align=\"left\">Versions</th> <th align=\"left\">Modern features</th> <th align=\"left\">Runtime</th> </tr> </thead><tbody> <tr> <td align=\"left\">depyo</td> <td align=\"left\">1.0\u20133.14</td> <td align=\"left\">Yes (match, except*, f-strings)</td> <td align=\"left\">Node.js</td> </tr> <tr> <td align=\"left\">uncompyle6/decompyle3</td> <td align=\"left\">2.x\u20133.12</td> <td align=\"left\">Partial</td> <td align=\"left\">Python</td> </tr> <tr> <td align=\"left\">pycdc</td> <td align=\"left\">2.x\u20133.x</td> <td align=\"left\">Limited</td> <td align=\"left\">C++</td> </tr> </tbody></table> <p>Main advantages:</p> <p>- Widest version coverage (30 years of Python)</p> <p>- No Python dependency - useful when decompiling old .pyc without version conflicts</p> <p>- Fast (~0.1ms per file)</p> <p>GitHub: <a href=\"https://github.com/skuznetsov/depyo.js\">https://github.com/skuznetsov/depyo.js</a></p> <p>Would love feedback, especially on edge cases!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ComputerMagych\"> /u/ComputerMagych </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1psab2c/i_built_a_python_bytecode_decompiler_covering/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1psab2c/i_built_a_python_bytecode_decompiler_covering/\">[comments]</a></span>",
      "author": "/u/ComputerMagych",
      "published_date": "2025-12-21T16:21:22+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 219,
      "reading_time": 1,
      "created_at": "2025-12-21T18:29:30.084792+00:00",
      "updated_at": "2025-12-21T18:29:30.084794+00:00"
    },
    {
      "id": "69f05ae1fe4e75df8fe54557f7460e5c",
      "url": "https://www.reddit.com/r/Python/comments/1psbzod/rug_0130_released/",
      "title": "rug 0.13.0 released",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>What's rug library:</p> <p>Library for fetching various stock data from the internet (official and unofficial APIs).</p> <p>Source code:</p> <p><a href=\"https://gitlab.com/imn1/rug\">https://gitlab.com/imn1/rug</a></p> <p>Releases including changelog:</p> <p><a href=\"https://gitlab.com/imn1/rug/-/releases\">https://gitlab.com/imn1/rug/-/releases</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/n1___\"> /u/n1___ </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1psbzod/rug_0130_released/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1psbzod/rug_0130_released/\">[comments]</a></span>",
      "author": "/u/n1___",
      "published_date": "2025-12-21T17:31:21+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 46,
      "reading_time": 1,
      "created_at": "2025-12-21T18:29:30.084754+00:00",
      "updated_at": "2025-12-21T18:29:30.084755+00:00"
    },
    {
      "id": "0dc5477bac0197cc967ddd88c3a6cd07",
      "url": "https://www.reddit.com/r/Python/comments/1ps39bq/how_far_into_a_learning_project_do_you_go/",
      "title": "How far into a learning project do you go",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>As a SWE student, it always feels like a race against my peers to land a job. Lately, though, web development has started to feel a bit boring for me and this new project, a custom text editor has been really fun and refreshing.</p> <p>Each new feature I add exposes really interesting problems and design concepts that I will never learn with web dev, and there\u2019s still so much I could implement or optimize. But I can\u2019t help but wonder, how do you know when a project has taken too much of your time and effort? A text editor might not sound impressive on a resume, but the learning experience has been huge.</p> <p>Would love to hear if anyone else has felt the same, or how you decide when to stick with a for fun learning project versus move on to something \u201cmore career-relevant.\u201d</p> <p>Here is the git hub: <a href=\"https://github.com/mihoagg/text_editor\">https://github.com/mihoagg/text_editor</a><br /> Any code review or tips are also much appreciated. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/getrice\"> /u/getrice </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1ps39bq/how_far_into_a_learning_project_do_you_go/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1ps39bq/how_far_into_a_learning_project_do_you_go/\">[comments]</a></span>",
      "author": "/u/getrice",
      "published_date": "2025-12-21T10:11:37+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 183,
      "reading_time": 1,
      "created_at": "2025-12-21T18:29:30.084730+00:00",
      "updated_at": "2025-12-21T18:29:30.084732+00:00"
    },
    {
      "id": "59e1d6d7ab76087f5ecda62e2bde13b6",
      "url": "https://www.reddit.com/r/Python/comments/1ps7gs4/whats_stopping_us_from_having_full_static/",
      "title": "What's stopping us from having full static validation of Python code?",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>I have developed two mypy plugins for Python to help with static checks (<a href=\"https://github.com/diegojromerolopez/mypy-pure\">mypy-pure</a> and <a href=\"https://github.com/diegojromerolopez/mypy-raise\">mypy-raise</a>)</p> <p>I was wondering, how far are we with providing such a high level of static checks for interpreted languages that almost all issues can be catch statically? Is there any work on that on any interpreted programming language, especially Python? What are the static tools that you are using in your Python projects?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/diegojromerolopez\"> /u/diegojromerolopez </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1ps7gs4/whats_stopping_us_from_having_full_static/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1ps7gs4/whats_stopping_us_from_having_full_static/\">[comments]</a></span>",
      "author": "/u/diegojromerolopez",
      "published_date": "2025-12-21T14:14:29+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 92,
      "reading_time": 1,
      "created_at": "2025-12-21T18:29:30.084692+00:00",
      "updated_at": "2025-12-21T18:29:30.084694+00:00"
    },
    {
      "id": "35cf8b93e74f04482a656d6bf2edece0",
      "url": "https://www.reddit.com/r/Python/comments/1ps1ab5/i_built_a_desktop_app_with_pythons_batteries/",
      "title": "I built a desktop app with Python's \"batteries included\" - Tkinter, SQLite, and minor soldering",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>Hi all. I work in a mass spectrometry laboratory at a large hospital in Rome, Italy. We analyze drugs, drugs of abuse, and various substances. I'm also a programmer.</p> <p>**What My Project Does**</p> <p>Inventarium is a laboratory inventory management system. It tracks reagents, consumables, and supplies through the full lifecycle: Products \u2192 Packages (SKUs) \u2192 Batches (lots) \u2192 Labels (individual items with barcodes).</p> <p>Features:</p> <p>- Color-coded stock levels (red/orange/green)</p> <p>- Expiration tracking with days countdown</p> <p>- Barcode scanning for quick unload</p> <p>- Purchase requests workflow</p> <p>- Statistics dashboard</p> <p>- Multi-language (IT/EN/ES)</p> <p>**Target Audience**</p> <p>Small laboratories, research facilities, or anyone needing to track consumables with expiration dates. It's a working tool we use daily - not a tutorial project.</p> <p>**What makes it interesting**</p> <p>I challenged myself to use only Python's &quot;batteries included&quot;:</p> <p>- Tkinter + ttk (GUI)</p> <p>- SQLite (database)</p> <p>- configparser, datetime, os, sys...</p> <p>External dependencies: just Pillow and python-barcode. No Electron, no web framework, no 500MB node_modules.</p> <p>**Screenshots:**</p> <p>- :Dashboard: <a href=\"https://ibb.co/JF2vmbmC\">https://ibb.co/JF2vmbmC</a></p> <p>- Warehouse: <a href=\"https://ibb.co/HTSqHF91\">https://ibb.co/HTSqHF91</a></p> <p>**GitHub:** <a href=\"https://github.com/1966bc/inventarium\">https://github.com/1966bc/inventarium</a></p> <p>Happy to answer questions or hear criticism. Both are useful.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Aggravating-Pain-626\"> /u/Aggravating-Pain-626 </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1ps1ab5/i_built_a_desktop_app_with_pythons_batteries/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1ps1ab5/i_built_a_desktop_app_with_pythons_batteries/\">[comments]</a></span>",
      "author": "/u/Aggravating-Pain-626",
      "published_date": "2025-12-21T08:01:25+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 201,
      "reading_time": 1,
      "created_at": "2025-12-21T18:29:30.084660+00:00",
      "updated_at": "2025-12-21T18:29:30.084664+00:00"
    },
    {
      "id": "e1fa2e76d69cec3266f32e5ca1f4c7d7",
      "url": "https://techcrunch.com/2025/12/21/waymo-suspends-service-in-san-francisco-as-robotaxis-stall-during-blackout/",
      "title": "Waymo suspends service in San Francisco as robotaxis stall during blackout",
      "content": "<p>Article URL: <a href=\"https://techcrunch.com/2025/12/21/waymo-suspends-service-in-san-francisco-as-robotaxis-stall-during-blackout/\">https://techcrunch.com/2025/12/21/waymo-suspends-service-in-san-francisco-as-robotaxis-stall-during-blackout/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46346510\">https://news.ycombinator.com/item?id=46346510</a></p>\n<p>Points: 17</p>\n<p># Comments: 4</p>",
      "author": "SilverElfin",
      "published_date": "2025-12-21T17:35:44+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-21T18:29:27.540195+00:00",
      "updated_at": "2025-12-21T18:29:27.540205+00:00"
    },
    {
      "id": "80d1f642eb4da0958753076107ac0cbe",
      "url": "http://daniellakens.blogspot.com/2025/07/easily-download-files-from-open-science.html",
      "title": "Easily download files from the Open Science Framework with Papercheck",
      "content": "<p>Researchers\nincreasingly use the <a href=\"https://osf.io/\">Open Science Framework</a> (OSF) to share files, such as data\nand code underlying scientific publications, or presentations and materials for\nscientific workshops. The OSF is an amazing service that has contributed\nimmensely to a changed research culture where psychologists share data, code, and\nmaterials. We are very grateful it exists.</p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">But it is\nnot always the most user-friendly. Specifically, downloading files from the OSF\nis a bigger hassle than we (<a href=\"https://debruine.github.io/\">Lisa DeBruine</a>\nand <a href=\"https://www.tue.nl/en/research/researchers/daniel-lakens/\">Daniel\nLakens</a>, the developers of Papercheck) would like it to be. Downloading individual\nfiles is so complex, <a href=\"https://bsky.app/profile/malte.the100.ci/post/3lpf4s6spns2i\">Malte Elson</a>\nrecently posted this meme on Bluesky. </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"NL\"><!--[if gte vml 1]><v:shapetype\n id=\"_x0000_t75\" coordsize=\"21600,21600\" o:spt=\"75\" o:preferrelative=\"t\"\n path=\"m@4@5l@4@11@9@11@9@5xe\" filled=\"f\" stroked=\"f\">\n <v:stroke joinstyle=\"miter\"/>\n <v:formulas>\n  <v:f eqn=\"if lineDrawn pixelLineWidth 0\"/>\n  <v:f eqn=\"sum @0 1 0\"/>\n  <v:f eqn=\"sum 0 0 @1\"/>\n  <v:f eqn=\"prod @2 1 2\"/>\n  <v:f eqn=\"prod @3 21600 pixelWidth\"/>\n  <v:f eqn=\"prod @3 21600 pixelHeight\"/>\n  <v:f eqn=\"sum @0 0 1\"/>\n  <v:f eqn=\"prod @6 1 2\"/>\n  <v:f eqn=\"prod @7 21600 pixelWidth\"/>\n  <v:f eqn=\"sum @8 21600 0\"/>\n  <v:f eqn=\"prod @7 21600 pixelHeight\"/>\n  <v:f eqn=\"sum @10 21600 0\"/>\n </v:formulas>\n <v:path o:extrusionok=\"f\" gradientshapeok=\"t\" o:connecttype=\"rect\"/>\n <o:lock v:ext=\"edit\" aspectratio=\"t\"/>\n</v:shapetype><v:shape id=\"_x0000_i1026\" type=\"#_x0000_t75\" style='width:453.75pt;\n height:276pt;visibility:visible;mso-wrap-style:square'>\n <v:imagedata src=\"file:///C:/Users/DLakens/AppData/Local/Temp/msohtmlclip1/01/clip_image001.jpg\"\n  o:title=\"\"/>\n</v:shape><![endif]--><!--[if !vml]--><img border=\"0\" height=\"368\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEinS5tFoL5qX14Z2OcgT1APMZLGlghAD3BfBhSnJ9pleVbJyRFUFLShqReS2j7SXGozmLMcVQkoM62UhneJDtH4yx3NRnXOkVZZi-Dm-OPwbGaidxr2raF9wzjx5fU92nfPpE3jmGfwZEwHS1WGSB4gUfRfV3XWjOC2-lCjOYR108h3fwORIHOnqxIX9m8\" width=\"605\" /><!--[endif]--></span><span lang=\"EN-US\"></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\"><span>&nbsp;</span></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">Not only is\nthe download button for files difficult to find, but downloading all files\nrelated to a project can be surprisingly effortful. It is possible to download\nall files in a zip folder that will be called \u2018osfstorage-archive.zip\u2019 when\ndownloaded. But as the OSF supports a nested folder structure, you might miss a\nfolder, and you will quickly end up with \u2018osfstorage-archive (1).zip\u2019, \u2018osfstorage-archive\n(2).zip\u2019, etc. Unzipping these archives creates a lot of files without the\norganized folder structure, in folders with meaningless names, making it\ndifficult to understand where files are. </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<h2 style=\"text-align: left;\"><b><span lang=\"EN-US\">The\nosf_file_download function in Papercheck </span></b></h2>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">We have added\na new function to our R package \u2018<a href=\"https://scienceverse.github.io/papercheck/\">Papercheck</a>\u2019 that will download all files and\nfolders in an OSF repository. It saves all files by recreating the folder\nstructure from the OSF in your download folder. Just install Papercheck, load\nthe library, and use the osf_file_download function to grab all files on the OSF:</span></p><p class=\"MsoNormal\"><span lang=\"EN-US\"><br /></span></p>\n\n<div style=\"text-align: left;\"><span style=\"font-family: courier;\"><b><span lang=\"EN-US\">devtools::install_github(\"scienceverse/papercheck\")<br /></span></b><b><span lang=\"EN-US\">library(papercheck)<br /></span></b><b><span lang=\"EN-US\">osf_file_download(\"6nt4v\")</span></b></span></div>\n\n\n\n\n\n<p class=\"MsoNormal\"><b><span lang=\"EN-US\">&nbsp;</span></b></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">All files\nwill be downloaded to your working directory. </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">Are you feeling\nFOMO for missing out on the <a href=\"https://www.kcl.ac.uk/events/open-research-summer-school-2025\">King Open\nResearch Summer School</a> that is going on these days, where <a href=\"https://research.tue.nl/en/persons/sajedeh-rasti\">Sajedeh Rasti</a> talked\nabout Preregistration, and <a href=\"https://research.tue.nl/en/persons/cristian-mesquida-caldentey\">Cristian\nMesquida</a> will give a workshop on using Papercheck? Well, at least it is\nvery easy to download all the files they have shared on the OSF and look at the\npresentations: </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\"><span style=\"font-family: courier;\">osf_file_download(\"b7es8\")</span></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">In the\noutput, we see that by default large files (more than 10mb) are omitted. <span><!--[if gte vml 1]><v:shape id=\"Picture_x0020_1\"\n o:spid=\"_x0000_i1025\" type=\"#_x0000_t75\" alt=\"A screenshot of a computer&#10;&#10;AI-generated content may be incorrect.\"\n style='width:453.75pt;height:292.5pt;visibility:visible;mso-wrap-style:square'>\n <v:imagedata src=\"file:///C:/Users/DLakens/AppData/Local/Temp/msohtmlclip1/01/clip_image003.png\"\n  o:title=\"A screenshot of a computer&#10;&#10;AI-generated content may be incorrect\"/>\n</v:shape><![endif]--><!--[if !vml]--><img alt=\"A screenshot of a computer\n\nAI-generated content may be incorrect.\" border=\"0\" height=\"390\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEj2jH76ywmEeLzL43u6gJl7GKR2lEGlhYS0LOXRPMMovOsJEVdXyamYCvmq96ez3p_GXHLoFz4JDyAKHlARK9pSy8QfzVa7yt1_uEg_H9IJfKgunnYWUwlROXABNcU6TvrA0_hx0KPZfj00b3Cb-Wn_7Bf3sFu9JApZoClcWoh_Vfl5bk1GQVZUH1tuGao\" width=\"605\" /><!--[endif]--></span></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">If you want\nto download all files, regardless of the size, then set the parameter to ignore\nthe maximum file size: </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\"><span style=\"font-family: courier;\">osf_file_download(\"b7es8\",\nmax_file_size = NULL)</span></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">Sometimes\nyou might want to download all files but ignore the file structure on the OSF,\nto just have all the files in one folder. Setting the parameter ignore_folder_structure\n= TRUE will give you all the files on the OSF in a single folder. By default, files will be downloaded into your working directory, but you can also specify\nwhere you want the files to be saved. </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\"><span style=\"font-family: courier;\">osf_file_download(\"6nt4v\",\nignore_folder_structure = TRUE, download_to = \"C:\\\\test_download\")</span></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">We hope\nthis function will make it easier for reviewers to access all supplementary\nfiles stored on the OSF during peer review, and for researchers who want to re-use\ndata, code, or materials shared on the OSF by downloading all the files they\nneed easily. Make sure to install the latest version of Papercheck (0.0.0.9050)\nto get access to this new function. Papercheck is still in active development,\nso report any bugs on <a href=\"https://github.com/scienceverse/papercheck\">GitHub</a>.</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>",
      "author": "noreply@blogger.com (Daniel Lakens)",
      "published_date": "2025-07-22T09:53:00+00:00",
      "source": "Twenty Percent Statistician",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 765,
      "reading_time": 3,
      "created_at": "2025-12-21T17:42:08.997761+00:00",
      "updated_at": "2025-12-21T18:21:38.678392+00:00",
      "metadata": {
        "processed_at": "2025-12-21T18:21:38.678401+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "bd7398ecbbd90ecd3269866b2fd3744f",
      "url": "https://erpinfo.org/blog/2023/6/23/decoding-webinar",
      "title": "ERP Decoding for Everyone: Software and Webinar",
      "content": "<p class=\"\"><strong>You can access the recording </strong><a href=\"https://video.ucdavis.edu/media/Virtual+ERP+Boot+CampA+Decoding+for+Everyone%2C+July+25+2023/1_lmwj6bu0\"><strong>here</strong></a><strong>.<br />You can access the final PDF of the slides </strong><a href=\"https://ucdavis.box.com/s/flf9gzeo12rz2jhxptih7xjl0omka2k7\"><strong>here</strong></a><strong>. <br />You can access the data </strong><a href=\"https://doi.org/10.18115/D5KS6S\"><strong>here</strong></a><strong>.</strong></p><p class=\"\">fMRI research has used decoding methods for over 20 years. These methods make it possible to decode what an individual is perceiving or holding in working memory on the basis of the pattern of BOLD activity across voxels. Remarkably, these methods can also be applied to ERP data, using the pattern of voltage across electrode sites rather than the pattern of activity across voxels to decode the information being represented by the brain (<a href=\"https://erpinfo.org/blog/2018/9/16/decoding\">see this previous blog post</a>). For example, ERPs can be used to decode the identity of a face that is being perceived, the emotional valence of a scene, the identity and semantic category of a word, and the features of an object that is being maintained in working memory. Moreover, decoding methods can be more sensitive than traditional methods for detecting conventional ERP effects (e.g., whether a word is semantically related or unrelated to a previous word in an N400 paradigm).</p><p class=\"\">So far, these methods have mainly been used by a small set of experts. We aim to change that with the upcoming Version 10 of <a href=\"https://erpinfo.org/erplab\">ERPLAB Toolbox</a>. This version of ERPLAB will contain an ERP decoding tool that makes it trivially easy for anyone who knows how to do conventional ERP processing to take advantage of the power of decoding. It should be available in mid-July at <a href=\"https://github.com/ucdavis/erplab/releases\">our GitHub site</a>. You can join the <a href=\"https://github.com/ucdavis/erplab/wiki/ERPLAB-email-list\">ERPLAB email list</a> to receive an announcement when this version is released. Please do not contact us with questions until it has been released and you have tried using it.</p><p class=\"\">On July 25, 2023, we will hold a 2-hour Zoom webinar to explain how decoding works at a conceptual level and show how to implement in ERPLAB Toolbox. The webinar will begin at 9:00 AM Pacific Time (California), 12:00 PM Eastern Time (New York), 5:00 PM British Summer Time (London), 6:00 PM Central European Summer Time (Berlin). </p><p class=\"\">The webinar is co-sponsored by the <a href=\"https://erpinfo.org/the-erp-boot-camp\">ERP Boot Camp</a> and the <a href=\"https://sprweb.org\">Society for Psychophysiological Research</a>. It is completely free, but you must register in advance at <a href=\"https://ucdavis.zoom.us/meeting/register/tJUrc-CtpzorEtBSmZXJINOlLJB9ZR0evpr4\">https://ucdavis.zoom.us/meeting/register/tJUrc-CtpzorEtBSmZXJINOlLJB9ZR0evpr4</a>. Once you register, you will receive an email with your own individual Zoom link. </p><p class=\"\">We will make a recording available a few days after the webinar on the <a href=\"https://erpinfo.org\">ERPinfo.org</a> web site.</p><p class=\"\">Please direct any questions about the webinar to <a href=\"mailto:erpbootcamp@gmail.com\">erpbootcamp@gmail.com</a>.</p>",
      "author": "Steve Luck",
      "published_date": "2023-06-23T21:05:26+00:00",
      "source": "Erp Boot Camp",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 420,
      "reading_time": 2,
      "created_at": "2025-12-21T17:42:06.389036+00:00",
      "updated_at": "2025-12-21T18:21:38.678405+00:00",
      "metadata": {
        "processed_at": "2025-12-21T18:21:38.678423+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "3d370217cb4a351bb54e7854066e15c3",
      "url": "https://erpinfo.org/blog/2024/2/4/optimal-filters",
      "title": "New Papers: Optimal Filter Settings for ERP Research",
      "content": "<p class=\"\">Zhang, G., Garrett, D. R., &amp; Luck, S. J. (in press). Optimal filters for ERP research I: A general approach for selecting filter settings. <em>Psychophysiology</em>. <a href=\"https://doi.org/10.1111/psyp.14531\"><span>https://doi.org/10.1111/psyp.14531</span></a> [<a href=\"https://www.researchgate.net/publication/377773270_Optimal_filters_for_ERP_research_I_A_general_approach_for_selecting_filter_settings\"><span>preprint</span></a>]</p><p class=\"\">Zhang, G., Garrett, D. R., &amp; Luck, S. J. (in press). Optimal filters for ERP research II: Recommended settings for seven common ERP components. <em>Psychophysiology</em>. <a href=\"https://doi.org/10.1111/psyp.14530\"><span>https://doi.org/10.1111/psyp.14530</span></a> [<a href=\"https://www.researchgate.net/publication/377766656_Optimal_filters_for_ERP_research_II_Recommended_settings_for_seven_common_ERP_components\"><span>preprint</span></a>]</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1490\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/d64086cc-e3b4-457d-89df-08d9b3f96439/Filter_Table.png?format=1000w\" width=\"2062\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">What filter settings should you apply to your ERP data? If your filters are too weak to attenuate the noise in your data, your effects may not be statistically significant. If your filters are too strong, they may create artifactual peaks that lead you to draw bogus conclusions.</p><p class=\"\">For years, I have been recommending a bandpass of 0.1\u201330 Hz for most cognitive and affective research in neurotypical young adults. In this kind of research, I have found that filtering from 0.1\u201330 Hz usually does a good job of minimizing noise while creating minimal waveform distortion. </p><p class=\"\">However, this recommendation was based on a combination of informal observations from many experimental paradigms and a careful examination of a couple paradigms, so it was a bit hand-wavy. In addition, the optimal filter settings will depend on the waveshape of the ERP effects and the nature of the noise in a given study, so I couldn\u2019t make any specific recommendations about other experimental paradigms and participant populations. Moreover, different filter settings may be optimal for different scoring methods (e.g., mean amplitude vs. peak amplitude vs. peak latency).</p><p class=\"\">Guanghui Zhang, David Garrett, and I spent the last year focusing on this issue. First we developed a general method that can be used to determine the optimal filter settings for a given dataset and scoring method (see <a href=\"https://doi.org/10.1111/psyp.14531\"><span>this paper</span></a>). Then we applied this method to the <a href=\"https://doi.org/10.1016/j.neuroimage.2020.117465\"><span>ERP CORE</span></a> data to determine the optimal filter settings for the N170, MMN, P3b, N400, N2pc, LRP, and ERN components in neurotypical young adults (see <a href=\"https://doi.org/10.1111/psyp.14530\"><span>this paper</span></a> and the table above).</p><p class=\"\">If you are doing research with these components (or similar components) in neurotypical young adults, you can simply use the filter settings that we identified. If you are using a very different paradigm or testing a very different subject population, you can apply our method to your own data to find the optimal settings. We added some new tools to <a href=\"https://github.com/ucdavis/erplab\"><span>ERPLAB Toolbox</span></a> to make this easier.</p><p class=\"\">One thing that we discovered was that our old recommendation of 0.1\u201330 Hz does a good job of avoiding filter artifacts but is overly conservative for some components. For example, we can raise the low end to 0.5 Hz when measuring N2pc and MMN amplitudes, which gets rid of more noise without producing problematic waveform distortions. And we can go all the way up to 0.9 Hz for the N170 component. However, later/slower components like P3b and N400 require lower cutoffs (no higher than 0.2 Hz).</p><p class=\"\">You might be wondering how we defined the \u201coptimal\u201d filter settings. At one level, the answer is simple: The optimal filter is the one that maximizes the signal-to-noise ratio without producing too much waveform distortion. The complexities arise in quantifying the signal-to-noise ratio, quantifying the waveform distortion, and deciding how much waveform distortion is \u201ctoo much\u201d. We believe we have found reasonably straightforward and practical solutions to these problems, which you can read about in the published papers.</p>",
      "author": "Steve Luck",
      "published_date": "2024-02-04T23:46:20+00:00",
      "source": "Erp Boot Camp",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 568,
      "reading_time": 2,
      "created_at": "2025-12-21T17:42:06.388988+00:00",
      "updated_at": "2025-12-21T18:21:38.678426+00:00",
      "metadata": {
        "processed_at": "2025-12-21T18:21:38.678428+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "36b12e5d65cfdd2edab0a64a9e2585d3",
      "url": "https://www.scd31.com/posts/programming-on-the-subway",
      "title": "I Program on the Subway",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46294694\">Comments</a>",
      "author": "",
      "published_date": "2025-12-16T21:23:18+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-21T17:41:05.475428+00:00",
      "updated_at": "2025-12-21T18:21:38.678430+00:00",
      "metadata": {
        "processed_at": "2025-12-21T18:21:38.678432+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "b3cd4fc4257e4deef4e24f2c3cdd8b67",
      "url": "https://brain.ieee.org/publications/neuroethics-framework/education/education-social-and-cultural-issues/education-social-and-cultural-issues/",
      "title": "Education: Social and Cultural Issues",
      "content": "Devices that therapeutically aid users with cognitive and learning disabilities/differences should not be equally applied to a general population seeking learning advantages. It must not be assumed that therapies able to improve cognition for mental and cognitive disorders (such as executive control and working memory) would work similarly on nondisabled people linearly to improve their cognition above standard levels. Although ...",
      "author": "Adriel Carridice",
      "published_date": "2025-02-05T15:45:23+00:00",
      "source": "Brain",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 61,
      "reading_time": 1,
      "created_at": "2025-12-21T17:19:18.438367+00:00",
      "updated_at": "2025-12-21T18:21:38.678434+00:00",
      "metadata": {
        "processed_at": "2025-12-21T18:21:38.678435+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "1348eff8059203eea8f1cf0c47dfeafd",
      "url": "https://brain.ieee.org/podcasts/qa-with-dr-richard-carson-professor-of-biomedical-engineering-and-radiology-biomedical-imaging-yale-university-and-yale-school-of-medicine/",
      "title": "Q&A with Dr. Richard Carson, Professor of Biomedical Engineering and Radiology & Biomedical Imaging, Yale University and Yale School of Medicine",
      "content": "",
      "author": "Adriel Carridice",
      "published_date": "2025-11-04T18:24:59+00:00",
      "source": "Brain",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-12-21T17:19:18.438158+00:00",
      "updated_at": "2025-12-21T17:19:18.438161+00:00"
    },
    {
      "id": "bad5757f306a00dd069fd23d649636a6",
      "url": "http://ieeexplore.ieee.org/document/10856219",
      "title": "IEEE Reviews in Biomedical Engineering (R-BME)",
      "content": "null",
      "author": "",
      "published_date": "2025-01-28T13:17:19+00:00",
      "source": "Reviews Biomedical Engineering",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 1,
      "reading_time": 1,
      "created_at": "2025-12-21T17:19:13.986760+00:00",
      "updated_at": "2025-12-21T17:19:13.986762+00:00"
    },
    {
      "id": "ceca395de40b84db3d5efa8f4a77ad99",
      "url": "https://hackernews-readings-613604506318.us-west1.run.app",
      "title": "Show HN: Books mentioned on Hacker News in 2025",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46345897\">Comments</a>",
      "author": "",
      "published_date": "2025-12-21T16:21:04+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-21T17:18:22.990496+00:00",
      "updated_at": "2025-12-21T17:18:22.990497+00:00"
    },
    {
      "id": "ceca395de40b84db3d5efa8f4a77ad99",
      "url": "https://hackernews-readings-613604506318.us-west1.run.app",
      "title": "Show HN: Books mentioned on Hacker News in 2025",
      "content": "<p>Article URL: <a href=\"https://hackernews-readings-613604506318.us-west1.run.app\">https://hackernews-readings-613604506318.us-west1.run.app</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46345897\">https://news.ycombinator.com/item?id=46345897</a></p>\n<p>Points: 16</p>\n<p># Comments: 3</p>",
      "author": "seinvak",
      "published_date": "2025-12-21T16:21:04+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-21T17:18:21.541377+00:00",
      "updated_at": "2025-12-21T17:18:21.541379+00:00"
    },
    {
      "id": "01a0c9001a6aac267cb0072bda62db43",
      "url": "http://doi.org/10.1037/pmu0000303",
      "title": "Implicit learning of melodic structure: A role for pitch?",
      "content": "Growing evidence suggests that pitch influences musical processing, with melodic processing being enhanced in higher pitch ranges (e.g., Fujioka et al., 2005) and rhythmic processing being enhanced in lower pitches, and these effects may have a basis in elementary properties of the auditory system (e.g., Hove et al., 2014). As such, pitch may constitute a fundamental constraint on the mechanisms that underpin musical learning. One such mechanism is implicit learning: the ability to learn from mere exposure without intention and without a clear awareness of what has been learned. The present study examined whether the high pitch effects that enhance melodic processing extend to implicit learning of melodic structure as well. In an artificial melodic grammar experiment, it was found that participants learned melodic structure better when instantiated in a lower rather than a higher pitch range. We propose that hearing melodies in lower pitch ranges attracts more attention, because melodic information is usually instantiated in higher pitches, and lower pitch melodies may cause attention to shift leading to more learning. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2024-01-22T00:00:00+00:00",
      "source": "Psychomusicology",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 180,
      "reading_time": 1,
      "created_at": "2025-12-21T16:47:20.467990+00:00",
      "updated_at": "2025-12-21T16:47:20.467991+00:00"
    },
    {
      "id": "f5d48b717c919893f96492998ce36e60",
      "url": "http://doi.org/10.1037/cns0000368",
      "title": "Autonomous sensory meridian response (ASMR): A PRISMA-guided systematic review.",
      "content": "The present PRISMA-guided article systematically reviews the current state of research on the autonomous sensory meridian response (ASMR). A systematic literature search was conducted in Pubmed, SCOPUS, and Web of Science (last search: March 2022) selecting all studies that conducted quantitative scientific research on the ASMR phenomenon. Fifty-four studies focusing on ASMR were retrieved (total participant number: <em>n</em> = 11,140). ASMR can be linked to several mental health-related variables (e.g., improved mood) and personality traits (e.g., neuroticism). On the neurobiological level, ASMR has been associated with altered electrophysiological response patterns (tentatively suggesting \u03b4 wave decreases), activation of specific brain areas (particularly the anterior cingulate gyrus and movement-related regions), and atypical functional connectivity patterns as well as physiological changes such as heart rate reduction. Future studies should evaluate the link between ASMR and additional psychological constructs, reveal more specific neurobiological outcome patterns and conduct long-term ASMR intervention studies. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2023-11-02T00:00:00+00:00",
      "source": "Clinical Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 156,
      "reading_time": 1,
      "created_at": "2025-12-21T16:47:18.819372+00:00",
      "updated_at": "2025-12-21T16:47:18.819373+00:00"
    },
    {
      "id": "2632ffdea823fa8469a9429df37c1901",
      "url": "http://doi.org/10.1037/cns0000352",
      "title": "Social bodies: Preliminary evidence that awareness of embodied emotions is associated with recognition of emotions in the bodily cues of others.",
      "content": "We experience and express emotions via our bodies, and we are also able to infer the emotional states of others by observing their movements and postures. The ability to extract affective bodily cues in social contexts may be achieved via internal simulation, which is closely associated with experience and awareness of emotions in one\u2019s own body. Here, we hypothesized that reports of one\u2019s own bodily experiences of emotions would be associated with the ability to infer other people\u2019s emotions from their bodily signals. Healthy individuals (<em>n</em> = 106) participated in two tasks. An emotional gait perception task was used to test the ability to extract emotional cues from other people\u2019s body movements. Subjective bodily experience of emotions was visualized with a computerized mapping tool, which required participants to localize sensations on the body corresponding to specific emotions. Participants reported specific locations of body sensations for different emotions. Emotional gait perception accuracy was positively associated with participants\u2019 reported intensity for bodily experiences of happiness and anger and with their tendency to report body mapping patterns similar to prototypes established in a much larger sample. Results suggest that awareness of emotions in one\u2019s own body is related to our ability to perceive emotions in others. Implications for future work on the role of embodiment in social cognition and psychiatric disorders are discussed. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2023-03-06T00:00:00+00:00",
      "source": "Clinical Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 229,
      "reading_time": 1,
      "created_at": "2025-12-21T16:47:18.819338+00:00",
      "updated_at": "2025-12-21T16:47:18.819339+00:00"
    },
    {
      "id": "557b09c5edb6880dd9185b2d70c061a8",
      "url": "https://nytpu.com/gemlog/2025-12-21",
      "title": "ELF Crimes: Program Interpreter Fun",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46345975\">Comments</a>",
      "author": "",
      "published_date": "2025-12-21T16:30:09+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-21T16:47:08.735189+00:00",
      "updated_at": "2025-12-21T16:47:08.735191+00:00"
    },
    {
      "id": "b231a1d940bf2aac716604b7efb10a70",
      "url": "https://walletwallet.alen.ro/",
      "title": "Show HN: WalletWallet \u2013 create Apple passes from anything",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46345745\">Comments</a>",
      "author": "",
      "published_date": "2025-12-21T16:04:05+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-21T16:47:08.735071+00:00",
      "updated_at": "2025-12-21T16:47:08.735073+00:00"
    }
  ]
}