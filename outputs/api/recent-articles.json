{
  "last_updated": "2025-11-10T20:18:26.378711+00:00",
  "count": 20,
  "articles": [
    {
      "id": "ad1925564c97f30cab5b55e76f20793b",
      "url": "https://www.embs.org/blog-post/regional-shifts-and-patterns/",
      "title": "Bridging Biotech: Regional shifts and patterns",
      "content": "<p>The post <a href=\"https://www.embs.org/blog-post/regional-shifts-and-patterns/\">Bridging Biotech: Regional shifts and patterns</a> appeared first on <a href=\"https://www.embs.org\">IEEE EMBS</a>.</p>",
      "author": "dziura",
      "published_date": "2025-02-05T15:45:50+00:00",
      "source": "Embs",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 15,
      "reading_time": 1,
      "created_at": "2025-11-10T19:39:14.414263+00:00",
      "updated_at": "2025-11-10T20:18:26.297324+00:00",
      "metadata": {
        "processed_at": "2025-11-10T20:18:26.297334+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "6b5f32570094f1cedcde640a7566d20a",
      "url": "https://www.embs.org/blog-post/welcoming-dr-ana-kyani-as-wibme-chair-ieee-embs/",
      "title": "Welcoming Dr. Ana Kyani as the New Women in Biomedical Engineering Chair for IEEE EMBS",
      "content": "<p>The post <a href=\"https://www.embs.org/blog-post/welcoming-dr-ana-kyani-as-wibme-chair-ieee-embs/\">Welcoming Dr. Ana Kyani as the New Women in Biomedical Engineering Chair for IEEE EMBS</a> appeared first on <a href=\"https://www.embs.org\">IEEE EMBS</a>.</p>",
      "author": "Nancy Zimmerman",
      "published_date": "2025-03-27T17:10:33+00:00",
      "source": "Embs",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 24,
      "reading_time": 1,
      "created_at": "2025-11-10T19:39:14.414245+00:00",
      "updated_at": "2025-11-10T20:18:26.297337+00:00",
      "metadata": {
        "processed_at": "2025-11-10T20:18:26.297339+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "138dbc20af95ce55414e7d62214f9607",
      "url": "https://www.embs.org/press/embc-eic-sunghoon-ivan-lee/#new_tab",
      "title": "Ivan Lee, Appointed Editor-in-Chief of EMBC Proceedings",
      "content": "<p>&#160;</p>\n<p>The post <a href=\"https://www.embs.org/press/embc-eic-sunghoon-ivan-lee/#new_tab\">Ivan Lee, Appointed Editor-in-Chief of EMBC Proceedings</a> appeared first on <a href=\"https://www.embs.org\">IEEE EMBS</a>.</p>",
      "author": "Nancy Zimmerman",
      "published_date": "2025-09-08T16:27:03+00:00",
      "source": "Embs",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 17,
      "reading_time": 1,
      "created_at": "2025-11-10T19:39:14.414099+00:00",
      "updated_at": "2025-11-10T20:18:26.297341+00:00",
      "metadata": {
        "processed_at": "2025-11-10T20:18:26.297343+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "a3728a2104d4c9bf44826458098ffc9e",
      "url": "https://arxiv.org/abs/2511.05400",
      "title": "Designing Hierarchical Exploratory Experiences for Ethnic Costumes: A Cultural Gene-Based Perspective",
      "content": "arXiv:2511.05400v1 Announce Type: new \nAbstract: Ethnic clothing is a vital carrier of cultural identity, yet its digital preservation often results in static displays that fail to convey deep cultural meaning or foster user engagement. Existing practices lack a systematic design framework for translating the hierarchical cultural connotations of these garments into dynamic, personalized, and identity-promoting digital experiences. To address this gap, this paper proposes a Three-Layer Cultural Gene Framework that systematically decodes ethnic costumes from their surface-level visual symbols, through their mid-level socio-cultural contexts, to their inner-layer spiritual core. Based on this framework, we designed and implemented an interactive digital platform featuring two key innovations: a \"gene-first\" exploratory path that encourages curiosity-driven discovery, and an AI-powered co-creation experience. This generative feature allows users to co-create personalized narratives and images based on their understanding of the \"inner-layer\" genes, transforming them from passive observers into active co-creators. A mixed-methods user study (N=24) was conducted to evaluate the platform. The findings demonstrate that our approach effectively enhances users' cultural cognition, deepens their affective connection, and significantly promotes their sense of cultural identity. This research contributes a validated framework and a practical exemplar for designing generative, identity-building digital experiences for cultural heritage, offering a new pathway for its preservation and revitalization in the digital age.",
      "author": "Ma Xiaofan, Yan Lirong, Zhao Weijia, Zeng Weiping, Wu Huiyue",
      "published_date": "2025-11-10T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 211,
      "reading_time": 1,
      "created_at": "2025-11-10T19:39:11.714206+00:00",
      "updated_at": "2025-11-10T20:18:26.297345+00:00",
      "metadata": {
        "processed_at": "2025-11-10T20:18:26.297346+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "d4e2280b68d0a7a8c97dc66275dff57b",
      "url": "https://arxiv.org/abs/2511.05346",
      "title": "Semantic Interactivity: leveraging NLP to enable a shared interaction approach for joint activities",
      "content": "arXiv:2511.05346v1 Announce Type: new \nAbstract: Collocated collaboration, where individuals work together in the same physical space and time, remains a cornerstone of effective teamwork. However, most collaborative systems are designed to support individual tasks rather than joint activities; they enable interactions for users to complete tasks rather than interactivity to engage in shared experiences. In this work, we introduce an NLP-driven mechanism that enables semantic interactivity through a shared interaction mechanism. This mechanism was developed as part of CollEagle, an interactive tabletop system that supports shared externalisation practices by offering a low-effort way for users to create, curate, organise, and structure information to capture the essence of collaborative discussions. Our preliminary study highlights the potential for semantic interactivity to mediate group interactions, suggesting that the interaction approach paves the way for designing novel collaborative interfaces. We contribute our implementation and offer insights for future research to enable semantic interactivity in systems that support joint activities.",
      "author": "Olaf V. Adan, Dimitra Dritsa, Steven Houben",
      "published_date": "2025-11-10T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 155,
      "reading_time": 1,
      "created_at": "2025-11-10T19:39:11.714172+00:00",
      "updated_at": "2025-11-10T20:18:26.297349+00:00",
      "metadata": {
        "processed_at": "2025-11-10T20:18:26.297350+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "5e0c009a3bfa69f9ec436400fbf9e420",
      "url": "https://arxiv.org/abs/2511.05304",
      "title": "psiUnity: A Platform for Multimodal Data-Driven XR",
      "content": "arXiv:2511.05304v1 Announce Type: new \nAbstract: Extended reality (XR) research increasingly relies on the ability to stream and synchronize multimodal data between headsets and immersive applications for data-driven interaction and experimentation. However, developers face a critical gap: the Platform for Situated Intelligence (psi), which excels at deterministic temporal alignment and multimodal data management, has been largely inaccessible to the dominant Unity/MRTK ecosystem used for HoloLens development. We introduce psiUnity, an open-source C# integration that bridges psi's .NET libraries with Unity 2022.3 and MRTK3 for HoloLens 2. psiUnity enables bidirectional, real-time streaming of head pose, hand tracking, gaze, IMU, audio, and depth sensor data (AHAT and long-throw) with microsecond-level temporal precision, allowing Unity applications to both consume and produce synchronized multimodal data streams. By embedding psi's native serialization, logging, and temporal coordination directly within Unity's architecture, psiUnity extends psi beyond its previous StereoKit limitations and empowers the HRI, HCI, and embodied-AI communities to develop reproducible, data-driven XR interactions and experiments within the familiar Unity environment. The integration is available at https://github.com/sailgt/psiUnity.",
      "author": "Akhil Ajikumar, Sahil Mayenkar, Steven Yoo, Sakib Reza, Mohsen Moghaddam",
      "published_date": "2025-11-10T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 169,
      "reading_time": 1,
      "created_at": "2025-11-10T19:39:11.714143+00:00",
      "updated_at": "2025-11-10T19:39:11.714144+00:00"
    },
    {
      "id": "0a95d44ac0dc87d234be27a38ef34c12",
      "url": "https://arxiv.org/abs/2511.05136",
      "title": "Interface Homme-Machine pour l'Identification des Liaisons de Coins",
      "content": "arXiv:2511.05136v1 Announce Type: new \nAbstract: ACCADIL is a project that led to the development of software tools for the identification of coin die links from coin photographs. It provides a computational algorithm based on computer vision and classification techniques, along with an online interface for the interactive verification of results. This guide briefly describes the algorithmic principles, the preparation of data prior to analysis, and the features offered by the interface: dataset addition, visualization modes (overlay, side-by-side, magnifier, transparency), result export, and distance visualization. ACCADIL thus provides numismatists with a comprehensive tool for the analysis of die links within a coin collection.",
      "author": "Patrice Labedan, Nicolas Drougard",
      "published_date": "2025-11-10T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 102,
      "reading_time": 1,
      "created_at": "2025-11-10T19:39:11.714111+00:00",
      "updated_at": "2025-11-10T19:39:11.714113+00:00"
    },
    {
      "id": "a1d56525dea5f2c518af6ecb691174a9",
      "url": "https://arxiv.org/abs/2511.05094",
      "title": "FM4Com: Foundation Model for Scene-Adaptive Communication Strategy Optimization",
      "content": "arXiv:2511.05094v1 Announce Type: new \nAbstract: The emergence of sixth-generation (6G) networks heralds an intelligent communication ecosystem driven by AI-native air interfaces. However, current physical-layer designs-typically following modular and isolated optimization paradigms-fail to achieve global end-to-end optimality due to neglected inter-module dependencies. Although large language models (LLMs) have recently been applied to communication tasks such as beam prediction and resource allocation, existing studies remain limited to single-task or single-modality scenarios and lack the ability to jointly reason over communication states and user intents for personalized strategy adaptation. To address these limitations, this paper proposes a novel multimodal communication decision-making model based on reinforcement learning. The proposed model semantically aligns channel state information (CSI) and textual user instructions, enabling comprehensive understanding of both physical-layer conditions and communication intents. It then generates physically realizable, user-customized link construction strategies that dynamically adapt to changing environments and preference tendencies. A two-stage reinforcement learning framework is employed: the first stage expands the experience pool via heuristic exploration and behavior cloning to obtain a near-optimal initialization, while the second stage fine-tunes the model through multi-objective reinforcement learning considering bit error rate, throughput, and complexity. Experimental results demonstrate that the proposed model significantly outperforms conventional planning-based algorithms under challenging channel conditions, achieving robust, efficient, and personalized 6G link construction.",
      "author": "Zhaoyang Li, Shangzhuo Xie, Qianqian Yang",
      "published_date": "2025-11-10T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 211,
      "reading_time": 1,
      "created_at": "2025-11-10T19:39:11.714085+00:00",
      "updated_at": "2025-11-10T19:39:11.714087+00:00"
    },
    {
      "id": "d941e3a1587d0d59bc4b2d4e9bb92ce7",
      "url": "https://arxiv.org/abs/2511.05066",
      "title": "VEIL: Reading Control Flow Graphs Like Code",
      "content": "arXiv:2511.05066v1 Announce Type: new \nAbstract: Control flow graphs (CFGs) are essential tools for understanding program behavior, yet the size of real-world CFGs makes them difficult to interpret. With thousands of nodes and edges, sophisticated graph drawing algorithms are required to present them on screens in ways that make them readable and understandable. However, being designed for general graphs, these algorithms frequently break the natural flow of execution, placing later instructions before earlier ones and obscuring critical program structures. In this paper, we introduce a set of criteria specifically tailored for CFG visualization, focusing on preserving execution order and making complex structures easier to follow. Building on these criteria, we present VEIL, a new layout algorithm that uses dominator analysis to produce clearer, more intuitive CFG layouts. Through a study of CFGs from real-world applications, we show how our method improves readability and provides improved layout performance compared to state of the art graph drawing techniques.",
      "author": "Philipp Schaad, Tal Ben-Nun, Torsten Hoefler",
      "published_date": "2025-11-10T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 155,
      "reading_time": 1,
      "created_at": "2025-11-10T19:39:11.714045+00:00",
      "updated_at": "2025-11-10T19:39:11.714047+00:00"
    },
    {
      "id": "8009c41022f466a10ef62139f8aa5a91",
      "url": "https://arxiv.org/abs/2511.05025",
      "title": "8bit-GPT: Exploring Human-AI Interaction on Obsolete Macintosh Operating Systems",
      "content": "arXiv:2511.05025v1 Announce Type: new \nAbstract: The proliferation of assistive chatbots offering efficient, personalized communication has driven widespread over-reliance on them for decision-making, information-seeking and everyday tasks. This dependence was found to have adverse consequences on information retention as well as lead to superficial emotional attachment. As such, this work introduces 8bit-GPT; a language model simulated on a legacy Macintosh Operating System, to evoke reflection on the nature of Human-AI interaction and the consequences of anthropomorphic rhetoric. Drawing on reflective design principles such as slow-technology and counterfunctionality, this work aims to foreground the presence of chatbots as a tool by defamiliarizing the interface and prioritizing inefficient interaction, creating a friction between the familiar and not.",
      "author": "Hala Sheta",
      "published_date": "2025-11-10T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 114,
      "reading_time": 1,
      "created_at": "2025-11-10T19:39:11.714015+00:00",
      "updated_at": "2025-11-10T19:39:11.714017+00:00"
    },
    {
      "id": "b64e3669befec1a1b7e9ffc3061f4194",
      "url": "https://arxiv.org/abs/2511.04997",
      "title": "Do intelligent tutoring systems benefit K-12 students? A meta-analysis and evaluation of heterogeneity of treatment effects in the U.S",
      "content": "arXiv:2511.04997v1 Announce Type: new \nAbstract: To expand the use of intelligent tutoring systems (ITS) in K-12 schools, it is essential to understand the conditions under which their use is most beneficial. This meta-analysis evaluated the heterogeneity of ITS effects across studies focusing on elementary, middle, and high schools in the U.S. It included 18 studies with 77 effect sizes across 11 ITS. Overall, there was a significant positive effect size of ITS on U.S. K-12 students' learning outcomes (g=0.271, SE=0.011, p=0.001). Furthermore, effect sizes were similar across elementary and middle schools, and for low-achieving students, but were lower in studies including rural schools. A MetaForest analysis showed that providing worked-out examples, intervention duration, intervention condition, type of learning outcome, and immediate measurement were the most important moderators of treatment effects.",
      "author": "Walter L. Leite, Huibin Zhang, Shibani Rana, Yide Hao, Amber D. Hatch, Lingchen Kong, Huan Kuang",
      "published_date": "2025-11-10T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 130,
      "reading_time": 1,
      "created_at": "2025-11-10T19:39:11.713987+00:00",
      "updated_at": "2025-11-10T19:39:11.713989+00:00"
    },
    {
      "id": "f2b5f4be94ddeb21016c074dc7ae51a3",
      "url": "https://arxiv.org/abs/2511.04995",
      "title": "Enhancing Public Speaking Skills in Engineering Students Through AI",
      "content": "arXiv:2511.04995v1 Announce Type: new \nAbstract: This research-to-practice full paper was inspired by the persistent challenge in effective communication among engineering students. Public speaking is a necessary skill for future engineers as they have to communicate technical knowledge with diverse stakeholders. While universities offer courses or workshops, they are unable to offer sustained and personalized training to students. Providing comprehensive feedback on both verbal and non-verbal aspects of public speaking is time-intensive, making consistent and individualized assessment impractical. This study integrates research on verbal and non-verbal cues in public speaking to develop an AI-driven assessment model for engineering students. Our approach combines speech analysis, computer vision, and sentiment detection into a multi-modal AI system that provides assessment and feedback. The model evaluates (1) verbal communication (pitch, loudness, pacing, intonation), (2) non-verbal communication (facial expressions, gestures, posture), and (3) expressive coherence, a novel integration ensuring alignment between speech and body language. Unlike previous systems that assess these aspects separately, our model fuses multiple modalities to deliver personalized, scalable feedback. Preliminary testing demonstrated that our AI-generated feedback was moderately aligned with expert evaluations. Among the state-of-the-art AI models evaluated, all of which were Large Language Models (LLMs), including Gemini and OpenAI models, Gemini Pro emerged as the best-performing, showing the strongest agreement with human annotators. By eliminating reliance on human evaluators, this AI-driven public speaking trainer enables repeated practice, helping students naturally align their speech with body language and emotion, crucial for impactful and professional communication.",
      "author": "Amol Harsh, Brainerd Prince, Siddharth Siddharth, Deepan Raj Prabakar Muthirayan, Kabir S Bhalla, Esraaj Sarkar Gupta, Siddharth Sahu",
      "published_date": "2025-11-10T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 243,
      "reading_time": 1,
      "created_at": "2025-11-10T19:39:11.713957+00:00",
      "updated_at": "2025-11-10T19:39:11.713960+00:00"
    },
    {
      "id": "91f48808778932020b7e317a1356d315",
      "url": "https://arxiv.org/abs/2511.04964",
      "title": "Scientific judgment drifts over time in AI ideation",
      "content": "arXiv:2511.04964v1 Announce Type: new \nAbstract: Scientific discovery begins with ideas, yet evaluating early-stage research concepts is a subtle and subjective human judgment. As large language models (LLMs) are increasingly tasked with generating scientific hypotheses, most systems assume that scientists' evaluations form a fixed gold standard, and that scientists' judgments do not change. Here we challenge this assumption. In a two-wave study with 7,182 ratings from 57 active researchers across six scientific departments, each participant repeatedly evaluated a constant \"control\" research idea alongside AI-generated ideas. We show that scientists' ratings of the very same idea systematically drift over time: overall quality scores increased by 0.61 points on a 0-10 scale (P = 0.005), and test-retest reliability was only moderate across core dimensions of scientific value, revealing systematic temporal drift in perceived idea quality. Yet the internal structure of judgment remained stable, such as the relative importance placed on originality, feasibility, clarity. We then aligned an LLM-based ideation system to first-wave human ratings and used it to select new ideas. Although alignment improved agreement with Wave-1 evaluations, its apparent gains disappeared once drift in human standards was accounted for. Thus, tuning to a fixed human snapshot produced improvements that were transient rather than persistent. These findings reveal that human evaluation of scientific ideas is not static but a dynamic process with stable priorities and requires shifting calibration. Treating one-time human ratings as immutable ground truth risks overstating progress in AI-assisted ideation and obscuring the challenge of co-evolving with changing expert standards. Drift-aware evaluation protocols and longitudinal benchmarks may therefore be essential for building AI systems that reliably augment, rather than overfit to, human scientific judgment.",
      "author": "Lingyu Zhang, Mitchell Wang, Boyuan Chen",
      "published_date": "2025-11-10T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 273,
      "reading_time": 1,
      "created_at": "2025-11-10T19:39:11.713911+00:00",
      "updated_at": "2025-11-10T19:39:11.713917+00:00"
    },
    {
      "id": "5cfbdafe9793835e1925461820d740a4",
      "url": "https://arxiv.org/abs/2510.04391",
      "title": "Internal World Models as Imagination Networks in Cognitive Agents",
      "content": "arXiv:2510.04391v2 Announce Type: replace-cross \nAbstract: What is the computational objective of imagination? While classical interpretations suggest imagination is useful for maximizing rewards, recent findings challenge this view. In this study, we propose that imagination serves to access an internal world model (IWM) and use psychological network analysis to explore IWMs in humans and large language models (LLMs). Specifically, we assessed imagination vividness ratings using two questionnaires and constructed imagination networks from these reports. Imagination networks from human groups showed correlations between different centrality measures, including expected influence, strength, and closeness. However, imagination networks from LLMs showed a lack of clustering and lower correlations between centrality measures under different prompts and conversational memory conditions. Together, these results indicate a lack of similarity between IWMs in human and LLM agents. Overall, our study offers a novel method for comparing internally-generated representations in humans and AI, providing insights for developing human-like imagination in artificial intelligence.",
      "author": "Saurabh Ranjan, Brian Odegaard",
      "published_date": "2025-11-10T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 152,
      "reading_time": 1,
      "created_at": "2025-11-10T19:39:10.611396+00:00",
      "updated_at": "2025-11-10T19:39:10.611397+00:00"
    },
    {
      "id": "3fa90a2838a2c270d7c6091f388ac06c",
      "url": "https://arxiv.org/abs/2507.06645",
      "title": "Quantifying Uncertainty in Error Consistency: Towards Reliable Behavioral Comparison of Classifiers",
      "content": "arXiv:2507.06645v2 Announce Type: replace \nAbstract: Benchmarking models is a key factor for the rapid progress in machine learning (ML) research. Thus, further progress depends on improving benchmarking metrics. A standard metric to measure the behavioral alignment between ML models and human observers is error consistency (EC). EC allows for more fine-grained comparisons of behavior than other metrics such as accuracy, and has been used in the influential Brain-Score benchmark to rank different DNNs by their behavioral consistency with humans. Previously, EC values have been reported without confidence intervals. However, empirically measured EC values are typically noisy -- thus, without confidence intervals, valid benchmarking conclusions are problematic. Here we improve on standard EC in two ways: First, we show how to obtain confidence intervals for EC using a bootstrapping technique, allowing us to derive significance tests for EC. Second, we propose a new computational model relating the EC between two classifiers to the implicit probability that one of them copies responses from the other. This view of EC allows us to give practical guidance to scientists regarding the number of trials required for sufficiently powerful, conclusive experiments. Finally, we use our methodology to revisit popular NeuroAI-results. We find that while the general trend of behavioral differences between humans and machines holds up to scrutiny, many reported differences between deep vision models are statistically insignificant. Our methodology enables researchers to design adequately powered experiments that can reliably detect behavioral differences between models, providing a foundation for more rigorous benchmarking of behavioral alignment.",
      "author": "Thomas Klein, Sascha Meyen, Wieland Brendel, Felix A. Wichmann, Kristof Meding",
      "published_date": "2025-11-10T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 250,
      "reading_time": 1,
      "created_at": "2025-11-10T19:39:10.611368+00:00",
      "updated_at": "2025-11-10T19:39:10.611370+00:00"
    },
    {
      "id": "15112a645bdf781c1a28a8200c5aa7fe",
      "url": "https://arxiv.org/abs/2506.05320",
      "title": "Generalizable, real-time neural decoding with hybrid state-space models",
      "content": "arXiv:2506.05320v2 Announce Type: replace \nAbstract: Real-time decoding of neural activity is central to neuroscience and neurotechnology applications, from closed-loop experiments to brain-computer interfaces, where models are subject to strict latency constraints. Traditional methods, including simple recurrent neural networks, are fast and lightweight but often struggle to generalize to unseen data. In contrast, recent Transformer-based approaches leverage large-scale pretraining for strong generalization performance, but typically have much larger computational requirements and are not always suitable for low-resource or real-time settings. To address these shortcomings, we present POSSM, a novel hybrid architecture that combines individual spike tokenization via a cross-attention module with a recurrent state-space model (SSM) backbone to enable (1) fast and causal online prediction on neural activity and (2) efficient generalization to new sessions, individuals, and tasks through multi-dataset pretraining. We evaluate POSSM's decoding performance and inference speed on intracortical decoding of monkey motor tasks, and show that it extends to clinical applications, namely handwriting and speech decoding in human subjects. Notably, we demonstrate that pretraining on monkey motor-cortical recordings improves decoding performance on the human handwriting task, highlighting the exciting potential for cross-species transfer. In all of these tasks, we find that POSSM achieves decoding accuracy comparable to state-of-the-art Transformers, at a fraction of the inference cost (up to 9x faster on GPU). These results suggest that hybrid SSMs are a promising approach to bridging the gap between accuracy, inference speed, and generalization when training neural decoders for real-time, closed-loop applications.",
      "author": "Avery Hee-Woon Ryoo, Nanda H. Krishna, Ximeng Mao, Mehdi Azabou, Eva L. Dyer, Matthew G. Perich, Guillaume Lajoie",
      "published_date": "2025-11-10T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 242,
      "reading_time": 1,
      "created_at": "2025-11-10T19:39:10.611334+00:00",
      "updated_at": "2025-11-10T19:39:10.611335+00:00"
    },
    {
      "id": "92393434d15c6396d9323e607b6048a5",
      "url": "https://arxiv.org/abs/2506.04906",
      "title": "TRACE: Contrastive learning for multi-trial time-series data in neuroscience",
      "content": "arXiv:2506.04906v2 Announce Type: replace \nAbstract: Modern neural recording techniques such as two-photon imaging or Neuropixel probes allow to acquire vast time-series datasets with responses of hundreds or thousands of neurons. Contrastive learning is a powerful self-supervised framework for learning representations of complex datasets. Existing applications for neural time series rely on generic data augmentations and do not exploit the multi-trial data structure inherent in many neural datasets. Here we present TRACE, a new contrastive learning framework that averages across different subsets of trials to generate positive pairs. TRACE allows to directly learn a two-dimensional embedding, combining ideas from contrastive learning and neighbor embeddings. We show that TRACE outperforms other methods, resolving fine response differences in simulated data. Further, using in vivo recordings, we show that the representations learned by TRACE capture both biologically relevant continuous variation, cell-type-related cluster structure, and can assist data quality control.",
      "author": "Lisa Schmors, Dominic Gonschorek, Jan Niklas B\\\"ohm, Yongrong Qiu, Na Zhou, Dmitry Kobak, Andreas Tolias, Fabian Sinz, Jacob Reimer, Katrin Franke, Sebastian Damrich, Philipp Berens",
      "published_date": "2025-11-10T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 145,
      "reading_time": 1,
      "created_at": "2025-11-10T19:39:10.611300+00:00",
      "updated_at": "2025-11-10T19:39:10.611301+00:00"
    },
    {
      "id": "ff2a3486586f0a1b604755ed87b3e92c",
      "url": "https://arxiv.org/abs/2511.05221",
      "title": "ActiTect: A Generalizable Machine Learning Pipeline for REM Sleep Behavior Disorder Screening through Standardized Actigraphy",
      "content": "arXiv:2511.05221v1 Announce Type: cross \nAbstract: Isolated rapid eye movement sleep behavior disorder (iRBD) is a major prodromal marker of $\\alpha$-synucleinopathies, often preceding the clinical onset of Parkinson's disease, dementia with Lewy bodies, or multiple system atrophy. While wrist-worn actimeters hold significant potential for detecting RBD in large-scale screening efforts by capturing abnormal nocturnal movements, they become inoperable without a reliable and efficient analysis pipeline. This study presents ActiTect, a fully automated, open-source machine learning tool to identify RBD from actigraphy recordings. To ensure generalizability across heterogeneous acquisition settings, our pipeline includes robust preprocessing and automated sleep-wake detection to harmonize multi-device data and extract physiologically interpretable motion features characterizing activity patterns. Model development was conducted on a cohort of 78 individuals, yielding strong discrimination under nested cross-validation (AUROC = 0.95). Generalization was confirmed on a blinded local test set (n = 31, AUROC = 0.86) and on two independent external cohorts (n = 113, AUROC = 0.84; n = 57, AUROC = 0.94). To assess real-world robustness, leave-one-dataset-out cross-validation across the internal and external cohorts demonstrated consistent performance (AUROC range = 0.84-0.89). A complementary stability analysis showed that key predictive features remained reproducible across datasets, supporting the final pooled multi-center model as a robust pre-trained resource for broader deployment. By being open-source and easy to use, our tool promotes widespread adoption and facilitates independent validation and collaborative improvements, thereby advancing the field toward a unified and generalizable RBD detection model using wearable devices.",
      "author": "David Bertram, Anja Ophey, Sinah R\\\"ottgen, Konstantin Kuffer, Gereon R. Fink, Elke Kalbe, Clint Hansen, Walter Maetzler, Maximilian Kapsecker, Lara M. Reimer, Stephan Jonas, Andreas T. Damgaard, Natasha B. Bertelsen, Casper Skjaerbaek, Per Borghammer, Karolien Groenewald, Pietro-Luca Ratti, Michele T. Hu, No \\'emie Moreau, Michael Sommerauer, Katarzyna Bozek",
      "published_date": "2025-11-10T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 242,
      "reading_time": 1,
      "created_at": "2025-11-10T19:39:10.611272+00:00",
      "updated_at": "2025-11-10T19:39:10.611273+00:00"
    },
    {
      "id": "a2dd78f4b1d4632dd34b7b497376c998",
      "url": "https://arxiv.org/abs/2511.04691",
      "title": "A Penny for Your Thoughts: Decoding Speech from Inexpensive Brain Signals",
      "content": "arXiv:2511.04691v1 Announce Type: cross \nAbstract: We explore whether neural networks can decode brain activity into speech by mapping EEG recordings to audio representations. Using EEG data recorded as subjects listened to natural speech, we train a model with a contrastive CLIP loss to align EEG-derived embeddings with embeddings from a pre-trained transformer-based speech model. Building on the state-of-the-art EEG decoder from Meta, we introduce three architectural modifications: (i) subject-specific attention layers (+0.15% WER improvement), (ii) personalized spatial attention (+0.45%), and (iii) a dual-path RNN with attention (-1.87%). Two of the three modifications improved performance, highlighting the promise of personalized architectures for brain-to-speech decoding and applications in brain-computer interfaces.",
      "author": "Quentin Auster, Kateryna Shapovalenko, Chuang Ma, Demaio Sun",
      "published_date": "2025-11-10T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 108,
      "reading_time": 1,
      "created_at": "2025-11-10T19:39:10.611236+00:00",
      "updated_at": "2025-11-10T19:39:10.611238+00:00"
    },
    {
      "id": "7a187895650adf355ab732b73cd7c93e",
      "url": "https://arxiv.org/abs/2511.05232",
      "title": "Travelling waves modulated by subthreshold oscillations in networks of integrate-and-fire neurons",
      "content": "arXiv:2511.05232v1 Announce Type: new \nAbstract: Travelling waves of neural firing activity are observed in brain tissue as a part of various sensory, motor and cognitive processes. They represent an object of major interest in the study of excitable networks, with analysis conducted in both neural field models and spiking neuronal networks. The latter class exposes the single-neuron dynamics directly, allowing us to study the details of their influence upon network-scale behaviour. Here we present a study of a laterally-inhibited network of leaky integrate-and-fire neurons modulated by a slow voltage-gated ion channel that acts as a linear adaptation variable. As the strength of the ion channel increases, we find that its interaction with the lateral inhibition increases wave speeds. The ion channel can enable subthreshold oscillations, with the intervals between the firing events of loosely-coupled travelling wave solutions structured around the neuron's natural period. These subthreshold oscillations also enable the occurrence of codimension-2 grazing bifurcations; along with the emergence of fold bifurcations along wave solution branches, the slow ion channel introduces a variety of intermediate structures in the solution space. These point towards further investigation of the role neighbouring solution branches play in the behaviour of waves forced across bifurcations, which we illustrate with the aid of simulations using a novel root-finding algorithm designed to handle uncertainty over the existence of firing solutions.",
      "author": "Henry D. J. Kerr, Peter Ashwin, Kyle C. A. Wedgwood",
      "published_date": "2025-11-10T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 222,
      "reading_time": 1,
      "created_at": "2025-11-10T19:39:10.611205+00:00",
      "updated_at": "2025-11-10T19:39:10.611206+00:00"
    }
  ]
}