{
  "last_updated": "2025-11-26T05:22:05.037014+00:00",
  "count": 20,
  "articles": [
    {
      "id": "0c1cc626c505de427b7eefa241b4c2cc",
      "url": "https://arxiv.org/abs/2511.19798",
      "title": "KOM: A Multi-Agent Artificial Intelligence System for Precision Management of Knee Osteoarthritis (KOA)",
      "content": "arXiv:2511.19798v1 Announce Type: cross \nAbstract: Knee osteoarthritis (KOA) affects more than 600 million individuals globally and is associated with significant pain, functional impairment, and disability. While personalized multidisciplinary interventions have the potential to slow disease progression and enhance quality of life, they typically require substantial medical resources and expertise, making them difficult to implement in resource-limited settings. To address this challenge, we developed KOM, a multi-agent system designed to automate KOA evaluation, risk prediction, and treatment prescription. This system assists clinicians in performing essential tasks across the KOA care pathway and supports the generation of tailored management plans based on individual patient profiles, disease status, risk factors, and contraindications. In benchmark experiments, KOM demonstrated superior performance compared to several general-purpose large language models in imaging analysis and prescription generation. A randomized three-arm simulation study further revealed that collaboration between KOM and clinicians reduced total diagnostic and planning time by 38.5% and resulted in improved treatment quality compared to each approach used independently. These findings indicate that KOM could help facilitate automated KOA management and, when integrated into clinical workflows, has the potential to enhance care efficiency. The modular architecture of KOM may also offer valuable insights for developing AI-assisted management systems for other chronic conditions.",
      "author": "Weizhi Liu, Xi Chen, Zekun Jiang, Liang Zhao, Kunyuan Jiang, Ruisi Tang, Li Wang, Mingke You, Hanyu Zhou, Hongyu Chen, Qiankun Xiong, Yong Nie, Kang Li, Jian Li",
      "published_date": "2025-11-26T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 205,
      "reading_time": 1,
      "created_at": "2025-11-26T05:21:46.637208+00:00",
      "updated_at": "2025-11-26T05:21:46.637210+00:00"
    },
    {
      "id": "57b24d0bd0cc2039ef0cb1089c1aae74",
      "url": "https://arxiv.org/abs/2511.19684",
      "title": "IndEgo: A Dataset of Industrial Scenarios and Collaborative Work for Egocentric Assistants",
      "content": "arXiv:2511.19684v1 Announce Type: cross \nAbstract: We introduce IndEgo, a multimodal egocentric and exocentric dataset addressing common industrial tasks, including assembly/disassembly, logistics and organisation, inspection and repair, woodworking, and others. The dataset contains 3,460 egocentric recordings (approximately 197 hours), along with 1,092 exocentric recordings (approximately 97 hours). A key focus of the dataset is collaborative work, where two workers jointly perform cognitively and physically intensive tasks. The egocentric recordings include rich multimodal data and added context via eye gaze, narration, sound, motion, and others. We provide detailed annotations (actions, summaries, mistake annotations, narrations), metadata, processed outputs (eye gaze, hand pose, semi-dense point cloud), and benchmarks on procedural and non-procedural task understanding, Mistake Detection, and reasoning-based Question Answering. Baseline evaluations for Mistake Detection, Question Answering and collaborative task understanding show that the dataset presents a challenge for the state-of-the-art multimodal models. Our dataset is available at: https://huggingface.co/datasets/FraunhoferIPK/IndEgo",
      "author": "Vivek Chavan, Yasmina Imgrund, Tung Dao, Sanwantri Bai, Bosong Wang, Ze Lu, Oliver Heimann, J\\\"org Kr\\\"uger",
      "published_date": "2025-11-26T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 145,
      "reading_time": 1,
      "created_at": "2025-11-26T05:21:46.637171+00:00",
      "updated_at": "2025-11-26T05:21:46.637173+00:00"
    },
    {
      "id": "e24019bd16f8a2772e1e1d5f9eb35ea7",
      "url": "https://arxiv.org/abs/2511.19580",
      "title": "Towards Synergistic Teacher-AI Interactions with Generative Artificial Intelligence",
      "content": "arXiv:2511.19580v1 Announce Type: cross \nAbstract: Generative artificial intelligence (GenAI) is increasingly used in education, posing significant challenges for teachers adapting to these changes. GenAI offers unprecedented opportunities for accessibility, scalability and productivity in educational tasks. However, the automation of teaching tasks through GenAI raises concerns about reduced teacher agency, potential cognitive atrophy, and the broader deprofessionalisation of teaching. Drawing findings from prior literature on AI in Education, and refining through a recent systematic literature review, this chapter presents a conceptualisation of five levels of teacher-AI teaming: transactional, situational, operational, praxical and synergistic teaming. The framework aims to capture the nuanced dynamics of teacher-AI interactions, particularly with GenAI, that may lead to the replacement, complementarity, or augmentation of teachers' competences and professional practice. GenAI technological affordances required in supporting teaming, along with empirical studies, are discussed. Drawing on empirical observations, we outline a future vision that moves beyond individual teacher agency toward collaborative decision-making between teachers and AI, in which both agents engage in negotiation, constructive challenge, and co-reasoning that enhance each other's capabilities and enable outcomes neither could realise independently. Further discussion of socio-technical factors beyond teacher-AI teaming is also included to streamline the synergy of teachers and AI in education ethically and practically.",
      "author": "Mutlu Cukurova, Wannapon Suraworachet, Qi Zhou, Sahan Bulathwela",
      "published_date": "2025-11-26T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 204,
      "reading_time": 1,
      "created_at": "2025-11-26T05:21:46.637142+00:00",
      "updated_at": "2025-11-26T05:21:46.637144+00:00"
    },
    {
      "id": "715bd6c9f7380cb3f68513ce0d5d9518",
      "url": "https://arxiv.org/abs/2511.19577",
      "title": "Using Wearable Devices to Improve Chronic PainTreatment among Patients with Opioid Use Disorder",
      "content": "arXiv:2511.19577v1 Announce Type: cross \nAbstract: Chronic pain (CP) and opioid use disorder (OUD) are common and interrelated chronic medical conditions. Currently, there is a paucity of evidence-based integrated treatments for CP and OUD among individuals receiving medication for opioid use disorder (MOUD). Wearable devices have the potential to monitor complex patient information and inform treatment development for persons with OUD and CP, including pain variability (e.g., exacerbations of pain or pain spikes) and clinical correlates (e.g., perceived stress). However, the application of large language models (LLMs) with wearable data for understanding pain spikes, remains unexplored. Consequently, the aim of this pilot study was to examine the clinical correlates of pain spikes using a range of AI approaches. We found that machine learning models achieved relatively high accuracy (>0.7) in predicting pain spikes, while LLMs were limited in providing insights on pain spikes. Real-time monitoring through wearable devices, combined with advanced AI models, could facilitate early detection of pain spikes and support personalized interventions that may help mitigate the risk of opioid relapse, improve adherence to MOUD, and enhance the integration of CP and OUD care. Given overall limited LLM performance, these findings highlight the need to develop LLMs which can provide actionable insights in the OUD/CP context.",
      "author": "Abhay Goyal, Navin Kumar, Kimberly DiMeola, Rafael Trujillo, Soorya Ram Shimgekar, Christian Poellabauer, Pi Zonooz, Ermonda Gjoni-Markaj, Declan Barry, Lynn Madden",
      "published_date": "2025-11-26T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 207,
      "reading_time": 1,
      "created_at": "2025-11-26T05:21:46.637110+00:00",
      "updated_at": "2025-11-26T05:21:46.637111+00:00"
    },
    {
      "id": "adc608a1d75ca99a6f1f2fd9118c59a2",
      "url": "https://arxiv.org/abs/2511.14198",
      "title": "DiverseClaire: Simulating Students to Improve Introductory Programming Course Materials for All CS1 Learners",
      "content": "arXiv:2511.14198v1 Announce Type: cross \nAbstract: Although CS programs are booming, introductory courses like CS1 still adopt a one-size-fits-all formats that can exacerbate cognitive load and discourage learners with autism, ADHD, dyslexia and other neurological conditions. These call for compassionate pedagogies and Universal Design For Learning (UDL) to create learning environments and materials where cognitive diversity is welcomed. To address this, we introduce DiverseClaire a pilot study, which simulates students including neurodiverse profiles using LLMs and diverse personas. By leveraging Bloom's Taxonomy and UDL, DiverseClaire compared UDL-transformed lecture slides with traditional formats. To evaluate DiverseClaire controlled experiments, we used the evaluation metric the average score. The findings revealed that the simulated neurodiverse students struggled with learning due to lecture slides that were in inaccessible formats. These results highlight the need to provide course materials in multiple formats for diverse learner preferences. Data from our pilot study will be made available to assist future CS1 instructors.",
      "author": "Wendy Wong, Yuchao Jiang, Yuekang Li",
      "published_date": "2025-11-26T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 154,
      "reading_time": 1,
      "created_at": "2025-11-26T05:21:46.637077+00:00",
      "updated_at": "2025-11-26T05:21:46.637078+00:00"
    },
    {
      "id": "20b3543a970059df4830968b15d13e8b",
      "url": "https://arxiv.org/abs/2511.20578",
      "title": "A User-customized and Untethered Electro-haptic Device for Immersive Human-Machine Interaction",
      "content": "arXiv:2511.20578v1 Announce Type: new \nAbstract: Haptic feedback is essential for human-machine interaction, as it bridges physical and digital experiences and enables immersive engagement with virtual environments. However, current haptic devices are frequently tethered, lack portability and flexibility. They also have limited ability to deliver fine-grained, multi-dimensional feedback. To address these challenges, we present a flexible, ultra-thin, and user-customized electro-haptic device fabricated with soft materials and printable liquid metal ink. Its highly integrated and lightweight design minimizes interference with natural hand movements while maintaining reliable skin contact. By delivering finely controlled electrical stimulation through 15 electrodes, it can evoke a wide range of tactile sensations that cover diverse interaction scenarios. Our user study demonstrates that the device is comfortable to wear and capable of generating tunable, precise electro-haptic feedback, thereby significantly enhancing immersion and realism in human-machine interactions.",
      "author": "Ziang Cui, Shanyong Wang, Yining Zhao, Yiran Wang, Xingming Wen, Siyuan Chen, Ze Xiong",
      "published_date": "2025-11-26T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 137,
      "reading_time": 1,
      "created_at": "2025-11-26T05:21:46.637047+00:00",
      "updated_at": "2025-11-26T05:21:46.637049+00:00"
    },
    {
      "id": "123e19e9b054d41cebe6ad5c3c0e7546",
      "url": "https://arxiv.org/abs/2511.20328",
      "title": "GUIDAETA - A Versatile Interactions Dataset with extensive Context Information and Metadata",
      "content": "arXiv:2511.20328v1 Announce Type: new \nAbstract: Interaction data is widely used in multiple domains such as cognitive science, visualization, human computer interaction, and cybersecurity, among others. Applications range from cognitive analyses over user/behavior modeling, adaptation, recommendations, to (user/bot) identification/verification. That is, research on these applications - in particular those relying on learned models - require copious amounts of structured data for both training and evaluation. Different application domains thereby impose different requirements. I.e., for some purposes it is vital that the data is based on a guided interaction process, meaning that monitored subjects pursued a given task, while other purposes require additional context information, such as widget interactions or metadata. Unfortunately, the amount of publicly available datasets is small and their respective applicability for specific purposes limited. We present GUIDEd Interaction DATA (GUIDAETA) - a new dataset, collected from a large-scale guided user study with more than 250 users, each working on three pre-defined information retrieval tasks using a custom-built consumer information system. Besides being larger than most comparable datasets - with 716 completed tasks, 2.39 million mouse and keyboard events (2.35 million and 40 thousand, respectively) and a total observation period of almost 50 hours - its interactions exhibit encompassing context information in the form of widget information, triggered (system) events and associated displayed content. Combined with extensive metadata such as sociodemographic user data and answers to explicit feedback questionnaires (regarding perceived usability, experienced cognitive load, pre-knowledge on the information system's topic), GUIDAETA constitutes a versatile dataset, applicable for various research domains and purposes.",
      "author": "Stefan Lengauer, Sarah Annabelle Von G\\\"otz, Marie-Therese Hoesch, Florian Dieter Steinwidder, Mariia Tytarenko, Michael Bedek, Tobias Schreck",
      "published_date": "2025-11-26T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 254,
      "reading_time": 1,
      "created_at": "2025-11-26T05:21:46.637018+00:00",
      "updated_at": "2025-11-26T05:21:46.637020+00:00"
    },
    {
      "id": "e91e08759163591743317f309f96680e",
      "url": "https://arxiv.org/abs/2511.20080",
      "title": "Adaptive LLM Agents: Toward Personalized Empathetic Care",
      "content": "arXiv:2511.20080v1 Announce Type: new \nAbstract: Current mental-health conversational systems are usually based on fixed, generic dialogue patterns. This paper proposes an adaptive framework based on large language models that aims to personalize therapeutic interaction according to a user's psychological state, quantified with the Acceptance of Illness Scale (AIS). The framework defines three specialized agents, L, M, and H, each linked to a different level of illness acceptance, and adjusts conversational behavior over time using continuous feedback signals. The AIS-stratified architecture is treated as a diegetic prototype placed in a plausible near-future setting and examined through the method of design fiction. By embedding the architecture in narrative scenarios, the study explores how such agents might influence access to care and therapeutic relationship. The goal is to show how clinically informed personalization, technical feasibility, and speculative scenario analysis can together inform the responsible design of LLM-based companions for mental-health support.",
      "author": "Priyanka Singh, Sebastian Von Mammen",
      "published_date": "2025-11-26T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 148,
      "reading_time": 1,
      "created_at": "2025-11-26T05:21:46.636979+00:00",
      "updated_at": "2025-11-26T05:21:46.636981+00:00"
    },
    {
      "id": "00e3a9a097c0ff5e6a19952cf7da5958",
      "url": "https://arxiv.org/abs/2511.19940",
      "title": "Editing with AI: How Doctors Refine LLM-Generated Answers to Patient Queries",
      "content": "arXiv:2511.19940v1 Announce Type: new \nAbstract: Patients frequently seek information during their medical journeys, but the rising volume of digital patient messages has strained healthcare systems. Large language models (LLMs) offer promise in generating draft responses for clinicians, yet how physicians refine these drafts remains underexplored. We present a mixed-methods study with nine ophthalmologists answering 144 cataract surgery questions across three conditions: writing from scratch, directly editing LLM drafts, and instruction-based indirect editing. Our quantitative and qualitative analyses reveal that while LLM outputs were generally accurate, occasional errors and automation bias revealed the need for human oversight. Contextualization--adapting generic answers to local practices and patient expectations--emerged as a dominant form of editing. Editing workflows revealed trade-offs: indirect editing reduced effort but introduced errors, while direct editing ensured precision but with higher workload. We conclude with design and policy implications for building safe, scalable LLM-assisted clinical communication systems.",
      "author": "Rahul Sharma, Pragnya Ramjee, Kaushik Murali, Mohit Jain",
      "published_date": "2025-11-26T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 146,
      "reading_time": 1,
      "created_at": "2025-11-26T05:21:46.636948+00:00",
      "updated_at": "2025-11-26T05:21:46.636950+00:00"
    },
    {
      "id": "85f4cc165fbf58ee26f63a0be8c7b716",
      "url": "https://arxiv.org/abs/2511.19934",
      "title": "Can You Keep Calm?: Adaptive Gameplay using Heart Rate as a Controller",
      "content": "arXiv:2511.19934v1 Announce Type: new \nAbstract: Serious games for health are designed with specific health objectives and are increasingly being used in mental health interventions. Leveraging sensor equipped handheld devices such as smartphones and smartwatches, these games can provide accessible and engaging therapeutic environments. This study introduces a heart rate (HR) controlled game to aid players manage stress by adjusting gameplay according to their biometric feedback. We aimed to determine how HR-based controls influence their experience and if it can be used to reduce stress. Findings from a controlled experiment revealed that HR controlled gameplay reduced negative and increased positive emotions. Also, players exhibited relatively less cardiac reactivity in HR adaptive target based gameplay. This highlights the promise of biometric feedback based gamified digital environments in supporting accessible mental health support.",
      "author": "Md Mosharaf Hossan, Rifat Ara Tasnim, Farjana Z Eishita",
      "published_date": "2025-11-26T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 130,
      "reading_time": 1,
      "created_at": "2025-11-26T05:21:46.636911+00:00",
      "updated_at": "2025-11-26T05:21:46.636915+00:00"
    },
    {
      "id": "02f8148c9fa6589221b7c65fea6144aa",
      "url": "https://arxiv.org/abs/2511.14466",
      "title": "Effect of Dopamine in Enhancement of SNR of Cortico-Striatal-Thalamo-Cortical Loop Spiking",
      "content": "arXiv:2511.14466v2 Announce Type: replace \nAbstract: In this work, the effects of dopamine neurotransmitter within the Cortico-Striatal-Thalamo-Cortical (CSTC) loop have been investigated. Simulations confirmed dopamine facilitates movement via thalamic disinhibition. Analysis of its impact on the signal-to-noise ratio (SNR) revealed a complex, region-specific outcome: SNR increased in some regions (e.g., D2 Striatum: 3.41 dB to 6.25 dB), decreased in others (e.g., Thalamus VL: 6.24 dB to 3.93 dB), and remained stable elsewhere (e.g., M1: 3.16 dB to 3.13 dB). This heterogeneity stems from dopamine increasing the excitability of D1-receptor-expressing neurons, which amplifies channel conductance noise and reduces SNR in specific circuits. Thus, dopamine acts not as a uniform signal enhancer, but as a complex modulator that critically balances facilitation and noise within the CSTC loop.",
      "author": "Hadi Barati, Ali Nayerifar, Mehdi Fardmanesh",
      "published_date": "2025-11-26T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 124,
      "reading_time": 1,
      "created_at": "2025-11-26T05:21:45.569952+00:00",
      "updated_at": "2025-11-26T05:21:45.569953+00:00"
    },
    {
      "id": "e121da32a84503a89554e4e1d6b6047f",
      "url": "https://arxiv.org/abs/2507.09045",
      "title": "Coevolutionary balance of resting-state brain networks in autism",
      "content": "arXiv:2507.09045v2 Announce Type: replace \nAbstract: Autism spectrum disorder (ASD) involves atypical brain organization, yet the large-scale functional principles underlying these alterations remain incompletely understood. Here we examine whether coevolutionary balance-a network-level energy measure derived from signed interactions and nodal activity states-captures disruptions in resting-state functional connectivity in autistic adults. Using ABIDE I resting-state fMRI data, we constructed whole-brain networks by combining binarized fALFF activity with signed functional correlations and quantified their coevolutionary energy. Compared with matched typically developing adults, the ASD group showed a characteristic redistribution of coevolutionary energy, with more negative global energy but higher (less negative) energy within the default mode network and altered energy in its interactions with dorsal attention and salience networks, indicating a reorganization rather than a uniform loss of balance in intrinsic network organization. These effects replicated across validation analyses with null models designed to disrupt link or node structure. Coevolutionary energy also showed modest but significant associations with ADI-R social and communication scores. Finally, incorporating coevolutionary features into a leakage-safe machine-learning classifier supported above-chance ASD versus typically developing (TD) discrimination on a held-out test set. These findings suggest that coevolutionary balance offers a compact, interpretable descriptor of altered resting-state network dynamics in autism.",
      "author": "S. Rezaei Afshar, H. Pouretemad, G. Reza Jafari",
      "published_date": "2025-11-26T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 200,
      "reading_time": 1,
      "created_at": "2025-11-26T05:21:45.569925+00:00",
      "updated_at": "2025-11-26T05:21:45.569926+00:00"
    },
    {
      "id": "9800daf17ee49108255a09d6874a7dde",
      "url": "https://arxiv.org/abs/2506.02013",
      "title": "A Novel Brain-Computer Interface Architecture: The Brain-Muscle-Hand Interface for replicating the motor pathway",
      "content": "arXiv:2506.02013v2 Announce Type: replace \nAbstract: Myoelectric interfaces enable intuitive and natural control by decoding residual muscle activity, providing an effective pathway for motor restoration in individuals with preserved musculature. However, in patients with severe muscular atrophy or high-level spinal cord injury, the absence of reliable muscle activity renders myoelectric control infeasible. In such cases, motor brain-computer interfaces (BCIs) offer an alternative route. However, conventional brain-computer interface systems rely mainly on noisy cortical signals and classification-based decoding algorithms, which often result in low signal fidelity, limited controllability, and unstable real-time performance. Inspired by the motor pathway--an evolutionarily optimized system that filters, integrates, and transmits motor commands from the brain to the muscles--this study proposes the Brain-Muscle-Hand Interface (BMHI). BMHI decodes cortical EEG signals to reconstruct muscle-level EMG activity, functionally substituting for the muscles and enabling regression-based, continuous, and natural control via a myoelectric interface. To validate this architecture, we performed offline verification, comparative analysis, and online control experiments. Results demonstrate that: (1) the BMHI achieves a prediction accuracy of 0.79; (2) compared with conventional end-to-end brain-hand interfaces, it reduces training time by approximately eighteenfold while improving decoding accuracy; and (3) in online operation, the BMHI enables stable and efficient manipulation of both a virtual hand and a robotic arm. Compared with conventional BCIs, the BMHI, by replicating the motor pathway, enables continuous, stable, and naturally intuitive control.",
      "author": "Sun Ye, Zuo Cuiming, Zhang Rui, Shi Bin, Pang Yajing, Gao Lingyun, Zhao Bowei, Wang Jing, Yao Dezhong, Liu Gang",
      "published_date": "2025-11-26T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 226,
      "reading_time": 1,
      "created_at": "2025-11-26T05:21:45.569892+00:00",
      "updated_at": "2025-11-26T05:21:45.569894+00:00"
    },
    {
      "id": "b45dc45cf721abcac73b0d9a5c4c67ec",
      "url": "https://arxiv.org/abs/2412.19329",
      "title": "Deep learning and whole-brain networks for biomarker discovery: modeling the dynamics of brain fluctuations in resting-state and cognitive tasks",
      "content": "arXiv:2412.19329v2 Announce Type: replace \nAbstract: Background: Brain network models offer insights into brain dynamics, but the utility of model-derived bifurcation parameters as biomarkers remains underexplored. Objective: This study evaluates bifurcation parameters from a whole-brain network model as biomarkers for distinguishing brain states associated with resting-state and task-based cognitive conditions. Methods: Synthetic BOLD signals were generated using a supercritical Hopf brain network model to train deep learning models for bifurcation parameter prediction. Inference was performed on Human Connectome Project data, including both resting-state and task-based conditions. Statistical analyses assessed the separability of brain states based on bifurcation parameter distributions. Results: Bifurcation parameter distributions differed significantly across task and resting-state conditions ($p < 0.0001$ for all but one comparison). Task-based brain states exhibited higher bifurcation values compared to rest. Conclusion: Bifurcation parameters effectively differentiate cognitive and resting states, warranting further investigation as biomarkers for brain state characterization and neurological disorder assessment.",
      "author": "Facundo Roffet, Gustavo Deco, Claudio Delrieux, Gustavo Patow",
      "published_date": "2025-11-26T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 149,
      "reading_time": 1,
      "created_at": "2025-11-26T05:21:45.569859+00:00",
      "updated_at": "2025-11-26T05:21:45.569861+00:00"
    },
    {
      "id": "85ad1bc7819e595f6223ae3327fa0c65",
      "url": "https://arxiv.org/abs/2511.20392",
      "title": "Mechano-chemical modeling of glia initiated secondary injury of neurons under mechanical load",
      "content": "arXiv:2511.20392v1 Announce Type: cross \nAbstract: Traumatic Brain Injury (TBI) results from an impact or concussion to the head with the injury being specifically characterized through pathological degradation at various biological length scales. Following injury, various mechanical modeling techniques have been proposed in the literature that seek to quantify neuronal-scale to tissue-scale metrics of brain damage. Broadly, the two categories of degradation encompass physiological deterioration of neurons and upregulation of chemical entities such as neurotransmitters which causes initiation of downstream pathophysiological effects. Despite the many contributing pathways, in this work, we delineate and model a potential glia-initiated injury pathway that leads to secondary injury. The goal of this work is to demonstrate a continuum framework which models the multiphysics of mechano-chemical interactions underlying TBI. Using a coupled PDE (partial differential equation) formulation and FEM (finite element method) discretization, the framework highlights evolution of field variables which spatio-temporally resolve mechanical metrics and chemical species across neuronal clusters. The modeling domain encompasses microglia, neurons and the extracellular matrix. The continuum framework used to model the mechano-chemical interactions assumes a three dimensional viscoelastic network to capture the mechanical response underlying proteins constituting the neuron microstructure and advection-diffusion equations modeling spatio-temporal evolution of chemical species. We use this framework to numerically estimate key concentrations of chemical species produced by the strain field. In this work, we identify key biomarkers within the labyrinth of molecular pathways and build a framework that captures the core mechano-chemical interactions. This framework is an attempt to quantify secondary injury and thus assist in developing targeted TBI treatments.",
      "author": "Debabrata Auddya, Shiva Rudraraju",
      "published_date": "2025-11-26T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 257,
      "reading_time": 1,
      "created_at": "2025-11-26T05:21:45.569830+00:00",
      "updated_at": "2025-11-26T05:21:45.569832+00:00"
    },
    {
      "id": "560b2c2b11bdb84f3a5e58f9eb6fd349",
      "url": "https://arxiv.org/abs/2511.20162",
      "title": "While recognizing actions, LMMs struggle to detect core interaction events",
      "content": "arXiv:2511.20162v1 Announce Type: cross \nAbstract: Large multi-modal models (LMMs) show increasing performance in realistic visual tasks for images and, more recently, for videos. For example, given a video sequence, such models are able to describe in detail objects, the surroundings and dynamic actions. In this study, we explored the extent to which these models ground their semantic understanding in the actual visual input. Specifically, given sequences of hands interacting with objects, we asked models when and where the interaction begins or ends. For this purpose, we introduce a first of its kind, large-scale dataset with more than 20K annotated interactions on videos from the Something-Something-V2 dataset. 250 AMTurk human annotators labeled core interaction events, particularly when and where objects and agents become attached ('contact') or detached ('release'). We asked two LMMs (Qwen-2.5VL and GPT-4o) to locate these events in short videos, each with a single event. The results show that although the models can reliably name the target objects, identify the action and provide coherent reasoning, they consistently fail to identify the frame where the interaction begins or ends and cannot localize the event within the scene. Our findings suggest that in struggling to pinpoint the moment and location of physical contact that defines the interaction, the models lack the perceptual grounding required for deeper understanding of dynamic scenes.",
      "author": "Daniel Harari, Michael Sidorov, Liel David, Chen Shterental, Abrham Kahsay Gebreselasie, Muhammad Haris Khan",
      "published_date": "2025-11-26T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 219,
      "reading_time": 1,
      "created_at": "2025-11-26T05:21:45.569792+00:00",
      "updated_at": "2025-11-26T05:21:45.569793+00:00"
    },
    {
      "id": "60944c24ac4a010b7dcf9935d8f4994b",
      "url": "https://arxiv.org/abs/2511.19548",
      "title": "When Should Neural Data Inform Welfare? A Critical Framework for Policy Uses of Neuroeconomics",
      "content": "arXiv:2511.19548v1 Announce Type: cross \nAbstract: Neuroeconomics promises to ground welfare analysis in neural and computational evidence about how people value outcomes, learn from experience and exercise self-control. At the same time, policy and commercial actors increasingly invoke neural data to justify paternalistic regulation, \"brain-based\" interventions and new welfare measures. This paper asks under what conditions neural data can legitimately inform welfare judgements for policy rather than merely describing behaviour. I develop a non-empirical, model-based framework that links three levels: neural signals, computational decision models and normative welfare criteria. Within an actor-critic reinforcement-learning model, I formalise the inference path from neural activity to latent values and prediction errors and then to welfare claims. I show that neural evidence constrains welfare judgements only when the neural-computational mapping is well validated, the decision model identifies \"true\" interests versus context-dependent mistakes, and the welfare criterion is explicitly specified and defended. Applying the framework to addiction, neuromarketing and environmental policy, I derive a Neuroeconomic Welfare Inference Checklist for regulators and for designers of NeuroAI systems. The analysis treats brains and artificial agents as value-learning systems while showing that internal reward signals, whether biological or artificial, are computational quantities and cannot be treated as welfare measures without an explicit normative model.",
      "author": "Yiven (Louis),  Zhu",
      "published_date": "2025-11-26T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 205,
      "reading_time": 1,
      "created_at": "2025-11-26T05:21:45.569759+00:00",
      "updated_at": "2025-11-26T05:21:45.569761+00:00"
    },
    {
      "id": "24a36dac733196aff0fa7251de45b14c",
      "url": "https://arxiv.org/abs/2511.19520",
      "title": "Modeling Bioelectric State Transitions in Glial Cells: An ASAL-Inspired Computational Approach to Glioblastoma Initiation",
      "content": "arXiv:2511.19520v1 Announce Type: cross \nAbstract: Understanding how glioblastoma (GBM) emerges from initially healthy glial tissue requires models that integrate bioelectrical, metabolic, and multicellular dynamics. This work introduces an ASAL-inspired agent-based framework that simulates bioelectric state transitions in glial cells as a function of mitochondrial efficiency (Meff), ion-channel conductances, gap-junction coupling, and ROS dynamics. Using a 64x64 multicellular grid over 60,000 simulation steps, we show that reducing Meff below a critical threshold (~0.6) drives sustained depolarization, ATP collapse, and elevated ROS, reproducing key electrophysiological signatures associated with GBM. We further apply evolutionary optimization (genetic algorithms and MAP-Elites) to explore resilience, parameter sensitivity, and the emergence of tumor-like attractors. Early evolutionary runs converge toward depolarized, ROS-dominated regimes characterized by weakened electrical coupling and altered ionic transport. These results highlight mitochondrial dysfunction and disrupted bioelectric signaling as sufficient drivers of malignant-like transitions and provide a computational basis for probing the bioelectrical origins of oncogenesis.",
      "author": "Wiktoria Agata Pawlak",
      "published_date": "2025-11-26T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 151,
      "reading_time": 1,
      "created_at": "2025-11-26T05:21:45.569726+00:00",
      "updated_at": "2025-11-26T05:21:45.569728+00:00"
    },
    {
      "id": "f1bb21dbce210f80422914a001e3d982",
      "url": "https://arxiv.org/abs/2511.20532",
      "title": "MIMIC-MJX: Neuromechanical Emulation of Animal Behavior",
      "content": "arXiv:2511.20532v1 Announce Type: new \nAbstract: The primary output of the nervous system is movement and behavior. While recent advances have democratized pose tracking during complex behavior, kinematic trajectories alone provide only indirect access to the underlying control processes. Here we present MIMIC-MJX, a framework for learning biologically-plausible neural control policies from kinematics. MIMIC-MJX models the generative process of motor control by training neural controllers that learn to actuate biomechanically-realistic body models in physics simulation to reproduce real kinematic trajectories. We demonstrate that our implementation is accurate, fast, data-efficient, and generalizable to diverse animal body models. Policies trained with MIMIC-MJX can be utilized to both analyze neural control strategies and simulate behavioral experiments, illustrating its potential as an integrative modeling framework for neuroscience.",
      "author": "Charles Y. Zhang (Harvard University), Yuanjia Yang (Salk Institute for Biological Studies), Aidan Sirbu (Mila), Elliott T. T. Abe (University of Washington), Emil W\\\"arnberg (Harvard University), Eric J. Leonardis (Salk Institute for Biological Studies), Diego E. Aldarondo (Harvard University), Adam Lee (Harvard University), Aaditya Prasad (Massachusetts Institute of Technology), Jason Foat (Salk Institute for Biological Studies), Kaiwen Bian (Salk Institute for Biological Studies), Joshua Park (Salk Institute for Biological Studies), Rusham Bhatt (Salk Institute for Biological Studies), Hutton Saunders (Salk Institute for Biological Studies), Akira Nagamori (Salk Institute for Biological Studies), Ayesha R. Thanawalla (Salk Institute for Biological Studies), Kee Wui Huang (Salk Institute for Biological Studies), Fabian Plum (Imperial College London), Hendrik K. Beck (Imperial College London), Steven W. Flavell (Massachusetts Institute of Technology), David Labonte (Imperial College London), Blake A. Richards (Mila), Bingni W. Brunton (University of Washington), Eiman Azim (Salk Institute for Biological Studies), Bence P. \\\"Olveczky (Harvard University), Talmo D. Pereira (Salk Institute for Biological Studies)",
      "published_date": "2025-11-26T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 122,
      "reading_time": 1,
      "created_at": "2025-11-26T05:21:45.569697+00:00",
      "updated_at": "2025-11-26T05:21:45.569698+00:00"
    },
    {
      "id": "332372bf5eb4c63d9404a302e72ad9b4",
      "url": "https://arxiv.org/abs/2511.20179",
      "title": "Human-computer interactions predict mental health",
      "content": "arXiv:2511.20179v1 Announce Type: new \nAbstract: Scalable assessments of mental illness, the leading driver of disability worldwide, remain a critical roadblock toward accessible and equitable care. Here, we show that human-computer interactions encode multiple dimensions of self-reported mental health and their changes over time.\n  We introduce MAILA, a MAchine-learning framework for Inferring Latent mental states from digital Activity. We trained MAILA to predict 1.3 million mental-health self-reports from 20,000 cursor and touchscreen recordings recorded in 9,000 online participants. The dataset includes 2,000 individuals assessed longitudinally, 1,500 diagnosed with depression, and 500 with obsessive-compulsive disorder. MAILA tracks dynamic mental states along three orthogonal dimensions, generalizes across contexts, and achieves near-ceiling accuracy when predicting group-level mental health. The model translates from general to clinical populations, identifies individuals living with mental illness, and captures signatures of psychological function that are not conveyed by language.\n  Our results demonstrate how everyday human-computer interactions can power passive, reliable, dynamic, and maximally scalable mental health assessments. The ability to decode mental states at zero marginal cost sets new benchmarks for precision medicine and public health, while raising important questions about privacy, agency, and autonomy online.",
      "author": "Veith Weilnhammer, Jefferson Ortega, David Whitney",
      "published_date": "2025-11-26T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 187,
      "reading_time": 1,
      "created_at": "2025-11-26T05:21:45.569663+00:00",
      "updated_at": "2025-11-26T05:21:45.569667+00:00"
    }
  ]
}