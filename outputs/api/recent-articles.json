{
  "last_updated": "2026-01-17T15:22:18.343555+00:00",
  "count": 20,
  "articles": [
    {
      "id": "cfe9fc0e389537b5495e45cf7346c6b3",
      "url": "https://www.reddit.com/r/Python/comments/1qf9ns8/mesas_new_unified_scheduling_api_rethinking_how/",
      "title": "Mesa's new unified scheduling API: Rethinking how time works in agent-based models",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>Hi <a href=\"/r/Python\">r/Python</a>,</p> <p>I'm one of the maintainers of <a href=\"https://github.com/projectmesa/mesa\">Mesa</a>, the Python framework for agent-based modeling. We're working on a pretty significant change to how models handle time and event scheduling, and I think (hope) it's a cool demonstration of user API design.</p> <h3>The problem</h3> <p>Right now, Mesa has two separate systems for advancing time. The traditional approach looks like this:</p> <p><code>python model = MyModel() for _ in range(100): model.step() </code></p> <p>Simple, but limited. If you want discrete event simulation (where things happen at irregular intervals), you need to use our experimental <code>Simulator</code> classes: a completely separate API that feels (and is) bolted on rather than integrated.</p> <h3>The new approach</h3> <p>We're unifying everything into a single, clean API that lives directly on the Model. Here's what it looks like:</p> <p>```python from mesa import Model from mesa.timeflow import scheduled</p> <p>class WolfSheep(Model): @scheduled # Runs every 1 time unit by default def step(self): self.agents.shuffle_do(&quot;step&quot;)</p> <p>model = WolfSheep() model.run_for(100) # Run for 100 time units ```</p> <p>The <code>@scheduled</code> decorator marks methods for automatic recurring execution. You can customize the interval:</p> <p>```python @scheduled(interval=7) # Weekly def collect_statistics(self): ...</p> <p>@scheduled(interval=0.5) # Twice per time unit def physics_update(self): ... ```</p> <h3>Start simple, add complexity</h3> <p>The real power comes from mixing regular stepping with one-off events:</p> <p>```python class EpidemicModel(Model): def <strong>init</strong>(self): super().<strong>init</strong>() # Schedule a one-time event self.schedule_at(self.introduce_vaccine, time=50)</p> <pre><code>@scheduled def step(self): self.agents.shuffle_do(&quot;step&quot;) def introduce_vaccine(self): # This fires once at t=50 self.vaccine_available = True </code></pre> <p>```</p> <p>Agents can even schedule their own future actions:</p> <p>```python class Prisoner(Agent): def get_arrested(self, sentence): self.in_jail = True self.model.schedule_after(self.release, delay=sentence)</p> <pre><code>def release(self): self.in_jail = False </code></pre> <p>```</p> <p>And for pure discrete event simulation (no regular stepping at all):</p> <p>```python class QueueingModel(Model): def <strong>init</strong>(self, arrival<em>rate): super().</em><em>init</em>_() self.schedule_at(self.customer_arrival, time=0)</p> <pre><code>def customer_arrival(self): Customer(self) # Schedule next arrival (Poisson process) next_time = self.time + self.random.expovariate(arrival_rate) self.schedule_at(self.customer_arrival, time=next_time) </code></pre> <p>model = QueueingModel(arrival_rate=2.0) model.run_until(1000.0) # Time jumps: 0 \u2192 0.3 \u2192 0.8 \u2192 1.2... ```</p> <h3>Run control methods</h3> <p><code>python model.run_for(100) # Run for 100 time units model.run_until(500) # Run until time reaches 500 model.run_while(lambda m: m.running) # Run while condition is true model.run_next_event() # Step through events one at a time </code></p> <h3>Design considerations</h3> <p>We kept in mind our wide user base: both students who just starting to learn ABM and PhD-level research. We try to allow progressive complexity: Start simple with <code>@scheduled</code> + <code>run_for()</code>, add events as needed</p> <p>There's now no more second tier: both paradigms are a first-class citizen</p> <p>What's also cool that agents can schedule their own future actions naturally, not everything has to be controlled centrally. This leads to complex patterns and emergent behavior (a very important concept in ABM).</p> <p>Finally we're quite proud that's it's fully backward compatible, that was very hard to get right.</p> <h3>Current status</h3> <p>This is in active development (<a href=\"https://github.com/projectmesa/mesa/pull/3155\">PR #3155</a>), so any insights (both on the specific PR and on a higher level) are appreciated!</p> <p>The (extensive) design discussion is in <a href=\"https://github.com/projectmesa/mesa/discussions/2921\">#2921</a> if you want to dive deeper.</p> <p>If you're more interested in the process of designing a new API in a larger community for a library with a varied user base, we recently wrote up our perspective on that: <a href=\"https://github.com/mesa/mesa/blob/main/CONTRIBUTING.md#mesa-development-process\">Mesa development process</a>.</p> <h3>What's next</h3> <p>We're also <a href=\"https://github.com/mesa/mesa/discussions/2921#discussioncomment-15524497\">designing</a> a more advanced <code>schedule()</code> method for complex patterns:</p> <p>```python</p> <h1>Poisson arrivals with stochastic intervals</h1> <p>model.schedule(customer_arrival, interval=lambda m: m.random.expovariate(2.0))</p> <h1>Run only during market hours, stop after 100 executions</h1> <p>model.schedule(trade, interval=1, only_if=lambda m: m.market_open, count=100)</p> <h1>Seasonal events</h1> <p>@scheduled(interval=1, only_if=lambda m: 90 &lt;= m.time % 365 &lt; 180) def breeding_season(self): ... ```</p> <p>I hope you guys find something like this interesting and it will lead to fruitful a discussion!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Balance-\"> /u/Balance- </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1qf9ns8/mesas_new_unified_scheduling_api_rethinking_how/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1qf9ns8/mesas_new_unified_scheduling_api_rethinking_how/\">[comments]</a></span>",
      "author": "/u/Balance-",
      "published_date": "2026-01-17T10:15:22+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 621,
      "reading_time": 3,
      "created_at": "2026-01-17T15:21:13.202532+00:00",
      "updated_at": "2026-01-17T15:21:13.202534+00:00"
    },
    {
      "id": "61240e61f3a4d95adfa6ee3bc02b8b30",
      "url": "https://www.sciencedirect.com/science/article/pii/S0006899326000181?dgcid=rss_sd_all",
      "title": "K-means++ guided multi-view CNN with channel attention for EEG emotion recognition",
      "content": "<p>Publication date: 1 March 2026</p><p><b>Source:</b> Brain Research, Volume 1874</p><p>Author(s): Yi Zhou, Ruiwen Jiang, Jingxiang Zhang</p>",
      "author": "",
      "published_date": null,
      "source": "Brain Research",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 15,
      "reading_time": 1,
      "created_at": "2026-01-17T14:43:51.999993+00:00",
      "updated_at": "2026-01-17T14:43:51.999994+00:00"
    },
    {
      "id": "d7067d150b0a12a646689d485a64be92",
      "url": "https://www.frontiersin.org/articles/10.3389/fninf.2025.1700481",
      "title": "Information-theoretic gradient flows in mouse visual cortex",
      "content": "IntroductionNeural activity can be described in terms of probability distributions that are continuously evolving in time. Characterizing how these distributions are reshaped as they pass between cortical regions is key to understanding how information is organized in the brain.MethodsWe developed a mathematical framework that represents these transformations as information-theoretic gradient flows \u2014 dynamical trajectories that follow the steepest ascent of entropy and expectation. The relative strengths of these two functionals provide interpretable measures of how neural probability distributions change as they propagate within neural systems. Following construct validation in silico, we applied the framework to publicly available continuous \u0394F/F two-photon calcium recordings from the mouse visual cortex.ResultsThe analysis revealed consistent bi-directional transformations between the rostrolateral area and the primary visual cortex across all five mice. These findings demonstrate that the relative contributions of entropy and expectation can be disambiguated and used to describe information flow within cortical networks.DiscussionWe introduce a framework for decomposing neural signal transformations into interpretable information-theoretic components. Beyond the mouse visual cortex, the method can be applied to diverse neuroimaging modalities and scales, thereby providing a generalizable approach for quantifying how information geometry shapes cortical communication.",
      "author": "Milan Br\u00e1zdil",
      "published_date": "2025-10-30T00:00:00+00:00",
      "source": "Frontiers Neuroinformatics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 189,
      "reading_time": 1,
      "created_at": "2026-01-17T14:43:38.496807+00:00",
      "updated_at": "2026-01-17T14:43:38.496809+00:00"
    },
    {
      "id": "6e59413c999c126f49402b7b1ab1cce3",
      "url": "https://iopscience.iop.org/article/10.1088/1741-2552/ae2f9c",
      "title": "The effects of electrical stimulation on neurons and glia of the central nervous system",
      "content": "Objective. This review paper focuses on how both direct current (DC) stimulation and alternating current (AC) stimulation affects the central nervous system\u2019s (CNSs) cells and its potential as a neurotherapeutic. Furthermore, addressing the promise of combinatorial approaches that utilize other treatments alongside electrical stimulation (ES) and how ES has shaped clinical approaches as a new rehabilitation treatment. Approach. Authors conducted this review to bridge the gap between basic research and clinical translation; 124 manuscripts were identified through Google Scholar for insights into ES effects on neurons and glia in both in vitro and in vivo models. Main results. The review summarizes findings from DC and AC stimulation paradigms applied to in vitro or in vivo preclinical models and summarizes the promise of ES when applied clinically. Generally, DC stimulation promotes axonal extension towards the cathode, while axons retract at the anode, limiting regeneration. AC stimulation alternates electrode polarity, enabling axonal extension in both directions. The intensity and duration of ES significantly affects the extent of neurite outgrowth. For astrocytes and microglia, ES\u2014whether AC or DC\u2014downregulates pro-inflammatory cytokine production and upregulates anti-inflammatory cytokine production, promoting A2 or M2 reactive states conducive to regeneration, respectively. Regarding oligodendrocyte precursor cells (OPCs), both DC and AC stimulation enhance OPC differentiation into oligodendrocytes, increasing myelin content and supporting axonal myelination. ES, when combined with stem cell treatments, drug delivery approaches, or with electroactive biomaterials, facilitate greater efficacy of these approaches. Clinically, short-single sessions of ES have shown long-term improvement. More specifically, preliminary efforts have been implemented to restore gait, hand tremors, and speech in spinal cord injuries, Parkinson\u2019s Disease, and stroke patients, respectively. Significance. ES is an evolving neurotherapeutic strategy for CNS related disease or injuries. Understanding how ES modulates neurons and glia is critical for optimizing its application in the clinic.",
      "author": "Jack Devlin and Ryan Gilbert",
      "published_date": "2026-01-13T00:00:00+00:00",
      "source": "Journal Neural Engineering",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 297,
      "reading_time": 1,
      "created_at": "2026-01-17T14:43:31.074577+00:00",
      "updated_at": "2026-01-17T14:43:31.074581+00:00"
    },
    {
      "id": "048520f8915ac1e4bf47bdb985a85d38",
      "url": "https://donmoynihan.substack.com/p/dispatch-from-the-occupation",
      "title": "What life is like in Minneapolis now",
      "content": "<p>Article URL: <a href=\"https://donmoynihan.substack.com/p/dispatch-from-the-occupation\">https://donmoynihan.substack.com/p/dispatch-from-the-occupation</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46658213\">https://news.ycombinator.com/item?id=46658213</a></p>\n<p>Points: 23</p>\n<p># Comments: 1</p>",
      "author": "_tk_",
      "published_date": "2026-01-17T14:13:11+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2026-01-17T14:43:05.861187+00:00",
      "updated_at": "2026-01-17T14:43:05.861195+00:00"
    },
    {
      "id": "e1385798428586a67ced89a895faeb47",
      "url": "https://erpinfo.org/blog/2024/6/10/erp-core-decoding-paper",
      "title": "New Paper: Using Multivariate Pattern Analysis to Increase Effect Sizes for ERP Amplitude Comparisons",
      "content": "<p class=\"\">Carrasco, C. D., Bahle, B., Simmons, A. M., &amp; Luck, S. J. (2024). Using multivariate pattern analysis to increase effect sizes for event-related potential analyses. Psychophysiology, 61, e14570. <a href=\"https://doi.org/10.1111/psyp.14570\">https://doi.org/10.1111/psyp.14570</a> [<a href=\"https://doi.org/10.1101/2023.11.07.566051\">preprint</a>]</p><p class=\"\">Multivariate pattern analysis (MVPA) can be used to \u201cdecode\u201d subtle information from ERP signals, such as which of several faces a participant is perceiving or the orientation that someone is holding in working memory (see <a href=\"https://erpinfo.org/blog/2018/9/16/decoding\">this previous blog post</a>). This approach is so powerful that we started wondering whether it might also give us greater statistical power in more typical experiments where the goal is to determine whether an ERP component differs in amplitude across experimental conditions. For example, might we more easily be able to tell if N400 amplitude is different between two different classes of words by using decoding? If so, that might make it possible to detect effects that would otherwise be too small to be significant.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"688\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/08f353c7-f484-4e87-b5d3-a256fe1206e2/N170_ES.png?format=1000w\" width=\"971\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">To address this question, we compared decoding with the conventional ERP analysis approach with using the 6 experimental paradigms in the <a href=\"https://doi.org/10.18115/D5JW4R\">ERP CORE</a>. In the conventional ERP analysis, we measured the mean amplitude during the standard measurement window from each participant in the two conditions of the paradigm (e.g., faces versus cars for N170, deviants versus standards for MMN). We quantified the magnitude of the difference between conditions using Cohen\u2019s <em>dz</em> (the variant of Cohen\u2019s <em>d</em> corresponding to a paired <em>t</em> test). For example, the effect size in the conventional ERP comparison of faces versus cars in the N170 paradigm was approximately 1.7 (see the figure).</p><p class=\"\">We also applied decoding to each paradigm. For example, in the N170 paradigm, we trained a support vector machine (SVM) to distinguish between ERPs elicited by faces and ERPs elicited by cars. This was done separately for each subject, and we converted the decoding accuracy into Cohen\u2019s <em>dz</em> so that it could be compared with the <em>dz</em> from the conventional ERP analysis. As you can see from the bar labeled SVM in the figure above, the effect size for the SVM-based decoding analysis was almost twice as large as the effect size for the conventional ERP analysis. That\u2019s a huge difference!</p><p class=\"\">We found a similar benefit for SVM-based decoding over conventional ERP analyses in 7 of the 10 cases we tested (see the figure below). In the other 3 cases, the ERP and SVM effects were approximately equivalent. So, there doesn\u2019t seem to be a downside to using decoding, at least in terms of effect size. But there can be a big benefit.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1371\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/d16f0782-7205-4d50-95e1-c6729cbc153e/All_Components.png?format=1000w\" width=\"4641\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">Because decoding has many possible benefits, we\u2019ve added it into <a href=\"ERPLAB Toolbox\">ERPLAB Toolbox</a>. It\u2019s super easy to use, and we\u2019ve created <a href=\"https://erpinfo.org/blog/2023/6/23/decoding-webinar\">detailed documentation and a video</a> to explain how it works at a conceptual level and to show you how to use it.</p><p class=\"\">We encourage you to apply it to your own data. It may give you the power to detect effects that are too small to be detected with conventional ERP analyses.</p>",
      "author": "Steve Luck",
      "published_date": "2024-06-10T18:01:45+00:00",
      "source": "Erp Boot Camp",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 525,
      "reading_time": 2,
      "created_at": "2026-01-17T14:20:55.255976+00:00",
      "updated_at": "2026-01-17T14:20:55.255978+00:00"
    },
    {
      "id": "906f73f5c36ba087882a0ad17e01fc20",
      "url": "https://erpinfo.org/blog/2024/6/11/erplab-studio",
      "title": "New software package: ERPLAB Studio",
      "content": "<p class=\"\">We are excited to announce the release of a new EEG/ERP analysis package, <a href=\"https://github.com/ucdavis/erplab/releases\">ERPLAB Studio</a>. We think it\u2019s a huge improvement over the classic EEGLAB user interface. See our cheesy <a href=\"https://www.youtube.com/watch?v=lIaKVQ9DD6E\">\u201cadvertisement\u201d video</a> to get a quick overview. </p><p class=\"\">Rather than operating as an EEGLAB plugin, ERPLAB Studio is a standalone Matlab program that provides a more efficient and user-friendly interface to the most commonly used EEGLAB and ERPLAB routines.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1080\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/c874d4ec-5186-4de9-981b-58010c7a06e1/Interface.jpeg?format=1000w\" width=\"1920\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">With ERPLAB Studio, you automatically see the EEG or ERP waveforms as soon as you load a file. And as soon as you perform an operation, you see what the new EEG/ERP looks like. For example, when you filter the data, you immediately see the filtered waveforms.</p><p class=\"\">You can even select multiple datasets and apply an operation like artifact detection on all of them in one step. And then you can immediately see the results, such as which EEG epochs have been marked with artifacts.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1080\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/b45f514d-2d21-4a5a-8be6-f3a8ff99c388/Artifacts.jpeg?format=1000w\" width=\"1920\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">We give you access to EEGLAB\u2019s ICA-based artifact correction tools, but with a nice bonus. You can plot the ICA activations in the same window with the EEG data, making it easy to see which ICA components correspond to specific artifacts such as eyeblinks.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1080\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/8bc191da-9040-4042-ae9c-550cd98def7d/ICA.jpeg?format=1000w\" width=\"1920\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">The program has an EEG tab for processing continuous and epoched EEG data, and an ERP tab for processing averaged ERPs.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1080\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/84bdd9df-b02e-4fc5-83b9-1139a91938f5/Tabs.jpg?format=1000w\" width=\"1920\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">The automatic ERP plotting makes it easy for you to view the data laid out according to the electrode locations. And we have an Advanced Waveform Viewer that can make publication-quality plots.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1080\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/a932631f-fc30-415f-b11d-660d2bf90da5/ERP.jpeg?format=1000w\" width=\"1920\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">ERPLAB Studio is mainly just a new user interface. Under the hood, we\u2019re running the same EEGLAB and ERPLAB routines you\u2019ve always used. And scripting is identical.</p><p class=\"\">ERPLAB Studio is included in <a href=\"https://github.com/ucdavis/erplab/releases\">version 11 and higher of ERPLAB</a>. You simply follow our <a href=\"https://github.com/ucdavis/erplab/wiki/installation\">download/installation instructions</a> and then type estudio from the Matlab command line. </p><p class=\"\">If you\u2019re new to ERPLAB, we strongly recommend that you go through our <a href=\"https://github.com/ucdavis/erplab/wiki/ERPLAB-Studio-Tutorial\" target=\"_blank\">tutorial</a> before starting to process your own data. </p><p class=\"\">If you already know how to use the original version of ERPLAB (which we now call ERPLAB Classic), you can quickly learn how to use ERPLAB Studio with our <a href=\"https://ucdavis.box.com/s/i4jfv22gv6rj9t5obctuk6yaruxqomcc\">Transition Guide</a>.</p><p class=\"\">We also have a <a href=\"https://github.com/ucdavis/erplab/wiki/ERPLAB-Studio-Manual\">manual</a> that describes every feature in detail. </p>",
      "author": "Steve Luck",
      "published_date": "2024-06-12T02:02:16+00:00",
      "source": "Erp Boot Camp",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 444,
      "reading_time": 2,
      "created_at": "2026-01-17T14:20:55.255906+00:00",
      "updated_at": "2026-01-17T14:20:55.255907+00:00"
    },
    {
      "id": "79d603b3db5911be59b9e07e11acc674",
      "url": "https://erpinfo.org/blog/2024/6/28/recording-and-slides-now-available-for-erplab-studio-webinar",
      "title": "Recording and slides now available for ERPLAB Studio webinar",
      "content": "<p class=\"\">We held a webinar to demonstration ERPLAB Studio on 28 June 2024.</p><p class=\"\"><a href=\"https://youtu.be/k-nGv00rTP8\">Click here</a> to access a recording.</p><p class=\"\"><a href=\"https://ucdavis.box.com/s/4fseqz6327dtuouauj12rgvivy1d1nmo\">Click here </a>to access a PDF of the slides.</p>",
      "author": "Steve Luck",
      "published_date": "2024-06-28T22:21:45+00:00",
      "source": "Erp Boot Camp",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 30,
      "reading_time": 1,
      "created_at": "2026-01-17T14:20:55.255845+00:00",
      "updated_at": "2026-01-17T14:20:55.255846+00:00"
    },
    {
      "id": "f94561e83f4fd7f40b976b317e1ae161",
      "url": "https://www.pnas.org/doi/abs/10.1073/pnas.2508541123?af=R",
      "title": "Immature Caenorhabditis elegans motor neurons control early embryo behavior via both synaptic and nonsynaptic GABA release",
      "content": "Proceedings of the National Academy of Sciences, Volume 123, Issue 2, January 2026. <br />SignificanceLittle is known about how prenatal circuits control embryo behavior. We show that the motion of earlyCaenorhabditis elegansembryos is transiently inhibited by immature GABAergic motor neurons that have not yet completed neurite outgrowth. ...",
      "author": "James Marvel-CoenEvan ArdielJian ZhaoStephen NurrishJoshua M. KaplanaDepartment of Molecular Biology, Massachusetts General Hospital, Boston, MA 02114bDepartment of Neurobiology, Harvard Medical School, Boston, MA 02115cBehavioral Neuroscience Program, Department of Psychology, Western Washington University, Bellingham, WA 98225dProgram in Neuroscience, Harvard Medical School, Boston, MA 02115",
      "published_date": "2026-01-06T08:00:00+00:00",
      "source": "Pnas Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 48,
      "reading_time": 1,
      "created_at": "2026-01-17T14:20:27.359666+00:00",
      "updated_at": "2026-01-17T14:20:27.359667+00:00"
    },
    {
      "id": "ef59dd8528eb92e0c4d2ea2de6bbb63b",
      "url": "http://doi.org/10.1037/bne0000635",
      "title": "A rational information gathering account of infant habituation.",
      "content": "Gaze is one of the primary experimental measures for studying cognitive development, especially in preverbal infants. However, the field is only beginning to develop a principled explanatory framework for making sense of the various factors affecting gaze. We approach this issue by addressing infant gaze from first principles, using rational information gathering. In particular, we revisit the influential descriptive account of Hunter and Ames (1988), which posits a set of regularities argued to govern how gaze preference for a stimulus changes with experience and other factors. When the Hunter and Ames\u2019s (1988) model is reconsidered from the perspective of rational information gathering (as recently also proposed by other authors), one feature of the model emerges as surprising: that preference for a stimulus is not monotonic with exposure. This claim, which has at least some empirical support, is in contrast to most statistical measures of informativeness, which strictly decline with experience. We present a normative, computational theory of visual exploration that rationalizes this and other features of the classic account. Our account suggests that Hunter and Ames\u2019s (1988) signature nonmonotonic pattern is a direct manifestation of a ubiquitous principle of the value of information in sequential tasks, other consequences of which have recently been observed in a range of settings including deliberation, exploration, curiosity, and boredom. This is that the value of information gathering, putatively driving gaze, depends on the interplay of a stimulus\u2019 informativeness (called gain, the focus of other rationally motivated accounts) with a second factor (called need) reflecting the estimated chance that information will be used in the future. This computational decomposition draws new connections between infant gaze and other cases of exploration, and offers novel, quantitative interpretations and predictions about the factors that may impact infant exploratory attention. (PsycInfo Database Record (c) 2026 APA, all rights reserved)",
      "author": "",
      "published_date": "2025-11-24T00:00:00+00:00",
      "source": "Behavioral Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 300,
      "reading_time": 1,
      "created_at": "2026-01-17T14:20:00.254526+00:00",
      "updated_at": "2026-01-17T14:20:00.254527+00:00"
    },
    {
      "id": "5cea6fb6906888ba92d763bdc5984b49",
      "url": "http://doi.org/10.1037/bne0000636",
      "title": "Extinction and reinstatement sex-dependently affect freezing behavior, pain perception, locomotion, and rearing behavior in a rat model of posttraumatic stress disorder (PTSD).",
      "content": "Evidence has shown that sex differences affect the symptoms and the response to treatments in neuropsychiatric disorders, including posttraumatic stress disorder (PTSD). Extinction, as a therapeutic method, and reinstatement, as a method that facilitates shock-related memory retrieval, may also be affected by sex differences; however, evidence is sparse. The present study aimed to explore the potential role of sex differences in the effect of extinction and reinstatement on behavioral functions in a rat model of PTSD. Fear learning was induced by three consecutive footshocks (0.8 mA, 3 s, paired with three sounds) on Day 1. Extinction training (20 sounds without footshock) was done 1 hr and 24 hr after footshocks. Reinstatement was done on Day 3, or 10, or 20, or 30, by placing rat in a new context and delivering one footshock (0.8 mA, 3 s, no sound). Results showed that females were more responsive to extinction due to significant decreases in freezing behavior in comparison with males, while reinstatement had more effect to recall shock-related memory in males. Pain threshold was increased and extinction decreased it in both sexes. Locomotion was decreased in fear conditioning group in both sexes and in PTSD + extinction males, while it was not changed in PTSD + extinction females. Reinstatement on Day 3 decreased locomotion in males. Rearing was decreased and extinction restored it in both sexes. By contrast, reinstatement on Day 3 decreased rearing in males. In conclusion, we suggested that females are more responsive to extinction and less sensitive to reinstatement. On the contrary, males are sensitive to reinstatement. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2025-10-16T00:00:00+00:00",
      "source": "Behavioral Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 268,
      "reading_time": 1,
      "created_at": "2026-01-17T14:20:00.254480+00:00",
      "updated_at": "2026-01-17T14:20:00.254481+00:00"
    },
    {
      "id": "5851e8e9c7c495a0382a46973f818152",
      "url": "https://www.freep.com/story/sports/nhl/red-wings/2026/01/12/sergei-fedorov-detroit-red-wings-russian-5/88035492007/",
      "title": "Sergei Fedorov's Escape from Soviet Union Helped Save Red Wings (2020)",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46593556\">Comments</a>",
      "author": "",
      "published_date": "2026-01-12T20:11:19+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-17T14:19:55.813982+00:00",
      "updated_at": "2026-01-17T14:19:55.813983+00:00"
    },
    {
      "id": "3ce61d87cf779ced9c88531f2247ce75",
      "url": "https://rust-for-c-programmers.com",
      "title": "Rust for C Programmers",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46658166\">Comments</a>",
      "author": "",
      "published_date": "2026-01-17T14:07:03+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-17T14:19:55.813887+00:00",
      "updated_at": "2026-01-17T14:19:55.813889+00:00"
    },
    {
      "id": "1c30118c40dce00316f7df64fcdb1c37",
      "url": "https://www.npr.org/2026/01/14/nx-s1-5674741/ai-schools-education",
      "title": "The Risks of AI in Schools Outweigh the Benefits, Report Says",
      "content": "<p>Article URL: <a href=\"https://www.npr.org/2026/01/14/nx-s1-5674741/ai-schools-education\">https://www.npr.org/2026/01/14/nx-s1-5674741/ai-schools-education</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46657719\">https://news.ycombinator.com/item?id=46657719</a></p>\n<p>Points: 12</p>\n<p># Comments: 1</p>",
      "author": "backpackerBMW",
      "published_date": "2026-01-17T12:59:35+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2026-01-17T14:19:54.532439+00:00",
      "updated_at": "2026-01-17T14:19:54.532441+00:00"
    },
    {
      "id": "2e92b636ead9458a3ec27523e65ae84b",
      "url": "https://techcrunch.com/2026/01/16/italy-investigates-activision-blizzard-for-pushing-in-game-purchases/",
      "title": "Italy investigates Activision Blizzard for pushing in-game purchases",
      "content": "<p>Article URL: <a href=\"https://techcrunch.com/2026/01/16/italy-investigates-activision-blizzard-for-pushing-in-game-purchases/\">https://techcrunch.com/2026/01/16/italy-investigates-activision-blizzard-for-pushing-in-game-purchases/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46658014\">https://news.ycombinator.com/item?id=46658014</a></p>\n<p>Points: 5</p>\n<p># Comments: 0</p>",
      "author": "7777777phil",
      "published_date": "2026-01-17T13:44:02+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2026-01-17T14:19:54.532363+00:00",
      "updated_at": "2026-01-17T14:19:54.532378+00:00"
    },
    {
      "id": "f485a145c3b839418e3d039dc3a92ea6",
      "url": "https://erpinfo.org/blog/2025/3/20/new-paper-oddball",
      "title": "New Paper: Does the P3b component reflect working memory updating?",
      "content": "<p class=\"\">Carrasco, C. D., Simmons, A. M., Kiat, J. E., &amp; Luck, S. J. (in press). Enhanced working memory representations for rare events. <em>Psychophysiology</em>. <a href=\"https://doi.org/10.1111/psyp.70038\">https://doi.org/10.1111/psyp.70038</a> [<a href=\"https://doi.org/10.1101/2024.03.20.585952\">preprint</a>]</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n<hr />\n\n\n  <p class=\"\">For decades, many ERP researchers have believed that the P3b wave (sometimes called P300) is a scalp manifestation of a process that updates working memory. This idea originated with Manny Donchin\u2019s <em>context updating</em> hypothesis of the P3b (<a href=\"https://doi.org/10.1111/j.1469-8986.1981.tb01815.x\">Donchin, 1981</a>). Donchin\u2019s idea of <em>context</em> was pretty different from working memory, but as this hypothesis percolated through the field over time, it gradually morphed into the idea that the P3b reflects the updating of working memory.</p><p class=\"\">Rolf Verleger mounted a major attack on the original context updating hypothesis in a classic review article in BBS (<a href=\"https://doi.org/10.1017/S0140525X00058015\">Verleger, 1988</a>), which was followed by a vigorous rebuttal by <a href=\"https://doi.org/10.1017/S0140525X00058027\">Donchin and Coles (1988)</a>. These are interesting papers to read, but they did not settle the issue. In the ensuing years, as the field became more focused on working memory instead of context, I\u2019m aware of no studies that directly tested the hypothesis that the P3b reflects working memory updating. </p><p class=\"\">One reason for the lack of direct evidence is that the oddball paradigms typically used to elicit the P3b do not provide a sensitive assessment of working memory. In a typical paradigm, for example, participants would see a sequence of 90% Xs and 10% Os, and the task would be to press one button for X and another button for O. The responses are made immediately, so it is not necessary to store the stimuli in working memory. Even if participants were asked to make a delayed response, the Xs and Os are so easily discriminable that memory performance would likely be at ceiling.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"698\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/f1d6cee6-5eab-4240-bda0-1a2b7bf4bf88/Figure_1.png?format=1000w\" width=\"720\" />\n\n            \n          \n        \n          \n        \n\n        \n          \n          <figcaption class=\"image-caption-wrapper\">\n            <p class=\"\">Figure 1</p>\n          </figcaption>\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">A few years ago, my lab (especially Carlos Carrasco, Aaron Simmons, and John Kiat) got interested in trying to test the working memory encoding hypothesis. We ran a couple of experiments, but we couldn\u2019t quite figure out the right design. Finally, we figured it out. We used a modified oddball paradigm in which a little dot appeared at one of many locations around an circle (see Figure 1). </p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1112\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/f68d38c2-c87c-4512-b0a7-fbecd75969ff/Figure_2.png?format=1000w\" width=\"1728\" />\n\n            \n          \n        \n          \n        \n\n        \n          \n          <figcaption class=\"image-caption-wrapper\">\n            <p class=\"\">Figure 2</p>\n          </figcaption>\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">On each trial, participants pressed one button if the circle was close to one of the four cardinal axes (left, right, top, and bottom) and a different button if it was close to one of the four diagonals (upper left, upper right, lower left, and lower right). One of these two categories was rare (the <em>oddballs</em>) and the other was frequent (the <em>standards</em>; counterbalanced across trial blocks). As is usual in oddball paradigms, the P3b was much larger for trials in the rare category than for trials in the frequent category (see Figure 2).</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1256\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/89260e9e-be6e-48b1-adc4-58b77a418deb/Figure_3.png?format=1000w\" width=\"1996\" />\n\n            \n          \n        \n          \n        \n\n        \n          \n          <figcaption class=\"image-caption-wrapper\">\n            <p class=\"\">Figure 3</p>\n          </figcaption>\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">The main question was whether the location of the dot was encoded in working memory better for the oddball trials than for the standard trials. To assess this, the experimental design contained occasional <em>probe</em> trials on which participants used the mouse to click on the exact location of the dot (see Figure 3). That is, after participants made the cardinal/diagonal buttonpress responses, they were sometimes then asked to click on the remembered location of the dot. This happened on only 12.5% of trials, selected at random, so that participants would mainly focus on the oddball task. </p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"706\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/166f7236-f77b-431b-8ebf-9633580dcf31/Figure_4.png?format=1000w\" width=\"1800\" />\n\n            \n          \n        \n          \n        \n\n        \n          \n          <figcaption class=\"image-caption-wrapper\">\n            <p class=\"\">Figure 4</p>\n          </figcaption>\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">We looked at the accuracy of these probe responses, calculated as the (absolute value of the) angular distance between the true location and the reported location. As shown in Figure 4, the response error of the probe responses was reduced for the oddball trials relative to the standard trials. In other words, working memory was better for the P3b-eliciting oddball trials than for the standards. Moreover, we found that participants with large P3b amplitudes on oddball trials had smaller response errors on oddball trials (whereas this correlation was not present for standards).</p><p class=\"\">At first glance, these findings seem like support for the idea that the P3b reflects working memory updating. However, the story is not that simple. For example, when we looked at single-trial P3b amplitudes, response errors were not lower for trials with larger P3b amplitudes than for trials with smaller P3b amplitudes.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1122\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/a7a11955-3619-4499-9ef4-61f72a408561/Figure_5.png?format=1000w\" width=\"1378\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">We also used ERP decoding to test whether the exact location of the dot was better stored in working memory on oddball trials than on standard trials (<a href=\"https://erpinfo.org/blog/2023/6/23/decoding-webinar\">click here</a> for information about how ERP decoding works and how you can decode your own data using ERPLAB Toolbox). As shown in Figure 5, we could decode the location of the dot better on oddball trials than on standard trials during the period following the P3b component. Note, however, that this was a pretty small difference that only barely crossed the threshold for statistical significance (p = .048). I would really like to see this effect replicated before fully believing it. However, the behavioral effect was rock solid (and replicated in a follow-up experiment).</p><p class=\"\">What can we conclude from these findings? When we started the project, I knew that it would be difficult to draw any strong causal conclusions about the relationship between the P3b component and working memory updating. That is, even if we saw both a larger P3b and improved working memory on oddball trials, this would just be a correlation and could potentially be explained by a third variable such as attention. But if we saw a big difference in working memory between oddballs and standards, and if we found that working memory was better on trials with larger P3b amplitudes, this would be at least consistent with the idea that the process that produces the P3b on the scalp is also involved in working memory encoding.</p><p class=\"\">However, although we saw an enormous difference in P3b amplitude between oddball trials and standard trials, we saw only small differences in working memory between oddballs and standards, whether measured via behavioral response errors on probe trials or EEG decoding accuracy. If the process that generates the scalp P3b voltage plays a major role in working memory encoding, then we would have expected a much larger working memory difference between oddballs and standards. Moreover, although we found that participants with larger P3b amplitudes had smaller response errors, we did not find any evidence that working memory was any better on trials with larger P3b amplitudes (even though we looked very hard for such a relationship). The bottom line is that, although I was really hoping we would finally provide some direct evidence for the working memory encoding hypothesis, the results of this study have actually convinced me that the P3b is probably not related to working memory encoding.</p><p class=\"\">What, then, explains the small but statistically significant differences in working memory accuracy between oddballs and standards, along with the subjectwise correlation between P3b amplitude and behavioral response errors? A very plausible explanation is that both the P3b component and working memory encoding are facilitated by increased attention. That is, there are several sources of evidence that rare events trigger increased attention, and this could independently produce a larger P3b and improved working memory.</p><p class=\"\">Of course, this is just one experiment, so I wouldn\u2019t say that the working memory encoding hypothesis is completely dead. But given our new findings and the general lack of direct evidence for the hypothesis, it\u2019s on life support.</p><p class=\"\">If the P3b doesn\u2019t reflect working memory encoding, then what does it reflect? This seems like a significant question: the P3b is huge and is observed across a broad range of experimental paradigms, and it\u2019s reasonable to assume that the underlying process must be important for the brain to devote so many watts of energy to it. In fact, I find it embarrassing that our field has not answered this question in the 60 years since <a href=\"https://doi.org/10.1126/science.150.3700.1187\">the P3b was first discovered</a>.</p><p class=\"\">My best bet is that the P3b is related to the process of making decisions about actions (where the term <em>actions</em> is broadly construed to include the withholding of responses and mental actions such as counting). This is related to the fact that the amplitude of the P3b is related to the probability of a task-defined category, not the probability of a physical stimulus category. Rolf Verleger has a nice review of the evidence for this idea (<a href=\"https://doi.org/10.1111/psyp.13542\">Verleger, 2020</a>). But it is still not clear to me why the brain devotes so many watts of energy to creating a large P3b when a rare task-defined category occurs. Verleger notes that several hypotheses about the P3b are compatible with the finding of a larger P3b for oddballs than for standards, but in my view these hypotheses have a hard time explaining the enormous size of the P3b observed for oddballs. This is a longstanding mystery in need of a solution!</p>",
      "author": "Steve Luck",
      "published_date": "2025-03-21T03:42:26+00:00",
      "source": "Erp Boot Camp",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 1547,
      "reading_time": 7,
      "created_at": "2026-01-17T13:48:28.251266+00:00",
      "updated_at": "2026-01-17T14:14:56.699027+00:00",
      "metadata": {
        "processed_at": "2026-01-17T14:14:56.699037+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "11da1006ee59369caf1a8b22a800f02c",
      "url": "https://erpinfo.org/blog/2025/8/20/boot-camp-summer-2026",
      "title": "10-Day ERP Boot Camp to be held June 15-24, 2026 in Davis, California",
      "content": "<p class=\"\">We have received another 5 years of funding from the National Institute of Mental Health, so we plan to hold ERP Boot Camps in each of the next 5 summers. The next one will be June 15-24, 2026 in Davis, California. The application portal will open around January 1, 2026.</p><p class=\"\">As in most previous years, all attendees will receive a scholarship that covers most or all travel and lodging expenses. There will be no registration fee.</p><p class=\"\"><a href=\"https://erpinfo.org/summer-boot-camp\">Click here</a> for more information about the ERP Boot Camp.</p><p class=\"\">If you would like to receive announcements about upcoming boot camps, <a href=\"https://erpinfo.org/bootcamp-email-list\">join our email list</a>. If you have any questions after reading this page and the <a href=\"https://erpinfo.org/application-info\">application information</a> page, please email us at <a href=\"mailto:erpbootcamp@gmail.com\">erpbootcamp@gmail.com</a>.</p>",
      "author": "Steve Luck",
      "published_date": "2025-08-20T15:07:14+00:00",
      "source": "Erp Boot Camp",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 125,
      "reading_time": 1,
      "created_at": "2026-01-17T13:48:28.251085+00:00",
      "updated_at": "2026-01-17T14:14:56.699042+00:00",
      "metadata": {
        "processed_at": "2026-01-17T14:14:56.699044+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "8a37f4aa5925a5559bd2dd315d94013b",
      "url": "https://brain.ieee.org/publications/neuroethics-framework/education/standards-education/education-standards/",
      "title": "Education: Standards",
      "content": "",
      "author": "Adriel Carridice",
      "published_date": "2025-02-13T19:51:15+00:00",
      "source": "Brain",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2026-01-17T13:48:25.681392+00:00",
      "updated_at": "2026-01-17T14:14:56.699047+00:00",
      "metadata": {
        "processed_at": "2026-01-17T14:14:56.699048+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "417111e13e4858f79734781862a95c17",
      "url": "https://brain.ieee.org/publications/neuroethics-framework/education/educational-and-training-resources-education/education-additional-resources/",
      "title": "Education: Additional Resources",
      "content": "Buckingham Shum, S. (2022). The UTS \u201cEdTech Ethics\u201d Deliberative Democracy Consultation: Rationale, Process and Outcomes. Connected Intelligence Centre, University of Technology Sydney, AUS. https://cic.uts.edu.au/projects/edtech-ethics Le\u00f3n Declaration on European neurotechnology (2023): a human-focused and rights-oriented approach October 2023. An informal meeting will be held with all telecommunications and digital ministers from EU member states. https://spanish-presidency.consilium.europa.eu/media/o4rh53jr/le%C3%B3n-declaration.pdf Neurotechnology Report: https://www.perseus-strategies.com/wp-content/uploads/2024/04/FINAL-Consumer-Neurotechnology-Report-Neurorights-Foundation-March-2024-3.pdf Al-Emran, M., Al-Nuaimi, ...",
      "author": "Adriel Carridice",
      "published_date": "2025-02-13T19:54:30+00:00",
      "source": "Brain",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 61,
      "reading_time": 1,
      "created_at": "2026-01-17T13:48:25.681376+00:00",
      "updated_at": "2026-01-17T14:14:56.699050+00:00",
      "metadata": {
        "processed_at": "2026-01-17T14:14:56.699052+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "0034e844e06f50c554f3ea92b4f7be58",
      "url": "https://iopscience.iop.org/article/10.1088/1741-2552/ae2805",
      "title": "A pretrained foundation model for headache disorders based on magnetoencephalography",
      "content": "Objective. Foundation models have demonstrated transformative potential in medical artificial intelligence but remain underexplored in functional neuroimaging, particularly magnetoencephalography (MEG). This study aims to develop a domain-specific, self-supervised MEG clinical foundation model tailored for headache disorders to address the challenges of high-dimensional data and limited labeled datasets in clinical research. Approach. We developed a transformer-based model pretrained on a large-scale dataset comprising multi-state MEG recordings (resting-state, auditory, and somatosensory stimulation) from 416 participants (362 headache patients and 54 healthy controls). The model utilized a self-supervised masked-signal reconstruction strategy to learn latent spatiotemporal representations of neural activity. We evaluated the model\u2019s performance through signal reconstruction, visualization of attention weights, and downstream classification tasks comparing model-derived features against original MEG signals for migraine diagnosis. Main results. The pretrained model successfully reconstructed both continuous MEG signals and stimulus-specific evoked responses, effectively capturing intrinsic spatiotemporal brain dynamics. Visualization of the model\u2019s attention weights demonstrated spatial alignment with corresponding sensory brain regions, confirming its neurophysiological interpretability. Furthermore, classifiers trained on features extracted from the pretrained model significantly outperformed those using original MEG signals in identifying migraine patients, revealing distinct neural response patterns. Significance. This study introduces a scalable, data-efficient framework for clinical MEG analysis that significantly reduces reliance on manual feature extraction and labeled data. It demonstrates the efficacy of foundation models in decoding complex neural dynamics, offering promising implications for understanding neuropathology and facilitating precision diagnostics in neurology.",
      "author": "Pan Liao, Jie Liang, Dong Qiu, Cunxin Lin, Zhonghua Xiong, Hao Wang, Jia-Hong Gao, Yonggang Wang and Bingjiang Lyu",
      "published_date": "2026-01-08T00:00:00+00:00",
      "source": "Journal Neural Engineering",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 234,
      "reading_time": 1,
      "created_at": "2026-01-17T13:47:50.169504+00:00",
      "updated_at": "2026-01-17T14:14:56.699054+00:00",
      "metadata": {
        "processed_at": "2026-01-17T14:14:56.699056+00:00",
        "processing_method": "github_actions"
      }
    }
  ]
}