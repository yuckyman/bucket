{
  "last_updated": "2025-11-18T05:21:25.646104+00:00",
  "count": 20,
  "articles": [
    {
      "id": "ee405f965603f782e9cc65faeacd339d",
      "url": "https://arxiv.org/abs/2511.12068",
      "title": "From Play to Detection: Mini-SPACE as a Serious Game for Unsupervised Cognitive Impairment Screening",
      "content": "arXiv:2511.12068v1 Announce Type: new \nAbstract: Early detection of Cognitive Impairment (CI) is critical for timely intervention, preservation of independence, and reducing the burden of dementia. Yet, most screening tools remain lengthy, clinic-based, and poorly suited for large-scale unsupervised deployment. This paper evaluates the test-retest reliability, validity, and usability of mini-SPACE, a short iPad-based serious game for detecting early signs of CI. Participants played mini-SPACE at home without supervision once a week for three weeks, with a longer version of the game in the final week. Mini-SPACE showed good test-retest reliability in unsupervised settings. While younger age was the primary predictor of performance, usability, and cognitive load, participants of all ages were able to complete the tasks and reported good usability and low cognitive load. Importantly, the prediction of scores in the Montreal Cognitive Assessment (MoCA) improved with repeated measures. These findings highlight mini-SPACE as a promising digital marker for scalable, age-sensitive screening and potential longitudinal tracking of CI.",
      "author": "Nana Tian, Giorgio Colombo, Victor Schinazi",
      "published_date": "2025-11-18T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 158,
      "reading_time": 1,
      "created_at": "2025-11-18T05:21:07.483978+00:00",
      "updated_at": "2025-11-18T05:21:07.483979+00:00"
    },
    {
      "id": "2190899dced0e003380833a5053f1a7c",
      "url": "https://arxiv.org/abs/2511.11962",
      "title": "A Study of Performance and Interaction Patterns in Hand and Tangible Interaction in Tabletop Mixed Reality",
      "content": "arXiv:2511.11962v1 Announce Type: new \nAbstract: This paper presents a comprehensive study of virtual 3D object manipulation along 4DoF on real surfaces in mixed reality (MR), using hand-based and tangible interactions. A custom cylindrical tangible proxy leverages affordances of physical knobs and tabletop support for stable input. We evaluate both modalities across isolated tasks (2DoF translation, 1DoF rotation scaling), semicombined (3DoF translation rotation), and full 4DoF compound manipulation.\n  We offer analyses of hand interactions, tangible interactions, and their comparison in MR tasks. For hand interactions, compound tasks required repetitive corrections, increasing completion times yet surprisingly, rotation errors were smaller in compound tasks than in rotation only tasks. Tangible interactions exhibited significantly larger errors in translation, rotation, and scaling during compound tasks compared to isolated tasks. Crucially, tangible interactions outperformed hand interactions in precision, likely due to tabletop support and constrained 4DoF design. These findings inform designers opting for hand-only interaction (highlighting tradeoffs in compound tasks) and those leveraging tangibles (emphasizing precision gains despite compound-task challenges).",
      "author": "Carlos Mosquera, Neven Elsayed, Ernst Kruijff, Joseph Newman, Eduardo Veas",
      "published_date": "2025-11-18T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 164,
      "reading_time": 1,
      "created_at": "2025-11-18T05:21:07.483949+00:00",
      "updated_at": "2025-11-18T05:21:07.483950+00:00"
    },
    {
      "id": "874fbf1a5db2f9ef8116e0804a4a66a5",
      "url": "https://arxiv.org/abs/2511.11961",
      "title": "\"Power of Words\": Stealthy and Adaptive Private Information Elicitation via LLM Communication Strategies",
      "content": "arXiv:2511.11961v1 Announce Type: new \nAbstract: While communication strategies of Large Language Models (LLMs) are crucial for human-LLM interactions, they can also be weaponized to elicit private information, yet such stealthy attacks remain under-explored. This paper introduces the first adaptive attack framework for stealthy and targeted private information elicitation via communication strategies. Our framework operates in a dynamic closed-loop: it first performs real-time psychological profiling of the users' state, then adaptively selects an optimized communication strategy, and finally maintains stealthiness through prompt-based rewriting. We validated this framework through a user study (N=84), demonstrating its generalizability across 3 distinct LLMs and 3 scenarios. The targeted attacks achieved a 205.4% increase in eliciting specific targeted information compared to stealthy interactions without strategies. Even stealthy interactions without specific strategies successfully elicited private information in 54.8% cases. Notably, users not only failed to detect the manipulation but paradoxically rated the attacking chatbot as more empathetic and trustworthy. Finally, we advocate for mitigations, encouraging developers to integrate adaptive, just-in-time alerts, users to build literacy against specific manipulative tactics, and regulators to define clear ethical boundaries distinguishing benign persuasion from coercion.",
      "author": "Shuning Zhang, Jiaqi Bai, Linzhi Wang, Shixuan Li, Xin Yi, Hewu Li",
      "published_date": "2025-11-18T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 184,
      "reading_time": 1,
      "created_at": "2025-11-18T05:21:07.483919+00:00",
      "updated_at": "2025-11-18T05:21:07.483920+00:00"
    },
    {
      "id": "f0dc5a1a10c73df2fca3595daa1e3024",
      "url": "https://arxiv.org/abs/2511.11930",
      "title": "Enhancing XR Auditory Realism via Multimodal Scene-Aware Acoustic Rendering",
      "content": "arXiv:2511.11930v1 Announce Type: new \nAbstract: In Extended Reality (XR), rendering sound that accurately simulates real-world acoustics is pivotal in creating lifelike and believable virtual experiences. However, existing XR spatial audio rendering methods often struggle with real-time adaptation to diverse physical scenes, causing a sensory mismatch between visual and auditory cues that disrupts user immersion. To address this, we introduce SAMOSA, a novel on-device system that renders spatially accurate sound by dynamically adapting to its physical environment. SAMOSA leverages a synergistic multimodal scene representation by fusing real-time estimations of room geometry, surface materials, and semantic-driven acoustic context. This rich representation then enables efficient acoustic calibration via scene priors, allowing the system to synthesize a highly realistic Room Impulse Response (RIR). We validate our system through technical evaluation using acoustic metrics for RIR synthesis across various room configurations and sound types, alongside an expert evaluation (N=12). Evaluation results demonstrate SAMOSA's feasibility and efficacy in enhancing XR auditory realism.",
      "author": "Tianyu Xu, Jihan Li, Penghe Zu, Pranav Sahay, Maruchi Kim, Jack Obeng-Marnu, Farley Miller, Xun Qian, Katrina Passarella, Mahitha Rachumalla, Rajeev Nongpiur, D. Shin",
      "published_date": "2025-11-18T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 156,
      "reading_time": 1,
      "created_at": "2025-11-18T05:21:07.483880+00:00",
      "updated_at": "2025-11-18T05:21:07.483881+00:00"
    },
    {
      "id": "fa8c42f1068e533af1b82846562c4019",
      "url": "https://arxiv.org/abs/2511.11823",
      "title": "CollaClassroom: An AI-Augmented Collaborative Learning Platform with LLM Support in the Context of Bangladeshi University Students",
      "content": "arXiv:2511.11823v1 Announce Type: new \nAbstract: CollaClassroom is an AI-enhanced platform that embeds large language models (LLMs) into both individual and group study panels to support real-time collaboration. We evaluate CollaClassroom with Bangladeshi university students (N = 12) through a small-group study session and a pre-post survey. Participants have substantial prior experience with collaborative learning and LLMs and express strong receptivity to LLM-assisted study (92% agree/strongly agree). Usability ratings are positive, including high learnability(67% \"easy\"), strong reliability (83% \"reliable\"), and low frustration (83% \"not at all\"). Correlational analyses show that participants who perceive the LLM as supporting equal participation also view it as a meaningful contributor to discussions (r = 0.86). Moreover, their pre-use expectations of LLM value align with post-use assessments (r = 0.61). These findings suggest that LLMs can enhance engagement and perceived learning when designed to promote equitable turn-taking and transparency across individual and shared spaces. The paper contributes an empirically grounded account of AI-mediated collaboration in a Global South higher-education context, with design implications for fairness-aware orchestration of human-AI teamwork.",
      "author": "Salman Sayeed, Bijoy Ahmed Saiem, Al-Amin Sany, Sadia Sharmin, A. B. M. Alim Al Islam",
      "published_date": "2025-11-18T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 173,
      "reading_time": 1,
      "created_at": "2025-11-18T05:21:07.483850+00:00",
      "updated_at": "2025-11-18T05:21:07.483851+00:00"
    },
    {
      "id": "bf6dc78f9b530f480820f44a2c468b6c",
      "url": "https://arxiv.org/abs/2511.11811",
      "title": "Lessons Learned from Developing a Privacy-Preserving Multimodal Wearable for Local Voice-and-Vision Inference",
      "content": "arXiv:2511.11811v1 Announce Type: new \nAbstract: Many promising applications of multimodal wearables require continuous sensing and heavy computation, yet users reject such devices due to privacy concerns. This paper shares our experiences building an ear-mounted voice-and-vision wearable that performs local AI inference using a paired smartphone as a trusted personal edge. We describe the hardware--software co-design of this privacy-preserving system, including challenges in integrating a camera, microphone, and speaker within a 30-gram form factor, enabling wake word-triggered capture, and running quantized vision-language and large-language models entirely offline. Through iterative prototyping, we identify key design hurdles in power budgeting, connectivity, latency, and social acceptability. Our initial evaluation shows that fully local multimodal inference is feasible on commodity mobile hardware with interactive latency. We conclude with design lessons for researchers developing embedded AI systems that balance privacy, responsiveness, and usability in everyday settings.",
      "author": "Yonatan Tussa, Andy Heredia, Nirupam Roy",
      "published_date": "2025-11-18T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 140,
      "reading_time": 1,
      "created_at": "2025-11-18T05:21:07.483819+00:00",
      "updated_at": "2025-11-18T05:21:07.483821+00:00"
    },
    {
      "id": "debf7b728e6aca342d2805ae135c747c",
      "url": "https://arxiv.org/abs/2511.11610",
      "title": "ARise: an Augmented Reality Mobile Application to Improve Cultural Heritage Resilience",
      "content": "arXiv:2511.11610v1 Announce Type: new \nAbstract: The preservation of cultural heritage faces increasing threats from climate change effects and environmental hazards, demanding innovative solutions that can promote awareness and resilience. This paper presents ARise, an Augmented Reality mobile application designed to enhance public engagement with cultural sites while raising awareness about the local impacts of climate change. Based on a user-centered co-creative methodology involving stakeholders from five European regions, ARise integrates multiple data sourcess - a Crowdsourcing Chatbot, a Social Media Data Analysis tool, and an AI-based Artwork Generation module - to deliver immersive and emotionally engaging experiences. Although formal user testing is forthcoming, this prototype demonstrates the potential of AR to support education, cultural sustainability, and climate adaptation.",
      "author": "Angelica Urbanelli, Marina Nadalin, Mario Chiesa, Rojin Bayat, Massimo Migliorini, Claudio Rossi",
      "published_date": "2025-11-18T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 118,
      "reading_time": 1,
      "created_at": "2025-11-18T05:21:07.483791+00:00",
      "updated_at": "2025-11-18T05:21:07.483792+00:00"
    },
    {
      "id": "b5804500df6798a69828291ae57af4e3",
      "url": "https://arxiv.org/abs/2511.11587",
      "title": "MedBuild AI: An Agent-Based Hybrid Intelligence Framework for Reshaping Agency in Healthcare Infrastructure Planning through Generative Design for Medical Architecture",
      "content": "arXiv:2511.11587v1 Announce Type: new \nAbstract: Globally, disparities in healthcare infrastructure remain stark, leaving countless communities without access to even basic services. Traditional infrastructure planning is often slow and inaccessible, and although many architects are actively delivering humanitarian and aid-driven hospital projects worldwide, these vital efforts still fall far short of the sheer scale and urgency of demand. This paper introduces MedBuild AI, a hybrid-intelligence framework that integrates large language models (LLMs) with deterministic expert systems to rebalance the early design and conceptual planning stages. As a web-based platform, it enables any region with satellite internet access to obtain guidance on modular, low-tech, low-cost medical building designs. The system operates through three agents: the first gathers local health intelligence via conversational interaction; the second translates this input into an architectural functional program through rule-based computation; and the third generates layouts and 3D models. By embedding computational negotiation into the design process, MedBuild AI fosters a reciprocal, inclusive, and equitable approach to healthcare planning, empowering communities and redefining agency in global healthcare architecture.",
      "author": "Yiming Zhang, Yuejia Xu, Ziyao Wang, Xin Yan, Xiaosai Hao",
      "published_date": "2025-11-18T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 171,
      "reading_time": 1,
      "created_at": "2025-11-18T05:21:07.483764+00:00",
      "updated_at": "2025-11-18T05:21:07.483766+00:00"
    },
    {
      "id": "6f2049d94d1913bd03c8217faee127ee",
      "url": "https://arxiv.org/abs/2511.11578",
      "title": "Social and Physical Attributes-Defined Trust Evaluation for Effective Collaborator Selection in Human-Device Coexistence Systems",
      "content": "arXiv:2511.11578v1 Announce Type: new \nAbstract: In human-device coexistence systems, collaborations among devices are determined by not only physical attributes such as network topology but also social attributes among human users. Consequently, trust evaluation of potential collaborators based on these multifaceted attributes becomes critical for ensuring the eventual outcome. However, due to the high heterogeneity and complexity of physical and social attributes, efficiently integrating them for accurate trust evaluation remains challenging. To overcome this difficulty, a canonical correlation analysis-enhanced hypergraph self-supervised learning (HSLCCA) method is proposed in this research. First, by treating all attributes as relationships among connected devices, a relationship hypergraph is constructed to comprehensively capture inter-device relationships across three dimensions: spatial attribute-related, device attribute-related, and social attribute-related. Next, a self-supervised learning framework is developed to integrate these multi-dimensional relationships and generate device embeddings enriched with relational semantics. In this learning framework, the relationship hypergraph is augmented into two distinct views to enhance semantic information. A parameter-sharing hypergraph neural network is then utilized to learn device embeddings from both views. To further enhance embedding quality, a CCA approach is applied, allowing the comparison of data between the two views. Finally, the trustworthiness of devices is calculated based on the learned device embeddings. Extensive experiments demonstrate that the proposed HSLCCA method significantly outperforms the baseline algorithm in effectively identifying trusted devices.",
      "author": "Botao Zhu, Xianbin Wang",
      "published_date": "2025-11-18T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 220,
      "reading_time": 1,
      "created_at": "2025-11-18T05:21:07.483731+00:00",
      "updated_at": "2025-11-18T05:21:07.483734+00:00"
    },
    {
      "id": "b5b98dcfb30f81e75e366cc4b80f3554",
      "url": "https://arxiv.org/abs/2511.11577",
      "title": "From customer to product: design tools for the visually impaired",
      "content": "arXiv:2511.11577v1 Announce Type: new \nAbstract: Navigation in new or unknown environments is vital, especially for visually impaired individuals. While many solutions exist, few are tailored to specific disabilities, often due to limited collaboration with handicap users in the design process. This article examines 7 tools that enable visually impaired users to participate in design, selected through a systematic review and analyzed for affinities, differences, and applications. The study suggests correlations among the tools, offering a foundation for a methodology that enhances inclusive design and accessibility.",
      "author": "Eduardo Augusto Monteiro de Almeida (UFPB, G-SCOP\\_COSYS), Guillaume Thomann (G-SCOP\\_COSYS), Angelina Dias Le\\~ao Costa (UFPB)",
      "published_date": "2025-11-18T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 85,
      "reading_time": 1,
      "created_at": "2025-11-18T05:21:07.483684+00:00",
      "updated_at": "2025-11-18T05:21:07.483688+00:00"
    },
    {
      "id": "32a2df07f0cca7bb8fcb28e006b52581",
      "url": "https://arxiv.org/abs/2506.23293",
      "title": "Self-Organizing Language",
      "content": "arXiv:2506.23293v2 Announce Type: replace-cross \nAbstract: We introduce a novel paradigm of emergent local memory. It is a continuous-learning completely-parallel content-addressable memory encoding global order. It demonstrates how local constraints on uncoordinated learning can produce topologically protected memories realizing emergent symbolic order. It is therefore a neuro-symbolic bridge.\n  It further has the ability to produce human language without data, by exploiting its own self-organizing dynamics. It teaches us that words arise as a side-effect of emergent symbolic order, and that human language patterns at all structural levels reflect a universal mechanism of word formation (which is subregular). This work answers essential questions about the existence \\& origin of all the human language data.",
      "author": "P. Myles Eugenio, Anthony Beavers",
      "published_date": "2025-11-18T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 112,
      "reading_time": 1,
      "created_at": "2025-11-18T05:21:06.394554+00:00",
      "updated_at": "2025-11-18T05:21:06.394556+00:00"
    },
    {
      "id": "afe06f568783535dd2198df288afd64e",
      "url": "https://arxiv.org/abs/2506.05178",
      "title": "Associative Memory and Generative Diffusion in the Zero-noise Limit",
      "content": "arXiv:2506.05178v2 Announce Type: replace-cross \nAbstract: This paper shows that generative diffusion processes converge to associative memory systems at vanishing noise levels and characterizes the stability, robustness, memorization, and generation dynamics of both model classes. Morse-Smale dynamical systems are shown to be universal approximators of associative memory models, with diffusion processes as their white-noise perturbations. The universal properties of associative memory that follow are used to characterize a generic transition from generation to memory as noise diminishes. Structural stability of Morse-Smale flows -- that is, the robustness of their global critical point structure -- implies the stability of both trajectories and invariant measures for diffusions in the zero-noise limit. The learning and generation landscapes of these models appear as parameterized families of gradient flows and their stochastic perturbations, and the bifurcation theory for Morse-Smale systems implies that they are generically stable except at isolated parameter values, where enumerable sets of local and global bifurcations govern transitions between stable systems in parameter space. These landscapes are thus characterized by ordered bifurcation sequences that create, destroy, or alter connections between rest points and are robust under small stochastic or deterministic perturbations. The framework is agnostic to model formulation, which we verify with examples from energy-based models, denoising diffusion models, and classical and modern Hopfield networks. We additionally derive structural stability criteria for Hopfield-type networks and find that simple cases violate them. Collectively, our geometric approach provides insight into the classification, stability, and emergence of memory and generative landscapes.",
      "author": "Joshua Hess, Quaid Morris",
      "published_date": "2025-11-18T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 245,
      "reading_time": 1,
      "created_at": "2025-11-18T05:21:06.394528+00:00",
      "updated_at": "2025-11-18T05:21:06.394529+00:00"
    },
    {
      "id": "88c33eee0557d47002de6a2ebf297938",
      "url": "https://arxiv.org/abs/2505.15813",
      "title": "Meta-Learning an In-Context Transformer Model of Human Higher Visual Cortex",
      "content": "arXiv:2505.15813v2 Announce Type: replace-cross \nAbstract: Understanding functional representations within higher visual cortex is a fundamental question in computational neuroscience. While artificial neural networks pretrained on large-scale datasets exhibit striking representational alignment with human neural responses, learning image-computable models of visual cortex relies on individual-level, large-scale fMRI datasets. The necessity for expensive, time-intensive, and often impractical data acquisition limits the generalizability of encoders to new subjects and stimuli. BraInCoRL uses in-context learning to predict voxelwise neural responses from few-shot examples without any additional finetuning for novel subjects and stimuli. We leverage a transformer architecture that can flexibly condition on a variable number of in-context image stimuli, learning an inductive bias over multiple subjects. During training, we explicitly optimize the model for in-context learning. By jointly conditioning on image features and voxel activations, our model learns to directly generate better performing voxelwise models of higher visual cortex. We demonstrate that BraInCoRL consistently outperforms existing voxelwise encoder designs in a low-data regime when evaluated on entirely novel images, while also exhibiting strong test-time scaling behavior. The model also generalizes to an entirely new visual fMRI dataset, which uses different subjects and fMRI data acquisition parameters. Further, BraInCoRL facilitates better interpretability of neural signals in higher visual cortex by attending to semantically relevant stimuli. Finally, we show that our framework enables interpretable mappings from natural language queries to voxel selectivity.",
      "author": "Muquan Yu, Mu Nan, Hossein Adeli, Jacob S. Prince, John A. Pyles, Leila Wehbe, Margaret M. Henderson, Michael J. Tarr, Andrew F. Luo",
      "published_date": "2025-11-18T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 226,
      "reading_time": 1,
      "created_at": "2025-11-18T05:21:06.394491+00:00",
      "updated_at": "2025-11-18T05:21:06.394493+00:00"
    },
    {
      "id": "5332f3dd03231d3e581ed1f78ccf0ee4",
      "url": "https://arxiv.org/abs/2410.16136",
      "title": "Modeling Dynamic Neural Activity by combining Naturalistic Video Stimuli and Stimulus-independent Latent Factors",
      "content": "arXiv:2410.16136v3 Announce Type: replace \nAbstract: The neural activity in the visual processing is influenced by both external stimuli and internal brain states. Ideally, a neural predictive model should account for both of them. Currently, there are no dynamic encoding models that explicitly model a latent state and the entire neuronal response distribution. We address this gap by proposing a probabilistic model that predicts the joint distribution of the neuronal responses from video stimuli and stimulus-independent latent factors. After training and testing our model on mouse V1 neuronal responses, we find that it outperforms video-only models in terms of log-likelihood and achieves improvements in likelihood and correlation when conditioned on responses from other neurons. Furthermore, we find that the learned latent factors strongly correlate with mouse behavior and that they exhibit patterns related to the neurons' position on the visual cortex, although the model was trained without behavior and cortical coordinates. Our findings demonstrate that unsupervised learning of latent factors from population responses can reveal biologically meaningful structure that bridges sensory processing and behavior, without requiring explicit behavioral annotations during training.",
      "author": "Finn Schmidt, Polina Turishcheva, Suhas Shrinivasan, Fabian H. Sinz",
      "published_date": "2025-11-18T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 180,
      "reading_time": 1,
      "created_at": "2025-11-18T05:21:06.394456+00:00",
      "updated_at": "2025-11-18T05:21:06.394458+00:00"
    },
    {
      "id": "1ac2695ea70032a42319a7655de6d57b",
      "url": "https://arxiv.org/abs/2511.13668",
      "title": "Integrative Model for Interoception and Exteroception: predictive coding, points of modulation, and testable predictions",
      "content": "arXiv:2511.13668v1 Announce Type: new \nAbstract: Interoception and exteroception provide continuous feedback about the body and the environment, yet how they are dynamically integrated within a unified predictive coding framework has remained under-specified. This paper develops and empirically validates an integrative predictive coding model that treats interoceptive and exteroceptive inference as parallel hierarchical systems exchanging precision-weighted prediction errors. Within this framework, arbitration between the two streams is governed by relative precision weights (w) and integrated within the anterior insula (AIC) and anterior cingulate cortex (ACC). Computational simulations of the model reproduced biologically plausible dynamics: prediction errors decayed exponentially while arbitration weights self-normalized toward equilibrium (w = 0.5), demonstrating stable convergence and coherent integration. Simulated anxiety and PTSD profiles, characterized respectively by interoceptive and exteroceptive overweighting, yielded rigid, self-sustaining imbalances (w to 1 or w to 0) and slowed recalibration. Empirical application of the arbitration equation to published EEG-fMRI datasets further validated the model. The framework contributes a unifying account of how dysregulated precision weighting may underlie anxiety (overweighted interoception) and PTSD (underweighted interoception). Building on this validation, a proposed experimental paradigm is outlined to test the model's predictions in humans. It examines recalibration across anxiety, neutral, and PTSD groups following targeted interoceptive or exteroceptive therapies. Key predictions include identifiable neural markers of coherence, modulation of heartbeat-evoked potentials by vagal stimulation, and precision-sensitive behavioral signatures in interoceptive-exteroceptive congruency tasks.",
      "author": "Pranjal Balar, Sundeep Kapila",
      "published_date": "2025-11-18T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 227,
      "reading_time": 1,
      "created_at": "2025-11-18T05:21:06.394424+00:00",
      "updated_at": "2025-11-18T05:21:06.394426+00:00"
    },
    {
      "id": "a6597888df51d997a4beef8f165434de",
      "url": "https://arxiv.org/abs/2511.12715",
      "title": "Predicting upcoming visual features during eye movements yields scene representations aligned with human visual cortex",
      "content": "arXiv:2511.12715v1 Announce Type: new \nAbstract: Scenes are complex, yet structured collections of parts, including objects and surfaces, that exhibit spatial and semantic relations to one another. An effective visual system therefore needs unified scene representations that relate scene parts to their location and their co-occurrence. We hypothesize that this structure can be learned self-supervised from natural experience by exploiting the temporal regularities of active vision: each fixation reveals a locally-detailed glimpse that is statistically related to the previous one via co-occurrence and saccade-conditioned spatial regularities. We instantiate this idea with Glimpse Prediction Networks (GPNs) -- recurrent models trained to predict the feature embedding of the next glimpse along human-like scanpaths over natural scenes. GPNs successfully learn co-occurrence structure and, when given relative saccade location vectors, show sensitivity to spatial arrangement. Furthermore, recurrent variants of GPNs were able to integrate information across glimpses into a unified scene representation. Notably, these scene representations align strongly with human fMRI responses during natural-scene viewing across mid/high-level visual cortex. Critically, GPNs outperform architecture- and dataset-matched controls trained with explicit semantic objectives, and match or exceed strong modern vision baselines, leaving little unique variance for those alternatives. These results establish next-glimpse prediction during active vision as a biologically plausible, self-supervised route to brain-aligned scene representations learned from natural visual experience.",
      "author": "Sushrut Thorat, Adrien Doerig, Alexander Kroner, Carmen Amme, Tim C. Kietzmann",
      "published_date": "2025-11-18T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 214,
      "reading_time": 1,
      "created_at": "2025-11-18T05:21:06.394384+00:00",
      "updated_at": "2025-11-18T05:21:06.394387+00:00"
    },
    {
      "id": "4dd527590fb9e81c2db8cc31ae770057",
      "url": "https://arxiv.org/abs/2511.11609",
      "title": "A Stochastic Quantum Neural Network Model for Ai",
      "content": "arXiv:2511.11609v1 Announce Type: new \nAbstract: Artificial intelligence (AI) has drawn significant inspiration from neuroscience to develop artificial neural network (ANN) models. However, these models remain constrained by the Von Neumann architecture and struggle to capture the complexity of the biological brain. Quantum computing, with its foundational principles of superposition, entanglement, and unitary evolution, offers a promising alternative approach to modeling neural dynamics. This paper explores the possibility of a neuro-quantum model of the brain by introducing a stochastic quantum approach that incorporates random fluctuations of neuronal processing within a quantum framework. We propose a mathematical formalization of stochastic quantum neural networks (QNNS), where qubits evolve according to stochastic differential equations inspired by biological neuronal processes. We also discuss challenges related to decoherence, qubit stability, and implications for AI and computational neuroscience.",
      "author": "Gautier-Edouard Filardo (CREOGN), Thibaut Heckmann (CREOGN)",
      "published_date": "2025-11-18T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 131,
      "reading_time": 1,
      "created_at": "2025-11-18T05:21:06.394325+00:00",
      "updated_at": "2025-11-18T05:21:06.394329+00:00"
    },
    {
      "id": "e5335568b217bf1bd72c2220cae0b005",
      "url": "https://www.biorxiv.org/content/10.1101/2025.11.17.688881v1?rss=1",
      "title": "Probabilistic working memory representations in human cortex guide behavior",
      "content": "Models of working memory make fundamentally different commitments to the architecture of individual memories. Information-sparse models conceptualize individual memories as single point estimates agnostic to meta-cognitive variables such as uncertainty. In contrast, information-rich models propose memories are encoded as probability distributions over feature space that embed memory uncertainty in the shape of the distribution. To distinguish these accounts, we constructed probability distributions of memory from participants iterative reports of motion direction on each trial. Remarkably, the idiosyncratic shape of these distributions (e.g., asymmetry) on single trials matched the shape of neural probability distributions decoded from fMRI patterns measured from occipital and parietal cortex. Consistent with information-rich models, the neural representation of an individual memory encodes more than the memorized feature; its variance (i.e., width and asymmetry) encodes idiosyncrasies whose read-out predicts memory behavior.",
      "author": "Zhou, Y., Curtis, C. E., Fougnie, D., Sreenivasan, K. K.",
      "published_date": "2025-11-17T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 133,
      "reading_time": 1,
      "created_at": "2025-11-18T05:20:57.423302+00:00",
      "updated_at": "2025-11-18T05:20:57.423307+00:00"
    },
    {
      "id": "8bd25d9aabcd733190a03c6b86bc309d",
      "url": "https://www.nature.com/articles/s41380-025-03344-y",
      "title": "NLRP3-mediated trained immunity of microglia is involved in the recurrence-like episode of depressive disorders",
      "content": "",
      "author": "",
      "published_date": "2025-11-18T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-11-18T05:20:56.197773+00:00",
      "updated_at": "2025-11-18T05:20:56.197777+00:00"
    },
    {
      "id": "46eab8d34082034e0b7e0ee499a86b35",
      "url": "https://arxiv.org/abs/2511.08544",
      "title": "LeJEPA",
      "content": "<a href=\"https://news.ycombinator.com/item?id=45960922\">Comments</a>",
      "author": "",
      "published_date": "2025-11-18T02:58:31+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-11-18T05:20:20.438684+00:00",
      "updated_at": "2025-11-18T05:20:20.438685+00:00"
    }
  ]
}