{
  "last_updated": "2025-09-26T04:24:30.870993+00:00",
  "count": 20,
  "articles": [
    {
      "id": "7c9ccc43b6145740efaef749f5672ac6",
      "url": "https://arxiv.org/abs/2509.20369",
      "title": "AI-driven formative assessment and adaptive learning in data-science education: Evaluating an LLM-powered virtual teaching assistant",
      "content": "arXiv:2509.20369v1 Announce Type: cross \nAbstract: This paper presents VITA (Virtual Teaching Assistants), an adaptive distributed learning (ADL) platform that embeds a large language model (LLM)-powered chatbot (BotCaptain) to provide dialogic support, interoperable analytics, and integrity-aware assessment for workforce preparation in data science. The platform couples context-aware conversational tutoring with formative-assessment patterns designed to promote reflective reasoning. The paper describes an end-to-end data pipeline that transforms chat logs into Experience API (xAPI) statements, instructor dashboards that surface outliers for just-in-time intervention, and an adaptive pathway engine that routes learners among progression, reinforcement, and remediation content. The paper also benchmarks VITA conceptually against emerging tutoring architectures, including retrieval-augmented generation (RAG)--based assistants and Learning Tools Interoperability (LTI)--integrated hubs, highlighting trade-offs among content grounding, interoperability, and deployment complexity. Contributions include a reusable architecture for interoperable conversational analytics, a catalog of patterns for integrity-preserving formative assessment, and a practical blueprint for integrating adaptive pathways into data-science courses. The paper concludes with implementation lessons and a roadmap (RAG integration, hallucination mitigation, and LTI~1.3 / OpenID Connect) to guide multi-course evaluations and broader adoption. In light of growing demand and scalability constraints in traditional instruction, the approach illustrates how conversational AI can support engagement, timely feedback, and personalized learning at scale. Future work will refine the platform's adaptive intelligence and examine applicability across varied educational settings.",
      "author": "Fadjimata I Anaroua, Qing Li, Yan Tang, Hong P. Liu",
      "published_date": "2025-09-26T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 219,
      "reading_time": 1,
      "created_at": "2025-09-26T04:24:10.942489+00:00",
      "updated_at": "2025-09-26T04:24:10.942491+00:00"
    },
    {
      "id": "3efa9f66e0ddd59f944185876e7a51ca",
      "url": "https://arxiv.org/abs/2509.21188",
      "title": "Adoption, usability and perceived clinical value of a UK AI clinical reference platform (iatroX): a mixed-methods formative evaluation of real-world usage and a 1,223-respondent user survey",
      "content": "arXiv:2509.21188v1 Announce Type: new \nAbstract: Clinicians face growing information overload from biomedical literature and guidelines, hindering evidence-based care. Retrieval-augmented generation (RAG) with large language models may provide fast, provenance-linked answers, but requires real-world evaluation. We describe iatroX, a UK-centred RAG-based clinical reference platform, and report early adoption, usability, and perceived clinical value from a formative implementation evaluation. Methods comprised a retrospective analysis of usage across web, iOS, and Android over 16 weeks (8 April-31 July 2025) and an in-product intercept survey. Usage metrics were drawn from web and app analytics with bot filtering. A client-side script randomized single-item prompts to approx. 10% of web sessions from a predefined battery assessing usefulness, reliability, and adoption intent. Proportions were summarized with Wilson 95% confidence intervals; free-text comments underwent thematic content analysis. iatroX reached 19,269 unique web users, 202,660 engagement events, and approx. 40,000 clinical queries. Mobile uptake included 1,960 iOS downloads and Android growth (peak >750 daily active users). The survey yielded 1,223 item-level responses: perceived usefulness 86.2% (95% CI 74.8-93.9%; 50/58); would use again 93.3% (95% CI 68.1-99.8%; 14/15); recommend to a colleague 88.4% (95% CI 75.1-95.9%; 38/43); perceived accuracy 75.0% (95% CI 58.8-87.3%; 30/40); reliability 79.4% (95% CI 62.1-91.3%; 27/34). Themes highlighted speed, guideline-linked answers, and UK specificity. Early real-world use suggests iatroX can mitigate information overload and support timely answers for UK clinicians. Limitations include small per-item samples and early-adopter bias; future work will include accuracy audits and prospective studies on workflow and care quality.",
      "author": "Kolawole Tytler",
      "published_date": "2025-09-26T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 246,
      "reading_time": 1,
      "created_at": "2025-09-26T04:24:10.942452+00:00",
      "updated_at": "2025-09-26T04:24:10.942455+00:00"
    },
    {
      "id": "2ca1ec84cdfeb409b6478273d82e53c6",
      "url": "https://arxiv.org/abs/2509.20901",
      "title": "CafGa: Customizing Feature Attributions to Explain Language Models",
      "content": "arXiv:2509.20901v1 Announce Type: new \nAbstract: Feature attribution methods, such as SHAP and LIME, explain machine learning model predictions by quantifying the influence of each input component. When applying feature attributions to explain language models, a basic question is defining the interpretable components. Traditional feature attribution methods, commonly treat individual words as atomic units. This is highly computationally inefficient for long-form text and fails to capture semantic information that spans multiple words. To address this, we present CafGa, an interactive tool for generating and evaluating feature attribution explanations at customizable granularities. CafGa supports customized segmentation with user interaction and visualizes the deletion and insertion curves for explanation assessments. Through a user study involving participants of various expertise, we confirm CafGa's usefulness, particularly among LLM practitioners. Explanations created using CafGa were also perceived as more useful compared to those generated by two fully automatic baseline methods: PartitionSHAP and MExGen, suggesting the effectiveness of the system.",
      "author": "Alan Boyle, Furui Cheng, Vil\\'em Zouhar, Mennatallah El-Assady",
      "published_date": "2025-09-26T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 153,
      "reading_time": 1,
      "created_at": "2025-09-26T04:24:10.942401+00:00",
      "updated_at": "2025-09-26T04:24:10.942402+00:00"
    },
    {
      "id": "f7f1aa6e4da844f9c6ba6817f13fe942",
      "url": "https://arxiv.org/abs/2509.20817",
      "title": "Even More Kawaii than Real-Person-Driven VTubers? Understanding How Viewers Perceive AI-Driven VTubers",
      "content": "arXiv:2509.20817v1 Announce Type: new \nAbstract: VTubers, digital personas represented by animated avatars, have gained massive popularity. Traditionally, VTubers are operated and voiced by human controllers known as Nakanohito. The reliance on Nakanohito, however, poses risks due to potential personal controversies and operational disruptions. The emergence of AI-driven VTubers offers a new model free from these human constraints. While AI-driven VTubers present benefits such as continuous operation and reduced scandal risk, they also raise questions about authenticity and audience engagement. Therefore, to gain deeper insights, we conduct a case study, investigating viewer perceptions of Neuro-sama, the most popular AI-driven VTuber with 845k followers on Twitch and 753k followers on YouTube. We analyze 108k Reddit posts and 136k YouTube comments, aiming to better understand viewer motivations, how AI constructs the virtual persona, and perceptions of the AI as Nakanohito. Our findings enhance the understanding of AI-driven VTubers and their impact on digital streaming culture.",
      "author": "Yiluo Wei, Yupeng He, Gareth Tyson",
      "published_date": "2025-09-26T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 152,
      "reading_time": 1,
      "created_at": "2025-09-26T04:24:10.942371+00:00",
      "updated_at": "2025-09-26T04:24:10.942373+00:00"
    },
    {
      "id": "cec62a849a78c5db7bd2b42c51569555",
      "url": "https://arxiv.org/abs/2509.20799",
      "title": "AuthGlass: Enhancing Voice Authentication on Smart Glasses via Air-Bone Acoustic Features",
      "content": "arXiv:2509.20799v1 Announce Type: new \nAbstract: With the rapid advancement of smart glasses, voice interaction has become widely deployed due to its naturalness and convenience. However, its practicality is often undermined by the vulnerability to spoofing attacks and interference from surrounding sounds, making seamless voice authentication crucial for smart glasses usage. To address this challenge, we propose AuthGlass, a voice authentication approach that leverages both air- and bone-conducted speech features to enhance accuracy and liveness detection. Aiming to gain comprehensive knowledge on speech-related acoustic and vibration features, we built a smart glasses prototype with redundant synchronized microphones: 14 air-conductive microphones and 2 bone-conductive units. In a study with 42 participants, we validated that combining sound-field and vibration features significantly improves authentication robustness and attack resistance. Furthermore, experiments demonstrated that AuthGlass maintains competitive accuracy even under various practical scenarios, highlighting its applicability and scalability for real-world deployment.",
      "author": "Weiye Xu, Zhang Jiang, Siqi Zheng, Xiyuxing Zhang, Yankai Zhao, Changhao Zhang, Jian Liu, Weiqiang Wang, Yuntao Wang",
      "published_date": "2025-09-26T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 145,
      "reading_time": 1,
      "created_at": "2025-09-26T04:24:10.942338+00:00",
      "updated_at": "2025-09-26T04:24:10.942339+00:00"
    },
    {
      "id": "76ccd150fc9727dc042db56a71cf117f",
      "url": "https://arxiv.org/abs/2509.20731",
      "title": "Imagining Design Workflows in Agentic AI Futures",
      "content": "arXiv:2509.20731v1 Announce Type: new \nAbstract: As designers become familiar with Generative AI, a new concept is emerging: Agentic AI. While generative AI produces output in response to prompts, agentic AI systems promise to perform mundane tasks autonomously, potentially freeing designers to focus on what they love: being creative. But how do designers feel about integrating agentic AI systems into their workflows? Through design fiction, we investigated how designers want to interact with a collaborative agentic AI platform. Ten professional designers imagined and discussed collaborating with an AI agent to organise inspiration sources and ideate. Our findings highlight the roles AI agents can play in supporting designers, the division of authority between humans and AI, and how designers' intent can be explained to AI agents beyond prompts. We synthesise our findings into a conceptual framework that identifies authority distribution among humans and AI agents and discuss directions for utilising AI agents in future design workflows.",
      "author": "Samangi Wadinambiarachchi, Jenny Waycott, Yvonne Rogers, Greg Wadley",
      "published_date": "2025-09-26T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 154,
      "reading_time": 1,
      "created_at": "2025-09-26T04:24:10.942309+00:00",
      "updated_at": "2025-09-26T04:24:10.942310+00:00"
    },
    {
      "id": "3193cc01e650ebe889084a39dc561f20",
      "url": "https://arxiv.org/abs/2509.20666",
      "title": "Understanding Mode Switching in Human-AI Collaboration: Behavioral Insights and Predictive Modeling",
      "content": "arXiv:2509.20666v1 Announce Type: new \nAbstract: Human-AI collaboration is typically offered in one of two of user control levels: guidance, where the AI provides suggestions and the human makes the final decision, and delegation, where the AI acts autonomously within user-defined constraints. Systems that integrate both modes, common in robotic surgery or driving assistance, often overlook shifts in user preferences within a task in response to factors like evolving trust, decision complexity, and perceived control. In this work, we investigate how users dynamically switch between higher and lower levels of control during a sequential decision-making task. Using a hand-and-brain chess setup, participants either selected a piece and the AI decided how it moved (brain mode), or the AI selected a piece and the participant decided how it moved (hand mode). We collected over 400 mode-switching decisions from eight participants, along with gaze, emotional state, and subtask difficulty data. Statistical analysis revealed significant differences in gaze patterns and subtask complexity prior to a switch and in the quality of the subsequent move. Based on these results, we engineered behavioral and task-specific features to train a lightweight model that predicted control level switches ($F1 = 0.65$). The model performance suggests that real-time behavioral signals can serve as a complementary input alongside system-driven mode-switching mechanisms currently used. We complement our quantitative results with qualitative factors that influence switching including perceived AI ability, decision complexity, and level of control, identified from post-game interview analysis. The combined behavioral and modeling insights can help inform the design of shared autonomy systems that need dynamic, subtask-level control switches aligned with user intent and evolving task demands.",
      "author": "Avinash Ajit Nargund, Arthur Caetano, Kevin Yang, Rose Yiwei Liu, Philip Tezaur, Kriteen Shrestha, Qisen Pan, Tobias H\\\"ollerer, Misha Sra",
      "published_date": "2025-09-26T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 268,
      "reading_time": 1,
      "created_at": "2025-09-26T04:24:10.942280+00:00",
      "updated_at": "2025-09-26T04:24:10.942281+00:00"
    },
    {
      "id": "1d16aa79e82b67ae2db4ab846d20632b",
      "url": "https://arxiv.org/abs/2509.20571",
      "title": "MechStyle: Augmenting Generative AI with Mechanical Simulation to Create Stylized and Structurally Viable 3D Models",
      "content": "arXiv:2509.20571v1 Announce Type: new \nAbstract: Recent developments in Generative AI enable creators to stylize 3D models based on text prompts. These methods change the 3D model geometry, which can compromise the model's structural integrity once fabricated. We present MechStyle, a system that enables creators to stylize 3D printable models while preserving their structural integrity. MechStyle accomplishes this by augmenting the Generative AI-based stylization process with feedback from a Finite Element Analysis (FEA) simulation. As the stylization process modifies the geometry to approximate the desired style, feedback from the FEA simulation reduces modifications to regions with increased stress. We evaluate the effectiveness of FEA simulation feedback in the augmented stylization process by comparing three stylization control strategies. We also investigate the time efficiency of our approach by comparing three adaptive scheduling strategies. Finally, we demonstrate MechStyle's user interface that allows users to generate stylized and structurally viable 3D models and provide five example applications.",
      "author": "Faraz Faruqi, Amira Abdel-Rahman, Leandra Tejedor, Martin Nisser, Jiaji Li, Vrushank Phadnis, Varun Jampani, Neil Gershenfeld, Megan Hofmann, Stefanie Mueller",
      "published_date": "2025-09-26T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 153,
      "reading_time": 1,
      "created_at": "2025-09-26T04:24:10.942239+00:00",
      "updated_at": "2025-09-26T04:24:10.942240+00:00"
    },
    {
      "id": "031e1f278d4efe91fb66307ec8481a9e",
      "url": "https://arxiv.org/abs/2509.20553",
      "title": "Perspectra: Choosing Your Experts Enhances Critical Thinking in Multi-Agent Research Ideation",
      "content": "arXiv:2509.20553v1 Announce Type: new \nAbstract: Recent advances in multi-agent systems (MAS) enable tools for information search and ideation by assigning personas to agents. However, how users can effectively control, steer, and critically evaluate collaboration among multiple domain-expert agents remains underexplored. We present Perspectra, an interactive MAS that visualizes and structures deliberation among LLM agents via a forum-style interface, supporting @-mention to invite targeted agents, threading for parallel exploration, with a real-time mind map for visualizing arguments and rationales. In a within-subjects study with 18 participants, we compared Perspectra to a group-chat baseline as they developed research proposals. Our findings show that Perspectra significantly increased the frequency and depth of critical-thinking behaviors, elicited more interdisciplinary replies, and led to more frequent proposal revisions than the group chat condition. We discuss implications for designing multi-agent tools that scaffold critical thinking by supporting user control over multi-agent adversarial discourse.",
      "author": "Yiren Liu, Viraj Shah, Sangho Suh, Pao Siangliulue, Tal August, Yun Huang",
      "published_date": "2025-09-26T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 146,
      "reading_time": 1,
      "created_at": "2025-09-26T04:24:10.942208+00:00",
      "updated_at": "2025-09-26T04:24:10.942210+00:00"
    },
    {
      "id": "392dc948d96793dc59ca50fb7c48e04c",
      "url": "https://arxiv.org/abs/2509.20512",
      "title": "CHOIR: A Chatbot-mediated Organizational Memory Leveraging Communication in University Research Labs",
      "content": "arXiv:2509.20512v1 Announce Type: new \nAbstract: University research labs often rely on chat-based platforms for communication and project management, where valuable knowledge surfaces but is easily lost in message streams. Documentation can preserve knowledge, but it requires ongoing maintenance and is challenging to navigate. Drawing on formative interviews that revealed organizational memory challenges in labs, we designed CHOIR, an LLM-based chatbot that supports organizational memory through four key functions: document-grounded Q&amp;A, Q&amp;A sharing for follow-up discussion, knowledge extraction from conversations, and AI-assisted document updates. We deployed CHOIR in four research labs for one month (n=21), where the lab members asked 107 questions and lab directors updated documents 38 times in the organizational memory. Our findings reveal a privacy-awareness tension: questions were asked privately, limiting directors' visibility into documentation gaps. Students often avoided contribution due to challenges in generalizing personal experiences into universal documentation. We contribute design implications for privacy-preserving awareness and supporting context-specific knowledge documentation.",
      "author": "Sangwook Lee, Adnan Abbas, Yan Chen, Young-Ho Kim, Sang Won Lee",
      "published_date": "2025-09-26T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 154,
      "reading_time": 1,
      "created_at": "2025-09-26T04:24:10.942174+00:00",
      "updated_at": "2025-09-26T04:24:10.942177+00:00"
    },
    {
      "id": "424fd3a4970e25b0acbcf5e5fe47946d",
      "url": "https://arxiv.org/abs/2508.16509",
      "title": "ML-PWS: Estimating the Mutual Information Between Experimental Time Series Using Neural Networks",
      "content": "arXiv:2508.16509v2 Announce Type: replace-cross \nAbstract: The ability to quantify information transmission is crucial for the analysis and design of natural and engineered systems. The information transmission rate is the fundamental measure for systems with time-varying signals, yet computing it is extremely challenging. In particular, the rate cannot be obtained directly from experimental time-series data without approximations, because of the high dimensionality of the signal trajectory space. Path Weight Sampling (PWS) is a computational technique that makes it possible to obtain the information rate exactly for any stochastic system. However, it requires a mathematical model of the system of interest, be it described by a master equation or a set of differential equations. Here, we present a technique that employs Machine Learning (ML) to develop a generative model from experimental time-series data, which is then combined with PWS to obtain the information rate. We demonstrate the accuracy of this technique, called ML-PWS, by comparing its results on synthetic time-series data generated from a non-linear model against ground-truth results obtained by applying PWS directly to the same model. We illustrate the utility of ML-PWS by applying it to neuronal time-series data.",
      "author": "Manuel Reinhardt, Ga\\v{s}per Tka\\v{c}ik, Pieter Rein ten Wolde",
      "published_date": "2025-09-26T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 189,
      "reading_time": 1,
      "created_at": "2025-09-26T04:24:09.874374+00:00",
      "updated_at": "2025-09-26T04:24:09.874376+00:00"
    },
    {
      "id": "b35d4e4ccf288a46cb6efcb7cf5f20f8",
      "url": "https://arxiv.org/abs/2502.01360",
      "title": "A Quotient Homology Theory of Representation in Neural Networks",
      "content": "arXiv:2502.01360v3 Announce Type: replace-cross \nAbstract: Previous research has proven that the set of maps implemented by neural networks with a ReLU activation function is identical to the set of piecewise linear continuous maps. Furthermore, such networks induce a hyperplane arrangement splitting the input domain of the network into convex polyhedra $G_J$ over which a network $\\Phi$ operates in an affine manner.\n  In this work, we leverage these properties to define an equivalence class $\\sim_\\Phi$ on top of an input dataset, which can be split into two sets related to the local rank of $\\Phi_J$ and the intersections $\\cap \\text{Im}\\Phi_{J_i}$. We refer to the latter as the \\textit{overlap decomposition} $\\mathcal{O}_\\Phi$ and prove that if the intersections between each polyhedron and an input manifold are convex, the homology groups of neural representations are isomorphic to quotient homology groups $H_k(\\Phi(\\mathcal{M})) \\simeq H_k(\\mathcal{M}/\\mathcal{O}_\\Phi)$. This lets us intrinsically calculate the Betti numbers of neural representations without the choice of an external metric. We develop methods to numerically compute the overlap decomposition through linear programming and a union-find algorithm.\n  Using this framework, we perform several experiments on toy datasets showing that, compared to standard persistent homology, our overlap homology-based computation of Betti numbers tracks purely topological rather than geometric features. Finally, we study the evolution of the overlap decomposition during training on several classification problems while varying network width and depth and discuss some shortcomings of our method.",
      "author": "Kosio Beshkov",
      "published_date": "2025-09-26T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 232,
      "reading_time": 1,
      "created_at": "2025-09-26T04:24:09.874343+00:00",
      "updated_at": "2025-09-26T04:24:09.874345+00:00"
    },
    {
      "id": "4acad20b64b64698b31230a66720d623",
      "url": "https://arxiv.org/abs/2507.16080",
      "title": "Interpretable Embeddings of Speech Enhance and Explain Brain Encoding Performance of Audio Models",
      "content": "arXiv:2507.16080v2 Announce Type: replace \nAbstract: Speech foundation models (SFMs) are increasingly hailed as powerful computational models of human speech perception. However, since their representations are inherently black-box, it remains unclear what drives their alignment with brain responses. To remedy this, we built linear encoding models from six interpretable feature families: mel-spectrogram, Gabor filter bank features, speech presence, phonetic, syntactic, and semantic features, and contextualized embeddings from three state-of-the-art SFMs (Whisper, HuBERT, WavLM), quantifying electrocorticography (ECoG) response variance shared between feature classes. Variance-partitioning analyses revealed several key insights: First, the SFMs' alignment with the brain can be mostly explained by their ability to learn and encode simple interpretable speech features. Second, SFMs exhibit a systematic trade-off between encoding of brain-relevant low-level and high-level features across layers. Finally, our results show that SFMs learn brain-relevant semantics which cannot be explained by lower-level speech features, with this capacity increasing with model size and context length. Together, our findings suggest a principled approach to build more interpretable, accurate, and efficient encoding models of the brain by augmenting SFM embeddings with interpretable features.",
      "author": "Riki Shimizu, Richard J. Antonello, Chandan Singh, Nima Mesgarani",
      "published_date": "2025-09-26T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 178,
      "reading_time": 1,
      "created_at": "2025-09-26T04:24:09.874308+00:00",
      "updated_at": "2025-09-26T04:24:09.874309+00:00"
    },
    {
      "id": "c20c73f6e85bc427d5f2c976351e99c6",
      "url": "https://arxiv.org/abs/2509.20916",
      "title": "Cross-Linguistic Analysis of Memory Load in Sentence Comprehension: Linear Distance and Structural Density",
      "content": "arXiv:2509.20916v1 Announce Type: cross \nAbstract: This study examines whether sentence-level memory load in comprehension is better explained by linear proximity between syntactically related words or by the structural density of the intervening material. Building on locality-based accounts and cross-linguistic evidence for dependency length minimization, the work advances Intervener Complexity-the number of intervening heads between a head and its dependent-as a structurally grounded lens that refines linear distance measures. Using harmonized dependency treebanks and a mixed-effects framework across multiple languages, the analysis jointly evaluates sentence length, dependency length, and Intervener Complexity as predictors of the Memory-load measure. Studies in Psycholinguistics have reported the contributions of feature interference and misbinding to memory load during processing. For this study, I operationalized sentence-level memory load as the linear sum of feature misbinding and feature interference for tractability; current evidence does not establish that their cognitive contributions combine additively. All three factors are positively associated with memory load, with sentence length exerting the broadest influence and Intervener Complexity offering explanatory power beyond linear distance. Conceptually, the findings reconcile linear and hierarchical perspectives on locality by treating dependency length as an important surface signature while identifying intervening heads as a more proximate indicator of integration and maintenance demands. Methodologically, the study illustrates how UD-based graph measures and cross-linguistic mixed-effects modelling can disentangle linear and structural contributions to processing efficiency, providing a principled path for evaluating competing theories of memory load in sentence comprehension.",
      "author": "Krishna Aggarwal",
      "published_date": "2025-09-26T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 237,
      "reading_time": 1,
      "created_at": "2025-09-26T04:24:09.874275+00:00",
      "updated_at": "2025-09-26T04:24:09.874277+00:00"
    },
    {
      "id": "9706f8b61e4824a370d7abb5ff5d9f40",
      "url": "https://arxiv.org/abs/2509.21277",
      "title": "More than a feeling: Expressive style influences cortical speech tracking in subjective cognitive decline",
      "content": "arXiv:2509.21277v1 Announce Type: new \nAbstract: Subjective cognitive decline (SCD) approximately doubles the risk of progressing to MCI and dementia. The present study investigates how one's subjective concerns of his/her own cognition are manifested in the neural dynamics during speech perception. EEG was collected from 56 Cantonese, cognitively normal older adults (aged 60 - 70) while they listened to stimuli of four expressive styles that varied in prosody: scrambled, descriptive, dialogue, and exciting. Using encoding models to predict EEG signals from acoustic, segmentation, and phonotactic features, we found that greater subjective concern was associated with weaker cortical tracking of (1) higher-level linguistic features but not acoustic features and (2) less engaging stimuli (scrambled and descriptive styles) but not prosodically rich stimuli. Overall, our results suggest that early signs of cognitive impairment can be revealed from speech perception via cortical tracking, especially while listening to prosodically flat speech.",
      "author": "Matthew King-Hang Ma, Manson Cheuk-Man Fong, Yun Feng, Cloris Pui-Hang Li, William Shiyuan Wang",
      "published_date": "2025-09-26T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 146,
      "reading_time": 1,
      "created_at": "2025-09-26T04:24:09.874225+00:00",
      "updated_at": "2025-09-26T04:24:09.874229+00:00"
    },
    {
      "id": "61a692d2f577df1977c9c0e94e1fbcfb",
      "url": "https://www.biorxiv.org/content/10.1101/2025.09.24.678252v1?rss=1",
      "title": "Changing the Motivation for Mental Work with Temporal Interference Stimulation",
      "content": "Successful goal-directed behavior often requires the exertion of effortful control processes. The striatum is thought to play a key role in determining whether a goal is worth the required cognitive effort, but whether and how the striatum causally influences effort-based decisions in humans remained unclear. Here, we address this gap by employing transcranial temporal interference stimulation (tTIS), a novel non-invasive brain stimulation technique capable of targeting deeper brain regions. We applied striatum-targeted tTIS to healthy participants performing an effort-based decision task during functional MRI scanning. Supporting the idea that the striatum encodes both the benefits and costs of actions, we found that, on the behavioral level, striatum-targeted tTIS increased the sensitivity to both reward magnitudes and effort costs. At the neural level, this was mirrored by stronger representations of effort demands in the striatum under stimulation as well as by enhanced functional coupling between the striatum and the anterior cingulate cortex, a region at the intersection of motivation and cognition. Together, our findings provide insights into the causal contributions of the striatum to trading-off rewards against effort costs, informing neural accounts of motivated cognition and suggesting novel neural interventions for the treatment of amotivation.",
      "author": "Vural, G., Drexler, S., Keeser, D., Soutschek, A.",
      "published_date": "2025-09-25T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 194,
      "reading_time": 1,
      "created_at": "2025-09-26T04:24:00.639754+00:00",
      "updated_at": "2025-09-26T04:24:00.639756+00:00"
    },
    {
      "id": "dd52b2c494a800776246522bcb540c85",
      "url": "https://www.biorxiv.org/content/10.1101/2025.09.24.678428v1?rss=1",
      "title": "High-Fidelity Neural Speech Reconstruction through an Efficient Acoustic-Linguistic Dual-Pathway Framework",
      "content": "Reconstructing speech from neural recordings is crucial for understanding speech coding and developing brain-computer interfaces (BCIs). However, existing methods trade off acoustic richness (pitch, prosody) for linguistic intelligibility (words, phonemes). To overcome this limitation, we propose a dual-path framework to concurrently decode acoustic and linguistic representations. The acoustic pathway uses a long-short term memory (LSTM) decoder and a high-fidelity generative adversarial network (HiFi-GAN) to reconstruct spectrotemporal features. The linguistic pathway employs a transformer adaptor and text-to-speech (TTS) generator for word tokens. These two pathways merge via voice cloning to combine both acoustic and linguistic validity. Using only 20 minutes of electrocorticography (ECoG) data per subject, our approach achieves highly intelligible synthesized speech (mean opinion score = 4.0/5.0, word error rate = 18.9%). Our dual-path framework reconstructs natural and intelligible speech from ECoG, resolving the acoustic-linguistic trade-off.",
      "author": "Li, J., Guo, C., Zhang, C., Chang, E. F., Li, Y.",
      "published_date": "2025-09-25T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 136,
      "reading_time": 1,
      "created_at": "2025-09-26T04:24:00.639720+00:00",
      "updated_at": "2025-09-26T04:24:00.639722+00:00"
    },
    {
      "id": "0a66c301ffd3a1d2bf2223d035a27445",
      "url": "https://www.biorxiv.org/content/10.1101/2025.09.25.678349v1?rss=1",
      "title": "Whole-genome DNA methylation profiling in COVID-19 positive patients reveals alterations in pathways linked to neurological dysfunction",
      "content": "Background Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) is a highly transmissible RNA betacoronavirus, causing coronavirus disease-19 (COVID-19). Infection with SARS-CoV-2 can result in a broad spectrum of clinical outcomes, ranging from asymptomatic or mild to a severe, deadly illness. Emerging evidence suggests SARS-CoV-2 affects host gene regulation through epigenetic mechanisms, such as DNA methylation, potentially contributing to immune dysregulation and post-acute sequelae, including neurological and psychiatric disorders. However, the extent and functional relevance of these epigenetic changes remain uncertain. Methods and results We employed whole-genome bisulfite sequencing to profile DNA methylation in peripheral blood from SARS-CoV-2-positive patients across a spectrum of symptom severity, ranging from asymptomatic to severe (n=101), in comparison to SARS-CoV-2-negative individuals (n=105). We observed a widespread hypomethylation in the genomes of infected individuals, which was more pronounced in severe cases. Notably, we identified differentially methylated genes in patients with mild (19 genes), moderate (19 genes), and severe (35 genes) symptoms. These genes included those involved in canonical immune responses as well as known to be linked to neurodegenerative diseases. Subsequent pathway enrichment analysis further supported the significant association between the differentially methylated genes and those implicated in Alzheimers and Parkinsons disease, as well as neuropsychiatric conditions, suggesting potential epigenetic links between acute SARS-CoV-2 infection and long-term neurological outcomes. This is one of the first studies to comprehensively map severity-stratified genome-wide DNA methylation changes in COVID-19 patients. Conclusion Our findings underscore the potential importance of epigenetic regulation in the acute responses to SARS-CoV-2 infection and highlight an overlap with epigenetic mechanisms relevant for neuropsychiatric disease processes.",
      "author": "Zameer, S., Anis, E., Sha, Q., Escobar Galvis, M. L., Khan, S., Steiner, J. A., Milciute, M., Kerseviciute, I., Gabrielaite, M., Gordevicius, J., Pospisilik, A., Saiyed, N., Graham, S. F., Brundin, P., Brundin, L.",
      "published_date": "2025-09-25T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 259,
      "reading_time": 1,
      "created_at": "2025-09-26T04:24:00.639689+00:00",
      "updated_at": "2025-09-26T04:24:00.639691+00:00"
    },
    {
      "id": "27d30366e1993eec239687966761eab4",
      "url": "https://www.biorxiv.org/content/10.1101/2025.09.25.678629v1?rss=1",
      "title": "A specialized cold sensing system in the naked mole-rat",
      "content": "Avoiding cold or seeking warmth are universal animal needs. Homeothermic mammals maintain a constant body temperature despite fluctuating ambient temperatures. One exception is the naked mole-rat which lacks effective thermogenesis. We show that the naked mole-rat has evolved a greatly expanded cold sensing system. Compared to mice, this species has many more cold-sensitive sensory neurons and most express the cold-activated TRPM8 channel. The naked mole-rat TrpM8 gene harbors a unique upstream exon that when translated produces a TRPM8 protein with a 71 amino acid N-terminal extension. When expressed, the N-terminal extension prevents membrane targeting and abolishes TRPM8 function. Splice forms lacking the extension formed functional cold and menthol activated channels in vivo. Additionally, many naked mole-rat sensory neurons use a TRPM8-independent mechanism to detect cold. Thus, we identified molecular changes that confer both sensitivity and flexibility to cold sensing in a species that is critically dependent on following thermal cues.",
      "author": "Wang, L., Gomez-Restrepo, A., Niqula, A., Jouhanneau, J.-S., Mendez-Aranda, D., Luo, W., Poulet, J. F. A., de la Pena, E., Viana, F., Begay, V., Lewin, G. R.",
      "published_date": "2025-09-25T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 150,
      "reading_time": 1,
      "created_at": "2025-09-26T04:24:00.639650+00:00",
      "updated_at": "2025-09-26T04:24:00.639651+00:00"
    },
    {
      "id": "c21c43df18b0afd2dce634db87b1b2d4",
      "url": "https://www.biorxiv.org/content/10.1101/2025.09.25.678501v1?rss=1",
      "title": "Proteolytic cleavage of G3BP1 by calpain 1 couples NMDAR activation to mTOR-dependent local translation",
      "content": "Ribonucleoprotein (RNP) granules are dynamic, membraneless organelles that sequester translationally repressed mRNAs and RNA-binding proteins, playing a pivotal role in the regulation of localized protein synthesis. While disassembly of RNP granules is essential for reactivating translation, the mechanisms by which neuronal activity regulates this process remain poorly understood. In this study, we show that stimulation of N-methyl-D-aspartate (NMDA) receptor (NMDAR) triggers calcium influx, leading to activation of calpain 1 and subsequent proteolytic cleavage of Ras-GTPase-activating protein binding protein 1 (G3BP1), a core component of stress granules. This cleavage results in the disassembly of G3BP1 granules in the neurites and promotes mTOR-dependent local translation, thereby linking synaptic activity to spatially restricted protein synthesis. Finally, we demonstrate that the NMDAR-calpain 1-G3BP1-mTOR signaling axis contributes to axonal regeneration, establishing proteolytic remodeling of RNP granules as a key mechanism of activity-dependent neural repair, with potential implications for therapeutic intervention in brain injury.",
      "author": "Suh, Y. H., Park, D.-h., Ahn, S.-Y., Kim, J., Choi, J., Lee, S., Kang, M., Song, J.-m.",
      "published_date": "2025-09-25T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 148,
      "reading_time": 1,
      "created_at": "2025-09-26T04:24:00.639618+00:00",
      "updated_at": "2025-09-26T04:24:00.639620+00:00"
    }
  ]
}