{
  "last_updated": "2025-11-24T05:45:46.262066+00:00",
  "count": 20,
  "articles": [
    {
      "id": "d4a9f9fad0783fdeec1c049b206b2515",
      "url": "https://www.frontiersin.org/articles/10.3389/fnhum.2025.1683924",
      "title": "Emerging technologies and neuroscience-based approaches in dyslexia: a narrative review toward integrative and personalized solutions",
      "content": "BackgroundDevelopmental dyslexia is a common neurodevelopmental disorder that impairs reading ability despite adequate intelligence and education, affecting up to 17% of children worldwide. Advances in neuroscience have revealed complex mechanisms involving phonological, visual, and temporal processing, with cross-linguistic variability. At the same time, technological innovation is driving a shift toward AI-powered diagnostics, immersive learning tools, and neurostimulation-based interventions.MethodsThis narrative review synthesizes evidence from recent research published between 2015 and 2025, focusing on four thematic areas: (1) neurobiological underpinnings of dyslexia, (2) diagnostic innovations using AI and eye- or handwriting-based deep learning, (3) neurostimulation and immersive VR/AR interventions, and (4) policy, equity, and ethical considerations. Studies were identified through major academic databases and thematically analyzed to highlight trends, strengths, and limitations.ResultsAI-based diagnostic tools using eye-tracking and handwriting features have achieved reported accuracies exceeding 80% in multiple pilot studies. VR/game-based programs and neurostimulation interventions (TMS, tDCS) have shown promising short-term effects on reading fluency and phonological processing, though evidence for long-term literacy transfer remains limited. Across studies, methodological heterogeneity and small sample sizes constrain generalizability. Significant disparities in access persist across socioeconomic, linguistic, and geographic contexts.ConclusionsWhile these technologies offer promising avenues for more personalized and scalable dyslexia care, their integration must be accompanied by stronger evidence, ethical safeguards, and equity-focused policies. Technology should augment, not replace, human interaction in inclusive education. Future research should prioritize larger trials, cross-linguistic validation, and sustainable implementation strategies.",
      "author": "Feng Zhu",
      "published_date": "2025-11-19T00:00:00+00:00",
      "source": "Frontiers Human Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 231,
      "reading_time": 1,
      "created_at": "2025-11-24T05:45:04.994054+00:00",
      "updated_at": "2025-11-24T05:45:04.994056+00:00"
    },
    {
      "id": "5de677cbd74105ea039fefec456373bd",
      "url": "https://www.frontiersin.org/articles/10.3389/fnins.2025.1737026",
      "title": "Editorial: Methods and applications of diffusion MRI tractometry",
      "content": "",
      "author": "Julio E. Villal\u00f3n-Reina",
      "published_date": "2025-11-19T00:00:00+00:00",
      "source": "Frontiers Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-11-24T05:45:02.094375+00:00",
      "updated_at": "2025-11-24T05:45:02.094377+00:00"
    },
    {
      "id": "92c454fe6a24050f54e3301877c9f699",
      "url": "https://www.frontiersin.org/articles/10.3389/fnins.2025.1632251",
      "title": "Loss of Nocturnin increases neuronal viability in oxidative stress conditions",
      "content": "Oxidative stress, characterized by an imbalance between reactive oxygen species (ROS) and antioxidants, plays a critical role in neurodegenerative disorders like Parkinson\u2019s Disease (PD) and is strongly associated with neuronal cell death. Nocturnin was identified as a NADP(H) phosphatase and key regulator of oxidative stress. NADPH serves as a crucial co-factor for enzymes which regenerate antioxidants, and downregulation of its levels increases sensitivity to oxidative stress mediated neurodegeneration. In this study, we examined how the loss of Nocturnin impacts redox homeostasis and neuronal survival in Cath.a-differentiated (CAD) cells and dopaminergic neurodegeneration in a mutant alpha-synuclein overexpression PD mouse model (DASYN53). Here we demonstrate that loss of Nocturnin increases CAD cell viability by increasing total glutathione levels, boosting metabolites involved in antioxidant defense, and reducing oxidative damage. Additionally, Nocturnin deletion in DASYN53 mice promotes midbrain dopaminergic neuron survival. These findings suggest that the loss of Nocturnin protects neurons from oxidative stress by increasing antioxidant defense, which rescues neurodegeneration of dopaminergic neurons.",
      "author": "Carla B. Green",
      "published_date": "2025-11-19T00:00:00+00:00",
      "source": "Frontiers Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 160,
      "reading_time": 1,
      "created_at": "2025-11-24T05:45:02.094357+00:00",
      "updated_at": "2025-11-24T05:45:02.094359+00:00"
    },
    {
      "id": "978cb9f0e0c20f67209dc289a1f4ea34",
      "url": "https://www.bbc.com/news/articles/c8676qpxgnqo",
      "title": "Japan's gamble to turn island of Hokkaido into global chip hub",
      "content": "<p>Article URL: <a href=\"https://www.bbc.com/news/articles/c8676qpxgnqo\">https://www.bbc.com/news/articles/c8676qpxgnqo</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46029929\">https://news.ycombinator.com/item?id=46029929</a></p>\n<p>Points: 10</p>\n<p># Comments: 0</p>",
      "author": "1659447091",
      "published_date": "2025-11-24T03:07:07+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-11-24T05:44:35.643605+00:00",
      "updated_at": "2025-11-24T05:44:35.643607+00:00"
    },
    {
      "id": "fb690277a7116b5b52ed5486f1745626",
      "url": "https://www.ft.com/content/abfe9741-f438-4ed6-a673-075ec177dc62",
      "title": "Insurers retreat from AI cover as risk of multibillion-dollar claims mounts",
      "content": "<p>Article URL: <a href=\"https://www.ft.com/content/abfe9741-f438-4ed6-a673-075ec177dc62\">https://www.ft.com/content/abfe9741-f438-4ed6-a673-075ec177dc62</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46030360\">https://news.ycombinator.com/item?id=46030360</a></p>\n<p>Points: 14</p>\n<p># Comments: 1</p>",
      "author": "gwintrob",
      "published_date": "2025-11-24T04:22:12+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-11-24T05:44:35.643553+00:00",
      "updated_at": "2025-11-24T05:44:35.643561+00:00"
    },
    {
      "id": "9d42cd3aff70ff7344537cfc257583e7",
      "url": "https://arxiv.org/abs/2511.16823",
      "title": "Monte Carlo Expected Threat (MOCET) Scoring",
      "content": "arXiv:2511.16823v1 Announce Type: cross \nAbstract: Evaluating and measuring AI Safety Level (ASL) threats are crucial for guiding stakeholders to implement safeguards that keep risks within acceptable limits. ASL-3+ models present a unique risk in their ability to uplift novice non-state actors, especially in the realm of biosecurity. Existing evaluation metrics, such as LAB-Bench, BioLP-bench, and WMDP, can reliably assess model uplift and domain knowledge. However, metrics that better contextualize \"real-world risks\" are needed to inform the safety case for LLMs, along with scalable, open-ended metrics to keep pace with their rapid advancements. To address both gaps, we introduce MOCET, an interpretable and doubly-scalable metric (automatable and open-ended) that can quantify real-world risks.",
      "author": "Joseph Kim, Saahith Potluri",
      "published_date": "2025-11-24T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 112,
      "reading_time": 1,
      "created_at": "2025-11-24T05:22:56.313124+00:00",
      "updated_at": "2025-11-24T05:22:56.313125+00:00"
    },
    {
      "id": "5a412a81f429ca3e4bfc661f5fbb8d8a",
      "url": "https://arxiv.org/abs/2511.16814",
      "title": "Stable diffusion models reveal a persisting human and AI gap in visual creativity",
      "content": "arXiv:2511.16814v1 Announce Type: cross \nAbstract: While recent research suggests Large Language Models match human creative performance in divergent thinking tasks, visual creativity remains underexplored. This study compared image generation in human participants (Visual Artists and Non Artists) and using an image generation AI model (two prompting conditions with varying human input: high for Human Inspired, low for Self Guided). Human raters (N=255) and GPT4o evaluated the creativity of the resulting images. We found a clear creativity gradient, with Visual Artists being the most creative, followed by Non Artists, then Human Inspired generative AI, and finally Self Guided generative AI. Increased human guidance strongly improved GenAI's creative output, bringing its productions close to those of Non Artists. Notably, human and AI raters also showed vastly different creativity judgment patterns. These results suggest that, in contrast to language centered tasks, GenAI models may face unique challenges in visual domains, where creativity depends on perceptual nuance and contextual sensitivity, distinctly human capacities that may not be readily transferable from language models.",
      "author": "Silvia Rondini, Claudia Alvarez-Martin, Paula Angermair-Barkai, Olivier Penacchio, M. Paz, Matthew Pelowski, Dan Dediu, Antoni Rodriguez-Fornells, Xim Cerda-Company",
      "published_date": "2025-11-24T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 168,
      "reading_time": 1,
      "created_at": "2025-11-24T05:22:56.313098+00:00",
      "updated_at": "2025-11-24T05:22:56.313099+00:00"
    },
    {
      "id": "bcb6a6f227913d70c4e5472210cd84ba",
      "url": "https://arxiv.org/abs/2511.17443",
      "title": "GRAPHIC--Guidelines for Reviewing Algorithmic Practices in Human-centred Design and Interaction for Creativity",
      "content": "arXiv:2511.17443v1 Announce Type: new \nAbstract: Artificial Intelligence (AI) has been increasingly applied to creative domains, leading to the development of systems that collaborate with humans in design processes. In Graphic Design, integrating computational systems into co-creative workflows presents specific challenges, as it requires balancing scientific rigour with the subjective and visual nature of design practice. Following the PRISMA methodology, we identified 872 articles, resulting in a final corpus of 71 publications describing 68 unique systems. Based on this review, we introduce GRAPHIC (Guidelines for Reviewing Algorithmic Practices in Human-centred Design and Interaction for Creativity), a framework for analysing AI-based systems applied to Graphic Design. Its goal is to understand how current systems support human-AI collaboration in the Graphic Design discipline. The framework comprises main dimensions, which our analysis revealed to be essential across diverse system types: (1) Collaborative Panorama, (2) Processes and Modalities, and (3) Graphic Design Principles. Its application revealed research gaps, including the need to balance initiative and control between agents, improve communication through explainable interaction models, and promote systems that support transformational creativity grounded in core design principles.",
      "author": "Joana Rovira Martins, Pedro Martins, Ana Boavida",
      "published_date": "2025-11-24T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 181,
      "reading_time": 1,
      "created_at": "2025-11-24T05:22:56.313068+00:00",
      "updated_at": "2025-11-24T05:22:56.313070+00:00"
    },
    {
      "id": "64bc9b7f180c0fba53776c09e80ce203",
      "url": "https://arxiv.org/abs/2511.17246",
      "title": "Mixed Reality Scenic Live Streaming for Cultural Heritage: Visual Interactions in a Historic Landscape",
      "content": "arXiv:2511.17246v1 Announce Type: new \nAbstract: Scenic Live Streams (SLS), capturing real-world scenic sites from fixed cameras without streamers, have gained increasing popularity recently. They afford unique real-time lenses into remote sites for viewers' synchronous and collective engagement. Foregrounding its lack of dynamism and interactivity, we aim to maximize the potential of SLS by making it interactive. Namely MRSLS, we overlaid plain SLS with interactive Mixed Reality content that matches the site's geographical structures and local cultural backgrounds. We further highlight the substantial benefit of MRSLS to cultural heritage site interactions, and we demonstrate this design proposal with an MRSLS prototype at a UNESCO-listed heritage site in China. The design process includes an interview (N=6) to pinpoint local scenery and culture, as well as two iterative design studies (N=15, 14). A mixed-methods, between-subjects study (N=43, 37) shows that MRSLS affords immersive scenery appreciation, effective cultural imprints, and vivid shared experience. With its balance between cultural, participatory, and authentic attributes, we appeal for more HCI attention to (MR)SLS as an under-explored design space.",
      "author": "Zeyu Huang, Zuyu Xu, Yuanhao Zhang, Chengzhong Liu, Yanwei Zhao, Chuhan Shi, Jason Chen Zhao, Xiaojuan Ma",
      "published_date": "2025-11-24T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 171,
      "reading_time": 1,
      "created_at": "2025-11-24T05:22:56.313037+00:00",
      "updated_at": "2025-11-24T05:22:56.313038+00:00"
    },
    {
      "id": "5eccab12089249af57835805a2658512",
      "url": "https://arxiv.org/abs/2511.16990",
      "title": "Senti-iFusion: An Integrity-centered Hierarchical Fusion Framework for Multimodal Sentiment Analysis under Uncertain Modality Missingness",
      "content": "arXiv:2511.16990v1 Announce Type: new \nAbstract: Multimodal Sentiment Analysis (MSA) is critical for human-computer interaction but faces challenges when the modalities are incomplete or missing. Existing methods often assume pre-defined missing modalities or fixed missing rates, limiting their real-world applicability. To address this challenge, we propose Senti-iFusion, an integrity-centered hierarchical fusion framework capable of handling both inter- and intra-modality missingness simultaneously. It comprises three hierarchical components: Integrity Estimation, Integrity-weighted Completion, and Integrity-guided Fusion. First, the Integrity Estimation module predicts the completeness of each modality and mitigates the noise caused by incomplete data. Second, the Integrity-weighted Cross-modal Completion module employs a novel weighting mechanism to disentangle consistent semantic structures from modality-specific representations, enabling the precise recovery of sentiment-related features across language, acoustic, and visual modalities. To ensure consistency in reconstruction, a dual-depth validation with semantic- and feature-level losses ensures consistent reconstruction at both fine-grained (low-level) and semantic (high-level) scales. Finally, the Integrity-guided Adaptive Fusion mechanism dynamically selects the dominant modality for attention-based fusion, ensuring that the most reliable modality, based on completeness and quality, contributes more significantly to the final prediction. Senti-iFusion employs a progressive training approach to ensure stable convergence. Experimental results on popular MSA datasets demonstrate that Senti-iFusion outperforms existing methods, particularly in fine-grained sentiment analysis tasks. The code and our proposed Senti-iFusion model will be publicly available.",
      "author": "Liling Li, Guoyang Xu, Xiongri Shen, Zhifei Xu, Yanbo Zhang, Zhiguo Zhang, Zhenxi Song",
      "published_date": "2025-11-24T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 218,
      "reading_time": 1,
      "created_at": "2025-11-24T05:22:56.313004+00:00",
      "updated_at": "2025-11-24T05:22:56.313005+00:00"
    },
    {
      "id": "fc9027b9c746c346b6840d671d41365a",
      "url": "https://arxiv.org/abs/2511.16989",
      "title": "The Wireless Charger as a Gesture Sensor: A Novel Approach to Ubiquitous Interaction",
      "content": "arXiv:2511.16989v1 Announce Type: new \nAbstract: Advancements in information technology have increased demand for natural human-computer interaction in areas such as gaming, smart homes, and vehicles. However, conventional approaches like physical buttons or cameras are often limited by contact requirements, privacy concerns, and high costs.Motivated by the observation that these EM signals are not only strong and measurable but also rich in gesture-related information, we propose EMGesture, a novel contactless interaction technique that leverages the electromagnetic (EM) signals from Qi wireless chargers for gesture recognition. EMGesture analyzes the distinctive EM features and employs a robust classification model. The end-to-end framework enables it capable of accurately interpreting user intent. Experiments involving 30 participants, 10 mobile devices, and 5 chargers showed that EMGesture achieves over 97% recognition accuracy. Corresponding user studies also confirmed higher usability and convenience, which demonstrating that EMGesture is a practical, privacy-conscious, and cost-effective solution for pervasive interaction.",
      "author": "Weiyi Wang, Lanqing Yang, Linqian Gan, Guangtao Xue",
      "published_date": "2025-11-24T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 148,
      "reading_time": 1,
      "created_at": "2025-11-24T05:22:56.312968+00:00",
      "updated_at": "2025-11-24T05:22:56.312970+00:00"
    },
    {
      "id": "12b5ff79d5e0d4fd2229f71a66d7b47e",
      "url": "https://arxiv.org/abs/2511.16896",
      "title": "IsharaKotha: A Comprehensive Avatar-based Bangla Sign Language Corpus",
      "content": "arXiv:2511.16896v1 Announce Type: new \nAbstract: Sign language is a vital communication medium for the hearing-impaired community, enabling effective interaction and self-expression. To help bridge the communication gap between hearing and hearing-impaired individuals, a text-to-sign translation system is essential. Such systems can also support learners interested in acquiring sign language skills. This work presents IsharaKotha, the first HamNoSys-based Bangla Sign Language corpus, containing 3823 words. A deep learning based lemmatizer was integrated to extract root words, enabling sign generation for complete sentences. An evaluation interface was developed to assess the quality of sign animations for letters, digits, and sentences. Two professional interpreters and one real sign language user rated the animations using categorical numeric scores. The system achieved an average rating of 3.14 out of 4.00, indicating high quality performance between Good and Excellent. These results demonstrate the potential of IsharaKotha to support future advancements in dynamic sign language translation systems. The evaluation system is available at http://bdsl-isharakotha.ap-1.evennode.com",
      "author": "MD. Ashikul Islam, Prato Dewan, Md Fuadul Islam, Md. Ataullha, M. Shahidur Rahman",
      "published_date": "2025-11-24T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 157,
      "reading_time": 1,
      "created_at": "2025-11-24T05:22:56.312932+00:00",
      "updated_at": "2025-11-24T05:22:56.312935+00:00"
    },
    {
      "id": "3f90b860ccae68c9c2be37fefd303bb4",
      "url": "https://arxiv.org/abs/2511.16805",
      "title": "Scene Awareness While Using Multiple Navigation Aids in AR Search",
      "content": "arXiv:2511.16805v1 Announce Type: new \nAbstract: Augmented reality (AR) allows virtual information to be presented in the real world, providing support for numerous tasks including search and navigation. Allowing users access to multiple navigation aids may help leverage the benefits of different navigational guidance methods, but may also have negative perceptual and cognitive impacts. In this study, users performed searches for virtual gems within a large-scale augmented environment while choosing to deploy two different navigation aids either independently or simultaneously: world-locked arrows and an on-screen radar. After completing the search, participants were asked to recall objects that may or may not have been present in the scene. The use of navigation aids impacted object recall, with impaired recall of objects in the environment when an aid was switched on. The results point at possible impact factors of object awareness in mobile AR and underscore the potential for adaptable interfaces to support users navigating the physical world.",
      "author": "Radha Kumaran, You-Jin Kim, Emily Machniak, Shane Dirksen, Junhyung Yoon, Tom Bullock, Barry Giesbrecht, Tobias H\\\"ollerer",
      "published_date": "2025-11-24T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 155,
      "reading_time": 1,
      "created_at": "2025-11-24T05:22:56.312888+00:00",
      "updated_at": "2025-11-24T05:22:56.312890+00:00"
    },
    {
      "id": "9b6ac85d2afd26cb2702de2f1a16a06c",
      "url": "https://arxiv.org/abs/2511.16783",
      "title": "Generative Augmented Reality: Paradigms, Technologies, and Future Applications",
      "content": "arXiv:2511.16783v1 Announce Type: new \nAbstract: This paper introduces Generative Augmented Reality (GAR) as a next-generation paradigm that reframes augmentation as a process of world re-synthesis rather than world composition by a conventional AR engine. GAR replaces the conventional AR engine's multi-stage modules with a unified generative backbone, where environmental sensing, virtual content, and interaction signals are jointly encoded as conditioning inputs for continuous video generation. We formalize the computational correspondence between AR and GAR, survey the technical foundations that make real-time generative augmentation feasible, and outline prospective applications that leverage its unified inference model. We envision GAR as a future AR paradigm that delivers high-fidelity experiences in terms of realism, interactivity, and immersion, while eliciting new research challenges on technologies, content ecosystems, and the ethical and societal implications.",
      "author": "Chen Liang, Jiawen Zheng, Yufeng Zeng, Yi Tan, Hengye Lyu, Yuhui Zheng, Zisu Li, Yueting Weng, Jiaxin Shi, Hanwang Zhang",
      "published_date": "2025-11-24T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 128,
      "reading_time": 1,
      "created_at": "2025-11-24T05:22:56.312857+00:00",
      "updated_at": "2025-11-24T05:22:56.312859+00:00"
    },
    {
      "id": "ded58082f6a1ebca43d25332c74351c9",
      "url": "https://arxiv.org/abs/2511.16769",
      "title": "Trust in AI emerges from distrust in humans: A machine learning study on decision-making guidance",
      "content": "arXiv:2511.16769v1 Announce Type: new \nAbstract: This study explores the dynamics of trust in artificial intelligence (AI) agents, particularly large language models (LLMs), by introducing the concept of \"deferred trust\", a cognitive mechanism where distrust in human agents redirects reliance toward AI perceived as more neutral or competent. Drawing on frameworks from social psychology and technology acceptance models, the research addresses gaps in user-centric factors influencing AI trust. Fifty-five undergraduate students participated in an experiment involving 30 decision-making scenarios (factual, emotional, moral), selecting from AI agents (e.g., ChatGPT), voice assistants, peers, adults, or priests as guides. Data were analyzed using K-Modes and K-Means clustering for patterns, and XGBoost models with SHAP interpretations to predict AI selection based on sociodemographic and prior trust variables.\n  Results showed adults (35.05\\%) and AI (28.29\\%) as the most selected agents overall. Clustering revealed context-specific preferences: AI dominated factual scenarios, while humans prevailed in social/moral ones. Lower prior trust in human agents (priests, peers, adults) consistently predicted higher AI selection, supporting deferred trust as a compensatory transfer. Participant profiles with higher AI trust were distinguished by human distrust, lower technology use, and higher socioeconomic status. Models demonstrated consistent performance (e.g., average precision up to 0.863).\n  Findings challenge traditional models like TAM/UTAUT, emphasizing relational and epistemic dimensions in AI trust. They highlight risks of over-reliance due to fluency effects and underscore the need for transparency to calibrate vigilance. Limitations include sample homogeneity and static scenarios; future work should incorporate diverse populations and multimodal data to refine deferred trust across contexts.",
      "author": "Johan Sebasti\\'an Galindez-Acosta, Juan Jos\\'e Giraldo-Huertas",
      "published_date": "2025-11-24T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 252,
      "reading_time": 1,
      "created_at": "2025-11-24T05:22:56.312823+00:00",
      "updated_at": "2025-11-24T05:22:56.312827+00:00"
    },
    {
      "id": "96703cfbaa405915e54b80a0631ff922",
      "url": "https://arxiv.org/abs/2511.02558",
      "title": "Forecasting Future Anatomies: Longitudinal Brain Mri-to-Mri Prediction",
      "content": "arXiv:2511.02558v2 Announce Type: replace-cross \nAbstract: Predicting future brain state from a baseline magnetic resonance image (MRI) is a central challenge in neuroimaging and has important implications for studying neurodegenerative diseases such as Alzheimer's disease (AD). Most existing approaches predict future cognitive scores or clinical outcomes, such as conversion from mild cognitive impairment to dementia. Instead, here we investigate longitudinal MRI image-to-image prediction that forecasts a participant's entire brain MRI several years into the future, intrinsically modeling complex, spatially distributed neurodegenerative patterns. We implement and evaluate five deep learning architectures (UNet, U2-Net, UNETR, Time-Embedding UNet, and ODE-UNet) on two longitudinal cohorts (ADNI and AIBL). Predicted follow-up MRIs are directly compared with the actual follow-up scans using metrics that capture global similarity and local differences. The best performing models achieve high-fidelity predictions, and all models generalize well to an independent external dataset, demonstrating robust cross-cohort performance. Our results indicate that deep learning can reliably predict participant-specific brain MRI at the voxel level, offering new opportunities for individualized prognosis.",
      "author": "Ali Farki, Elaheh Moradi, Deepika Koundal, Jussi Tohka",
      "published_date": "2025-11-24T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 166,
      "reading_time": 1,
      "created_at": "2025-11-24T05:22:55.231337+00:00",
      "updated_at": "2025-11-24T05:22:55.231339+00:00"
    },
    {
      "id": "7a0d77dbb4f5523d07401604f6d40b8c",
      "url": "https://arxiv.org/abs/2506.02813",
      "title": "Brain-Like Processing Pathways Form in Models With Heterogeneous Experts",
      "content": "arXiv:2506.02813v3 Announce Type: replace \nAbstract: The brain is made up of a vast set of heterogeneous regions that dynamically organize into pathways as a function of task demands. Examples of such pathways can be found in the interactions between cortical and subcortical networks during learning, or in sub-networks specializing for task characteristics such as difficulty or modality. Despite the large role these pathways play in cognition, the mechanisms through which brain regions organize into pathways remain unclear. In this work, we use an extension of the Heterogeneous Mixture-of-Experts architecture to show that heterogeneous regions do not form processing pathways by themselves, implying that the brain likely implements specific constraints which result in the reliable formation of pathways. We identify three biologically relevant inductive biases that encourage pathway formation: a routing cost imposed on the use of more complex regions, a scaling factor that reduces this cost when task performance is low, and randomized expert dropout. When comparing our resulting \\textit{Mixture-of-Pathways} model with the brain, we observe that the artificial pathways in our model match how the brain uses cortical and subcortical systems to learn and solve tasks of varying difficulty. In summary, we introduce a novel framework for investigating how the brain forms task-specific pathways through inductive biases, and the effects these biases have on the behavior of Mixture-of-Experts models.",
      "author": "Jack Cook, Danyal Akarca, Rui Ponte Costa, Jascha Achterberg",
      "published_date": "2025-11-24T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 220,
      "reading_time": 1,
      "created_at": "2025-11-24T05:22:55.231303+00:00",
      "updated_at": "2025-11-24T05:22:55.231305+00:00"
    },
    {
      "id": "07c7bc01f89e45790231b265bfbeaf68",
      "url": "https://arxiv.org/abs/2504.08016",
      "title": "Emergence of psychopathological computations in large language models",
      "content": "arXiv:2504.08016v2 Announce Type: replace \nAbstract: Can large language models (LLMs) instantiate computations of psychopathology? An effective approach to the question hinges on addressing two factors. First, for conceptual validity, we require a general and computational account of psychopathology that is applicable to computational entities without biological embodiment or subjective experience. Second, psychopathological computations, derived from the adapted theory, need to be empirically identified within the LLM's internal processing. Thus, we establish a computational-theoretical framework to provide an account of psychopathology applicable to LLMs. Based on the framework, we conduct experiments demonstrating two key claims: first, that the computational structure of psychopathology exists in LLMs; and second, that executing this computational structure results in psychopathological functions. We further observe that as LLM size increases, the computational structure of psychopathology becomes denser and that the functions become more effective. Taken together, the empirical results corroborate our hypothesis that network-theoretic computations of psychopathology have already emerged in LLMs. This suggests that certain LLM behaviors mirroring psychopathology may not be a superficial mimicry but a feature of their internal processing. Our work shows the promise of developing a new powerful in silico model of psychopathology and also alludes to the possibility of safety threat from the AI systems with psychopathological behaviors in the near future.",
      "author": "Soo Yong Lee, Hyunjin Hwang, Taekwan Kim, Yuyeong Kim, Kyuri Park, Jaemin Yoo, Denny Borsboom, Kijung Shin",
      "published_date": "2025-11-24T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 211,
      "reading_time": 1,
      "created_at": "2025-11-24T05:22:55.231269+00:00",
      "updated_at": "2025-11-24T05:22:55.231271+00:00"
    },
    {
      "id": "14cd691b01d157fb2b961ea5e8cba846",
      "url": "https://arxiv.org/abs/2412.19622",
      "title": "Reassessing prediction in the brain: Pre-onset neural encoding during natural listening does not reflect pre-activation",
      "content": "arXiv:2412.19622v2 Announce Type: replace \nAbstract: Predictive processing theories propose that the brain continuously anticipates upcoming input. However, direct neural evidence for predictive pre-activation during natural language comprehension remains limited and debated. Previous studies using large language model (LLM)-based encoding models with fMRI and ECoG have reported pre-onset signals that appear to encode upcoming words, but these effects may instead reflect dependencies in the stimulus or autocorrelations in neural activity. Here, we re-examined this question by aligning LLM-derived word embeddings with neural activity recorded during naturalistic listening using magnetoencephalography (MEG) and electrocorticography (ECoG). We replicated pre-onset encoding effects previously observed in ECoG across both modalities, and found that they persist even after controlling for stimulus correlations. Crucially, temporal generalization analyses revealed no stable overlap between pre- and post-onset representations, indicating that pre-onset activity does not reflect pre-activation of the next word. Consistent with this, long-range predictive effects previously reported in fMRI did not replicate in our higher-temporal-resolution data. While we found no evidence for predictive pre-activation, we observed clear signatures of postdiction, with neural activity reflecting persistent encoding of prior words. These results suggest that reported apparent predictive signals do not reflect pre-activation of upcoming input. They call for caution in interpreting LLM-based encoding models and highlight the need for a more nuanced understanding of what constitutes \"prediction\" in language comprehension.",
      "author": "Sahel Azizpour, Britta U. Westner, Jakub Szewczyk, Umut G\\\"u\\c{c}l\\\"u, Linda Geerligs",
      "published_date": "2025-11-24T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 220,
      "reading_time": 1,
      "created_at": "2025-11-24T05:22:55.231229+00:00",
      "updated_at": "2025-11-24T05:22:55.231233+00:00"
    },
    {
      "id": "79e3312287655f4607742b7b6e047b76",
      "url": "https://mathwonder.org/Having-Fun-with-Complex-Numbers/",
      "title": "Having Fun with Complex Numbers: A Real-Life Journey for Upper Elementary Studen",
      "content": "<a href=\"https://news.ycombinator.com/item?id=45973364\">Comments</a>",
      "author": "",
      "published_date": "2025-11-18T22:52:57+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-11-24T05:22:10.849591+00:00",
      "updated_at": "2025-11-24T05:22:10.849593+00:00"
    }
  ]
}