{
  "last_updated": "2026-01-21T05:30:42.106249+00:00",
  "count": 20,
  "articles": [
    {
      "id": "427afbf9c74f7e1066b2b69ea86f1b16",
      "url": "https://arxiv.org/abs/2601.11533",
      "title": "Artificial Intelligence as a Training Tool in Clinical Psychology: A Comparison of Text-Based and Avatar Simulations",
      "content": "arXiv:2601.11533v1 Announce Type: new \nAbstract: Clinical psychology students frequently report feeling underprepared for the interpersonal demands of therapeutic work, highlighting the need for accessible opportunities to practise core counselling skills before seeing real clients. Advances in artificial intelligence (AI) now enable simulated interaction partners that may support early skills development. This study examined postgraduate clinical psychology students' perceptions of two AI-based simulations: a text-based chatbot (ChatGPT) and a voice-based avatar (HeyGen). Twenty-four students completed two brief cognitive-behavioural role-plays (counterbalanced), one with each tool, and provided both quantitative ratings and qualitative feedback on perceived usefulness, skill application, responsiveness and engagement, and perceived skill improvement. Both AI tools were evaluated positively across dimensions. However, the avatar was rated significantly higher than the chatbot for perceived usefulness, skill application, and perceived skill improvement, and qualitative comments highlighted the added value of voice-based interaction for conveying social and emotional cues. These findings suggest that AI-driven simulation may supplement early-stage clinical skills training, with voice-based avatars offering additional benefits. Future work should test whether such simulated interactions translate to objective improvements in real therapeutic performance.",
      "author": "V. El Sawah, A. Bhardwaj, A. Pryke-Hobbes, D. Gamaleldin, C. S. Ang, A. K. Martin",
      "published_date": "2026-01-21T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 180,
      "reading_time": 1,
      "created_at": "2026-01-21T05:30:23.307708+00:00",
      "updated_at": "2026-01-21T05:30:23.307710+00:00"
    },
    {
      "id": "718153e3d6348bcbcdc3a9d9515b21a7",
      "url": "https://arxiv.org/abs/2601.11532",
      "title": "\"Jutters\"",
      "content": "arXiv:2601.11532v1 Announce Type: new \nAbstract: This project explores how we engage with AI-generated content through the lens of the jutter: Dutch coastal foragers who comb the shoreline after storms, gathering and repurposing what the sea leaves behind. Reflecting how our lives are increasingly shaped by AI-generated media, we create a beach-like installation that blends real shoreline debris with AI-transformed images and videos. Visitors are invited to explore this space as contemporary jutters, deciding what to keep and what to discard. In doing so, the project reimagines AI-imagery as material for reflection, encouraging a more discerning engagement with the content that drifts through our feeds. A video preview of the installation can be found at https://www.youtube.com/watch?v=L6319Ii7MT8.",
      "author": "Meike Driessen, Selina Khan, Gon\\c{c}alo Marcelino",
      "published_date": "2026-01-21T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 115,
      "reading_time": 1,
      "created_at": "2026-01-21T05:30:23.307676+00:00",
      "updated_at": "2026-01-21T05:30:23.307678+00:00"
    },
    {
      "id": "d8e541c09d336480c5320638644bbdcc",
      "url": "https://arxiv.org/abs/2601.11531",
      "title": "NOVAID: Natural-language Observability Visualization Assistant for ITOps Dashboard Widget Generation",
      "content": "arXiv:2601.11531v1 Announce Type: new \nAbstract: Manual creation of IT monitoring dashboard widgets is slow, error-prone, and a barrier for both novice and expert users. We present NOVAID, an interactive chatbot that leverages Large Language Models (LLMs) to generate IT monitoring widgets directly from natural language queries. Unlike general natural language-to-visualization tools, NOVAID addresses IT operations-specific challenges: specialized widget types like SLO charts, dynamic API-driven data retrieval, and complex contextual filters. The system combines a domain-aware semantic parser, fuzzy entity matching, and schema completion to produce standardized widget JSON specifications. An interactive clarification loop ensures accuracy in underspecified queries. On a curated dataset of 271 realistic queries, NOVAID achieves promising accuracy (up to 94.10% in metric extraction) across multiple LLMs. A user study with IT engineers yielded a System Usability Scale score of 74.2 for NOVAID, indicating good usability. By bridging natural language intent with operational dashboards, NOVAID demonstrates clear potential and a path for deployment in enterprise ITOps monitoring platforms.",
      "author": "Pratik Mishra, Caner G\\\"oz\\\"ub\\\"uy\\\"uk, Seema Nagar, Prateeti Mohapatra, Raya Wittich, Arthur de Magalhaes",
      "published_date": "2026-01-21T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 160,
      "reading_time": 1,
      "created_at": "2026-01-21T05:30:23.307650+00:00",
      "updated_at": "2026-01-21T05:30:23.307652+00:00"
    },
    {
      "id": "a68f1dd70197d4f70d3ffc5f153b8a2a",
      "url": "https://arxiv.org/abs/2601.11530",
      "title": "AI for Proactive Mental Health: A Multi-Institutional, Longitudinal, Randomized Controlled Trial",
      "content": "arXiv:2601.11530v1 Announce Type: new \nAbstract: Young adults today face unprecedented mental health challenges, yet many hesitate to seek support due to barriers such as accessibility, stigma, and time constraints. Bite-sized well-being interventions offer a promising solution to preventing mental distress before it escalates to clinical levels, but have not yet been delivered through personalized, interactive, and scalable technology. We conducted the first multi-institutional, longitudinal, preregistered randomized controlled trial of a generative AI-powered mobile app (\"Flourish\") designed to address this gap. Over six weeks in Fall 2024, 486 undergraduate students from three U.S. institutions were randomized to receive app access or waitlist control. Participants in the treatment condition reported significantly greater positive affect, resilience, and social well-being (i.e., increased belonging, closeness to community, and reduced loneliness) and were buffered against declines in mindfulness and flourishing. These findings suggest that, with purposeful and ethical design, generative AI can deliver proactive, population-level well-being interventions that produce measurable benefits.",
      "author": "Julie Y. A. Cachia, Xuan Zhao, John Hunter, Delancey Wu, Eta Lin, Julian De Freitas",
      "published_date": "2026-01-21T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 155,
      "reading_time": 1,
      "created_at": "2026-01-21T05:30:23.307620+00:00",
      "updated_at": "2026-01-21T05:30:23.307622+00:00"
    },
    {
      "id": "707d0f20ebdda22c51771140d2a73e44",
      "url": "https://arxiv.org/abs/2601.11529",
      "title": "SNAP: A Plan-Driven Framework for Controllable Interactive Narrative Generation",
      "content": "arXiv:2601.11529v1 Announce Type: new \nAbstract: Large Language Models (LLMs) hold great potential for web-based interactive applications, including browser games, online education, and digital storytelling platforms. However, LLM-based conversational agents suffer from spatiotemporal distortions when responding to variant user inputs, failing to maintain consistency with provided scenarios. We propose SNAP (Story and Narrative-based Agent with Planning), a framework that structures narratives into Cells with explicit Plans to prevent narrative drift in web environments. By confining context within each Cell and employing detailed plans that specify spatiotemporal settings, character actions, and plot developments, SNAP enables coherent and scenario-consistent dialogues while adapting to diverse user responses. Via automated and human evaluations, we validate SNAP's superiority in narrative controllability, demonstrating effective scenario consistency despite variant user inputs in web-based interactive storytelling.",
      "author": "Geonwoo Bang, DongMyung Kim, Hayoung Oh",
      "published_date": "2026-01-21T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 127,
      "reading_time": 1,
      "created_at": "2026-01-21T05:30:23.307588+00:00",
      "updated_at": "2026-01-21T05:30:23.307590+00:00"
    },
    {
      "id": "39aea28d2ffdc19a5b23f2d2cfb538fd",
      "url": "https://arxiv.org/abs/2601.11527",
      "title": "Do LLMs Give Good Romantic Relationship Advice? A Study on User Satisfaction and Attitude Change",
      "content": "arXiv:2601.11527v1 Announce Type: new \nAbstract: Large Language Models (LLMs) are increasingly being used to provide support and advice in personal domains such as romantic relationships, yet little is known about user perceptions of this type of advice. This study investigated how people evaluate advice on LLM-generated romantic relationships. Participants rated advice satisfaction, model reliability, and helpfulness, and completed pre- and post-measures of their general attitudes toward LLMs. Overall, the results showed participants' high satisfaction with LLM-generated advice. Greater satisfaction was, in turn, strongly and positively associated with their perceptions of the models' reliability and helpfulness. Importantly, participants' attitudes toward LLMs improved significantly after exposure to the advice, suggesting that supportive and contextually relevant advice can enhance users' trust and openness toward these AI systems.",
      "author": "Niva Manchanda, Akshata Kishore Moharir, Isabel Michel, Ratna Kandala",
      "published_date": "2026-01-21T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 124,
      "reading_time": 1,
      "created_at": "2026-01-21T05:30:23.307560+00:00",
      "updated_at": "2026-01-21T05:30:23.307562+00:00"
    },
    {
      "id": "60726cb22ca38d929a7d20f744c9be9a",
      "url": "https://arxiv.org/abs/2601.11526",
      "title": "Chatsparent: An Interactive System for Detecting and Mitigating Cognitive Fatigue in LLMs",
      "content": "arXiv:2601.11526v1 Announce Type: new \nAbstract: LLMs are increasingly being deployed as chatbots, but today's interfaces offer little to no friction: users interact through seamless conversations that conceal when the model is drifting, hallucinating or failing. This lack of transparency fosters blind trust, even as models produce unstable or repetitive outputs. We introduce an interactive demo that surfaces and mitigates cognitive fatigue, a failure mode where LLMs gradually lose coherence during auto-regressive generation. Our system, Chatsparent, instruments real-time, token-level signals of fatigue, including attention-to-prompt decay, embedding drift, and entropy collapse, and visualizes them as a unified fatigue index. When fatigue thresholds are crossed, the interface allows users to activate lightweight interventions such as attention resets, entropy-regularized decoding, and self-reflection checkpoints. The demo streams live text and fatigue signals, allowing users to observe when fatigue arises, how it affects output quality, and how interventions restore stability. By turning passive chatbot interaction into an interactive diagnostic experience, our system empowers users to better understand LLM behavior while improving reliability at inference time.",
      "author": "Riju Marwah, Vishal Pallagani, Ritvik Garimella, Amit Sheth",
      "published_date": "2026-01-21T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 169,
      "reading_time": 1,
      "created_at": "2026-01-21T05:30:23.307529+00:00",
      "updated_at": "2026-01-21T05:30:23.307530+00:00"
    },
    {
      "id": "c2907c5f48abc27129be6003d36a6c78",
      "url": "https://arxiv.org/abs/2601.11525",
      "title": "PlotGen-Bench: Evaluating VLMs on Generating Visualization Code from Diverse Plots across Multiple Libraries",
      "content": "arXiv:2601.11525v1 Announce Type: new \nAbstract: Recent advances in vision-language models (VLMs) have expanded their multimodal code generation capabilities, yet their ability to generate executable visualization code from plots, especially for complex 3D, animated, plot-to-plot transformations, or multi-library scenarios, remains underexplored. To address this gap, we introduce PlotGen-Bench, a comprehensive benchmark for evaluating plot-to-code generation under realistic and complex visualization scenarios. The benchmark spans 9 major categories, 30 subcategories, and 3 core tasks-plot replication, plot transformation, and multi-library generation, covering both 2D, 3D and animated plots across 5 widely used visualization libraries. Through systematic evaluation of state-of-the-art open- and closed-source VLMs, we find that open-source models still lag considerably behind in visual fidelity and semantic consistency, despite achieving comparable code executability. Moreover, all models exhibit substantial degradation on reasoning-intensive tasks such as chart type conversion and animation generation. PlotGen-Bench establishes a rigorous foundation for advancing research toward more capable and reliable VLMs for visualization authoring and code synthesis, with all data and code available at https://plotgen.github.io.",
      "author": "Yi Zhao, Zhen Yang, Shuaiqi Duan, Wenmeng Yu, Zhe Su, Jibing Gong, Jie Tang",
      "published_date": "2026-01-21T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 165,
      "reading_time": 1,
      "created_at": "2026-01-21T05:30:23.307497+00:00",
      "updated_at": "2026-01-21T05:30:23.307499+00:00"
    },
    {
      "id": "2434d37e3d46e9ece3b42c444d65f1c4",
      "url": "https://arxiv.org/abs/2601.11524",
      "title": "Clusters in Focus: A Simple and Robust Detail-On-Demand Dashboard for Patient Data",
      "content": "arXiv:2601.11524v1 Announce Type: new \nAbstract: Exploring tabular datasets to understand how different feature pairs partition data into meaningful cohorts is crucial in domains such as biomarker discovery, yet comparing clusters across multiple feature pair projections is challenging. We introduce Clusters in Focus, an interactive visual analytics dashboard designed to address this gap. Clusters in Focus employs a three-panel coordinated view: a Data Panel offers multiple perspectives (tabular, heatmap, condensed with histograms / SHAP values) for initial data exploration; a Selection Panel displays the 2D clustering (K-Means/DBSCAN) for a user-selected feature pair; and a novel Cluster Similarity Panel featuring two switchable views for comparing clusters. A ranked list enables the identification of top-matching feature pairs, while an interactive similarity matrix with reordering capabilities allows for the discovery of global structural patterns and groups of related features. This dual-view design supports both focused querying and broad visual exploration. A use case on a Parkinson's disease speech dataset demonstrates the tool's effectiveness in revealing relationships between different feature pairs characterizing the same patient subgroup.",
      "author": "Lukas Schilcher, Peter Waldert, Benedikt Kantz, Tobias Schreck",
      "published_date": "2026-01-21T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 171,
      "reading_time": 1,
      "created_at": "2026-01-21T05:30:23.307464+00:00",
      "updated_at": "2026-01-21T05:30:23.307466+00:00"
    },
    {
      "id": "0411fdaa632ac3403b6b26d49be961bc",
      "url": "https://arxiv.org/abs/2601.11523",
      "title": "MetaScoreLens: Evaluating User Feedback Across Digital Entertainment Systems",
      "content": "arXiv:2601.11523v1 Announce Type: new \nAbstract: The popularity of electronic games has grown steadily in recent years, attracting a broad audience across age groups. With this growth comes a large volume of related data, prompting efforts like the PlayMyData to compile and share structured datasets for academic use. This study utilizes such a dataset to compare user review ratings across four current-generation gaming systems: Nintendo, Xbox, PlayStation, and PC. Statistical methods, including analysis of variance (ANOVA), were applied to identify differences in average scores among these platforms. The findings indicate that PC titles tend to receive the most favorable user feedback, followed by Xbox and PlayStation, while Nintendo games showed the lowest average ratings. These patterns suggest that the platform on which a game is released may influence how players evaluate their experience. Such results may be valuable to developers and industry stakeholders in making informed decisions about future investments and development priorities.",
      "author": "Christian Ellington, Paramahansa Pramanik, Haley K. Robinson",
      "published_date": "2026-01-21T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 152,
      "reading_time": 1,
      "created_at": "2026-01-21T05:30:23.307427+00:00",
      "updated_at": "2026-01-21T05:30:23.307430+00:00"
    },
    {
      "id": "1400b9c73df5e60571c2d3ca9d708276",
      "url": "https://arxiv.org/abs/2601.13297",
      "title": "Multifaceted neural representation of words in naturalistic language",
      "content": "arXiv:2601.13297v1 Announce Type: new \nAbstract: Understanding how the brain represents the multifaceted properties of words in context is essential for explaining the neural architecture of human language. Here, we combine large-scale psycholinguistic modeling with naturalistic fMRI to uncover the latent structure of word properties and their neural representations during narrative comprehension. By analyzing 106 psycholinguistic variables across 13,850 English words, we identified eight interpretable latent dimensions spanning lexical usage, word form, phonology orthography mapping, sublexical regularity, and semantic organization. These factors robustly predicted behavioral performance across lexical decision, naming, recognition, and semantic judgment tasks, demonstrating their cognitive relevance. Parcel-based and multivariate fMRI analyses of narrative listening revealed that these latent dimensions are encoded in overlapping yet functionally differentiated cortical systems. Multidimensional scaling and hierarchical clustering analyses further identified four interacting subsystems supporting sensorimotor grounding, controlled semantic retrieval, resolution of lexical competition, and contextual episodic integration. Together, these findings provide a unified neurocognitive framework linking fundamental lexical psycholinguistic dimensions to distributed cortical systems engaged during naturalistic language comprehension.",
      "author": "Xuan Yang, Chuanji Gao, Cheng Xiao, Nicholas Riccardi, Rutvik H. Desai",
      "published_date": "2026-01-21T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 167,
      "reading_time": 1,
      "created_at": "2026-01-21T05:30:22.146089+00:00",
      "updated_at": "2026-01-21T05:30:22.146091+00:00"
    },
    {
      "id": "1d4dc1495741b37745cb1e85eb6a4c8f",
      "url": "https://arxiv.org/abs/2601.13182",
      "title": "Polyphonic Intelligence: Constraint-Based Emergence, Pluralistic Inference, and Non-Dominating Integration",
      "content": "arXiv:2601.13182v1 Announce Type: new \nAbstract: Across neuroscience, artificial intelligence, and related fields, dominant models of intelligence typically privilege convergence: uncertainty is reduced, competing explanations are eliminated, and behaviour is governed by the optimisation of a single objective or policy. While this framing has proved powerful in many settings, it sits uneasily with biological and adaptive systems that maintain redundancy, ambiguity, and parallel explanatory processes over extended timescales. Here we propose an alternative perspective, termed polyphonic intelligence, in which coherent behaviour and meaning emerge from the coordination of multiple semi-independent inferential processes operating under shared constraints. Rather than resolving plurality through dominance or collapse, polyphonic systems sustain multiple explanatory trajectories and integrate them through soft alignment, compatibility relations, and bounded influence. We develop this perspective conceptually and formally, introducing a variational framework in which multiple coordinated approximations are maintained without winner-takes-all selection. This formulation makes explicit how plurality can remain stable, tractable, and productive, and clarifies how polyphonic inference differs from ensemble methods, mixture models, and Bayesian model averaging. Through proof-of-principle examples, we demonstrate that non-dominating, pluralistic inference can be implemented in simple computational systems without requiring centralised control or global convergence. We conclude by discussing implications for neuroscience, psychiatry, and artificial intelligence, and by arguing that intelligence may be more fruitfully understood as coordination without command rather than as the elimination of uncertainty.",
      "author": "Alexander D Shaw",
      "published_date": "2026-01-21T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 223,
      "reading_time": 1,
      "created_at": "2026-01-21T05:30:22.146059+00:00",
      "updated_at": "2026-01-21T05:30:22.146061+00:00"
    },
    {
      "id": "7ac41ed6f22938c30708505d295de605",
      "url": "https://arxiv.org/abs/2601.13170",
      "title": "Global stability of a Hebbian/anti-Hebbian network for principal subspace learning",
      "content": "arXiv:2601.13170v1 Announce Type: new \nAbstract: Biological neural networks self-organize according to local synaptic modifications to produce stable computations. How modifications at the synaptic level give rise to such computations at the network level remains an open question. Pehlevan et al. [Neur. Comp. 27 (2015), 1461--1495] proposed a model of a self-organizing neural network with Hebbian and anti-Hebbian synaptic updates that implements an algorithm for principal subspace analysis; however, global stability of the nonlinear synaptic dynamics has not been established. Here, for the case that the feedforward and recurrent weights evolve at the same timescale, we prove global stability of the continuum limit of the synaptic dynamics and show that the dynamics evolve in two phases. In the first phase, the synaptic weights converge to an invariant manifold where the `neural filters' are orthonormal. In the second phase, the synaptic dynamics follow the gradient flow of a non-convex potential function whose minima correspond to neural filters that span the principal subspace of the input data.",
      "author": "David Lipshutz, Robert J. Lipshutz",
      "published_date": "2026-01-21T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 164,
      "reading_time": 1,
      "created_at": "2026-01-21T05:30:22.146025+00:00",
      "updated_at": "2026-01-21T05:30:22.146026+00:00"
    },
    {
      "id": "7ff75b56d7a4ad3c9875529e398456fc",
      "url": "https://arxiv.org/abs/2601.12837",
      "title": "Cognition spaces: natural, artificial, and hybrid",
      "content": "arXiv:2601.12837v1 Announce Type: new \nAbstract: Cognitive processes are realized across an extraordinary range of natural, artificial, and hybrid systems, yet there is no unified framework for comparing their forms, limits, and unrealized possibilities. Here, we propose a cognition space approach that replaces narrow, substrate-dependent definitions with a comparative representation based on organizational and informational dimensions. Within this framework, cognition is treated as a graded capacity to sense, process, and act upon information, allowing systems as diverse as cells, brains, artificial agents, and human-AI collectives to be analyzed within a common conceptual landscape. We introduce and examine three cognition spaces -- basal aneural, neural, and human-AI hybrid -- and show that their occupation is highly uneven, with clusters of realized systems separated by large unoccupied regions. We argue that these voids are not accidental but reflect evolutionary contingencies, physical constraints, and design limitations. By focusing on the structure of cognition spaces rather than on categorical definitions, this approach clarifies the diversity of existing cognitive systems and highlights hybrid cognition as a promising frontier for exploring novel forms of complexity beyond those produced by biological evolution.",
      "author": "Ricard Sol\\'e, Luis F Seoane, Jordi Pla-Mauri, Michael Timothy Bennett, Michael E. Hochberg, Michael Levin",
      "published_date": "2026-01-21T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 184,
      "reading_time": 1,
      "created_at": "2026-01-21T05:30:22.145994+00:00",
      "updated_at": "2026-01-21T05:30:22.145996+00:00"
    },
    {
      "id": "cdb34aa292adc19a84b754a1af016c36",
      "url": "https://arxiv.org/abs/2601.12577",
      "title": "Primate-like perceptual decision making emerges through deep recurrent reinforcement learning",
      "content": "arXiv:2601.12577v1 Announce Type: new \nAbstract: Progress has led to a detailed understanding of the neural mechanisms that underlie decision making in primates. However, less is known about why such mechanisms are present in the first place. Theory suggests that primate decision making mechanisms, and their resultant behavioral abilities, emerged to maximize reward in the face of noisy, temporally evolving information. To test this theory, we trained an end-to-end deep recurrent neural network using reinforcement learning on a noisy perceptual discrimination task. Networks learned several key abilities of primate-like decision making including trading off speed for accuracy, and flexibly changing their mind in the face of new information. Internal dynamics of these networks suggest that these abilities were supported by similar decision mechanisms as those observed in primate neurophysiological studies. These results provide experimental support for key pressures that gave rise to the primate ability to make flexible decisions.",
      "author": "Nathan J. Wispinski, Scott A. Stone, Anthony Singhal, Patrick M. Pilarski, Craig S. Chapman",
      "published_date": "2026-01-21T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 148,
      "reading_time": 1,
      "created_at": "2026-01-21T05:30:22.145963+00:00",
      "updated_at": "2026-01-21T05:30:22.145964+00:00"
    },
    {
      "id": "d339b9dab5474b1c0f1e8a631ad13615",
      "url": "https://arxiv.org/abs/2601.12424",
      "title": "If Grid Cells are the Answer, What is the Question? A Review of Normative Grid Cell Theory",
      "content": "arXiv:2601.12424v1 Announce Type: new \nAbstract: For 20 years the beautiful structure in the grid cell code has presented an attractive puzzle: what computation do these representations subserve, and why does it manifest so curiously in neurons. The first question quickly attracted an answer: grid cells subserve path-integration, the ability to keep track of one's position as you move about the world. Subsequent work has only solidified this link: bottom-up mechanistic models that perform path-integration match the measured neural responses, while experimental perturbations that selectively disrupt grid cell activity impair performance on path-integration dependent tasks. A more controversial area of work has been top-down normative modelling: why has the brain chosen to compute like this? Floods of ink have been spilt attempting to build a precise link between the population's objective and the measured implementation. The holy grail is a normative link with broad predictive power which generalises to other neural systems. We review this literature and argue that, despite some controversies, the literature largely agrees that grid cells can be explained as a (1) biologically plausible (2) high fidelity, non-linearly decodable code for position that (3) subserves path-integration. As a rare area of neuroscience with mature theoretical and experimental work, this story holds lessons for normative theories of neural computations, and on the risks and rewards of integrating task-optimised neural networks into such theorising.",
      "author": "William Dorrell, James C. R. Whittington",
      "published_date": "2026-01-21T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 224,
      "reading_time": 1,
      "created_at": "2026-01-21T05:30:22.145935+00:00",
      "updated_at": "2026-01-21T05:30:22.145936+00:00"
    },
    {
      "id": "19ad6cddbc61847ba87113bb5718170f",
      "url": "https://arxiv.org/abs/2601.12258",
      "title": "Modeling Dynamic Computations in the Primate Ventral Visual Stream",
      "content": "arXiv:2601.12258v1 Announce Type: new \nAbstract: A major goal of computational neuroscience has been to explain how the primate ventral visual stream (VVS) transforms visual input into temporally evolving neural representations that support robust visual perception. Historically, most modeling efforts have assumed static conditions: monkeys fixate a dot, images are briefly flashed, and neural responses are analyzed through time-averaged metrics. Feedforward deep networks trained on static object recognition tasks outperform prior work in approximating these static snapshot-driven VVS responses. However, mounting neurophysiological evidence demonstrates that VVS responses are rich dynamical signals shaped not only by the retinal input but also by intrinsic circuit dynamics, recurrent interactions, and widespread top-down modulation. Moreover, real-world vision is inherently dynamic: objects move, the observer moves, and the eyes actively sample the environment. Here, we review recent progress in modeling dynamic responses in the macaque ventral stream across three domains: (1) intrinsic dynamics elicited by static images, (2) dynamics evoked by dynamic visual stimuli, and (3) dynamics generated by active sensing during eye movements. We argue that accurately modeling VVS dynamics will require representational, circuit-level, and behavioral perspectives, including multi-area recurrence, structured E/I interactions, and temporal objectives that better reflect natural behavior. We outline some key missing ingredients and propose a roadmap toward dynamic, multi-timescale models of the primate VVS.",
      "author": "Matteo Dunnhofer, Maren Wehrheim, Hamidreza Ramezanpour, Sabine Muzellec, Kohitij Kar",
      "published_date": "2026-01-21T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 214,
      "reading_time": 1,
      "created_at": "2026-01-21T05:30:22.145902+00:00",
      "updated_at": "2026-01-21T05:30:22.145903+00:00"
    },
    {
      "id": "e9c5cee4d20f5c1260967b3a15d9d3eb",
      "url": "https://arxiv.org/abs/2601.12054",
      "title": "Automated Place Preference Paradigm for Optogenetic Stimulation of the Pedunculopontine Nucleus Reveals Motor Arrest-Linked Preference Behavior",
      "content": "arXiv:2601.12054v1 Announce Type: new \nAbstract: Understanding how the brain integrates motor suppression with motivational processes remains a fundamental question in neuroscience. The rostral Pedunculopontine nucleus, a brainstem structure involved in motor control, has been shown to induce transient motor arrest upon optogenetic or electrical stimulation. However, our current understanding of its potential role in linking motor suppression with motivational or reinforcement-related processes is still insufficient. To further explore the effects induced by PPN stimulations and infer the potential mechanism underlying its role involved in both motor and emotional regulation, we developed a fully automated, low-cost system combining real-time animal tracking with closed-loop optogenetic stimulation, using the OpenMV Cam H7 Plus and embedded neural network models. The system autonomously detects the rat's position and triggers optical stimulation upon entry into a predefined region of interest, enabling unbiased, unsupervised behavioral assays. Optogenetic activation of CaMKIIa-expressing neurons in the rostral PPN reliably induced transient motor arrest. When stimulation was consistently paired with a specific location in a conditioned place preference task. When motor arrest was spatially paired with a defined region of interest, rats developed a robust place preference after limited training. These results suggest that rostral PPN activation can couple motor inhibition with reinforcement-related behavioral circuitry. Together, our work provides both a technical framework for scalable closed-loop neuroscience experiments and preliminary evidence that the rostral PPN may participate in coordinating motor suppression with motivational processes.",
      "author": "Guanghui Li, Xingfei Hou, Zhenxiang Zhao",
      "published_date": "2026-01-21T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 233,
      "reading_time": 1,
      "created_at": "2026-01-21T05:30:22.145868+00:00",
      "updated_at": "2026-01-21T05:30:22.145870+00:00"
    },
    {
      "id": "2482786623645d5b92bbbe61583ea079",
      "url": "https://arxiv.org/abs/2601.12053",
      "title": "A New Strategy for Artificial Intelligence: Training Foundation Models Directly on Human Brain Data",
      "content": "arXiv:2601.12053v1 Announce Type: new \nAbstract: While foundation models have achieved remarkable results across a diversity of domains, they still rely on human-generated data, such as text, as a fundamental source of knowledge. However, this data is ultimately the product of human brains, the filtered projection of a deeper neural complexity. In this paper, we explore a new strategy for artificial intelligence: moving beyond surface-level statistical regularities by training foundation models directly on human brain data. We hypothesize that neuroimaging data could open a window into elements of human cognition that are not accessible through observable actions, and argue that this additional knowledge could be used, alongside classical training data, to overcome some of the current limitations of foundation models. While previous research has demonstrated the possibility to train classical machine learning or deep learning models on neural patterns, this path remains largely unexplored for high-level cognitive functions. Here, we classify the current limitations of foundation models, as well as the promising brain regions and cognitive processes that could be leveraged to address them, along four levels: perception, valuation, execution, and integration. Then, we propose two methods that could be implemented to prioritize the use of limited neuroimaging data for strategically chosen, high-value steps in foundation model training: reinforcement learning from human brain (RLHB) and chain of thought from human brain (CoTHB). We also discuss the potential implications for agents, artificial general intelligence, and artificial superintelligence, as well as the ethical, social, and technical challenges and opportunities. We argue that brain-trained foundation models could represent a realistic and effective middle ground between continuing to scale current architectures and exploring alternative, neuroscience-inspired solutions.",
      "author": "Ma\\\"el Donoso",
      "published_date": "2026-01-21T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 271,
      "reading_time": 1,
      "created_at": "2026-01-21T05:30:22.145832+00:00",
      "updated_at": "2026-01-21T05:30:22.145834+00:00"
    },
    {
      "id": "42f6ce73a7f148914ccf7fb852d4d579",
      "url": "https://arxiv.org/abs/2601.11653",
      "title": "AI Agents Need Memory Control Over More Context",
      "content": "arXiv:2601.11653v1 Announce Type: new \nAbstract: AI agents are increasingly used in long, multi-turn workflows in both research and enterprise settings. As interactions grow, agent behavior often degrades due to loss of constraint focus, error accumulation, and memory-induced drift. This problem is especially visible in real-world deployments where context evolves, distractions are introduced, and decisions must remain consistent over time. A common practice is to equip agents with persistent memory through transcript replay or retrieval-based mechanisms. While convenient, these approaches introduce unbounded context growth and are vulnerable to noisy recall and memory poisoning, leading to unstable behavior and increased drift. In this work, we introduce the Agent Cognitive Compressor (ACC), a bio-inspired memory controller that replaces transcript replay with a bounded internal state updated online at each turn. ACC separates artifact recall from state commitment, enabling stable conditioning while preventing unverified content from becoming persistent memory. We evaluate ACC using an agent-judge-driven live evaluation framework that measures both task outcomes and memory-driven anomalies across extended interactions. Across scenarios spanning IT operations, cybersecurity response, and healthcare workflows, ACC consistently maintains bounded memory and exhibits more stable multi-turn behavior, with significantly lower hallucination and drift than transcript replay and retrieval-based agents. These results show that cognitive compression provides a practical and effective foundation for reliable memory control in long-horizon AI agents.",
      "author": "Fouad Bousetouane",
      "published_date": "2026-01-21T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 218,
      "reading_time": 1,
      "created_at": "2026-01-21T05:30:22.145787+00:00",
      "updated_at": "2026-01-21T05:30:22.145791+00:00"
    }
  ]
}