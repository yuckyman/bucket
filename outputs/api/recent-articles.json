{
  "last_updated": "2025-11-05T05:22:12.696413+00:00",
  "count": 20,
  "articles": [
    {
      "id": "a0557799b2b66560bd70d30663a47e77",
      "url": "https://arxiv.org/abs/2511.02515",
      "title": "Emotional Contagion in Code: How GitHub Emoji Reactions Shape Developer Collaboration",
      "content": "arXiv:2511.02515v1 Announce Type: new \nAbstract: Developer communities increasingly rely on emoji reactions to communicate, but we know little about how these emotional signals spread and influence technical discussions. We analyzed 2,098 GitHub issues and pull requests across 50 popular repositories, examining patterns in 106,743 emoji reactions to understand emotional contagion in software development. Our findings reveal a surprisingly positive emotional landscape: 57.4% of discussions carry positive sentiment, with positive emotional cascades outnumbering negative ones 23:1. We identified five distinct patterns, with \"instant enthusiasm\" affecting 45.6% of items--nearly half receive immediate positive reinforcement. Statistical analysis confirms strong emotional contagion (r=0.679, p<0.001) with a massive effect size (d=2.393), suggesting that initial reactions powerfully shape discussion trajectories. These findings challenge assumptions about technical discourse being purely rational, demonstrating that even minimal emotional signals create measurable ripple effects. Our work provides empirical evidence that emoji reactions are not mere decoration but active forces shaping collaborative outcomes in software development.",
      "author": "Obada Kraishan",
      "published_date": "2025-11-05T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 155,
      "reading_time": 1,
      "created_at": "2025-11-05T05:21:53.513010+00:00",
      "updated_at": "2025-11-05T05:21:53.513011+00:00"
    },
    {
      "id": "925985bf4847818c1094804a5e5d68af",
      "url": "https://arxiv.org/abs/2511.02468",
      "title": "HAGI++: Head-Assisted Gaze Imputation and Generation",
      "content": "arXiv:2511.02468v1 Announce Type: new \nAbstract: Mobile eye tracking plays a vital role in capturing human visual attention across both real-world and extended reality (XR) environments, making it an essential tool for applications ranging from behavioural research to human-computer interaction. However, missing values due to blinks, pupil detection errors, or illumination changes pose significant challenges for further gaze data analysis. To address this challenge, we introduce HAGI++ - a multi-modal diffusion-based approach for gaze data imputation that, for the first time, uses the integrated head orientation sensors to exploit the inherent correlation between head and eye movements. HAGI++ employs a transformer-based diffusion model to learn cross-modal dependencies between eye and head representations and can be readily extended to incorporate additional body movements. Extensive evaluations on the large-scale Nymeria, Ego-Exo4D, and HOT3D datasets demonstrate that HAGI++ consistently outperforms conventional interpolation methods and deep learning-based time-series imputation baselines in gaze imputation. Furthermore, statistical analyses confirm that HAGI++ produces gaze velocity distributions that closely match actual human gaze behaviour, ensuring more realistic gaze imputations. Moreover, by incorporating wrist motion captured from commercial wearable devices, HAGI++ surpasses prior methods that rely on full-body motion capture in the extreme case of 100% missing gaze data (pure gaze generation). Our method paves the way for more complete and accurate eye gaze recordings in real-world settings and has significant potential for enhancing gaze-based analysis and interaction across various application domains.",
      "author": "Chuhan Jiao, Zhiming Hu, Andreas Bulling",
      "published_date": "2025-11-05T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 232,
      "reading_time": 1,
      "created_at": "2025-11-05T05:21:53.512982+00:00",
      "updated_at": "2025-11-05T05:21:53.512984+00:00"
    },
    {
      "id": "81d80692a1233ca3d50394a3c8685c44",
      "url": "https://arxiv.org/abs/2511.02455",
      "title": "OpenCourier: an Open Protocol for Building a Decentralized Ecosystem of Community-owned Delivery Platforms",
      "content": "arXiv:2511.02455v1 Announce Type: new \nAbstract: Although the platform gig economy has reshaped the landscape of work, its centralized operation by select actors has brought about challenges that impedes workers' well-being. We present the architecture and design of OpenCourier, an open protocol that defines communication patterns within a decentralized ecosystem of delivery platforms. Through this protocol, we aim to address three key challenges in the current economy: power imbalances between the platform and workers, information asymmetries caused by black-boxed algorithms and value misalignments in the infrastructure design process. With the OpenCourier protocol, we outline a blueprint for community-owned ecosystem of delivery platforms that centers worker agency, transparency, and bottom-up design.",
      "author": "Yuhan Liu, Varun Nagaraj Rao, Sohyeon Hwang, Janet Vertesi, Andr\\'es Monroy-Hern\\'andez",
      "published_date": "2025-11-05T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 109,
      "reading_time": 1,
      "created_at": "2025-11-05T05:21:53.512949+00:00",
      "updated_at": "2025-11-05T05:21:53.512950+00:00"
    },
    {
      "id": "c9ba8e10b698d63a78a875f1be41488c",
      "url": "https://arxiv.org/abs/2511.02428",
      "title": "Can Conversational AI Counsel for Change? A Theory-Driven Approach to Supporting Dietary Intentions in Ambivalent Individuals",
      "content": "arXiv:2511.02428v1 Announce Type: new \nAbstract: Adherence to healthy diets reduces chronic illness risk, yet rates remain low. Large Language Models (LLMs) are increasingly used for health communication but often struggle to engage individuals with ambivalent intentions at a pivotal stage of the Transtheoretical Model (TTM). We developed CounselLLM, an open-source model enhanced through persona design and few-shot, domain-specific prompts grounded in TTM and Motivational Interviewing (MI). In controlled evaluations, CounselLLM showed stronger use of TTM subprocesses and MI affirmations than human counselors, with comparable linguistic robustness but expressed in more concrete terms. A user study then tested CounselLLM in an interactive counseling setting against a baseline system. While knowledge and perceptions did not change, participants' intentions for immediate dietary change increased significantly after interacting with CounselLLM. Participants also rated it as easy to use, understandable, and supportive. These findings suggest theory-driven LLMs can effectively engage ambivalent individuals and provide a scalable approach to digital counseling.",
      "author": "Michelle Bak, Kexin Quan, Tre Tomaszewski, Jessie Chin",
      "published_date": "2025-11-05T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 155,
      "reading_time": 1,
      "created_at": "2025-11-05T05:21:53.512925+00:00",
      "updated_at": "2025-11-05T05:21:53.512927+00:00"
    },
    {
      "id": "f02745e73308b544dcbf4fa37b96cba0",
      "url": "https://arxiv.org/abs/2511.02378",
      "title": "Revisiting put-that-there, context aware window interactions via LLMs",
      "content": "arXiv:2511.02378v1 Announce Type: new \nAbstract: We revisit Bolt's classic \"Put-That-There\" concept for modern head-mounted displays by pairing Large Language Models (LLMs) with XR sensor and tech stack. The agent fuses (i) a semantically segmented 3-D environment, (ii) live application metadata, and (iii) users' verbal, pointing, and head-gaze cues to issue JSON window-placement actions. As a result, users can manage a panoramic workspace through: (1) explicit commands (\"Place Google Maps on the coffee table\"), (2) deictic speech plus gestures (\"Put that there\"), or (3) high-level goals (\"I need to send a message\"). Unlike traditional explicit interfaces, our system supports one-to-many action mappings and goal-centric reasoning, allowing the LLM to dynamically infer relevant applications and layout decisions, including interrelationships across tools. This enables seamless, intent-driven interaction without manual window juggling in immersive XR environments.",
      "author": "Riccardo Bovo, Daniele Giunchi, Pasquale Cascarano, Eric J. Gonzalez, Mar Gonzalez-Franco",
      "published_date": "2025-11-05T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 132,
      "reading_time": 1,
      "created_at": "2025-11-05T05:21:53.512897+00:00",
      "updated_at": "2025-11-05T05:21:53.512899+00:00"
    },
    {
      "id": "ea7e6f6c7f831956935ba788d23ad61c",
      "url": "https://arxiv.org/abs/2511.02370",
      "title": "AI Credibility Signals Outrank Institutions and Engagement in Shaping News Perception on Social Media",
      "content": "arXiv:2511.02370v1 Announce Type: new \nAbstract: AI-generated content is rapidly becoming a salient component of online information ecosystems, yet its influence on public trust and epistemic judgments remains poorly understood. We present a large-scale mixed-design experiment (N = 1,000) investigating how AI-generated credibility scores affect user perception of political news. Our results reveal that AI feedback significantly moderates partisan bias and institutional distrust, surpassing traditional engagement signals such as likes and shares. These findings demonstrate the persuasive power of generative AI and suggest a need for design strategies that balance epistemic influence with user autonomy.",
      "author": "Adnan Hoq, Matthew Facciani, Tim Weninger",
      "published_date": "2025-11-05T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 94,
      "reading_time": 1,
      "created_at": "2025-11-05T05:21:53.512870+00:00",
      "updated_at": "2025-11-05T05:21:53.512872+00:00"
    },
    {
      "id": "249c88838301afe4a283745f58f89daf",
      "url": "https://arxiv.org/abs/2511.02367",
      "title": "The Pervasive Blind Spot: Benchmarking VLM Inference Risks on Everyday Personal Videos",
      "content": "arXiv:2511.02367v1 Announce Type: new \nAbstract: The proliferation of Vision-Language Models (VLMs) introduces profound privacy risks from personal videos. This paper addresses the critical yet unexplored inferential privacy threat, the risk of inferring sensitive personal attributes over the data. To address this gap, we crowdsourced a dataset of 508 everyday personal videos from 58 individuals. We then conducted a benchmark study evaluating VLM inference capabilities against human performance. Our findings reveal three critical insights: (1) VLMs possess superhuman inferential capabilities, significantly outperforming human evaluators, leveraging a shift from object recognition to behavioral inference from temporal streams. (2) Inferential risk is strongly correlated with factors such as video characteristics and prompting strategies. (3) VLM-driven explanation towards the inference is unreliable, as we revealed a disconnect between the model-generated explanations and evidential impact, identifying ubiquitous objects as misleading confounders.",
      "author": "Shuning Zhang, Zhaoxin Li, Changxi Wen, Ying Ma, Simin Li, Gengrui Zhang, Ziyi Zhang, Yibo Meng, Hantao Zhao, Xin Yi, Hewu Li",
      "published_date": "2025-11-05T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 136,
      "reading_time": 1,
      "created_at": "2025-11-05T05:21:53.512842+00:00",
      "updated_at": "2025-11-05T05:21:53.512844+00:00"
    },
    {
      "id": "60a010953f055186d4a2d11185eb6133",
      "url": "https://arxiv.org/abs/2511.02233",
      "title": "Learning Spatial Awareness for Laparoscopic Surgery with AI Assisted Visual Feedback",
      "content": "arXiv:2511.02233v1 Announce Type: new \nAbstract: Laparoscopic surgery constrains surgeons spatial awareness because procedures are performed through a monocular, two-dimensional (2D) endoscopic view. Conventional training methods using dry-lab models or recorded videos provide limited depth cues, often leading trainees to misjudge instrument position and perform ineffective or unsafe maneuvers. To address this limitation, we present an AI-assisted training framework developed in NVIDIA Isaac Sim that couples the standard 2D laparoscopic feed with synchronized three-dimensional (3D) visual feedback delivered through a mixed-reality (MR) interface. While trainees operate using the clinical 2D view, validated AI modules continuously localize surgical instruments and detect instrument-tissue interactions in the background. When spatial misjudgments are detected, 3D visual feedback are displayed to trainees, while preserving the original operative perspective. Our framework considers various surgical tasks including navigation, manipulation, transfer, cutting, and suturing. Visually similar 2D cases can be disambiguated through the added 3D context, improving depth perception, contact awareness, and tool orientation understanding.",
      "author": "Songyang Liu, Yunpeng Tan, Shuai Li",
      "published_date": "2025-11-05T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 156,
      "reading_time": 1,
      "created_at": "2025-11-05T05:21:53.512816+00:00",
      "updated_at": "2025-11-05T05:21:53.512817+00:00"
    },
    {
      "id": "2379c0549aaaa03efa6c39a6ebba49fd",
      "url": "https://arxiv.org/abs/2511.02133",
      "title": "AlloyLens: A Visual Analytics Tool for High-throughput Alloy Screening and Inverse Design",
      "content": "arXiv:2511.02133v1 Announce Type: new \nAbstract: Designing multi-functional alloys requires exploring high-dimensional composition-structure-property spaces, yet current tools are limited to low-dimensional projections and offer limited support for sensitivity or multi-objective tradeoff reasoning. We introduce AlloyLens, an interactive visual analytics system combining a coordinated scatterplot matrix (SPLOM), dynamic parameter sliders, gradient-based sensitivity curves, and nearest neighbor recommendations. This integrated approach reveals latent structure in simulation data, exposes the local impact of compositional changes, and highlights tradeoffs when exact matches are absent. We validate the system through case studies co-developed with domain experts spanning structural, thermal, and electrical alloy design.",
      "author": "Suyang Li, Fernando Fajardo-Rojas, Diego Gomez-Gualdron, Remco Chang, Mingwei Li",
      "published_date": "2025-11-05T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 97,
      "reading_time": 1,
      "created_at": "2025-11-05T05:21:53.512787+00:00",
      "updated_at": "2025-11-05T05:21:53.512789+00:00"
    },
    {
      "id": "660a71ec3b5d1f3a01d07de119754f6b",
      "url": "https://arxiv.org/abs/2511.02079",
      "title": "NeuResonance: Exploring Feedback Experiences for Fostering the Inter-brain Synchronization",
      "content": "arXiv:2511.02079v1 Announce Type: new \nAbstract: When several individuals collaborate on a shared task, their brain activities often synchronize. This phenomenon, known as Inter-brain Synchronization (IBS), is notable for inducing prosocial outcomes such as enhanced interpersonal feelings, including closeness, trust, empathy, and more. Further strengthening the IBS with the aid of external feedback would be beneficial for scenarios where those prosocial feelings play a vital role in interpersonal communication, such as rehabilitation between a therapist and a patient, motor skill learning between a teacher and a student, and group performance art. This paper investigates whether visual, auditory, and haptic feedback of the IBS level can further enhance its intensity, offering design recommendations for feedback systems in IBS. We report findings when three different types of feedback were provided: IBS level feedback by means of on-body projection mapping, sonification using chords, and vibration bands attached to the wrist.",
      "author": "Jamie Ngoc Dinh, Snehesh Shrestha, You-Jin Kim, Jun Nishida, Myungin Lee",
      "published_date": "2025-11-05T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 146,
      "reading_time": 1,
      "created_at": "2025-11-05T05:21:53.512757+00:00",
      "updated_at": "2025-11-05T05:21:53.512761+00:00"
    },
    {
      "id": "6712c541016c509f6b2bfdc45e4a98a5",
      "url": "https://arxiv.org/abs/2510.01386",
      "title": "A Single-Equation Approach to Classifying Neuronal Operational Modes",
      "content": "arXiv:2510.01386v2 Announce Type: replace \nAbstract: The neural coding is yet to be discovered. The neuronal operational modes that arise with fixed inputs but with varying degrees of stimulation help to elucidate their coding properties. In neurons receiving {\\it in vivo} stimulation, we show that two operation modes can be described with simplified models: the coincidence detection mode and the integration mode. Our derivations include a simplified polynomial model with non-linear coefficients ($\\beta_i$) that capture the subthreshold dynamics of these modes of operation. The resulting model can explain these transitions with the sign and size of the smallest nonlinear coefficient of the polynomial alone. Defining neuronal operational modes provides insight into the processing and transmission of information through electrical currents. Requisite operational modes for proper neuronal functioning may explain disorders involving dysfunction of electrophysiological behavior, such as channelopathies.",
      "author": "Lindsey Knowles, Cesar Ceballos, Rodrigo Pena",
      "published_date": "2025-11-05T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 137,
      "reading_time": 1,
      "created_at": "2025-11-05T05:21:52.420435+00:00",
      "updated_at": "2025-11-05T05:21:52.420437+00:00"
    },
    {
      "id": "6abe44770965fb5f855feddb86dbb8ee",
      "url": "https://arxiv.org/abs/2404.03902",
      "title": "Modulation of metastable ensemble dynamics explains the inverted-U relationship between tone discriminability and arousal in auditory cortex",
      "content": "arXiv:2404.03902v3 Announce Type: replace \nAbstract: Past work has reported inverted-U relationships between arousal and auditory task performance, but the underlying neural network mechanisms remain unclear. To make progress, we recorded auditory cortex activity from behaving mice during passive tone presentation and simultaneously monitored pupil-indexed arousal. In these experiments, neural discriminability of tones was maximized at intermediate arousal, revealing a neural correlate of the inverted-U. We explained this arousal-dependent sound processing using a spiking model with clusters. In the model, stimulus discriminability peaked as the network transitioned from a multi-attractor phase exhibiting slow switching between metastable cluster activations (low arousal) to a single-attractor phase with uniform activity (high arousal). This transition also qualitatively captured arousal-induced reductions of neural variability observed in the data. Altogether, this study elucidates computational principles to explain interactions between arousal, neural discriminability, and variability, and suggests that transitions in the dynamical regime of cortical networks could underlie nonlinear modulations of sensory processing.",
      "author": "Lia Papadopoulos, Suhyun Jo, Kevin Zumwalt, Michael Wehr, Santiago Jaramillo, David A. McCormick, Luca Mazzucato",
      "published_date": "2025-11-05T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 155,
      "reading_time": 1,
      "created_at": "2025-11-05T05:21:52.420409+00:00",
      "updated_at": "2025-11-05T05:21:52.420410+00:00"
    },
    {
      "id": "96703cfbaa405915e54b80a0631ff922",
      "url": "https://arxiv.org/abs/2511.02558",
      "title": "Forecasting Future Anatomies: Longitudianl Brain Mri-to-Mri Prediction",
      "content": "arXiv:2511.02558v1 Announce Type: cross \nAbstract: Predicting future brain state from a baseline magnetic resonance image (MRI) is a central challenge in neuroimaging and has important implications for studying neurodegenerative diseases such as Alzheimer's disease (AD). Most existing approaches predict future cognitive scores or clinical outcomes, such as conversion from mild cognitive impairment to dementia. Instead, here we investigate longitudinal MRI image-to-image prediction that forecasts a participant's entire brain MRI several years into the future, intrinsically modeling complex, spatially distributed neurodegenerative patterns. We implement and evaluate five deep learning architectures (UNet, U2-Net, UNETR, Time-Embedding UNet, and ODE-UNet) on two longitudinal cohorts (ADNI and AIBL). Predicted follow-up MRIs are directly compared with the actual follow-up scans using metrics that capture global similarity and local differences. The best performing models achieve high-fidelity predictions, and all models generalize well to an independent external dataset, demonstrating robust cross-cohort performance. Our results indicate that deep learning can reliably predict participant-specific brain MRI at the voxel level, offering new opportunities for individualized prognosis.",
      "author": "Ali Farki, Elaheh Moradi, Deepika Koundal, Jussi Tohka",
      "published_date": "2025-11-05T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 166,
      "reading_time": 1,
      "created_at": "2025-11-05T05:21:52.420382+00:00",
      "updated_at": "2025-11-05T05:21:52.420383+00:00"
    },
    {
      "id": "f2ecee06435989d1678c4cec00476a75",
      "url": "https://arxiv.org/abs/2511.02241",
      "title": "Structural Plasticity as Active Inference: A Biologically-Inspired Architecture for Homeostatic Control",
      "content": "arXiv:2511.02241v1 Announce Type: cross \nAbstract: Traditional neural networks, while powerful, rely on biologically implausible learning mechanisms such as global backpropagation. This paper introduces the Structurally Adaptive Predictive Inference Network (SAPIN), a novel computational model inspired by the principles of active inference and the morphological plasticity observed in biological neural cultures. SAPIN operates on a 2D grid where processing units, or cells, learn by minimizing local prediction errors. The model features two primary, concurrent learning mechanisms: a local, Hebbian-like synaptic plasticity rule based on the temporal difference between a cell's actual activation and its learned expectation, and a structural plasticity mechanism where cells physically migrate across the grid to optimize their information-receptive fields. This dual approach allows the network to learn both how to process information (synaptic weights) and also where to position its computational resources (network topology). We validated the SAPIN model on the classic Cart Pole reinforcement learning benchmark. Our results demonstrate that the architecture can successfully solve the CartPole task, achieving robust performance. The network's intrinsic drive to minimize prediction error and maintain homeostasis was sufficient to discover a stable balancing policy. We also found that while continual learning led to instability, locking the network's parameters after achieving success resulted in a stable policy. When evaluated for 100 episodes post-locking (repeated over 100 successful agents), the locked networks maintained an average 82% success rate.",
      "author": "Brennen A. Hill",
      "published_date": "2025-11-05T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 226,
      "reading_time": 1,
      "created_at": "2025-11-05T05:21:52.420354+00:00",
      "updated_at": "2025-11-05T05:21:52.420355+00:00"
    },
    {
      "id": "02ff260ea784680e6e11b1979315fe6a",
      "url": "https://arxiv.org/abs/2511.01885",
      "title": "Mirror-Neuron Patterns in AI Alignment",
      "content": "arXiv:2511.01885v1 Announce Type: cross \nAbstract: As artificial intelligence (AI) advances toward superhuman capabilities, aligning these systems with human values becomes increasingly critical. Current alignment strategies rely largely on externally specified constraints that may prove insufficient against future super-intelligent AI capable of circumventing top-down controls.\n  This research investigates whether artificial neural networks (ANNs) can develop patterns analogous to biological mirror neurons cells that activate both when performing and observing actions, and how such patterns might contribute to intrinsic alignment in AI. Mirror neurons play a crucial role in empathy, imitation, and social cognition in humans. The study therefore asks: (1) Can simple ANNs develop mirror-neuron patterns? and (2) How might these patterns contribute to ethical and cooperative decision-making in AI systems?\n  Using a novel Frog and Toad game framework designed to promote cooperative behaviors, we identify conditions under which mirror-neuron patterns emerge, evaluate their influence on action circuits, introduce the Checkpoint Mirror Neuron Index (CMNI) to quantify activation strength and consistency, and propose a theoretical framework for further study.\n  Our findings indicate that appropriately scaled model capacities and self/other coupling foster shared neural representations in ANNs similar to biological mirror neurons. These empathy-like circuits support cooperative behavior and suggest that intrinsic motivations modeled through mirror-neuron dynamics could complement existing alignment techniques by embedding empathy-like mechanisms directly within AI architectures.",
      "author": "Robyn Wyrick",
      "published_date": "2025-11-05T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 218,
      "reading_time": 1,
      "created_at": "2025-11-05T05:21:52.420322+00:00",
      "updated_at": "2025-11-05T05:21:52.420324+00:00"
    },
    {
      "id": "421016a3b423488f145d87049021a37b",
      "url": "https://arxiv.org/abs/2511.02766",
      "title": "Microbes in the Moonlight: How the Gut Microbiota Influences Sleep",
      "content": "arXiv:2511.02766v1 Announce Type: new \nAbstract: The gut microbiota has emerged as a fundamental regulator of sleep physiology, influencing neural, endocrine, and immune pathways through the gut-microbiota-brain axis (GMBA). This bidirectional communication system modulates neurotransmitter production, circadian rhythms, and metabolic homeostasis, while disruptions in microbial composition have been linked to sleep disorders, neuroinflammation, and systemic immune dysfunction. Recent findings suggest that gut dysbiosis contributes to sleep disturbances by altering serotonin, GABA, and short-chain fatty acid (SCFA) metabolism, with implications for neurodegenerative diseases, metabolic syndromes, and mood disorders. Additionally, the gut microbiota interacts with the endocrine and immune systems, shaping inflammatory responses and stress adaptation mechanisms. This review explores the intricate connections between sleep and the gut microbiota, integrating emerging research on microbiota-targeted therapies, such as probiotics, fecal microbiota transplantation (FMT), and chrononutrition, as potential interventions to restore sleep homeostasis and improve health outcomes",
      "author": "Enso Onill Torres Alegre",
      "published_date": "2025-11-05T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 142,
      "reading_time": 1,
      "created_at": "2025-11-05T05:21:52.420289+00:00",
      "updated_at": "2025-11-05T05:21:52.420291+00:00"
    },
    {
      "id": "f1dfecb43e3591e77cd7cbfbb563526f",
      "url": "https://arxiv.org/abs/2511.02722",
      "title": "Association-sensory spatiotemporal hierarchy and functional gradient-regularised recurrent neural network with implications for schizophrenia",
      "content": "arXiv:2511.02722v1 Announce Type: new \nAbstract: The human neocortex is functionally organised at its highest level along a continuous sensory-to-association (AS) hierarchy. This study characterises the AS hierarchy of patients with schizophrenia in a comparison with controls. Using a large fMRI dataset (N=355), we extracted individual AS gradients via spectral analysis of brain connectivity, quantified hierarchical specialisation by gradient spread, and related this spread with connectivity geometry. We found that schizophrenia compresses the AS hierarchy indicating reduced functional differentiation. By modelling neural timescale with the Ornstein-Uhlenbeck process, we observed that the most specialised, locally cohesive regions at the gradient extremes exhibit dynamics with a longer time constant, an effect that is attenuated in schizophrenia. To study computation, we used the gradients to regularise subject-specific recurrent neural networks (RNNs) trained on working memory tasks. Networks endowed with greater gradient spread learned more efficiently, plateaued at lower task loss, and maintained stronger alignment to the prescribed AS hierarchical geometry. Fixed point linearisation showed that high-range networks settled into more stable neural states during memory delay, evidenced by lower energy and smaller maximal Jacobian eigenvalues. This gradient-regularised RNN framework therefore links large-scale cortical architecture with fixed point stability, providing a mechanistic account of how gradient de-differentiation could destabilise neural computations in schizophrenia, convergently supported by empirical timescale flattening and model-based evidence of less stable fixed points.",
      "author": "Subati Abulikemu, Puria Radmard, Michail Mamalakis, John Suckling",
      "published_date": "2025-11-05T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 222,
      "reading_time": 1,
      "created_at": "2025-11-05T05:21:52.420262+00:00",
      "updated_at": "2025-11-05T05:21:52.420264+00:00"
    },
    {
      "id": "84d2040427b3827a966a0717b34c9749",
      "url": "https://arxiv.org/abs/2511.02063",
      "title": "Neural dynamics of cognitive control: Current tensions and future promise",
      "content": "arXiv:2511.02063v1 Announce Type: new \nAbstract: Cognitive control is a suite of processes that helps individuals pursue goals despite resistance or uncertainty about what to do. Although cognitive control has been extensively studied as a dynamic feedback loop of perception, valuation, and action, it remains incompletely understood as a cohesive dynamic and distributed neural process. Here, we critically examine the history of and advances in the study of cognitive control, including how metaphors and cultural norms of power, morality, and rationality are intertwined with definitions of control, to consider holistically how different models explain which brain regions act as controllers. Controllers, the source of top-down signals, are typically localized in regions whose neural activations implement elementary component processes of control, including conflict monitoring and behavioral inhibition. Top-down signals from these regions guide the activation of other task-specific regions, biasing them towards task-specific activity patterns. A relatively new approach, network control theory, has roots in dynamical systems theory and systems engineering. This approach can mathematically show that controllers are regions with strongly nested and recurrent anatomical connectivity that efficiently propagate top-down signals, and precisely estimate the amount, location, and timing of signaling required to bias global activity to task-specific patterns. The theory converges with prior evidence, offers new mathematical tools and intuitions for understanding control loops across levels of analysis, and naturally produces graded predictions of control across brain regions and modules of psychological function that have been unconsidered or marginalized. We describe how prior approaches converge and diverge, noting directions for future integration to improve understanding of how the brain instantiates cognitive control.",
      "author": "Dale Zhou, Danielle Cosme, Yoona Kang, Ovidia Stanoi, David M. Lydon-Staley, Peter J. Mucha, Emily B. Falk, Kevin N. Ochsner, Dani S. Bassett",
      "published_date": "2025-11-05T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 262,
      "reading_time": 1,
      "created_at": "2025-11-05T05:21:52.420230+00:00",
      "updated_at": "2025-11-05T05:21:52.420232+00:00"
    },
    {
      "id": "15405863dcb65cde494750c04da90b88",
      "url": "https://arxiv.org/abs/2511.01870",
      "title": "CytoNet: A Foundation Model for the Human Cerebral Cortex",
      "content": "arXiv:2511.01870v1 Announce Type: new \nAbstract: To study how the human brain works, we need to explore the organization of the cerebral cortex and its detailed cellular architecture. We introduce CytoNet, a foundation model that encodes high-resolution microscopic image patches of the cerebral cortex into highly expressive feature representations, enabling comprehensive brain analyses. CytoNet employs self-supervised learning using spatial proximity as a powerful training signal, without requiring manual labelling. The resulting features are anatomically sound and biologically relevant. They encode general aspects of cortical architecture and unique brain-specific traits. We demonstrate top-tier performance in tasks such as cortical area classification, cortical layer segmentation, cell morphology estimation, and unsupervised brain region mapping. As a foundation model, CytoNet offers a consistent framework for studying cortical microarchitecture, supporting analyses of its relationship with other structural and functional brain features, and paving the way for diverse neuroscientific investigations.",
      "author": "Christian Schiffer, Zeynep Boztoprak, Jan-Oliver Kropp, Julia Th\\\"onni{\\ss}en, Katia Berr, Hannah Spitzer, Katrin Amunts, Timo Dickscheid",
      "published_date": "2025-11-05T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 143,
      "reading_time": 1,
      "created_at": "2025-11-05T05:21:52.420192+00:00",
      "updated_at": "2025-11-05T05:21:52.420193+00:00"
    },
    {
      "id": "1f53dc0f4a57e26eb9ca0261be9af102",
      "url": "https://arxiv.org/abs/2511.01868",
      "title": "Condition-Invariant fMRI Decoding of Speech Intelligibility with Deep State Space Model",
      "content": "arXiv:2511.01868v1 Announce Type: new \nAbstract: Clarifying the neural basis of speech intelligibility is critical for computational neuroscience and digital speech processing. Recent neuroimaging studies have shown that intelligibility modulates cortical activity beyond simple acoustics, primarily in the superior temporal and inferior frontal gyri. However, previous studies have been largely confined to clean speech, leaving it unclear whether the brain employs condition-invariant neural codes across diverse listening environments. To address this gap, we propose a novel architecture built upon a deep state space model for decoding intelligibility from fMRI signals, specifically tailored to their high-dimensional temporal structure. We present the first attempt to decode intelligibility across acoustically distinct conditions, showing our method significantly outperforms classical approaches. Furthermore, region-wise analysis highlights contributions from auditory, frontal, and parietal regions, and cross-condition transfer indicates the presence of condition-invariant neural codes, thereby advancing understanding of abstract linguistic representations in the brain.",
      "author": "Ching-Chih Sung, Shuntaro Suzuki, Francis Pingfan Chien, Komei Sugiura, Yu Tsao",
      "published_date": "2025-11-05T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 146,
      "reading_time": 1,
      "created_at": "2025-11-05T05:21:52.420159+00:00",
      "updated_at": "2025-11-05T05:21:52.420164+00:00"
    }
  ]
}