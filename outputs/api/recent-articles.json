{
  "last_updated": "2026-01-26T06:30:20.358203+00:00",
  "count": 20,
  "articles": [
    {
      "id": "9b7968741403d6b479424052728c8879",
      "url": "http://ieeexplore.ieee.org/document/10856260",
      "title": "Front Cover",
      "content": "null",
      "author": "",
      "published_date": "2025-01-28T13:17:19+00:00",
      "source": "Reviews Biomedical Engineering",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 1,
      "reading_time": 1,
      "created_at": "2026-01-26T05:55:49.913086+00:00",
      "updated_at": "2026-01-26T06:30:20.249998+00:00",
      "metadata": {
        "processed_at": "2026-01-26T06:30:20.250007+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "7441f8a9c001207bbbea8adb1642b1f2",
      "url": "https://www.nature.com/articles/s41593-025-02192-x",
      "title": "Who delivers evidence matters",
      "content": "<p>Nature Neuroscience, Published online: 07 January 2026; <a href=\"https://www.nature.com/articles/s41593-025-02192-x\">doi:10.1038/s41593-025-02192-x</a></p>Who delivers evidence matters",
      "author": "Henrietta Howells",
      "published_date": "2026-01-07T00:00:00+00:00",
      "source": "Nature Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 12,
      "reading_time": 1,
      "created_at": "2026-01-26T05:55:34.109199+00:00",
      "updated_at": "2026-01-26T06:30:20.250012+00:00",
      "metadata": {
        "processed_at": "2026-01-26T06:30:20.250014+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "8d486873b6728e5969fb54b3a44976e8",
      "url": "https://www.frontiersin.org/articles/10.3389/fninf.2025.1679196",
      "title": "Cross-modal privacy-preserving synthesis and mixture-of-experts ensemble for robust ASD prediction",
      "content": "IntroductionAutism Spectrum Disorder (ASD) diagnosis remains complex due to limited access to large-scale multimodal datasets and privacy concerns surrounding clinical data. Traditional methods rely heavily on resource-intensive clinical assessments and are constrained by unimodal or non-adaptive learning models. To address these limitations, this study introduces AutismSynthGen, a privacy-preserving framework for synthesizing multimodal ASD data and enhancing prediction accuracy.Materials and methodsThe proposed system integrates a Multimodal Autism Data Synthesis Network (MADSN), which employs transformer-based encoders and cross-modal attention within a conditional GAN to generate synthetic data across structural MRI, EEG, behavioral vectors, and severity scores. Differential privacy is enforced via DP-SGD (\u03b5\u202f\u2264\u202f1.0). A complementary Adaptive Multimodal Ensemble Learning (AMEL) module, consisting of five heterogeneous experts and a gating network, is trained on both real and synthetic data. Evaluation is conducted on the ABIDE, NDAR, and SSC datasets using metrics such as AUC, F1 score, MMD, KS statistic, and BLEU.ResultsSynthetic augmentation improved model performance, yielding validation AUC gains of \u2265 0.04. AMEL achieved an AUC of 0.98 and an F1 score of 0.99 on real data and approached near-perfect internal performance (AUC\u202f\u2248\u202f1.00, F1\u202f\u2248\u202f1.00) when synthetic data were included. Distributional metrics (MMD\u202f=\u202f0.04; KS\u202f=\u202f0.03) and text similarity (BLEU\u202f=\u202f0.70) demonstrated high fidelity between the real and synthetic samples. Ablation studies confirmed the importance of cross-modal attention and entropy-regularized expert gating.DiscussionAutismSynthGen offers a scalable, privacy-compliant solution for augmenting limited multimodal datasets and enhancing ASD prediction. Future directions include semi-supervised learning, explainable AI for clinical trust, and deployment in federated environments to broaden accessibility while maintaining privacy.",
      "author": "Karthiga M.",
      "published_date": "2025-11-19T00:00:00+00:00",
      "source": "Frontiers Neuroinformatics",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 262,
      "reading_time": 1,
      "created_at": "2026-01-26T05:55:29.146974+00:00",
      "updated_at": "2026-01-26T06:30:20.250017+00:00",
      "metadata": {
        "processed_at": "2026-01-26T06:30:20.250018+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "051b00eb368bb3d8d8ce021fb514a810",
      "url": "https://fmhy.net/posts/changelog-sites",
      "title": "Changelog Sites",
      "content": "<p><strong><a href=\"https://changes.fmhy.bid/\" rel=\"noreferrer\" target=\"_blank\">https://changes.fmhy.bid/</a></strong></p>\n<p>This covers changes that occur in both the #Recently-Added and #Monthly-Update channels in our Discord.</p>\n<hr />\n<p><strong><a href=\"https://fmhy-tracker.pages.dev/\" rel=\"noreferrer\" target=\"_blank\">https://fmhy-tracker.pages.dev/</a></strong></p>\n<p>This covers links that have been added, updated, or removed by watching GitHub for changes.</p>\n<hr />\n<p>Note that we will also continue to make the monthly posts same as always, and you can still follow updates by joining our <a href=\"https://redd.it/17f8msf\" rel=\"noreferrer\" target=\"_blank\">Discord</a>, or watching the <a href=\"https://github.com/fmhy/edit/commits/main/\" rel=\"noreferrer\" target=\"_blank\">Commits Page</a> on GitHub yourself.</p>\n<p>We hope you guys like them, if you have any suggestions or questions feel free to let us know.</p>",
      "author": "",
      "published_date": "2025-12-12T00:00:00+00:00",
      "source": "Fmhy",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 99,
      "reading_time": 1,
      "created_at": "2026-01-26T05:54:58.496432+00:00",
      "updated_at": "2026-01-26T06:30:20.250021+00:00",
      "metadata": {
        "processed_at": "2026-01-26T06:30:20.250022+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "23e750187081436c0ce9ec098162cd82",
      "url": "https://microclimates.solofounders.com/",
      "title": "SF Microclimates",
      "content": "<p>Article URL: <a href=\"https://microclimates.solofounders.com/\">https://microclimates.solofounders.com/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46761219\">https://news.ycombinator.com/item?id=46761219</a></p>\n<p>Points: 9</p>\n<p># Comments: 0</p>",
      "author": "rmason",
      "published_date": "2026-01-26T02:38:55+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2026-01-26T05:54:54.750941+00:00",
      "updated_at": "2026-01-26T06:30:20.250025+00:00",
      "metadata": {
        "processed_at": "2026-01-26T06:30:20.250026+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "dfe659db88246ddf53f2222fcde9bbdb",
      "url": "https://whythere.life",
      "title": "Show HN: WhyThere \u2013 Compare cities side-by-side to decide where to move",
      "content": "<p>Article URL: <a href=\"https://whythere.life\">https://whythere.life</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46761547\">https://news.ycombinator.com/item?id=46761547</a></p>\n<p>Points: 4</p>\n<p># Comments: 0</p>",
      "author": "daversa",
      "published_date": "2026-01-26T03:31:02+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2026-01-26T05:54:54.750921+00:00",
      "updated_at": "2026-01-26T05:54:54.750923+00:00"
    },
    {
      "id": "e383bc2b59fb44dc82d633e65d9f0289",
      "url": "https://arxiv.org/abs/2601.16751",
      "title": "\"What I Sign Is Not What I See\": Towards Explainable and Trustworthy Cryptocurrency Wallet Signatures",
      "content": "arXiv:2601.16751v1 Announce Type: new \nAbstract: Cryptocurrency wallets have become the primary gateway to decentralized applications, yet users often face significant difficulty in discerning what a wallet signature actually does or entails. Prior work has mainly focused on mitigating protocol vulnerabilities, with limited attention to how users perceive and interpret what they are authorizing. To examine this usability-security gap, we conducted two formative studies investigating how users interpret authentic signing requests and what cues they rely on to assess risk. Findings reveal that users often misread critical parameters, underestimate high-risk signatures, and rely on superficial familiarity rather than understanding transaction intent. Building on these insights, we designed the Signature Semantic Decoder -- a prototype framework that reconstructs and visualizes the intent behind wallet signatures prior to confirmation. Through structured parsing and semantic labeling, it demonstrates how signing data can be transformed into plain-language explanations with contextual risk cues. In a between-subjects user study (N = 128), participants using the prototype achieved higher accuracy in identifying risky signatures, improved clarity and decision confidence, and lower cognitive workload compared with the baseline wallet interface. Our study reframes wallet signing as a problem of interpretability within secure interaction design and offers design implications for more transparent and trustworthy cryptocurrency wallet interfaces.",
      "author": "Yuyang Qin, Haihan Duan",
      "published_date": "2026-01-26T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 207,
      "reading_time": 1,
      "created_at": "2026-01-26T05:09:16.594029+00:00",
      "updated_at": "2026-01-26T05:09:16.594031+00:00"
    },
    {
      "id": "603f5e7b36b624f184a171681bb88d1d",
      "url": "https://arxiv.org/abs/2601.16740",
      "title": "Evaluating Generative AI in the Lab: Methodological Challenges and Guidelines",
      "content": "arXiv:2601.16740v1 Announce Type: new \nAbstract: Generative AI (GenAI) systems are inherently non-deterministic, producing varied outputs even for identical inputs. While this variability is central to their appeal, it challenges established HCI evaluation practices that typically assume consistent and predictable system behavior. Designing controlled lab studies under such conditions therefore remains a key methodological challenge. We present a reflective multi-case analysis of four lab-based user studies with GenAI-integrated prototypes, spanning conversational in-car assistant systems and image generation tools for design workflows. Through cross-case reflection and thematic analysis across all study phases, we identify five methodological challenges and propose eighteen practice-oriented recommendations, organized into five guidelines. These challenges represent methodological constructs that are either amplified, redefined, or newly introduced by GenAI's stochastic nature: (C1) reliance on familiar interaction patterns, (C2) fidelity-control trade-offs, (C3) feedback and trust, (C4) gaps in usability evaluation, and (C5) interpretive ambiguity between interface and system issues. Our guidelines address these challenges through strategies such as reframing onboarding to help participants manage unpredictability, extending evaluation with constructs such as trust and intent alignment, and logging system events, including hallucinations and latency, to support transparent analysis. This work contributes (1) a methodological reflection on how GenAI's stochastic nature unsettles lab-based HCI evaluation and (2) eighteen recommendations that help researchers design more transparent, robust, and comparable studies of GenAI systems in controlled settings.",
      "author": "Hyerim Park, Khanh Huynh, Malin Eiband, Jeremy Dillmann, Sven Mayer, Michael Sedlmair",
      "published_date": "2026-01-26T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 222,
      "reading_time": 1,
      "created_at": "2026-01-26T05:09:16.593972+00:00",
      "updated_at": "2026-01-26T05:09:16.593973+00:00"
    },
    {
      "id": "9fa3c46cf1a7f3a82b07533b781262ce",
      "url": "https://arxiv.org/abs/2601.16720",
      "title": "Watching AI Think: User Perceptions of Visible Thinking in Chatbots",
      "content": "arXiv:2601.16720v1 Announce Type: new \nAbstract: People increasingly turn to conversational agents such as ChatGPT to seek guidance for their personal problems. As these systems grow in capability, many now display elements of \"thinking\": short reflective statements that reveal a model's intentions or values before responding. While initially introduced to promote transparency, such visible thinking can also anthropomorphise the agent and shape user expectations. Yet little is known about how these displays affect user perceptions in help-seeking contexts. We conducted a 3 x 2 mixed design experiment examining the impact of 'Thinking Content' (None, Emotionally-Supportive, Expertise-Supportive) and 'Conversation Context' (Habit-related vs. Feelings-related problems) on users' perceptions of empathy, warmth, competence, and engagement. Participants interacted with a chatbot that either showed no visible thinking or presented value-oriented reflections prior to its response. Our findings contribute to understanding how thinking transparency influences user experience in supportive dialogues, and offer implications for designing conversational agents that communicate intentions in sensitive, help-seeking scenarios.",
      "author": "Samuel Rhys Cox, Jade Martin-Lise, Simo Hosio, Niels van Berkel",
      "published_date": "2026-01-26T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 158,
      "reading_time": 1,
      "created_at": "2026-01-26T05:09:16.593937+00:00",
      "updated_at": "2026-01-26T05:09:16.593939+00:00"
    },
    {
      "id": "3d6b80db15af6d50433f812764d054db",
      "url": "https://arxiv.org/abs/2601.16708",
      "title": "Make the Unhearable Visible: Exploring Visualization for Musical Instrument Practice",
      "content": "arXiv:2601.16708v1 Announce Type: new \nAbstract: We explore the potential of visualization to support musicians in instrument practice through real-time feedback and reflection on their playing. Musicians often struggle to observe the patterns in their playing and interpret them with respect to their goals. Our premise is that these patterns can be made visible with interactive visualization: we can make the unhearable visible. However, understanding the design of such visualizations is challenging: the diversity of needs, including different instruments, skills, musical attributes, and genres, means that any single use case is unlikely to illustrate the broad potential and opportunities. To address this challenge, we conducted a design exploration study where we created and iterated on 33 designs, each focusing on a subset of needs, for example, only one musical skill. Our designs are grounded in our own experience as musicians and the ideas and feedback of 18 musicians with various musical backgrounds and we evaluated them with 13 music learners and teachers. This paper presents the results of our exploration, focusing on a few example designs as instances of possible instrument practice visualizations. From our work, we draw design considerations that contribute to future research and products for visual instrument education.",
      "author": "Frank Heyen, Michael Gleicher, Michael Sedlmair",
      "published_date": "2026-01-26T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 200,
      "reading_time": 1,
      "created_at": "2026-01-26T05:09:16.593907+00:00",
      "updated_at": "2026-01-26T05:09:16.593909+00:00"
    },
    {
      "id": "1ae28e271aa3d1e7a16f2adaa0cebd45",
      "url": "https://arxiv.org/abs/2601.16658",
      "title": "Talking about privacy always feels like opening a can of worms. How Intimate Partners Navigate Boundary-Setting in Mobile Phone Without Words",
      "content": "arXiv:2601.16658v1 Announce Type: new \nAbstract: Mobile phones, as simultaneously personal and shared technologies, complicate how partners manage digital privacy in intimate relationships. While prior research has examined device-access practices, explicit privacy-rule negotiation, and toxic practices such as surveillance, little is known about how couples manage digital privacy without direct discussion in everyday relationships. To address this gap, we ask: How is digital privacy managed nonverbally and across different media on mobile phones? Drawing on 20 semi-structured interviews, we find that partners often regulate privacy practices through privacy silence -- the intentional avoidance of privacy-related conversations. We identify five motivations for leaving boundaries unspoken: perceiving privacy as unnecessary in intimacy, assuming implicit respect for boundaries, signaling trust and closeness, avoiding potential conflict or harm, and responding to broader societal and cultural expectations that discourage explicit privacy talk. We also identify a hierarchical grouping of content-specific privacy sensitivities, ranging from highly private domains such as financial data to lower-risk domains such as streaming accounts, and show how these priorities shift across relationship stages. These findings show how silence, culture, and content sensitivity shape everyday boundary-setting and underscore the relational and emotional dynamics underpinning mobile phone privacy management.",
      "author": "Sima Amirkhani, Mahla Fatemeh Alizadeh, Farzaneh Gerami, Dave Randall, Gunnar Stevens",
      "published_date": "2026-01-26T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 195,
      "reading_time": 1,
      "created_at": "2026-01-26T05:09:16.593875+00:00",
      "updated_at": "2026-01-26T05:09:16.593877+00:00"
    },
    {
      "id": "18e3561f6977d3718834d2bc7baea9f5",
      "url": "https://arxiv.org/abs/2601.16656",
      "title": "Generative Confidants: How do People Experience Trust in Emotional Support from Generative AI?",
      "content": "arXiv:2601.16656v1 Announce Type: new \nAbstract: People are increasingly turning to generative AI (e.g., ChatGPT, Gemini, Copilot) for emotional support and companionship. While trust is likely to play a central role in enabling these informal and unsupervised interactions, we still lack an understanding of how people develop and experience it in this context. Seeking to fill this gap, we recruited 24 frequent users of generative AI for emotional support and conducted a qualitative study consisting of diary entries about interactions, transcripts of chats with AI, and in-depth interviews. Our results suggest important novel drivers of trust in this context: familiarity emerging from personalisation, nuanced mental models of generative AI, and awareness of people's control over conversations. Notably, generative AI's homogeneous use of personalised, positive, and persuasive language appears to promote some of these trust-building factors. However, this also seems to discourage other trust-related behaviours, such as remembering that generative AI is a machine trained to converse in human language. We present implications for future research that are likely to become critical as the use of generative AI for emotional support increasingly overlaps with therapeutic work.",
      "author": "Riccardo Volpato, Simone Stumpf, Lisa DeBruine",
      "published_date": "2026-01-26T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 184,
      "reading_time": 1,
      "created_at": "2026-01-26T05:09:16.593842+00:00",
      "updated_at": "2026-01-26T05:09:16.593843+00:00"
    },
    {
      "id": "c134d07d443febf041111707408cb4ed",
      "url": "https://arxiv.org/abs/2601.16639",
      "title": "HapticMatch: An Exploration for Generative Material Haptic Simulation and Interaction",
      "content": "arXiv:2601.16639v1 Announce Type: new \nAbstract: High-fidelity haptic feedback is essential for immersive virtual environments, yet authoring realistic tactile textures remains a significant bottleneck for designers. We introduce HapticMatch, a visual-to-tactile generation framework designed to democratize haptic content creation. We present a novel dataset containing precisely aligned pairs of micro-scale optical images, surface height maps, and friction-induced vibrations for 100 diverse materials. Leveraging this data, we explore and demonstrate that conditional generative models like diffusion and flow-matching can synthesize high-fidelity, renderable surface geometries directly from standard RGB photos. By enabling a \"Scan-to-Touch\" workflow, HapticMatch allows interaction designers to rapidly prototype multimodal surface sensations without specialized recording equipment, bridging the gap between visual and tactile immersion in VR/AR interfaces.",
      "author": "Mingxin Zhang, Yu Yao, Yasutoshi Makino, Hiroyuki Shinoda, Masashi Sugiyama",
      "published_date": "2026-01-26T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 117,
      "reading_time": 1,
      "created_at": "2026-01-26T05:09:16.593810+00:00",
      "updated_at": "2026-01-26T05:09:16.593811+00:00"
    },
    {
      "id": "33e9db9396c2e163efd84f9b4bca0d5d",
      "url": "https://arxiv.org/abs/2601.16583",
      "title": "Who You Explain To Matters: Learning by Explaining to Conversational Agents with Different Pedagogical Roles",
      "content": "arXiv:2601.16583v1 Announce Type: new \nAbstract: Conversational agents are increasingly used in education for learning support. An application is \"learning by explaining\", where learners explain their understanding to an agent. However, existing research focuses on single roles, leaving it unclear how different pedagogical roles influence learners' interaction patterns, learning outcomes and experiences. We conducted a between-subjects study (N=96) comparing agents with three pedagogical roles (Tutee, Peer, Challenger) and a control condition while learning an economics concept. We found that different pedagogical roles shaped learning dynamics, including interaction patterns and experiences. Specifically, the Tutee agent elicited the most cognitive investment but led to high pressure. The Peer agent fostered high absorption and interest through collaborative dialogue. The Challenger agent promoted cognitive and metacognitive acts, enhancing critical thinking with moderate pressure. The findings highlight how agent roles shape different learning dynamics, guiding the design of educational agents tailored to specific pedagogical goals and learning phases.",
      "author": "Zhengtao Xu, Junti Zhang, Anthony Tang, Yi-Chieh Lee",
      "published_date": "2026-01-26T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 152,
      "reading_time": 1,
      "created_at": "2026-01-26T05:09:16.593782+00:00",
      "updated_at": "2026-01-26T05:09:16.593784+00:00"
    },
    {
      "id": "52baa9cba2dec1cdf3cf7511400e6755",
      "url": "https://arxiv.org/abs/2601.16356",
      "title": "The Behavioral Fabric of LLM-Powered GUI Agents: Human Values and Interaction Outcomes",
      "content": "arXiv:2601.16356v1 Announce Type: new \nAbstract: Large Language Model (LLM)-powered web GUI agents are increasingly automating everyday online tasks. Despite their popularity, little is known about how users' preferences and values impact agents' reasoning and behavior. In this work, we investigate how both explicit and implicit user preferences, as well as the underlying user values, influence agent decision-making and action trajectories. We built a controlled testbed of 14 common interactive web tasks, spanning shopping, travel, dining, and housing, each replicated from real websites and integrated with a low-fidelity LLM-based recommender system. We injected 12 human preferences and values as personas into four state-of-the-art agents and systematically analyzed their task behaviors. Our results show that preference and value-infused prompts consistently guided agents toward outcomes that reflected these preferences and values. While the absence of user preference or value guidance led agents to exhibit a strong efficiency bias and employ shortest-path strategies, their presence steered agents' behavior trajectories through the greater use of corresponding filters and interactive web features. Despite their influence, dominant interface cues, such as discounts and advertisements, frequently overrode these effects, shortening the agents' action trajectories and inducing rationalizations that masked rather than reflected value-consistent reasoning. The contributions of this paper are twofold: (1) an open-source testbed for studying the influence of values in agent behaviors, and (2) an empirical investigation of how user preferences and values shape web agent behaviors.",
      "author": "Simret Araya Gebreegziabher, Yukun Yang, Charles Chiang, Hojun Yoo, Chaoran Chen, Hyo Jin Do, Zahra Ashktorab, Werner Geyer, Diego G\\'omez-Zar\\'a, Toby Jia-Jun Li",
      "published_date": "2026-01-26T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 231,
      "reading_time": 1,
      "created_at": "2026-01-26T05:09:16.593750+00:00",
      "updated_at": "2026-01-26T05:09:16.593752+00:00"
    },
    {
      "id": "a3888cf8dbb12e9c9a3bcf9af2c6dff9",
      "url": "https://arxiv.org/abs/2601.16321",
      "title": "My Parents Expectations Were Overwhelming: Online Dating Romance Scams Targeting Minors in Iran Through Exploitation of Parental Pressure",
      "content": "arXiv:2601.16321v1 Announce Type: new \nAbstract: Minors are at risk of myriad harms online, yet online dating romance scams are seldom considered one of them. While research of romance scams in Western countries finds victims to predominantly be middle-age, it is unknown if minors in geographic regions with cultural norms around teenage marriage are uniquely susceptible to online dating romance scams. We present an interview study with 16 victims of online dating romance scams in Iran who were minors when scammed. Findings show that, with westernized dating apps banned in Iran, scammers find teenage victims through messaging platforms tethered to local neighborhoods, offering relief for parental pressures around finding a marital partner and academic performance. Using threats, lies, and exploitation of emotional attachment lacking from their families, scammers pressured minors into financial and sexual favors. The study demonstrates how local cultural context should be foregrounded in future research on, and solutions for, technology-mediated harm against minors. Content Warning: This paper discusses sexual abuse.",
      "author": "Sima Amirkhani, Mahla Fatemeh Alizadeh, Dave Randall, Gunnar Stevens, Douglas Zytko",
      "published_date": "2026-01-26T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 162,
      "reading_time": 1,
      "created_at": "2026-01-26T05:09:16.593700+00:00",
      "updated_at": "2026-01-26T05:09:16.593705+00:00"
    },
    {
      "id": "e9c5cee4d20f5c1260967b3a15d9d3eb",
      "url": "https://arxiv.org/abs/2601.12054",
      "title": "Automated Place Preference Paradigm for Optogenetic Stimulation of the Pedunculopontine Nucleus Reveals Motor Arrest-Linked Preference Behavior",
      "content": "arXiv:2601.12054v3 Announce Type: replace \nAbstract: Understanding how the brain integrates motor suppression with motivational processes remains a fundamental question in neuroscience. The rostral Pedunculopontine nucleus, a brainstem structure involved in motor control, has been shown to induce transient motor arrest upon optogenetic or electrical stimulation. However, our current understanding of its potential role in linking motor suppression with motivational or reinforcement-related processes is still insufficient. To further explore the effects induced by PPN stimulations and infer the potential mechanism underlying its role involved in both motor and emotional regulation, we developed a fully automated, low-cost system combining real-time animal tracking with closed-loop optogenetic stimulation, using the OpenMV Cam H7 Plus and embedded neural network models. The system autonomously detects the rat's position and triggers optical stimulation upon entry into a predefined region of interest, enabling unbiased, unsupervised behavioral assays. Optogenetic activation of CaMKIIa-expressing neurons in the rostral PPN reliably induced transient motor arrest. When motor arrest was spatially paired with a defined region of interest, rats developed a robust place preference after limited training. These results suggest that rostral PPN activation can couple motor inhibition with reinforcement-related behavioral circuitry. Together, our work provides both a technical framework for scalable closed-loop neuroscience experiments and preliminary evidence that the rostral PPN may participate in coordinating motor suppression with motivational processes.",
      "author": "Guanghui Li, Xingfei Hou, Zhenxiang Zhao",
      "published_date": "2026-01-26T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 218,
      "reading_time": 1,
      "created_at": "2026-01-26T05:09:15.507432+00:00",
      "updated_at": "2026-01-26T05:09:15.507433+00:00"
    },
    {
      "id": "01f9249abfe6bc84ad3f1469b7486740",
      "url": "https://arxiv.org/abs/2507.13638",
      "title": "State Space Models Naturally Produce Time Cell and Oscillatory Behaviors and Scale to Abstract Cognitive Functions",
      "content": "arXiv:2507.13638v2 Announce Type: replace \nAbstract: A grand challenge in modern neuroscience is to bridge the gap between the detailed mapping of microscale neural circuits and mechanistic understanding of cognitive functions. While extensive knowledge exists about neuronal connectivity and biophysics, how these low-level phenomena eventually produce abstract behaviors remains largely unresolved. Here, we propose that a framework based on State Space Models, an emerging class of deep learning architectures, can help bridge this gap. We suggest that the differential equations governing elements in a State Space Model are conceptually consistent with the dynamics of biophysical processes, while the model offers a scalable framework to build on the dynamics to produce emergent behaviors observed in experimental neuroscience. We test this framework by training a model employing a diagonal state transition matrix on temporal discrimination tasks with reinforcement learning. Our results suggest that neural behaviors such as time cells naturally emerge from two fundamental principles: optimal pre-configuration and rotational dynamics. These features are shown mathematically to optimize history compression, and naturally generate structured temporal dynamics even prior to training, mirroring recent findings in biological circuits. We show that learning acts primarily as a selection mechanism that fine-tunes these pre-configured oscillatory modes, rather than constructing temporal codes de novo. The model can be readily scaled to abstract cognitive functions such as event counting, supporting the use of State Space Models as a computationally tractable framework for understanding neural activities.",
      "author": "Sen Lu, Xiaoyu Zhang, Mingtao Hu, Eric Yeu-Jer Lee, Soohyeon Kim, Wei D. Lu",
      "published_date": "2026-01-26T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 235,
      "reading_time": 1,
      "created_at": "2026-01-26T05:09:15.507398+00:00",
      "updated_at": "2026-01-26T05:09:15.507400+00:00"
    },
    {
      "id": "40b174c94ba7091dbdaf5ec31aaba64a",
      "url": "https://arxiv.org/abs/2309.15566",
      "title": "Simultaneity of consciousness with physical reality: the key that unlocks the mind-matter problem",
      "content": "arXiv:2309.15566v2 Announce Type: replace \nAbstract: The problem of explaining the relationship between subjective experience and physical reality remains difficult and unresolved. In most explanations, consciousness is epiphenomenal, without causal power. The most notable exception is Integrated Information Theory (IIT), which provides a causal explanation for consciousness. However, IIT relies on an identity between subjectivity and a particular type of physical structure, namely with an information structure that has intrinsic causal power greater than the sum of its parts. Any theory that relies on a psycho-physical identity must eventually appeal to panpsychism, which undermines that theorys claim to be fundamental. IIT has recently pivoted towards a strong version of causal emergence, but macroscopic causal structures cannot be causally stronger than its microscopic parts without some new physical law or governing principle. The approach taken here is designed to uncover such a principle. The decisive argument is entirely deductive from initial premises that are phenomenologically certain. If correct, the arguments prove that conscious experience is sufficient to create additional degrees of causal freedom independently of the content of experience, and in a manner that is unpredictable and unobservable by any temporally sequential means. This provides a fundamental principle about consciousness, and a conceptual bridge between it and the physics describing what is experienced. The principle makes testable predictions about brain function, with notable differences from IIT, some of which are also empirically testable.",
      "author": "John Sanfey",
      "published_date": "2026-01-26T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 231,
      "reading_time": 1,
      "created_at": "2026-01-26T05:09:15.507363+00:00",
      "updated_at": "2026-01-26T05:09:15.507365+00:00"
    },
    {
      "id": "27b35524a016fbe4e9d5420ca7e1060e",
      "url": "https://arxiv.org/abs/2601.16378",
      "title": "Cognitively-Inspired Tokens Overcome Egocentric Bias in Multimodal Models",
      "content": "arXiv:2601.16378v1 Announce Type: cross \nAbstract: Multimodal language models (MLMs) perform well on semantic vision-language tasks but fail at spatial reasoning that requires adopting another agent's visual perspective. These errors reflect a persistent egocentric bias and raise questions about whether current models support allocentric reasoning. Inspired by human spatial cognition, we introduce perspective tokens, specialized embeddings that encode orientation through either (1) embodied body-keypoint cues or (2) abstract representations supporting mental rotation. Integrating these tokens into LLaVA-1.5-13B yields performance on level-2 visual perspective-taking tasks. Across synthetic and naturalistic benchmarks (Isle Bricks V2, COCO, 3DSRBench), perspective tokens improve accuracy, with rotation-based tokens generalizing to non-human reference agents. Representational analyses reveal that fine-tuning enhances latent orientation sensitivity already present in the base model, suggesting that MLMs contain precursors of allocentric reasoning but lack appropriate internal structure. Overall, embedding cognitively grounded spatial structure directly into token space provides a lightweight, model-agnostic mechanism for perspective-taking and more human-like spatial reasoning.",
      "author": "Bridget Leonard, Scott O. Murray",
      "published_date": "2026-01-26T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 155,
      "reading_time": 1,
      "created_at": "2026-01-26T05:09:15.507322+00:00",
      "updated_at": "2026-01-26T05:09:15.507324+00:00"
    }
  ]
}