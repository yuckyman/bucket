{
  "last_updated": "2025-10-10T16:25:26.135988+00:00",
  "count": 20,
  "articles": [
    {
      "id": "1afc4c4e54184a244c216bb5b044f863",
      "url": "https://www.embs.org/blog-post/change-foi-for-ieee-embs/#new_tab",
      "title": "Notice to IEEE EMBS Members: Change to Field of Interest",
      "content": "<p>The post <a href=\"https://www.embs.org/blog-post/change-foi-for-ieee-embs/#new_tab\">Notice to IEEE EMBS Members: Change to Field of Interest</a> appeared first on <a href=\"https://www.embs.org\">IEEE EMBS</a>.</p>",
      "author": "Nancy Zimmerman",
      "published_date": "2025-04-27T21:46:11+00:00",
      "source": "Embs",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 19,
      "reading_time": 1,
      "created_at": "2025-10-10T16:25:07.222823+00:00",
      "updated_at": "2025-10-10T16:25:07.222825+00:00"
    },
    {
      "id": "5d49304b30e3f1cca1ea313fc654375e",
      "url": "https://www.embs.org/uncategorized/call-for-adcom-nominations/",
      "title": "Open Call for AdCom Nominations",
      "content": "<p>The post <a href=\"https://www.embs.org/uncategorized/call-for-adcom-nominations/\">Open Call for AdCom Nominations</a> appeared first on <a href=\"https://www.embs.org\">IEEE EMBS</a>.</p>",
      "author": "Nancy Zimmerman",
      "published_date": "2025-05-02T17:09:21+00:00",
      "source": "Embs",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 14,
      "reading_time": 1,
      "created_at": "2025-10-10T16:25:07.222802+00:00",
      "updated_at": "2025-10-10T16:25:07.222804+00:00"
    },
    {
      "id": "3727d0ebc34094cb889f4f09a3e22f0e",
      "url": "https://www.embs.org/press/embc-eic-sunghoon-ivan-lee/",
      "title": "IEEE EMBS Appoints Sunghoon \u201cIvan\u201d Lee, Ph.D., as Editor-in-Chief of EMBC Proceedings, the Leading Biomedical Engineering Conference Publication",
      "content": "<p>(Piscataway, N.J., August 12, 2025) Sunghoon \u201cIvan\u201d Lee, Ph.D., a Donna M. and Robert J. Manning Faculty Fellow and an Associate Professor of computer science, electrical and computer engineering, and&#8230; <a class=\"continue\" href=\"https://www.embs.org/press/embc-eic-sunghoon-ivan-lee/\">Continue Reading<span> IEEE EMBS Appoints Sunghoon \u201cIvan\u201d Lee, Ph.D., as Editor-in-Chief of EMBC Proceedings, the Leading Biomedical Engineering Conference Publication</span></a></p>\n<p>The post <a href=\"https://www.embs.org/press/embc-eic-sunghoon-ivan-lee/\">IEEE EMBS Appoints Sunghoon \u201cIvan\u201d Lee, Ph.D., as Editor-in-Chief of EMBC Proceedings, the Leading Biomedical Engineering Conference Publication</a> appeared first on <a href=\"https://www.embs.org\">IEEE EMBS</a>.</p>",
      "author": "Nancy Zimmerman",
      "published_date": "2025-08-19T14:41:24+00:00",
      "source": "Embs",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 79,
      "reading_time": 1,
      "created_at": "2025-10-10T16:25:07.222781+00:00",
      "updated_at": "2025-10-10T16:25:07.222783+00:00"
    },
    {
      "id": "549175845c3e5a33324ec1d03a43ab51",
      "url": "https://arxiv.org/abs/2510.08104",
      "title": "Development of Mental Models in Human-AI Collaboration: A Conceptual Framework",
      "content": "arXiv:2510.08104v1 Announce Type: new \nAbstract: Artificial intelligence has become integral to organizational decision-making and while research has explored many facets of this human-AI collaboration, the focus has mainly been on designing the AI agent(s) and the way the collaboration is set up - generally assuming a human decision-maker to be \"fixed\". However, it has largely been neglected that decision-makers' mental models evolve through their continuous interaction with AI systems. This paper addresses this gap by conceptualizing how the design of human-AI collaboration influences the development of three complementary and interdependent mental models necessary for this collaboration. We develop an integrated socio-technical framework that identifies the mechanisms driving the mental model evolution: data contextualization, reasoning transparency, and performance feedback. Our work advances human-AI collaboration literature through three key contributions: introducing three distinct mental models (domain, information processing, complementarity-awareness); recognizing the dynamic nature of mental models; and establishing mechanisms that guide the purposeful design of effective human-AI collaboration.",
      "author": "Joshua Holstein, Gerhard Satzger",
      "published_date": "2025-10-10T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 156,
      "reading_time": 1,
      "created_at": "2025-10-10T16:25:05.808319+00:00",
      "updated_at": "2025-10-10T16:25:05.808321+00:00"
    },
    {
      "id": "861cb2481303e2f9c4c998a2aaf920b7",
      "url": "https://arxiv.org/abs/2510.07987",
      "title": "Quantifying Locomotion Differences Between Virtual Reality Users With and Without Motor Impairments",
      "content": "arXiv:2510.07987v1 Announce Type: new \nAbstract: Today's virtual reality (VR) systems and environments assume that users have typical abilities, which can make VR inaccessible to people with physical impairments. However, there is not yet an understanding of how inaccessible locomotion techniques are, and which interactions make them inaccessible. To this end, we conducted a study in which people with and without upper-body impairments navigated a virtual environment with six locomotion techniques to quantify performance differences among groups. We found that groups performed similarly with Sliding Looking on all performance measures, suggesting that this might be a good default locomotion technique for VR apps. To understand the nature of performance differences with the other techniques, we collected low-level interaction data from the controllers and headset and analyzed interaction differences with a set of movement-, button-, and target-related metrics. We found that movement-related metrics from headset data reveal differences among groups with all techniques, suggesting these are good metrics for identifying whether a user has an upper-body impairment. We also identify movement-, button, and target- related metrics that can explain performance differences between groups for particular locomotion techniques.",
      "author": "Rachel L. Franz, Jacob O. Wobbrock",
      "published_date": "2025-10-10T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 185,
      "reading_time": 1,
      "created_at": "2025-10-10T16:25:05.808284+00:00",
      "updated_at": "2025-10-10T16:25:05.808286+00:00"
    },
    {
      "id": "bc92261b448981f22adaab2651955f07",
      "url": "https://arxiv.org/abs/2510.07967",
      "title": "Pre/Absence: Prompting Cultural Awareness and Understanding for Lost Architectural Heritage in Virtual Reality",
      "content": "arXiv:2510.07967v1 Announce Type: new \nAbstract: Lost architectural heritage presents interpretive challenges due to vanished structures and fragmented historical records. Using Hanyuan Hall of the Tang dynasty's Daming Palace as a case study, we conducted a formative investigation with archaeologists, heritage administrators, and visitors to identify key issues in current interpretation practices. We found that these practices often compress complex cultural layers into factual summaries and rely on linear narratives that overlook the continuing reinterpretations following a site's disappearance. In response, we designed Pre/Absence, a virtual reality experience grounded in the presence-absence dialectic to interweave tangible and vanished aspects of heritage within a spatiotemporal narrative. A mixed-method study with 28 participants compared Pre/Absence to a paper-based experience. Both improved users' factual understanding, but the VR experience more strongly enhanced cultural awareness, evoked emotional engagement with loss, and encouraged critical reflection on the evolving social and political meanings of heritage. The findings suggest that VR can move beyond static reconstruction to engage users as co-constructors of cultural meaning, providing a nuanced framework for critical heritage narrative design in human-computer interaction.",
      "author": "Yaning Li, Ke Zhao, Shucheng Zheng, Xingyu Chen, Chenyi Chen, Wenxi Dai, Weile Jiang, Qi Dong, Yiqing Zhao, Meng Li, Lin-Ping Yuan",
      "published_date": "2025-10-10T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 178,
      "reading_time": 1,
      "created_at": "2025-10-10T16:25:05.808254+00:00",
      "updated_at": "2025-10-10T16:25:05.808255+00:00"
    },
    {
      "id": "6835349f348bec1ac060b82a8148764c",
      "url": "https://arxiv.org/abs/2510.07960",
      "title": "A Systematic Evaluation of Self-Supervised Learning for Label-Efficient Sleep Staging with Wearable EEG",
      "content": "arXiv:2510.07960v1 Announce Type: new \nAbstract: Wearable EEG devices have emerged as a promising alternative to polysomnography (PSG). As affordable and scalable solutions, their widespread adoption results in the collection of massive volumes of unlabeled data that cannot be analyzed by clinicians at scale. Meanwhile, the recent success of deep learning for sleep scoring has relied on large annotated datasets. Self-supervised learning (SSL) offers an opportunity to bridge this gap, leveraging unlabeled signals to address label scarcity and reduce annotation effort. In this paper, we present the first systematic evaluation of SSL for sleep staging using wearable EEG. We investigate a range of well-established SSL methods and evaluate them on two sleep databases acquired with the Ikon Sleep wearable EEG headband: BOAS, a high-quality benchmark containing PSG and wearable EEG recordings with consensus labels, and HOGAR, a large collection of home-based, self-recorded, and unlabeled recordings. Three evaluation scenarios are defined to study label efficiency, representation quality, and cross-dataset generalization. Results show that SSL consistently improves classification performance by up to 10% over supervised baselines, with gains particularly evident when labeled data is scarce. SSL achieves clinical-grade accuracy above 80% leveraging only 5% to 10% of labeled data, while the supervised approach requires twice the labels. Additionally, SSL representations prove robust to variations in population characteristics, recording environments, and signal quality. Our findings demonstrate the potential of SSL to enable label-efficient sleep staging with wearable EEG, reducing reliance on manual annotations and advancing the development of affordable sleep monitoring systems.",
      "author": "Emilio Estevan, Mar\\'ia Sierra-Torralba, Eduardo L\\'opez-Larraz, Luis Montesano",
      "published_date": "2025-10-10T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 248,
      "reading_time": 1,
      "created_at": "2025-10-10T16:25:05.808223+00:00",
      "updated_at": "2025-10-10T16:25:05.808224+00:00"
    },
    {
      "id": "cd326e608ffe5456dd923dd19e94657d",
      "url": "https://arxiv.org/abs/2510.07829",
      "title": "The Rise of the Knowledge Sculptor: A New Archetype for Knowledge Work in the Age of Generative AI",
      "content": "arXiv:2510.07829v1 Announce Type: new \nAbstract: In the Generative Age, the nature of knowledge work is transforming. Traditional models that emphasise the organisation and retrieval of pre-existing information are increasingly inadequate in the face of generative AI (GenAI) systems capable of autonomous content creation. This paper introduces the Knowledge Sculptor (KS), a new professional archetype for Human-GenAI collaboration that transforms raw AI output into trustworthy, actionable knowledge. Grounded in a socio-technical perspective, the KS is conceptualised through a framework of competencies, including architecting a vision, iterative dialogue, information sculpting, and curiosity-driven synthesis. A practice-based vignette illustrates the KS role in action, and in a self-referential approach, the paper itself serves as an artefact of the sculpting process it describes.",
      "author": "Cathal Doyle",
      "published_date": "2025-10-10T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 118,
      "reading_time": 1,
      "created_at": "2025-10-10T16:25:05.808186+00:00",
      "updated_at": "2025-10-10T16:25:05.808188+00:00"
    },
    {
      "id": "17535effb200f0c4b4d17c5e1fedf587",
      "url": "https://arxiv.org/abs/2510.07754",
      "title": "Human-in-the-Loop Optimization with Model-Informed Priors",
      "content": "arXiv:2510.07754v1 Announce Type: new \nAbstract: Human-in-the-loop optimization identifies optimal interface designs by iteratively observing user performance. However, it often requires numerous iterations due to the lack of prior information. While recent approaches have accelerated this process by leveraging previous optimization data, collecting user data remains costly and often impractical. We present a conceptual framework, Human-in-the-Loop Optimization with Model-Informed Priors (HOMI), which augments human-in-the-loop optimization with a training phase where the optimizer learns adaptation strategies from diverse, synthetic user data generated with predictive models before deployment. To realize HOMI, we introduce Neural Acquisition Function+ (NAF+), a Bayesian optimization method featuring a neural acquisition function trained with reinforcement learning. NAF+ learns optimization strategies from large-scale synthetic data, improving efficiency in real-time optimization with users. We evaluate HOMI and NAF+ with mid-air keyboard optimization, a representative VR input task. Our work presents a new approach for more efficient interface adaptation by bridging in situ and in silico optimization processes.",
      "author": "Yi-Chi Liao, Jo\\~ao Belo, Hee-Seung Moon, J\\\"urgen Steimle, Anna Maria Feit",
      "published_date": "2025-10-10T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 156,
      "reading_time": 1,
      "created_at": "2025-10-10T16:25:05.808159+00:00",
      "updated_at": "2025-10-10T16:25:05.808161+00:00"
    },
    {
      "id": "2acb51e56a4a01d13ed9d536ffeb7991",
      "url": "https://arxiv.org/abs/2510.07610",
      "title": "The Slow Space Editor : Broadening Access to Restorative XR",
      "content": "arXiv:2510.07610v1 Announce Type: new \nAbstract: The Slow Space Editor is a 2D tool for creating 3D spaces. It was built as part of a research-through-design project that investigates how Virtual and Mixed Reality (XR) environments might be used for reflection and attention restoration. In this phase, we seek to radically simplify the creation of virtual environments, thereby broadening the potential group of users who could benefit from them. The research described in this paper has three aspects. First, we define the concept of \"slow space,\" situating it alongside existing research in HCI and environmental psychology. Second, we report on a series of interviews with professional designers about how slow spaces are created in the physical world. Third, we share the design of the tool itself, focussing on the benefits of providing a simple method for users to control their environments. We conclude with our findings from a 19-person qualitative study of the tool.",
      "author": "Nate Laffan, Ashley Hom, Andrea Nadine Castillo, Elizabeth Gitelman, Rebecca Zhao, Nikita Shenoy, Kaia Rae Schweig, Katherine Isbister",
      "published_date": "2025-10-10T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 153,
      "reading_time": 1,
      "created_at": "2025-10-10T16:25:05.808128+00:00",
      "updated_at": "2025-10-10T16:25:05.808130+00:00"
    },
    {
      "id": "fe99a45b70d7a40d3ee7b41761213248",
      "url": "https://arxiv.org/abs/2510.07609",
      "title": "IGUANA: Immersive Guidance, Navigation, and Control for Consumer UAV",
      "content": "arXiv:2510.07609v1 Announce Type: new \nAbstract: As the markets for unmanned aerial vehicles (UAVs) and mixed reality (MR) headsets continue to grow, recent research has increasingly explored their integration, which enables more intuitive, immersive, and situationally aware control systems. We present IGUANA, an MR-based immersive guidance, navigation, and control system for consumer UAVs. IGUANA introduces three key elements beyond conventional control interfaces: (1) a 3D terrain map interface with draggable waypoint markers and live camera preview for high-level control, (2) a novel spatial control metaphor that uses a virtual ball as a physical analogy for low-level control, and (3) a spatial overlay that helps track the UAV when it is not visible with the naked eye or visual line of sight is interrupted. We conducted a user study to evaluate our design, both quantitatively and qualitatively, and found that (1) the 3D map interface is intuitive and easy to use, relieving users from manual control and suggesting improved accuracy and consistency with lower perceived workload relative to conventional dual-stick controller, (2) the virtual ball interface is intuitive but limited by the lack of physical feedback, and (3) the spatial overlay is very useful in enhancing the users' situational awareness.",
      "author": "Victor Victor, Tania Krisanty, Matthew McGinity, Stefan Gumhold, Uwe A{\\ss}mann",
      "published_date": "2025-10-10T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 198,
      "reading_time": 1,
      "created_at": "2025-10-10T16:25:05.808096+00:00",
      "updated_at": "2025-10-10T16:25:05.808098+00:00"
    },
    {
      "id": "8e9e179fb464c187a7ee4bbba1d6964c",
      "url": "https://arxiv.org/abs/2510.07322",
      "title": "A LoRa IoT Framework with Machine Learning for Remote Livestock Monitoring in Smart Agriculture",
      "content": "arXiv:2510.07322v1 Announce Type: new \nAbstract: This work presents AgroTrack, a LoRa-based IoT framework for remote livestock monitoring in smart agriculture. The system is designed for low-power, long-range communication and supports real-time tracking and basic health assessment of free-range livestock through GPS, motion, and temperature sensors integrated into wearable collars. Data is collected and transmitted via LoRa to gateways and forwarded to a cloud platform for visualization, alerts, and analytics. To enhance its practical deployment, AgroTrack incorporates advanced analytics, including machine learning models for predictive health alerts and behavioral anomaly detection. This integration transforms the framework from a basic monitoring tool into an intelligent decision-support system, enabling farmers to improve livestock management, operational efficiency, and sustainability in rural environments.",
      "author": "Hitesh Mohapatra",
      "published_date": "2025-10-10T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 118,
      "reading_time": 1,
      "created_at": "2025-10-10T16:25:05.808045+00:00",
      "updated_at": "2025-10-10T16:25:05.808047+00:00"
    },
    {
      "id": "8aef26e3def5420d229cd626051a6e75",
      "url": "https://arxiv.org/abs/2510.07321",
      "title": "How human is the machine? Evidence from 66,000 Conversations with Large Language Models",
      "content": "arXiv:2510.07321v1 Announce Type: new \nAbstract: When Artificial Intelligence (AI) is used to replace consumers (e.g., synthetic data), it is often assumed that AI emulates established consumers, and more generally human behaviors. Ten experiments with Large Language Models (LLMs) investigate if this is true in the domain of well-documented biases and heuristics. Across studies we observe four distinct types of deviations from human-like behavior. First, in some cases, LLMs reduce or correct biases observed in humans. Second, in other cases, LLMs amplify these same biases. Third, and perhaps most intriguingly, LLMs sometimes exhibit biases opposite to those found in humans. Fourth, LLMs' responses to the same (or similar) prompts tend to be inconsistent (a) within the same model after a time delay, (b) across models, and (c) among independent research studies. Such inconsistencies can be uncharacteristic of humans and suggest that, at least at one point, LLMs' responses differed from humans. Overall, unhuman-like responses are problematic when LLMs are used to mimic or predict consumer behavior. These findings complement research on synthetic consumer data by showing that sources of bias are not necessarily human-centric. They also contribute to the debate about the tasks for which consumers, and more generally humans, can be replaced by AI.",
      "author": "Antonios Stamatogiannakis, Arsham Ghodsinia, Sepehr Etminanrad, Dilney Gon\\c{c}alves, David Santos",
      "published_date": "2025-10-10T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 204,
      "reading_time": 1,
      "created_at": "2025-10-10T16:25:05.808009+00:00",
      "updated_at": "2025-10-10T16:25:05.808014+00:00"
    },
    {
      "id": "ff9f7d97218d63dfc4876538f55ebe5b",
      "url": "https://arxiv.org/abs/2205.10723",
      "title": "Stochastic Models of Neuronal Growth",
      "content": "arXiv:2205.10723v2 Announce Type: replace-cross \nAbstract: Neuronal circuits arise as axons and dendrites extend, navigate, and connect to target cells. Axonal growth, in particular, integrates deterministic guidance from substrate mechanics and geometry with stochastic fluctuations generated by signaling, molecular detection, cytoskeletal assembly, and growth cone dynamics. A comprehensive quantitative description of this process remains incomplete. We review stochastic models in which Langevin dynamics and the associates Fokker-Planck equation capture axonal motion and turning under combined biases and noise. Paired with experiments, these models yield key parameters, including effective diffusion (motility) coefficients, speed and angle distributions, mean-square displacement, and mechanical measures of cell-substrate coupling, thereby linking single-cell biophysics and intercellular interactions to collective growth statistics and network formation. We further couple the Fokker-Planck description to a mechanochemical actin-myosin-clutch model and perform a linear stability analysis of the resulting dynamics. Routh--Hurwitz criteria identify regimes of steady extension, damped oscillations, and Hopf bifurcations that generate sustained limit cycles. Together, these results clarify the mechanisms that govern axonal guidance and connectivity and inform the design of engineered substrates and neuroprosthetic scaffolds aimed at enhancing nerve repair and regeneration.",
      "author": "Cristian Staii",
      "published_date": "2025-10-10T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 183,
      "reading_time": 1,
      "created_at": "2025-10-10T16:25:04.718234+00:00",
      "updated_at": "2025-10-10T16:25:04.718236+00:00"
    },
    {
      "id": "3903706a5d25ebc1aa80360bf9a59f28",
      "url": "https://arxiv.org/abs/2509.23896",
      "title": "A Computational Perspective on NeuroAI and Synthetic Biological Intelligence",
      "content": "arXiv:2509.23896v2 Announce Type: replace \nAbstract: NeuroAI is an emerging field at the intersection of neuroscience and artificial intelligence, where insights from brain function guide the design of intelligent systems. A central area within this field is synthetic biological intelligence (SBI), which combines the adaptive learning properties of biological neural networks with engineered hardware and software. SBI systems provide a platform for modeling neural computation, developing biohybrid architectures, and enabling new forms of embodied intelligence. In this review, we organize the NeuroAI landscape into three interacting domains: hardware, software, and wetware. We outline computational frameworks that integrate biological and non-biological systems and highlight recent advances in organoid intelligence, neuromorphic computing, and neuro-symbolic learning. These developments collectively point toward a new class of systems that compute through interactions between living neural tissue and digital algorithms.",
      "author": "Dhruvik Patel, Md Sayed Tanveer, Jesus Gonzalez-Ferrer, Alon Loeffler, Brett J. Kagan, Mohammed A. Mostajo-Radji, Ge Wang",
      "published_date": "2025-10-10T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 133,
      "reading_time": 1,
      "created_at": "2025-10-10T16:25:04.718203+00:00",
      "updated_at": "2025-10-10T16:25:04.718204+00:00"
    },
    {
      "id": "549da4b14f3a4b20187dea9100776d3f",
      "url": "https://arxiv.org/abs/2505.08831",
      "title": "Neural encoding of real world face perception",
      "content": "arXiv:2505.08831v2 Announce Type: replace \nAbstract: Social perception unfolds as we freely interact with people around us. We investigated the neural basis of real world face perception using multi electrode intracranial recordings in humans during spontaneous interactions with friends, family, and others. Computational models reconstructed the faces participants looked at during natural interactions, including facial expressions and motion, from brain activity alone. The results highlighted a critical role for the social vision pathway, a network of areas spanning parietal, temporal, and occipital cortex. This network was more sharply tuned to subtle expressions compared to intense expressions, which was confirmed with controlled psychophysical experiments. These findings reveal that the human social vision pathway encodes facial expressions and motion as deviations from a neutral expression prototype during natural social interactions in real life.",
      "author": "Arish Alreja, Michael J. Ward, Lisa S. Parker, R. Mark Richardson, Louis-Philippe Morency, Taylor J. Abel, Avniel Singh Ghuman",
      "published_date": "2025-10-10T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 130,
      "reading_time": 1,
      "created_at": "2025-10-10T16:25:04.718175+00:00",
      "updated_at": "2025-10-10T16:25:04.718176+00:00"
    },
    {
      "id": "0ba61ce3a0e4a16ce84a9fde4107282c",
      "url": "https://arxiv.org/abs/2502.16456",
      "title": "Language learning shapes visual category-selectivity in deep neural networks",
      "content": "arXiv:2502.16456v2 Announce Type: replace \nAbstract: Category-selective regions in the human brain-such as the fusiform face area (FFA), extrastriate body area (EBA), parahippocampal place area (PPA), and visual word form area (VWFA)-support high-level visual recognition. Here, we investigate whether artificial neural networks (ANNs) exhibit analogous category-selective neurons and how these representations are shaped by language experience. Using an fMRI-inspired functional localizer approach, we identified face-, body-, place-, and word-selective neurons in deep networks presented with category images and scrambled controls. Both the purely visual ResNet and a linguistically supervised Lang-Learned ResNet contained category-selective neurons that increased in proportion across layers. However, compared to the vision-only model, the Lang-Learned ResNet showed a greater number but lower specificity of category-selective neurons, along with reduced spatial localization and attenuated activation strength-indicating a shift toward more distributed, semantically aligned coding. These effects were replicated in the large-scale vision-language model CLIP. Together, our findings reveal that language experience systematically reorganizes visual category representations in ANNs, providing a computational parallel to how linguistic context may shape categorical organization in the human brain.",
      "author": "Zitong Lu, Yuxin Wang",
      "published_date": "2025-10-10T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 175,
      "reading_time": 1,
      "created_at": "2025-10-10T16:25:04.718146+00:00",
      "updated_at": "2025-10-10T16:25:04.718148+00:00"
    },
    {
      "id": "fe760053d665b34a8da11992edac41b9",
      "url": "https://arxiv.org/abs/2510.08436",
      "title": "Spike-frequency and h-current based adaptation are dynamically equivalent in a Wilson-Cowan field model",
      "content": "arXiv:2510.08436v1 Announce Type: cross \nAbstract: During slow-wave sleep, the brain produces traveling waves of slow oscillations (SOs; $\\leq 2$ Hz), characterized by the propagation of alternating high- and low-activity states. The question of internal mechanisms that modulate traveling waves of SOs is still unanswered although it is established that it is an adaptation mechanism that mediates them. One mechanism investigated is spike-frequency adaptation, a hyperpolarizing feedback current that is activated during periods of high-activity. An alternative mechanism is based on hyperpolarization-activated currents, which are positive feedback currents that are activated in low-activity states. Both adaptation mechanisms were shown to feature SO-like dynamics in neuronal populations, and the inclusion of a spatial domain seems to enhance observable differences in their effects. To investigate this in detail, we examine a spatially extended two-population Wilson-Cowan model with local spatial coupling and the excitatory populations equipped with either one of the two adaptation mechanisms. We describe them with the same dynamical equation and include the inverse mode of action by changing the signs of adaptation strength and gain. We show that the dynamical systems are mathematically equivalent under a compensatory external input, which depends on the adaptation strength, leading to a shift in state space of the otherwise equivalent bifurcation structure. Strong enough adaptation is required to induce traveling waves. Additionally, adaptation modulates the properties of the spatio-temporal activity patterns, such as temporal and spatial frequencies, and the speed of the traveling waves, all of which increase with increasing strength. Though being dynamically equivalent, our results also explain why location-dependent variations in feedback strength cause differences in the propagation of traveling waves between both adaptation mechanisms.",
      "author": "Ronja Str\\\"omsd\\\"orfer, Klaus Obermayer",
      "published_date": "2025-10-10T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 272,
      "reading_time": 1,
      "created_at": "2025-10-10T16:25:04.718113+00:00",
      "updated_at": "2025-10-10T16:25:04.718115+00:00"
    },
    {
      "id": "15c034299ba08d9d63bbfa91c0e64709",
      "url": "https://arxiv.org/abs/2510.07415",
      "title": "Autoencoding Coordinate Sequences from Psychophysiologic Signals",
      "content": "arXiv:2510.07415v1 Announce Type: cross \nAbstract: We present a method for converting 24 channels of psychophysiologic time series data collected from individual participants via electroencephalogram (EEG), electrocardiogram (ECG), electrodermal activity (EDA), respiration rate (RR) into trackable three dimensional (3D) coordinates sufficient to estimate participation in specific task and cognitive states.",
      "author": "Timothy L. Hutcheson, Anil K. Raj",
      "published_date": "2025-10-10T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 49,
      "reading_time": 1,
      "created_at": "2025-10-10T16:25:04.718046+00:00",
      "updated_at": "2025-10-10T16:25:04.718047+00:00"
    },
    {
      "id": "a34ae947ceb624ab849a5d0ee716670a",
      "url": "https://arxiv.org/abs/2510.08082",
      "title": "Optimizing BCI Rehabilitation Protocols for Stroke: Exploring Task Design and Training Duration",
      "content": "arXiv:2510.08082v1 Announce Type: new \nAbstract: Stroke is a leading cause of long-term disability and the second most common cause of death worldwide. Although acute treatments have advanced, recovery remains challenging and limited. Brain-computer interfaces (BCIs) have emerged as a promising tool for post-stroke rehabilitation by promoting neuroplasticity. However, clinical outcomes remain variable, and optimal protocols have yet to be established. This study explores strategies to optimize BCI-based rehabilitation by comparing motor imagery of affected hand movement versus rest, instead of the conventional left-versus-right motor imagery. This alternative aims to simplify the task and address the weak contralateral activation commonly observed in stroke patients. Two datasets, one from healthy individuals and one from stroke patients, were used to evaluate the proposed approach. The results showed improved performance using both FBCSP and EEGNet. Additionally, we investigated the impact of session duration and found that shorter training sessions produced better BCI performance than longer sessions.",
      "author": "Aniana Cruz, Marko Kuzmanoski, Gabriel Pires",
      "published_date": "2025-10-10T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 152,
      "reading_time": 1,
      "created_at": "2025-10-10T16:25:04.718019+00:00",
      "updated_at": "2025-10-10T16:25:04.718021+00:00"
    }
  ]
}