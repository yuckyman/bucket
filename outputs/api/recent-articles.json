{
  "last_updated": "2025-09-30T07:41:08.437145+00:00",
  "count": 20,
  "articles": [
    {
      "id": "5cf06dd1c8477abb17ef4e5c3b5426e0",
      "url": "https://erpinfo.org/blog/2021/12/22/applications-2023",
      "title": "Applications now being accepted for UC-Davis/SDSU ERP Boot Camp, July 31 \u2013 August 9, 2023",
      "content": "<p class=\"\">The next 10-day ERP Boot Camp will be held July 31 \u2013 August 9, 2023 in San Diego, California. We are now taking applications, which will be due by April 1, 2023. <a href=\"https://erpinfo.org/summer-boot-camp\">Click here</a> for more information.</p><p class=\"\">We are currently planning to hold this workshop as an in-person event. However, these plans are subject to change as the COVID-19 pandemic evolves. If the event is held in person, we will require that everyone is fully vaccinated, and we will also implement any other safety measures that are warranted at the time of the workshop.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"980\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/1609175691205-RTD3XM69YGOFMVP23U6T/Boot_Camp_Logo.png?format=1000w\" width=\"1148\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>",
      "author": "Steve Luck",
      "published_date": "2023-01-16T18:31:57+00:00",
      "source": "Erp Boot Camp",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 108,
      "reading_time": 1,
      "created_at": "2025-09-30T07:41:00.705499+00:00",
      "updated_at": "2025-09-30T07:41:00.705500+00:00"
    },
    {
      "id": "bd7398ecbbd90ecd3269866b2fd3744f",
      "url": "https://erpinfo.org/blog/2023/6/23/decoding-webinar",
      "title": "ERP Decoding for Everyone: Software and Webinar",
      "content": "<p class=\"\"><strong>You can access the recording </strong><a href=\"https://video.ucdavis.edu/media/Virtual+ERP+Boot+CampA+Decoding+for+Everyone%2C+July+25+2023/1_lmwj6bu0\"><strong>here</strong></a><strong>.<br />You can access the final PDF of the slides </strong><a href=\"https://ucdavis.box.com/s/flf9gzeo12rz2jhxptih7xjl0omka2k7\"><strong>here</strong></a><strong>. <br />You can access the data </strong><a href=\"https://doi.org/10.18115/D5KS6S\"><strong>here</strong></a><strong>.</strong></p><p class=\"\">fMRI research has used decoding methods for over 20 years. These methods make it possible to decode what an individual is perceiving or holding in working memory on the basis of the pattern of BOLD activity across voxels. Remarkably, these methods can also be applied to ERP data, using the pattern of voltage across electrode sites rather than the pattern of activity across voxels to decode the information being represented by the brain (<a href=\"https://erpinfo.org/blog/2018/9/16/decoding\">see this previous blog post</a>). For example, ERPs can be used to decode the identity of a face that is being perceived, the emotional valence of a scene, the identity and semantic category of a word, and the features of an object that is being maintained in working memory. Moreover, decoding methods can be more sensitive than traditional methods for detecting conventional ERP effects (e.g., whether a word is semantically related or unrelated to a previous word in an N400 paradigm).</p><p class=\"\">So far, these methods have mainly been used by a small set of experts. We aim to change that with the upcoming Version 10 of <a href=\"https://erpinfo.org/erplab\">ERPLAB Toolbox</a>. This version of ERPLAB will contain an ERP decoding tool that makes it trivially easy for anyone who knows how to do conventional ERP processing to take advantage of the power of decoding. It should be available in mid-July at <a href=\"https://github.com/ucdavis/erplab/releases\">our GitHub site</a>. You can join the <a href=\"https://github.com/ucdavis/erplab/wiki/ERPLAB-email-list\">ERPLAB email list</a> to receive an announcement when this version is released. Please do not contact us with questions until it has been released and you have tried using it.</p><p class=\"\">On July 25, 2023, we will hold a 2-hour Zoom webinar to explain how decoding works at a conceptual level and show how to implement in ERPLAB Toolbox. The webinar will begin at 9:00 AM Pacific Time (California), 12:00 PM Eastern Time (New York), 5:00 PM British Summer Time (London), 6:00 PM Central European Summer Time (Berlin). </p><p class=\"\">The webinar is co-sponsored by the <a href=\"https://erpinfo.org/the-erp-boot-camp\">ERP Boot Camp</a> and the <a href=\"https://sprweb.org\">Society for Psychophysiological Research</a>. It is completely free, but you must register in advance at <a href=\"https://ucdavis.zoom.us/meeting/register/tJUrc-CtpzorEtBSmZXJINOlLJB9ZR0evpr4\">https://ucdavis.zoom.us/meeting/register/tJUrc-CtpzorEtBSmZXJINOlLJB9ZR0evpr4</a>. Once you register, you will receive an email with your own individual Zoom link. </p><p class=\"\">We will make a recording available a few days after the webinar on the <a href=\"https://erpinfo.org\">ERPinfo.org</a> web site.</p><p class=\"\">Please direct any questions about the webinar to <a href=\"mailto:erpbootcamp@gmail.com\">erpbootcamp@gmail.com</a>.</p>",
      "author": "Steve Luck",
      "published_date": "2023-06-23T21:05:26+00:00",
      "source": "Erp Boot Camp",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 420,
      "reading_time": 2,
      "created_at": "2025-09-30T07:41:00.705470+00:00",
      "updated_at": "2025-09-30T07:41:00.705471+00:00"
    },
    {
      "id": "3d370217cb4a351bb54e7854066e15c3",
      "url": "https://erpinfo.org/blog/2024/2/4/optimal-filters",
      "title": "New Papers: Optimal Filter Settings for ERP Research",
      "content": "<p class=\"\">Zhang, G., Garrett, D. R., &amp; Luck, S. J. (in press). Optimal filters for ERP research I: A general approach for selecting filter settings. <em>Psychophysiology</em>. <a href=\"https://doi.org/10.1111/psyp.14531\"><span>https://doi.org/10.1111/psyp.14531</span></a> [<a href=\"https://www.researchgate.net/publication/377773270_Optimal_filters_for_ERP_research_I_A_general_approach_for_selecting_filter_settings\"><span>preprint</span></a>]</p><p class=\"\">Zhang, G., Garrett, D. R., &amp; Luck, S. J. (in press). Optimal filters for ERP research II: Recommended settings for seven common ERP components. <em>Psychophysiology</em>. <a href=\"https://doi.org/10.1111/psyp.14530\"><span>https://doi.org/10.1111/psyp.14530</span></a> [<a href=\"https://www.researchgate.net/publication/377766656_Optimal_filters_for_ERP_research_II_Recommended_settings_for_seven_common_ERP_components\"><span>preprint</span></a>]</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1490\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/d64086cc-e3b4-457d-89df-08d9b3f96439/Filter_Table.png?format=1000w\" width=\"2062\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">What filter settings should you apply to your ERP data? If your filters are too weak to attenuate the noise in your data, your effects may not be statistically significant. If your filters are too strong, they may create artifactual peaks that lead you to draw bogus conclusions.</p><p class=\"\">For years, I have been recommending a bandpass of 0.1\u201330 Hz for most cognitive and affective research in neurotypical young adults. In this kind of research, I have found that filtering from 0.1\u201330 Hz usually does a good job of minimizing noise while creating minimal waveform distortion. </p><p class=\"\">However, this recommendation was based on a combination of informal observations from many experimental paradigms and a careful examination of a couple paradigms, so it was a bit hand-wavy. In addition, the optimal filter settings will depend on the waveshape of the ERP effects and the nature of the noise in a given study, so I couldn\u2019t make any specific recommendations about other experimental paradigms and participant populations. Moreover, different filter settings may be optimal for different scoring methods (e.g., mean amplitude vs. peak amplitude vs. peak latency).</p><p class=\"\">Guanghui Zhang, David Garrett, and I spent the last year focusing on this issue. First we developed a general method that can be used to determine the optimal filter settings for a given dataset and scoring method (see <a href=\"https://doi.org/10.1111/psyp.14531\"><span>this paper</span></a>). Then we applied this method to the <a href=\"https://doi.org/10.1016/j.neuroimage.2020.117465\"><span>ERP CORE</span></a> data to determine the optimal filter settings for the N170, MMN, P3b, N400, N2pc, LRP, and ERN components in neurotypical young adults (see <a href=\"https://doi.org/10.1111/psyp.14530\"><span>this paper</span></a> and the table above).</p><p class=\"\">If you are doing research with these components (or similar components) in neurotypical young adults, you can simply use the filter settings that we identified. If you are using a very different paradigm or testing a very different subject population, you can apply our method to your own data to find the optimal settings. We added some new tools to <a href=\"https://github.com/ucdavis/erplab\"><span>ERPLAB Toolbox</span></a> to make this easier.</p><p class=\"\">One thing that we discovered was that our old recommendation of 0.1\u201330 Hz does a good job of avoiding filter artifacts but is overly conservative for some components. For example, we can raise the low end to 0.5 Hz when measuring N2pc and MMN amplitudes, which gets rid of more noise without producing problematic waveform distortions. And we can go all the way up to 0.9 Hz for the N170 component. However, later/slower components like P3b and N400 require lower cutoffs (no higher than 0.2 Hz).</p><p class=\"\">You might be wondering how we defined the \u201coptimal\u201d filter settings. At one level, the answer is simple: The optimal filter is the one that maximizes the signal-to-noise ratio without producing too much waveform distortion. The complexities arise in quantifying the signal-to-noise ratio, quantifying the waveform distortion, and deciding how much waveform distortion is \u201ctoo much\u201d. We believe we have found reasonably straightforward and practical solutions to these problems, which you can read about in the published papers.</p>",
      "author": "Steve Luck",
      "published_date": "2024-02-04T23:46:20+00:00",
      "source": "Erp Boot Camp",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 568,
      "reading_time": 2,
      "created_at": "2025-09-30T07:41:00.705422+00:00",
      "updated_at": "2025-09-30T07:41:00.705423+00:00"
    },
    {
      "id": "c2319578819743fdf0159bf723bcb1b5",
      "url": "https://erpinfo.org/blog/2024/3/5/changes-to-the-2024-erp-boot-camp",
      "title": "Important Changes to the 2024 ERP Boot Camp",
      "content": "<p class=\"\">We are disappointed to announce that we will not be holding a regular 10-day ERP Boot Camp this summer.</p><p class=\"\">We have held Boot Camps nearly every summer since 2007, supported by a series of generous grants from NIMH that allowed us to provide scholarships for all attendees. Unfortunately, although our recent renewal proposal received extremely positive reviews and scores, we were recently given the surprising and disappointing news that the renewal will not be funded this year. We believe that the ERP Boot Camp provides essential training to the field, and we will continue to pursue financial support to continue holding 10-day ERP Boot Camps in the future. </p><p class=\"\">In the meantime, we have partial funding that will allow us to hold a 5-day ERP Boot Camp this summer from July 8-12, 2024 in Davis, California. The workshop will include 5-days of lectures and activities on EEG and ERP measures, including practical and theoretical issues.</p><p class=\"\">Unfortunately, we will not be able to provide scholarships to pay for travel and lodging costs, and we must charge a registration fee. We are very sorry if this causes a hardship. </p><p class=\"\">We are no longer taking applications through our application portal. Instead of a competitive application process, we will simply accept the first 30 people who complete the registration process and pay the registration fee. This provides an opportunity to attend for individuals who might otherwise not make it through our ordinary application process, which is highly competitive. </p><p class=\"\">The registration fee will be $1000 (or $900 for people who register by April 15). The registration fee will cover 6 nights in a single occupancy hotel room (arriving July 7 and departing July 13), daily breakfast at the hotel, a catered lunch for each day of the workshop, and a group dinner. <strong>You must pay the registration fee with a credit card when you register.</strong> There are no exceptions to the registration fee policy.</p><p class=\"\"><strong>Registration is now open</strong> at <a href=\"https://na.eventscloud.com/793175\">https://na.eventscloud.com/793175</a>.</p><p class=\"\">Given that we will accept the first 30 registrants, we encourage you to register as soon as possible. <strong>Registration will close on May 20</strong>, but we anticipate that the workshop will be filled up long before then. </p><p class=\"\">You must pay for your own transportation to Davis. Davis is approximately 20 minutes away from the Sacramento Airport (SMF). You can take the <a href=\"https://www.davisairporter.com/\" target=\"_blank\">Davis Airporter</a> shuttle service or a rideshare service from SMF to Davis. If you are coming from outside North America, you may want to fly into the San Francisco airport (SFO), which is 135 km (84 miles) from Davis. We recommend taking the <a href=\"https://www.davisairporter.com/\" target=\"_blank\">Davis Airporter</a> from SFO to Davis.</p>",
      "author": "Steve Luck",
      "published_date": "2024-03-05T19:34:57+00:00",
      "source": "Erp Boot Camp",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 444,
      "reading_time": 2,
      "created_at": "2025-09-30T07:41:00.705355+00:00",
      "updated_at": "2025-09-30T07:41:00.705357+00:00"
    },
    {
      "id": "d1b3a64c1957f2b048e1e94f5d37c6e5",
      "url": "https://erpinfo.org/blog/2024/3/15/registration-full",
      "title": "Registration is now full for the 2024 ERP Boot Camp",
      "content": "<p class=\"\">The demand for the<a href=\"https://erpinfo.org/2024-erp-boot-camp\"> 2024 ERP Boot Camp</a> was far beyond our expectations, and we reached our maximum registration of 30 people within one day. We already have a waiting list of over 30 people, so we have closed the registration site.</p><p class=\"\">We realize that this is very disappointing to many people. We hope to offer another workshop like this next summer, or possibly earlier.</p><p class=\"\">If you would like to get announcements about upcoming boot camps and webinars, you should <a href=\"https://erpinfo.org/bootcamp-email-list\">join our email list</a>.</p><p class=\"\">You may also consider hosting a <a href=\"https://erpinfo.org/mini-erp-boot-camps\">Mini ERP Boot Camp</a> at your institution (in person or over Zoom).</p>",
      "author": "Steve Luck",
      "published_date": "2024-03-16T15:14:42+00:00",
      "source": "Erp Boot Camp",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 106,
      "reading_time": 1,
      "created_at": "2025-09-30T07:41:00.705306+00:00",
      "updated_at": "2025-09-30T07:41:00.705307+00:00"
    },
    {
      "id": "e1385798428586a67ced89a895faeb47",
      "url": "https://erpinfo.org/blog/2024/6/10/erp-core-decoding-paper",
      "title": "New Paper: Using Multivariate Pattern Analysis to Increase Effect Sizes for ERP Amplitude Comparisons",
      "content": "<p class=\"\">Carrasco, C. D., Bahle, B., Simmons, A. M., &amp; Luck, S. J. (2024). Using multivariate pattern analysis to increase effect sizes for event-related potential analyses. Psychophysiology, 61, e14570. <a href=\"https://doi.org/10.1111/psyp.14570\">https://doi.org/10.1111/psyp.14570</a> [<a href=\"https://doi.org/10.1101/2023.11.07.566051\">preprint</a>]</p><p class=\"\">Multivariate pattern analysis (MVPA) can be used to \u201cdecode\u201d subtle information from ERP signals, such as which of several faces a participant is perceiving or the orientation that someone is holding in working memory (see <a href=\"https://erpinfo.org/blog/2018/9/16/decoding\">this previous blog post</a>). This approach is so powerful that we started wondering whether it might also give us greater statistical power in more typical experiments where the goal is to determine whether an ERP component differs in amplitude across experimental conditions. For example, might we more easily be able to tell if N400 amplitude is different between two different classes of words by using decoding? If so, that might make it possible to detect effects that would otherwise be too small to be significant.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"688\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/08f353c7-f484-4e87-b5d3-a256fe1206e2/N170_ES.png?format=1000w\" width=\"971\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">To address this question, we compared decoding with the conventional ERP analysis approach with using the 6 experimental paradigms in the <a href=\"https://doi.org/10.18115/D5JW4R\">ERP CORE</a>. In the conventional ERP analysis, we measured the mean amplitude during the standard measurement window from each participant in the two conditions of the paradigm (e.g., faces versus cars for N170, deviants versus standards for MMN). We quantified the magnitude of the difference between conditions using Cohen\u2019s <em>dz</em> (the variant of Cohen\u2019s <em>d</em> corresponding to a paired <em>t</em> test). For example, the effect size in the conventional ERP comparison of faces versus cars in the N170 paradigm was approximately 1.7 (see the figure).</p><p class=\"\">We also applied decoding to each paradigm. For example, in the N170 paradigm, we trained a support vector machine (SVM) to distinguish between ERPs elicited by faces and ERPs elicited by cars. This was done separately for each subject, and we converted the decoding accuracy into Cohen\u2019s <em>dz</em> so that it could be compared with the <em>dz</em> from the conventional ERP analysis. As you can see from the bar labeled SVM in the figure above, the effect size for the SVM-based decoding analysis was almost twice as large as the effect size for the conventional ERP analysis. That\u2019s a huge difference!</p><p class=\"\">We found a similar benefit for SVM-based decoding over conventional ERP analyses in 7 of the 10 cases we tested (see the figure below). In the other 3 cases, the ERP and SVM effects were approximately equivalent. So, there doesn\u2019t seem to be a downside to using decoding, at least in terms of effect size. But there can be a big benefit.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1371\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/d16f0782-7205-4d50-95e1-c6729cbc153e/All_Components.png?format=1000w\" width=\"4641\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">Because decoding has many possible benefits, we\u2019ve added it into <a href=\"ERPLAB Toolbox\">ERPLAB Toolbox</a>. It\u2019s super easy to use, and we\u2019ve created <a href=\"https://erpinfo.org/blog/2023/6/23/decoding-webinar\">detailed documentation and a video</a> to explain how it works at a conceptual level and to show you how to use it.</p><p class=\"\">We encourage you to apply it to your own data. It may give you the power to detect effects that are too small to be detected with conventional ERP analyses.</p>",
      "author": "Steve Luck",
      "published_date": "2024-06-10T18:01:45+00:00",
      "source": "Erp Boot Camp",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 525,
      "reading_time": 2,
      "created_at": "2025-09-30T07:41:00.705278+00:00",
      "updated_at": "2025-09-30T07:41:00.705280+00:00"
    },
    {
      "id": "906f73f5c36ba087882a0ad17e01fc20",
      "url": "https://erpinfo.org/blog/2024/6/11/erplab-studio",
      "title": "New software package: ERPLAB Studio",
      "content": "<p class=\"\">We are excited to announce the release of a new EEG/ERP analysis package, <a href=\"https://github.com/ucdavis/erplab/releases\">ERPLAB Studio</a>. We think it\u2019s a huge improvement over the classic EEGLAB user interface. See our cheesy <a href=\"https://www.youtube.com/watch?v=lIaKVQ9DD6E\">\u201cadvertisement\u201d video</a> to get a quick overview. </p><p class=\"\">Rather than operating as an EEGLAB plugin, ERPLAB Studio is a standalone Matlab program that provides a more efficient and user-friendly interface to the most commonly used EEGLAB and ERPLAB routines.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1080\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/c874d4ec-5186-4de9-981b-58010c7a06e1/Interface.jpeg?format=1000w\" width=\"1920\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">With ERPLAB Studio, you automatically see the EEG or ERP waveforms as soon as you load a file. And as soon as you perform an operation, you see what the new EEG/ERP looks like. For example, when you filter the data, you immediately see the filtered waveforms.</p><p class=\"\">You can even select multiple datasets and apply an operation like artifact detection on all of them in one step. And then you can immediately see the results, such as which EEG epochs have been marked with artifacts.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1080\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/b45f514d-2d21-4a5a-8be6-f3a8ff99c388/Artifacts.jpeg?format=1000w\" width=\"1920\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">We give you access to EEGLAB\u2019s ICA-based artifact correction tools, but with a nice bonus. You can plot the ICA activations in the same window with the EEG data, making it easy to see which ICA components correspond to specific artifacts such as eyeblinks.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1080\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/8bc191da-9040-4042-ae9c-550cd98def7d/ICA.jpeg?format=1000w\" width=\"1920\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">The program has an EEG tab for processing continuous and epoched EEG data, and an ERP tab for processing averaged ERPs.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1080\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/84bdd9df-b02e-4fc5-83b9-1139a91938f5/Tabs.jpg?format=1000w\" width=\"1920\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">The automatic ERP plotting makes it easy for you to view the data laid out according to the electrode locations. And we have an Advanced Waveform Viewer that can make publication-quality plots.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1080\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/a932631f-fc30-415f-b11d-660d2bf90da5/ERP.jpeg?format=1000w\" width=\"1920\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">ERPLAB Studio is mainly just a new user interface. Under the hood, we\u2019re running the same EEGLAB and ERPLAB routines you\u2019ve always used. And scripting is identical.</p><p class=\"\">ERPLAB Studio is included in <a href=\"https://github.com/ucdavis/erplab/releases\">version 11 and higher of ERPLAB</a>. You simply follow our <a href=\"https://github.com/ucdavis/erplab/wiki/installation\">download/installation instructions</a> and then type estudio from the Matlab command line. </p><p class=\"\">If you\u2019re new to ERPLAB, we strongly recommend that you go through our <a href=\"https://github.com/ucdavis/erplab/wiki/ERPLAB-Studio-Tutorial\" target=\"_blank\">tutorial</a> before starting to process your own data. </p><p class=\"\">If you already know how to use the original version of ERPLAB (which we now call ERPLAB Classic), you can quickly learn how to use ERPLAB Studio with our <a href=\"https://ucdavis.box.com/s/i4jfv22gv6rj9t5obctuk6yaruxqomcc\">Transition Guide</a>.</p><p class=\"\">We also have a <a href=\"https://github.com/ucdavis/erplab/wiki/ERPLAB-Studio-Manual\">manual</a> that describes every feature in detail. </p>",
      "author": "Steve Luck",
      "published_date": "2024-06-12T02:02:16+00:00",
      "source": "Erp Boot Camp",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 444,
      "reading_time": 2,
      "created_at": "2025-09-30T07:41:00.705210+00:00",
      "updated_at": "2025-09-30T07:41:00.705212+00:00"
    },
    {
      "id": "b36c483362d8e2adfbd29771d0c72343",
      "url": "https://www.embs.org/awards/society-awards/#new_tab",
      "title": "Call for 2025 Society Awards Nominations",
      "content": "<p>The post <a href=\"https://www.embs.org/awards/society-awards/#new_tab\">Call for 2025 Society Awards Nominations</a> appeared first on <a href=\"https://www.embs.org\">IEEE EMBS</a>.</p>",
      "author": "Deidre Artis",
      "published_date": "2025-02-03T21:05:59+00:00",
      "source": "Embs",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 15,
      "reading_time": 1,
      "created_at": "2025-09-30T07:40:51.509579+00:00",
      "updated_at": "2025-09-30T07:40:51.509581+00:00"
    },
    {
      "id": "ad1925564c97f30cab5b55e76f20793b",
      "url": "https://www.embs.org/blog-post/regional-shifts-and-patterns/",
      "title": "Bridging Biotech: Regional shifts and patterns",
      "content": "<p>The post <a href=\"https://www.embs.org/blog-post/regional-shifts-and-patterns/\">Bridging Biotech: Regional shifts and patterns</a> appeared first on <a href=\"https://www.embs.org\">IEEE EMBS</a>.</p>",
      "author": "dziura",
      "published_date": "2025-02-05T15:45:50+00:00",
      "source": "Embs",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 15,
      "reading_time": 1,
      "created_at": "2025-09-30T07:40:51.509561+00:00",
      "updated_at": "2025-09-30T07:40:51.509562+00:00"
    },
    {
      "id": "138dbc20af95ce55414e7d62214f9607",
      "url": "https://www.embs.org/press/embc-eic-sunghoon-ivan-lee/#new_tab",
      "title": "Ivan Lee, Appointed Editor-in-Chief of EMBC Proceedings",
      "content": "<p>&#160;</p>\n<p>The post <a href=\"https://www.embs.org/press/embc-eic-sunghoon-ivan-lee/#new_tab\">Ivan Lee, Appointed Editor-in-Chief of EMBC Proceedings</a> appeared first on <a href=\"https://www.embs.org\">IEEE EMBS</a>.</p>",
      "author": "Nancy Zimmerman",
      "published_date": "2025-09-08T16:27:03+00:00",
      "source": "Embs",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 17,
      "reading_time": 1,
      "created_at": "2025-09-30T07:40:51.509384+00:00",
      "updated_at": "2025-09-30T07:40:51.509389+00:00"
    },
    {
      "id": "3709bb39f06490cfa8015ecb2a260cb6",
      "url": "https://www.frontiersin.org/articles/10.3389/fnhum.2025.1632265",
      "title": "Sensorimotor mismatch disrupts motor automaticity and increases anxiety during a goal-directed balance task",
      "content": "IntroductionSensorimotor integration is crucial role for goal-directed tasks, with sensorimotor mismatch impairing movement execution and potentially evoking anxiety. However, the relationship between mismatch-induced anxiety, movement precision, and automaticity remains unexplored. This study investigated the effect of sensorimotor mismatch on voluntary postural control during goal-directed tasks and the relationship between sensorimotor mismatch-induced anxiety and motor performance.MethodsTwenty-three young, injury-free adults performed a precision task requiring center of pressure (COP) control within a limited screen area under congruent (aligned visual inputs and motor outputs) and incongruent (180-degree mismatch between visual feedback and motor actions) conditions. Self-reported anxiety was assessed using a seven-point Likert scale. Motor performance was quantified using COP area, total path length and sample entropy of COP trajectory for movement precision and automaticity.ResultsSensorimotor mismatch significantly increased self-reported anxiety (p = 0.02) and reduced movement automaticity, evidenced by lower sample entropy values (p < 0.01). Higher anxiety scores were correlated with decreased movement automaticity in the medio-lateral direction (lower sample entropy) under the mismatch condition (r = \u22120.33, p = 0.008).DiscussionThese findings suggest that sensorimotor mismatch induces self-perceived anxiety and disrupts automatic motor control processes.",
      "author": "Jian Wang",
      "published_date": "2025-09-25T00:00:00+00:00",
      "source": "Frontiers Human Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 183,
      "reading_time": 1,
      "created_at": "2025-09-30T07:40:29.568846+00:00",
      "updated_at": "2025-09-30T07:40:29.568848+00:00"
    },
    {
      "id": "8b8d34ec2b751eb299bb9a3845601b7e",
      "url": "https://www.frontiersin.org/articles/10.3389/fnhum.2025.1557739",
      "title": "Association between neuroticism and physical activity: a systematic review and meta-analysis",
      "content": "BackgroundPhysical activity has been shown to be associated with neuroticism, a personality trait reflecting emotional instability and a tendency toward negative emotions. Understanding this relationship is crucial for developing effective mental health interventions. However, the underlying mechanisms and the strength of this association remain insufficiently understood.ObjectiveThis systematic review and meta-analysis aims to examine the current research on the relationship between neuroticism and physical activity, analyze their correlations and moderating factors, and investigate the potential bidirectional mechanisms linking these two factors.MethodsFollowing the PRISMA guidelines, we conducted a comprehensive search of Web of Science, PubMed, ProQuest, Scopus, and EBSCOhost for studies published between January 2000 and November 2024. We included English-language studies across all age groups that employed cross-sectional, longitudinal, or cohort designs. Studies focusing on special populations, non-peer-reviewed works, samples with fewer than 50 participants, non-empirical studies, and reviews were excluded. Data extraction was performed using standardized forms, and a meta-analysis was conducted in Stata 18 to assess heterogeneity and publication bias.ResultsAfter screening, 25 studies were included, comprising 15 Pearson correlation analyses and 12 multiple regression analyses. The meta-analysis revealed a significant negative correlation between physical activity and neuroticism, with an average correlation coefficient r = \u22120.141. This suggests that higher levels of physical activity are associated with lower levels of neuroticism. Specifically, the average standardized coefficient \u03b2 for neuroticism inhibiting physical activity was \u22120.150, indicating that for every one standard deviation increase in neuroticism, physical activity decreases by approximately 0.150 standard deviation units. Conversely, the average standardized coefficient \u03b2 for physical activity affecting neuroticism was \u22120.113, suggesting a potential reduction in neuroticism with increased physical activity, although this effect was not statistically significant across the limited number of studies.ConclusionOur findings confirm a significant negative association between physical activity and neuroticism, highlighting the potential of physical activity as a strategy for improving mental health. However, establishing causality requires further verification through longitudinal and experimental designs. The results emphasize the need for personalized interventions targeting individuals with high neuroticism. Future research should prioritize diverse cultural samples, standardized measurement protocols, and mechanistic investigations of this bidirectional relationship to better understand the underlying processes and develop effective interventions.Systematic review registrationhttps://www.crd.york.ac.uk/PROSPERO/view/CRD420251051360, identifier: CRD420251051360.",
      "author": "Wenxue Ma",
      "published_date": "2025-09-25T00:00:00+00:00",
      "source": "Frontiers Human Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 358,
      "reading_time": 1,
      "created_at": "2025-09-30T07:40:29.568776+00:00",
      "updated_at": "2025-09-30T07:40:29.568778+00:00"
    },
    {
      "id": "e1d207683d596cab59a8f9b8472881f5",
      "url": "https://www.frontiersin.org/articles/10.3389/fnhum.2025.1648245",
      "title": "Comparison of the reticulospinal drive to lumbar erector spinae muscles in postural and voluntary tasks using the StartReact paradigm",
      "content": "IntroductionWhile lesion and neurophysiological animal studies point toward a notable involvement of subcortical pathways in the control of low back muscles, little attention has been dedicated to the subject in humans. The StartReact paradigm may allow to indirectly test the potential contribution of the reticulospinal system during motor control, thus addressing this gap of knowledge. In this study, we aimed to compare the potential contribution of the reticulospinal system in the control of low back muscles during voluntary (lumbar spine extension) and postural (upper limb movement eliciting anticipatory postural adjustment) tasks using the StartReact paradigm.MethodsThe reaction time (RT) of the lumbar erector spinae was measured within a simple precued RT task while conditioned by startling (SAS\u2014116\u202fdB) or non-startling (NSAS\u201480\u202fdB) acoustic stimuli.ResultsThe reduction in RT was similar during the postural and voluntary tasks. However, RT was more shortened with the SAS condition compared to the NSAS condition in both tasks. This finding was replicated using a cumulative distribution functions analysis.DiscussionFor the first time, a StartReact effect of back muscles was demonstrated during a voluntary task and was shown to be similar to that observed in a postural task. Therefore, these results suggest a contribution of the reticulospinal tract in the postural and voluntary control of back muscles in humans.",
      "author": "Hugo Mass\u00e9-Alarie",
      "published_date": "2025-09-25T00:00:00+00:00",
      "source": "Frontiers Human Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 210,
      "reading_time": 1,
      "created_at": "2025-09-30T07:40:29.568705+00:00",
      "updated_at": "2025-09-30T07:40:29.568706+00:00"
    },
    {
      "id": "0d7003a58c06dc1418541f47aeead00f",
      "url": "https://www.frontiersin.org/articles/10.3389/fnhum.2025.1666735",
      "title": "Case Report: Implementation of stereoelectroencephalography in Kazakhstan: early experience in surgical planning for drug-resistant epilepsy",
      "content": "IntroductionThis clinical report describes the management of a 32-year-old patient with a long-standing history of drug-resistant epilepsy. It uniquely illustrates how stereoelectroencephalography (SEEG) played a significant role in the presurgical evaluation of a multifocal epileptic disorder which, despite a long history of no changes on MRI, was ultimately found to be associated with bilateral hippocampal sclerosis. This is one of the first documented cases of SEEG application in Kazakhstan, where the method was introduced in 2024.Clinical presentation and diagnostic findingsThe patient suffered from debilitating seizures (4\u20136 times/week, often in series of 3-4/day) refractory to combined antiepileptic therapy. Scalp EEG revealed the first originating from the right frontotemporal leads with subsequent diffuse, predominantly right-sided, propagation. The second seizure, however, showed onset from the left temporal leads; notably, only left-onset seizures culminated in bilateral synchronization. Financial constraints precluding PET-CT and the diagnostic ambiguity of routine methods necessitated invasive SEEG.SEEG results and therapeutic strategySEEG monitoring unequivocally identified three independent epileptogenic foci: in the right hippocampus, left hippocampus, and left orbitofrontal region. Such multifocal pathology significantly reduces the likelihood of successful focal resection. Despite this inherent complexity, a crucial clinical outcome was achieved: the patient has remained completely seizure-free for 7\u202fmonths following the ANT-DBS procedure.ConclusionThis report underscores the critical role of SEEG in the precise localization and characterization of complex, multifocal epileptogenic networks, often elusive to non-invasive modalities. It convincingly demonstrates that a comprehensive invasive approach can lead to successful seizure control even in cases previously considered inoperable. It also reflects the challenges and advancements in developing high-tech epileptological care in regions where advanced methods like SEEG have only recently been introduced.",
      "author": "Berik Tuleubayev",
      "published_date": "2025-09-29T00:00:00+00:00",
      "source": "Frontiers Human Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 269,
      "reading_time": 1,
      "created_at": "2025-09-30T07:40:29.568667+00:00",
      "updated_at": "2025-09-30T07:40:29.568669+00:00"
    },
    {
      "id": "fc91edf0bfc53791714b193a17cb2ccb",
      "url": "https://www.frontiersin.org/articles/10.3389/fnbot.2025.1631998",
      "title": "Dynamic graph neural networks for UAV-based group activity recognition in structured team sports",
      "content": "IntroductionUnderstanding group actions in real-world settings is essential for the advancement of applications in surveillance, robotics, and autonomous systems. Group activity recognition, particularly in sports scenarios, presents unique challenges due to dynamic interactions, occlusions, and varying viewpoints. To address these challenges, we develop a deep learning system that recognizes multi-person behaviors by integrating appearance-based features (HOG, LBP, SIFT), skeletal data (MediaPipe, MOCON), and motion features. Our approach employs a Dynamic Graph Neural Network (DGNN) and Bi-LSTM architecture, enabling robust recognition of group activities in diverse and dynamic environments. To further validate our framework\u2019s adaptability, we include evaluations on Volleyball and SoccerTrack UAV-recorded datasets, which offer unique perspectives and challenges.MethodOur framework integrates YOLOv11 for object detection and SORT for tracking to extract multi-modal features\u2014including HOG, LBP, SIFT, skeletal data (MediaPipe), and motion context (MOCON). These features are optimized using genetic algorithms and fused within a Dynamic Graph Neural Network (DGNN), which models players as nodes in a spatio-temporal graph, effectively capturing both spatial formations and temporal dynamics.ResultsWe evaluated our framework on three datasets: a volleyball dataset, SoccerTrack UAV-based soccer dataset, and NBA basketball dataset. Our system achieved 94.5% accuracy on the volleyball dataset (mAP: 94.2%, MPCA: 93.8%) with an inference time of 0.18\u202fs per frame. On the SoccerTrack UAV dataset, accuracy was 91.8% (mAP: 91.5%, MPCA: 90.5%) with 0.20\u202fs inference, and on the NBA basketball dataset, it was 91.1% (mAP: 90.8%, MPCA: 89.8%) with the same 0.20\u202fs per frame. These results highlight our framework\u2019s high performance and efficient computational efficiency across various sports and perspectives.DiscussionOur approach demonstrates robust performance in recognizing multi-person actions across diverse conditions, highlighting its adaptability to both conventional and UAV-based video sources.",
      "author": "Hui Liu",
      "published_date": "2025-09-08T00:00:00+00:00",
      "source": "Frontiers Neurorobotics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 278,
      "reading_time": 1,
      "created_at": "2025-09-30T07:40:28.217891+00:00",
      "updated_at": "2025-09-30T07:40:28.217893+00:00"
    },
    {
      "id": "acad90d166d90fd0a5adf8d96e11f39b",
      "url": "https://www.frontiersin.org/articles/10.3389/fnbot.2025.1575995",
      "title": "Toward accurate single image sand dust removal by utilizing uncertainty-aware neural network",
      "content": "Although deep learning methods have made significant strides in single image sand dust removal, the heterogeneous uncertainty induced by dusty environments poses a considerable challenge. In response, our research presents a novel framework known as the Hierarchical Interactive Uncertainty-aware Network (HIUNet). HIUNet leverages Bayesian neural networks for the extraction of robust shallow features, bolstered by pre-trained encoders for feature extraction and the agility of lightweight decoders for preliminary image reconstitution. Subsequently, a feature frequency selection mechanism is activated to enhance overall performance by strategically identifying and retaining valuable features while effectively suppressing redundant and irrelevant ones. Following this, a feature enhancement module is applied to the preliminary restoration. This intricate fusion culminates in the production of a restored image of superior quality. Our extensive experiments, using our proposed Sand11K dataset that exhibits various levels of degradation from dust and sand, confirm the effectiveness and soundness of our proposed method. By modeling uncertainty via Bayesian neural networks to extract robust shallow features and selecting valuable features through frequency selection, HIUNet can reconstruct high-quality clean images. For future work, we plan to extend our uncertainty-aware framework to handle extreme sand scenarios.",
      "author": "Yixin Wang",
      "published_date": "2025-09-10T00:00:00+00:00",
      "source": "Frontiers Neurorobotics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 189,
      "reading_time": 1,
      "created_at": "2025-09-30T07:40:28.217846+00:00",
      "updated_at": "2025-09-30T07:40:28.217848+00:00"
    },
    {
      "id": "a049925ba33d5eb41d0ff4cb6515dfac",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38873838/?utm_source=BucketBot&utm_medium=rss&utm_campaign=None&utm_content=1BUB2BG5RbxOblm-hBbiJWEhGG43qlVrvGNHOTqBKva9wWrItM&fc=None&ff=20250930034016&v=2.18.0.post9+e462414",
      "title": "The impact of CSF-filled cavities on scalp EEG and its implications",
      "content": "Previous studies have found electroencephalogram (EEG) amplitude and scalp topography differences between neurotypical and neurological/neurosurgical groups, being interpreted at the cognitive level. However, these comparisons are invariably accompanied by anatomical changes. Critical to EEG are the so-called volume currents, which are affected by the spatial distribution of the different tissues in the head. We investigated the effect of cerebrospinal fluid (CSF)-filled cavities on simulated...",
      "author": "Maria Carla Piastra",
      "published_date": "2024-06-14T10:00:00+00:00",
      "source": "Oostenveld Robert",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 64,
      "reading_time": 1,
      "created_at": "2025-09-30T07:40:22.786338+00:00",
      "updated_at": "2025-09-30T07:40:22.786339+00:00"
    },
    {
      "id": "5a4ccf5a4ccd4813679e415f9d6bf610",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38956071/?utm_source=BucketBot&utm_medium=rss&utm_campaign=None&utm_content=1BUB2BG5RbxOblm-hBbiJWEhGG43qlVrvGNHOTqBKva9wWrItM&fc=None&ff=20250930034016&v=2.18.0.post9+e462414",
      "title": "Motion-BIDS: an extension to the brain imaging data structure to organize motion data for reproducible research",
      "content": "We present an extension to the Brain Imaging Data Structure (BIDS) for motion data. Motion data is frequently recorded alongside human brain imaging and electrophysiological data. The goal of Motion-BIDS is to make motion data interoperable across different laboratories and with other data modalities in human brain and behavioral research. To this end, Motion-BIDS standardizes the data format and metadata structure. It describes how to document experimental details, considering the diversity of...",
      "author": "Julius Welzel",
      "published_date": "2024-07-02T10:00:00+00:00",
      "source": "Oostenveld Robert",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 72,
      "reading_time": 1,
      "created_at": "2025-09-30T07:40:22.786315+00:00",
      "updated_at": "2025-09-30T07:40:22.786316+00:00"
    },
    {
      "id": "4ce14df5f58cc696e96f7d467f9eb546",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39174725/?utm_source=BucketBot&utm_medium=rss&utm_campaign=None&utm_content=1BUB2BG5RbxOblm-hBbiJWEhGG43qlVrvGNHOTqBKva9wWrItM&fc=None&ff=20250930034016&v=2.18.0.post9+e462414",
      "title": "One hundred years of EEG for brain and behaviour research",
      "content": "No abstract",
      "author": "Pedro Valdes-Sosa",
      "published_date": "2024-08-22T10:00:00+00:00",
      "source": "Oostenveld Robert",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-09-30T07:40:22.786291+00:00",
      "updated_at": "2025-09-30T07:40:22.786292+00:00"
    },
    {
      "id": "331d0b43caed4ac03ff24135122129e9",
      "url": "https://pubmed.ncbi.nlm.nih.gov/39229492/?utm_source=BucketBot&utm_medium=rss&utm_campaign=None&utm_content=1BUB2BG5RbxOblm-hBbiJWEhGG43qlVrvGNHOTqBKva9wWrItM&fc=None&ff=20250930034016&v=2.18.0.post9+e462414",
      "title": "Freezing of gait in Parkinson's disease is related to imbalanced stopping-related cortical activity",
      "content": "Freezing of gait, characterized by involuntary interruptions of walking, is a debilitating motor symptom of Parkinson's disease that restricts people's autonomy. Previous brain imaging studies investigating the mechanisms underlying freezing were restricted to scan people in supine positions and yielded conflicting theories regarding the role of the supplementary motor area and other cortical regions. We used functional near-infrared spectroscopy to investigate cortical haemodynamics related to...",
      "author": "Richard J A van Wezel",
      "published_date": "2024-09-04T10:00:00+00:00",
      "source": "Oostenveld Robert",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 65,
      "reading_time": 1,
      "created_at": "2025-09-30T07:40:22.786272+00:00",
      "updated_at": "2025-09-30T07:40:22.786274+00:00"
    }
  ]
}