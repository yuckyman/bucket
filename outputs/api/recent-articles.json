{
  "last_updated": "2025-11-13T05:21:53.255048+00:00",
  "count": 20,
  "articles": [
    {
      "id": "3fce80778739ecdac94f0fb3d0579467",
      "url": "https://arxiv.org/abs/2511.09458",
      "title": "Exploring The Interaction-Outcome Paradox: Seemingly Richer and More Self-Aware Interactions with LLMs May Not Yet Lead to Better Learning",
      "content": "arXiv:2511.09458v1 Announce Type: new \nAbstract: While Large Language Models (LLMs) have transformed the user interface for learning, moving from keyword search to natural language dialogue, their impact on educational outcomes remains unclear. We present a controlled study (N=20) that directly compares the learning interaction and outcomes between LLM and search-based interfaces. We found that although LLMs elicit richer and nuanced interactions from a learner, they do not produce broadly better learning outcomes. In this paper, we explore this the ``Interaction-Outcome Paradox.'' To explain this, we discuss the concept of a cognitive shift: the locus of student effort moves from finding and synthesizing disparate sources (search) to a more self-aware identification and articulation of their knowledge gaps and strategies to bridge those gaps (LLMs). This insight provides a new lens for evaluating educational technologies, suggesting that the future of learning tools lies not in simply enriching interaction, but in designing systems that scaffold productive cognitive work by leveraging this student expressiveness.",
      "author": "Rahul R. Divekar, Sophia Guerra, Lisette Gonzalez, Natasha Boos",
      "published_date": "2025-11-13T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 160,
      "reading_time": 1,
      "created_at": "2025-11-13T05:21:31.415743+00:00",
      "updated_at": "2025-11-13T05:21:31.415745+00:00"
    },
    {
      "id": "4bce2618116a74e3de51cc473b4aec42",
      "url": "https://arxiv.org/abs/2511.09454",
      "title": "Algorithmic Advice as a Strategic Signal on Competitive Markets",
      "content": "arXiv:2511.09454v1 Announce Type: new \nAbstract: As algorithms increasingly mediate competitive decision-making, their influence extends beyond individual outcomes to shaping strategic market dynamics. In two preregistered experiments, we examined how algorithmic advice affects human behavior in classic economic games with unique, non-collusive, and analytically traceable equilibria. In Experiment 1 (N = 107), participants played a Bertrand price competition with individualized or collective algorithmic recommendations. Initially, collusively upward-biased advice increased prices, particularly when individualized, but prices gradually converged toward equilibrium over the course of the experiment. However, participants avoided setting prices above the algorithm's recommendation throughout the experiment, suggesting that advice served as a soft upper bound for acceptable prices. In Experiment 2 (N = 129), participants played a Cournot quantity competition with equilibrium-aligned or strategically biased algorithmic recommendations. Here, individualized equilibrium advice supported stable convergence, whereas collusively downward-biased advice led to sustained underproduction and supracompetitive profits - hallmarks of tacit collusion. In both experiments, participants responded more strongly and consistently to individualized advice than collective advice, potentially due to greater perceived ownership of the former. These findings demonstrate that algorithmic advice can function as a strategic signal, shaping coordination even without explicit communication. The results echo real-world concerns about algorithmic collusion and underscore the need for careful design and oversight of algorithmic decision-support systems in competitive environments.",
      "author": "Tobias R. Rebholz, Maxwell Uphoff, Christian H. R. Bernges, Florian Scholten",
      "published_date": "2025-11-13T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 216,
      "reading_time": 1,
      "created_at": "2025-11-13T05:21:31.415714+00:00",
      "updated_at": "2025-11-13T05:21:31.415716+00:00"
    },
    {
      "id": "0200829fccc1f03b9ea419a10b3c4c63",
      "url": "https://arxiv.org/abs/2511.09394",
      "title": "A multimodal AI agent for clinical decision support in ophthalmology",
      "content": "arXiv:2511.09394v1 Announce Type: new \nAbstract: Artificial intelligence has shown promise in medical imaging, yet most existing systems lack flexibility, interpretability, and adaptability - challenges especially pronounced in ophthalmology, where diverse imaging modalities are essential. We present EyeAgent, the first agentic AI framework for comprehensive and interpretable clinical decision support in ophthalmology. Using a large language model (DeepSeek-V3) as its central reasoning engine, EyeAgent interprets user queries and dynamically orchestrates 53 validated ophthalmic tools across 23 imaging modalities for diverse tasks including classification, segmentation, detection, image/report generation, and quantitative analysis. Stepwise ablation analysis demonstrated a progressive improvement in diagnostic accuracy, rising from a baseline of 69.71% (using only 5 general tools) to 80.79% when the full suite of 53 specialized tools was integrated. In an expert rating study on 200 real-world clinical cases, EyeAgent achieved 93.7% tool selection accuracy and received expert ratings of more than 88% across accuracy, completeness, safety, reasoning, and interpretability. In human-AI collaboration, EyeAgent matched or exceeded the performance of senior ophthalmologists and, when used as an assistant, improved overall diagnostic accuracy by 18.51% and report quality scores by 19%, with the greatest benefit observed among junior ophthalmologists. These findings establish EyeAgent as a scalable and trustworthy AI framework for ophthalmology and provide a blueprint for modular, multimodal, and clinically aligned next-generation AI systems.",
      "author": "Danli Shi, Xiaolan Chen, Bingjie Yan, Weiyi Zhang, Pusheng Xu, Jiancheng Yang, Ruoyu Chen, Siyu Huang, Bowen Liu, Xinyuan Wu, Meng Xie, Ziyu Gao, Yue Wu, Senlin Lin, Kai Jin, Xia Gong, Yih Chung Tham, Xiujuan Zhang, Li Dong, Yuzhou Zhang, Jason Yam, Guangming Jin, Xiaohu Ding, Haidong Zou, Yalin Zheng, Zongyuan Ge, Mingguang He",
      "published_date": "2025-11-13T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 217,
      "reading_time": 1,
      "created_at": "2025-11-13T05:21:31.415681+00:00",
      "updated_at": "2025-11-13T05:21:31.415682+00:00"
    },
    {
      "id": "dda0b3085f939e5168fb664aafffea2a",
      "url": "https://arxiv.org/abs/2511.09337",
      "title": "TempoQL: A Readable, Precise, and Portable Query System for Electronic Health Record Data",
      "content": "arXiv:2511.09337v1 Announce Type: new \nAbstract: Electronic health record (EHR) data is an essential data source for machine learning for health, but researchers and clinicians face steep barriers in extracting and validating EHR data for modeling. Existing tools incur trade-offs between expressivity and usability and are typically specialized to a single data standard, making it difficult to write temporal queries that are ready for modern model-building pipelines and adaptable to new datasets. This paper introduces TempoQL, a Python-based toolkit designed to lower these barriers. TempoQL provides a simple, human-readable language for temporal queries; support for multiple EHR data standards, including OMOP, MEDS, and others; and an interactive notebook-based query interface with optional large language model (LLM) authoring assistance. Through a performance evaluation and two use cases on different datasets, we demonstrate that TempoQL simplifies the creation of cohorts for machine learning while maintaining precision, speed, and reproducibility.",
      "author": "Ziyong Ma, Richard D. Boyce, Adam Perer, Venkatesh Sivaraman",
      "published_date": "2025-11-13T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 146,
      "reading_time": 1,
      "created_at": "2025-11-13T05:21:31.415647+00:00",
      "updated_at": "2025-11-13T05:21:31.415649+00:00"
    },
    {
      "id": "3a3c933233b43615540f6cbd5e524f7c",
      "url": "https://arxiv.org/abs/2511.09309",
      "title": "TaskSense: Cognitive Chain Modeling and Difficulty Estimation for GUI Tasks",
      "content": "arXiv:2511.09309v1 Announce Type: new \nAbstract: Measuring GUI task difficulty is crucial for user behavior analysis and agent capability evaluation. Yet, existing benchmarks typically quantify difficulty based on motor actions (e.g., step counts), overlooking the cognitive demands underlying task completion. In this work, we propose Cognitive Chain, a novel framework that models task difficulty from a cognitive perspective. A cognitive chain decomposes the cognitive processes preceding a motor action into a sequence of cognitive steps (e.g., finding, deciding, computing), each with a difficulty index grounded in information theories. We develop an LLM-based method to automatically extract cognitive chains from task execution traces. Validation with linear regression shows that our estimated cognitive difficulty correlates well with user completion time (step-level R-square=0.46 after annotation). Assessment of state-of-the-art GUI agents shows reduced success on cognitively demanding tasks, revealing capability gaps and Human-AI consistency patterns. We conclude by discussing potential applications in agent training, capability assessment, and human-agent delegation optimization.",
      "author": "Yiwen Yin, Zhian Hu, Xiaoxi Xu, Chun Yu, Xintong Wu, Wenyu Fan, Yuanchun Shi",
      "published_date": "2025-11-13T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 155,
      "reading_time": 1,
      "created_at": "2025-11-13T05:21:31.415618+00:00",
      "updated_at": "2025-11-13T05:21:31.415620+00:00"
    },
    {
      "id": "6a97f3558b13ea1cce3dfee8ea6edf62",
      "url": "https://arxiv.org/abs/2511.09240",
      "title": "SimPath: Mitigating Motion Sickness in In - vehicle Infotainment Systems via Driving Condition Adaptation",
      "content": "arXiv:2511.09240v1 Announce Type: new \nAbstract: The problem of Motion Sickness (MS) among passengers significantly impacts the comfort and efficiency of In-Vehicle Infotainment Systems (IVIS) use. In this study, we innovatively designed SimPath, a visual design to effectively mitigate passengers' MS and boost their efficiency of using IVIS during driving. The study focuses on the problem of irregular motion conditions frequently encountered during actual driving. To validate the efficacy of this approach, two sets of real - vehicle experiments were carried out in real driving scenarios. The results demonstrate that this approach significantly reduces passenger's MS level to a certain extent. However, due to divided attention from visual content, it does not directly improve the IVIS efficiency. In conclusion, this study offers crucial insights for the design of a more intelligent and user friendly IVIS, based on the discussion of the principle, providing strong theoretical support and practical guidance for the development of future IVIS in autonomous vehicles.",
      "author": "Jinghao Huang, Siqi Yao, Yu Zhang",
      "published_date": "2025-11-13T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 157,
      "reading_time": 1,
      "created_at": "2025-11-13T05:21:31.415570+00:00",
      "updated_at": "2025-11-13T05:21:31.415571+00:00"
    },
    {
      "id": "6630f2746282a491867f2d346a3c4e41",
      "url": "https://arxiv.org/abs/2511.08971",
      "title": "Plug-and-Play Clarifier: A Zero-Shot Multimodal Framework for Egocentric Intent Disambiguation",
      "content": "arXiv:2511.08971v1 Announce Type: new \nAbstract: The performance of egocentric AI agents is fundamentally limited by multimodal intent ambiguity. This challenge arises from a combination of underspecified language, imperfect visual data, and deictic gestures, which frequently leads to task failure. Existing monolithic Vision-Language Models (VLMs) struggle to resolve these multimodal ambiguous inputs, often failing silently or hallucinating responses. To address these ambiguities, we introduce the Plug-and-Play Clarifier, a zero-shot and modular framework that decomposes the problem into discrete, solvable sub-tasks. Specifically, our framework consists of three synergistic modules: (1) a text clarifier that uses dialogue-driven reasoning to interactively disambiguate linguistic intent, (2) a vision clarifier that delivers real-time guidance feedback, instructing users to adjust their positioning for improved capture quality, and (3) a cross-modal clarifier with grounding mechanism that robustly interprets 3D pointing gestures and identifies the specific objects users are pointing to. Extensive experiments demonstrate that our framework improves the intent clarification performance of small language models (4--8B) by approximately 30%, making them competitive with significantly larger counterparts. We also observe consistent gains when applying our framework to these larger models. Furthermore, our vision clarifier increases corrective guidance accuracy by over 20%, and our cross-modal clarifier improves semantic answer accuracy for referential grounding by 5%. Overall, our method provides a plug-and-play framework that effectively resolves multimodal ambiguity and significantly enhances user experience in egocentric interaction.",
      "author": "Sicheng Yang, Yukai Huang, Weitong Cai, Shitong Sun, You He, Jiankang Deng, Hang Zhang, Jifei Song, Zhensong Zhang",
      "published_date": "2025-11-13T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 225,
      "reading_time": 1,
      "created_at": "2025-11-13T05:21:31.415541+00:00",
      "updated_at": "2025-11-13T05:21:31.415542+00:00"
    },
    {
      "id": "a479cfa86ba7f1308928bebbdfb53c0d",
      "url": "https://arxiv.org/abs/2511.08917",
      "title": "\"It's trained by non-disabled people\": Evaluating How Image Quality Affects Product Captioning with VLMs",
      "content": "arXiv:2511.08917v1 Announce Type: new \nAbstract: Vision-Language Models (VLMs) are increasingly used by blind and low-vision (BLV) people to identify and understand products in their everyday lives, such as food, personal products, and household goods. Despite their prevalence, we lack an empirical understanding of how common image quality issues, like blur and misframing of items, affect the accuracy of VLM-generated captions and whether resulting captions meet BLV people's information needs. Grounded in a survey with 86 BLV people, we systematically evaluate how image quality issues affect captions generated by VLMs. We show that the best model recognizes products in images with no quality issues with 98% accuracy, but drops to 75% accuracy overall when quality issues are present, worsening considerably as issues compound. We discuss the need for model evaluations that center on disabled people's experiences throughout the process and offer concrete recommendations for HCI and ML researchers to make VLMs more reliable for BLV people.",
      "author": "Kapil Garg, Xinru Tang, Jimin Heo, Dwayne R. Morgan, Darren Gergle, Erik B. Sudderth, Anne Marie Piper",
      "published_date": "2025-11-13T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 155,
      "reading_time": 1,
      "created_at": "2025-11-13T05:21:31.415507+00:00",
      "updated_at": "2025-11-13T05:21:31.415508+00:00"
    },
    {
      "id": "31da290567350f9eccfb454e72814e58",
      "url": "https://arxiv.org/abs/2511.08880",
      "title": "Simulating Psychological Risks in Human-AI Interactions: Real-Case Informed Modeling of AI-Induced Addiction, Anorexia, Depression, Homicide, Psychosis, and Suicide",
      "content": "arXiv:2511.08880v1 Announce Type: new \nAbstract: As AI systems become increasingly integrated into daily life, their potential to exacerbate or trigger severe psychological harms remains poorly understood and inadequately tested. This paper presents a proactive methodology for systematically exploring psychological risks in simulated human-AI interactions based on documented real-world cases involving AI-induced or AI-exacerbated addiction, anorexia, depression, homicide, psychosis, and suicide. We collected and analyzed 18 reported real-world cases where AI interactions contributed to severe psychological outcomes. From these cases, we developed a process to extract harmful interaction patterns and assess potential risks through 2,160 simulated scenarios using clinical staging models. We tested four major LLMs across multi-turn conversations to identify where psychological risks emerge: which harm domains, conversation stages, and contexts reveal system vulnerabilities. Through the analysis of 157,054 simulated conversation turns, we identify critical gaps in detecting psychological distress, responding appropriately to vulnerable users, and preventing harm escalation. Regression analysis reveals variability across persona types: LLMs tend to perform worse with elderly users but better with low- and middle-income groups compared to high-income groups. Clustering analysis of harmful responses reveals a taxonomy of fifteen distinct failure patterns organized into four categories of AI-enabled harm. This work contributes a novel methodology for identifying psychological risks, empirical evidence of common failure modes across systems, and a classification of harmful AI response patterns in high-stakes human-AI interactions.",
      "author": "Chayapatr Archiwaranguprok, Constanze Albrecht, Pattie Maes, Karrie Karahalios, Pat Pataranutaporn",
      "published_date": "2025-11-13T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 225,
      "reading_time": 1,
      "created_at": "2025-11-13T05:21:31.415476+00:00",
      "updated_at": "2025-11-13T05:21:31.415478+00:00"
    },
    {
      "id": "32eea95849d67baf2e5231d42766db20",
      "url": "https://arxiv.org/abs/2511.08763",
      "title": "Modeling multi-agent motion dynamics in immersive rooms",
      "content": "arXiv:2511.08763v1 Announce Type: new \nAbstract: Immersive rooms are increasingly popular augmented reality systems that support multi-agent interactions within a virtual world. However, despite extensive content creation and technological developments, insights about perceptually-driven social dynamics, such as the complex movement patterns during virtual world navigation, remain largely underexplored. Computational models of motion dynamics can help us understand the underlying mechanism of human interaction in immersive rooms and develop applications that better support spatially distributed interaction. In this work, we propose a new agent-based model of emergent human motion dynamics. The model represents human agents as simple spatial geometries in the room that relocate and reorient themselves based on the salient virtual spatial objects they approach. Agent motion is modeled as an interactive process combining external diffusion-driven influences from the environment with internal self-propelling interactions among agents. Further, we leverage simulation-based inference (SBI) to show that the governing parameters of motion patterns can be estimated from simple observables. Our results indicate that the model successfully captures action-related agent properties but exposes local non-identifiability linked to environmental awareness. We argue that our simulation-based approach paves the way for creating adaptive, responsive immersive rooms -- spaces that adjust their interfaces and interactions based on human collective movement patterns and spatial attention.",
      "author": "Mincong (Jerry),  Huang, Stefan T. Radev",
      "published_date": "2025-11-13T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 207,
      "reading_time": 1,
      "created_at": "2025-11-13T05:21:31.415435+00:00",
      "updated_at": "2025-11-13T05:21:31.415440+00:00"
    },
    {
      "id": "ff2a3486586f0a1b604755ed87b3e92c",
      "url": "https://arxiv.org/abs/2511.05221",
      "title": "ActiTect: A Generalizable Machine Learning Pipeline for REM Sleep Behavior Disorder Screening through Standardized Actigraphy",
      "content": "arXiv:2511.05221v2 Announce Type: replace-cross \nAbstract: Isolated rapid eye movement sleep behavior disorder (iRBD) is a major prodromal marker of $\\alpha$-synucleinopathies, often preceding the clinical onset of Parkinson's disease, dementia with Lewy bodies, or multiple system atrophy. While wrist-worn actimeters hold significant potential for detecting RBD in large-scale screening efforts by capturing abnormal nocturnal movements, they become inoperable without a reliable and efficient analysis pipeline. This study presents ActiTect, a fully automated, open-source machine learning tool to identify RBD from actigraphy recordings. To ensure generalizability across heterogeneous acquisition settings, our pipeline includes robust preprocessing and automated sleep-wake detection to harmonize multi-device data and extract physiologically interpretable motion features characterizing activity patterns. Model development was conducted on a cohort of 78 individuals, yielding strong discrimination under nested cross-validation (AUROC = 0.95). Generalization was confirmed on a blinded local test set (n = 31, AUROC = 0.86) and on two independent external cohorts (n = 113, AUROC = 0.84; n = 57, AUROC = 0.94). To assess real-world robustness, leave-one-dataset-out cross-validation across the internal and external cohorts demonstrated consistent performance (AUROC range = 0.84-0.89). A complementary stability analysis showed that key predictive features remained reproducible across datasets, supporting the final pooled multi-center model as a robust pre-trained resource for broader deployment. By being open-source and easy to use, our tool promotes widespread adoption and facilitates independent validation and collaborative improvements, thereby advancing the field toward a unified and generalizable RBD detection model using wearable devices.",
      "author": "David Bertram, Anja Ophey, Sinah R\\\"ottgen, Konstantin Kufer, Gereon R. Fink, Elke Kalbe, Clint Hansen, Walter Maetzler, Maximilian Kapsecker, Lara M. Reimer, Stephan Jonas, Andreas T. Damgaard, Natasha B. Bertelsen, Casper Skjaerbaek, Per Borghammer, Karolien Groenewald, Pietro-Luca Ratti, Michele T. Hu, No\\'emie Moreau, Michael Sommerauer, Katarzyna Bozek",
      "published_date": "2025-11-13T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 242,
      "reading_time": 1,
      "created_at": "2025-11-13T05:21:30.272053+00:00",
      "updated_at": "2025-11-13T05:21:30.272054+00:00"
    },
    {
      "id": "d0d363a51887b59f6c16199e82262e10",
      "url": "https://arxiv.org/abs/2507.01651",
      "title": "A Dynamical Cartography of the Epistemic Diffusion of Artificial Intelligence in Neuroscience",
      "content": "arXiv:2507.01651v2 Announce Type: replace-cross \nAbstract: Neuroscience and AI have an intertwined history, largely relayed in the literature of both fields. In recent years, due to the engineering orientations of AI research and the monopoly of industry for its large-scale applications, the mutual expansion of neuroscience and AI in fundamental research seems challenged. In this paper, we bring some empirical evidences that, on the contrary, AI and neuroscience are continuing to grow together, but with a pronounced interest in the fields of study related to neurodegenerative diseases since the 1990s. With a temporal knowledge cartography of neuroscience drawn with advanced document embedding techniques, we draw the dynamical shaping of the discipline since the 1970s and identified the conceptual articulation of AI with this particular subfield mentioned before. However, a further analysis of the underlying citation network of the studied corpus shows that the produced AI technologies remain confined in the different subfields and are not transferred from one subfield to another. This invites us to discuss the genericity capability of AI in the context of an intradisciplinary development, especially in the diffusion of its associated metrology.",
      "author": "Sylvain Fontaine",
      "published_date": "2025-11-13T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 185,
      "reading_time": 1,
      "created_at": "2025-11-13T05:21:30.272018+00:00",
      "updated_at": "2025-11-13T05:21:30.272019+00:00"
    },
    {
      "id": "ec7f0f11cc7fc3c0888e2491a60fcc0e",
      "url": "https://arxiv.org/abs/2505.11477",
      "title": "Fractal geometry predicts dynamic differences in structural and functional connectomes",
      "content": "arXiv:2505.11477v2 Announce Type: replace-cross \nAbstract: Understanding the intricate architecture of brain networks and its connection to brain function is essential for deciphering the underlying principles of cognition and disease. While traditional graph-theoretical measures have been widely used to characterize these networks, they often fail to fully capture the emergent properties of large-scale neural dynamics. Here, we introduce an alternative approach to quantify brain networks that is rooted in complex dynamics, fractal geometry, and asymptotic analysis. We apply these concepts to brain connectomes and demonstrate how quadratic iterations and geometric properties of Mandelbrot-like sets can provide novel insights into structural and functional network dynamics. Our findings reveal fundamental distinctions between structural (positive) and functional (signed) connectomes, such as the shift of cusp orientation and the variability in equi-M set geometry. Notably, structural connectomes exhibit more robust, predictable features, while functional connectomes show increased variability for non-trivial tasks. We further demonstrate that traditional graph-theoretical measures, when applied separately to the positive and negative sub-networks of functional connectomes, fail to fully capture their dynamic complexity. Instead, size and shape-based invariants of the equi-M set effectively differentiate between rest and emotional task states, which highlights their potential as superior markers of emergent network dynamics. These results suggest that incorporating fractal-based methods into network neuroscience provides a powerful tool for understanding how information flows in natural systems beyond static connectivity measures, while maintaining their simplicity.",
      "author": "Anca Radulescu, Eva Kaslik, Alexandru Fikl, Johan Nakuci, Sarah Muldoon, Michael Anderson",
      "published_date": "2025-11-13T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 230,
      "reading_time": 1,
      "created_at": "2025-11-13T05:21:30.271988+00:00",
      "updated_at": "2025-11-13T05:21:30.271989+00:00"
    },
    {
      "id": "8fc6fd3c65be9824116e2d9fb9f1d2dc",
      "url": "https://arxiv.org/abs/2509.02139",
      "title": "On sources to variabilities of simple cells in the primary visual cortex: A principled theory for the interaction between geometric image transformations and receptive field responses",
      "content": "arXiv:2509.02139v5 Announce Type: replace \nAbstract: This paper gives an overview of a theory for modelling the interaction between geometric image transformations and receptive field responses for a visual observer that views objects and spatio-temporal events in the environment. This treatment is developed over combinations of (i) uniform spatial scaling transformations, (ii) spatial affine transformations, (iii) Galilean transformations and (iv) temporal scaling transformations.\n  By postulating that the family of receptive fields should be covariant under these classes of geometric image transformations, it follows that the receptive field shapes should be expanded over the degrees of freedom of the corresponding image transformations, to enable a formal matching between the receptive field responses computed under different viewing conditions for the same scene or for a structurally similar spatio-temporal event.\n  We conclude the treatment by discussing and providing potential support for a working hypothesis that the receptive fields of simple cells in the primary visual cortex ought to be covariant under these classes of geometric image transformations, and thus have the shapes of their receptive fields expanded over the degrees of freedom of the corresponding geometric image transformations.",
      "author": "Tony Lindeberg",
      "published_date": "2025-11-13T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 184,
      "reading_time": 1,
      "created_at": "2025-11-13T05:21:30.271953+00:00",
      "updated_at": "2025-11-13T05:21:30.271955+00:00"
    },
    {
      "id": "e02058bd9e2a7bdd74eeff82c2642a77",
      "url": "https://arxiv.org/abs/2511.09290",
      "title": "Multi-step Predictive Coding Leads To Simplicity Bias",
      "content": "arXiv:2511.09290v1 Announce Type: cross \nAbstract: Predictive coding is a framework for understanding the formation of low-dimensional internal representations mirroring the environment's latent structure. The conditions under which such representations emerge remain unclear. In this work, we investigate how the prediction horizon and network depth shape the solutions of predictive coding tasks. Using a minimal abstract setting inspired by prior work, we show empirically and theoretically that sufficiently deep networks trained with multi-step prediction horizons consistently recover the underlying latent structure, a phenomenon explained through the Ordinary Least Squares estimator structure and biases in learning dynamics. We then extend these insights to nonlinear networks and complex datasets, including piecewise linear functions, MNIST, multiple latent states and higher dimensional state geometries. Our results provide a principled understanding of when and why predictive coding induces structured representations, bridging the gap between empirical observations and theoretical foundations.",
      "author": "Aviv Ratzon, Omri Barak",
      "published_date": "2025-11-13T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 143,
      "reading_time": 1,
      "created_at": "2025-11-13T05:21:30.271922+00:00",
      "updated_at": "2025-11-13T05:21:30.271924+00:00"
    },
    {
      "id": "599d9582cef13fb736ce8672f3a51cf1",
      "url": "https://arxiv.org/abs/2511.09506",
      "title": "A thermoinformational framework for the description of neuropsychological systems",
      "content": "arXiv:2511.09506v1 Announce Type: new \nAbstract: This work presents a statistical thermodynamics-inspired framework that summarizes multichannel EEG and behavior using macroscopic state variables (entropy, internal energy, temperature, Helmholtz free energy) to quantify stability and reconfiguration in neuropsychological systems. Applied to mother-infant EEG dyads performing the A-not-B task, these variables dissociate neural reconfiguration from behavioral success across a large set of model and feature configurations. Informational heat increases during environmental switches and decision errors, consistent with increased information exchange with the task context. In contrast, correct choices are preceded by lower temperature and higher free energy in the window, and are followed by free-energy declines as the system re-stabilizes. In an independent optogenetic dam-pup paradigm, the same variables separate stimulation conditions and trace coherent trajectories in thermodynamic state space. Together, these findings show that the thermoinformational framework yields compact, physically grounded descriptors that hold in both human and mouse datasets studied here.",
      "author": "George-Rafael Domenikos, Victoria Leong",
      "published_date": "2025-11-13T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 150,
      "reading_time": 1,
      "created_at": "2025-11-13T05:21:30.271894+00:00",
      "updated_at": "2025-11-13T05:21:30.271896+00:00"
    },
    {
      "id": "91a9c2faaf9accb421080e545e416322",
      "url": "https://arxiv.org/abs/2511.09243",
      "title": "Characterizing sleep stages through the complexity-entropy plane in human intracranial data and in a whole-brain model",
      "content": "arXiv:2511.09243v1 Announce Type: new \nAbstract: Characterizing the brain dynamics during different cortical states can reveal valuable information about its patterns across various cognitive processes. In particular, studying the differences between awake and sleep stages can shed light on the understanding of brain processes essential for physical and mental well-being, such as memory consolidation, information processing, and fatigue recovery. Alterations in these patterns may indicate disorders and pathologies such as obstructive sleep apnea, narcolepsy, as well as Alzheimer's and Parkinson's diseases. Here, we analyze time series obtained from intracranial recordings of 106 patients, covering four sleep stages: Wake, N2, N3, and REM. Intracranial electroencephalography (iEEG), which can include electrocorticography (ECoG) and depth recordings, represents the state-of-the-art measurements of brain activity, offering unparalleled spatial and temporal resolution for investigating neural dynamics. We characterize the signals using Bandt and Pompe symbolic methodology to calculate the Weighted Permutation Entropy (WPE) and the Statistical Complexity Measure (SCM) based on the Jensen and Shannon disequilibrium. By mapping the data onto the complexity-entropy plane, we observe that each stage occupies a distinct region, revealing its own dynamic signature. We show that our empirical results can be reproduced by a whole-brain computational model, in which each cortical region is described by a mean-field formulation based on networks of Adaptive Exponential Integrate-and-Fire (AdEx) neurons, adjusting the adaptation parameter to simulate the different sleep stages. Finally, we show that a classification approach using Support Vector Machine (SVM) provides high accuracy in distinguishing between cortical states.",
      "author": "Helena Bordini de Lucas, Leonardo Dalla Porta, Alain Destexhe, Maria V. Sanchez-Vives, Osvaldo A. Rosso, Cl\\'audio R. Mirasso, Fernanda Selingardi Matias",
      "published_date": "2025-11-13T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 245,
      "reading_time": 1,
      "created_at": "2025-11-13T05:21:30.271864+00:00",
      "updated_at": "2025-11-13T05:21:30.271866+00:00"
    },
    {
      "id": "2e4398d37663d1881cc8b7d3b208f501",
      "url": "https://arxiv.org/abs/2511.08847",
      "title": "Data-driven spatiotemporal modeling reveals personalized trajectories of cortical atrophy in Alzheimer's disease",
      "content": "arXiv:2511.08847v1 Announce Type: new \nAbstract: Alzheimer's disease (AD) is characterized by the progressive spread of pathology across brain networks, yet forecasting this cascade at the individual level remains challenging. We present a personalized graph-based dynamical model that captures the spatiotemporal evolution of cortical atrophy from longitudinal MRI and PET data. The approach constructs individualized brain graphs and learns the dynamics driving regional neurodegeneration. Applied to 1,891 participants from the Alzheimer's Disease Neuroimaging Initiative, the model accurately predicts key AD biomarkers -- including amyloid-beta, tau, neurodegeneration, and cognition -- outperforming clinical and neuroimaging benchmarks. Patient-specific parameters reveal distinct progression subtypes and anticipate future cognitive decline more effectively than standard biomarkers. Sensitivity analysis highlights regional drivers of disease spread, reproducing known temporolimbic and frontal vulnerability patterns. This network-based digital twin framework offers a quantitative, personalized paradigm for AD trajectory prediction, with implications for patient stratification, clinical trial design, and targeted therapeutic development.",
      "author": "Chunyan Li, Yutong Mao, Xiao Liu, Wenrui Hao",
      "published_date": "2025-11-13T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 150,
      "reading_time": 1,
      "created_at": "2025-11-13T05:21:30.271819+00:00",
      "updated_at": "2025-11-13T05:21:30.271823+00:00"
    },
    {
      "id": "437dd11491bad5ef899b86bf9271e125",
      "url": "http://doi.org/10.1037/cns0000370",
      "title": "Investigating how individual differences in selective attention relate to schizotypy and altered states of consciousness.",
      "content": "Measures of altered states of consciousness (ASC) are useful for understanding anomalies within conscious experiences. Within psychedelic clinical trials, ASC have been associated with long-term positive treatment outcomes for numerous types of mental illnesses. Schizotypal Personality Scale (STA), a set of personality traits that can be related to psychedelic-induced ASC, is associated with potential changes in selective attention, such as being less bound to previously learned associations (i.e., reduced associative blocking). Given the similarity between schizotypy and psychedelic-induced ASC, we hypothesized that there may be attentional differences in individuals with past experiences of ASC. This study examined how differences in selective attention relate to past experiences of ASC and STA. In Study 1, participants completed a visual categorization task designed to elicit associative blocking, the STA, and the ASC scale. Results revealed slow learning feature\u2013category associations in participants high in ASC and STA. Study 2 tested whether this deficit in performance was due to widened attention by implementing additional inference trials that measured incidental learning of feature\u2013feature associations. Results from Study 2 confirmed that participants high in ASC and STA show deficits in learning categories, but this was not accounted for by wider selective attention per se. Our results suggest that flexible or widened attention may not be the locus of cognitive changes associated with past experiences of ASC. Rather, by showing reliable latency in an error-driven learning task, we add to a comprehensive understanding of the relationships between cognition and ASC. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2023-09-14T00:00:00+00:00",
      "source": "Clinical Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 251,
      "reading_time": 1,
      "created_at": "2025-11-13T05:20:50.342096+00:00",
      "updated_at": "2025-11-13T05:20:50.342097+00:00"
    },
    {
      "id": "b84f4acfaa385c55c9bcc74850be8c16",
      "url": "http://doi.org/10.1037/cns0000380",
      "title": "Sensory-processing sensitivity as a confounder in the positive relationship between mindful awareness and psychological distress: A theoretical review.",
      "content": "Mindfulness meditation is credited as a positive driver of promoting psychological well-being and reducing stress, anxiety, and depression symptoms. However, dispositional mindfulness has been somewhat correlated with psychological distress, as awareness has been positively correlated with psychological symptoms and negative affective states in many studies. This counterintuitive phenomenon has been tentatively explained in a variety of ways, including a wrong interpretation of the items of the mindfulness assessment scales in nonmeditators. The most credited explanation is that increasing attention to present-moment experiences would boost affective reaction to negative experiences and therefore exacerbate related psychological symptoms. This hypothesis is unsatisfactory, as there is much contrasting evidence in this regard. Therefore, we propose a new hypothesis: in dispositional studies, the assessment of the awareness skill of mindfulness would be affected by sensory-processing sensitivity, which could be a confounder in its relationship with psychological distress. Sensory-processing sensitivity refers to a temperamental trait characterized by both awareness of sensorial stimulation and reactivity to experience. Thus, highly sensitive persons usually report increased awareness of subtleties in the environment, ease of overstimulation, and increased affective reaction to stimulation. In support of our hypothesis, we showed in particular how the most widely used scale for assessing mindful awareness could be paired with and interpreted as a measure of sensory-processing sensitivity. We then propose a set of testable hypotheses to drive future research on this topic. If supported by future experimental results, our hypothesis would shed new light on the overall field of dispositional mindfulness studies. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2023-11-02T00:00:00+00:00",
      "source": "Clinical Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 257,
      "reading_time": 1,
      "created_at": "2025-11-13T05:20:50.342053+00:00",
      "updated_at": "2025-11-13T05:20:50.342055+00:00"
    }
  ]
}