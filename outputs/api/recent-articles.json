{
  "last_updated": "2026-01-28T05:30:36.120893+00:00",
  "count": 20,
  "articles": [
    {
      "id": "a0db57542fb18f125a514976d2bfb0e6",
      "url": "https://arxiv.org/abs/2601.19203",
      "title": "Before Smelling the Video: A Two-Stage Pipeline for Interpretable Video-to-Scent Plans",
      "content": "arXiv:2601.19203v1 Announce Type: new \nAbstract: Olfactory cues can enhance immersion in interactive media, yet smell remains rare because it is difficult to author and synchronize with dynamic video. Prior olfactory interfaces rely on designer triggers and fixed event-to-odor mappings that do not scale to unconstrained content. This work examines whether semantic planning for smell is intelligible to people before physical scent delivery. We present a video-to-scent planning pipeline that separates visual semantic extraction using a vision-language model from semantic-to-olfactory inference using a large language model. Two survey studies compare system-generated scent plans with over-inclusive and naive baselines. Results show consistent preference for plans that prioritize perceptually salient cues and align scent changes with visible actions, supporting semantic planning as a foundation for future olfactory media systems.",
      "author": "Kaicheng Wang, Kevin Zhongyang Shao, Ruiqi Chen, Sep Makhsous, Denise Wilson",
      "published_date": "2026-01-28T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 126,
      "reading_time": 1,
      "created_at": "2026-01-28T05:30:17.629971+00:00",
      "updated_at": "2026-01-28T05:30:17.629973+00:00"
    },
    {
      "id": "a2159aa9d53c7b702cdde7ae9399281d",
      "url": "https://arxiv.org/abs/2601.19171",
      "title": "Bridging Gulfs in UI Generation through Semantic Guidance",
      "content": "arXiv:2601.19171v1 Announce Type: new \nAbstract: While generative AI enables high-fidelity UI generation from text prompts, users struggle to articulate design intent and evaluate or refine results-creating gulfs of execution and evaluation. To understand the information needed for UI generation, we conducted a thematic analysis of UI prompting guidelines, identifying key design semantics and discovering that they are hierarchical and interdependent. Leveraging these findings, we developed a system that enables users to specify semantics, visualize relationships, and extract how semantics are reflected in generated UIs. By making semantics serve as an intermediate representation between human intent and AI output, our system bridges both gulfs by making requirements explicit and outcomes interpretable. A comparative user study suggests that our approach enhances users' perceived control over intent expression, outcome interpretation, and facilitates more predictable, iterative refinement. Our work demonstrates how explicit semantic representation enables systematic and explainable exploration of design possibilities in AI-driven UI design.",
      "author": "Seokhyeon Park, Soohyun Lee, Eugene Choi, Hyunwoo Kim, Minkyu Kweon, Yumin Song, Jinwook Seo",
      "published_date": "2026-01-28T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 152,
      "reading_time": 1,
      "created_at": "2026-01-28T05:30:17.629946+00:00",
      "updated_at": "2026-01-28T05:30:17.629947+00:00"
    },
    {
      "id": "a264ff33e71755d36f2409e03e7ea8bf",
      "url": "https://arxiv.org/abs/2601.19168",
      "title": "Nonvisual Support for Understanding and Reasoning about Data Structures",
      "content": "arXiv:2601.19168v1 Announce Type: new \nAbstract: Blind and visually impaired (BVI) computer science students face systematic barriers when learning data structures: current accessibility approaches typically translate diagrams into alternative text, focusing on visual appearance rather than preserving the underlying structure essential for conceptual understanding. More accessible alternatives often do not scale in complexity, cost to produce, or both. Motivated by a recent shift to tools for creating visual diagrams from code, we propose a solution that automatically creates accessible representations from structural information about diagrams. Based on a Wizard-of-Oz study, we derive design requirements for an automated system, Arboretum, that compiles text-based diagram specifications into three synchronized nonvisual formats$\\unicode{x2013}$tabular, navigable, and tactile. Our evaluation with BVI users highlights the strength of tactile graphics for complex tasks such as binary search; the benefits of offering multiple, complementary nonvisual representations; and limitations of existing digital navigation patterns for structural reasoning. This work reframes access to data structures by preserving their structural properties. The solution is a practical system to advance accessible CS education.",
      "author": "Brianna L. Wimer, Ritesh Kanchi, Kaija Frierson, Venkatesh Potluri, Ronald Metoyer, Jennifer Mankoff, Miya Natsuhara, Matt X. Wang",
      "published_date": "2026-01-28T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 170,
      "reading_time": 1,
      "created_at": "2026-01-28T05:30:17.629918+00:00",
      "updated_at": "2026-01-28T05:30:17.629920+00:00"
    },
    {
      "id": "6be222c654b5355c1e67265992be93cd",
      "url": "https://arxiv.org/abs/2601.19143",
      "title": "Grand Challenges around Designing Computers' Control Over Our Bodies",
      "content": "arXiv:2601.19143v1 Announce Type: new \nAbstract: Advances in emerging technologies, such as on-body mechanical actuators and electrical muscle stimulation, have allowed computers to take control over our bodies. This presents opportunities as well as challenges, raising fundamental questions about agency and the role of our bodies when interacting with technology. To advance this research field as a whole, we brought together expert perspectives in a week-long seminar to articulate the grand challenges that should be tackled when it comes to the design of computers' control over our bodies. These grand challenges span technical, design, user, and ethical aspects. By articulating these grand challenges, we aim to begin initiating a research agenda that positions bodily control not only as a technical feature but as a central, experiential, and ethical concern for future human-computer interaction endeavors.",
      "author": "Florian 'Floyd' Mueller, Nadia Bianchi-Berthouze, Misha Sra, Mar Gonzalez-Franco, Henning Pohl, Susanne Boll, Richard Byrne, Arthur Caetano, Masahiko Inami, Jarrod Knibbe, Per Ola Kristensson, Xiang Li, Zhuying Li, Joe Marshall, Louise Petersen Matjeka, Minna Nygren, Rakesh Patibanda, Sara Price, Harald Reiterer, Aryan Saini, Oliver Schneider, Ambika Shahu, J\\\"urgen Steimle, Phoebe O. Toups Dugas, Don Samitha Elvitigala",
      "published_date": "2026-01-28T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 133,
      "reading_time": 1,
      "created_at": "2026-01-28T05:30:17.629889+00:00",
      "updated_at": "2026-01-28T05:30:17.629891+00:00"
    },
    {
      "id": "32552b1bca23666071114140a86cdfd2",
      "url": "https://arxiv.org/abs/2601.19053",
      "title": "From Answer Givers to Design Mentors: Guiding LLMs with the Cognitive Apprenticeship Model",
      "content": "arXiv:2601.19053v1 Announce Type: new \nAbstract: Design feedback helps practitioners improve their artifacts while also fostering reflection and design reasoning. Large Language Models (LLMs) such as ChatGPT can support design work, but often provide generic, one-off suggestions that limit reflective engagement. We investigate how to guide LLMs to act as design mentors by applying the Cognitive Apprenticeship Model, which emphasizes demonstrating reasoning through six methods: modeling, coaching, scaffolding, articulation, reflection, and exploration. We operationalize these instructional methods through structured prompting and evaluate them in a within-subjects study with data visualization practitioners. Participants interacted with both a baseline LLM and an instructional LLM designed with cognitive apprenticeship prompts. Surveys, interviews, and conversational log analyses compared experiences across conditions. Our findings show that cognitively informed prompts elicit deeper design reasoning and more reflective feedback exchanges, though the baseline is sometimes preferred depending on task types or experience levels. We distill design considerations for AI-assisted feedback systems that foster reflective practice.",
      "author": "Yongsu Ahn, Lejun R Liao, Benjamin Bach, Nam Wook Kim",
      "published_date": "2026-01-28T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 157,
      "reading_time": 1,
      "created_at": "2026-01-28T05:30:17.629862+00:00",
      "updated_at": "2026-01-28T05:30:17.629864+00:00"
    },
    {
      "id": "4b277fe280950cf51b4752bf179f0d69",
      "url": "https://arxiv.org/abs/2601.19021",
      "title": "Listening before Asking: Lived-Experience Advisors as Methodological Partners in Dementia Caregiving Studies",
      "content": "arXiv:2601.19021v1 Announce Type: new \nAbstract: Research with dementia caregivers poses persistent methodological and ethical challenges, particularly when interview-based studies are designed without sufficient grounding in lived caregiving realities. Questions framed through clinical or deficit-oriented assumptions risk alienating participants, undermining rapport, and producing shallow or ethically fraught data. While human-computer interaction (HCI) research increasingly adopts participatory approaches in technology design, participation rarely extends to the design of research methods themselves. This paper examines the role of lived-experience advisors as methodological partners in caregiver interview research. We report on a qualitative study in which two advisors with extensive dementia caregiving experience were engaged prior to fieldwork as methodological partners, extending participatory principles beyond technology design into the design of research methods themselves. Drawing on transcripts of advisor consultations and subsequent interviews with ten caregivers and one person living with dementia, we identify two key methodological contributions of advisor involvement. First, advisors enabled anticipatory validity by surfacing caregiving challenges, ethical sensitivities, and interpretive concerns that later appeared in caregiver interviews, allowing the researcher to enter the field with grounded awareness under constrained recruitment and fieldwork conditions. Second, advisors provided cultural, emotional, and systemic context that improved interpretive sensitivity and helped avoid misreadings. We argue that lived experience functions as methodological infrastructure, extending participatory principles into the design and conduct of research itself, and constituting a generalizable methodological pattern for HCI research with caregivers and other vulnerable or marginalized populations.",
      "author": "Joy Lai, Kelly Beaton, David Black, Alex Mihailidis",
      "published_date": "2026-01-28T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 236,
      "reading_time": 1,
      "created_at": "2026-01-28T05:30:17.629834+00:00",
      "updated_at": "2026-01-28T05:30:17.629835+00:00"
    },
    {
      "id": "ce589947e7bf4c4d457a9392c193bbe1",
      "url": "https://arxiv.org/abs/2601.18979",
      "title": "XR Design Framework for Early Childhood Education",
      "content": "arXiv:2601.18979v1 Announce Type: new \nAbstract: Extended Reality in early childhood education presents high-risk challenges due to children's rapid developmental changes. While augmented and virtual reality offer immersive pedagogical benefits, they often impose excessive cognitive load or sensory conflict. We introduce the Augmented Human Development (AHD) framework to model these interactions through cognitive, sensory, environmental, and developmental parameters. To ground this framework, we conducted a Systematization of Knowledge (SoK) of 111 peer-reviewed studies involving children aged 3 - 8. Our findings, interpreted through the AHD lens, reveal a critical \"risk vs. attention gap,\" where high-impact safety and security risks remain under-researched compared to short-term pedagogical gains.",
      "author": "Supriya Khadka, Sanchari Das",
      "published_date": "2026-01-28T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 105,
      "reading_time": 1,
      "created_at": "2026-01-28T05:30:17.629797+00:00",
      "updated_at": "2026-01-28T05:30:17.629799+00:00"
    },
    {
      "id": "4344607614d544cf6090e5f986d26ad4",
      "url": "https://arxiv.org/abs/2601.18975",
      "title": "HumanoidTurk: Expanding VR Haptics with Humanoids for Driving Simulations",
      "content": "arXiv:2601.18975v1 Announce Type: new \nAbstract: We explore how humanoid robots can be repurposed as haptic media, extending beyond their conventional role as social, assistive, collaborative agents. To illustrate this approach, we implemented HumanoidTurk, taking a first step toward a humanoid-based haptic system that translates in-game g-force signals into synchronized motion feedback in VR driving. A pilot study involving six participants compared two synthesis methods, leading us to adopt a filter-based approach for smoother and more realistic feedback. A subsequent study with sixteen participants evaluated four conditions: no-feedback, controller, humanoid+controller, and human+controller. Results showed that humanoid feedback enhanced immersion, realism, and enjoyment, while introducing moderate costs in terms of comfort and simulation sickness. Interviews further highlighted the robot's consistency and predictability in contrast to the adaptability of human feedback. From these findings, we identify fidelity, adaptability, and versatility as emerging themes, positioning humanoids as a distinct haptic modality for immersive VR.",
      "author": "DaeHo Lee, Ryo Suzuki, Jin-Hyuk Hong",
      "published_date": "2026-01-28T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 150,
      "reading_time": 1,
      "created_at": "2026-01-28T05:30:17.629772+00:00",
      "updated_at": "2026-01-28T05:30:17.629774+00:00"
    },
    {
      "id": "5c59d046a869ad3ede36691dc553f62f",
      "url": "https://arxiv.org/abs/2601.18966",
      "title": "People Can Accurately Predict Behavior of Complex Algorithms That Are Available, Compact, and Aligned",
      "content": "arXiv:2601.18966v1 Announce Type: new \nAbstract: Users trust algorithms more when they can predict the algorithms' behavior. Simple algorithms trivially yield predictively accurate mental models, but modern AI algorithms have often been assumed too complex for people to build predictive mental models, especially in the social media domain. In this paper, we describe conditions under which even complex algorithms can yield predictive mental models, opening up opportunities for a broader set of human-centered algorithms. We theorize that users will form an accurate predictive mental model of an algorithm's behavior if and only if the algorithm simultaneously satisfies three criteria: (1) cognitive availability of the underlying concepts being modeled, (2) concept compactness (does it form a single cognitive construct?), and (3) high alignment between the person's and algorithm's execution of the concept. We evaluate this theory through a pre-registered experiment (N=1250) where users predict behavior of 25 social media feed ranking algorithms that vary on these criteria. We find that even complex (e.g., LLM-based) algorithms enjoy accurate prediction rates when they meet all criteria, and even simple (e.g., basic term count) algorithms fail to be predictable when a single criterion fails. We also find that these criteria determine outcomes beyond prediction accuracy, such as which mental models users deploy to make their predictions.",
      "author": "Lindsay Popowski, Helena Vasconcelos, Ignacio Javier Fernandez, Chijioke Chinaza Mgbahurike, Ralf Herbrich, Jeffrey Hancock, Michael S. Bernstein",
      "published_date": "2026-01-28T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 211,
      "reading_time": 1,
      "created_at": "2026-01-28T05:30:17.629743+00:00",
      "updated_at": "2026-01-28T05:30:17.629744+00:00"
    },
    {
      "id": "f5b69a2e3ffe40a7abfa772c84049f6b",
      "url": "https://arxiv.org/abs/2601.18934",
      "title": "Whispering Water: Materializing Human-AI Dialogue as Interactive Ripples",
      "content": "arXiv:2601.18934v1 Announce Type: new \nAbstract: Across cultures, water has served as a recipient of human confession, a yielding medium that receives vulnerability where rigid surfaces cannot. We present Whispering Water, an interactive installation that materializes human-AI dialogue through cymatic patterns on water. Participants confess secrets to a water surface, triggering a four-phase ritual: confession, contemplation, response, and release. The user's speech sentiment is directly transmitted into the water to prime its state, while semantic content enters a multi-agent system, initiating ripples of conversation where agent identities are situated through discourse and voice profiles are chosen based on what they say. We propose a novel algorithm that decomposes speech into component waves and reconstructs them in water, establishing a translation between speech and the physics of material form. By rendering machine reasoning as emergent physical phenomena, the installation explores possibilities for emotional self-exploration through ambiguous, sensory-rich interfaces.",
      "author": "Ruipeng Wang, Tawab Safi, Yunge Wen, Christina Cunningham, Hoi Ling Tang, Behnaz Farahi",
      "published_date": "2026-01-28T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 146,
      "reading_time": 1,
      "created_at": "2026-01-28T05:30:17.629702+00:00",
      "updated_at": "2026-01-28T05:30:17.629706+00:00"
    },
    {
      "id": "d265fa37031b644ef5c62a28f3553db7",
      "url": "https://arxiv.org/abs/2507.14056",
      "title": "Noradrenergic-inspired gain modulation attenuates the stability gap in joint training",
      "content": "arXiv:2507.14056v2 Announce Type: replace-cross \nAbstract: Recent work in continual learning has highlighted the stability gap -- a temporary performance drop on previously learned tasks when new ones are introduced. This phenomenon reflects a mismatch between rapid adaptation and strong retention at task boundaries, underscoring the need for optimization mechanisms that balance plasticity and stability over abrupt distribution changes. While optimizers such as momentum-SGD and Adam introduce implicit multi-timescale behavior, they still exhibit pronounced stability gaps. Importantly, these gaps persist even under ideal joint training, making it crucial to study them in this setting to isolate their causes from other sources of forgetting. Motivated by how noradrenergic (neuromodulatory) bursts transiently increase neuronal gain under uncertainty, we introduce a dynamic gain scaling mechanism as a two-timescale optimization technique that balances adaptation and retention by modulating effective learning rates and flattening the local landscape through an effective reparameterization. Across domain- and class-incremental MNIST, CIFAR, and mini-ImageNet benchmarks under task-agnostic joint training, dynamic gain scaling effectively attenuates stability gaps while maintaining competitive accuracy, improving robustness at task transitions.",
      "author": "Alejandro Rodriguez-Garcia, Anindya Ghosh, Srikanth Ramaswamy",
      "published_date": "2026-01-28T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 174,
      "reading_time": 1,
      "created_at": "2026-01-28T05:30:16.549642+00:00",
      "updated_at": "2026-01-28T05:30:16.549644+00:00"
    },
    {
      "id": "3594cb018331cce38495999e77fc277a",
      "url": "https://arxiv.org/abs/2601.11018",
      "title": "KOCOBrain: Kuramoto-Guided Graph Network for Uncovering Structure-Function Coupling in Adolescent Prenatal Drug Exposure",
      "content": "arXiv:2601.11018v2 Announce Type: replace \nAbstract: Exposure to psychoactive substances during pregnancy, such as cannabis, can disrupt neurodevelopment and alter large-scale brain networks, yet identifying their neural signatures remains challenging. We introduced KOCOBrain: KuramotO COupled Brain Graph Network; a unified graph neural network framework that integrates structural and functional connectomes via Kuramoto-based phase dynamics and cognition-aware attention. The Kuramoto layer models neural synchronization over anatomical connections, generating phase-informed embeddings that capture structure-function coupling, while cognitive scores modulate information routing in a subject-specific manner followed by a joint objective enhancing robustness under class imbalance scenario. Applied to the ABCD cohort, KOCOBrain improved prenatal drug exposure prediction over relevant baselines and revealed interpretable structure-function patterns that reflect disrupted brain network coordination associated with early exposure.",
      "author": "Badhan Mazumder, Lei Wu, Sir-Lord Wiafe, Vince D. Calhoun, Dong Hye Ye",
      "published_date": "2026-01-28T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 122,
      "reading_time": 1,
      "created_at": "2026-01-28T05:30:16.549614+00:00",
      "updated_at": "2026-01-28T05:30:16.549616+00:00"
    },
    {
      "id": "b370fbd652ceb8f94e0d103f40694c19",
      "url": "https://arxiv.org/abs/2506.11062",
      "title": "Decoding Cortical Microcircuits: A Generative Model for Latent Space Exploration and Controlled Synthesis",
      "content": "arXiv:2506.11062v2 Announce Type: replace \nAbstract: A central idea in understanding brains and building artificial intelligence is that structure determines function. Yet, how the brain's complex structure arises from a limited set of genetic instructions remains a key question. The ultra high-dimensional detail of neural connections vastly exceeds the information storage capacity of genes, suggesting a compact, low-dimensional blueprint must guide brain development. Our motivation is to uncover this blueprint. We introduce a generative model, to learn this underlying representation from detailed connectivity maps of mouse cortical microcircuits. Our model successfully captures the essential structural information of these circuits in a compressed latent space. We found that specific, interpretable directions within this space directly relate to understandable network properties. Building on this, we demonstrate a novel method to controllably generate new, synthetic microcircuits with desired structural features by navigating this latent space. This work offers a new way to investigate the design principles of neural circuits and explore how structure gives rise to function, potentially informing the development of more advanced artificial neural networks.",
      "author": "Xingyu Liu, Yubin Li, Guozhang Chen",
      "published_date": "2026-01-28T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 173,
      "reading_time": 1,
      "created_at": "2026-01-28T05:30:16.549589+00:00",
      "updated_at": "2026-01-28T05:30:16.549590+00:00"
    },
    {
      "id": "914af1378a412bea090a32f4fda6547c",
      "url": "https://arxiv.org/abs/2412.00008",
      "title": "The Copernican Argument for Alien Consciousness; The Mimicry Argument Against Robot Consciousness",
      "content": "arXiv:2412.00008v3 Announce Type: replace \nAbstract: On broadly Copernican grounds, we are entitled to assume that apparently behaviorally sophisticated extraterrestrial entities (\"aliens\") would be conscious. Otherwise, we humans would be inexplicably, implausibly lucky to have consciousness, while similarly behaviorally sophisticated entities elsewhere would be mere shells, devoid of consciousness. However, this Copernican default assumption is canceled in the case of behaviorally sophisticated entities designed to mimic superficial features associated with consciousness (\"consciousness mimics\"), and in particular a broad class of current, near-future, and hypothetical robots. These considerations, which we formulate, respectively, as the Copernican and Mimicry Arguments, jointly defeat an otherwise potentially attractive parity principle, according to which we should apply the same types of behavioral or cognitive tests to aliens and robots, attributing or denying consciousness similarly to the extent they perform similarly. Our approach is unusual in the following respect: Instead of grounding speculations about alien and robot consciousness in a particular metaphysical or scientific theory about the physical or functional bases of consciousness, we appeal directly to the epistemic principles of Copernican mediocrity and inference to the best explanation.",
      "author": "Eric Schwitzgebel, Jeremy Pober",
      "published_date": "2026-01-28T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 181,
      "reading_time": 1,
      "created_at": "2026-01-28T05:30:16.549560+00:00",
      "updated_at": "2026-01-28T05:30:16.549561+00:00"
    },
    {
      "id": "5748fa97a6e8abfeac952bc60f8cf085",
      "url": "https://arxiv.org/abs/2601.19125",
      "title": "Stroboscopic motion reversals in delay-coupled neural fields",
      "content": "arXiv:2601.19125v1 Announce Type: new \nAbstract: Visual illusions provide a window into the mechanisms underlying visual processing, and dynamical neural circuit models offer a natural framework for proposing and testing theories of their emergence. We propose and analyze a delay-coupled neural field model that explains stroboscopic percepts arising from the subsampling of a moving, often rotating, stimulus, such as the wagon-wheel illusion. Motivated by the role of activity propagation delays in shaping visual percepts, we study neural fields with both uniform and spatially dependent delays, representing the finite time required for signals to travel along axonal projections. Each module is organized as a ring of neurons encoding angular preference, with instantaneous local coupling and delayed long-range coupling strongest between neurons with similar preference. We show that delays generate a family of coexisting traveling bump solutions with distinct, quantized propagation speeds. Using interface-based asymptotic methods, we reduce the neural field dynamics to a low-dimensional system of coupled delay differential equations, enabling a detailed analysis of speed selection, stability, entrainment, and state transitions. Regularly pulsed inputs induce transitions between distinct speed states, including motion opposite to the forcing direction, capturing key features of visual aliasing and stroboscopic motion reversal. These results demonstrate how delayed neural interactions organize perception into discrete dynamical states and provide a mechanistic explanation for stroboscopic visual illusions.",
      "author": "Noah Parks, Zachary P Kilpatrick",
      "published_date": "2026-01-28T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 218,
      "reading_time": 1,
      "created_at": "2026-01-28T05:30:16.549530+00:00",
      "updated_at": "2026-01-28T05:30:16.549531+00:00"
    },
    {
      "id": "e7c478a1a1710c2be5757473fbaf1fac",
      "url": "https://arxiv.org/abs/2601.19019",
      "title": "Smooth embeddings in contracting recurrent networks driven by regular dynamics: A synthesis for neural representation",
      "content": "arXiv:2601.19019v1 Announce Type: new \nAbstract: Recurrent neural networks trained for time-series prediction often develop latent trajectories that preserve qualitative structure of the dynamical systems generating their inputs. Recent empirical work has documented topology-preserving latent organization in trained recurrent models, and recent theoretical results in reservoir computing establish conditions under which the synchronization map is an embedding. Here we synthesize these threads into a unified account of when contracting recurrent networks yield smooth, topology-preserving internal representations for a broad and biologically relevant class of inputs: regular dynamics on invariant circles and tori.\n  Our contribution is an integrated framework that assembles (i) generalized synchronization and embedding guarantees for contracting reservoirs, (ii) regularity mechanisms ensuring differentiability of the synchronization map under mild constraints, and (iii) a base-system viewpoint in which the invariant manifold generating the input stream is treated as the driving system. In this regular setting, the conditions commonly viewed as restrictive in chaotic-attractor analyses become mild and readily satisfied by standard contractive architectures. The framework clarifies how representational content in recurrent circuits is inherently historical: the network state encodes finite windows of input history rather than instantaneous stimuli.\n  By consolidating disparate empirical and theoretical results under common assumptions, the synthesis yields concrete, testable expectations about when prediction-trained recurrent circuits should (or should not) form smooth latent embeddings and how required state dimension scales with the intrinsic dimension of the driving dynamics.",
      "author": "Vikas N. O'Reilly-Shah, Alessandro Maria Selvitella",
      "published_date": "2026-01-28T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 230,
      "reading_time": 1,
      "created_at": "2026-01-28T05:30:16.549496+00:00",
      "updated_at": "2026-01-28T05:30:16.549498+00:00"
    },
    {
      "id": "2ca9b3d3f2a21d8e296733a4e26691d7",
      "url": "https://arxiv.org/abs/2601.18946",
      "title": "Schema-based active inference supports rapid generalization of experience and frontal cortical coding of abstract structure",
      "content": "arXiv:2601.18946v1 Announce Type: new \nAbstract: Schemas -- abstract relational structures that capture the commonalities across experiences -- are thought to underlie humans' and animals' ability to rapidly generalize knowledge, rebind new experiences to existing structures, and flexibly adapt behavior across contexts. Despite their central role in cognition, the computational principles and neural mechanisms supporting schema formation and use remain elusive. Here, we introduce schema-based hierarchical active inference (S-HAI), a novel computational framework that combines predictive processing and active inference with schema-based mechanisms. In S-HAI, a higher-level generative model encodes abstract task structure, while a lower-level model encodes spatial navigation, with the two levels linked by a grounding likelihood that maps abstract goals to physical locations. Through a series of simulations, we show that S-HAI reproduces key behavioral signatures of rapid schema-based generalization in spatial navigation tasks, including the ability to flexibly remap abstract schemas onto novel contexts, resolve goal ambiguity, and balance reuse versus accommodation of novel mappings. Crucially, S-HAI also reproduces prominent neural codes reported in rodent medial prefrontal cortex during a schema-dependent navigation and decision task, including task-invariant goal-progress cells, goal-identity cells, and goal-and-spatially conjunctive cells, as well as place-like codes at the lower level. Taken together, these results provide a mechanistic account of schema-based learning and inference that bridges behavior, neural data, and theory. More broadly, our findings suggest that schema formation and generalization may arise from predictive processing principles implemented hierarchically across cortical and hippocampal circuits, enabling the generalization of experience.",
      "author": "Toon Van de Maele, Tim Verbelen, Dileep George, Giovanni Pezzulo",
      "published_date": "2026-01-28T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 245,
      "reading_time": 1,
      "created_at": "2026-01-28T05:30:16.549448+00:00",
      "updated_at": "2026-01-28T05:30:16.549451+00:00"
    },
    {
      "id": "4e40320fbeed013239816db84a8da326",
      "url": "https://www.nature.com/articles/s41386-026-02332-2",
      "title": "The role of brain health and resilience in reshaping trajectories of late-life neuropsychiatric disorders",
      "content": "",
      "author": "",
      "published_date": "2026-01-28T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2026-01-28T05:30:06.516974+00:00",
      "updated_at": "2026-01-28T05:30:06.516975+00:00"
    },
    {
      "id": "bdd3df88a57617405445c9b93a1e6d59",
      "url": "https://www.frontiersin.org/articles/10.3389/fncom.2025.1724190",
      "title": "Measurement effects on critical scaling in neural systems",
      "content": "The recently developed phenomenological renormalization group (pRG) analysis has uncovered scale-free properties in large-scale neural population recordings across recording modalities, including extracellular electrophysiology and calcium imaging. The convergence of these properties across the datasets hints at universal neural behavior. Yet, it is unknown how differences in temporal resolution and measurement details affect pRG scaling. Here, we use a network model known to produce scaling under pRG analysis as a testbed to assess how recording and analysis choices shape inferred scaling exponents. We show that scaling properties depend on the choices of temporal binning, measurement nonlinearities, and deconvolution, and that the quality of scaling for cluster covariance eigenvalues is particularly sensitive to measurement effects. Moreover, all scaling exponents shift substantially with these transformations, even when the underlying neural dynamics are identical. Together, these results show how experimental choices can change pRG scaling and provide a framework for separating scaling driven by neural dynamics from that introduced by the recording method.",
      "author": "Audrey J. Sederberg",
      "published_date": "2026-01-23T00:00:00+00:00",
      "source": "Frontiers Computational Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 159,
      "reading_time": 1,
      "created_at": "2026-01-28T05:29:58.288408+00:00",
      "updated_at": "2026-01-28T05:29:58.288410+00:00"
    },
    {
      "id": "a2e3ae6917a666e458c015811c68a33a",
      "url": "https://www.frontiersin.org/articles/10.3389/fncom.2026.1750926",
      "title": "Causal links between serotonin dynamics and cued fear learning: evidence from experimental studies",
      "content": "Serotonin is thought to regulate emotional learning and memory, but there remains much to be explored regarding its causal role in cued fear conditioning and extinction (CFC-E). Recent in vivo recording of dorsal raphe nucleus serotonin neuronal activity during CFC-E paradigm showed that the time course of serotonin level includes both rapid responses to conditioned and unconditioned stimuli and a slowly accumulating component that spans inter-trial intervals and reverses during extinction. By reviewing the studies that directly link the fear expression during CFC-E to the acute or chronic perturbations of serotonin dynamics at the organism level or within specific brain areas via pharmacological, genetic, and projection-specific manipulations, we argue that theoretical models defining the causal role of serotonin must incorporate continuous-time serotonin dynamics.",
      "author": "Taegon Kim",
      "published_date": "2026-01-23T00:00:00+00:00",
      "source": "Frontiers Computational Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 123,
      "reading_time": 1,
      "created_at": "2026-01-28T05:29:58.288378+00:00",
      "updated_at": "2026-01-28T05:29:58.288380+00:00"
    }
  ]
}