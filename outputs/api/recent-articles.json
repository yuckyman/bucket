{
  "last_updated": "2026-01-22T04:51:17.019265+00:00",
  "count": 20,
  "articles": [
    {
      "id": "ef3bbfc6af0a84792da3c36ea1533ce3",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.17.700104v1?rss=1",
      "title": "Agomelatine drives sex-specific neuroprotection and reduced pathology in rat and human Alzheimer's models",
      "content": "Alzheimer's disease (AD) remains without effective disease-modifying therapies, underscoring the need for interventions that target interconnected molecular and cellular processes driving cognitive decline. Leveraging a cross-species translational framework integrating a progressive rat model of Alzheimer's disease with human iPSC-derived neurons carrying familial AD mutations, we identify agomelatine (AGO) as a disease-modifying candidate. A clinically used melatonergic agonist and 5-HT2C serotonergic antagonist, we found that AGO acts as a sex-selective modulator of AD-related neuronal and microglial dysfunction with therapeutic relevance across species. TgF344-AD rats and their wildtype littermates received chronic dietary AGO ({approx}10 mg/kg/day) from 5 to 11 months of age and underwent hippocampal-dependent spatial learning assessment, quantitative hippocampal histopathology, and bulk RNA sequencing to evaluate the therapeutic effect on cognition, pathology, and molecular mechanisms. Human isogenic iPSC-derived cortical neurons carrying PSEN2N141I or APPV717I mutations were treated with 20 M AGO followed by bulk RNA sequencing, to define AGO-driven transcriptional pathway modulation in AD neurons. In TgF344-AD rats, AGO produced robust female-specific benefits. AGO selectively restored hippocampal-dependent cognitive performance in female but not male transgenic rats. These improvements were independent of amyloid burden and instead aligned with reductions in microgliosis and pathogenic AT8-positive tau phosphorylation. Additionally, AGO normalized reactive and amoeboid microglial states exclusively in females and enhanced doublecortin-defined neurogenesis without altering mature NeuN neuronal density. This coordinated hippocampal stabilization highlights AGO's capacity to restore plasticity rather than simply suppress pathology. Transcriptomic analyses revealed sex-divergent mechanisms underlying these effects. In females, AGO activated metabolic, oxygen-handling, lipid-processing, neuroimmune, and CREB/IGF-1 signaling pathways while suppressing ER-stress, epigenetic, and ion-channel transcripts, changes consistent with resilience-promoting cellular reprogramming. In males, AGO preferentially modulated mitochondrial redox biology, transcriptional regulators, and extracellular matrix components. Despite these differences, both sexes showed AGO-induced engagement of conserved AD-relevant pathways, including shared induction of synaptic plasticity and hemoglobin/oxygen-transport related genes, suggesting a convergent neuroprotective molecular signature. To translate these findings to a human system, we examined AGO's effects in PSEN2N141I and APPV717I iPSC-derived cortical neurons. Both mutations produced convergent deficits in synaptic integrity, neuronal maturity, trophic signaling, proteostasis, metabolism, and excitability, alongside dysregulated developmental and ECM-remodeling programs. AGO partially reversed these pathogenic transcriptional changes, up-regulating synaptic, metabolic, vesicle-trafficking, and redox-stress resilience genes while suppressing pathological developmental and inflammatory pathways, demonstrating conserved engagement of neuronal recovery programs. Together, these results identify AGO as a promising non-amyloid therapeutic candidate capable of modulating AD-relevant pathways in rodents and human models. The sex-selective efficacy observed in vivo, combined with conserved transcriptional responses across species, underscores the translational relevance of AGO-driven molecular reprogramming in AD.",
      "author": "Terry, G. A., Aziz, S., Raihana, N., Xie, L., Rockwell, P., Serrano, P. A., Figueiredo-Pereira, M. E.",
      "published_date": "2026-01-21T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 419,
      "reading_time": 2,
      "created_at": "2026-01-22T04:50:47.022511+00:00",
      "updated_at": "2026-01-22T04:50:47.022515+00:00"
    },
    {
      "id": "c89d2ad698747e7dcffde4a37776f9ab",
      "url": "https://www.nature.com/articles/s41593-025-02191-y",
      "title": "Rethinking the role of position in cortical function",
      "content": "<p>Nature Neuroscience, Published online: 08 January 2026; <a href=\"https://www.nature.com/articles/s41593-025-02191-y\">doi:10.1038/s41593-025-02191-y</a></p>Abnormally located cortical neurons, displaced in developing mice lacking cortical Eml1, retain their molecular identities, form appropriate connections and build functional sensory maps. Most strikingly, these misplaced neurons can drive behavior by themselves \u2014 showing that brain function depends on how neurons connect, and to what, more than where they live.",
      "author": "",
      "published_date": "2026-01-08T00:00:00+00:00",
      "source": "Nature Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 59,
      "reading_time": 1,
      "created_at": "2026-01-22T04:50:44.472494+00:00",
      "updated_at": "2026-01-22T04:50:44.472496+00:00"
    },
    {
      "id": "704e93957179c44d936aeac519f265d0",
      "url": "https://www.frontiersin.org/articles/10.3389/fncom.2025.1737839",
      "title": "Bridging neuromorphic computing and deep learning for next-generation neural data interpretation",
      "content": "",
      "author": "Zhiyuan Zhu",
      "published_date": "2026-01-08T00:00:00+00:00",
      "source": "Frontiers Computational Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2026-01-22T04:50:37.803465+00:00",
      "updated_at": "2026-01-22T04:50:37.803466+00:00"
    },
    {
      "id": "cb985508c82ff275099651880c945849",
      "url": "https://iopscience.iop.org/article/10.1088/1741-2552/ae2e8c",
      "title": "Neuropacify: a method to transform and match a patient\u2019s intracranial EEG to their NeuroPace RNS system data",
      "content": "Objective. Closed-loop responsive neurostimulators, such as the NeuroPace responsive neurostimulation (RNS) system, continuously monitor brain activity and deliver electrical stimulation in response to abnormal electrographic activity in patients with drug-resistant epilepsy. Practical technical constraints limit the temporal resolution of these devices, reducing the quality of EEG recordings. Approach. In this work, we introduce a novel technique to convert high-resolution intracranial electroencephalography (iEEG) obtained from inpatient monitoring into the same format, parameters, and resolution produced by the RNS system, allowing direct comparison of iEEG with RNS system data. We validated this technique using data from patients who had both iEEG and RNS. Electrodes from the iEEG and RNS system were co-registered onto the same 3D coordinate grid, and vector math was applied to determine the iEEG electrodes closest to the operational RNS electrodes. Main results. Through spectral analysis, we derived a transfer function that accounts for all filtering and data processing produced by the RNS system. Comparison of the recorded data using visual and spectral analysis from iEEG and RNS confirmed that EEG characteristics were correctly transformed by the filtering function, allowing analysis of how iEEG signals would appear within the RNS system. We demonstrate two examples from the extreme edges of the spectra, showing how DC shifts and high frequency oscillations would be transformed by the RNS. We provide a tutorial to tune this method to local device parameters, a process that can be applied to other devices as well. Significance. This tool allows researchers and clinicians to extract EEG biomarkers from high-resolution iEEG and determine if/how they can be detected in lower-resolution RNS. This provides an opportunity to develop patient-specific seizure detection parameters and investigate the long-term effects of neurostimulation therapy.",
      "author": "Grant Barkelew, Kathleen Kish, Zachary T Sanger, Raghav Varshney, Sarah Dykstra, David Brang, Theoden I Netoff and William C Stacey",
      "published_date": "2026-01-08T00:00:00+00:00",
      "source": "Journal Neural Engineering",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 282,
      "reading_time": 1,
      "created_at": "2026-01-22T04:50:30.921405+00:00",
      "updated_at": "2026-01-22T04:50:30.921406+00:00"
    },
    {
      "id": "607713e2d7916743f5ac5058e609c98a",
      "url": "https://news.ycombinator.com/item?id=46705676",
      "title": "Tell HN: 2 years building a kids audio app as a solo dev \u2013 lessons learned",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46705676\">Comments</a>",
      "author": "",
      "published_date": "2026-01-21T13:49:07+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-22T04:50:04.934290+00:00",
      "updated_at": "2026-01-22T04:50:04.934291+00:00"
    },
    {
      "id": "2659c00bf48a6f98d6a4bca7266f1da9",
      "url": "https://huggingface.co/sweepai/sweep-next-edit-1.5B",
      "title": "Show HN: Sweep, Open-weights 1.5B model for next-edit autocomplete",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46713106\">Comments</a>",
      "author": "",
      "published_date": "2026-01-21T23:22:40+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-22T04:50:04.934133+00:00",
      "updated_at": "2026-01-22T04:50:04.934135+00:00"
    },
    {
      "id": "2659c00bf48a6f98d6a4bca7266f1da9",
      "url": "https://huggingface.co/sweepai/sweep-next-edit-1.5B",
      "title": "Show HN: Sweep, Open-weights 1.5B model for next-edit autocomplete",
      "content": "<p>Hey HN, we trained and open-sourced a 1.5B model that predicts your next edits, similar to Cursor. You can download the weights here (<a href=\"https://huggingface.co/sweepai/sweep-next-edit-1.5b\" rel=\"nofollow\">https://huggingface.co/sweepai/sweep-next-edit-1.5b</a>) or try it in our JetBrains plugin (<a href=\"https://plugins.jetbrains.com/plugin/26860-sweep-ai-autocomplete--coding-agent\" rel=\"nofollow\">https://plugins.jetbrains.com/plugin/26860-sweep-ai-autocomp...</a>).<p>Next-edit autocomplete differs from standard autocomplete by using your recent edits as context when predicting completions. The model is small enough to run locally while outperforming models 4x its size on both speed and accuracy.<p>We tested against Mercury (Inception), Zeta (Zed), and Instinct (Continue) across five benchmarks: next-edit above/below cursor, tab-to-jump for distant changes, standard FIM, and noisiness. We found exact-match accuracy correlates best with real usability because code is fairly precise and the solution space is small.<p>Prompt format turned out to matter more than we expected. We ran a genetic algorithm over 30+ diff formats and found simple `original`/`updated` blocks beat unified diffs. The verbose format is just easier for smaller models to understand.<p>Training was SFT on ~100k examples from permissively-licensed repos (4hrs on 8xH100), then RL for 2000 steps with tree-sitter parse checking and size regularization. The RL step fixes edge cases SFT can\u2019t like, generating code that doesn\u2019t parse or overly verbose outputs.<p>We're open-sourcing the weights so the community can build fast, privacy-preserving autocomplete for any editor. If you're building for VSCode, Neovim, or something else, we'd love to see what you make with it!</p>\n<hr />\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46713106\">https://news.ycombinator.com/item?id=46713106</a></p>\n<p>Points: 17</p>\n<p># Comments: 2</p>",
      "author": "williamzeng0",
      "published_date": "2026-01-21T23:22:40+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 234,
      "reading_time": 1,
      "created_at": "2026-01-22T04:50:03.820459+00:00",
      "updated_at": "2026-01-22T04:50:03.820461+00:00"
    },
    {
      "id": "b7eb98822f7b91927e377c5983193834",
      "url": "https://lix.dev/blog/introducing-lix/",
      "title": "Lix \u2013 universal version control system for binary files",
      "content": "<p>Article URL: <a href=\"https://lix.dev/blog/introducing-lix/\">https://lix.dev/blog/introducing-lix/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46713387\">https://news.ycombinator.com/item?id=46713387</a></p>\n<p>Points: 10</p>\n<p># Comments: 3</p>",
      "author": "onecommit",
      "published_date": "2026-01-21T23:55:06+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2026-01-22T04:50:03.820415+00:00",
      "updated_at": "2026-01-22T04:50:03.820417+00:00"
    },
    {
      "id": "898042330a0e0a0354b8995d93a19859",
      "url": "https://www.kentik.com/blog/from-stealth-blackout-to-whitelisting-inside-the-iranian-shutdown/",
      "title": "From stealth blackout to whitelisting: Inside the Iranian shutdown",
      "content": "<p>Article URL: <a href=\"https://www.kentik.com/blog/from-stealth-blackout-to-whitelisting-inside-the-iranian-shutdown/\">https://www.kentik.com/blog/from-stealth-blackout-to-whitelisting-inside-the-iranian-shutdown/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46713444\">https://news.ycombinator.com/item?id=46713444</a></p>\n<p>Points: 5</p>\n<p># Comments: 0</p>",
      "author": "oavioklein",
      "published_date": "2026-01-22T00:00:36+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2026-01-22T04:50:03.820395+00:00",
      "updated_at": "2026-01-22T04:50:03.820397+00:00"
    },
    {
      "id": "478a57a3c71b21e09918b56cf241220b",
      "url": "https://marketplace.visualstudio.com/items?itemName=xinbenlv.dotenv-mask-editor",
      "title": "Show HN: Dotenv Mask Editor: No more embarrassing screen leaks of your .env",
      "content": "<p>Hi HN,<p>I built this because I often work in coworking spaces or do screen sharing, and I've always had this fear of accidentally flashing my .env file with production secrets to the whole room (or recording).<p>It\u2019s a simple VS Code extension that opens .env files in a custom grid editor. It automatically masks any value longer than 6 characters so I can safely open the file to check keys without exposing the actual secrets.<p>It runs 100% locally with zero dependencies (I know how sensitive these files are). It just reads the file, renders the grid, and saves it back as standard text.<p>It's open source (MIT) and I'd love any feedback on the masking logic or other features that would make it safer to use.<p>Marketplace: <a href=\"https://marketplace.visualstudio.com/items?itemName=xinbenlv.dotenv-mask-editor\" rel=\"nofollow\">https://marketplace.visualstudio.com/items?itemName=xinbenlv...</a>  Github <a href=\"https://github.com/xinbenlv/dotenv-mask-editor\" rel=\"nofollow\">https://github.com/xinbenlv/dotenv-mask-editor</a></p>\n<hr />\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46713473\">https://news.ycombinator.com/item?id=46713473</a></p>\n<p>Points: 6</p>\n<p># Comments: 3</p>",
      "author": "xinbenlv",
      "published_date": "2026-01-22T00:04:47+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 142,
      "reading_time": 1,
      "created_at": "2026-01-22T04:50:03.820375+00:00",
      "updated_at": "2026-01-22T04:50:03.820377+00:00"
    },
    {
      "id": "b915afb406e73bb7a7c1832608ee2968",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.17.699936v1?rss=1",
      "title": "The amplitude and latency of the earliest signal in V1 encode bottom-up saliency by feature conjunction",
      "content": "The neural origin of bottom-up saliency for exogenous attention remains highly controversial. In this study, we investigated whether the earliest activity in the primary visual cortex (V1) encodes saliency signals defined by the eye-of-origin and feature-conjunction information. Electroencephalography (EEG) recordings from the human occipital cortex revealed early responses to eye-of-origin (E) and/or orientation (O) singletons, with larger response amplitudes to the double-feature (EO) singletons. The short onset latency (58-70 ms) and polarity reversal of the responses indicate a V1 origin. Importantly, the latency and amplitude of these responses predicted behavioral detection performance. Together, these findings suggest that the timing and amplitude of the earliest signals in V1 represent the saliency of combined feature contrasts for bottom-up attention. These signals unlikely originate from projections of other proposed source areas of saliency, due to the scarcity of necessary monocular neurons to process eye-of-origin information.",
      "author": "Wu, C., Li, X., Li, H., Wang, X., Yin, Z., Wang, Z., Zhang, P., Yang, Z., Zou, J.",
      "published_date": "2026-01-21T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 142,
      "reading_time": 1,
      "created_at": "2026-01-22T03:50:05.337222+00:00",
      "updated_at": "2026-01-22T04:43:34.915607+00:00",
      "metadata": {
        "processed_at": "2026-01-22T04:43:34.915617+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "b37601d09093bbd8cc42468419126021",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.17.700125v1?rss=1",
      "title": "From cognitive abstraction to adaptive behavior: neural bases of concept learning in autistic adolescents",
      "content": "BACKGROUND: Learned knowledge does not consistently generalize to new contexts in autistic individuals, limiting potential for adapting to real-world demands. This challenge is hypothesized to stem from difficulties with forming abstract representations, potentially arising from perceptual processing that favors local details over the gestalt. We tested the prediction that generalization would be primarily based on exemplar-specific representations in autistic youth using computational modelling coupled with neuroimaging. METHODS: Sixty-four autistic adolescents without intellectual disability (69% males; ages 14-18 years) completed a category generalization task during functional magnetic resonance imaging at two time points. Computational models estimated abstract (prototype-based) and specific (exemplar-based) representations and underlying neural correlates. We further examined associations with adaptive functioning and moderation by autistic traits. RESULTS: Contrary to predictions, we observed a consistent prototype-dominant majority, a subgroup who generalized without consistent representational reliance, and a small minority who failed to acquire category structure. Prototypes were represented in bilateral ventromedial prefrontal cortex (VMPFC), inferior parietal lobule (IPL), right frontal pole, and right lateral occipital cortex, while exemplars were represented in bilateral cuneus. Better generalization predicted better real-world adaptive functioning. Moreover, greater prototype-related activation in left IPL predicted better adaptive functioning in participants with higher autistic traits. CONCLUSIONS: These findings challenge the prevailing view that concept learning in autism relies primarily on hyper-specific perceptual processing, identify meaningful variability in representational strategies, and reveal neural pathways through which abstract representation may support real-world adaptive behavior.",
      "author": "Chen, Y., Hawkins, B., Puckett, H., Sharp, K., Lopez, A., Zeithamova, D., Xie, H., Verbalis, A., VanMeter, A. S., Gaillard, W. D., Kenworthy, L., Vaidya, C. J.",
      "published_date": "2026-01-21T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 234,
      "reading_time": 1,
      "created_at": "2026-01-22T03:50:05.337190+00:00",
      "updated_at": "2026-01-22T04:43:34.915621+00:00",
      "metadata": {
        "processed_at": "2026-01-22T04:43:34.915623+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "b33b472cdb8563c7c43c617b484ebda6",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.18.700161v1?rss=1",
      "title": "Divergent excitatory and inhibitory signaling in a head direction circuit",
      "content": "Neural cell types are often clustered into inhibitory, excitatory, or neuromodulatory populations. However, the signaling mechanism between two neurons ultimately depends on their neurotransmitter-receptor pairings. Here, we demonstrate an example of a glutamatergic population of neurons that appears to either excite or inhibit their downstream partners depending on the type of glutamate receptor expressed in the downstream cell type. The upstream population encodes a sinusoidal head direction signal. The downstream partners that are excited by glutamate encode the same signal while the downstream partners that are inhibited by glutamate encode a 180$^degree$ phase-shifted copy. The upstream population therefore appears to pass on two different phases of the same signal by making either excitatory or inhibitory connections to different downstream partners.",
      "author": "Eddy, J., Shenasa, A. H., Monroy Alfaro, P., Fernanda Viveros, M., Turner-Evans, D. B.",
      "published_date": "2026-01-21T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 120,
      "reading_time": 1,
      "created_at": "2026-01-22T03:50:05.337140+00:00",
      "updated_at": "2026-01-22T04:43:34.915625+00:00",
      "metadata": {
        "processed_at": "2026-01-22T04:43:34.915627+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "3940bc586d485dfa10ff0242facb774a",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.17.700100v1?rss=1",
      "title": "Memory erasure by dopamine-gated retrospective learning",
      "content": "Erasing outdated memories is crucial for adaptive behavior. Yet once a cue-outcome association is learned, repeated cue exposure without outcome suppresses conditioned behavior without erasing the underlying memory. This allows rapid behavioral recovery when outcomes are reintroduced. Here, we confirm this limitation for standard prospective extinction protocols that present cues without the associated outcome, but show that true memory erasure is achieved by inverting the paradigm: presenting outcomes without associated cues, i.e., retrospective extinction. We demonstrate that orbitofrontal cortex activity at outcome is necessary for the rapid behavioral recovery following prospective extinction, and that mesolimbic dopamine activity at outcome is necessary for retrospective extinction. These findings reconceptualize extinction mechanisms and suggest complementary strategies to mitigate relapse and erase maladaptive memories.",
      "author": "Jeong, H., Zsembik, L., Farouq, F., Chakraborty, R., Belur, N., Zhou, M., Sanders, A. D., Wang, S. X., Srinivasan, A., Cox, S. M. L., Garr, E., Brooke, S., Janak, P. H., Leyton, M., Chen, R., Namboodiri, V. M. K.",
      "published_date": "2026-01-21T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 120,
      "reading_time": 1,
      "created_at": "2026-01-22T03:50:05.337110+00:00",
      "updated_at": "2026-01-22T04:43:34.915629+00:00",
      "metadata": {
        "processed_at": "2026-01-22T04:43:34.915630+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "3f1b7dbb004c0c5cfefdd86a8ce6e33f",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.18.698509v1?rss=1",
      "title": "Minimal Mimics and Maps of Natural Light for Mammals",
      "content": "Light drives processes that include perception and the regulation of circadian rhythms, sleep, metabolism, and development. These processes are initiated by photopigment molecules, each preferentially absorbing particular wavelengths. Light of a given spectrum stimulates an animal's set of photopigments in a specific profile. Natural light and its variations produce stimulation profiles that promote normal physiology. To mimic these profiles using artificial light, we consider the thermally stable, photoconvertible states of relevant photopigments: ground states of rhodopsin and cone photopigments, and three states of melanopsin. This gives a high-dimensional representation of illumination. Nevertheless, we find that two wavelengths suffice to closely mimic the effects of natural light for mammals, including humans and mice. Adjusting the wavelength ratio allows mimicry of natural light's variations, such as those from twilight to noon. Ratio adjustments also compensate for light's filtering by elements like the eye's optics and laboratory cages. Adding a third wavelength makes natural light mimicry nearly perfect. By contrast, common artificial lighting--designed for low-dimensional, human color space--stimulates photopigments in unnatural proportions. We conclude by providing species-specific maps of photopigment stimulation profiles under natural and artificial illumination, which make our observations intuitive while providing insight into the diverse visual ecologies of mammals.",
      "author": "Morquette, P., Do, M. T. H.",
      "published_date": "2026-01-21T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 199,
      "reading_time": 1,
      "created_at": "2026-01-22T03:50:05.337078+00:00",
      "updated_at": "2026-01-22T04:43:34.915633+00:00",
      "metadata": {
        "processed_at": "2026-01-22T04:43:34.915635+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "55ec7de400ee82646891185d1cd2e293",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.18.699677v1?rss=1",
      "title": "EEG-Based Decoding of Color and Visual Category Representations Is Reliable Within and Across Sessions",
      "content": "The human visual system represents stimuli in a rich and detailed manner. Traditional methods of studying visual representations in humans, such as event-related potentials (ERP), revealed numerous distinctions between the brain activity elicited by different categories of stimuli. However, these methods miss the information embedded in the spatial distributions of brain activity, or patterns, and are not always sensitive to study visual representations of different stimuli at the single participant or single trial level. Time-resolved multivariate pattern classification analysis (MVPA), or Decoding, efficiently extracts the visual representations of stimuli from the EEG topography without a-priori assumptions about the location of the effect in time and space at the single participant level. The rich information this method provides has increased its popularity dramatically in recent years. Yet, different participants show variable quality of decoding performance, and it is unclear if the accuracy of decoding is maintained within participants across multiple sessions, tasks, attentional conditions and visual features. In the current study, participants performed three visual tasks, over two sessions (1-7 days apart). We examined the correlation of decoding accuracy: within the cross-validation set, between sessions, between features (color and category) and to different measurements of the ERP signal and behavioral performance. We also examined how models generalized to different tasks and different attention conditions. We found that decoding accuracies varied substantially across participants, and that decoding accuracy was reliable within participant, over sessions, attention condition and task. This suggests the decodability behaves like an individual trait. Moreover, the spatial patterns underlying the decoding (classification weights) generalized across different tasks, attentional conditions and sessions. This suggests minimal representational drift at the resolution allowed by the EEG. We conclude that EEG decoding is a reliable method, and that visual representations are stable.",
      "author": "Frenkel, C., Deouell, L. Y.",
      "published_date": "2026-01-21T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 289,
      "reading_time": 1,
      "created_at": "2026-01-22T03:50:05.337034+00:00",
      "updated_at": "2026-01-22T03:50:05.337039+00:00"
    },
    {
      "id": "013d768606abe824c9ff3c71c3cff317",
      "url": "https://www.nature.com/articles/s41467-026-68763-z",
      "title": "No evidence of immediate or persistent analgesic effect from a single dose of psilocybin in three mouse models of pain",
      "content": "",
      "author": "",
      "published_date": "2026-01-22T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2026-01-22T03:50:03.999303+00:00",
      "updated_at": "2026-01-22T03:50:03.999305+00:00"
    },
    {
      "id": "50c75745ac996fd28f573f487daa6553",
      "url": "https://www.youtube.com/watch?v=Hju0H3NHxVI",
      "title": "Mote: An Interactive Ecosystem Simulation [video]",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46712547\">Comments</a>",
      "author": "",
      "published_date": "2026-01-21T22:30:18+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-22T03:49:22.782128+00:00",
      "updated_at": "2026-01-22T03:49:22.782129+00:00"
    },
    {
      "id": "821a9a1d334a8d0100c9442a15d2b8da",
      "url": "https://www.jamf.com/blog/threat-actors-expand-abuse-of-visual-studio-code/",
      "title": "Threat actors expand abuse of Microsoft Visual Studio Code",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46713526\">Comments</a>",
      "author": "",
      "published_date": "2026-01-22T00:12:00+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-22T03:49:22.782053+00:00",
      "updated_at": "2026-01-22T03:49:22.782054+00:00"
    },
    {
      "id": "50c75745ac996fd28f573f487daa6553",
      "url": "https://www.youtube.com/watch?v=Hju0H3NHxVI",
      "title": "Mote: An Interactive Ecosystem Simulation [video]",
      "content": "<p><a href=\"https://www.tiktok.com/@recursecenter/video/7597943894319369502\" rel=\"nofollow\">https://www.tiktok.com/@recursecenter/video/7597943894319369...</a></p>\n<hr />\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46712547\">https://news.ycombinator.com/item?id=46712547</a></p>\n<p>Points: 9</p>\n<p># Comments: 0</p>",
      "author": "evakhoury",
      "published_date": "2026-01-21T22:30:18+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 14,
      "reading_time": 1,
      "created_at": "2026-01-22T03:49:21.427514+00:00",
      "updated_at": "2026-01-22T03:49:21.427516+00:00"
    }
  ]
}