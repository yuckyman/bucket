{
  "last_updated": "2025-11-28T10:17:45.562201+00:00",
  "count": 20,
  "articles": [
    {
      "id": "dcbcab96818b9c4fc39b243192bd378c",
      "url": "http://ieeexplore.ieee.org/document/11245798",
      "title": "IEEE Engineering in Medicine and Biology Society Publication Information",
      "content": "null",
      "author": "",
      "published_date": "2025-11-13T13:16:42+00:00",
      "source": "Transactions Biomedical Engineering",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 1,
      "reading_time": 1,
      "created_at": "2025-11-28T09:42:53.624810+00:00",
      "updated_at": "2025-11-28T10:17:45.456578+00:00",
      "metadata": {
        "processed_at": "2025-11-28T10:17:45.456587+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "9b9b9688b1b7ad0daae0d07393c16aad",
      "url": "http://ieeexplore.ieee.org/document/11245797",
      "title": "Front Cover",
      "content": "null",
      "author": "",
      "published_date": "2025-11-13T13:16:42+00:00",
      "source": "Transactions Biomedical Engineering",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 1,
      "reading_time": 1,
      "created_at": "2025-11-28T09:42:53.624785+00:00",
      "updated_at": "2025-11-28T10:17:45.456591+00:00",
      "metadata": {
        "processed_at": "2025-11-28T10:17:45.456592+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "9f02c4eedd52f85c551aa57725365bcf",
      "url": "https://www.wsj.com/tech/ai/tech-titans-amass-multimillion-dollar-war-chests-to-fight-ai-regulation-88c600e1",
      "title": "Tech Titans Amass Multimillion-Dollar War Chests to Fight AI Regulation",
      "content": "<p>Article URL: <a href=\"https://www.wsj.com/tech/ai/tech-titans-amass-multimillion-dollar-war-chests-to-fight-ai-regulation-88c600e1\">https://www.wsj.com/tech/ai/tech-titans-amass-multimillion-dollar-war-chests-to-fight-ai-regulation-88c600e1</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46077038\">https://news.ycombinator.com/item?id=46077038</a></p>\n<p>Points: 4</p>\n<p># Comments: 0</p>",
      "author": "thm",
      "published_date": "2025-11-28T09:21:55+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-11-28T09:41:58.853366+00:00",
      "updated_at": "2025-11-28T10:17:45.456595+00:00",
      "metadata": {
        "processed_at": "2025-11-28T10:17:45.456596+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "0bcc7d21165006148ca00c71c85848b9",
      "url": "https://www.nature.com/articles/s41398-025-03784-8",
      "title": "Gender differences in gray matter volume of the anterior cingulate cortex and suicidal ideation in patients with major depressive disorder: evidence from the REST-meta-MDD project",
      "content": "",
      "author": "",
      "published_date": "2025-11-28T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-11-28T09:22:25.954090+00:00",
      "updated_at": "2025-11-28T10:17:45.456599+00:00",
      "metadata": {
        "processed_at": "2025-11-28T10:17:45.456600+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "1eeace3760b4d1c5ef3e6cbb99785b8e",
      "url": "https://www.nature.com/articles/s41537-025-00706-x",
      "title": "Distinct microRNA profiles in neuron-derived extracellular vesicles between recent-onset and chronic-phase schizophrenia",
      "content": "",
      "author": "",
      "published_date": "2025-11-28T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-11-28T09:22:25.954069+00:00",
      "updated_at": "2025-11-28T10:17:45.456602+00:00",
      "metadata": {
        "processed_at": "2025-11-28T10:17:45.456604+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "a56f42cd2dde8bdd8304479e68ddc506",
      "url": "https://www.youtube.com/watch?v=bR9EN3kUlfg",
      "title": "How to make precise sheet metal parts (photochemical machining) [video]",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46020561\">Comments</a>",
      "author": "",
      "published_date": "2025-11-23T03:37:49+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-11-28T09:21:49.080025+00:00",
      "updated_at": "2025-11-28T09:21:49.080026+00:00"
    },
    {
      "id": "cc9a21edd0f6564ab501d68dfab3390d",
      "url": "https://www.collabora.com/news-and-blog/blog/2025/11/24/implementing-bluetooth-le-audio-and-auracast-on-linux-systems/",
      "title": "Implementing Bluetooth LE Audio and Auracast on Linux Systems",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46038684\">Comments</a>",
      "author": "",
      "published_date": "2025-11-24T20:15:53+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-11-28T08:29:06.730974+00:00",
      "updated_at": "2025-11-28T08:29:06.730975+00:00"
    },
    {
      "id": "36b99d6c1b0c6e341fbad6ab4db229cb",
      "url": "https://github.com/steveyegge/beads",
      "title": "Beads \u2013 A memory upgrade for your coding agent",
      "content": "<p>Article URL: <a href=\"https://github.com/steveyegge/beads\">https://github.com/steveyegge/beads</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46075616\">https://news.ycombinator.com/item?id=46075616</a></p>\n<p>Points: 5</p>\n<p># Comments: 0</p>",
      "author": "latchkey",
      "published_date": "2025-11-28T04:50:57+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-11-28T08:29:05.396512+00:00",
      "updated_at": "2025-11-28T08:29:05.396514+00:00"
    },
    {
      "id": "c584087c0806ea9e1b72b339624da54d",
      "url": "https://popovicu.com/posts/how-to-use-linux-vsock-for-fast-vm-communication/",
      "title": "How to use Linux vsock for fast VM communication",
      "content": "<p>Article URL: <a href=\"https://popovicu.com/posts/how-to-use-linux-vsock-for-fast-vm-communication/\">https://popovicu.com/posts/how-to-use-linux-vsock-for-fast-vm-communication/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46075746\">https://news.ycombinator.com/item?id=46075746</a></p>\n<p>Points: 4</p>\n<p># Comments: 0</p>",
      "author": "mfrw",
      "published_date": "2025-11-28T05:19:45+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-11-28T08:29:05.396472+00:00",
      "updated_at": "2025-11-28T08:29:05.396474+00:00"
    },
    {
      "id": "a6e32672b993f45061da858a670f95d5",
      "url": "https://www.frontiersin.org/articles/10.3389/fnhum.2025.1667742",
      "title": "Observing walking with asymmetric treadmill belt speeds induces stronger activation of the action observation network than normal walking",
      "content": "IntroductionObserving the actions of others activates the action observation network (AON). Although previous studies have reported that motor experience and visual familiarity with an observed action can modulate the AON activity, the response of the AON to the observation of unusual walking patterns remains unclear. Therefore, this study aimed to investigate the brain activity induced by observing walking in a split-belt condition, where the left and right treadmill belt speeds differ.MethodsWe examined the brain activity during the observation of video clips showing normal walking under a tied condition (the same left and right treadmill speeds) as well as walking during the initial and late periods of a split-belt condition using functional magnetic resonance imaging in 19 healthy adults. The step lengths of the actor walking in the video clips were asymmetric during the initial period of the split-belt condition and nearly symmetric during the tied condition and late period of the split-belt condition.Results and discussionObserving the walking video clips activated broad regions of the occipito-temporo-parietal and frontal cortices, irrespective of the clip conditions. The contrasts between the conditions revealed that observing walking in the initial and late periods of the split-belt condition induced stronger activation in a subset of the AON than in the tied condition. These results suggest that observing unusual walking patterns under asymmetric speed condition induces a stronger AON activity than normal walking.",
      "author": "Kiyotaka Kamibayashi",
      "published_date": "2025-11-28T00:00:00+00:00",
      "source": "Frontiers Human Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 226,
      "reading_time": 1,
      "created_at": "2025-11-28T07:21:01.019388+00:00",
      "updated_at": "2025-11-28T08:22:05.182857+00:00",
      "metadata": {
        "processed_at": "2025-11-28T08:22:05.182867+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "62b715ea907604996b8e3dcd86065d5e",
      "url": "https://www.frontiersin.org/articles/10.3389/fnhum.2025.1705660",
      "title": "Impact of visual distractors in virtual reality environments on sustained attention behavioral performance and EEG characteristics",
      "content": "IntroductionThis study investigates the effects of visual distractors in virtual reality (VR) environments on sustained attention, focusing on how visual distraction modulates neural mechanisms of attentional allocation and regulation.MethodsBehavioral and electroencephalographic (EEG) data were collected from 66 participants performing a Go/No-go continuous performance test (CPT) in a virtual classroom under conditions with (Y-D) and without (N-D) visual distractors. We analyzed behavioral performance (commission/omission errors, multipress, reaction time), event-related potential (P300) characteristics (latency, amplitude), and nonlinear dynamics (sample entropy, fuzzy entropy) of the EEG signals.ResultsBehavioral results revealed that visual distractors significantly increased commission errors, omission errors, and multipress (all p < 0.001), with no significant difference in reaction time. EEG analysis demonstrated that distractors significantly prolonged P300 latency, particularly at CPz, Pz, and Oz electrodes, and increased P300 amplitude at Fz, FCz, and Oz. Furthermore, both sample entropy and fuzzy entropy values were significantly higher under distraction conditions in the frontal, central, and parietal regions.DiscussionThese findings indicate that visual distractors disrupt cognitive processes related to visual information integration, attentional control, and decision-making, leading to decreased behavioral performance and increased neural complexity. This study deepens the understanding of the neural mechanisms of attention processing under ecological conditions and provides a scientific basis for optimizing educational environments and developing attention assessment tools based on neuroengineering.",
      "author": "Suogang Wang",
      "published_date": "2025-11-28T00:00:00+00:00",
      "source": "Frontiers Human Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 212,
      "reading_time": 1,
      "created_at": "2025-11-28T07:21:01.019313+00:00",
      "updated_at": "2025-11-28T08:22:05.182871+00:00",
      "metadata": {
        "processed_at": "2025-11-28T08:22:05.182873+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "071a719fc4e7d55af24a0ae6c24ce136",
      "url": "https://www.frontiersin.org/articles/10.3389/fnhum.2025.1699598",
      "title": "Visual feedback adaptation enhances arm-posture coordination during floor-surface perturbations",
      "content": "BackgroundMaintaining postural stability during perturbations requires coordinated sensorimotor and interjoint coordination. This study investigated the effects of different feedback modalities (knowledge of results [KR] and continuous visual feedback) on postural adaptation during floor surface perturbations while standing.MethodsNineteen healthy young adults (mean age: 23.1 \u00b1 1.2 years; 12 males) performed an arm-holding task while standing on a backward-translating force platform under five phases: baseline test, KR adaptation training, post-KR adaptation (P-KRA) test, visual adaptation training, and post-visual adaptation (P-VA) test. Endpoint position variability, center of pressure (COP), center of mass (COM), margin of stability (MOS), and interjoint coordination were compared among Baseline, P-KRA, and P-VA using a mixed-model repeated-measures analysis of variance.ResultsCompared to Baseline, endpoint position variability was significantly reduced in the P-VA at both perturbation offset (8.97 \u00b1 1.04 mm vs. 15.35 \u00b1 1.52 mm, p = 0.006) and 1.5 s after offset (14.39 \u00b1 1.02 mm vs. 19.73 \u00b1 1.71 mm, p = 0.027). The MOS at 1.5 s after offset was lower in P-VA (39.33 \u00b1 4.28 mm) than in Baseline (58.04 \u00b1 4.53 mm, p = 0.011), and the minimum MOS was significantly smaller in P-VA (32.20 \u00b1 4.38 mm vs. 50.59 \u00b1 4.26 mm, p = 0.011). Anticipatory COP displacement at onset in P-VA was significantly increased (14.11 \u00b1 1.46 mm vs. 6.20 \u00b1 0.89 mm, p < 0.001) and reduced peak forward COP displacement (89.42 \u00b1 2.00 mm vs. 110.18 \u00b1 3.35 mm, p < 0.001). The time to stability was shorter in P-VA (1,266.42 \u00b1 68.29 ms) than in Baseline (1,525.78 \u00b1 66.11 ms, p = 0.017). The cross-correlation coefficient between the elbow and ankle joints was significantly higher in P-VA than in Baseline (0.98 \u00b1 0.01 vs. 0.89 \u00b1 0.04, p = 0.014).ConclusionThese findings demonstrate that continuous visual feedback adaptation may enhance arm-posture coordination during external perturbations in healthy young adults.",
      "author": "Naoya Hasegawa",
      "published_date": "2025-11-28T00:00:00+00:00",
      "source": "Frontiers Human Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 308,
      "reading_time": 1,
      "created_at": "2025-11-28T07:21:01.019268+00:00",
      "updated_at": "2025-11-28T08:22:05.182876+00:00",
      "metadata": {
        "processed_at": "2025-11-28T08:22:05.182877+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "ab9db00e1672c26c5e821f4664cd6d26",
      "url": "https://www.frontiersin.org/articles/10.3389/fnins.2025.1725264",
      "title": "Advantages of human opsins in optogenetic visual restoration",
      "content": "Optogenetic vision restoration has progressed from proof-of-concept to early clinical testing, yet most programmes rely on microbial channels that demand high irradiance and offer limited adaptation. This review synthesizes preclinical and clinical evidence comparing microbial actuators with human opsins (rhodopsin, cone opsins, melanopsin) and outlines vector and safety considerations for translation. Human opsins activate G-protein\u2013coupled cascades, providing intrinsic signal amplification and operation at room-light levels (\u223c1011\u20131012 photons\u22c5cm\u20132\u22c5s\u20131), in contrast to the \u22651015 photons\u22c5cm\u20132\u22c5s\u20131 typically needed for channelrhodopsins. Rhodopsin and MW cone opsin preserve photopic-range sensitivity (rhodopsin > cone opsin) while delivering millisecond-scale kinetics and adaptation across backgrounds, enabling patterned retinal responses without optical intensification devices; clinical validation without external intensification is pending. Such mammalian pigments also confer bleaching-based light adaptation, whereas microbial tools are photocyclic and can desensitize under steady illumination, limiting sustained contrast encoding. Bistable melanopsin enables durable irradiance coding but with slow dynamics; chimeric designs (e.g., melanopsin\u2013mGluR6, Gloeobacter\u2013human rhodopsin) aim to combine amplification with favorable reset properties. In contrast to human opsins, microbial channels warrant safety considerations including light-dose budgeting (particularly at short wavelengths), potential cytotoxicity from proton or calcium loads, and vector-related ocular inflammation; red-shifted actuators improve photochemical safety margins. Targeting opsins to ON bipolar (ON-BP) cells retains inner-retinal computations (center\u2013surround, ON/OFF segregation, temporal filtering). Engineered adeno-associated virus (AAV) capsids (e.g., AAV2-7m8 intravitreally; AAV8.BP2 subretinally) paired with GRM6 or L7 promoters achieve broad ON-BP expression in rodents but a much more limited expression profile in non-human primates. First clinical studies report acceptable early ocular safety with emerging efficacy signals. We propose accelerating phase I safety human trials of human-opsin vectors with prospectively defined light-exposure budgets and low vision functional endpoints such as navigation, face and object recognition, temporal contrast sensitivity, alongside work on chromophore support, cascade integrity in late degeneration, and scalable vector\u2013promoter solutions. Pharmacological noise suppression in degenerating retinas (e.g., gap-junction blockers or retinoic-acid pathway modulators) may further enhance signal-to-noise without altering opsin biochemistry. Together, these steps can move human-opsin optogenetics from experimental promise to clinically meaningful restoration of light sensitivity.",
      "author": "Jasmina Cehajic-Kapetanovic",
      "published_date": "2025-11-28T00:00:00+00:00",
      "source": "Frontiers Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 335,
      "reading_time": 1,
      "created_at": "2025-11-28T07:20:58.112898+00:00",
      "updated_at": "2025-11-28T08:22:05.182879+00:00",
      "metadata": {
        "processed_at": "2025-11-28T08:22:05.182881+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "8fd62d37676cc6e16073939ab394954e",
      "url": "https://www.frontiersin.org/articles/10.3389/fnins.2025.1687815",
      "title": "SSEL: spike-based structural entropic learning for spiking graph neural networks",
      "content": "Spiking Neural Networks (SNNs) offer transformative, event-driven neuromorphic computing with unparalleled energy efficiency, representing a third-generation AI paradigm. Extending this paradigm to graph-structured data via Spiking Graph Neural Networks (SGNNs) promises energy-efficient graph cognition, yet existing SGNN architectures exhibit critical fragility under adversarial topology perturbations. To address this challenge, this study presents the Spike-based Structural Entropy Learning framework (SSEL), which introduces structural entropy theory into the learning objectives of SGNNs. The core innovation establishes structural entropy-guided topology refinement: By minimizing structural entropy, we derive a sparse topological graph that intrinsically prunes noisy edges while preserving critical low-entropy connections. To further enforce robustness, we develop an entropy-driven topological gating mechanism that restricts spiking message propagation exclusively to entropy-optimized edges, systematically eliminating adversarial pathways. Crucially, this co-design strategy synergizes two sparsity sources: Structural sparsity from the entropy-minimized graph topology and Event-driven sparsity from spike-based computation. This dual mechanism not only ensures exceptional robustness (64.58% accuracy vs. 30.14% baseline under 0.1 salt-and-pepper noise) but also enables ultra-low energy consumption, achieving 97.28% reduction compared to conventional GNNs while maintaining state-of-the-art accuracy (85.31% on Cora). This work demonstrates that the principled minimization of structural entropy is a powerful strategy for enhancing the robustness of Spiking Graph Neural Networks. The SSEL framework successfully mitigates the impact of adversarial topological perturbations while capitalizing on the energy-efficient nature of spike-based computation, which underscore the significant potential of combining information-theoretic graph principles with neuromorphic computing paradigms.",
      "author": "Badong Chen",
      "published_date": "2025-11-28T00:00:00+00:00",
      "source": "Frontiers Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 237,
      "reading_time": 1,
      "created_at": "2025-11-28T07:20:58.112718+00:00",
      "updated_at": "2025-11-28T08:22:05.182883+00:00",
      "metadata": {
        "processed_at": "2025-11-28T08:22:05.182884+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "ebd2f1c37169b7451f930e0562810c45",
      "url": "https://www.reddit.com/r/Python/comments/1p8muey/i_built_a_tool_that_automatically_cleans_unused/",
      "title": "I built a tool that automatically cleans unused dependencies from Python projects.",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>I built a tool that automatically cleans unused dependencies from Python projects. It's called Depcleaner and you can easily get started by reading it's PYPI or Github page!<br /> <a href=\"https://pypi.org/project/depcleaner/\">https://pypi.org/project/depcleaner/</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/JermyDiscord\"> /u/JermyDiscord </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1p8muey/i_built_a_tool_that_automatically_cleans_unused/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1p8muey/i_built_a_tool_that_automatically_cleans_unused/\">[comments]</a></span>",
      "author": "/u/JermyDiscord",
      "published_date": "2025-11-28T05:30:15+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 52,
      "reading_time": 1,
      "created_at": "2025-11-28T07:20:36.038272+00:00",
      "updated_at": "2025-11-28T07:20:36.038274+00:00"
    },
    {
      "id": "4e88dead9d716582b7b7f20fbcfe2380",
      "url": "https://github.com/NullPxl/banrays",
      "title": "Show HN: Ray-BANNED, Glasses to detect smart-glasses that have cameras",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46075882\">Comments</a>",
      "author": "",
      "published_date": "2025-11-28T05:52:38+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-11-28T07:20:34.852910+00:00",
      "updated_at": "2025-11-28T07:20:34.852912+00:00"
    },
    {
      "id": "4e88dead9d716582b7b7f20fbcfe2380",
      "url": "https://github.com/NullPxl/banrays",
      "title": "Show HN: Ray-BANNED, Glasses to detect smart-glasses that have cameras",
      "content": "<p>Hi! Recently smart-glasses with cameras like the Meta Ray-bans seem to be getting more popular. As does some people's desire to remove/cover up the recording indicator LED. I wanted to see if there's a way to detect when people are recording with these types of glasses, so a little bit ago I started working this project. I've hit a little bit of a wall though so I'm very much open to ideas!<p>I've written a bunch more on the link (+photos are there), but essentially this uses 2 fingerprinting approaches: \n- retro-reflectivity of the camera sensor by looking at IR reflections. mixed results here.\n- wireless traffic (primarily BLE, also looking into BTC and wifi)<p>For the latter, I'm currently just using an ESP32, and I can consistently detect when the Meta Raybans are 1) pairing, 2) first powered on, 3) (less consistently) when they're taken out of the charging case. When they do detect something, it plays a little jingle next to your ear.<p>Ideally I want to be able to detect them when they're in use, and not just at boot. I've come across the nRF52840, which seems like it can follow directed BLE traffic beyond the initial broadcast, but from my understanding it would still need to catch the first CONNECT_REQ event regardless. On the bluetooth classic side of things, all the hardware looks really expensive! Any ideas are appreciated. Thanks!</p>\n<hr />\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46075882\">https://news.ycombinator.com/item?id=46075882</a></p>\n<p>Points: 10</p>\n<p># Comments: 0</p>",
      "author": "nullpxl",
      "published_date": "2025-11-28T05:52:38+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 242,
      "reading_time": 1,
      "created_at": "2025-11-28T07:20:33.453944+00:00",
      "updated_at": "2025-11-28T07:20:33.453947+00:00"
    },
    {
      "id": "98cdc5d1153760f985ad6c09ba7ccf3d",
      "url": "https://xcancel.com/GrapheneOS/status/1993035936800584103",
      "title": "GrapheneOS Moving Out of France",
      "content": "<p>Article URL: <a href=\"https://xcancel.com/GrapheneOS/status/1993035936800584103\">https://xcancel.com/GrapheneOS/status/1993035936800584103</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46076150\">https://news.ycombinator.com/item?id=46076150</a></p>\n<p>Points: 9</p>\n<p># Comments: 3</p>",
      "author": "LaSombra",
      "published_date": "2025-11-28T06:43:13+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-11-28T07:20:33.453888+00:00",
      "updated_at": "2025-11-28T07:20:33.453897+00:00"
    },
    {
      "id": "e5cb715a925f94f66746b2643dec8d6b",
      "url": "https://www.nature.com/articles/s41380-025-03352-y",
      "title": "3D genetic architecture of schizophrenia risk across three neuronal subtypes",
      "content": "",
      "author": "",
      "published_date": "2025-11-28T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-11-28T06:33:45.337350+00:00",
      "updated_at": "2025-11-28T06:33:45.337351+00:00"
    },
    {
      "id": "ac9fa06572e59c717faed1f3bff899c2",
      "url": "https://www.nature.com/articles/s12276-025-01576-0",
      "title": "Exploring neurokinin-1 receptor antagonism for depression with structurally differentiated inhibitors",
      "content": "",
      "author": "",
      "published_date": "2025-11-28T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-11-28T06:33:45.337329+00:00",
      "updated_at": "2025-11-28T06:33:45.337331+00:00"
    }
  ]
}