{
  "last_updated": "2025-12-02T17:27:54.154758+00:00",
  "count": 20,
  "articles": [
    {
      "id": "27acf52f6250fa48328ce9760685d724",
      "url": "https://www.biorxiv.org/content/10.1101/10.64898/2025.11.28.691140v1?rss=1",
      "title": "Lifelong maintenance of locomotion by embryonically active dopamine neurons",
      "content": "Locomotor skills arise early in life and must be maintained throughout the lifespan, yet how this continuity is achieved despite major neural remodeling remains unclear. Using Drosophila, which undergoes complete metamorphosis, we show that dopamine neurons (DANs) are active during the embryonic stage and that this early activity is essential for locomotion across all developmental stages and adulthood. Through stage-specific behavioral assays, optogenetics, in vivo brain imaging, and fluorescent neuronal tracking, we identify a subset of ventral nervous system (VNS) DANs that modulate locomotor function throughout life. Transcriptomic analyses reveal that they maintain expression of developmental transcription factors. Knocking down these factors in post-mitotic VNS DANs impairs adult locomotion. These findings uncover a previously overlooked function for embryonic DANs and suggest that stable locomotion during nervous system maturation relies on persistent developmental regulator expression coupled with structural remodeling.",
      "author": "Padmanabhan, A., Rahman, D., Zhu, R., Khorbtli, S., Sathianathan, S., Le Flohic, B., Assanga Bisse, L., Mollereau, B., Huang, C., Konstantinides, N., Issa, A. R.",
      "published_date": "2025-12-02T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 138,
      "reading_time": 1,
      "created_at": "2025-12-02T17:27:23.147958+00:00",
      "updated_at": "2025-12-02T17:27:23.147959+00:00"
    },
    {
      "id": "da418564ae640d5e2532345cbc7c39c2",
      "url": "https://www.biorxiv.org/content/10.1101/10.64898/2025.11.28.689466v1?rss=1",
      "title": "Higher inter-trial latency variability contributes to reduced visual EEG responses in schizophrenia",
      "content": "Patients with schizophrenia show strong impairments in visual backward masking, which are associated with reduced EEG N1 responses. However, it is currently unclear whether reduced N1 amplitudes in patients reflect attenuated neural responses or increased inter-trial latency variability, as both can lead to reduced trial-averaged responses. Previous studies using trial-averaged data cannot distinguish between these two possibilities. Here, we estimated inter-trial latency variability of the visual N1 component and found significantly increased variability in patients compared to controls. Inter-trial latency-variability was a strong predictor of the N1 amplitude in both groups. Importantly, after accounting for the effect of latency variability in the group comparison, patients continued to exhibit significantly reduced N1 amplitudes, although the effect size diminished from large to medium. These findings indicate that both higher latency variability and attenuated neural responses contribute to visual processing deficits in schizophrenia.",
      "author": "Gordillo, D., da Cruz, J. R., Brand, A., Chkonia, E., Roinishvili, M., Figueiredo, P., Herzog, M. H.",
      "published_date": "2025-12-02T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 140,
      "reading_time": 1,
      "created_at": "2025-12-02T17:27:23.147928+00:00",
      "updated_at": "2025-12-02T17:27:23.147929+00:00"
    },
    {
      "id": "9e24e1c5b96f56cd9d7978969f8bb64d",
      "url": "https://www.biorxiv.org/content/10.1101/10.64898/2025.11.28.691222v1?rss=1",
      "title": "Reorganisation of Cortico-Hippocampal White Matter Pathways in Healthy Ageing: Evidence for Paradoxical Shifts in Structural Connectivity.",
      "content": "The hippocampus plays a central role in episodic memory and has been the focus of extensive research over past decades. A substantial body of work has demonstrated that age-related memory decline is linked to changes in how the hippocampus functionally interacts with distributed brain networks. While functional connectivity changes in ageing are well documented, relatively little is known about alterations in the structural connectivity (SC) of the hippocampus, despite its foundational role in supporting communication across neural systems. In this study, we combined high-quality data from the Human Connectome Project and advanced diffusion-weighted imaging (DWI) methods to investigate age-related changes in hippocampal SC. Using a recently developed tractography pipeline that allows greater anatomical specificity than conventional approaches, we systematically compared connectivity patterns between younger (26-30 years) and older (56-60 years) adults. Results revealed reduced hippocampal SC with the entorhinal cortex and medial parietal cortices in older participants, alongside increased SC with anterior temporal areas. This paradoxical pattern suggests that ageing is associated with both vulnerability and reorganisation of hippocampal networks, with increased hippocampal-temporal connectivity potentially reflecting compensatory plasticity in response to reduced posterior medial connection. These findings provide in vivo evidence of cortico-hippocampal structural reorganisation in late middle age, a critical period when pathological processes such as tau deposition are already detectable in cognitively healthy individuals. More broadly, they demonstrate the power of our anatomically refined tractography pipeline as a proof of concept for detecting subtle, regionally specific changes in hippocampal pathway density. This approach holds promise for charting normative ageing trajectories and identifying early biomarkers of vulnerability and compensation in memory-related networks.",
      "author": "Dalton, M. A., D'Souza, A., Ansari Mahabadian, A., Calamante, F., Piguet, O.",
      "published_date": "2025-12-02T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 263,
      "reading_time": 1,
      "created_at": "2025-12-02T17:27:23.147895+00:00",
      "updated_at": "2025-12-02T17:27:23.147897+00:00"
    },
    {
      "id": "35ae4805c59b0a7d6da80e482cf8da8a",
      "url": "https://www.biorxiv.org/content/10.1101/10.64898/2025.11.29.691281v1?rss=1",
      "title": "The PDE4D ortholog Dunce suppresses memory in Drosophila melanogaster",
      "content": "The regulation of cAMP concentration is a key component of the mechanisms underlying learning and memory. In Drosophila melanogaster, the cAMP-specific phosphodiesterase mutant dunce1 results in increased levels of cAMP but poorer associative short-term memory and anesthesia-resistant memory. This raises the question of how elevated cAMP levels can cause defects in both short-term and long-term memory. To answer this question, we analyzed associative olfactory learning and memory in Drosophila larvae of both sexes with the isoform-specific dunceD143 mutation. Flies with this mutation exhibited better learning than flies with the dunce1 mutant. The memory facilitated by dunceD143 was stable and easily reversable. The improvement in memory was also traced to a defined subset of neurons. A comparison of the subcellular localization of Dunce isoforms indicates that the regulation of cAMP in the soma suppresses early memory formation. We revealed that Dunce regulates at least two different aspects of learning and memory, specifically, preventing the premature formation of memory and facilitating the formation of memory after multiple training sessions. The different functions of Dunce might be due to different cell types.",
      "author": "Hasselmann, T., Verbrueggen, M., Mueller, M., Gompert, M., Scholz, H.",
      "published_date": "2025-12-02T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 179,
      "reading_time": 1,
      "created_at": "2025-12-02T17:27:23.147836+00:00",
      "updated_at": "2025-12-02T17:27:23.147838+00:00"
    },
    {
      "id": "3328fc5b103e28707e2c822f369e2226",
      "url": "https://www.biorxiv.org/content/10.1101/10.64898/2025.11.29.691280v1?rss=1",
      "title": "Neural information sharing across the orienting attentional network predicts intelligence in children",
      "content": "Efficient brain functioning is often defined as the ability to achieve high performance with minimal cognitive resources. This study investigated the relationship between intelligence and attentional network efficiency in school-aged children, using electroencephalography (EEG) during the Attention Network Test (ANT). Participants were 38 children aged 11-14 years, recruited from schools in the Maule Region of Chile. Attentional network efficiency was assessed through event-related potentials (ERPs), midfrontal theta power as an index of conflict processing, and weighted Symbolic Mutual Information (wSMI) to quantify large-scale, nonlinear information sharing. Higher full-scale IQ scores were specifically associated with reduced wSMI within the orienting network, suggesting greater neural efficiency through less widespread information exchange between dorsal frontoparietal nodes. No significant associations were found between IQ and theta-band power during conflict processing. These findings provide novel evidence linking intelligence in childhood to network-level neural efficiency in attentional orienting, supporting the view that individual differences in cognitive ability reflect not only localized neural activity but also the efficiency of information integration within task-relevant networks.",
      "author": "Lucero, B., Munoz-Quezada, M. T., Saracini, C., Lanfranco, R. C., Canales-Johnson, A.",
      "published_date": "2025-12-02T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 167,
      "reading_time": 1,
      "created_at": "2025-12-02T17:27:23.147789+00:00",
      "updated_at": "2025-12-02T17:27:23.147793+00:00"
    },
    {
      "id": "e7ba906edb8af0b67222b89479ff3a92",
      "url": "https://www.reddit.com/r/Python/comments/1pcce1w/pyimagecuda_gpuaccelerated_image_compositing_for/",
      "title": "PyImageCUDA - GPU-accelerated image compositing for Python",
      "content": "<!-- SC_OFF --><div class=\"md\"><h2>What My Project Does</h2> <p>PyImageCUDA is a lightweight (~1MB) library for <strong>GPU-accelerated image composition</strong>. Unlike OpenCV (computer vision) or Pillow (CPU-only), it fills the gap for high-performance design workflows.</p> <p><strong>10-400x speedups</strong> for GPU-friendly operations with a Pythonic API.</p> <h2>Target Audience</h2> <ul> <li><strong>Generative Art</strong> - Render thousands of variations in seconds</li> <li><strong>Video Processing</strong> - Real-time frame manipulation</li> <li><strong>Data Augmentation</strong> - Batch transformations for ML</li> <li><strong>Tool Development</strong> - Backend for image editors</li> <li><strong>Game Development</strong> - Procedural asset generation</li> </ul> <h2>Why I Built This</h2> <p>I wanted to <strong>learn CUDA from scratch</strong>. This evolved into the core engine for a <strong>parametric node-based image editor</strong> I'm building (release coming soon!).</p> <p><strong>The gap:</strong> CuPy/OpenCV lack design primitives. Pillow is CPU-only and slow. Existing solutions require CUDA Toolkit or lack composition features.</p> <p><strong>The solution:</strong> &quot;Pillow on steroids&quot; - render drop shadows, gradients, blend modes... without writing raw kernels. Zero heavy dependencies (just pip install), design-first API, smart memory management.</p> <h2>Key Features</h2> <p>\u2705 <strong>Zero Setup</strong> - No CUDA Toolkit/Visual Studio, just standard NVIDIA drivers<br /> \u2705 <strong>1MB Library</strong> - Ultra-lightweight<br /> \u2705 <strong>Float32 Precision</strong> - Prevents color banding<br /> \u2705 <strong>Smart Memory</strong> - Reuse buffers, resize without reallocation<br /> \u2705 <strong>NumPy Integration</strong> - Works with OpenCV, Pillow, Matplotlib<br /> \u2705 <strong>Rich Features</strong> - +40 operations (gradients, blend modes, effects...)</p> <h2>Quick Example</h2> <p>```python from pyimagecuda import Image, Fill, Effect, Blend, Transform, save</p> <p>with Image(1024, 1024) as bg: Fill.color(bg, (0, 1, 0.8, 1))</p> <pre><code>with Image(512, 512) as card: Fill.gradient(card, (1, 0, 0, 1), (0, 0, 1, 1), 'radial') Effect.rounded_corners(card, 50) with Effect.stroke(card, 10, (1, 1, 1, 1)) as stroked: with Effect.drop_shadow(stroked, blur=50, color=(0, 0, 0, 1)) as shadowed: with Transform.rotate(shadowed, 45) as rotated: Blend.normal(bg, rotated, anchor='center') save(bg, 'output.png') </code></pre> <p>```</p> <h2>Advanced: Zero-Allocation Batch Processing</h2> <p><strong>Buffer reuse eliminates allocations + dynamic resize without reallocation:</strong> ```python from pyimagecuda import Image, ImageU8, load, Filter, save</p> <h1>Pre-allocate buffers once (with max capacity)</h1> <p>src = Image(4096, 4096) # Source images dst = Image(4096, 4096) # Processed results<br /> temp = Image(4096, 4096) # Temp for operations u8 = ImageU8(4096, 4096) # I/O conversions</p> <h1>Process 1000 images with zero additional allocations</h1> <h1>Buffers resize dynamically within capacity</h1> <p>for i in range(1000): load(f&quot;input<em>{i}.jpg&quot;, f32_buffer=src, u8_buffer=u8) Filter.gaussian_blur(src, radius=10, dst_buffer=dst, temp_buffer=temp) save(dst, f&quot;output</em>{i}.jpg&quot;, u8_buffer=u8)</p> <h1>Cleanup once</h1> <p>src.free() dst.free() temp.free() u8.free() ```</p> <h2>Operations</h2> <ul> <li><a href=\"https://offerrall.github.io/pyimagecuda/fill/\">Fill</a> (Solid colors, Gradients, Checkerboard, Grid, Stripes, Dots, Circle, Ngon, Noise, Perlin)</li> <li><a href=\"https://offerrall.github.io/pyimagecuda/text/\">Text</a> (Rich typography, system fonts, HTML-like markup, letter spacing...)</li> <li><a href=\"https://offerrall.github.io/pyimagecuda/blend/\">Blend</a> (Normal, Multiply, Screen, Add, Overlay, Soft Light, Hard Light, Mask)</li> <li><a href=\"https://offerrall.github.io/pyimagecuda/resize/\">Resize</a> (Nearest, Bilinear, Bicubic, Lanczos)</li> <li><a href=\"https://offerrall.github.io/pyimagecuda/adjust/\">Adjust</a> (Brightness, Contrast, Saturation, Gamma, Opacity)</li> <li><a href=\"https://offerrall.github.io/pyimagecuda/transform/\">Transform</a> (Flip, Rotate, Crop)</li> <li><a href=\"https://offerrall.github.io/pyimagecuda/filter/\">Filter</a> (Gaussian Blur, Sharpen, Sepia, Invert, Threshold, Solarize, Sobel, Emboss)</li> <li><a href=\"https://offerrall.github.io/pyimagecuda/effect/\">Effect</a> (Drop Shadow, Rounded Corners, Stroke, Vignette)</li> </ul> <p><a href=\"https://offerrall.github.io/pyimagecuda/\"><strong>\u2192 Full Documentation</strong></a></p> <h2>Performance</h2> <ul> <li><strong>Advanced operations</strong> (blur, blend, Drop shadow...): <strong>10-260x faster</strong> than CPU</li> <li><strong>Simple operations</strong> (flip, crop...): <strong>3-20x faster</strong> than CPU</li> <li><strong>Single operation + file I/O</strong>: <strong>1.5-2.5x faster</strong> (CPU-GPU transfer adds overhead, but still outperforms Pillow/OpenCV - see benchmarks)</li> <li><strong>Multi-operation pipelines</strong>: <strong>Massive speedups</strong> (data stays on GPU)</li> </ul> <p>Maximum performance when chaining operations on GPU without saving intermediate results.</p> <p><a href=\"https://offerrall.github.io/pyimagecuda/benchmarks/\"><strong>\u2192 Full Benchmarks</strong></a></p> <h2>Installation</h2> <p><code>bash pip install pyimagecuda </code></p> <p><strong>Requirements:</strong> - Windows 10/11 or Linux (Ubuntu, Fedora, Arch, WSL2...) - NVIDIA GPU (GTX 900+) - Standard NVIDIA drivers</p> <p><strong>NOT required:</strong> CUDA Toolkit, Visual Studio, Conda</p> <h2>Status</h2> <p><strong>Version:</strong> 0.0.7 Alpha<br /> <strong>State:</strong> Core features stable, more coming soon</p> <h2>Links</h2> <ul> <li><strong>GitHub</strong>: <a href=\"https://github.com/offerrall/pyimagecuda\">https://github.com/offerrall/pyimagecuda</a></li> <li><strong>Docs</strong>: <a href=\"https://offerrall.github.io/pyimagecuda/\">https://offerrall.github.io/pyimagecuda/</a></li> <li><strong>PyPI</strong>: <code>pip install pyimagecuda</code></li> </ul> <hr /> <p><strong>Feedback welcome!</strong> </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/drboom9\"> /u/drboom9 </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1pcce1w/pyimagecuda_gpuaccelerated_image_compositing_for/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1pcce1w/pyimagecuda_gpuaccelerated_image_compositing_for/\">[comments]</a></span>",
      "author": "/u/drboom9",
      "published_date": "2025-12-02T16:07:57+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 595,
      "reading_time": 2,
      "created_at": "2025-12-02T17:26:47.534811+00:00",
      "updated_at": "2025-12-02T17:26:47.534813+00:00"
    },
    {
      "id": "7653cf9539ffd724a010995f44d78e2d",
      "url": "https://www.ycombinator.com/companies/poka-labs/jobs/RCQgmqB-founding-engineer",
      "title": "Poka Labs (YC S24) Is Hiring a Founding Engineer",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46123374\">Comments</a>",
      "author": "",
      "published_date": "2025-12-02T17:00:12+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-02T17:26:46.321133+00:00",
      "updated_at": "2025-12-02T17:26:46.321134+00:00"
    },
    {
      "id": "1a1ca4483f3cc4c1809be883021a5161",
      "url": "https://api.github.com/meta",
      "title": "API GitHub Meta",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46123469\">Comments</a>",
      "author": "",
      "published_date": "2025-12-02T17:06:24+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-02T17:26:46.321094+00:00",
      "updated_at": "2025-12-02T17:26:46.321096+00:00"
    },
    {
      "id": "7653cf9539ffd724a010995f44d78e2d",
      "url": "https://www.ycombinator.com/companies/poka-labs/jobs/RCQgmqB-founding-engineer",
      "title": "Poka Labs (YC S24) Is Hiring a Founding Engineer",
      "content": "<p>Article URL: <a href=\"https://www.ycombinator.com/companies/poka-labs/jobs/RCQgmqB-founding-engineer\">https://www.ycombinator.com/companies/poka-labs/jobs/RCQgmqB-founding-engineer</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46123374\">https://news.ycombinator.com/item?id=46123374</a></p>\n<p>Points: 0</p>\n<p># Comments: 0</p>",
      "author": "arbass",
      "published_date": "2025-12-02T17:00:12+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-02T17:26:45.048966+00:00",
      "updated_at": "2025-12-02T17:26:45.048968+00:00"
    },
    {
      "id": "1a1ca4483f3cc4c1809be883021a5161",
      "url": "https://api.github.com/meta",
      "title": "API GitHub Meta",
      "content": "<p>Article URL: <a href=\"https://api.github.com/meta\">https://api.github.com/meta</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46123469\">https://news.ycombinator.com/item?id=46123469</a></p>\n<p>Points: 11</p>\n<p># Comments: 0</p>",
      "author": "luispa",
      "published_date": "2025-12-02T17:06:24+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-02T17:26:45.048935+00:00",
      "updated_at": "2025-12-02T17:26:45.048943+00:00"
    },
    {
      "id": "086acbf16f45fb407e18e9f3023332e7",
      "url": "https://www.reddit.com/r/Python/comments/1pccbk4/structure_large_python_projects_for/",
      "title": "Structure Large Python Projects for Maintainability",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>I'm scaling a Python project from &quot;works for me&quot; to &quot;multiple people need to work on this,&quot; and I'm realizing my structure isn't great.</p> <p><strong>Current situation:</strong></p> <p>I have one main directory with 50+ modules. No clear separation of concerns. Tests are scattered. Imports are a mess. It works, but it's hard to navigate and modify.</p> <p><strong>Questions I have:</strong></p> <ul> <li>What's a good folder structure for a medium-sized Python project (5K-20K lines)?</li> <li>How do you organize code by domain vs by layer (models, services, utils)?</li> <li>How strict should you be about import rules (no circular imports, etc.)?</li> <li>When should you split code into separate packages?</li> <li>What does a good test directory structure look like?</li> <li>How do you handle configuration and environment-specific settings?</li> </ul> <p><strong>What I'm trying to achieve:</strong></p> <ul> <li>Make it easy for new developers to understand the codebase</li> <li>Prevent coupling between different parts</li> <li>Make testing straightforward</li> <li>Reduce merge conflicts when multiple people work on it</li> </ul> <p>Do you follow a specific pattern, or make your own rules?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Electrical-Signal858\"> /u/Electrical-Signal858 </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1pccbk4/structure_large_python_projects_for/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1pccbk4/structure_large_python_projects_for/\">[comments]</a></span>",
      "author": "/u/Electrical-Signal858",
      "published_date": "2025-12-02T16:05:15+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 188,
      "reading_time": 1,
      "created_at": "2025-12-02T16:57:05.182747+00:00",
      "updated_at": "2025-12-02T16:57:05.182749+00:00"
    },
    {
      "id": "30da574f63d47691cbe97ee8049b5df2",
      "url": "https://jacobin.com/2025/11/peter-thiel-palantir-apocalypse-antichrist",
      "title": "Peter Thiel's Apocalyptic Worldview Is a Dangerous Fantasy",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46122851\">Comments</a>",
      "author": "",
      "published_date": "2025-12-02T16:23:27+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-02T16:57:03.900230+00:00",
      "updated_at": "2025-12-02T16:57:03.900231+00:00"
    },
    {
      "id": "30da574f63d47691cbe97ee8049b5df2",
      "url": "https://jacobin.com/2025/11/peter-thiel-palantir-apocalypse-antichrist",
      "title": "Peter Thiel's Apocalyptic Worldview Is a Dangerous Fantasy",
      "content": "<p>Article URL: <a href=\"https://jacobin.com/2025/11/peter-thiel-palantir-apocalypse-antichrist\">https://jacobin.com/2025/11/peter-thiel-palantir-apocalypse-antichrist</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46122851\">https://news.ycombinator.com/item?id=46122851</a></p>\n<p>Points: 79</p>\n<p># Comments: 21</p>",
      "author": "robtherobber",
      "published_date": "2025-12-02T16:23:27+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-02T16:57:02.503002+00:00",
      "updated_at": "2025-12-02T16:57:02.503011+00:00"
    },
    {
      "id": "80d1f642eb4da0958753076107ac0cbe",
      "url": "http://daniellakens.blogspot.com/2025/07/easily-download-files-from-open-science.html",
      "title": "Easily download files from the Open Science Framework with Papercheck",
      "content": "<p>Researchers\nincreasingly use the <a href=\"https://osf.io/\">Open Science Framework</a> (OSF) to share files, such as data\nand code underlying scientific publications, or presentations and materials for\nscientific workshops. The OSF is an amazing service that has contributed\nimmensely to a changed research culture where psychologists share data, code, and\nmaterials. We are very grateful it exists.</p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">But it is\nnot always the most user-friendly. Specifically, downloading files from the OSF\nis a bigger hassle than we (<a href=\"https://debruine.github.io/\">Lisa DeBruine</a>\nand <a href=\"https://www.tue.nl/en/research/researchers/daniel-lakens/\">Daniel\nLakens</a>, the developers of Papercheck) would like it to be. Downloading individual\nfiles is so complex, <a href=\"https://bsky.app/profile/malte.the100.ci/post/3lpf4s6spns2i\">Malte Elson</a>\nrecently posted this meme on Bluesky. </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"NL\"><!--[if gte vml 1]><v:shapetype\n id=\"_x0000_t75\" coordsize=\"21600,21600\" o:spt=\"75\" o:preferrelative=\"t\"\n path=\"m@4@5l@4@11@9@11@9@5xe\" filled=\"f\" stroked=\"f\">\n <v:stroke joinstyle=\"miter\"/>\n <v:formulas>\n  <v:f eqn=\"if lineDrawn pixelLineWidth 0\"/>\n  <v:f eqn=\"sum @0 1 0\"/>\n  <v:f eqn=\"sum 0 0 @1\"/>\n  <v:f eqn=\"prod @2 1 2\"/>\n  <v:f eqn=\"prod @3 21600 pixelWidth\"/>\n  <v:f eqn=\"prod @3 21600 pixelHeight\"/>\n  <v:f eqn=\"sum @0 0 1\"/>\n  <v:f eqn=\"prod @6 1 2\"/>\n  <v:f eqn=\"prod @7 21600 pixelWidth\"/>\n  <v:f eqn=\"sum @8 21600 0\"/>\n  <v:f eqn=\"prod @7 21600 pixelHeight\"/>\n  <v:f eqn=\"sum @10 21600 0\"/>\n </v:formulas>\n <v:path o:extrusionok=\"f\" gradientshapeok=\"t\" o:connecttype=\"rect\"/>\n <o:lock v:ext=\"edit\" aspectratio=\"t\"/>\n</v:shapetype><v:shape id=\"_x0000_i1026\" type=\"#_x0000_t75\" style='width:453.75pt;\n height:276pt;visibility:visible;mso-wrap-style:square'>\n <v:imagedata src=\"file:///C:/Users/DLakens/AppData/Local/Temp/msohtmlclip1/01/clip_image001.jpg\"\n  o:title=\"\"/>\n</v:shape><![endif]--><!--[if !vml]--><img border=\"0\" height=\"368\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEinS5tFoL5qX14Z2OcgT1APMZLGlghAD3BfBhSnJ9pleVbJyRFUFLShqReS2j7SXGozmLMcVQkoM62UhneJDtH4yx3NRnXOkVZZi-Dm-OPwbGaidxr2raF9wzjx5fU92nfPpE3jmGfwZEwHS1WGSB4gUfRfV3XWjOC2-lCjOYR108h3fwORIHOnqxIX9m8\" width=\"605\" /><!--[endif]--></span><span lang=\"EN-US\"></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\"><span>&nbsp;</span></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">Not only is\nthe download button for files difficult to find, but downloading all files\nrelated to a project can be surprisingly effortful. It is possible to download\nall files in a zip folder that will be called \u2018osfstorage-archive.zip\u2019 when\ndownloaded. But as the OSF supports a nested folder structure, you might miss a\nfolder, and you will quickly end up with \u2018osfstorage-archive (1).zip\u2019, \u2018osfstorage-archive\n(2).zip\u2019, etc. Unzipping these archives creates a lot of files without the\norganized folder structure, in folders with meaningless names, making it\ndifficult to understand where files are. </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<h2 style=\"text-align: left;\"><b><span lang=\"EN-US\">The\nosf_file_download function in Papercheck </span></b></h2>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">We have added\na new function to our R package \u2018<a href=\"https://scienceverse.github.io/papercheck/\">Papercheck</a>\u2019 that will download all files and\nfolders in an OSF repository. It saves all files by recreating the folder\nstructure from the OSF in your download folder. Just install Papercheck, load\nthe library, and use the osf_file_download function to grab all files on the OSF:</span></p><p class=\"MsoNormal\"><span lang=\"EN-US\"><br /></span></p>\n\n<div style=\"text-align: left;\"><span style=\"font-family: courier;\"><b><span lang=\"EN-US\">devtools::install_github(\"scienceverse/papercheck\")<br /></span></b><b><span lang=\"EN-US\">library(papercheck)<br /></span></b><b><span lang=\"EN-US\">osf_file_download(\"6nt4v\")</span></b></span></div>\n\n\n\n\n\n<p class=\"MsoNormal\"><b><span lang=\"EN-US\">&nbsp;</span></b></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">All files\nwill be downloaded to your working directory. </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">Are you feeling\nFOMO for missing out on the <a href=\"https://www.kcl.ac.uk/events/open-research-summer-school-2025\">King Open\nResearch Summer School</a> that is going on these days, where <a href=\"https://research.tue.nl/en/persons/sajedeh-rasti\">Sajedeh Rasti</a> talked\nabout Preregistration, and <a href=\"https://research.tue.nl/en/persons/cristian-mesquida-caldentey\">Cristian\nMesquida</a> will give a workshop on using Papercheck? Well, at least it is\nvery easy to download all the files they have shared on the OSF and look at the\npresentations: </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\"><span style=\"font-family: courier;\">osf_file_download(\"b7es8\")</span></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">In the\noutput, we see that by default large files (more than 10mb) are omitted. <span><!--[if gte vml 1]><v:shape id=\"Picture_x0020_1\"\n o:spid=\"_x0000_i1025\" type=\"#_x0000_t75\" alt=\"A screenshot of a computer&#10;&#10;AI-generated content may be incorrect.\"\n style='width:453.75pt;height:292.5pt;visibility:visible;mso-wrap-style:square'>\n <v:imagedata src=\"file:///C:/Users/DLakens/AppData/Local/Temp/msohtmlclip1/01/clip_image003.png\"\n  o:title=\"A screenshot of a computer&#10;&#10;AI-generated content may be incorrect\"/>\n</v:shape><![endif]--><!--[if !vml]--><img alt=\"A screenshot of a computer\n\nAI-generated content may be incorrect.\" border=\"0\" height=\"390\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEj2jH76ywmEeLzL43u6gJl7GKR2lEGlhYS0LOXRPMMovOsJEVdXyamYCvmq96ez3p_GXHLoFz4JDyAKHlARK9pSy8QfzVa7yt1_uEg_H9IJfKgunnYWUwlROXABNcU6TvrA0_hx0KPZfj00b3Cb-Wn_7Bf3sFu9JApZoClcWoh_Vfl5bk1GQVZUH1tuGao\" width=\"605\" /><!--[endif]--></span></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">If you want\nto download all files, regardless of the size, then set the parameter to ignore\nthe maximum file size: </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\"><span style=\"font-family: courier;\">osf_file_download(\"b7es8\",\nmax_file_size = NULL)</span></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">Sometimes\nyou might want to download all files but ignore the file structure on the OSF,\nto just have all the files in one folder. Setting the parameter ignore_folder_structure\n= TRUE will give you all the files on the OSF in a single folder. By default, files will be downloaded into your working directory, but you can also specify\nwhere you want the files to be saved. </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\"><span style=\"font-family: courier;\">osf_file_download(\"6nt4v\",\nignore_folder_structure = TRUE, download_to = \"C:\\\\test_download\")</span></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">We hope\nthis function will make it easier for reviewers to access all supplementary\nfiles stored on the OSF during peer review, and for researchers who want to re-use\ndata, code, or materials shared on the OSF by downloading all the files they\nneed easily. Make sure to install the latest version of Papercheck (0.0.0.9050)\nto get access to this new function. Papercheck is still in active development,\nso report any bugs on <a href=\"https://github.com/scienceverse/papercheck\">GitHub</a>.</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>",
      "author": "noreply@blogger.com (Daniel Lakens)",
      "published_date": "2025-07-22T09:53:00+00:00",
      "source": "Twenty Percent Statistician",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 765,
      "reading_time": 3,
      "created_at": "2025-12-02T16:31:33.777634+00:00",
      "updated_at": "2025-12-02T16:31:33.777636+00:00"
    },
    {
      "id": "5cf06dd1c8477abb17ef4e5c3b5426e0",
      "url": "https://erpinfo.org/blog/2021/12/22/applications-2023",
      "title": "Applications now being accepted for UC-Davis/SDSU ERP Boot Camp, July 31 \u2013 August 9, 2023",
      "content": "<p class=\"\">The next 10-day ERP Boot Camp will be held July 31 \u2013 August 9, 2023 in San Diego, California. We are now taking applications, which will be due by April 1, 2023. <a href=\"https://erpinfo.org/summer-boot-camp\">Click here</a> for more information.</p><p class=\"\">We are currently planning to hold this workshop as an in-person event. However, these plans are subject to change as the COVID-19 pandemic evolves. If the event is held in person, we will require that everyone is fully vaccinated, and we will also implement any other safety measures that are warranted at the time of the workshop.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"980\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/1609175691205-RTD3XM69YGOFMVP23U6T/Boot_Camp_Logo.png?format=1000w\" width=\"1148\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>",
      "author": "Steve Luck",
      "published_date": "2023-01-16T18:31:57+00:00",
      "source": "Erp Boot Camp",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 108,
      "reading_time": 1,
      "created_at": "2025-12-02T16:31:31.366804+00:00",
      "updated_at": "2025-12-02T16:31:31.366806+00:00"
    },
    {
      "id": "bd7398ecbbd90ecd3269866b2fd3744f",
      "url": "https://erpinfo.org/blog/2023/6/23/decoding-webinar",
      "title": "ERP Decoding for Everyone: Software and Webinar",
      "content": "<p class=\"\"><strong>You can access the recording </strong><a href=\"https://video.ucdavis.edu/media/Virtual+ERP+Boot+CampA+Decoding+for+Everyone%2C+July+25+2023/1_lmwj6bu0\"><strong>here</strong></a><strong>.<br />You can access the final PDF of the slides </strong><a href=\"https://ucdavis.box.com/s/flf9gzeo12rz2jhxptih7xjl0omka2k7\"><strong>here</strong></a><strong>. <br />You can access the data </strong><a href=\"https://doi.org/10.18115/D5KS6S\"><strong>here</strong></a><strong>.</strong></p><p class=\"\">fMRI research has used decoding methods for over 20 years. These methods make it possible to decode what an individual is perceiving or holding in working memory on the basis of the pattern of BOLD activity across voxels. Remarkably, these methods can also be applied to ERP data, using the pattern of voltage across electrode sites rather than the pattern of activity across voxels to decode the information being represented by the brain (<a href=\"https://erpinfo.org/blog/2018/9/16/decoding\">see this previous blog post</a>). For example, ERPs can be used to decode the identity of a face that is being perceived, the emotional valence of a scene, the identity and semantic category of a word, and the features of an object that is being maintained in working memory. Moreover, decoding methods can be more sensitive than traditional methods for detecting conventional ERP effects (e.g., whether a word is semantically related or unrelated to a previous word in an N400 paradigm).</p><p class=\"\">So far, these methods have mainly been used by a small set of experts. We aim to change that with the upcoming Version 10 of <a href=\"https://erpinfo.org/erplab\">ERPLAB Toolbox</a>. This version of ERPLAB will contain an ERP decoding tool that makes it trivially easy for anyone who knows how to do conventional ERP processing to take advantage of the power of decoding. It should be available in mid-July at <a href=\"https://github.com/ucdavis/erplab/releases\">our GitHub site</a>. You can join the <a href=\"https://github.com/ucdavis/erplab/wiki/ERPLAB-email-list\">ERPLAB email list</a> to receive an announcement when this version is released. Please do not contact us with questions until it has been released and you have tried using it.</p><p class=\"\">On July 25, 2023, we will hold a 2-hour Zoom webinar to explain how decoding works at a conceptual level and show how to implement in ERPLAB Toolbox. The webinar will begin at 9:00 AM Pacific Time (California), 12:00 PM Eastern Time (New York), 5:00 PM British Summer Time (London), 6:00 PM Central European Summer Time (Berlin). </p><p class=\"\">The webinar is co-sponsored by the <a href=\"https://erpinfo.org/the-erp-boot-camp\">ERP Boot Camp</a> and the <a href=\"https://sprweb.org\">Society for Psychophysiological Research</a>. It is completely free, but you must register in advance at <a href=\"https://ucdavis.zoom.us/meeting/register/tJUrc-CtpzorEtBSmZXJINOlLJB9ZR0evpr4\">https://ucdavis.zoom.us/meeting/register/tJUrc-CtpzorEtBSmZXJINOlLJB9ZR0evpr4</a>. Once you register, you will receive an email with your own individual Zoom link. </p><p class=\"\">We will make a recording available a few days after the webinar on the <a href=\"https://erpinfo.org\">ERPinfo.org</a> web site.</p><p class=\"\">Please direct any questions about the webinar to <a href=\"mailto:erpbootcamp@gmail.com\">erpbootcamp@gmail.com</a>.</p>",
      "author": "Steve Luck",
      "published_date": "2023-06-23T21:05:26+00:00",
      "source": "Erp Boot Camp",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 420,
      "reading_time": 2,
      "created_at": "2025-12-02T16:31:31.366776+00:00",
      "updated_at": "2025-12-02T16:31:31.366777+00:00"
    },
    {
      "id": "7df2e655b8c09b49a328eaab20cde20d",
      "url": "https://www.biorxiv.org/content/10.1101/10.64898/2025.11.29.691344v1?rss=1",
      "title": "Progranulin loss induces mitochondrial dysfunction and ferroptosis in human cerebral organoids",
      "content": "Loss-of-function mutations in the granulin (GRN) gene cause frontotemporal dementia when the mutations are heterozygous and neuronal ceroid lipofuscinosis, a lysosomal storage disease, when homozygous. While it is well established that disease-causing GRN mutations decrease progranulin (PGRN) levels, leading to neurodegeneration, the cellular and molecular mechanisms underlying these conditions remain poorly understood. In this study, we utilized human induced pluripotent stem cell (iPSC) derived forebrain organoids to investigate the impact of PGRN homozygous deficiency on neuronal and glial cell populations. Through single-cell RNA sequencing, we identified robust downregulation of the mitochondrial oxidative phosphorylation pathway in PGRN KO organoids. In line with these results, PGRN KO organoids showed decreased mitochondrial respiration. Furthermore, our study demonstrated that PGRN loss induced increased levels of reactive oxygen species (ROS), lipid peroxidation and iron accumulation. Finally, we observed increased vulnerability to ferroptotic cell death in PGRN KO organoids. Our findings suggest that mitochondrial dysfunction and impaired responses to oxidative stress are early manifestations of PGRN loss, and offer insights into the molecular mechanisms driving neurodegeneration caused by PGRN deficiency.",
      "author": "Maciel Camargo, C., Almeida, M. C., Mejia-Cupajita, B., Hwang, I., Faynus, M. A., Carrettiero, D. C., Kosik, K. S.",
      "published_date": "2025-12-02T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 174,
      "reading_time": 1,
      "created_at": "2025-12-02T16:31:10.452723+00:00",
      "updated_at": "2025-12-02T16:31:10.452725+00:00"
    },
    {
      "id": "cab0fb4811c8012915c836e251d7b93a",
      "url": "https://www.biorxiv.org/content/10.1101/10.64898/2025.11.29.691294v1?rss=1",
      "title": "Early and transient increase in cortical pyramidal cell excitability and delayed alteration of evoked synaptic transmission and t-SNARE proteins content in the hippocampus and neocortex of neonatal and juvenile STXBP1 heterozygous mice",
      "content": "De novo mutations in the STXBP1 gene leads to the haploinsufficiency of Munc18.1 protein in patient, and represent one of the major causes of neurodevelopmental disorders including developmental epileptic and non-epileptic encephalopathies. Given the fundamental role of this protein in vesicular exocytosis, most electrophysiological studies have focused on the impact of this haploinsufficiency on synaptic transmission, and much less on intrinsic neuronal properties. Furthermore, the possibility that the electrophysiological consequences may be dependent on the developmental stage has not yet been investigated. Here, we analyze using acute brain slices from neonatal and juvenile STXBP1 heterozygous mice the intrinsic properties as well as spontaneous and evoked glutamatergic and GABAergic synaptic transmission in pyramidal cells located in the CA1 region of the hippocampus and in layers II/III of the motor cortex. We show that Munc18.1 deficiency has different electrophysiological consequences in neonatal (postnatal days, PND 4-7) and juvenile mice (PND30-35). The deficit of Munc18.1 leads to an increase in the intrinsic excitability of hippocampal and motor cortical pyramidal cells in neonates while in juveniles, it is evoked synaptic transmission that is affected, with a greater sensitivity of glutamatergic synapses than of GABAergic synapses in response to high-frequency electrical stimulation. However spontaneous ongoing synaptic activity mediated by glutamate and GABA receptors was unaffected at both stages of development. In addition, we performed western blot analysis and observed that Munc18.1 deficiency in STXBP1 heterozygous mice is associated with decreased t-SNARE proteins expression levels in the hippocampus and neocortex of juvenile but not neonatal mice. Therefore, Munc18.1 deficiency has multiple electrophysiological and biochemical consequences, which depend on the developmental stage. These data suggest also that an alteration in the function of some ion channels is one of the first electrophysiological consequences of the deficit of Munc18.1 and we suggest that the decrease in t-SNARE proteins expression could contribute to the normalization of pyramidal cells firing properties in juvenile.",
      "author": "Pineau, L., Becq, H., Pallesi, E., Brosset-Heckel, M., Biba Maazou, N., Montheil, A., Milh, M., Lenck-Santini, p.-p., aniksztejn, l.",
      "published_date": "2025-12-02T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 313,
      "reading_time": 1,
      "created_at": "2025-12-02T16:31:10.452687+00:00",
      "updated_at": "2025-12-02T16:31:10.452688+00:00"
    },
    {
      "id": "e1a85896af3d385805599bb36f3b7528",
      "url": "https://www.biorxiv.org/content/10.1101/10.64898/2025.11.30.691386v1?rss=1",
      "title": "Sleep fragmentation drives local, network-specific epileptic activity in human epilepsy",
      "content": "Although complex interactions between sleep and epilepsy have long been recognised, the directionality of the link between sleep fragmentation and epileptic activity remains unclear. We investigated causality in this relationship by experimentally manipulating sleep stability in individuals with drug-resistant focal epilepsy. Using combined stereo-electroencephalography (SEEG) and sleep recordings from 17 patients, alongside targeted auditory stimulation to induce arousals during non-rapid eye movement (NREM) sleep, we directly assessed how transient sleep disruption influences the occurrence and spatial propagation of interictal epileptiform discharges (IEDs) and examined key factors that modulate this relationship. We demonstrate that arousals acutely increase IED counts, with this effect being dependent on anatomical brain region, seizure-onset zone (SOZ) involvement, and sleep stage. Transient arousal-driven increases in IEDs were observed in neocortical regions, outside the SOZ and during NREM stage 2 sleep (N2), reflecting both regional and network-level specificity. Despite increasing IED counts, arousals did not influence IED propagation, indicating that sleep fragmentation selectively enhances local cortical excitability without engaging broader epileptic networks. Together, these findings highlight the critical role of sleep stability in shaping pathological activity, and support sleep stabilisation as a promising therapeutic strategy to reduce interictal spike burden during sleep and improve clinical outcomes.",
      "author": "Frauscher, B., Ho, A., Matouskova, B., Jaber, K., Avigdor, T., Minato, E., Thomas, J., Southwell, D. G., Hall, J., Klimes, P., Peter-Derex, L., Hannan, S.",
      "published_date": "2025-12-02T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 198,
      "reading_time": 1,
      "created_at": "2025-12-02T16:31:10.452644+00:00",
      "updated_at": "2025-12-02T16:31:10.452646+00:00"
    },
    {
      "id": "0de36ca06b00077911cb01a9ee012568",
      "url": "https://www.biorxiv.org/content/10.1101/10.64898/2025.11.29.691273v1?rss=1",
      "title": "Brainstem GLP-1 neurons modulate physiological satiation and drive sustained weight loss in obese mice",
      "content": "Glucagon-like peptide-1 receptor (GLP-1R) activation in the brain strongly reduces appetite, but most brain GLP-1Rs are not accessible for systemically administered GLP-1R agonists. Acute activation of nucleus tractus solitarius (NTS) GLP-1 neurons, targeting brain GLP-1Rs, strongly suppresses food intake separate from GLP-1R agonists. However, it is unknown if their chronic stimulation is a viable strategy for appetite suppression, or if obesity disrupts their function. Here we demonstrate that GLP-1 neurons, distributed through NTS and IRT, determine meal size and their number is inversely correlated with bodyweight gain. GLP-1 neurons in IRT and NTS differ in their inputs but generate outputs in largely overlapping areas. Higher body weight and fat mass predicts a higher percentage of active GLP-1 neurons. Their chemogenetic activation is an efficient means of reducing food intake, and in obese mice chronic activation elicits sustained weight loss. In conclusion, GLP-1 neurons are a feasible target for obesity treatment.",
      "author": "Jiang, W., Skoug, C., Rodrigues, I., Ciabatti, E., Gribble, F. M., Reimann, F., Brierley, D. I., Holt, M. K., Trapp, S.",
      "published_date": "2025-12-02T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 150,
      "reading_time": 1,
      "created_at": "2025-12-02T16:31:10.452609+00:00",
      "updated_at": "2025-12-02T16:31:10.452611+00:00"
    }
  ]
}