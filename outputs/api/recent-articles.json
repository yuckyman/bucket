{
  "last_updated": "2025-12-30T01:15:55.512403+00:00",
  "count": 20,
  "articles": [
    {
      "id": "91f6c782e21b9da934fcd29f01d2dfa0",
      "url": "https://www.embs.org/featured-news/welcoming-congratulating-our-newly-elected-embs-excom-members/",
      "title": "Welcoming & Congratulating Our Newly Elected EMBS ExCom Members",
      "content": "<p>The post <a href=\"https://www.embs.org/featured-news/welcoming-congratulating-our-newly-elected-embs-excom-members/\">Welcoming &#038; Congratulating Our Newly Elected EMBS ExCom Members</a> appeared first on <a href=\"https://www.embs.org\">IEEE EMBS</a>.</p>",
      "author": "Nancy Zimmerman",
      "published_date": "2025-12-14T18:48:47+00:00",
      "source": "Embs",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 18,
      "reading_time": 1,
      "created_at": "2025-12-29T23:21:22.965316+00:00",
      "updated_at": "2025-12-30T01:15:55.402263+00:00",
      "metadata": {
        "processed_at": "2025-12-30T01:15:55.402272+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "ab4c3d63daed430cad03bc37b5ff57b8",
      "url": "https://iopscience.iop.org/article/10.1088/1741-2552/ae220d",
      "title": "Enhancing SSVEP-BCI performance through multi-stimulus discriminant fusion analysis",
      "content": "Objective. To enhance frequency recognition in steady-state visual evoked potential (SSVEP)-based brain\u2013computer interfaces (BCIs), particularly under short data acquisition and complex environmental conditions. Approach. We propose multi-stimulus discriminant fusion analysis (MSDFA), a novel method that integrates multi-stimulus strategies with discriminant modeling. MSDFA was evaluated on two public datasets (Benchmark and BETA) and compared with conventional approaches including eCCA, eTRCA, and their variants. Main results. MSDFA consistently outperformed existing methods across different data lengths and training block quantities. It achieved maximum information transfer rates of 247.17\u2009\u00b1\u200910.15\u2009bpm on the Benchmark dataset and 192.72\u2009\u00b1\u20099.44\u2009bpm on the BETA dataset, demonstrating superior robustness and efficiency. Significance. By combining complementary algorithmic strengths, MSDFA improves adaptability to individual variability and complex environments, advancing the practical utility and reliability of SSVEP-BCI systems.",
      "author": "Senmiao Fang, Xi zhao, Zhenyu Wang, Yuan Si, Haifeng Liu, Honglin Hu, Tianheng Xu and Ting Zhou",
      "published_date": "2025-12-24T00:00:00+00:00",
      "source": "Journal Neural Engineering",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 130,
      "reading_time": 1,
      "created_at": "2025-12-29T23:20:55.503067+00:00",
      "updated_at": "2025-12-30T01:15:55.402277+00:00",
      "metadata": {
        "processed_at": "2025-12-30T01:15:55.402278+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "6a0ab316423ff20bacb5d20aa195f079",
      "url": "https://www.reddit.com/r/Python/comments/1py9ctf/the_gil_was_your_lock/",
      "title": "The GIL Was Your Lock",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>&gt; Free-threaded Python is the biggest change to the ecosystem in a decade. While it unlocks massive performance potential, it also removes the &quot;accidental synchronization&quot; we've grown used to. Check <a href=\"https://open.substack.com/pub/baarse/p/the-gil-was-your-lock?r=qjwrd&amp;utm_campaign=post&amp;utm_medium=web&amp;showWelcomeOnShare=true\">the full article</a>.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Helpful_Garbage_7242\"> /u/Helpful_Garbage_7242 </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1py9ctf/the_gil_was_your_lock/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1py9ctf/the_gil_was_your_lock/\">[comments]</a></span>",
      "author": "/u/Helpful_Garbage_7242",
      "published_date": "2025-12-29T01:58:10+00:00",
      "source": "Reddit Python",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 55,
      "reading_time": 1,
      "created_at": "2025-12-29T23:20:34.226176+00:00",
      "updated_at": "2025-12-30T01:15:55.402281+00:00",
      "metadata": {
        "processed_at": "2025-12-30T01:15:55.402283+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "6f7bd901e837599967fddc96185cd906",
      "url": "https://www.reddit.com/r/Python/comments/1pyly13/i_built_an_automated_git_documentation_tool_using/",
      "title": "I built an automated Git documentation tool using Watchdog and Groq to maintain a \"flow state\" histo",
      "content": "<!-- SC_OFF --><div class=\"md\"><p><a href=\"https://imgur.com/PSnT0EN\">https://imgur.com/PSnT0EN</a></p> <p><strong>Introduction</strong></p> <p>I\u2019m the kind of developer who either forgets to commit for hours or ends up with a git log full of &quot;update,&quot; &quot;fix,&quot; and &quot;asdf.&quot; I wanted a way to document my progress without breaking my flow. This is a background watcher that handles the documentation for me.</p> <p><strong>What My Project Does</strong></p> <p>This tool is a local automation script built with Watchdog and Subprocess. It monitors a project directory for file saves. When you hit save, it:</p> <ol> <li>Detects the modified file.</li> <li>Extracts the diff between the live file and the last committed version using git show HEAD.</li> <li>Sends the versions to Groq (Llama-3.1-8b-instant) for a sub-second summary.</li> <li>Automatically runs git add and git commit locally.</li> </ol> <p><strong>Target Audience</strong></p> <p>It\u2019s designed for developers who want a high-granularity history during rapid prototyping. It keeps the &quot;breadcrumb trail&quot; intact while you\u2019re in the flow, so you can look back and see exactly how a feature evolved without manual documentation effort. It is strictly for local development and does not perform any git push operations.</p> <p><strong>Comparison</strong></p> <p>Most auto-committers use generic timestamps or static messages, which makes history useless for debugging. Existing AI commit tools usually require a manual CLI command (e.g., git ai-commit). This project differs by being fully passive; it reacts to your editor's save event, requiring zero context switching once the script is running.</p> <p><strong>Technical Implementation</strong></p> <p>While this utilizes an LLM for message generation, the focus is the Python-driven orchestration of the Git workflow.</p> <ul> <li><strong>Event Handling:</strong> Uses watchdog for low-level OS file events.</li> <li><strong>Git Integration:</strong> Manages state through the subprocess module, handling edge cases like new/untracked files and preventing infinite commit loops.</li> <li><strong>Modular Design:</strong> The AI is treated as a pluggable component; the prompt logic is isolated so it could be replaced by a local regex parser or a different local LLM model.</li> </ul> <p><strong>Link to Source Code:</strong><br /> <a href=\"https://www.google.com/url?sa=E&amp;q=https%3A%2F%2Fgist.github.com%2FDDecoene%2Fa27f68416e5eec217f84cb375fee7d70\">https://gist.github.com/DDecoene/a27f68416e5eec217f84cb375fee7d70</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/MidnightBolt\"> /u/MidnightBolt </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1pyly13/i_built_an_automated_git_documentation_tool_using/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1pyly13/i_built_an_automated_git_documentation_tool_using/\">[comments]</a></span>",
      "author": "/u/MidnightBolt",
      "published_date": "2025-12-29T13:12:15+00:00",
      "source": "Reddit Python",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 335,
      "reading_time": 1,
      "created_at": "2025-12-29T23:20:34.226152+00:00",
      "updated_at": "2025-12-30T01:15:55.402285+00:00",
      "metadata": {
        "processed_at": "2025-12-30T01:15:55.402287+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "5b4da778158d92f8244c2a7f1bf6a7fe",
      "url": "https://github.com/mutable-state-inc/ensue-skill",
      "title": "Show HN: Stop Claude Code from forgetting everything",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46426624\">Comments</a>",
      "author": "",
      "published_date": "2025-12-29T22:30:25+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-29T23:20:33.023225+00:00",
      "updated_at": "2025-12-30T01:15:55.402289+00:00",
      "metadata": {
        "processed_at": "2025-12-30T01:15:55.402290+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "1e64128703d98be1aa559d62be69cbb1",
      "url": "https://alec.is/posts/ai-employees-dont-pay-taxes/",
      "title": "AI Employees Don't Pay Taxes",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46426596\">Comments</a>",
      "author": "",
      "published_date": "2025-12-29T22:28:53+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-29T23:20:33.023205+00:00",
      "updated_at": "2025-12-29T23:20:33.023207+00:00"
    },
    {
      "id": "1e64128703d98be1aa559d62be69cbb1",
      "url": "https://alec.is/posts/ai-employees-dont-pay-taxes/",
      "title": "AI Employees Don't Pay Taxes",
      "content": "<p>Article URL: <a href=\"https://alec.is/posts/ai-employees-dont-pay-taxes/\">https://alec.is/posts/ai-employees-dont-pay-taxes/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46426596\">https://news.ycombinator.com/item?id=46426596</a></p>\n<p>Points: 19</p>\n<p># Comments: 6</p>",
      "author": "arm32",
      "published_date": "2025-12-29T22:28:53+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-29T23:20:31.642897+00:00",
      "updated_at": "2025-12-29T23:20:31.642899+00:00"
    },
    {
      "id": "5b4da778158d92f8244c2a7f1bf6a7fe",
      "url": "https://github.com/mutable-state-inc/ensue-skill",
      "title": "Show HN: Stop Claude Code from forgetting everything",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46426624\">Comments</a>",
      "author": "",
      "published_date": "2025-12-29T22:30:25+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-29T23:20:33.023225+00:00",
      "updated_at": "2025-12-30T01:15:55.402289+00:00",
      "metadata": {
        "processed_at": "2025-12-30T01:15:55.402290+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "c2badf68cacc9dec3d628aadc12aa158",
      "url": "http://ieeexplore.ieee.org/document/11303644",
      "title": "Monolingual, Non-tone Bilingual, and Tone Bilingual Infants: Language Experiences Alter Speech and Nonspeech Perception",
      "content": "Studies on first-year infants' pitch perception have witnessed shifts of perceptual focus from acoustic to linguistic information and from a wide range of contrasts to those relevant to their native language. Nevertheless, how linguistic experience interacts with this developmental process remains an open question. This study compared the neural discrimination of speech/lexical and nonspeech/violin tone contrasts by 5- to 6- and 11- to 12-month-old infants across three types of language backgrounds: monolingual infants learning a non-tone language (Mono), bilingual infants learning two non-tone languages (Bi-NT), and bilingual infants learning a non-tone and a tone language (Bi-Tone). Although Mono infants do not show significant responses to the lexical tone contrast, both Bi-NT and Bi-Tone infants showed positive mismatch responses at both ages, indicating an enhancement effect brought by a complex language environment as early as 5 months after birth. Regarding the violin tone perception, distinct patterns were observed across language backgrounds: a perceptual decrease for Mono infants, no significant response for Bi-NT infants, and a perceptual increase for Bi-Tone infants over the first year. These patterns suggest that pitch perception may be affected across domains by language experiences at this stage, where interactions in cognitive processing between speech and nonspeech prosodic information may occur.",
      "author": "",
      "published_date": "2025-12-18T13:16:55+00:00",
      "source": "Cognitive Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 203,
      "reading_time": 1,
      "created_at": "2025-12-29T22:44:52.276762+00:00",
      "updated_at": "2025-12-29T22:44:52.276764+00:00"
    },
    {
      "id": "ab043b2bcd71b18a1c1891ad57329ddc",
      "url": "http://ieeexplore.ieee.org/document/11303559",
      "title": "Oscillatory Correlates of Metacontrol: Beta and Theta Band Contributions to Feedback-dependent Cognitive Adaptation",
      "content": "The ability to adapt to varying task demands is essential for goal-directed behavior. Cognitive control styles regulate this adaptation, with persistence reflecting high top\u2013down control and flexibility reflecting lower control. Metacontrol facilitates the dynamic adjustment between these states based on current demands. The present study investigated short-term feedback-dependent adaptations in cognitive control style during conflict monitoring. Behavioral results demonstrated that RT feedback promoted a more persistent cognitive control style in subsequent trials, improving performance in incongruent conditions while diminishing facilitative effects in congruent conditions. On the neurophysiological level, theta-band activity primarily reflected these changes during conflict processing. Crucially, intertrial interval analyses revealed a key role of beta-band activity in using RT feedback. Correlations with behavioral congruency effects suggested that decreased beta-band activity reflected a generally more flexible control style, whereas increased beta-band activity was associated with generally greater persistence. By demonstrating that pretrial beta-band modulations reflect cognitive control dispositions, this study provides novel insights into the neural mechanisms underlying metacontrol.",
      "author": "",
      "published_date": "2025-12-18T13:16:55+00:00",
      "source": "Cognitive Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 160,
      "reading_time": 1,
      "created_at": "2025-12-29T22:44:52.276729+00:00",
      "updated_at": "2025-12-29T22:44:52.276730+00:00"
    },
    {
      "id": "bc13a0801056a86eedc2331fa460c37f",
      "url": "http://ieeexplore.ieee.org/document/11303564",
      "title": "The Role of Rapid Eye Movement Sleep in Neural Differentiation of Memories in the Hippocampus",
      "content": "When faced with a familiar situation, we can use memory to make predictions about what will happen next. If such predictions turn out to be erroneous, the brain can adapt by differentiating the representations of the cue from the mispredicted item itself, reducing the likelihood of future prediction errors. Prior work by Kim, G., Norman, K. A., and Turk-Browne, N. B. Neural differentiation of incorrectly predicted memories. Journal of Neuroscience, 37, 2022\u20132031 [2017] found that violating a sequential association in a statistical learning paradigm triggered differentiation of the neural representations of the associated items in the hippocampus. Here, we used fMRI to test the preregistered hypothesis that this hippocampal differentiation occurs only when violations are followed by rapid eye movement (REM) sleep. Participants first learned that some items predict others (e.g., A predicts B) and then encountered a violation in which a predicted item (B) failed to appear when expected after its associated item (A); the predicted item later appeared on its own after an unrelated item. Participants were then randomly assigned to one of three conditions: remain awake, take a nap containing non-REM sleep only, or take a nap with both non-REM and REM sleep. While the predicted results were not observed in the preregistered left CA2/3/dentate gyrus (DG) ROI, we did observe evidence for our hypothesis in closely related hippocampal ROIs, uncorrected for multiple comparisons: In right CA2/3/DG, differentiation in the group with REM sleep was greater than in the groups without REM sleep (wake and non-REM nap); this differentiation was item-specific and concentrated in right DG. REM-related differentiation effects were also greater in bilateral DG when the predicted item was more strongly reactivated during the violation. Overall, these results provide initial evidence linking REM sleep to changes in the hippocampal representations of memories in humans.",
      "author": "",
      "published_date": "2025-12-18T13:16:55+00:00",
      "source": "Cognitive Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 298,
      "reading_time": 1,
      "created_at": "2025-12-29T22:44:52.276696+00:00",
      "updated_at": "2025-12-29T22:44:52.276697+00:00"
    },
    {
      "id": "053a64c388be11291b58cb5dddb68ec6",
      "url": "http://ieeexplore.ieee.org/document/11303561",
      "title": "Scene-sensitive Medial Temporal Lobe Subregions Are Recruited for the Integration of Non-scene Stimuli",
      "content": "A hallmark feature of episodic memory is the ability to flexibly recombine information across episodes to form new associations and guide behavior. This process, termed associative inference, relies on the hippocampus and surrounding medial temporal lobe (MTL) subregions. We previously found that cross-episode binding was improved when episodes were linked by scenes rather than by faces or objects. Here, we tested whether differential recruitment of category-sensitive MTL subregions underlies these behavioral differences. Participants completed study-test phases of the Associative Inference in Memory task while undergoing fMRI scanning. During the study phase, they encoded overlapping AB and BC pairs. A and C items were always objects. The linking B item was either a face or a scene. At test, memory for the direct (AB, BC) and indirect associations (inferred AC) was tested. Category sensitivity in MTL subregions was tested using an independent functional localizer and the low integration (AB) trials from the study phase of the Associative Inference in Memory task. Within the MTL, no subregions exhibited face sensitivity. The anterior hippocampal head, anterolateral and posteromedial entorhinal cortices, and parahippocampal cortex were identified as scene sensitive. Although accuracy of the indirect inferences did not differ between pairs linked by faces and scenes, MTL subregion recruitment differed across categories. Scene-sensitive subregions in MTL cortex (anterolateral entorhinal cortex, posteromedial entorhinal cortex, and parahippocampal cortex), but not the hippocampus (anterior hippocampal head), were recruited to support associative inference for faces during encoding. These findings suggest that regions in MTL cortex identified as scene sensitive here may be involved in integrating disparate elements of episodes into coherent representations, and may be recruited for non-scene stimuli when integration demands during encoding are high (e.g., during associative inference).",
      "author": "",
      "published_date": "2025-12-18T13:16:55+00:00",
      "source": "Cognitive Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 281,
      "reading_time": 1,
      "created_at": "2025-12-29T22:44:52.276654+00:00",
      "updated_at": "2025-12-29T22:44:52.276655+00:00"
    },
    {
      "id": "d07d9c88cf921ac53c3b05c1709a7d87",
      "url": "http://ieeexplore.ieee.org/document/11303567",
      "title": "Increasing Signal, Reducing Noise: Contrasting Neural Mechanisms of Attention in Visual Search",
      "content": "When invariant target\u2013distractor arrays are presented repeatedly during visual search, participants respond faster on repeated versus novel configuration trials. This effect reflects attentional guidance through long-term memory (LTM) templates\u2014a phenomenon termed contextual cueing. Subsequently, relocating the target within the same distractor layout abolishes any contextual cueing effects, and relearning the new target position is much harder than the initial learning\u2014likely due to consistent attentional misguidance toward the initial (learned) target position. Here, we studied how the different processes involved in contextual cueing and relearning affect the variability of neural responses in human participants as measured with EEG. Attention has previously been shown to reduce trial-by-trial variability in EEG [Arazi, A., Yeshurun, Y., & Dinstein, I. Neural variability is quenched by attention. Journal of Neuroscience, 39, 5975\u20135985, 2019], indicating that, in addition to increasing the neural response to an attended stimulus, attention may reduce the noise within the neural response itself. While repeated versus novel contexts did not modulate the trial-by-trial variability during initial learning, significant lateralized variability reductions were observed for repeated but not novel context trials in the relocations phase. This contrasts with how contextual cueing affected lateralized ERPs in past research. Zinchenko and colleagues [Zinchenko, A., Conci, M., T\u00f6llner, T., M\u00fcller, H. J., & Geyer, T. Automatic guidance (and misguidance) of visuospatial attention by acquired scene memory: Evidence from an N1pc polarity reversal. Psychological Science, 31, 1531\u20131543, 2020] found that lateralized ERPs signal correct and incorrect (i.e., misguided) attentional selection of target positions learned earlier. This phenomenon was observed during both the learning and relocation phases. Thus, variability and lateralized ERPs may represent different facets of attention, where variability becomes evident specifically under high attentional demand conditions, such as when participants must override the misguidance caused by LTM templates.",
      "author": "",
      "published_date": "2025-12-18T13:16:55+00:00",
      "source": "Cognitive Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 291,
      "reading_time": 1,
      "created_at": "2025-12-29T22:44:52.276615+00:00",
      "updated_at": "2025-12-29T22:44:52.276617+00:00"
    },
    {
      "id": "f95a9f64dc97257327f12c06475d3643",
      "url": "http://ieeexplore.ieee.org/document/11303565",
      "title": "The Neural Bases of Graphical Perception: A Novel Instance of Cultural Recycling?",
      "content": "Graphical representations of quantitative data abound in our culture, and yet the brain mechanisms of graphicacy, by which viewers quickly extract statistical information from a data graphic, are unknown. Here, using scatterplots as stimuli, we tested two hypotheses about the brain areas underlying graphicacy. First, at the perceptual level, we hypothesized that the visual processing of scatterplots and their main trend recycles cortical regions devoted to the perception of the principal axis of objects. Second, at a higher level, we speculated that the math-responsive network active during arithmetic and mathematical truth judgments should also be involved in graphical perception. Using fMRI, we indeed found that the judgment of the trend in a scatterplot recruits a right lateral occipital area involved in detecting the orientation of objects, as well as a right anterior intraparietal region also recruited during mathematical tasks. Both behavior and brain activity were driven by the t value that indexes the statistical correlation in the data, and right intraparietal activation covaried with participants' graphicacy level. On the basis of this first approach to the neural bases of graphical perception, we suggest that, like literacy and numeracy, graphicacy relies on the recycling of brain areas previously attuned to a similar problem, here the perception of object orientation.",
      "author": "",
      "published_date": "2025-12-18T13:16:55+00:00",
      "source": "Cognitive Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 208,
      "reading_time": 1,
      "created_at": "2025-12-29T22:44:52.276567+00:00",
      "updated_at": "2025-12-29T22:44:52.276568+00:00"
    },
    {
      "id": "cfdf4cdfc85c3633062d4f70f1a372c0",
      "url": "http://ieeexplore.ieee.org/document/11303571",
      "title": "Neural Evidence for Tonal Prediction: Multivariate Decoding of Predicted Tone Categories Using Functional Magnetic Resonance Imaging Data",
      "content": "Predictive processing plays a central role in language comprehension, allowing listeners to generate predictions about upcoming linguistic input. Although considerable evidence supports segmental prediction, less is known about whether listeners can form predictions about suprasegmental features such as lexical tone. This study investigates whether listeners can generate and neurally represent predicted tonal information in the absence of auditory input. Using a Mandarin Chinese tone sandhi paradigm, we established tonal predictions based on sentence and visual context, recording brain activity with functional magnetic resonance imaging. Multivariate pattern analysis showed that predicted tonal categories could be decoded from brain activity even without tonal stimuli present. These representations were localized in auditory areas, articulatory motor regions, and the right cerebellum. We also found that predicted tone representations had distinct neural substrates compared to perceived tone representations. The study provides direct neural evidence that listeners can form representations of lexical tone in predictions of auditory input. The findings expand our understanding of suprasegmental prediction in speech and highlight the cerebellum's role in linguistic prediction.",
      "author": "",
      "published_date": "2025-12-18T13:16:55+00:00",
      "source": "Cognitive Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 170,
      "reading_time": 1,
      "created_at": "2025-12-29T22:44:52.276532+00:00",
      "updated_at": "2025-12-29T22:44:52.276534+00:00"
    },
    {
      "id": "301d3b51ba3b7d4480873efc4d9dc87b",
      "url": "http://ieeexplore.ieee.org/document/11303645",
      "title": "Typical Perceptual Sensitivity to Changes in Interpersonal Distance in Developmental Prosopagnosia",
      "content": "Social perception research has traditionally sought to elucidate the visual processing engaged by the faces and bodies of individuals. Recently, however, there has been growing interest in how we perceive dyadic interactions between people. Early findings suggest that dyads arranged face-to-face may engage neurocognitive processing similar to that recruited by faces. Given these parallels, we sought to determine whether individuals with developmental prosopagnosa (DP), who exhibit lifelong face recognition difficulties, also exhibit impaired perception of facing dyads. The focus of our investigation was interpersonal distance\u2014a key visual feature of dyadic social interactions. Participants completed three distance change detection tasks. Two of the tasks depicted distance changes during dyadic social interactions (fighting and dancing). A third task depicted distance changes using nonsocial objects (a pair of grandfather clocks). If DP is associated with impoverished perception of dyadic interactions, we reasoned that individuals with DP should exhibit diminished sensitivity to distance changes on the dancers task and the boxers task, but not on the clocks task. Contrary to this prediction, however, individuals with DP and typical controls did not differ significantly in their ability to detect distance changes on any of the tasks. Although the visual processing of faces and facing dyads exhibit certain similarities, these findings suggest that the underlying perceptual mechanisms may dissociate.",
      "author": "",
      "published_date": "2025-12-18T13:16:55+00:00",
      "source": "Cognitive Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 213,
      "reading_time": 1,
      "created_at": "2025-12-29T22:44:52.276497+00:00",
      "updated_at": "2025-12-29T22:44:52.276499+00:00"
    },
    {
      "id": "e3ec69f3c8697bf33383e62c0473d5c0",
      "url": "http://ieeexplore.ieee.org/document/11303570",
      "title": "The Interactive Effects of Negative Emotion and Reward Motivation on Visual Perception",
      "content": "Although there is a rapidly growing interest in reward\u2013emotion interactions, our current understanding of how negative emotion influences reward motivation and modulates reward-driven enhancements in visual perception remains limited. To address these gaps, we conducted an fMRI study using a novel variant of the monetary incentive delay task where the valence (negative or neutral) of an emotional scene image served as a cue to indicate a reward or no-reward prospect in the subsequent house\u2013building discrimination task. During the initial cue stage, we hypothesized competitive interactions between reward anticipation and negative emotion along the common value/valence dimension. However, we instead found independent neural signatures of reward (vs. no-reward) anticipation in the ventral striatum and negative (vs. neutral) emotion in the ventromedial pFC and amygdala, with a lack of evidence for their interaction. Notably, during the subsequent task stage, we detected an Emotion \u00d7 Reward interaction in the parahippocampal gyrus (PHG), wherein reward-driven enhancements in task-related processing were attenuated in the case of negative (vs. neutral) cue images. Furthermore, the Emotion \u00d7 Reward interaction scores in PHG and behavioral RTs were correlated across participants. Finally, a regression analysis revealed that negative valence-related activity in ventromedial pFC moderated the relationship between ventral striatum reward anticipation activity and PHG task-related processing. These findings demonstrate that negative emotion and reward motivation, which were largely segregated during the cue stage, interactively modulated subsequent visual perception, thus potentially influencing behavior.",
      "author": "",
      "published_date": "2025-12-18T13:16:55+00:00",
      "source": "Cognitive Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 233,
      "reading_time": 1,
      "created_at": "2025-12-29T22:44:52.276457+00:00",
      "updated_at": "2025-12-29T22:44:52.276459+00:00"
    },
    {
      "id": "75ea4dfc0e3afdf03fcdbd572a25e70e",
      "url": "http://ieeexplore.ieee.org/document/11303560",
      "title": "Suppressive Interactions between Nearby Stimuli in Visual Cortex Reflect Crowding",
      "content": "Crowding is a phenomenon in which visual object identification is impaired by the close proximity of other stimuli. The neural processes leading to object recognition and its breakdown as seen in crowding are still debated. To assess how crowding affects the processing of stimuli in visual cortex, we recorded steady-state visual evoked potentials (SSVEPs) elicited by flickering target and flanker stimuli while manipulating the spacing of these stimuli (Experiment 1) as well as target similarity (Experiment 2). Participants who performed an orientation discrimination task while proportion correct, along with frequency-tagged SSVEPs elicited by target and flanker stimuli, were recorded. Decreasing target\u2013flanker distance reduced both behavioral performance and target-elicited SSVEP amplitudes. Estimates of the critical spacing, a measure of the spatial extent of crowding, from both behavioral data and SSVEP amplitudes were similar. In addition, manipulating target similarity affected both measures in the same way. These findings establish a clear connection between the suppression of stimulus processing by nearby flankers in visual cortex and crowding, and demonstrate the usefulness of SSVEPs in studying the cortical mechanisms of visual crowding.",
      "author": "",
      "published_date": "2025-12-18T13:16:55+00:00",
      "source": "Cognitive Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 178,
      "reading_time": 1,
      "created_at": "2025-12-29T22:44:52.276406+00:00",
      "updated_at": "2025-12-29T22:44:52.276411+00:00"
    },
    {
      "id": "408594270cea960481b2fd7d929a85bd",
      "url": "https://www.sciencedirect.com/science/article/pii/S105381192500641X?dgcid=rss_sd_all",
      "title": "Does nonsense make sense? A springboard to studying dynamic reconfiguration of large-scale networks during semantic and intonation speech processing",
      "content": "<p>Publication date: January 2026</p><p><b>Source:</b> NeuroImage, Volume 325</p><p>Author(s): Irina Anurova, Katarzyna Ciesla, Amir Amedi</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroimage",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-29T22:44:40.365529+00:00",
      "updated_at": "2025-12-29T22:44:40.365531+00:00"
    },
    {
      "id": "893eae5ef0641a147cddc0a80e73971b",
      "url": "https://manus.im/blog/manus-joins-meta-for-next-era-of-innovation",
      "title": "ManusAI Joins Meta",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46426534\">Comments</a>",
      "author": "",
      "published_date": "2025-12-29T22:24:22+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-29T22:43:59.933980+00:00",
      "updated_at": "2025-12-29T22:43:59.933982+00:00"
    }
  ]
}