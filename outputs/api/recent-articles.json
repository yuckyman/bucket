{
  "last_updated": "2025-11-22T14:40:39.302600+00:00",
  "count": 20,
  "articles": [
    {
      "id": "3cace5c5d9bdc4eeebb05365c3e99538",
      "url": "http://doi.org/10.1037/cns0000402",
      "title": "Creating a world in the head: The conscious apprehension of neural content originating from internal sources.",
      "content": "Klein et al. (2023) argued that the evolutionary transition from respondent to agent during the Cambrian explosion would be a promising vantage point from which to gain insight into the evolution of organic sentience. They focused on how increased competition for resources\u2014in consequence of the proliferation of new, neurally sophisticated life-forms\u2014made awareness of the external world (in the service of agentic acts) an adaptive priority. The explanatory scope of Klein et al. (2023) was limited to consideration of the conscious apprehension of externally sourced content\u2014that is, content delivered from the sensory registration of objects occupying phenomenal space. But consciousness\u2014at least for humans\u2014takes its objects from internal as well as external sources. In the present article, we extend their analysis to the question of how internally sourced content (i.e., mental states) became the object of conscious apprehension. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2024-09-09T00:00:00+00:00",
      "source": "Clinical Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 145,
      "reading_time": 1,
      "created_at": "2025-11-22T14:39:41.687146+00:00",
      "updated_at": "2025-11-22T14:39:41.687148+00:00"
    },
    {
      "id": "17fd32a0af4cc19c41e4b1f77e98aa79",
      "url": "https://arstechnica.com/space/2025/11/the-twin-probes-just-launched-toward-mars-have-an-easter-egg-on-board/",
      "title": "The twin probes just launched toward Mars have an Easter egg on board",
      "content": "<a href=\"https://news.ycombinator.com/item?id=45936776\">Comments</a>",
      "author": "",
      "published_date": "2025-11-15T11:49:24+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-11-22T14:39:33.412741+00:00",
      "updated_at": "2025-11-22T14:39:33.412743+00:00"
    },
    {
      "id": "4dc92cbf63e410e4d59f6ffd2f7dec90",
      "url": "http://doi.org/10.1037/cns0000406",
      "title": "Not all minds think alike: Examining the impact of time and task on visual and verbal thought.",
      "content": "Research suggests that individuals have different phenomenological experiences across various tasks. However, little is known about how these experiences vary by task or over time. This study examined participants\u2019 experiences of task-unrelated thoughts (i.e., TUTs), visual, and verbal thoughts across two experimental sessions and two different tasks. In addition, we examined relations between participants\u2019 thoughts and key individual difference factors. In Session 1, participants (<em>n</em> = 85) engaged in a focused-attention meditation and a reading task, then completed a second identical session with a new text. Throughout both tasks, participants were prompted to report on the characteristics of their thoughts. Participants\u2019 ratings of TUT, visual, and verbal thoughts were subject to change over time. Furthermore, on average, participants visualized more and had fewer TUTs while reading compared to meditation; however, no task difference was found for verbal-thinking reports. This suggests that visual imagery is more malleable than verbal-thinking. There was a strong negative correlation between visual and verbal thoughts, suggesting that at any given time, individuals\u2019 thoughts tended to be either predominantly visual or verbal. Finally, individual differences in the tendency to become immersed in narratives and motivation to engage with other people\u2019s perspectives (i.e., mind-reading motivation) were related to higher reports of visual imagery during reading, whereas verbal-thinking was negatively associated with mind-reading motivation and unrelated to TUT. Overall, this study revealed that individuals\u2019 phenomenological experiences vary during tasks and across time, providing a foundation for future work to examine why and how variability in these phenomenological experiences emerge. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2024-10-14T00:00:00+00:00",
      "source": "Clinical Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 259,
      "reading_time": 1,
      "created_at": "2025-11-22T14:17:37.872787+00:00",
      "updated_at": "2025-11-22T14:17:37.872790+00:00"
    },
    {
      "id": "a8adb8e21ba8ade167865b32c18747a2",
      "url": "http://ieeexplore.ieee.org/document/11235877",
      "title": "Separate Timescales for Spatial and Anatomical Information Processing of Body Stimuli",
      "content": "Observing different body stimuli can influence the speed and accuracy of our responses. Prior work indicates this effect is influenced by factors such as spatial congruence and perspective. We hypothesized that the influence of these factors would vary depending on the amount of time that participants had to process visual stimuli. Experiment 1 was a RT task (n = 29) with stimuli varying in spatial congruence (congruent, incongruent, neutral), perspective (first- or third-person), and stimulus type (body or control). Experiment 2 (n = 50) used the same stimuli in a \u201cForced Response\u201d paradigm, which controlled the time participants had to prepare a response. This allowed us to assess responses as a function of preparation time. Experiment 1 showed effects of spatial congruence, with longer RTs and more errors for spatially incongruent stimuli. This effect was greater for body stimuli. Experiment 2 showed that spatial information was processed faster than anatomical information, inducing incorrect responses at short preparation times for spatially incongruent body stimuli. There was little-to-no corresponding effect for control stimuli. Both experiments also showed weak-to-no effects of perspective, which appear to have been driven by spatial congruence. Our results indicate that spatial information is processed faster than anatomical information during observation of body stimuli. These data are consistent with the dual visual streams hypothesis, whereby spatial information would be processed rapidly via the dorsal stream, whereas anatomical processing would occur later via the ventral stream. These data also indicate differences in processing between body and control stimuli.",
      "author": "",
      "published_date": "2025-11-07T13:16:23+00:00",
      "source": "Cognitive Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 248,
      "reading_time": 1,
      "created_at": "2025-11-22T13:40:51.824416+00:00",
      "updated_at": "2025-11-22T14:13:09.150699+00:00",
      "metadata": {
        "processed_at": "2025-11-22T14:13:09.150708+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "fb588439a33dbfe3eb0b3edf79a54446",
      "url": "http://ieeexplore.ieee.org/document/11235874",
      "title": "Transient Inhibition of the Posterior Parietal Cortex Affects Action-related But Not Action-unrelated Visual Processing during Path Integration",
      "content": "Path integration refers to the ability to monitor self-motion cues to keep track of changes in position and orientation. This function is often assumed to rely predominantly on medial temporal lobe structures containing grid, place, and head direction cells. Recent evidence, however, suggests that key navigational computations may occur outside this system, for example, in posterior parietal areas. Here, we adopted a novel perspective derived from animal research and examined whether human path integration relies on processing streams in the posterior parietal cortex (PPC), depending on the involvement of actively controlled motion as opposed to passive perception of visual optic flow. We compared the effects of inhibiting the PPC via TMS on two path integration tasks in a virtual reality, only one of which involved active control of a visually simulated forward movement. Behavioral performance showed that distance judgments were selectively affected in the action-related path integration task. This finding shows that the processing of actively controlled motion depends on computations in the PPC, whereas passive processing of optic flow is largely independent of the PPC computations. Our results reinforce the hypothesis that the PPC plays a critical role for the integration of goal locations and self-positional signals within an egocentric frame of reference. In addition to the medial temporal lobe, the posterior parietal system is recruited during tasks involving actively controlled movements, whereas medial temporal computations are sufficient for passive monitoring of positional changes.",
      "author": "",
      "published_date": "2025-11-07T13:16:23+00:00",
      "source": "Cognitive Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 235,
      "reading_time": 1,
      "created_at": "2025-11-22T13:40:51.824364+00:00",
      "updated_at": "2025-11-22T14:13:09.150712+00:00",
      "metadata": {
        "processed_at": "2025-11-22T14:13:09.150714+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "18c3c12e475b78177dd66fbb81fefe5e",
      "url": "https://cdn.openai.com/pdf/41df8f28-d4ef-43e9-aed2-823f9393e470/circuit-sparsity-paper.pdf",
      "title": "Weight-sparse transformers have interpretable circuits [pdf]",
      "content": "<a href=\"https://news.ycombinator.com/item?id=45926371\">Comments</a>",
      "author": "",
      "published_date": "2025-11-14T13:08:27+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-11-22T13:40:01.910926+00:00",
      "updated_at": "2025-11-22T14:13:09.150717+00:00",
      "metadata": {
        "processed_at": "2025-11-22T14:13:09.150718+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "62665642553d5bcd7a03c8004f9733d9",
      "url": "https://www.biorxiv.org/content/10.1101/2025.11.21.689649v1?rss=1",
      "title": "Two-photon characterisation of long-Stokes-shift dye ATTO 490LS for single-laser multicolour imaging",
      "content": "Long-Stokes-shift fluorophores enable high sensitivity and multiplexed imaging with single-wavelength excitation. Under single-photon conditions ATTO 490LS exhibits a 165-nm Stokes shift, but its two-photon properties remain uncharacterised. Emission and excitation spectral analyses of ATTO 490LS in ex vivo Drosophila melanogaster brains identified two-photon excitation sensitivity at 940 nm, with peak emission at 640 nm. We demonstrate successful duplexed imaging of ATTO 490LS alongside Alexa Fluor 488 using a single 920-nm fibre laser and dual photomultiplier tubes, enabling distinct measurement of red and green fluorescence signals. These findings establish ATTO 490LS as suitable for multicolour two-photon microscopy with single-laser systems.",
      "author": "Cheung, K. Y., Wu, Y., Lee, S. Y., Zhang, X., Fukuda, M., Claridge-Chang, A.",
      "published_date": "2025-11-22T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 99,
      "reading_time": 1,
      "created_at": "2025-11-22T13:24:46.368745+00:00",
      "updated_at": "2025-11-22T14:13:09.150721+00:00",
      "metadata": {
        "processed_at": "2025-11-22T14:13:09.150722+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "c9813f7e2686b875916ad9e5f34c9c42",
      "url": "https://www.biorxiv.org/content/10.1101/2025.11.20.689599v1?rss=1",
      "title": "Neural dynamics outside task-coding dimensions drive decision trajectories through transient amplification",
      "content": "Most behaviors involve neural dynamics in high-dimensional activity spaces. A common approach is to extract dimensions that capture task-related variability, such as those separating stimuli or choices, yielding low-dimensional, task-aligned neural activity subspaces (\"coding dimensions\"). However, whether these dimensions actively drive decisions or merely reflect underlying computations remains unclear. Moreover, neural activity outside these coding subspaces (\"residual dimensions\") is often ignored, though it could also causally shape neural dynamics driving behavior. We developed a recurrent neural network model that fits population activity and uncovers the dynamic interactions between coding and residual subspaces on single trials. Applied to electrophysiological recordings from the anterior lateral motor cortex (ALM) and motor thalamus in mice performing a delayed response task, our model demonstrates that perturbations of residual dimensions reliably alter behavioral choices, whereas perturbations of the choice dimension, which strongly encodes the animal's upcoming decision, are largely ineffective. These perturbation effects arise because residual dimensions drive transient amplification across an intermediate number of coding and residual dimensions (~10), before the dynamics collapse into discrete attractor states corresponding to the animal's choice. By dissecting the low-dimensional variability underlying error trials, we find that it primarily shifts trajectories along residual dimensions, biasing single decisions. Residual activity in thalamus shapes cortical decision dynamics, implicating weakly selective thalamic populations in the emergence of cortical selectivity. Our findings challenge the conventional focus on low-dimensional coding subspaces as sufficient framework for understanding neural computations, demonstrating that dimensions previously considered task-irrelevant and accounting for little variance can have a critical role in driving behavior.",
      "author": "Pereira-Obilinovic, U., Daie, K., Chen, S., Svoboda, K., Darshan, R.",
      "published_date": "2025-11-22T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 253,
      "reading_time": 1,
      "created_at": "2025-11-22T13:24:46.368717+00:00",
      "updated_at": "2025-11-22T14:13:09.150724+00:00",
      "metadata": {
        "processed_at": "2025-11-22T14:13:09.150726+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "3732647e5d51f3021952b6c4f815999d",
      "url": "https://www.biorxiv.org/content/10.1101/2025.11.20.689570v1?rss=1",
      "title": "High extraversion enhances attentional control through dynamic network reorganization",
      "content": "The extraversion-introversion dimension of personality is hypothesized to differ based on low or high cortical arousal, respectively. Notably, high cortical arousal in introverts is thought to underlie increased distractibility. Here, we assess fMRI while participants meditate (focused attention to their breath) under three levels of auditory distraction: no, low and high. Whereas introverts exhibited worsening attentional focus on their breath with increasing distraction, extraverts retained their ability to focus attention despite distraction. Dynamic functional connectivity analysis indicated that extraverts exhibited less globally efficient and less modular networks, which may prevent distracting stimuli from creating interference. Furthermore, connectivity strengths amongst the default mode, central executive, and salience networks were increased for extraverts and decreased in introverts during high focused attention; potentially indicating distinct cognitive processes that support attentional control. These findings support the hypothesis regarding differing levels of cortical arousal in extraverts and introverts and extend personality theory by linking the extraversion dimension to attentional control and functional connectivity dynamics.",
      "author": "Chen, J. C. C., Nandi, B., Campusano, R., Jiang, F., Ziegler, D., Gazzaley, A., Zanto, T.",
      "published_date": "2025-11-22T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 159,
      "reading_time": 1,
      "created_at": "2025-11-22T13:24:46.368670+00:00",
      "updated_at": "2025-11-22T13:24:46.368672+00:00"
    },
    {
      "id": "fb77e055ff1bd60dfb4095d8617cfe3e",
      "url": "https://www.biorxiv.org/content/10.1101/2025.11.20.689621v1?rss=1",
      "title": "Multiple longitudinal tracts in the cephalopod arm sensorimotor system",
      "content": "Octopuses have an incredibly rich behavioral repertoire, exhibiting complex motor acts that require the coordination of eight highly flexible arms, each with hundreds of suckers. These movements are controlled by an axial nerve cord (ANC), equivalent to the spinal cord, situated in the center of the arm musculature. The ANC has a cell body layer which forms a U-shape around its neuropil and is capped aborally, or opposite the sucker, by the cerebrobrachial tract (CBT), a massive fiber bundle known to interconnect the arms and the brain. In vertebrate spinal cords, in addition to the major fiber tracts that interconnect the brain and spinal cord, there are spinospinal connectives that coordinate complex motor behaviors across the appendages. Here, we asked with tract-tracing and immunohistochemistry, whether an octopus arm's ANC might also have intrinsic longitudinal connections for coordinated arm and sucker movements. We found that the ANC neuropil is enriched in longitudinal fibers. These fibers form distinct tracts, two within the oral (sucker-side) neuropil and two in the aboral (brachial-side) neuropil. In addition, CBT itself demonstrates four major subtracts, and DiI labeling and dextran tracing suggests that (1) the CBT also carries arm-intrinsic longitudinal connections and (2) the CBT and the neuropil tracts can be subcategorized into those that primarily connect with the sucker and those that serve the arm musculature. We also examined the organization of fiber-tracts in the ANC of the arms and tentacles of two species of squid, establishing that an aboral, extra-neuropil tract is a shared feature across all cephalopod species studied. In addition, the squids also had an oral longitudinal tract, though its positioning and size varied with species and appendage. In sum, these findings describe the neural substrate for coordinating motor behaviors across the length of a cephalopod appendage.",
      "author": "Olson, C. S., Ragsdale, C. W.",
      "published_date": "2025-11-22T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 294,
      "reading_time": 1,
      "created_at": "2025-11-22T13:24:46.368631+00:00",
      "updated_at": "2025-11-22T13:24:46.368635+00:00"
    },
    {
      "id": "dcbd797cd2d38c39dc41975d275f3b96",
      "url": "https://www.reddit.com/r/Python/comments/1p30v4c/mission_for_a_python_developer/",
      "title": "Mission for a python developer",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone, hope you\u2019re doing well!</p> <p>I\u2019m currently looking for a skilled developer to build an automated PDF-splitting solution using machine learning and AI.</p> <p>I already have a few document codes available. The goal of the script is to detect the type of each document and classify it accordingly.</p> <p>Here\u2019s the context: the Python script will receive a PDF file that may contain multiple documents merged together. The objective is to automatically recognize each document type and split the file into separate PDFs based on the classification.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Adsvisor\"> /u/Adsvisor </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1p30v4c/mission_for_a_python_developer/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1p30v4c/mission_for_a_python_developer/\">[comments]</a></span>",
      "author": "/u/Adsvisor",
      "published_date": "2025-11-21T15:01:24+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 108,
      "reading_time": 1,
      "created_at": "2025-11-22T13:24:06.192865+00:00",
      "updated_at": "2025-11-22T13:24:06.192867+00:00"
    },
    {
      "id": "f33aff11d24229c6b399f8380f3e09a2",
      "url": "https://blog.datameister.ai/detection-transformers-real-time-object-detection",
      "title": "Why DETRs are replacing YOLOs for real-time object detection",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46013900\">Comments</a>",
      "author": "",
      "published_date": "2025-11-22T11:21:27+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-11-22T13:24:04.779605+00:00",
      "updated_at": "2025-11-22T13:24:04.779606+00:00"
    },
    {
      "id": "c410c606971421068ff24ecf9027b699",
      "url": "https://lucumr.pocoo.org/2025/11/21/agents-are-hard/",
      "title": "Agent Design Is Still Hard",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46013935\">Comments</a>",
      "author": "",
      "published_date": "2025-11-22T11:27:24+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-11-22T13:24:04.779489+00:00",
      "updated_at": "2025-11-22T13:24:04.779491+00:00"
    },
    {
      "id": "f33aff11d24229c6b399f8380f3e09a2",
      "url": "https://blog.datameister.ai/detection-transformers-real-time-object-detection",
      "title": "Why DETRs are replacing YOLOs for real-time object detection",
      "content": "<p>Article URL: <a href=\"https://blog.datameister.ai/detection-transformers-real-time-object-detection\">https://blog.datameister.ai/detection-transformers-real-time-object-detection</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46013900\">https://news.ycombinator.com/item?id=46013900</a></p>\n<p>Points: 8</p>\n<p># Comments: 0</p>",
      "author": "axelvlaminck",
      "published_date": "2025-11-22T11:21:27+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-11-22T13:24:03.671960+00:00",
      "updated_at": "2025-11-22T13:24:03.671961+00:00"
    },
    {
      "id": "c410c606971421068ff24ecf9027b699",
      "url": "https://lucumr.pocoo.org/2025/11/21/agents-are-hard/",
      "title": "Agent Design Is Still Hard",
      "content": "<p>Article URL: <a href=\"https://lucumr.pocoo.org/2025/11/21/agents-are-hard/\">https://lucumr.pocoo.org/2025/11/21/agents-are-hard/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46013935\">https://news.ycombinator.com/item?id=46013935</a></p>\n<p>Points: 9</p>\n<p># Comments: 0</p>",
      "author": "the_mitsuhiko",
      "published_date": "2025-11-22T11:27:24+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-11-22T13:24:03.671938+00:00",
      "updated_at": "2025-11-22T13:24:03.671940+00:00"
    },
    {
      "id": "b8dd870bfe7c0db7344e4da857095e1c",
      "url": "https://monotropism.org/adhd/",
      "title": "ADHD and Monotropism (2023)",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46013960\">Comments</a>",
      "author": "",
      "published_date": "2025-11-22T11:31:30+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-11-22T12:36:51.374779+00:00",
      "updated_at": "2025-11-22T12:36:51.374780+00:00"
    },
    {
      "id": "c669509d502ea7ca7a340e68646d298a",
      "url": "https://stratechery.com/2025/an-interview-with-unity-ceo-matthew-bromberg-about-turnarounds/",
      "title": "An Interview with Unity CEO Matthew Bromberg About Turnarounds",
      "content": "<a href=\"https://news.ycombinator.com/item?id=45913432\">Comments</a>",
      "author": "",
      "published_date": "2025-11-13T11:01:49+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-11-22T12:36:51.374628+00:00",
      "updated_at": "2025-11-22T12:36:51.374629+00:00"
    },
    {
      "id": "69e07cda9853a036b54cd7945993c6f5",
      "url": "https://blog.melashri.net/micro/privacy-price/",
      "title": "My private information is worth $30",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46013816\">Comments</a>",
      "author": "",
      "published_date": "2025-11-22T11:04:15+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-11-22T12:36:51.374576+00:00",
      "updated_at": "2025-11-22T12:36:51.374580+00:00"
    },
    {
      "id": "10d43f08eb50186f5ca70a2ac76d890f",
      "url": "https://www.openwall.com/lists/oss-security/2025/11/22/1",
      "title": "Libpng 1.6.51: Four buffer overflow vulnerabilities fixed",
      "content": "<p>Article URL: <a href=\"https://www.openwall.com/lists/oss-security/2025/11/22/1\">https://www.openwall.com/lists/oss-security/2025/11/22/1</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46013579\">https://news.ycombinator.com/item?id=46013579</a></p>\n<p>Points: 16</p>\n<p># Comments: 3</p>",
      "author": "ledoge",
      "published_date": "2025-11-22T10:08:31+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-11-22T12:36:49.937228+00:00",
      "updated_at": "2025-11-22T12:36:49.937229+00:00"
    },
    {
      "id": "69e07cda9853a036b54cd7945993c6f5",
      "url": "https://blog.melashri.net/micro/privacy-price/",
      "title": "My private information is worth $30",
      "content": "<p>Article URL: <a href=\"https://blog.melashri.net/micro/privacy-price/\">https://blog.melashri.net/micro/privacy-price/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46013816\">https://news.ycombinator.com/item?id=46013816</a></p>\n<p>Points: 39</p>\n<p># Comments: 28</p>",
      "author": "elashri",
      "published_date": "2025-11-22T11:04:15+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-11-22T12:36:49.937186+00:00",
      "updated_at": "2025-11-22T12:36:49.937188+00:00"
    }
  ]
}