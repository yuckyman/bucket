{
  "last_updated": "2025-12-16T06:36:33.147888+00:00",
  "count": 20,
  "articles": [
    {
      "id": "fb588439a33dbfe3eb0b3edf79a54446",
      "url": "http://ieeexplore.ieee.org/document/11235874",
      "title": "Transient Inhibition of the Posterior Parietal Cortex Affects Action-related But Not Action-unrelated Visual Processing during Path Integration",
      "content": "Path integration refers to the ability to monitor self-motion cues to keep track of changes in position and orientation. This function is often assumed to rely predominantly on medial temporal lobe structures containing grid, place, and head direction cells. Recent evidence, however, suggests that key navigational computations may occur outside this system, for example, in posterior parietal areas. Here, we adopted a novel perspective derived from animal research and examined whether human path integration relies on processing streams in the posterior parietal cortex (PPC), depending on the involvement of actively controlled motion as opposed to passive perception of visual optic flow. We compared the effects of inhibiting the PPC via TMS on two path integration tasks in a virtual reality, only one of which involved active control of a visually simulated forward movement. Behavioral performance showed that distance judgments were selectively affected in the action-related path integration task. This finding shows that the processing of actively controlled motion depends on computations in the PPC, whereas passive processing of optic flow is largely independent of the PPC computations. Our results reinforce the hypothesis that the PPC plays a critical role for the integration of goal locations and self-positional signals within an egocentric frame of reference. In addition to the medial temporal lobe, the posterior parietal system is recruited during tasks involving actively controlled movements, whereas medial temporal computations are sufficient for passive monitoring of positional changes.",
      "author": "",
      "published_date": "2025-11-07T13:16:23+00:00",
      "source": "Cognitive Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 235,
      "reading_time": 1,
      "created_at": "2025-12-16T06:36:15.357230+00:00",
      "updated_at": "2025-12-16T06:36:15.357235+00:00"
    },
    {
      "id": "3d6b5f8f7d117269f6d483cfe999ae04",
      "url": "https://www.frontiersin.org/articles/10.3389/fncom.2025.1641519",
      "title": "Fractal memory structure in the spatiotemporal learning rule",
      "content": "The spatiotemporal learning rule (STLR) can reproduce synaptic plasticity in the hippocampus. Analysis of the synaptic weights in the network with the STLR is challenging. Consequently, our previous research only focused on the network's outputs. However, a detailed analysis of the STLR requires focusing on the synaptic weights themselves. To address this issue, we mapped the synaptic weights to a distance space and analyzed the characteristics of the STLR. The results indicate that the synaptic weights form a fractal-like structure in Euclidean distance space. Furthermore, three analytical approaches\u2014multi-dimensional scaling, estimating fractal dimension, and modeling with an iterated function system\u2014demonstrate that the STLR forms a fractal structure in the synaptic weights through fractal coding. These findings contribute to clarifying the learning mechanisms in the hippocampus.",
      "author": "Yoshihiko Horio",
      "published_date": "2025-12-16T00:00:00+00:00",
      "source": "Frontiers Computational Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 124,
      "reading_time": 1,
      "created_at": "2025-12-16T06:35:51.711715+00:00",
      "updated_at": "2025-12-16T06:35:51.711720+00:00"
    },
    {
      "id": "e533e42c8519cc6178e085ef3d6fd4bf",
      "url": "https://www.frontiersin.org/articles/10.3389/fnhum.2025.1708257",
      "title": "Task-constrained self-initiated attention shifts are indexed by frontal-midline theta ramping",
      "content": "In everyday vision, we often shift attention internally without external cues. These self-initiated attention shifts are fundamental to voluntary behavior but are poorly understood because most studies use cue-based paradigms that predetermine when and where to shift attention. To address this gap, we designed a multi-sequential-choice rapid serial visual presentation (RSVP) paradigm with identical visual inputs to dissociate internal and external determinants of attention across three voluntary shift types: task-constrained self-initiated, externally instructed, and unconstrained free-viewing. Participants viewed four simultaneous streams of letters and made overt attention shifts among them, while EEG was recorded. We time-locked theta (4\u20137 Hz) and alpha (8\u201312 Hz) oscillations to shift onset and found distinct signatures for each condition. Notably, a frontal-midline theta ramping was observed before self-initiated shifts but not before instructed or free-viewing shifts, suggesting a preparatory buildup of cognitive control specific to internally driven shifts. Concurrently, sustained suppression of posterior alpha occurred before self-initiated shifts. In contrast, instructed and free-viewing shifts showed relatively higher posterior alpha. These findings suggest that internally generated, goal-driven shifts engage an anticipatory frontal control mechanism indexed by theta increase and reduce posterior inhibition, whereas externally cued or unguided shifts do not. By isolating these condition-specific neural dynamics under identical external stimuli, our study identifies a unique oscillatory signature, frontal-midline theta ramping, associated with task-constrained self-initiated attention shifts.",
      "author": "Satoshi Shioiri",
      "published_date": "2025-12-16T00:00:00+00:00",
      "source": "Frontiers Human Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 220,
      "reading_time": 1,
      "created_at": "2025-12-16T06:35:50.202821+00:00",
      "updated_at": "2025-12-16T06:35:50.202825+00:00"
    },
    {
      "id": "73fd28eb4140acf0aa10b65897f270ff",
      "url": "https://www.frontiersin.org/articles/10.3389/fnins.2025.1727683",
      "title": "Circadian and sleep\u2013wake rhythm alterations in isolated REM sleep behavior disorder: biomarkers of prodromal \u03b1-synucleinopathy",
      "content": "Growing evidence highlights a tight interplay linking circadian and sleep\u2013wake disturbances to the pathophysiology of neurodegenerative disorders. In \u03b1-synucleinopathies, three key points have emerged: (1) circadian and sleep\u2013wake disruptions may increase the risk of neurodegeneration; (2) these alterations reflect widespread dysfunction in neural circuits regulating sleep, wakefulness, and biological rhythms; and (3) the prodromal condition of isolated rapid eye movement (REM) sleep behavior disorder (iRBD) offers a unique window into early pathological changes, as it is characterized by neurodegeneration in brainstem structures critical for sleep\u2013wake regulation and REM sleep control. Hence, sleep- and circadian-related biomarkers may represent feasible tools for early diagnosis, prevention, and treatment across the spectrum of \u03b1-synucleinopathies. However, despite their potential, diagnostic or therapeutic pathways grounded in sleep and circadian biology have yet to be systematically explored or validated, and key questions remain, including the trajectories that characterize the clinical progression from iRBD to overt \u03b1-synucleinopathies. Key challenges include translational barriers, inter-individual variability in biomarker profiles, and the need for longitudinal studies to define clinically actionable thresholds. Against this backdrop, this mini-review synthesizes current evidence on sleep\u2013wake rhythm alterations in iRBD as a prodromal stage of \u03b1-synucleinopathy-driven neurodegeneration. Candidate circadian biomarkers are discussed, including objective parameters from long-term actigraphic monitoring, encompassing rest\u2013activity rhythms modeled with parametric and non-parametric approaches, as well as physiological indicators such as dim light melatonin onset and core body temperature.",
      "author": "Claudio Liguori",
      "published_date": "2025-12-16T00:00:00+00:00",
      "source": "Frontiers Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 227,
      "reading_time": 1,
      "created_at": "2025-12-16T06:35:47.043809+00:00",
      "updated_at": "2025-12-16T06:35:47.043811+00:00"
    },
    {
      "id": "9a79c46655235abe552463129aecff3d",
      "url": "https://www.frontiersin.org/articles/10.3389/fnins.2025.1689003",
      "title": "Noninvasive MGMT-promotor methylation prediction in high grade gliomas using conventional MRI and deep learning-based segmentations",
      "content": "Background/objectivesHigh grade gliomas (HGG) are aggressive brain tumors, most frequently glioblastoma and astrocytoma grade 4. Methylation of O6-methylguanine-DNA methyltransferase (MGMT) promoter in HGG is crucial for temozolomide efficacy. As MGMT promoter methylation (MGMTpm) assessment requires tumor tissue, magnetic resonance imaging (MRI) is of interest for non-invasive prediction. We aimed to analyze volumetric data from edema, contrast-enhancing tumor, necrosis, total-tumor and total-tumor/edema ratio for MGMTpm prediction in HGG. Further we assessed overall survival (OS) and progression free survival (PFS) between groups and volumes.MethodsSegmentation was performed using deep learning models (DL-models), DeepBraTumIA and Raidionics, on 70 HGG patients (45 males, 32 MGMTpm). Manual segmentation was conducted in 37 for validation of DL-models. Group differences were evaluated using Man-Whitney U tests and receiver operation characteristic (ROC) curves. Multivariate analysis was conducted using logistic regression and bootstrapping. Dice coefficient, intraclass correlation coefficient (ICC) and Kruskal\u2013Wallis test evaluated DL-model performance.ResultsMGMTpm tumors displayed significantly larger edema, segmented by DeepBraTumIA (p\u202f=\u202f0.03), and lower total-tumor/edema ratio segmented by both DL-models (p\u202f<\u202f0.01). Raidionics segmented total-tumor/edema ratio showed highest univariate predictive ability with area under curve 0.687 (sensitivity 46.2%, specificity 87.5%). Multivariate analysis confirmed this, showing that the ratios from both DL-models were the only ROIs to remain independent, significant predictors (p\u202f<\u202f0.05) after controlling for clinical covariates. The overall multivariate models were significant (p\u202f=\u202f0.01) and improved prediction over baseline. ICC showed interclass correlation of 0.96 (contrast-enhancing tumor), 0.50 (tumor necrosis) and 0.90 (peritumoral edema). Segmentation methods demonstrated 83\u201391% median overlap in contrast-enhancing tumor, 67\u201380% in necrosis and 80\u201384% in edema regions. Significant OS and PFS differences were observed, notably being longer in MGMTpm tumors and lower tumor volumes.ConclusionThis study suggests that significant radiological differences in MGMTpm can be found using deep learning models, primarily in tumor edema volume. MGMTpm status and region of interest volumes impact OS and PFS. Future studies should incorporate other molecular imaging sequences for methylation prediction.",
      "author": "Pia C. Sundgren",
      "published_date": "2025-12-16T00:00:00+00:00",
      "source": "Frontiers Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 318,
      "reading_time": 1,
      "created_at": "2025-12-16T06:35:47.043759+00:00",
      "updated_at": "2025-12-16T06:35:47.043764+00:00"
    },
    {
      "id": "437dd11491bad5ef899b86bf9271e125",
      "url": "http://doi.org/10.1037/cns0000370",
      "title": "Investigating how individual differences in selective attention relate to schizotypy and altered states of consciousness.",
      "content": "Measures of altered states of consciousness (ASC) are useful for understanding anomalies within conscious experiences. Within psychedelic clinical trials, ASC have been associated with long-term positive treatment outcomes for numerous types of mental illnesses. Schizotypal Personality Scale (STA), a set of personality traits that can be related to psychedelic-induced ASC, is associated with potential changes in selective attention, such as being less bound to previously learned associations (i.e., reduced associative blocking). Given the similarity between schizotypy and psychedelic-induced ASC, we hypothesized that there may be attentional differences in individuals with past experiences of ASC. This study examined how differences in selective attention relate to past experiences of ASC and STA. In Study 1, participants completed a visual categorization task designed to elicit associative blocking, the STA, and the ASC scale. Results revealed slow learning feature\u2013category associations in participants high in ASC and STA. Study 2 tested whether this deficit in performance was due to widened attention by implementing additional inference trials that measured incidental learning of feature\u2013feature associations. Results from Study 2 confirmed that participants high in ASC and STA show deficits in learning categories, but this was not accounted for by wider selective attention per se. Our results suggest that flexible or widened attention may not be the locus of cognitive changes associated with past experiences of ASC. Rather, by showing reliable latency in an error-driven learning task, we add to a comprehensive understanding of the relationships between cognition and ASC. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2023-09-14T00:00:00+00:00",
      "source": "Clinical Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 251,
      "reading_time": 1,
      "created_at": "2025-12-16T06:35:29.632737+00:00",
      "updated_at": "2025-12-16T06:35:29.632739+00:00"
    },
    {
      "id": "c3f3c4ea06e00ef611c2a8ea02f27a0d",
      "url": "https://terrytao.wordpress.com/2025/12/08/the-story-of-erdos-problem-126/",
      "title": "Erd\u0151s Problem #1026",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46284897\">Comments</a>",
      "author": "",
      "published_date": "2025-12-16T04:49:03+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-16T06:35:20.163855+00:00",
      "updated_at": "2025-12-16T06:35:20.163857+00:00"
    },
    {
      "id": "c3f3c4ea06e00ef611c2a8ea02f27a0d",
      "url": "https://terrytao.wordpress.com/2025/12/08/the-story-of-erdos-problem-126/",
      "title": "Erd\u0151s Problem #1026",
      "content": "<p>Article URL: <a href=\"https://terrytao.wordpress.com/2025/12/08/the-story-of-erdos-problem-126/\">https://terrytao.wordpress.com/2025/12/08/the-story-of-erdos-problem-126/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46284897\">https://news.ycombinator.com/item?id=46284897</a></p>\n<p>Points: 28</p>\n<p># Comments: 0</p>",
      "author": "tzury",
      "published_date": "2025-12-16T04:49:03+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-16T06:35:18.949403+00:00",
      "updated_at": "2025-12-16T06:35:18.949411+00:00"
    },
    {
      "id": "698a3967478d4ba61f5711c9117ea7e6",
      "url": "https://www.embs.org/uncategorized/call-for-applications-ieee-tmrb-editor-in-chief-search/",
      "title": "Call for Applications: IEEE T-MRB Editor in Chief Search",
      "content": "<p>The post <a href=\"https://www.embs.org/uncategorized/call-for-applications-ieee-tmrb-editor-in-chief-search/\">Call for Applications: IEEE T-MRB Editor in Chief Search</a> appeared first on <a href=\"https://www.embs.org\">IEEE EMBS</a>.</p>",
      "author": "Deidre Artis",
      "published_date": "2025-04-03T14:16:16+00:00",
      "source": "Embs",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 18,
      "reading_time": 1,
      "created_at": "2025-12-16T05:47:41.021614+00:00",
      "updated_at": "2025-12-16T06:26:20.680030+00:00",
      "metadata": {
        "processed_at": "2025-12-16T06:26:20.680039+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "23af8b2d5b8c04fa79359ee9ea796514",
      "url": "https://www.sciencedirect.com/science/article/pii/S0306452225011595?dgcid=rss_sd_all",
      "title": "Alarm pheromone activates posterior medial amygdala-to-bed nucleus of the stria terminalis projections in male rats",
      "content": "<p>Publication date: 26 January 2026</p><p><b>Source:</b> Neuroscience, Volume 593</p><p>Author(s): Mao Kobayashi-Sakashita, Ming-Hsuan Lu, Yukari Takeuchi, Markus Fendt, Akira Uematsu, Yasushi Kiyokawa</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroscience Journal",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 20,
      "reading_time": 1,
      "created_at": "2025-12-16T05:47:32.763069+00:00",
      "updated_at": "2025-12-16T06:26:20.680043+00:00",
      "metadata": {
        "processed_at": "2025-12-16T06:26:20.680045+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "b87d71bcf3489ef22415edbb6971023f",
      "url": "https://www.sciencedirect.com/science/article/pii/S0306452225011571?dgcid=rss_sd_all",
      "title": "Doublecortin-expressing cells are selectively altered in the piriform cortex but not in neurogenic areas of symptomatic <em>Mecp2</em>-heterozygous mice",
      "content": "<p>Publication date: 26 January 2026</p><p><b>Source:</b> Neuroscience, Volume 593</p><p>Author(s): Rafael Esteve-P\u00e9rez, Paloma Sevilla-Ferrer, Enrique Lanuza, Vicente Herranz-P\u00e9rez, Jose V. Torres-P\u00e9rez, Carmen Agust\u00edn-Pav\u00f3n</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroscience Journal",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 21,
      "reading_time": 1,
      "created_at": "2025-12-16T05:47:32.763045+00:00",
      "updated_at": "2025-12-16T06:26:20.680048+00:00",
      "metadata": {
        "processed_at": "2025-12-16T06:26:20.680049+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "28625c4028e5700b8f3c9af0abe854d8",
      "url": "https://www.nature.com/articles/s41467-025-67457-2",
      "title": "Structure of ATTRv-F64S fibrils isolated from skin tissue of a living patient",
      "content": "",
      "author": "",
      "published_date": "2025-12-16T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-12-16T05:47:28.057766+00:00",
      "updated_at": "2025-12-16T06:26:20.680052+00:00",
      "metadata": {
        "processed_at": "2025-12-16T06:26:20.680053+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "b84f4acfaa385c55c9bcc74850be8c16",
      "url": "http://doi.org/10.1037/cns0000380",
      "title": "Sensory-processing sensitivity as a confounder in the positive relationship between mindful awareness and psychological distress: A theoretical review.",
      "content": "Mindfulness meditation is credited as a positive driver of promoting psychological well-being and reducing stress, anxiety, and depression symptoms. However, dispositional mindfulness has been somewhat correlated with psychological distress, as awareness has been positively correlated with psychological symptoms and negative affective states in many studies. This counterintuitive phenomenon has been tentatively explained in a variety of ways, including a wrong interpretation of the items of the mindfulness assessment scales in nonmeditators. The most credited explanation is that increasing attention to present-moment experiences would boost affective reaction to negative experiences and therefore exacerbate related psychological symptoms. This hypothesis is unsatisfactory, as there is much contrasting evidence in this regard. Therefore, we propose a new hypothesis: in dispositional studies, the assessment of the awareness skill of mindfulness would be affected by sensory-processing sensitivity, which could be a confounder in its relationship with psychological distress. Sensory-processing sensitivity refers to a temperamental trait characterized by both awareness of sensorial stimulation and reactivity to experience. Thus, highly sensitive persons usually report increased awareness of subtleties in the environment, ease of overstimulation, and increased affective reaction to stimulation. In support of our hypothesis, we showed in particular how the most widely used scale for assessing mindful awareness could be paired with and interpreted as a measure of sensory-processing sensitivity. We then propose a set of testable hypotheses to drive future research on this topic. If supported by future experimental results, our hypothesis would shed new light on the overall field of dispositional mindfulness studies. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2023-11-02T00:00:00+00:00",
      "source": "Clinical Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 257,
      "reading_time": 1,
      "created_at": "2025-12-16T05:47:00.796119+00:00",
      "updated_at": "2025-12-16T06:26:20.680056+00:00",
      "metadata": {
        "processed_at": "2025-12-16T06:26:20.680057+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "a89cc9d9bab0838b2e06072add1ef2ed",
      "url": "http://doi.org/10.1037/cns0000335",
      "title": "A shared perceptual inference for cross-modally induced illusions of self-attribution.",
      "content": "The representation of our own body is malleable. Evidence indicates that multisensory stimulation can trigger an illusory sense of ownership over a fake hand, a partner\u2019s face, or a virtual body. Despite our understanding of the processes supporting the construction of bodily self, we know less about the processes that trigger illusory ownership of nonbody attributes (e.g., voice during articulation) and about whether multisensory stimulation can drive a shared inference across distinct attributes. Here, we compared the classic rubber hand illusion with another multisensory illusion that elicits a sense of ownership over a stranger\u2019s voice during talking. We observed that, given congruent multisensory input, the degree to which one perceived the sense of ownership over the fake hand predicted the degree to which one perceived the sense of ownership over the stranger\u2019s voice, after controlling for task demand and suggestibility. Thus, our results provide evidence for a shared inference supporting subjective sense of self across fundamentally different attributes. We suggest that individual reliance on multisensory signals to drive such an inference can be further explored. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2022-08-25T00:00:00+00:00",
      "source": "Clinical Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 184,
      "reading_time": 1,
      "created_at": "2025-12-16T05:47:00.796077+00:00",
      "updated_at": "2025-12-16T05:47:00.796078+00:00"
    },
    {
      "id": "fa250840ddf6808c93613cad856c7c25",
      "url": "http://doi.org/10.1037/cns0000353",
      "title": "Unmuting lucid dreams: Speech decoding and vocalization in real time.",
      "content": "Since the 1970s, scientists have been searching for ways to communicate with people in lucid dreams (LDs), during which it is possible to maintain consciousness. Previously, dreamers could hear sounds from reality and respond with some simple signals, but they could not speak back. In this study, facial surface electromyography (EMG) was tested as a proof of concept for unmuting people in LDs. Remmyo, an EMG distinctive constructed language, was used. The software was developed to translate facial EMG impulses into Remmyo sounds and letters, translate words into English, and digitally vocalize the final text in English. Four LD practitioners were trained to pronounce a short phrase or a word in Remmyo and were then asked to achieve the same task in LDs under polysomnographic observation. LDs were verified by preagreed eye movements in rapid eye movement (REM) sleep. Four volunteers tried to speak in Remmyo in 15 LDs. Due to software failures, mispronunciations, and missing sounds, the decoding efficiency in real time or in recordings ranged from 13% to 81%. The first phrase and word heard from sleeping people were \u201cno war\u201d and \u201cfreedom.\u201d The later was automatically translated and vocalized in English in real time for 11 times. Despite controversial results, the study shows that, with further development, people could possibly talk in LDs and could be heard in reality with the help of EMG sensors. To achieve this goal, a range of possible obstacles is discussed. This technology could provide opportunities for LD studies and their practical applications. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2023-03-13T00:00:00+00:00",
      "source": "Clinical Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 260,
      "reading_time": 1,
      "created_at": "2025-12-16T05:47:00.796039+00:00",
      "updated_at": "2025-12-16T05:47:00.796041+00:00"
    },
    {
      "id": "3cace5c5d9bdc4eeebb05365c3e99538",
      "url": "http://doi.org/10.1037/cns0000402",
      "title": "Creating a world in the head: The conscious apprehension of neural content originating from internal sources.",
      "content": "Klein et al. (2023) argued that the evolutionary transition from respondent to agent during the Cambrian explosion would be a promising vantage point from which to gain insight into the evolution of organic sentience. They focused on how increased competition for resources\u2014in consequence of the proliferation of new, neurally sophisticated life-forms\u2014made awareness of the external world (in the service of agentic acts) an adaptive priority. The explanatory scope of Klein et al. (2023) was limited to consideration of the conscious apprehension of externally sourced content\u2014that is, content delivered from the sensory registration of objects occupying phenomenal space. But consciousness\u2014at least for humans\u2014takes its objects from internal as well as external sources. In the present article, we extend their analysis to the question of how internally sourced content (i.e., mental states) became the object of conscious apprehension. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2024-09-09T00:00:00+00:00",
      "source": "Clinical Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 145,
      "reading_time": 1,
      "created_at": "2025-12-16T05:47:00.795993+00:00",
      "updated_at": "2025-12-16T05:47:00.795995+00:00"
    },
    {
      "id": "4dc92cbf63e410e4d59f6ffd2f7dec90",
      "url": "http://doi.org/10.1037/cns0000406",
      "title": "Not all minds think alike: Examining the impact of time and task on visual and verbal thought.",
      "content": "Research suggests that individuals have different phenomenological experiences across various tasks. However, little is known about how these experiences vary by task or over time. This study examined participants\u2019 experiences of task-unrelated thoughts (i.e., TUTs), visual, and verbal thoughts across two experimental sessions and two different tasks. In addition, we examined relations between participants\u2019 thoughts and key individual difference factors. In Session 1, participants (<em>n</em> = 85) engaged in a focused-attention meditation and a reading task, then completed a second identical session with a new text. Throughout both tasks, participants were prompted to report on the characteristics of their thoughts. Participants\u2019 ratings of TUT, visual, and verbal thoughts were subject to change over time. Furthermore, on average, participants visualized more and had fewer TUTs while reading compared to meditation; however, no task difference was found for verbal-thinking reports. This suggests that visual imagery is more malleable than verbal-thinking. There was a strong negative correlation between visual and verbal thoughts, suggesting that at any given time, individuals\u2019 thoughts tended to be either predominantly visual or verbal. Finally, individual differences in the tendency to become immersed in narratives and motivation to engage with other people\u2019s perspectives (i.e., mind-reading motivation) were related to higher reports of visual imagery during reading, whereas verbal-thinking was negatively associated with mind-reading motivation and unrelated to TUT. Overall, this study revealed that individuals\u2019 phenomenological experiences vary during tasks and across time, providing a foundation for future work to examine why and how variability in these phenomenological experiences emerge. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2024-10-14T00:00:00+00:00",
      "source": "Clinical Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 259,
      "reading_time": 1,
      "created_at": "2025-12-16T05:47:00.795958+00:00",
      "updated_at": "2025-12-16T05:47:00.795960+00:00"
    },
    {
      "id": "bdd171593d416ff5533a5fb1ddd7e15d",
      "url": "https://arxiv.org/abs/2512.12348",
      "title": "Understanding Trust Toward Human versus AI-generated Health Information through Behavioral and Physiological Sensing",
      "content": "arXiv:2512.12348v1 Announce Type: new \nAbstract: As AI-generated health information proliferates online and becomes increasingly indistinguishable from human-sourced information, it becomes critical to understand how people trust and label such content, especially when the information is inaccurate. We conducted two complementary studies: (1) a mixed-methods survey (N=142) employing a 2 (source: Human vs. LLM) $\\times$ 2 (label: Human vs. AI) $\\times$ 3 (type: General, Symptom, Treatment) design, and (2) a within-subjects lab study (N=40) incorporating eye-tracking and physiological sensing (ECG, EDA, skin temperature). Participants were presented with health information varying by source-label combinations and asked to rate their trust, while their gaze behavior and physiological signals were recorded. We found that LLM-generated information was trusted more than human-generated content, whereas information labeled as human was trusted more than that labeled as AI. Trust remained consistent across information types. Eye-tracking and physiological responses varied significantly by source and label. Machine learning models trained on these behavioral and physiological features predicted binary self-reported trust levels with 73% accuracy and information source with 65% accuracy. Our findings demonstrate that adding transparency labels to online health information modulates trust. Behavioral and physiological features show potential to verify trust perceptions and indicate if additional transparency is needed.",
      "author": "Xin Sun, Rongjun Ma, Shu Wei, Pablo Cesar, Jos A. Bosch, Abdallah El Ali",
      "published_date": "2025-12-16T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 201,
      "reading_time": 1,
      "created_at": "2025-12-16T05:24:51.308045+00:00",
      "updated_at": "2025-12-16T05:24:51.308047+00:00"
    },
    {
      "id": "7f43a46e0c6bea90d4ca3fce117e600c",
      "url": "https://arxiv.org/abs/2512.12283",
      "title": "Large Language Models have Chain-of-Affective",
      "content": "arXiv:2512.12283v1 Announce Type: new \nAbstract: Large language models (LLMs) are increasingly deployed as collaborative agents in emotionally charged settings, yet most evaluations treat them as purely cognitive systems and largely ignore their affective behaviour. Here we take a functional perspective and ask whether contemporary LLMs implement a structured chain-of-affective: organised affective dynamics that are family-specific, temporally coherent and behaviourally consequential. Across eight major LLM families (GPT, Gemini, Claude, Grok, Qwen, DeepSeek, GLM, Kimi), we combine two experimental modules. The first characterises inner chains-of-affective via baseline ''affective fingerprints'', 15-round sad-news exposure, and a 10-round news self-selection paradigm. We find stable, family-specific affective profiles, a reproducible three-phase trajectory under sustained negative input (accumulation, overload, defensive numbing), distinct defence styles, and human-like negativity biases that induce self-reinforcing affect-choice feedback loops. The second module probes outer consequences using a composite performance benchmark, human-AI dialogues on contentious topics, and multi-agent LLM interactions. We demonstrate that induced affect preserves core reasoning while reshaping high-freedom generation. Sentiment metrics predict user comfort and empathy but reveal trade-offs in resisting problematic views. In multi-agent settings, group structure drives affective contagion, role specialization (initiators, absorbers, firewalls), and bias. We characterize affect as an emergent control layer, advocating for 'chains-of-affect' as a primary target for evaluation and alignment.",
      "author": "Junjie Xu, Xingjiao Wu, Luwei Xiao, Yuzhe Yang, Jie Zhou, Zihao Zhang, Luhan Wang, Yi Huang, Nan Wu, Yingbin Zheng, Chao Yan, Cheng Jin, Honglin Li, Liang He",
      "published_date": "2025-12-16T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 207,
      "reading_time": 1,
      "created_at": "2025-12-16T05:24:51.308015+00:00",
      "updated_at": "2025-12-16T05:24:51.308016+00:00"
    },
    {
      "id": "b50fee1f877625e562131a28d99fb6e5",
      "url": "https://arxiv.org/abs/2512.12240",
      "title": "System X: A Mobile Voice-Based AI System for EMR Generation and Clinical Decision Support in Low-Resource Maternal Healthcare",
      "content": "arXiv:2512.12240v1 Announce Type: new \nAbstract: We present the design, implementation, and in-situ deployment of a smartphone-based voice-enabled AI system for generating electronic medical records (EMRs) and clinical risk alerts in maternal healthcare settings. Targeted at low-resource environments such as Pakistan, the system integrates a fine-tuned, multilingual automatic speech recognition (ASR) model and a prompt-engineered large language model (LLM) to enable healthcare workers to engage naturally in Urdu, their native language, regardless of literacy or technical background. Through speech-based input and localized understanding, the system generates structured EMRs and flags critical maternal health risks. Over a seven-month deployment in a not-for-profit hospital, the system supported the creation of over 500 EMRs and flagged over 300 potential clinical risks. We evaluate the system's performance across speech recognition accuracy, EMR field-level correctness, and clinical relevance of AI-generated red flags. Our results demonstrate that speech based AI interfaces, can be effectively adapted to real-world healthcare settings, especially in low-resource settings, when combined with structured input design, contextual medical dictionaries, and clinician-in-the-loop feedback loops. We discuss generalizable design principles for deploying voice-based mobile healthcare AI support systems in linguistically and infrastructurally constrained settings.",
      "author": "Maryam Mustafa, Umme Ammara, Amna Shahnawaz, Moaiz Abrar, Bakhtawar Ahtisham, Fozia Umber Qurashi, Mostafa Shahin, Beena Ahmed",
      "published_date": "2025-12-16T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 188,
      "reading_time": 1,
      "created_at": "2025-12-16T05:24:51.307983+00:00",
      "updated_at": "2025-12-16T05:24:51.307984+00:00"
    }
  ]
}