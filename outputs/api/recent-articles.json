{
  "last_updated": "2025-10-01T16:26:07.035925+00:00",
  "count": 20,
  "articles": [
    {
      "id": "4f503efc209479f9b870bfb5bde19f97",
      "url": "https://arxiv.org/abs/2509.25537",
      "title": "Healthy Lifestyles and Self-Improvement Videos on YouTube: A Thematic Analysis of Teen-Targeted Social Media Content",
      "content": "arXiv:2509.25537v1 Announce Type: new \nAbstract: As teenagers increasingly turn to social media for health-related information, understanding the values of teen-targeted content has become important. Although videos on healthy lifestyles and self-improvement are gaining popularity on social media platforms like YouTube, little is known about how these videos benefit and engage with teenage viewers. To address this, we conducted a thematic analysis of 44 YouTube videos and 66,901 comments. We found that these videos provide various advice on teenagers' common challenges, use engaging narratives for authenticity, and foster teen-centered communities through comments. However, a few videos also gave misleading advice to adolescents that can be potentially harmful. Based on our findings, we discuss design implications for creating relatable and intriguing social media content for adolescents. Additionally, we suggest ways for social media platforms to promote healthier and safer experiences for teenagers.",
      "author": "Kyuha Jung, Tyler Kim, Yunan Chen",
      "published_date": "2025-10-01T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 140,
      "reading_time": 1,
      "created_at": "2025-10-01T16:25:48.661704+00:00",
      "updated_at": "2025-10-01T16:25:48.661705+00:00"
    },
    {
      "id": "ba103cc111df09142bb2ce13dfcbc549",
      "url": "https://arxiv.org/abs/2509.25513",
      "title": "User Prompting Strategies and ChatGPT Contextual Adaptation Shape Conversational Information-Seeking Experiences",
      "content": "arXiv:2509.25513v1 Announce Type: new \nAbstract: Conversational AI, such as ChatGPT, is increasingly used for information seeking. However, little is known about how ordinary users actually prompt and how ChatGPT adapts its responses in real-world conversational information seeking (CIS). In this study, a nationally representative sample of 937 U.S. adults engaged in multi-turn CIS with ChatGPT on both controversial and non-controversial topics across science, health, and policy contexts. We analyzed both user prompting strategies and the communication styles of ChatGPT responses. The findings revealed behavioral signals of digital divide: only 19.1% of users employed prompting strategies, and these users were disproportionately more educated and Democrat-leaning. Further, ChatGPT demonstrated contextual adaptation: responses to controversial topics contain more cognitive complexity and more external references than to non-controversial topics. Notably, cognitively complex responses were perceived as less favorable but produced more positive issue-relevant attitudes. This study highlights disparities in user prompting behaviors and shows how user prompts and AI responses together shape information-seeking with conversational AI.",
      "author": "Haoning Xue, Yoo Jung Oh, Xinyi Zhou, Xinyu Zhang, Berit Oxley",
      "published_date": "2025-10-01T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 162,
      "reading_time": 1,
      "created_at": "2025-10-01T16:25:48.661676+00:00",
      "updated_at": "2025-10-01T16:25:48.661678+00:00"
    },
    {
      "id": "12518e6b2b2e986bef078011dbe9c579",
      "url": "https://arxiv.org/abs/2509.25504",
      "title": "XR Blocks: Accelerating Human-centered AI + XR Innovation",
      "content": "arXiv:2509.25504v1 Announce Type: new \nAbstract: We are on the cusp where Artificial Intelligence (AI) and Extended Reality (XR) are converging to unlock new paradigms of interactive computing. However, a significant gap exists between the ecosystems of these two fields: while AI research and development is accelerated by mature frameworks like JAX and benchmarks like LMArena, prototyping novel AI-driven XR interactions remains a high-friction process, often requiring practitioners to manually integrate disparate, low-level systems for perception, rendering, and interaction. To bridge this gap, we present XR Blocks, a cross-platform framework designed to accelerate human-centered AI + XR innovation. XR Blocks strives to provide a modular architecture with plug-and-play components for core abstraction in AI + XR: user, world, peers; interface, context, and agents. Crucially, it is designed with the mission of \"reducing frictions from idea to reality\", thus accelerating rapid prototyping of AI + XR apps. Built upon accessible technologies (WebXR, three.js, TensorFlow, Gemini), our toolkit lowers the barrier to entry for XR creators. We demonstrate its utility through a set of open-source templates, samples, and advanced demos, empowering the community to quickly move from concept to interactive XR prototype. Site: https://xrblocks.github.io",
      "author": "David Li, Nels Numan, Xun Qian, Yanhe Chen, Zhongyi Zhou, Evgenii Alekseev, Geonsun Lee, Alex Cooper, Min Xia, Scott Chung, Jeremy Nelson, Xiuxiu Yuan, Jolica Dias, Tim Bettridge, Benjamin Hersh, Michelle Huynh, Konrad Piascik, Ricardo Cabello, David Kim, Ruofei Du",
      "published_date": "2025-10-01T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 191,
      "reading_time": 1,
      "created_at": "2025-10-01T16:25:48.661646+00:00",
      "updated_at": "2025-10-01T16:25:48.661648+00:00"
    },
    {
      "id": "6751d4ba29952f47f6af983d84f172cd",
      "url": "https://arxiv.org/abs/2509.25499",
      "title": "Atlas of Human-AI Interaction (v1): An Interactive Meta-Science Platform for Large-Scale Research Literature Sensemaking",
      "content": "arXiv:2509.25499v1 Announce Type: new \nAbstract: Human-AI interaction researchers face an overwhelming challenge: synthesizing insights from thousands of empirical studies to understand how AI impacts people and inform effective design. Existing approach for literature reviews cluster papers by similarities, keywords or citations, missing the crucial cause-and-effect relationships that reveal how design decisions impact user outcomes. We introduce the Atlas of Human-AI Interaction, an interactive web interface that provides the first systematic mapping of empirical findings across 1,000+ HCI papers using LLM-powered knowledge extraction. Our approach identifies causal relationships, and visualizes them through an AI-enabled interactive web interface as a navigable knowledge graph. We extracted 2,037 empirical findings, revealing research topic clusters, common themes, and disconnected areas. Expert evaluation with 20 researchers revealed the system's effectiveness for discovering research gaps. This work demonstrates how AI can transform literature synthesis itself, offering a scalable framework for evidence-based design, opening new possibilities for computational meta-science across HCI and beyond.",
      "author": "Chayapatr Archiwaranguprok, Awu Chen, Sheer Karny, Hiroshi Ishii, Pattie Maes, Pat Pataranutaporn",
      "published_date": "2025-10-01T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 155,
      "reading_time": 1,
      "created_at": "2025-10-01T16:25:48.661615+00:00",
      "updated_at": "2025-10-01T16:25:48.661616+00:00"
    },
    {
      "id": "863c3da472b0a1909355d8b7dcb7ee7d",
      "url": "https://arxiv.org/abs/2509.25492",
      "title": "Botender: Supporting Communities in Collaboratively Designing AI Agents through Case-Based Provocations",
      "content": "arXiv:2509.25492v1 Announce Type: new \nAbstract: AI agents, or bots, serve important roles in online communities. However, they are often designed by outsiders or a few tech-savvy members, leading to bots that may not align with the broader community's needs. How might communities collectively shape the behavior of community bots? We present Botender, a system that enables communities to collaboratively design LLM-powered bots without coding. With Botender, community members can directly propose, iterate on, and deploy custom bot behaviors tailored to community needs. Botender facilitates testing and iteration on bot behavior through case-based provocations: interaction scenarios generated to spark user reflection and discussion around desirable bot behavior. A validation study found these provocations more useful than standard test cases for revealing improvement opportunities and surfacing disagreements. During a five-day deployment across six Discord servers, Botender supported communities in tailoring bot behavior to their specific needs, showcasing the usefulness of case-based provocations in facilitating collaborative bot design.",
      "author": "Tzu-Sheng Kuo, Sophia Liu, Quan Ze Chen, Joseph Seering, Amy X. Zhang, Haiyi Zhu, Kenneth Holstein",
      "published_date": "2025-10-01T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 155,
      "reading_time": 1,
      "created_at": "2025-10-01T16:25:48.661586+00:00",
      "updated_at": "2025-10-01T16:25:48.661588+00:00"
    },
    {
      "id": "b463bcc77eb4a19055464b7208d1af96",
      "url": "https://arxiv.org/abs/2509.25491",
      "title": "LLM-Assisted News Discovery in High-Volume Information Streams: A Case Study",
      "content": "arXiv:2509.25491v1 Announce Type: new \nAbstract: Journalists face mounting challenges in monitoring ever-expanding digital information streams to identify newsworthy content. While traditional automation tools gather information at scale, they struggle with the editorial judgment needed to assess newsworthiness. This paper investigates whether large language models (LLMs) can serve as effective first-pass filters for journalistic monitoring. We develop a prompt-based approach encoding journalistic news values - timeliness, impact, controversy, and generalizability - into LLM instructions to extract and evaluate potential story leads. We validate our approach across multiple models against expert-annotated ground truth, then deploy a real-world monitoring pipeline that processes trade press articles daily. Our evaluation reveals strong performance in extracting relevant leads from source material ($F1=0.94$) and in coarse newsworthiness assessment ($\\pm$1 accuracy up to 92%), but it consistently struggles with nuanced editorial judgments requiring beat expertise. The system proves most valuable as a hybrid tool combining automated monitoring with human review, successfully surfacing novel, high-value leads while filtering obvious noise. We conclude with practical recommendations for integrating LLM-powered monitoring into newsroom workflows that preserves editorial judgment while extending journalistic capacity.",
      "author": "Nick Hagar, Ethan Silver, Clare Spencer, Nicholas Diakopoulos",
      "published_date": "2025-10-01T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 181,
      "reading_time": 1,
      "created_at": "2025-10-01T16:25:48.661557+00:00",
      "updated_at": "2025-10-01T16:25:48.661558+00:00"
    },
    {
      "id": "652dad4caaec29b92ff350a5d8368251",
      "url": "https://arxiv.org/abs/2509.25460",
      "title": "\"Where Can I Park?\" Understanding Human Perspectives and Scalably Detecting Disability Parking from Aerial Imagery",
      "content": "arXiv:2509.25460v1 Announce Type: new \nAbstract: Accessible parking is critical for people with disabilities (PwDs), allowing equitable access to destinations, independent mobility, and community participation. Despite mandates, there has been no large-scale investigation of the quality or allocation of disability parking in the US nor significant research on PwD perspectives and uses of disability parking. In this paper, we first present a semi-structured interview study with 11 PwDs to advance understanding of disability parking uses, concerns, and relevant technology tools. We find that PwDs often adapt to disability parking challenges according to their personal mobility needs and value reliable, real-time accessibility information. Informed by these findings, we then introduce a new deep learning pipeline, called AccessParkCV, and parking dataset for automatically detecting disability parking and inferring quality characteristics (e.g., width) from orthorectified aerial imagery. We achieve a micro-F1=0.89 and demonstrate how our pipeline can support new urban analytics and end-user tools. Together, we contribute new qualitative understandings of disability parking, a novel detection pipeline and open dataset, and design guidelines for future tools.",
      "author": "Jared Hwang, Chu Li, Hanbyul Kang, Maryam Hosseini, Jon E. Froehlich",
      "published_date": "2025-10-01T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 172,
      "reading_time": 1,
      "created_at": "2025-10-01T16:25:48.661520+00:00",
      "updated_at": "2025-10-01T16:25:48.661521+00:00"
    },
    {
      "id": "a41507032d26f246243a270dec0c3ddb",
      "url": "https://arxiv.org/abs/2509.25457",
      "title": "Human vs. AI Safety Perception? Decoding Human Safety Perception with Eye-Tracking Systems, Street View Images, and Explainable AI",
      "content": "arXiv:2509.25457v1 Announce Type: new \nAbstract: The way residents perceive safety plays an important role in how they use public spaces. Studies have combined large-scale street view images and advanced computer vision techniques to measure the perception of safety of urban environments. Despite their success, such studies have often overlooked the specific environmental visual factors that draw human attention and trigger people's feelings of safety perceptions. In this study, we introduce a computational framework that enriches the existing body of literature on place perception by using eye-tracking systems with street view images and deep learning approaches. Eye-tracking systems quantify not only what users are looking at but also how long they engage with specific environmental elements. This allows us to explore the nuance of which visual environmental factors influence human safety perceptions. We conducted our research in Helsingborg, Sweden, where we recruited volunteers outfitted with eye-tracking systems. They were asked to indicate which of the two street view images appeared safer. By examining participants' focus on specific features using Mean Object Ratio in Highlighted Regions (MoRH) and Mean Object Hue (MoH), we identified key visual elements that attract human attention when perceiving safe environments. For instance, certain urban infrastructure and public space features draw more human attention while the sky is less relevant in influencing safety perceptions. These insights offer a more human-centered understanding of which urban features influence human safety perceptions. Furthermore, we compared the real human attention from eye-tracking systems with attention maps obtained from eXplainable Artificial Intelligence (XAI) results. Several XAI models were tested, and we observed that XGradCAM and EigenCAM most closely align with human safety perceptual patterns.",
      "author": "Yuhao Kang, Junda Chen, Liu Liu, Kshitij Sharmad, Martina Mazzarello, Simone Mora, Fabio Duarte, Carlo Ratti",
      "published_date": "2025-10-01T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 271,
      "reading_time": 1,
      "created_at": "2025-10-01T16:25:48.661488+00:00",
      "updated_at": "2025-10-01T16:25:48.661490+00:00"
    },
    {
      "id": "62e8e142ac157eefa4e4017fbeb7b007",
      "url": "https://arxiv.org/abs/2509.25383",
      "title": "Beyond the Pocket: A Large-Scale International Study on User Preferences on Bodily Placements of Commercial Wearables",
      "content": "arXiv:2509.25383v1 Announce Type: new \nAbstract: As wearable technologies continue to evolve-becoming smaller, more powerful, and more deeply embedded in daily life-their integration into diverse user contexts raises critical design challenges. There remains a notable gap in large-scale empirical data on where users actually wear or carry these devices throughout the day, systematically examining user preferences for wearable placement across varied contexts and routines. In this work, we conducted a questionnaire in several countries aimed at capturing real-world habits related to wearable device placement. The results from n = 320 participants reveal how wearable usage patterns shift depending on time of day and context. We propose a set of practical, user-centered guidelines for sensor placement and discuss how they align or diverge from assumptions seen in existing ISWC work. This study contributes to ongoing efforts within the community to design more inclusive, adaptable, and context-aware wearable systems.",
      "author": "Joanna Sorysz, Lars Krupp, Dominique Nshimyimana, Meagan B. Loerakker, Bo Zhou, Paul Lukowicz, Jakob Karolus",
      "published_date": "2025-10-01T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 146,
      "reading_time": 1,
      "created_at": "2025-10-01T16:25:48.661447+00:00",
      "updated_at": "2025-10-01T16:25:48.661449+00:00"
    },
    {
      "id": "260f25030b0e62b268d1f3df829adf81",
      "url": "https://www.biorxiv.org/content/10.1101/2025.09.29.679121v1?rss=1",
      "title": "Concept Learning Builds Behaviourally Relevant Attentional Templates",
      "content": "Attention optimizes learning by filtering relevant information to build conceptual knowledge. However, how learned concepts, once encoded in memory, subsequently guide attentional processes remains an intriguing question. We propose that concept learning leads to the emergence of attentional templates that store goal-relevant representations, thereby actively guiding attention allocation. Participants completed two separate learning tasks and a test, wherein each trial began with a cue, indicating which learning task should be employed. Random test trials included a probe instead of concept specific features: a small arrow appeared at a feature location that was relevant (i.e., valid) or irrelevant (i.e., invalid) for the cued task. Successful learners were faster at responding to valid probes than invalid, demonstrating the deployment of concept-specific attentional templates. Importantly, the efficiency of this attention allocation was tied to concept learning success, with higher learning performance yielding greater response time benefits at test. Thus, our results reveal that learning builds behaviourally relevant attentional templates, and subsequently, learned concepts in memory guide attention by deploying these templates, a phenomenon that we introduce as learning-guided attention. This work provides novel insights into the dynamic interplay between learning, memory, and attention.",
      "author": "Gumus, M., Lee, Z. Z. Y., Mack, M. L.",
      "published_date": "2025-10-01T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 190,
      "reading_time": 1,
      "created_at": "2025-10-01T16:25:38.111041+00:00",
      "updated_at": "2025-10-01T16:25:38.111045+00:00"
    },
    {
      "id": "e0e6156b7626ec83506824a14a1920f8",
      "url": "https://www.nature.com/articles/s41593-025-02056-4",
      "title": "A bottom-up septal inhibitory circuit mediates anticipatory control of drinking",
      "content": "<p>Nature Neuroscience, Published online: 22 September 2025; <a href=\"https://www.nature.com/articles/s41593-025-02056-4\">doi:10.1038/s41593-025-02056-4</a></p>Xu et al. reveal that a bottom-up neural circuit from the medial septum to the subfornical organ prevents overhydration in mice by integrating oral and gastrointestinal signals before osmolality changes, demonstrating precise drinking control mechanisms.",
      "author": "Zhong Chen",
      "published_date": "2025-09-22T00:00:00+00:00",
      "source": "Nature Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 43,
      "reading_time": 1,
      "created_at": "2025-10-01T16:25:35.730103+00:00",
      "updated_at": "2025-10-01T16:25:35.730104+00:00"
    },
    {
      "id": "c26d89d902991a3e13b4738807303d24",
      "url": "http://www.jneurosci.org/cgi/content/short/45/39/etwij45392025?rss=1",
      "title": "This Week in The Journal",
      "content": "",
      "author": "McKeon, P.",
      "published_date": "2025-09-24T16:30:28+00:00",
      "source": "Journal Neuroscience This Week",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-10-01T16:25:34.502002+00:00",
      "updated_at": "2025-10-01T16:25:34.502007+00:00"
    },
    {
      "id": "bddb79df0f916d4ca8f713f4b38e2fa3",
      "url": "http://www.jneurosci.org/cgi/content/short/45/39/e2175242025?rss=1",
      "title": "Spatial and Temporal Factors Influencing Fixational Saccades",
      "content": "<p>Much research has focused on how perceptual, cognitive, and attentional processes modulate microsaccades, the small rapid gaze shifts that humans perform when attempting to maintain steady gaze on a point. Yet the reasons why these fixational saccades occur in the first place have remained unclear. Long-standing theories have argued for either spatial (i.e., gaze centering) or temporal mechanisms (i.e., a periodical release process). However, this debate has never been resolved, primarily because of uncertainty in determining where the observer looks. Whereas modern eye-trackers enable detection of small eye movements, accurate localization of the line of sight remains challenging. Here, rather than indirectly inferring gaze position from oculomotor activity, we used a gaze-contingent procedure to directly estimate the perceived center of the visual field, a method that has been previously shown to effectively reduce uncertainty. Our results from subjects of both sexes show that the generation of fixational saccades depends on the interaction of spatial and temporal factors. Fixational saccades are remarkably accurate in correcting for fixation errors, even when gaze is minimally displaced. However, fixational saccades also occur when gaze is centered, but their latency increases as the fixation error decreases. These results suggest that fixational saccades serve an important corrective function when needed, but they can only be avoided for a limited period of time when fixation is already accurate.</p>",
      "author": "Wang, J. Z., Cherici, C., Rucci, M.",
      "published_date": "2025-09-24T16:30:28+00:00",
      "source": "Journal Neuroscience Current",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 221,
      "reading_time": 1,
      "created_at": "2025-10-01T16:25:33.153390+00:00",
      "updated_at": "2025-10-01T16:25:33.153391+00:00"
    },
    {
      "id": "2abc94ffb1cecfa2469439e94301d859",
      "url": "http://www.jneurosci.org/cgi/content/short/45/39/e2160242025?rss=1",
      "title": "Left Perisylvian Rhythms Encode Prosody and Syntax during Delayed Sentence Repetition",
      "content": "<p>The human brain must add information to the acoustic speech signal in order to understand language. Many accounts propose that the prosodic structure of utterances (including their syllabic rhythm and speech melody), in combination with stored lexical knowledge, cue and interact with higher order abstract semantic and syntactic information. While cortical rhythms, particularly in the delta and theta band, synchronize to quasi-rhythmic low-level acoustic speech features, it remains unclear how the human brain encodes abstract speech properties in neural rhythms in the absence of an acoustic signal, i.e., when speakers hold planned sentences in working memory. This study disentangles the contributions of prosodic and syntactic features in cortical rhythms during delayed sentence repetition. Using high-resolution ECoG during awake tumor surgery in the left perisylvian cortex in nine patients (five female), we show that the phase of neural rhythms with frequencies ranging from 1 to 48&nbsp;Hz and the broadband gamma power envelope code both low-level acoustic and abstract syntactic speech features during sentence processing and retention. Syntax and prosody coding occurred in the same frequency bands, which argues against the assumption of different frequency channels for processing and representing these speech features. Our data suggest the brain leverages the phase of various neural rhythms to code both acoustic and abstract linguistic features.</p>",
      "author": "Gehrig, J., Bergmann, C., Forster, M.-T., Weismantel, C., Bai, F., Czabanka, M., Martin, A. E., Meyer, A., Kell, C. A.",
      "published_date": "2025-09-24T16:30:28+00:00",
      "source": "Journal Neuroscience Current",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 211,
      "reading_time": 1,
      "created_at": "2025-10-01T16:25:33.153355+00:00",
      "updated_at": "2025-10-01T16:25:33.153356+00:00"
    },
    {
      "id": "cc0d617d47bef1365880c900a1561a9f",
      "url": "http://www.jneurosci.org/cgi/content/short/45/39/e2073242025?rss=1",
      "title": "Hierarchical Organization of Human Visual Feature Attention Control",
      "content": "<p>Attention can be deployed in advance of visual stimuli based on features such as color or direction of motion. This anticipatory feature-based attention involves top-down neural control signals from the frontoparietal network that bias visual cortex to enhance attended information and suppress distraction. For example, anticipatory attention control can enable effective selection based on stimulus color while ignoring distracting information about stimulus motion. Anticipatory attention can also be focused more narrowly, for example, to select specific colors or motion directions that define task-relevant aspects of the stimuli. One important question that remains open is whether anticipatory attention control first biases broad feature dimensions such as color versus motion before biasing the specific feature attributes (e.g., blue vs green). To investigate this, we recorded EEG activity during a task where human participants of either sex were cued to either attend to a motion direction (up or down) or a color (blue or green) on a trial-by-trial basis. Applying multivariate decoding approaches to the EEG alpha band activity (8&ndash;12&nbsp;Hz) during attention control (cue-target interval), we observed significant decoding for both the attended dimensions (motion vs color) and specific feature attributes (up vs down; blue vs green). Importantly, the temporal onset of the dimension-level biasing (motion vs color) preceded that of the attribute-level biasing (up vs down and blue vs green). These findings demonstrate that the top-down control of feature-based attention proceeds in a hierarchical fashion, first biasing the broad feature dimension, and then narrowing to the specific feature attribute.</p>",
      "author": "Meyyappan, S., Ding, M., Mangun, G. R.",
      "published_date": "2025-09-24T16:30:28+00:00",
      "source": "Journal Neuroscience Current",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 247,
      "reading_time": 1,
      "created_at": "2025-10-01T16:25:33.153320+00:00",
      "updated_at": "2025-10-01T16:25:33.153322+00:00"
    },
    {
      "id": "4f10be02f2c7a1ec6d143b7d4c067728",
      "url": "http://www.jneurosci.org/cgi/content/short/45/39/e1018252025?rss=1",
      "title": "Familiarity Gates Socially Transmitted Aggression via the Medial Amygdala",
      "content": "<p>Aggressive behavior can be acquired through observation, providing adaptive advantages but also posing significant social risks. In humans, individuals repeatedly exposed to aggression are more likely to engage in violent behavior later in life. Yet, the environmental factors and neural mechanisms underlying observationally acquired aggression remain unclear. Here, we propose that social familiarity with an aggressor is critical for activating neural circuits in observers that primes aggression. To investigate this, we established a novel behavioral paradigm termed \"socially transmitted aggression (STA),\" in which witness mice observed either familiar or unfamiliar demonstrators attacking intruder mice. Remarkably, male, but not female, witnesses displayed increased aggression only after observing familiar demonstrators, with no effect from unfamiliar ones. Given that excitatory neurons in the posterior&ndash;ventral segment of the medial amygdala (MeApv) have been implicated in aggression priming, we hypothesized these neurons might be involved in STA as well. Supporting this hypothesis, fiber photometry revealed selective activation of excitatory MeApv neurons during familiar, but not unfamiliar, demonstrator attacks. Chemogenetically and optogenetically inhibiting these neurons suppressed STA, while activating them during unfamiliar demonstrator attacks promoted aggression. These results establish social familiarity as essential for the observational transmission of aggression and identify excitatory MeApv neurons as critical mediators of this phenomenon, offering potential avenues for clinical intervention.</p>",
      "author": "Adjei, M. P., Qasem, E., Aaflaq, S., Jacobs, J. T., Skinner, S., Summa, F., Spotanski, C., Thompson, R., Aholt, M. L., Lineberry, T., Nordman, J. C.",
      "published_date": "2025-09-24T16:30:28+00:00",
      "source": "Journal Neuroscience Current",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 210,
      "reading_time": 1,
      "created_at": "2025-10-01T16:25:33.153283+00:00",
      "updated_at": "2025-10-01T16:25:33.153284+00:00"
    },
    {
      "id": "5d0309982d311545b5543bb427d7d77c",
      "url": "http://www.jneurosci.org/cgi/content/short/45/39/e0943252025?rss=1",
      "title": "Perisynaptic Astroglial Response to In Vivo Long-Term Potentiation and Concurrent Long-Term Depression in the Hippocampal Dentate Gyrus",
      "content": "<p>Perisynaptic astroglia provide critical molecular and structural support to regulate synaptic transmission and plasticity in the nanodomain of the axon&ndash;spine interface. Three-dimensional reconstruction from serial section electron microscopy (3DEM) was used to investigate relationships between perisynaptic astroglia and dendritic spine synapses undergoing plasticity in the adult hippocampus. Delta-burst stimulation (DBS) of the medial perforant pathway induced long-term potentiation (LTP) in the middle molecular layer and concurrent long-term depression (cLTD) in the outer molecular layer of the dentate gyrus in awake male rats. The contralateral hippocampus received baseline stimulation as a within-animal control. Brains were obtained 30&nbsp;min or 2&nbsp;h after DBS onset. An automated 3DEM pipeline was developed to enable unbiased quantification of astroglial coverage at the perimeter of the axon&ndash;spine interface. Under all conditions, &gt;85% of synapses had perisynaptic astroglia processes within 120&nbsp;nm of some portion of the perimeter. LTP broadened the distribution of spine sizes while reducing the presence and proximity of perisynaptic astroglia near the axon&ndash;spine interface of large spines. In contrast, cLTD transiently reduced the length of the axon&ndash;spine interface perimeter without substantially altering astroglial apposition. The postsynaptic density was discovered to be displaced from the center of the axon&ndash;spine interface, with this offset increasing during LTP and decreasing during cLTD. Astroglial access to the postsynaptic density was diminished during LTP and enhanced during cLTD, in parallel with changes in spine size. Thus, access of perisynaptic astroglia to synapses is dynamically modulated during LTP and cLTD alongside synaptic remodeling.</p>",
      "author": "Nam, A. J., Kuwajima, M., Parker, P. H., Bowden, J. B., Abraham, W. C., Harris, K. M.",
      "published_date": "2025-09-24T16:30:28+00:00",
      "source": "Journal Neuroscience Current",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 242,
      "reading_time": 1,
      "created_at": "2025-10-01T16:25:33.153246+00:00",
      "updated_at": "2025-10-01T16:25:33.153248+00:00"
    },
    {
      "id": "b846600b42504d4e49f23d049b7c9d14",
      "url": "http://www.jneurosci.org/cgi/content/short/45/39/e0805252025?rss=1",
      "title": "Strengthening Medial Olivocochlear Feedback Reduces the Developmental Impact of Early Noise Exposure",
      "content": "<p>The early onset of peripheral deafness significantly alters the proper development of the auditory system. Likewise, exposure to loud noise during early development produces a similar disruptive effect. Before hearing onset in altricial mammals, cochlear inner hair cells (IHCs) exhibit spontaneous electrical activity that drives auditory circuit development. This activity is modulated by medial olivocochlear (MOC) efferent feedback through &alpha;9&alpha;10 nicotinic cholinergic receptors in IHCs. In adults, these receptors are restricted to outer hair cells, where they mediate MOC feedback to regulate cochlear amplification. Although the MOC system's protective role to prevent noise-induced hearing loss in adulthood is well established, its influence during early developmental stages&mdash;especially in response to exposure to loud noise&mdash;remains largely unexplored. In this study, we investigated the role of MOC feedback during early postnatal development using &alpha;9 knock-out (KO) and &alpha;9 knock-in (KI) mice of either sex, which respectively lack or exhibit enhanced cholinergic activity. Our findings reveal that both increased and absent olivocochlear activity result in altered auditory sensitivity at the onset of hearing, along with long-range alterations in the number and morphology of ribbon synapses. Early noise exposure caused lasting auditory damage in both wild-type and &alpha;9KO mice, with deficits persisting into adulthood. In contrast, &alpha;9KI mice were protected from noise-induced damage, with no long-term effects on auditory function. These results highlight the increased susceptibility of the auditory system during early postnatal development. Moreover, they indicate that an enhanced MOC feedback shields the auditory system from noise damage during this period.</p>",
      "author": "Castagna, V. C., Boero, L. E., Di Guilmi, M. N., Catalano Di Meo, C., Ballestero, J. A., Fuchs, P. A., Lauer, A. M., Elgoyhen, A. B., Gomez-Casati, M. E.",
      "published_date": "2025-09-24T16:30:27+00:00",
      "source": "Journal Neuroscience Current",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 247,
      "reading_time": 1,
      "created_at": "2025-10-01T16:25:33.153208+00:00",
      "updated_at": "2025-10-01T16:25:33.153210+00:00"
    },
    {
      "id": "c26d89d902991a3e13b4738807303d24",
      "url": "http://www.jneurosci.org/cgi/content/short/45/39/etwij45392025?rss=1",
      "title": "This Week in The Journal",
      "content": "",
      "author": "McKeon, P.",
      "published_date": "2025-09-24T16:30:28+00:00",
      "source": "Journal Neuroscience Current",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-10-01T16:25:33.153040+00:00",
      "updated_at": "2025-10-01T16:25:33.153045+00:00"
    },
    {
      "id": "45271a80a221a35912e75ec358f4cf54",
      "url": "https://www.frontiersin.org/articles/10.3389/fninf.2025.1633273",
      "title": "Generation of synthetic TSPO PET maps from structural MRI images",
      "content": "IntroductionNeuroinflammation, a pathophysiological process involved in numerous disorders, is typically imaged using [11C]PBR28 (or TSPO) PET. However, this technique is limited by high costs and ionizing radiation, restricting its widespread clinical use. MRI, a more accessible alternative, is commonly used for structural or functional imaging, but when used using traditional approaches has limited sensitivity to specific molecular processes. This study aims to develop a deep learning model to generate TSPO PET images from structural MRI data collected in human subjects.MethodsA total of 204 scans, from participants with knee osteoarthritis (n\u202f=\u202f15 scanned once, 15 scanned twice, 14 scanned three times), back pain (n\u202f=\u202f40 scanned twice, 3 scanned three times), and healthy controls (n\u202f=\u202f28, scanned once), underwent simultaneous 3\u202fT MRI and [11C]PBR28 TSPO PET scans. A 3D U-Net model was trained on 80% of these PET-MRI pairs and validated using 5-fold cross-validation. The model\u2019s accuracy in reconstructed PET from MRI only was assessed using various intensity and noise metrics.ResultsThe model achieved a low voxel-wise mean squared error (0.0033\u202f\u00b1\u202f0.0010) across all folds and a median contrast-to-noise ratio of 0.0640\u202f\u00b1\u202f0.2500 when comparing true to reconstructed PET images. The synthesized PET images accurately replicated the spatial patterns observed in the original PET data. Additionally, the reconstruction accuracy was maintained even after spatial normalization.DiscussionThis study demonstrates that deep learning can accurately synthesize TSPO PET images from conventional, T1-weighted MRI. This approach could enable low-cost, noninvasive neuroinflammation imaging, expanding the clinical applicability of this imaging method.",
      "author": "Marco L. Loggia",
      "published_date": "2025-09-08T00:00:00+00:00",
      "source": "Frontiers Neuroinformatics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 250,
      "reading_time": 1,
      "created_at": "2025-10-01T16:25:30.473641+00:00",
      "updated_at": "2025-10-01T16:25:30.473642+00:00"
    }
  ]
}