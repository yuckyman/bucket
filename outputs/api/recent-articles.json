{
  "last_updated": "2025-12-23T18:33:56.952859+00:00",
  "count": 20,
  "articles": [
    {
      "id": "b9592cc6e8b525ca7c468c4d4b89787c",
      "url": "https://www.nature.com/articles/s42003-025-09354-4",
      "title": "Decoding the human brain during intelligence testing",
      "content": "",
      "author": "",
      "published_date": "2025-12-23T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-12-23T18:33:25.118242+00:00",
      "updated_at": "2025-12-23T18:33:25.118243+00:00"
    },
    {
      "id": "b82a29aab915b0dd3d99e21efabbfd74",
      "url": "https://www.nature.com/articles/s41467-025-67518-6",
      "title": "A flexible photoacoustic retinal prosthesis",
      "content": "",
      "author": "",
      "published_date": "2025-12-23T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-12-23T18:33:25.118148+00:00",
      "updated_at": "2025-12-23T18:33:25.118150+00:00"
    },
    {
      "id": "e827b8b4072b527d13604de0986ff046",
      "url": "https://www.nature.com/articles/s41467-025-67765-7",
      "title": "A brain-to-small intestine circuit mediates morphine-induced constipation in male mice",
      "content": "",
      "author": "",
      "published_date": "2025-12-23T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-12-23T18:33:25.118129+00:00",
      "updated_at": "2025-12-23T18:33:25.118130+00:00"
    },
    {
      "id": "2ed7dd539978111476eaeb28c65e7d6e",
      "url": "https://www.nature.com/articles/s41539-025-00391-6",
      "title": "Cardiovascular exercise enhances motor learning across multiple sessions in people with Parkinson\u2019s disease: a randomized controlled pilot trial",
      "content": "",
      "author": "",
      "published_date": "2025-12-23T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-12-23T18:33:25.118084+00:00",
      "updated_at": "2025-12-23T18:33:25.118088+00:00"
    },
    {
      "id": "5a324eb7d29510b004cfa478a69ff9ac",
      "url": "https://clan.lol/blog/towards-app-platform-vmtech/",
      "title": "Towards a secure peer-to-peer app platform for Clan",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46367232\">Comments</a>",
      "author": "",
      "published_date": "2025-12-23T17:34:22+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-23T18:32:49.162306+00:00",
      "updated_at": "2025-12-23T18:32:49.162307+00:00"
    },
    {
      "id": "2b07627d5af9f15ea55b4dfbe952f510",
      "url": "https://blog.helix.ml/p/we-mass-deployed-15-year-old-screen",
      "title": "We replaced H.264 streaming with JPEG screenshots (and it worked better)",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46367475\">Comments</a>",
      "author": "",
      "published_date": "2025-12-23T18:00:31+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-23T18:32:49.162245+00:00",
      "updated_at": "2025-12-23T18:32:49.162247+00:00"
    },
    {
      "id": "045ff16bb859601807339b4a50c2d751",
      "url": "https://devblogs.microsoft.com/oldnewthing/20251223-00/?p=111896",
      "title": "When irate product support customers demand to speak to Bill Gates",
      "content": "<p>Article URL: <a href=\"https://devblogs.microsoft.com/oldnewthing/20251223-00/?p=111896\">https://devblogs.microsoft.com/oldnewthing/20251223-00/?p=111896</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46366761\">https://news.ycombinator.com/item?id=46366761</a></p>\n<p>Points: 22</p>\n<p># Comments: 8</p>",
      "author": "magnat",
      "published_date": "2025-12-23T16:43:03+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-23T18:32:47.789761+00:00",
      "updated_at": "2025-12-23T18:32:47.789762+00:00"
    },
    {
      "id": "6946518e2feb6e8dfccb48d328b8d121",
      "url": "https://www.nytimes.com/2025/12/23/us/politics/doge-musk-trump-analysis.html",
      "title": "How Did Doge Disrupt So Much While Saving So Little?",
      "content": "<p>Article URL: <a href=\"https://www.nytimes.com/2025/12/23/us/politics/doge-musk-trump-analysis.html\">https://www.nytimes.com/2025/12/23/us/politics/doge-musk-trump-analysis.html</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46367223\">https://news.ycombinator.com/item?id=46367223</a></p>\n<p>Points: 60</p>\n<p># Comments: 26</p>",
      "author": "JumpCrisscross",
      "published_date": "2025-12-23T17:33:40+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-23T18:32:47.789721+00:00",
      "updated_at": "2025-12-23T18:32:47.789723+00:00"
    },
    {
      "id": "5a324eb7d29510b004cfa478a69ff9ac",
      "url": "https://clan.lol/blog/towards-app-platform-vmtech/",
      "title": "Towards a secure peer-to-peer app platform for Clan",
      "content": "<p>Article URL: <a href=\"https://clan.lol/blog/towards-app-platform-vmtech/\">https://clan.lol/blog/towards-app-platform-vmtech/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46367232\">https://news.ycombinator.com/item?id=46367232</a></p>\n<p>Points: 3</p>\n<p># Comments: 0</p>",
      "author": "throawayonthe",
      "published_date": "2025-12-23T17:34:22+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-23T18:32:47.789649+00:00",
      "updated_at": "2025-12-23T18:32:47.789658+00:00"
    },
    {
      "id": "08e664e88f4ab84df159a973a76a40e7",
      "url": "http://doi.org/10.1037/bne0000634",
      "title": "Conditioned place preferences for virtual reality cannabis cues.",
      "content": "This study investigated whether 221 undergraduates (123 males, 98 females) with varying levels of cannabis use displayed a conditioned place preference (CPP) for a virtual reality (VR) room that previously contained virtual cannabis stimuli compared to a neutral VR room that was not paired with cannabis cues. We hypothesized that cannabis-using participants (<em>n</em> = 180) would spend a greater amount of time in, report greater subjective enjoyment in, and explicitly prefer a VR room that was previously paired with virtual cannabis stimuli relative to a neutral room, while participants with nonuse (<em>n</em> = 41) would not. Overall, participants did not demonstrate an implicit or explicit CPP for a VR room that was previously paired with cannabis cues. Interestingly, however, participants with recent cannabis use (<em>n</em> = 41) exhibited a significant implicit CPP for the cannabis-cue-paired VR room, while participants with nonrecent cannabis use (<em>n</em> = 113) did not. Furthermore, relative to males with cannabis use (<em>n</em> = 93), females with cannabis use (<em>n</em> = 87) demonstrated a significant explicit CPP for the cannabis-cue-paired context as well as significantly greater cannabis cravings. These findings elucidate the need for further research on the role of acute cannabis intoxication, sex, and cue-induced cravings in modulating CPP for cannabis-associated contexts. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2025-09-01T00:00:00+00:00",
      "source": "Behavioral Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 215,
      "reading_time": 1,
      "created_at": "2025-12-23T17:44:45.183037+00:00",
      "updated_at": "2025-12-23T18:24:05.403879+00:00",
      "metadata": {
        "processed_at": "2025-12-23T18:24:05.403889+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "5168657f83102357e9854c856d6e8912",
      "url": "http://doi.org/10.1037/bne0000630",
      "title": "Paraventricular thalamic inputs to the ventral pallidum shape reward seeking during threat and fear responding in extinction.",
      "content": "Environmental threats are typically encountered when animals are searching for food and other necessities. Adaptive behavior must balance competition between fear behavior and reward seeking. We gave rats local neuronal deletions of the ventral pallidum (VP) or specifically deleted paraventricular thalamic nucleus (PVT) neurons projecting directly to the VP. Rats were then assessed in a conditioned suppression procedure in which cues predicting unique foot shock probabilities were presented during, but independent from, reward seeking. Foot shock introduction generally suppressed reward seeking in rats, and recovery from shock introduction was facilitated in rats with VP or PVT \u2192 VP pathway deletions. Discriminative fear was observed in controls, and this fear responding reduced over a single extinction session. VP deletion enhanced extinction fear responding, and PVT \u2192 VP pathway deletion abolished within-session fear reductions. The results demonstrate the VP and its inputs from the PVT shape reward seeking in threat settings and govern fear extinction responding. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2025-09-01T00:00:00+00:00",
      "source": "Behavioral Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 163,
      "reading_time": 1,
      "created_at": "2025-12-23T17:44:45.183000+00:00",
      "updated_at": "2025-12-23T18:24:05.403893+00:00",
      "metadata": {
        "processed_at": "2025-12-23T18:24:05.403895+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "a8bbd636a4560189b204aa4362d5d614",
      "url": "https://github.com/bellard/mquickjs/blob/main/README.md",
      "title": "Fabrice Bellard Releases MicroQuickJS",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46367224\">Comments</a>",
      "author": "",
      "published_date": "2025-12-23T17:33:42+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-23T17:44:40.479952+00:00",
      "updated_at": "2025-12-23T18:24:05.403897+00:00",
      "metadata": {
        "processed_at": "2025-12-23T18:24:05.403899+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "a8bbd636a4560189b204aa4362d5d614",
      "url": "https://github.com/bellard/mquickjs/blob/main/README.md",
      "title": "Fabrice Bellard Releases MicroQuickJS",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46367224\">Comments</a>",
      "author": "",
      "published_date": "2025-12-23T17:33:42+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-23T17:44:40.479952+00:00",
      "updated_at": "2025-12-23T18:24:05.403897+00:00",
      "metadata": {
        "processed_at": "2025-12-23T18:24:05.403899+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "a3d213dde683645a6f59de9d80bcf5db",
      "url": "https://www.phoronix.com/news/Meta-SCX-LAVD-Steam-Deck-Server",
      "title": "Meta Is Using the Linux Scheduler Designed for Valve's Steam Deck on Its Servers",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46366998\">Comments</a>",
      "author": "",
      "published_date": "2025-12-23T17:08:34+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-23T17:44:40.479913+00:00",
      "updated_at": "2025-12-23T18:24:05.403902+00:00",
      "metadata": {
        "processed_at": "2025-12-23T18:24:05.403903+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "a3d213dde683645a6f59de9d80bcf5db",
      "url": "https://www.phoronix.com/news/Meta-SCX-LAVD-Steam-Deck-Server",
      "title": "Meta Is Using the Linux Scheduler Designed for Valve's Steam Deck on Its Servers",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46366998\">Comments</a>",
      "author": "",
      "published_date": "2025-12-23T17:08:34+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-23T17:44:40.479913+00:00",
      "updated_at": "2025-12-23T18:24:05.403902+00:00",
      "metadata": {
        "processed_at": "2025-12-23T18:24:05.403903+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "b1cdce7f5e061a4ca5bf268adc4e71f2",
      "url": "http://doi.org/10.1037/bne0000629",
      "title": "Patterns of prefrontal cortical activity associated with attention-demanding and motor aspects of dual-task walking as measured with functional near-infrared spectroscopy.",
      "content": "The ability to engage in everyday tasks, such as walking, requires the integration of cognitive and motor processes. How these processes integrate may be discernable through the relation of brain activity patterns to behavioral performance, particularly in the prefrontal cortex (PFC), examination of which has been restricted because of the limitations in experimental design. We related behavior (cognition, walking) to brain activity, as measured by functional near-infrared spectroscopy, under dual-task conditions (cognition while walking) in healthy young adults. Our probe design enabled us to examine eight regions of interest across PFC and motor cortex to identify key areas related to behavior. Healthy young adults (N = 19) engaged in standing cognition (Serial 3 subtraction), single-task walking, and dual-task walking. We used functional near-infrared spectroscopy to identify regions associated with increases or decreases in activity under dual-task relative to the other conditions. We observed differences in brain activity patterns by task across multiple regions of interest, mostly in PFC. Specifically, more lateral regions were related to attention-demanding tasks, whereas motor tasks were related to relatively medial regions. Our results relate behavior to brain activity, as measured by functional near-infrared spectroscopy, under dual-task conditions. Our finding of relatively lateral PFC activity during attention-demanding tasks provides insights into behavioral and brain processes during experimental analogues of everyday activity, bringing us closer to understanding behavior-brain relations in the real world. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2025-09-01T00:00:00+00:00",
      "source": "Behavioral Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 235,
      "reading_time": 1,
      "created_at": "2025-12-23T17:21:38.042719+00:00",
      "updated_at": "2025-12-23T17:21:38.042723+00:00"
    },
    {
      "id": "98738c175114f372cd7deaeb64145720",
      "url": "https://astroimagery.com/techniques/imaging/astrophotography-target-planner/",
      "title": "Astrophotography Target Planner: Discover Hidden Nebulas",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46330012\">Comments</a>",
      "author": "",
      "published_date": "2025-12-19T19:44:41+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-23T17:21:33.565182+00:00",
      "updated_at": "2025-12-23T17:21:33.565183+00:00"
    },
    {
      "id": "23a96a2a2c038884db3681a5ba667d30",
      "url": "https://yapi.run/blog/what-is-yapi",
      "title": "Show HN: Yapi \u2013 FOSS terminal API client for power users",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46352350\">Comments</a>",
      "author": "",
      "published_date": "2025-12-22T08:49:47+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-23T17:21:33.565163+00:00",
      "updated_at": "2025-12-23T17:21:33.565164+00:00"
    },
    {
      "id": "e1385798428586a67ced89a895faeb47",
      "url": "https://erpinfo.org/blog/2024/6/10/erp-core-decoding-paper",
      "title": "New Paper: Using Multivariate Pattern Analysis to Increase Effect Sizes for ERP Amplitude Comparisons",
      "content": "<p class=\"\">Carrasco, C. D., Bahle, B., Simmons, A. M., &amp; Luck, S. J. (2024). Using multivariate pattern analysis to increase effect sizes for event-related potential analyses. Psychophysiology, 61, e14570. <a href=\"https://doi.org/10.1111/psyp.14570\">https://doi.org/10.1111/psyp.14570</a> [<a href=\"https://doi.org/10.1101/2023.11.07.566051\">preprint</a>]</p><p class=\"\">Multivariate pattern analysis (MVPA) can be used to \u201cdecode\u201d subtle information from ERP signals, such as which of several faces a participant is perceiving or the orientation that someone is holding in working memory (see <a href=\"https://erpinfo.org/blog/2018/9/16/decoding\">this previous blog post</a>). This approach is so powerful that we started wondering whether it might also give us greater statistical power in more typical experiments where the goal is to determine whether an ERP component differs in amplitude across experimental conditions. For example, might we more easily be able to tell if N400 amplitude is different between two different classes of words by using decoding? If so, that might make it possible to detect effects that would otherwise be too small to be significant.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"688\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/08f353c7-f484-4e87-b5d3-a256fe1206e2/N170_ES.png?format=1000w\" width=\"971\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">To address this question, we compared decoding with the conventional ERP analysis approach with using the 6 experimental paradigms in the <a href=\"https://doi.org/10.18115/D5JW4R\">ERP CORE</a>. In the conventional ERP analysis, we measured the mean amplitude during the standard measurement window from each participant in the two conditions of the paradigm (e.g., faces versus cars for N170, deviants versus standards for MMN). We quantified the magnitude of the difference between conditions using Cohen\u2019s <em>dz</em> (the variant of Cohen\u2019s <em>d</em> corresponding to a paired <em>t</em> test). For example, the effect size in the conventional ERP comparison of faces versus cars in the N170 paradigm was approximately 1.7 (see the figure).</p><p class=\"\">We also applied decoding to each paradigm. For example, in the N170 paradigm, we trained a support vector machine (SVM) to distinguish between ERPs elicited by faces and ERPs elicited by cars. This was done separately for each subject, and we converted the decoding accuracy into Cohen\u2019s <em>dz</em> so that it could be compared with the <em>dz</em> from the conventional ERP analysis. As you can see from the bar labeled SVM in the figure above, the effect size for the SVM-based decoding analysis was almost twice as large as the effect size for the conventional ERP analysis. That\u2019s a huge difference!</p><p class=\"\">We found a similar benefit for SVM-based decoding over conventional ERP analyses in 7 of the 10 cases we tested (see the figure below). In the other 3 cases, the ERP and SVM effects were approximately equivalent. So, there doesn\u2019t seem to be a downside to using decoding, at least in terms of effect size. But there can be a big benefit.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1371\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/d16f0782-7205-4d50-95e1-c6729cbc153e/All_Components.png?format=1000w\" width=\"4641\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">Because decoding has many possible benefits, we\u2019ve added it into <a href=\"ERPLAB Toolbox\">ERPLAB Toolbox</a>. It\u2019s super easy to use, and we\u2019ve created <a href=\"https://erpinfo.org/blog/2023/6/23/decoding-webinar\">detailed documentation and a video</a> to explain how it works at a conceptual level and to show you how to use it.</p><p class=\"\">We encourage you to apply it to your own data. It may give you the power to detect effects that are too small to be detected with conventional ERP analyses.</p>",
      "author": "Steve Luck",
      "published_date": "2024-06-10T18:01:45+00:00",
      "source": "Erp Boot Camp",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 525,
      "reading_time": 2,
      "created_at": "2025-12-23T16:55:07.829282+00:00",
      "updated_at": "2025-12-23T16:55:07.829284+00:00"
    },
    {
      "id": "906f73f5c36ba087882a0ad17e01fc20",
      "url": "https://erpinfo.org/blog/2024/6/11/erplab-studio",
      "title": "New software package: ERPLAB Studio",
      "content": "<p class=\"\">We are excited to announce the release of a new EEG/ERP analysis package, <a href=\"https://github.com/ucdavis/erplab/releases\">ERPLAB Studio</a>. We think it\u2019s a huge improvement over the classic EEGLAB user interface. See our cheesy <a href=\"https://www.youtube.com/watch?v=lIaKVQ9DD6E\">\u201cadvertisement\u201d video</a> to get a quick overview. </p><p class=\"\">Rather than operating as an EEGLAB plugin, ERPLAB Studio is a standalone Matlab program that provides a more efficient and user-friendly interface to the most commonly used EEGLAB and ERPLAB routines.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1080\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/c874d4ec-5186-4de9-981b-58010c7a06e1/Interface.jpeg?format=1000w\" width=\"1920\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">With ERPLAB Studio, you automatically see the EEG or ERP waveforms as soon as you load a file. And as soon as you perform an operation, you see what the new EEG/ERP looks like. For example, when you filter the data, you immediately see the filtered waveforms.</p><p class=\"\">You can even select multiple datasets and apply an operation like artifact detection on all of them in one step. And then you can immediately see the results, such as which EEG epochs have been marked with artifacts.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1080\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/b45f514d-2d21-4a5a-8be6-f3a8ff99c388/Artifacts.jpeg?format=1000w\" width=\"1920\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">We give you access to EEGLAB\u2019s ICA-based artifact correction tools, but with a nice bonus. You can plot the ICA activations in the same window with the EEG data, making it easy to see which ICA components correspond to specific artifacts such as eyeblinks.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1080\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/8bc191da-9040-4042-ae9c-550cd98def7d/ICA.jpeg?format=1000w\" width=\"1920\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">The program has an EEG tab for processing continuous and epoched EEG data, and an ERP tab for processing averaged ERPs.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1080\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/84bdd9df-b02e-4fc5-83b9-1139a91938f5/Tabs.jpg?format=1000w\" width=\"1920\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">The automatic ERP plotting makes it easy for you to view the data laid out according to the electrode locations. And we have an Advanced Waveform Viewer that can make publication-quality plots.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1080\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/a932631f-fc30-415f-b11d-660d2bf90da5/ERP.jpeg?format=1000w\" width=\"1920\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">ERPLAB Studio is mainly just a new user interface. Under the hood, we\u2019re running the same EEGLAB and ERPLAB routines you\u2019ve always used. And scripting is identical.</p><p class=\"\">ERPLAB Studio is included in <a href=\"https://github.com/ucdavis/erplab/releases\">version 11 and higher of ERPLAB</a>. You simply follow our <a href=\"https://github.com/ucdavis/erplab/wiki/installation\">download/installation instructions</a> and then type estudio from the Matlab command line. </p><p class=\"\">If you\u2019re new to ERPLAB, we strongly recommend that you go through our <a href=\"https://github.com/ucdavis/erplab/wiki/ERPLAB-Studio-Tutorial\" target=\"_blank\">tutorial</a> before starting to process your own data. </p><p class=\"\">If you already know how to use the original version of ERPLAB (which we now call ERPLAB Classic), you can quickly learn how to use ERPLAB Studio with our <a href=\"https://ucdavis.box.com/s/i4jfv22gv6rj9t5obctuk6yaruxqomcc\">Transition Guide</a>.</p><p class=\"\">We also have a <a href=\"https://github.com/ucdavis/erplab/wiki/ERPLAB-Studio-Manual\">manual</a> that describes every feature in detail. </p>",
      "author": "Steve Luck",
      "published_date": "2024-06-12T02:02:16+00:00",
      "source": "Erp Boot Camp",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 444,
      "reading_time": 2,
      "created_at": "2025-12-23T16:55:07.829201+00:00",
      "updated_at": "2025-12-23T16:55:07.829202+00:00"
    }
  ]
}