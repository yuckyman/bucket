{
  "last_updated": "2026-01-24T21:20:56.938134+00:00",
  "count": 20,
  "articles": [
    {
      "id": "c03b847f5fac00dacfbc3f8912ce96ed",
      "url": "https://www.sciencedirect.com/science/article/pii/S0306452225012266?dgcid=rss_sd_all",
      "title": "Advances in how the peripheral immune system interacts with the brain in health and disease",
      "content": "<p>Publication date: 5 March 2026</p><p><b>Source:</b> Neuroscience, Volume 596</p><p>Author(s): Victor Manuel Ruiz-Rodr\u00edguez, Ares Orlando Cuellar-Santoyo, Ana Mar\u00eda Estrada-S\u00e1nchez</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroscience Journal",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 17,
      "reading_time": 1,
      "created_at": "2026-01-24T21:20:22.387656+00:00",
      "updated_at": "2026-01-24T21:20:22.387658+00:00"
    },
    {
      "id": "b7e4fdb3d226ba2874eddb3a8c00b216",
      "url": "https://www.reddit.com/r/Python/comments/1qlx02c/generate_openai_embeddings_locally_with_minilm/",
      "title": "Generate OpenAI Embeddings Locally with MiniLM ( 70x Cost Saving / Speed Improvement )",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>[This is my 2nd attempt at a post here; dear moderators, I am not an AI! ... at least I don't think I am ]</p> <p><strong>What My Project Does:</strong> <a href=\"https://medium.com/@ace0278/generate-openai-style-embeddings-locally-with-minilm-adapter-f43ec9c3b7da\">EmbeddingAdapters </a>is a Python library for translating between embedding model vector spaces.</p> <p>It provides plug-and-play adapters that map embeddings produced by one model into the vector space of another \u2014 locally or via provider APIs \u2014 enabling cross-model retrieval, routing, interoperability, and migration <strong>without re-embedding an existing corpus</strong>.</p> <p>If a vector index is already built using one embedding model, embedding-adapters allows it to be queried using another, without rebuilding the index.</p> <p><strong>Target Audience</strong>: Anyone who is a developer or startup, if you have a mobile app and you want to run ultra fast on-device RAG with provider level quality, use this. If you want to save money on embeddings over millions of queries, use this. If you want to sample embedding spaces you don't have access to - gemini mongo etc. - use this.</p> <p><strong>Comparison:</strong> There is no comparable library that specializes in this</p> <p><strong>Why I Made This:</strong> This solved a serious pain point for me, but I also realized that we could extend it greatly as a community. Each time a new model is added to the library, it permits a new connection\u2014you can effectively walk across different model spaces. Chain these adapters together and you can do some really interesting things.</p> <p>For example, you could go from OpenAI \u2192 MiniLM (you may not think you want to do that, but consider the cost savings of being able to interact with MiniLM embeddings as if they were OpenAI).</p> <p>I know this doesn\u2019t sound possible, but it is. The adapters reinterpret the semantic signals already present in these models. It won\u2019t work for every input text, but by pairing each adapter with a confidence score, you can effectively route between a provider and a local model. This cuts costs dramatically and significantly speeds up query embedding generation.</p> <p><strong>GitHub:</strong><br /> <a href=\"https://github.com/PotentiallyARobot/EmbeddingAdapters/\">https://github.com/PotentiallyARobot/EmbeddingAdapters/</a></p> <p><strong>PyPI:</strong><br /> <a href=\"https://pypi.org/project/embedding-adapters/\">https://pypi.org/project/embedding-adapters/</a></p> <h1>Example</h1> <p>Generate an OpenAI embedding locally from minilm+adapter:</p> <pre><code>pip install embedding-adapters embedding-adapters embed \\ --source sentence-transformers/all-MiniLM-L6-v2 \\ --target openai/text-embedding-3-small \\ --flavor large \\ --text &quot;where are restaurants with a hamburger near me&quot; </code></pre> <p>The command returns:</p> <ul> <li>an embedding in the target (OpenAI) space</li> <li>a confidence / quality score estimating adapter reliability</li> </ul> <h1>Model Input</h1> <p>At inference time, the adapter\u2019s <strong>only input is an embedding vector</strong> from a source model.<br /> No text, tokens, prompts, or provider embeddings are used.</p> <p>A pure <strong>vector \u2192 vector</strong> mapping is sufficient to recover most of the retrieval behavior of larger proprietary embedding models for in-domain queries.</p> <h1>Benchmark results</h1> <p><strong>Dataset:</strong> SQuAD (8,000 Q/A pairs)</p> <p><strong>Latency (answer embeddings):</strong></p> <ul> <li>MiniLM embed: <strong>1.08 s</strong></li> <li>Adapter transform: <strong>0.97 s</strong></li> <li>OpenAI API embed: <strong>40.29 s</strong></li> </ul> <p>\u2248 <strong>70\u00d7 faster</strong> for local MiniLM + adapter vs OpenAI API calls.</p> <p><strong>Retrieval quality (Recall@10):</strong></p> <ul> <li>MiniLM \u2192 MiniLM: <strong>10.32%</strong></li> <li>Adapter \u2192 Adapter: <strong>15.59%</strong></li> <li>Adapter \u2192 OpenAI: <strong>16.93%</strong></li> <li>OpenAI \u2192 OpenAI: <strong>18.26%</strong></li> </ul> <p>Bootstrap difference (OpenAI \u2212 Adapter \u2192 OpenAI): <strong>~1.34%</strong></p> <p>For in-domain queries, the MiniLM \u2192 OpenAI adapter recovers ~<strong>93%</strong> of OpenAI retrieval performance and substantially outperforms MiniLM-only baselines.</p> <h1>How it works (high level)</h1> <p>Each adapter is trained on a <strong>restricted domain</strong>, allowing it to specialize in interpreting the semantic signals of smaller models and projecting them into higher-dimensional provider spaces while preserving retrieval-relevant structure.</p> <p>A quality score is provided to determine whether an input is well-covered by the adapter\u2019s training distribution.</p> <h1>Practical uses in Python applications</h1> <ul> <li>Query an existing vector index built with one embedding model using another</li> <li>Operate mixed vector indexes and route queries to the most effective embedding space</li> <li>Reduce cost and latency by embedding locally for in-domain queries</li> <li>Evaluate embedding providers before committing to a full re-embed</li> <li>Gradually migrate between embedding models</li> <li>Handle provider outages or rate limits gracefully</li> <li>Run RAG pipelines in air-gapped or restricted environments</li> <li>Maintain a stable \u201ccanonical\u201d embedding space while changing edge models</li> </ul> <h1>Supported adapters</h1> <ul> <li>MiniLM \u2194 OpenAI</li> <li>OpenAI \u2194 Gemini</li> <li>E5 \u2194 MiniLM</li> <li>E5 \u2194 OpenAI</li> <li>E5 \u2194 Gemini</li> <li>MiniLM \u2194 Gemini</li> </ul> <p>The project is under active development, with ongoing work on additional adapter pairs, domain specialization, evaluation tooling, and training efficiency.</p> <p>Please Like/Upvote</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Interesting-Town-433\"> /u/Interesting-Town-433 </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1qlx02c/generate_openai_embeddings_locally_with_minilm/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1qlx02c/generate_openai_embeddings_locally_with_minilm/\">[comments]</a></span>",
      "author": "/u/Interesting-Town-433",
      "published_date": "2026-01-24T19:53:55+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 722,
      "reading_time": 3,
      "created_at": "2026-01-24T21:19:38.798652+00:00",
      "updated_at": "2026-01-24T21:19:38.798654+00:00"
    },
    {
      "id": "34057d2cf16cc6a248c6c8b4cce339df",
      "url": "https://www.ycombinator.com/companies/gym-class-by-irl-studios/jobs/ywXHGBv-design-engineer-senior-staff-principal",
      "title": "First Design Engineer Hire \u2013 Build Games at Gym Class (YC W22)",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46747625\">Comments</a>",
      "author": "",
      "published_date": "2026-01-24T21:01:02+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-24T21:19:37.463149+00:00",
      "updated_at": "2026-01-24T21:19:37.463150+00:00"
    },
    {
      "id": "1c7eab55c441d6f48946b3c764c12eb4",
      "url": "https://m24tom.com/bye-bye-gmail/show",
      "title": "Bye Bye Gmail",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46746946\">Comments</a>",
      "author": "",
      "published_date": "2026-01-24T19:44:52+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-24T21:19:37.463090+00:00",
      "updated_at": "2026-01-24T21:19:37.463091+00:00"
    },
    {
      "id": "9eebf62669c90dcbaa4e008159f45867",
      "url": "https://micahcantor.com/blog/bluesky-comment-section.html",
      "title": "I added a Bluesky comment section to my blog",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46747366\">Comments</a>",
      "author": "",
      "published_date": "2026-01-24T20:33:40+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-24T21:19:37.463047+00:00",
      "updated_at": "2026-01-24T21:19:37.463050+00:00"
    },
    {
      "id": "b632eef197d74cc883fd4708d1adbb83",
      "url": "https://news.ycombinator.com/item?id=46746700",
      "title": "Show HN: Polymcp \u2013 Turn Any Python Function into an MCP Tool for AI Agents",
      "content": "<p>I built Polymcp, a framework that allows you to transform any Python function into an MCP (Model Context Protocol) tool ready to be used by AI agents. No rewriting, no complex integrations.<p>Examples<p>Simple function:<p>from polymcp.polymcp_toolkit import expose_tools_http<p>def add(a: int, b: int) -> int:\n    \"\"\"Add two numbers\"\"\"\n    return a + b<p>app = expose_tools_http([add], title=\"Math Tools\")<p>Run with:<p>uvicorn server_mcp:app --reload<p>Now add is exposed via MCP and can be called directly by AI agents.<p>API function:<p>import requests\nfrom polymcp.polymcp_toolkit import expose_tools_http<p>def get_weather(city: str):\n    \"\"\"Return current weather data for a city\"\"\"\n    response = requests.get(f\"<a href=\"https://api.weatherapi.com/v1/current.json?q={city}\" rel=\"nofollow\">https://api.weatherapi.com/v1/current.json?q={city}</a>\")\n    return response.json()<p>app = expose_tools_http([get_weather], title=\"Weather Tools\")<p>AI agents can call get_weather(\"London\") to get real-time weather data instantly.<p>Business workflow function:<p>import pandas as pd\nfrom polymcp.polymcp_toolkit import expose_tools_http<p>def calculate_commissions(sales_data: list[dict]):\n    \"\"\"Calculate sales commissions from sales data\"\"\"\n    df = pd.DataFrame(sales_data)\n    df[\"commission\"] = df[\"sales_amount\"] * 0.05\n    return df.to_dict(orient=\"records\")<p>app = expose_tools_http([calculate_commissions], title=\"Business Tools\")<p>AI agents can now generate commission reports automatically.<p>Why it matters for companies\n \u2022 Reuse existing code immediately: legacy scripts, internal libraries, APIs.\n \u2022 Automate complex workflows: AI can orchestrate multiple tools reliably.\n \u2022 Plug-and-play: multiple Python functions exposed on the same MCP server.\n \u2022 Reduce development time: no custom wrappers or middleware needed.\n \u2022 Built-in reliability: input/output validation and error handling included.<p>Polymcp makes Python functions immediately usable by AI agents, standardizing integration across enterprise software.<p>Repo: <a href=\"https://github.com/poly-mcp/Polymcp\" rel=\"nofollow\">https://github.com/poly-mcp/Polymcp</a></p>\n<hr />\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46746700\">https://news.ycombinator.com/item?id=46746700</a></p>\n<p>Points: 5</p>\n<p># Comments: 0</p>",
      "author": "justvugg",
      "published_date": "2026-01-24T19:27:58+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 224,
      "reading_time": 1,
      "created_at": "2026-01-24T21:19:36.301362+00:00",
      "updated_at": "2026-01-24T21:19:36.301364+00:00"
    },
    {
      "id": "1c7eab55c441d6f48946b3c764c12eb4",
      "url": "https://m24tom.com/bye-bye-gmail/show",
      "title": "Bye Bye Gmail",
      "content": "<p>Article URL: <a href=\"https://m24tom.com/bye-bye-gmail/show\">https://m24tom.com/bye-bye-gmail/show</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46746946\">https://news.ycombinator.com/item?id=46746946</a></p>\n<p>Points: 42</p>\n<p># Comments: 20</p>",
      "author": "tklenke",
      "published_date": "2026-01-24T19:44:52+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2026-01-24T21:19:36.301269+00:00",
      "updated_at": "2026-01-24T21:19:36.301271+00:00"
    },
    {
      "id": "4c901924233fc6cdde6d812dc5e0dcff",
      "url": "https://github.com/hissain/jscipy",
      "title": "Show HN: JSciPy \u2013 SciPy-inspired signal processing library for Java and Android",
      "content": "<p>jSciPy is an open-source Java signal processing and scientific computing library inspired by SciPy.<p>It focuses on FFT, filters, PSD, STFT, DCT and Android compatibility, aiming to fill the gap for DSP-heavy workloads on JVM and Android.</p>\n<hr />\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46747351\">https://news.ycombinator.com/item?id=46747351</a></p>\n<p>Points: 3</p>\n<p># Comments: 0</p>",
      "author": "hissain",
      "published_date": "2026-01-24T20:31:41+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 47,
      "reading_time": 1,
      "created_at": "2026-01-24T21:19:36.301210+00:00",
      "updated_at": "2026-01-24T21:19:36.301212+00:00"
    },
    {
      "id": "9eebf62669c90dcbaa4e008159f45867",
      "url": "https://micahcantor.com/blog/bluesky-comment-section.html",
      "title": "I added a Bluesky comment section to my blog",
      "content": "<p>Article URL: <a href=\"https://micahcantor.com/blog/bluesky-comment-section.html\">https://micahcantor.com/blog/bluesky-comment-section.html</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46747366\">https://news.ycombinator.com/item?id=46747366</a></p>\n<p>Points: 39</p>\n<p># Comments: 3</p>",
      "author": "hydroxideOH-",
      "published_date": "2026-01-24T20:33:40+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2026-01-24T21:19:36.301186+00:00",
      "updated_at": "2026-01-24T21:19:36.301188+00:00"
    },
    {
      "id": "34057d2cf16cc6a248c6c8b4cce339df",
      "url": "https://www.ycombinator.com/companies/gym-class-by-irl-studios/jobs/ywXHGBv-design-engineer-senior-staff-principal",
      "title": "First Design Engineer Hire \u2013 Build Games at Gym Class (YC W22)",
      "content": "<p>Article URL: <a href=\"https://www.ycombinator.com/companies/gym-class-by-irl-studios/jobs/ywXHGBv-design-engineer-senior-staff-principal\">https://www.ycombinator.com/companies/gym-class-by-irl-studios/jobs/ywXHGBv-design-engineer-senior-staff-principal</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46747625\">https://news.ycombinator.com/item?id=46747625</a></p>\n<p>Points: 0</p>\n<p># Comments: 0</p>",
      "author": "hackerews",
      "published_date": "2026-01-24T21:01:02+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2026-01-24T21:19:36.301156+00:00",
      "updated_at": "2026-01-24T21:19:36.301164+00:00"
    },
    {
      "id": "961067587112d5e2f4f1370110478f71",
      "url": "https://www.sciencedirect.com/science/article/pii/S0006899326000193?dgcid=rss_sd_all",
      "title": "Aperiodic slope reflects glutamatergic tone in the human brain",
      "content": "<p>Publication date: 1 March 2026</p><p><b>Source:</b> Brain Research, Volume 1874</p><p>Author(s): Aislin A. Sheldon, Hannah R. Moser, Kamar S. Abdullahi, Karly D. Allison, Carter B. Mulder, Samantha A. Montoya, Scott R. Sponheim, Ma\u0142gorzata Marja\u0144ska, Michael-Paul Schallmo</p>",
      "author": "",
      "published_date": null,
      "source": "Brain Research",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 34,
      "reading_time": 1,
      "created_at": "2026-01-24T20:44:28.077464+00:00",
      "updated_at": "2026-01-24T20:44:28.077466+00:00"
    },
    {
      "id": "0203471c36a8b7f13cdf8929ea42e582",
      "url": "https://www.nature.com/articles/s41593-026-02203-5",
      "title": "Author Correction: Choroid plexus apocrine secretion shapes CSF proteome during mouse brain development",
      "content": "<p>Nature Neuroscience, Published online: 15 January 2026; <a href=\"https://www.nature.com/articles/s41593-026-02203-5\">doi:10.1038/s41593-026-02203-5</a></p>Author Correction: Choroid plexus apocrine secretion shapes CSF proteome during mouse brain development",
      "author": "Maria K. Lehtinen",
      "published_date": "2026-01-15T00:00:00+00:00",
      "source": "Nature Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 21,
      "reading_time": 1,
      "created_at": "2026-01-24T20:44:19.707304+00:00",
      "updated_at": "2026-01-24T20:44:19.707306+00:00"
    },
    {
      "id": "01a0c9001a6aac267cb0072bda62db43",
      "url": "http://doi.org/10.1037/pmu0000303",
      "title": "Implicit learning of melodic structure: A role for pitch?",
      "content": "Growing evidence suggests that pitch influences musical processing, with melodic processing being enhanced in higher pitch ranges (e.g., Fujioka et al., 2005) and rhythmic processing being enhanced in lower pitches, and these effects may have a basis in elementary properties of the auditory system (e.g., Hove et al., 2014). As such, pitch may constitute a fundamental constraint on the mechanisms that underpin musical learning. One such mechanism is implicit learning: the ability to learn from mere exposure without intention and without a clear awareness of what has been learned. The present study examined whether the high pitch effects that enhance melodic processing extend to implicit learning of melodic structure as well. In an artificial melodic grammar experiment, it was found that participants learned melodic structure better when instantiated in a lower rather than a higher pitch range. We propose that hearing melodies in lower pitch ranges attracts more attention, because melodic information is usually instantiated in higher pitches, and lower pitch melodies may cause attention to shift leading to more learning. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2024-01-22T00:00:00+00:00",
      "source": "Psychomusicology",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 180,
      "reading_time": 1,
      "created_at": "2026-01-24T20:43:53.298075+00:00",
      "updated_at": "2026-01-24T20:43:53.298077+00:00"
    },
    {
      "id": "f5d48b717c919893f96492998ce36e60",
      "url": "http://doi.org/10.1037/cns0000368",
      "title": "Autonomous sensory meridian response (ASMR): A PRISMA-guided systematic review.",
      "content": "The present PRISMA-guided article systematically reviews the current state of research on the autonomous sensory meridian response (ASMR). A systematic literature search was conducted in Pubmed, SCOPUS, and Web of Science (last search: March 2022) selecting all studies that conducted quantitative scientific research on the ASMR phenomenon. Fifty-four studies focusing on ASMR were retrieved (total participant number: <em>n</em> = 11,140). ASMR can be linked to several mental health-related variables (e.g., improved mood) and personality traits (e.g., neuroticism). On the neurobiological level, ASMR has been associated with altered electrophysiological response patterns (tentatively suggesting \u03b4 wave decreases), activation of specific brain areas (particularly the anterior cingulate gyrus and movement-related regions), and atypical functional connectivity patterns as well as physiological changes such as heart rate reduction. Future studies should evaluate the link between ASMR and additional psychological constructs, reveal more specific neurobiological outcome patterns and conduct long-term ASMR intervention studies. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2023-11-02T00:00:00+00:00",
      "source": "Clinical Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 156,
      "reading_time": 1,
      "created_at": "2026-01-24T20:43:51.903803+00:00",
      "updated_at": "2026-01-24T20:43:51.903804+00:00"
    },
    {
      "id": "2632ffdea823fa8469a9429df37c1901",
      "url": "http://doi.org/10.1037/cns0000352",
      "title": "Social bodies: Preliminary evidence that awareness of embodied emotions is associated with recognition of emotions in the bodily cues of others.",
      "content": "We experience and express emotions via our bodies, and we are also able to infer the emotional states of others by observing their movements and postures. The ability to extract affective bodily cues in social contexts may be achieved via internal simulation, which is closely associated with experience and awareness of emotions in one\u2019s own body. Here, we hypothesized that reports of one\u2019s own bodily experiences of emotions would be associated with the ability to infer other people\u2019s emotions from their bodily signals. Healthy individuals (<em>n</em> = 106) participated in two tasks. An emotional gait perception task was used to test the ability to extract emotional cues from other people\u2019s body movements. Subjective bodily experience of emotions was visualized with a computerized mapping tool, which required participants to localize sensations on the body corresponding to specific emotions. Participants reported specific locations of body sensations for different emotions. Emotional gait perception accuracy was positively associated with participants\u2019 reported intensity for bodily experiences of happiness and anger and with their tendency to report body mapping patterns similar to prototypes established in a much larger sample. Results suggest that awareness of emotions in one\u2019s own body is related to our ability to perceive emotions in others. Implications for future work on the role of embodiment in social cognition and psychiatric disorders are discussed. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2023-03-06T00:00:00+00:00",
      "source": "Clinical Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 229,
      "reading_time": 1,
      "created_at": "2026-01-24T20:43:51.903770+00:00",
      "updated_at": "2026-01-24T20:43:51.903771+00:00"
    },
    {
      "id": "db4bb0caf85728fb106445f8d41cccdc",
      "url": "https://www.reddit.com/r/Python/comments/1qlxsy9/i_built_a_cli_to_make_reverseengineering_apis/",
      "title": "I built a CLI to make reverse-engineering APIs easier",
      "content": "<!-- SC_OFF --><div class=\"md\"><p><strong>What My Project Does</strong></p> <p>I\u2019m working on <strong>reverse-api-engineer</strong>, a tool that helps you generate Python API clients just by using a website normally.<br /> It\u2019s a CLI built in Python and it uses the Python Claude Agent SDK for the agent part.</p> <p>The idea is simple:</p> <ul> <li>You browse a web app</li> <li>The tool captures the network traffic (HAR)</li> <li>The agent analyzes the HAR</li> <li>It generates a usable Python client</li> </ul> <p>It\u2019s useful when there is no official API, when the API is undocumented, or when you just want to run quick experiments.<br /> There are multiple modes: you can run it manually, let the agent handle the full process, or generate Playwright scripts for automation.</p> <p>I originally built it to automate undocumented public APIs for myself. I kept doing the same reverse-engineering work again and again for my map project, so I decided to turn it into a tool.</p> <p>It already helped me build a dataset of around 750k job listings (I\u2019m still adding more sources).<br /> If you\u2019re interested let me know.</p> <p>Repo:<br /> <a href=\"https://github.com/kalil0321/reverse-api-engineer\">https://github.com/kalil0321/reverse-api-engineer</a></p> <p><strong>Target Audience</strong></p> <p>Developers who:</p> <ul> <li>Deal with undocumented or poorly documented APIs</li> <li>Do scraping, automation, or data collection</li> <li>Want to prototype fast without spending hours reversing endpoints</li> </ul> <p>It\u2019s not meant to be a polished production SDK generator yet.<br /> Right now it\u2019s more of a power tool for experimentation, internal projects, and automation-heavy workflows.</p> <p><strong>Comparison</strong></p> <p>Compared to classic reverse-engineering workflows:</p> <ul> <li>You don\u2019t manually inspect every request</li> <li>You don\u2019t rewrite clients from scratch each time</li> <li>The agent does most of the boring pattern recognition</li> </ul> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Own_Relationship9794\"> /u/Own_Relationship9794 </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1qlxsy9/i_built_a_cli_to_make_reverseengineering_apis/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1qlxsy9/i_built_a_cli_to_make_reverseengineering_apis/\">[comments]</a></span>",
      "author": "/u/Own_Relationship9794",
      "published_date": "2026-01-24T20:24:09+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 285,
      "reading_time": 1,
      "created_at": "2026-01-24T20:43:44.499304+00:00",
      "updated_at": "2026-01-24T20:43:44.499306+00:00"
    },
    {
      "id": "828df48a2bdd4274c3fc72258fed2970",
      "url": "https://antoine.vandecreme.net/blog/rust-closures/",
      "title": "Understanding Rust Closures",
      "content": "<p>Article URL: <a href=\"https://antoine.vandecreme.net/blog/rust-closures/\">https://antoine.vandecreme.net/blog/rust-closures/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46746266\">https://news.ycombinator.com/item?id=46746266</a></p>\n<p>Points: 4</p>\n<p># Comments: 0</p>",
      "author": "avandecreme",
      "published_date": "2026-01-24T18:42:13+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2026-01-24T20:43:41.821018+00:00",
      "updated_at": "2026-01-24T20:43:41.821020+00:00"
    },
    {
      "id": "0d949b6b05239c860661fc301d413956",
      "url": "https://jeisey.github.io/stormwatch/",
      "title": "Show HN: StormWatch \u2013 Weather emergency dashboard with prep checklists",
      "content": "<p>Basically was getting annoyed jumping between 5 different sites during this winter storm season, so I built \"StormWatch\". It's a no-fuss, mobile-friendly webpage (dashboard) that shows all the stuff I was looking for, but in one simple UI.<p>Features:<p>- Real-time NWS alerts with safety tips\n- Snow/ice/precip accumulation forecasts (+wind)\n- Dynamic preparation checklists based on your alerts\n- Supply calculator for your household size\n- Regional weather news<p>It's free, no login required, works on any device. Just enter your ZIP.<p><a href=\"https://jeisey.github.io/stormwatch/\" rel=\"nofollow\">https://jeisey.github.io/stormwatch/</a><p>Uses NWS and GDELT APIs and open source. Feel free to fork and modify however you'd like.<p>For builders:\n- Used an API-testing agent to verify all endpoints, response patterns, types, and rate limits\n- Used a scope & validation agent to keep the slices simple, focused, and tested\n- VS-code Copilot (Sonnet 4 for dev agents + Opus 4.5 for scope and validation)</p>\n<hr />\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46746900\">https://news.ycombinator.com/item?id=46746900</a></p>\n<p>Points: 3</p>\n<p># Comments: 0</p>",
      "author": "lotusxblack",
      "published_date": "2026-01-24T19:40:52+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 155,
      "reading_time": 1,
      "created_at": "2026-01-24T20:43:41.820913+00:00",
      "updated_at": "2026-01-24T20:43:41.820915+00:00"
    },
    {
      "id": "a108d8d4b302c7d2f8f62ee6441deaec",
      "url": "https://www.nature.com/articles/s41593-025-02196-7",
      "title": "Investigating the methodological foundation of lesion network mapping",
      "content": "<p>Nature Neuroscience, Published online: 15 January 2026; <a href=\"https://www.nature.com/articles/s41593-025-02196-7\">doi:10.1038/s41593-025-02196-7</a></p>The lesion network mapping method links diverse brain lesions to similar functional brain networks, reflecting general brain organization rather than disorder-specific circuits.",
      "author": "Luca Cocchi",
      "published_date": "2026-01-15T00:00:00+00:00",
      "source": "Nature Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 30,
      "reading_time": 1,
      "created_at": "2026-01-24T20:24:03.632677+00:00",
      "updated_at": "2026-01-24T20:24:03.632678+00:00"
    },
    {
      "id": "e09b50cfba90dbb8bd82df8b2ce9dd57",
      "url": "https://json-render.dev/",
      "title": "JSON-render: LLM-based JSON-to-UI tool",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46746570\">Comments</a>",
      "author": "",
      "published_date": "2026-01-24T19:12:56+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-24T20:23:25.556197+00:00",
      "updated_at": "2026-01-24T20:23:25.556199+00:00"
    }
  ]
}