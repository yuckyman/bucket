{
  "last_updated": "2026-01-05T05:03:21.918912+00:00",
  "count": 20,
  "articles": [
    {
      "id": "e28c19416a3e921c09c1ca4ca3c1b2a2",
      "url": "https://arxiv.org/abs/2601.00097",
      "title": "The Agentic Leash: Extracting Causal Feedback Fuzzy Cognitive Maps with LLMs",
      "content": "arXiv:2601.00097v1 Announce Type: cross \nAbstract: We design a large-language-model (LLM) agent that extracts causal feedback fuzzy cognitive maps (FCMs) from raw text. The causal learning or extraction process is agentic both because of the LLM's semi-autonomy and because ultimately the FCM dynamical system's equilibria drive the LLM agents to fetch and process causal text. The fetched text can in principle modify the adaptive FCM causal structure and so modify the source of its quasi-autonomy--its equilibrium limit cycles and fixed-point attractors. This bidirectional process endows the evolving FCM dynamical system with a degree of autonomy while still staying on its agentic leash. We show in particular that a sequence of three finely tuned system instructions guide an LLM agent as it systematically extracts key nouns and noun phrases from text, as it extracts FCM concept nodes from among those nouns and noun phrases, and then as it extracts or infers partial or fuzzy causal edges between those FCM nodes. We test this FCM generation on a recent essay about the promise of AI from the late diplomat and political theorist Henry Kissinger and his colleagues. This three-step process produced FCM dynamical systems that converged to the same equilibrium limit cycles as did the human-generated FCMs even though the human-generated FCM differed in the number of nodes and edges. A final FCM mixed generated FCMs from separate Gemini and ChatGPT LLM agents. The mixed FCM absorbed the equilibria of its dominant mixture component but also created new equilibria of its own to better approximate the underlying causal dynamical system.",
      "author": "Akash Kumar Panda, Olaoluwa Adigun, Bart Kosko",
      "published_date": "2026-01-05T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 257,
      "reading_time": 1,
      "created_at": "2026-01-05T05:03:01.553454+00:00",
      "updated_at": "2026-01-05T05:03:01.553456+00:00"
    },
    {
      "id": "232dc90ee3b86dcd6a39a0ca97b97f4a",
      "url": "https://arxiv.org/abs/2601.00765",
      "title": "The Effect of Transparency on Students' Perceptions of AI Graders",
      "content": "arXiv:2601.00765v1 Announce Type: new \nAbstract: The development of effective autograders is key for scaling assessment and feedback. While NLP based autograding systems for open-ended response questions have been found to be beneficial for providing immediate feedback, autograders are not always liked, understood, or trusted by students. Our research tested the effect of transparency on students' attitudes towards autograders. Transparent autograders increased students' perceptions of autograder accuracy and willingness to discuss autograders in survey comments, but did not improve other related attitudes -- such as willingness to be graded by them on a test -- relative to the control without transparency. However, this lack of impact may be due to higher measured student trust towards autograders in this study than in prior work in the field. We briefly discuss possible reasons for this trend.",
      "author": "Joslyn Orgill, Andra Rice, Max Fowler, Seth Poulsen",
      "published_date": "2026-01-05T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 133,
      "reading_time": 1,
      "created_at": "2026-01-05T05:03:01.553418+00:00",
      "updated_at": "2026-01-05T05:03:01.553419+00:00"
    },
    {
      "id": "d85bd3bfd962ef312a7187529af38944",
      "url": "https://arxiv.org/abs/2601.00670",
      "title": "Wave2Word: A Multimodal Transformer Framework for Joint EEG-Text Alignment and Multi-Task Representation Learning in Neurocritical Care",
      "content": "arXiv:2601.00670v1 Announce Type: new \nAbstract: Continuous electroencephalography (EEG) is routinely used in neurocritical care to monitor seizures and other harmful brain activity, including rhythmic and periodic patterns that are clinically significant. Although deep learning methods have achieved high accuracy in seizure detection, most existing approaches remain seizure-centric, rely on discrete-label supervision, and are primarily evaluated using accuracy-based metrics. A central limitation of current EEG modeling practice is the weak correspondence between learned representations and how EEG findings are interpreted and summarized in clinical workflows. Harmful EEG activity exhibits overlapping patterns, graded expert agreement, and temporal persistence, which are not well captured by classification objectives alone. This work proposes a multimodal EEG representation learning framework that integrates signal-domain modeling with structured clinical language supervision. First, raw EEG is transformed into a longitudinal bipolar montage and time-frequency representations. Second, dual transformer-based encoders model complementary temporal and frequency-centric dependencies and are fused using an adaptive gating mechanism. Third, EEG embeddings are aligned with structured expert consensus descriptions through a contrastive objective. Finally, an EEG-conditioned text reconstruction loss is introduced as a representation-level constraint alongside standard classification loss. Experimental evaluation using a controlled train-validation-test split achieves a six-class test accuracy of 0.9797. Ablation analyses show that removing contrastive alignment reduces cross-modal retrieval performance from Recall@10 of 0.3390 to 0.0045, despite minimal change in classification accuracy. These findings demonstrate that discriminative accuracy does not reliably reflect representation quality for clinically meaningful EEG modeling.",
      "author": "Argha Kamal Samanta, Deepak Mewada, Monalisa Sarma, Debasis Samanta",
      "published_date": "2026-01-05T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 238,
      "reading_time": 1,
      "created_at": "2026-01-05T05:03:01.553390+00:00",
      "updated_at": "2026-01-05T05:03:01.553392+00:00"
    },
    {
      "id": "9c7477e92f7159b3e45ada25832da84e",
      "url": "https://arxiv.org/abs/2601.00592",
      "title": "Evaluating Web Accessibility and Usability in Bangladesh: A Comparative Analysis of Government and Non-Government Websites",
      "content": "arXiv:2601.00592v1 Announce Type: new \nAbstract: Ensuring digital accessibility is essential for inclusive access to online services. However, many government and non-government websites that provide critical services - such as education, healthcare, and public administration - continue to exhibit significant accessibility and usability barriers. This study evaluates the accessibility of Bangladeshi government and non-government websites under WCAG~2.2 by combining automated accessibility assessments with user-reported feedback. A total of 212 websites were analyzed using multiple automated tools, complemented by a survey of 103 users to capture real-world usability, accessibility, and security experiences. The results reveal substantial disparities between government and non-government websites, highlighting persistent issues related to navigation complexity, interaction cost, visual readability, accessibility feature adoption, and authentication mechanisms. While non-government websites generally demonstrate better usability and functional performance, accessibility support remains inconsistent across both categories. The findings underscore the need for regular accessibility audits, user-centered design practices, and policy-driven interventions to improve digital inclusivity and ensure equitable access to online services for diverse user populations.",
      "author": "Sanjida Islam Era, Ishika Tarin Ime, A. B. M. Alim Al Islam",
      "published_date": "2026-01-05T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 164,
      "reading_time": 1,
      "created_at": "2026-01-05T05:03:01.553355+00:00",
      "updated_at": "2026-01-05T05:03:01.553356+00:00"
    },
    {
      "id": "97e71d80c79d785b044feaa52e6f01ba",
      "url": "https://arxiv.org/abs/2601.00579",
      "title": "The AI Invisibility Effect: Understanding Human-AI Interaction When Users Don't Recognize Artificial Intelligence",
      "content": "arXiv:2601.00579v1 Announce Type: new \nAbstract: The fast integration of artificial intelligence into mobile applications has completely changed the digital landscape; however, the impact of this change on user perception of AI features remains poorly understood. This large-scale analysis examined 1,484,633 mobile application reviews across 422 applications (200 AI-featuring, 222 control) from iOS App Store and Google Play Store. By employing sentiment classification, topic modeling, and concern-benefit categorization, we identified a major disconnect: only 11.9% of reviews mentioned AI, even though 47.4% of applications featured AI capabilities. AI-featuring applications received significantly lower ratings than traditional applications (d = 0.40); however, hierarchical regression revealed a hidden pattern - the negative relationship reversed after controlling for AI mentions and review characteristics (b = 0.405, p < .001). Privacy dominated user concerns (34.8% of concern-expressing reviews), while efficiency represented the primary benefit (42.3%). Effects varied greatly by category, from positive for Assistant applications (d = 0.55) to negative for Entertainment (d = -0.23). These findings suggest that AI features often operate below user awareness thresholds, and it is the explicit recognition of AI, rather than its mere presence, that drives negative evaluations. This challenges basic assumptions about technology acceptance in AI systems.",
      "author": "Obada Kraishan",
      "published_date": "2026-01-05T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 198,
      "reading_time": 1,
      "created_at": "2026-01-05T05:03:01.553324+00:00",
      "updated_at": "2026-01-05T05:03:01.553326+00:00"
    },
    {
      "id": "f76dc15d74c3d93305fc447c122c5d75",
      "url": "https://arxiv.org/abs/2601.00570",
      "title": "User Perceptions of an LLM-Based Chatbot for Cognitive Reappraisal of Stress: Feasibility Study",
      "content": "arXiv:2601.00570v1 Announce Type: new \nAbstract: Cognitive reappraisal is a well-studied emotion regulation strategy that helps individuals reinterpret stressful situations to reduce their impact. Many digital mental health tools struggle to support this process because rigid scripts fail to accommodate how users naturally describe stressors. This study examined the feasibility of an LLM-based single-session intervention (SSI) for workplace stress reappraisal. We assessed short-term changes in stress-related outcomes and examined design tensions during use. We conducted a feasibility study with 100 employees at a large technology company who completed a structured cognitive reappraisal session delivered by a GPT-4o-based chatbot. Pre-post measures included perceived stress intensity, stress mindset, perceived demand, and perceived resources. These outcomes were analyzed using paired Wilcoxon signed-rank tests with correction for multiple comparisons. We also examined sentiment and stress trajectories across conversation quartiles using two RoBERTa-based classifiers and an LLM-based stress rater. Open-ended responses were analyzed using thematic analysis. Results showed significant reductions in perceived stress intensity and significant improvements in stress mindset. Changes in perceived resources and perceived demand trended in expected directions but were not statistically significant. Automated analyses indicated consistent declines in negative sentiment and stress over the course of the interaction. Qualitative findings suggested that participants valued the structured prompts for organizing thoughts, gaining perspective, and feeling acknowledged. Participants also reported tensions around scriptedness, preferred interaction length, and reactions to AI-driven empathy. These findings highlight both the promise and the design constraints of integrating LLMs into DMH interventions for workplace settings.",
      "author": "Ananya Bhattacharjee, Jina Suh, Mohit Chandra, Javier Hernandez",
      "published_date": "2026-01-05T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 246,
      "reading_time": 1,
      "created_at": "2026-01-05T05:03:01.553292+00:00",
      "updated_at": "2026-01-05T05:03:01.553294+00:00"
    },
    {
      "id": "07c599ae35e322c7ce5b23c347630711",
      "url": "https://arxiv.org/abs/2601.00382",
      "title": "Unseen Risks of Clinical Speech-to-Text Systems: Transparency, Privacy, and Reliability Challenges in AI-Driven Documentation",
      "content": "arXiv:2601.00382v1 Announce Type: new \nAbstract: AI-driven speech-to-text (STT) documentation systems are increasingly adopted in clinical settings to reduce documentation burden and improve workflow efficiency. However, their rapid deployment has outpaced understanding of the associated socio-technical risks, including transparency, reliability, patient autonomy, workflow alignment, and organizational governance. A clearer analysis of these risks is needed to support safe and equitable integration into healthcare practice. This study synthesizes interdisciplinary evidence from technical performance research, regulatory and ethical standards, clinical workflow analyses, and organizational policy guidance. The synthesis was used to develop a multi-layered socio-technical conceptual framework for evaluating and governing STT systems. Findings show that STT systems operate within tightly coupled socio-technical environments in which model performance, clinician oversight, patient rights, workflow design, and institutional governance are interdependent. The study offers a structured socio-technical governance framework and an implementation roadmap that outlines readiness assessment, vendor evaluation, pilot deployment, clinician training, ongoing monitoring, and iterative improvement. The framework emphasizes safeguards that protect patient autonomy, documentation integrity, and institutional trust while enabling the efficient and beneficial use of STT technologies. This work provides actionable guidance for healthcare organizations seeking to adopt STT systems responsibly and equitably.",
      "author": "Nelly Elsayed",
      "published_date": "2026-01-05T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 192,
      "reading_time": 1,
      "created_at": "2026-01-05T05:03:01.553257+00:00",
      "updated_at": "2026-01-05T05:03:01.553258+00:00"
    },
    {
      "id": "4021a4d57f0eef4489871beaf405670c",
      "url": "https://arxiv.org/abs/2601.00333",
      "title": "Effects of Limited Field of View on Musical Collaboration Experience with Avatars in Extended Reality",
      "content": "arXiv:2601.00333v1 Announce Type: new \nAbstract: During musical collaboration, visual cues are essential for communication between musicians. Extended Reality (XR) applications, often used with head-mounted displays like Augmented Reality (AR) glasses, can limit the field of view (FOV) of players. We conducted a study to investigate the effects of limited FOV on co-presence, gesture recognition, overall enjoyment, and reaction time.\n  Initially, we observed experienced musicians collaborating informally with and without visual occlusion, noting that collaboration suffered with limited FOV. We then conducted a within-subjects study with 19 participants, comparing an unrestricted FOV holographic setup called HoloJam to Nreal AR glasses with a 52$^{\\circ}$ limited FOV. In the AR setup, we tested two conditions: standard AR with a 52$^{\\circ}$ FOV and a modified AR notification system called Mini Musicians.\n  Results showed that HoloJam provided higher co-presence, quicker gesture recognition, and greater enjoyment. The Mini Musicians application reduced reaction time and maintained enjoyment compared to the standard AR setup. We conclude that limited FOV impacts musical collaboration, but notifications can improve reaction time and should be considered in future XR music collaborations.",
      "author": "Suibi Che-Chuan Weng, Torin Hopkins, Shih-Yu Ma, Amy Banic, Ellen Yi-Luen Do",
      "published_date": "2026-01-05T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 179,
      "reading_time": 1,
      "created_at": "2026-01-05T05:03:01.553224+00:00",
      "updated_at": "2026-01-05T05:03:01.553226+00:00"
    },
    {
      "id": "defdd552a242075eb0feca3638688a0e",
      "url": "https://arxiv.org/abs/2601.00326",
      "title": "MR-DAW: Towards Collaborative Digital Audio Workstations in Mixed Reality",
      "content": "arXiv:2601.00326v1 Announce Type: new \nAbstract: Digital Audio Workstations (DAWs) are central to modern music production but often encumber the musician's workflow, tethering them to a desk and hindering natural interaction with their instrument. Furthermore, effective remote collaboration remains a significant challenge, with existing solutions hampered by network latency and asynchronous file sharing. This paper investigates the potential of Mixed Reality (MR) to overcome these barriers, creating an intuitive environment for real-time, remote musical collaboration. We employ qualitative and speculative design techniques to better understand: 1) how players currently use DAWs, and 2) to imagine a speculative future of collaborative MR-DAWs. To facilitate this discussion, we developed and evaluated the usability of a design probe, MR-DAW. An MR system enabling multiple, geographically dispersed users to control a single, shared DAW instance while moving freely in their local spaces. Our networked system enables each remote musician to use a physical foot pedal for collaborative looping, merging a familiar, hands-free interaction with a shared virtual session. Based on interviews and system evaluations with 20 musicians, we analyze current practices, report on the user experience with our MR system, and speculate on the future of musical collaboration in MR. Our results highlight the affordances of MR for unencumbered musical interaction and provide a speculative outlook on the future of remote collaborative DAWs in the Musical Metaverse.",
      "author": "Torin Hopkins, Shih-Yu Ma, Suibi Che-Chuan Weng, Ming-Yuan Pai, Ellen Yi-Luen Do, Luca Turchet",
      "published_date": "2026-01-05T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 222,
      "reading_time": 1,
      "created_at": "2026-01-05T05:03:01.553191+00:00",
      "updated_at": "2026-01-05T05:03:01.553193+00:00"
    },
    {
      "id": "635d53275d4e738e2d225e1e143c32d5",
      "url": "https://arxiv.org/abs/2601.00001",
      "title": "Augmented Reality Indoor Wayfinding in Hospital Environments An Empirical Study on Navigation Efficiency, User Experience, and Cognitive Load",
      "content": "arXiv:2601.00001v1 Announce Type: new \nAbstract: Hospitals are among the most cognitively demanding indoor environments, especially for patients and visitors unfamiliar with their layout. This study investigates the effectiveness of an augmented reality (AR)-based handheld navigation system compared to traditional paper maps in a large hospital setting. Through a mixed-methods experiment with 32 participants, we measured navigation performance, cognitive workload (NASA-TLX), situational anxiety (STAI-State), spatial behavior, and user satisfaction. Results show that AR users completed navigation tasks significantly faster, made fewer errors, and reported lower anxiety and workload. However, paper map users demonstrated stronger spatial memory in sketch-based recall tasks, highlighting a trade-off between real-time efficiency and long-term spatial learning. We discuss implications for inclusive AR design, spatial cognition, and healthcare accessibility, offering actionable design strategies for adaptive indoor navigation tools.",
      "author": "Kai Liu, Michelle L. Aebersold, Mark Lindquist, Haoting Gao",
      "published_date": "2026-01-05T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 130,
      "reading_time": 1,
      "created_at": "2026-01-05T05:03:01.553146+00:00",
      "updated_at": "2026-01-05T05:03:01.553150+00:00"
    },
    {
      "id": "2d1348e4d7ee72fa84177881fa3ce975",
      "url": "https://arxiv.org/abs/2501.04706",
      "title": "Associations between iron and mean kurtosis in iron-rich grey matter nuclei in aging",
      "content": "arXiv:2501.04706v3 Announce Type: replace-cross \nAbstract: Elevated kurtosis values have been observed in subcortical grey matter structures of patients with neurodegenerative diseases. Here we tested whether these elevated values are related to iron content, which generate magnetic fields that add to the diffusion encoding gradients. Multi-shell diffusion and multi-echo gradient echo acquisitions were used to derive mean kurtosis and iron measures (R2* and magnetic susceptibility), respectively, in subcortical grey matter nuclei and white matter tracts in a discovery cohort (110 older and 63 younger adults) and replication cohort (72 healthy older adults). Iron-rich grey matter regions exhibited higher mean kurtosis, R2*, and magnetic susceptibility and white matter regions had lower mean kurtosis in the older adult group. In both cohorts, mean kurtosis was significantly correlated with R2* and magnetic susceptibility in iron-rich grey matter nuclei. No association was seen between signal-to-noise ratio and mean kurtosis in any grey matter region, indicating that the increase in mean kurtosis was not due to reduced signal-to-noise. Finally, a phantom experiment found higher mean kurtosis as iron concentrations increased. Our findings indicate that kurtosis is associated with iron-sensitive metrics in iron-rich grey matter structures, suggesting that kurtosis may be sensitive to iron deposits.",
      "author": "Jason Langley, Kitzia Solis, Vala Masjedizadeh, Murphy Shao, Ilana Bennett, Xiaoping P. Hu",
      "published_date": "2026-01-05T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 198,
      "reading_time": 1,
      "created_at": "2026-01-05T05:03:00.467387+00:00",
      "updated_at": "2026-01-05T05:03:00.467388+00:00"
    },
    {
      "id": "7b18ebcb58248c5f83cf68779d0b7def",
      "url": "https://arxiv.org/abs/2512.18585",
      "title": "Deep Teleportation: Quantum Simulation of Conscious Report in Attentional Blink",
      "content": "arXiv:2512.18585v2 Announce Type: replace \nAbstract: Recent quantum models of cognition have successfully simulated several interesting effects in human experimental data, from vision to reasoning and recently even consciousness. The latter case, consciousness has been a quite challenging phenomenon to model, and most efforts have been through abstract mathematical quantum methods, mainly focused on conceptual issues. Classical (non-quantum) models of consciousness-related experiments exist, but they generally fail to align well with human data. We developed a straightforward quantum model to simulate conscious reporting of seeing or missing competing stimuli within the famous attentional blink paradigm. In an attentional blink task, a target stimulus (T2) that appears after a previous one (T1) can be consciously reported if the delay between presenting them is short enough (called lag 1), otherwise it can be rendered invisible during the so-called refractory period of attention (lags 2 to 6 and even longer). For modeling this phenomenon, we employed a three-qubit entanglement ansatz circuit in the form of a deep teleportation channel instead of the well-known EPR channel. While reporting the competing stimuli was supposed to be the classical measurement outcomes, the effect of distractor stimuli (i.e., masks, if any) was encoded simply as random angle rotations. The simulation outcome for different states was measured, and the classical outcome probabilities were further used as inputs to a simple linear neural network. The result revealed a non-linear, alternating state pattern that closely mirrors human responses in conscious stimuli reporting. The main result was a successful simulation of Lag 1 sparing, lag 7 divergence, and masking effect through probabilistic outcome of measurement in different conditions.",
      "author": "Ahmad Sohrabi",
      "published_date": "2026-01-05T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 266,
      "reading_time": 1,
      "created_at": "2026-01-05T05:03:00.467353+00:00",
      "updated_at": "2026-01-05T05:03:00.467355+00:00"
    },
    {
      "id": "a6317b1de27be55c18fc5db45d32308c",
      "url": "https://arxiv.org/abs/2510.23321",
      "title": "Model-Behavior Alignment under Flexible Evaluation: When the Best-Fitting Model Isn't the Right One",
      "content": "arXiv:2510.23321v2 Announce Type: replace \nAbstract: Linearly transforming stimulus representations of deep neural networks yields high-performing models of behavioral and neural responses to complex stimuli. But does the test accuracy of such predictions identify genuine representational alignment? We addressed this question through a large-scale model-recovery study. Twenty diverse vision models were linearly aligned to 4.5 million behavioral judgments from the THINGS odd-one-out dataset and calibrated to reproduce human response variability. For each model in turn, we sampled synthetic responses from its probabilistic predictions, fitted all candidate models to the synthetic data, and tested whether the data-generating model would re-emerge as the best predictor of the simulated data. Model recovery accuracy improved with training-set size but plateaued below 80%, even at millions of simulated trials. Regression analyses linked misidentification primarily to shifts in representational geometry induced by the linear transformation, as well as to the effective dimensionality of the transformed features. These findings demonstrate that, even with massive behavioral data, overly flexible alignment metrics may fail to guide us toward artificial representations that are genuinely more human-aligned. Model comparison experiments must be designed to balance the trade-off between predictive accuracy and identifiability-ensuring that the best-fitting model is also the right one.",
      "author": "Itamar Avitan, Tal Golan",
      "published_date": "2026-01-05T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 199,
      "reading_time": 1,
      "created_at": "2026-01-05T05:03:00.467311+00:00",
      "updated_at": "2026-01-05T05:03:00.467313+00:00"
    },
    {
      "id": "582cd4b48dfa58acff38f5d8e209ed1b",
      "url": "https://arxiv.org/abs/2601.00466",
      "title": "Rogue Variable Theory: A Quantum-Compatible Cognition Framework with a Rosetta Stone Alignment Algorithm",
      "content": "arXiv:2601.00466v1 Announce Type: new \nAbstract: Many of the most consequential dynamics in human cognition occur \\emph{before} events become explicit: before decisions are finalized, emotions are labeled, or meanings stabilize into narrative form. These pre-event states are characterized by ambiguity, contextual tension, and competing latent interpretations. Rogue Variable Theory (RVT) formalizes such states as \\emph{Rogue Variables}: structured, pre-event cognitive configurations that influence outcomes while remaining unresolved or incompatible with a system's current representational manifold. We present a quantum-consistent information-theoretic implementation of RVT based on a time-indexed \\emph{Mirrored Personal Graph} (MPG) embedded into a fixed graph Hilbert space, a normalized \\emph{Quantum MPG State} (QMS) constructed from node and edge metrics under context, Hamiltonian dynamics derived from graph couplings, and an error-weighted `rogue operator'' whose principal eigenvectors identify rogue factor directions and candidate Rogue Variable segments. We further introduce a \\emph{Rosetta Stone Layer} (RSL) that maps user-specific latent factor coordinates into a shared reference Hilbert space to enable cross-user comparison and aggregation without explicit node alignment. The framework is fully implementable on classical systems and does not assume physical quantum processes; \\emph{collapse} is interpreted as informational decoherence under interaction, often human clarification.",
      "author": "Jacek Ma{\\l}ecki, Alexander Mathiesen-Ohman",
      "published_date": "2026-01-05T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 189,
      "reading_time": 1,
      "created_at": "2026-01-05T05:03:00.467270+00:00",
      "updated_at": "2026-01-05T05:03:00.467274+00:00"
    },
    {
      "id": "badbdfb2f7df7ba55e4414ac596e385c",
      "url": "https://www.bbc.com/travel/article/20250417-the-baffling-purple-honey-found-only-in-north-carolina",
      "title": "The baffling purple honey found only in North Carolina",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46448356\">Comments</a>",
      "author": "",
      "published_date": "2025-12-31T21:06:16+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-05T05:02:13.967735+00:00",
      "updated_at": "2026-01-05T05:02:13.967736+00:00"
    },
    {
      "id": "cf4e625471494a5a69c73e91c1d777cd",
      "url": "https://consumer.drop.privacy.ca.gov/",
      "title": "California residents can now request all data brokers delete personal info",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46495220\">Comments</a>",
      "author": "",
      "published_date": "2026-01-05T04:00:38+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-05T05:02:13.967648+00:00",
      "updated_at": "2026-01-05T05:02:13.967652+00:00"
    },
    {
      "id": "cf4e625471494a5a69c73e91c1d777cd",
      "url": "https://consumer.drop.privacy.ca.gov/",
      "title": "California residents can now request all data brokers delete personal info",
      "content": "<p>Article URL: <a href=\"https://consumer.drop.privacy.ca.gov/\">https://consumer.drop.privacy.ca.gov/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46495220\">https://news.ycombinator.com/item?id=46495220</a></p>\n<p>Points: 77</p>\n<p># Comments: 12</p>",
      "author": "memalign",
      "published_date": "2026-01-05T04:00:38+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2026-01-05T05:02:12.580269+00:00",
      "updated_at": "2026-01-05T05:02:12.580279+00:00"
    },
    {
      "id": "449f636bf19a9861fc4e17d727b8b060",
      "url": "https://www.nature.com/articles/s44159-025-00516-z",
      "title": "The development of spatial perception with and without visual experience",
      "content": "",
      "author": "",
      "published_date": "2026-01-05T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2026-01-05T04:01:08.772008+00:00",
      "updated_at": "2026-01-05T04:53:34.181756+00:00",
      "metadata": {
        "processed_at": "2026-01-05T04:53:34.181766+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "268dc7d9e199fe37a63e69771335c93e",
      "url": "https://www.nature.com/articles/s41467-025-68218-x",
      "title": "Neuronal feedback loop of the suprachiasmatic nucleus generates robust circadian rhythms",
      "content": "",
      "author": "",
      "published_date": "2026-01-05T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2026-01-05T04:01:08.771984+00:00",
      "updated_at": "2026-01-05T04:53:34.181770+00:00",
      "metadata": {
        "processed_at": "2026-01-05T04:53:34.181772+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "13475a4a2dc3268439d30940634f498d",
      "url": "https://www.reddit.com/r/Python/comments/1q3oxk3/i_built_a_tui_process_manager_that_uses_a_local/",
      "title": "I built a TUI Process Manager that uses a Local LLM to classify and \"roast\" background processes",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>**What My Project Does** </p> <p>A terminal\u2011based TUI that monitors the process tree (parent, CPU, memory, I/O) and feeds this context to a local LLM (Llama 3 via Ollama or Groq). The model classifies each process as \u201cCritical\u201d or \u201cBloatware\u201d. For bloatware it prints a short roast and offers to kill it. BrainKernel (<a href=\"https://github.com/mprajyothreddy/brainkernel\">https://github.com/mprajyothreddy/brainkernel</a>) replaces the usual CPU % sorting with \u201cvibe\u2011based\u201d sorting, shows a live\u2011updating table while staying under 1 % CPU, and can auto\u2011suspend distraction apps (e.g., Steam, games) when they exceed a user\u2011defined threshold. </p> <p>**Target Audience** </p> <p>- Developers who are tired of manually hunting down unknown processes. </p> <p>- Linux and Windows users who want a task manager that explains what a process is doing. </p> <p>- Anyone experimenting with local edge AI integrated into the OS loop. </p> <p>**Comparison** </p> <p>- **vs htop/top:** htop is faster and lighter but assumes you know every process name. BrainKernel adds semantic classification, giving meaning to each PID. </p> <p>- **vs Windows Task Manager:** Windows\u2019 manager is GUI\u2011centric and lacks process explanations. BrainKernel is keyboard\u2011centric, can \u201croast\u201d bloatware for entertainment, and includes a focus/governor mode that can automatically suspend or kill distracting applications.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Turbulent-Spark6633\"> /u/Turbulent-Spark6633 </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1q3oxk3/i_built_a_tui_process_manager_that_uses_a_local/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1q3oxk3/i_built_a_tui_process_manager_that_uses_a_local/\">[comments]</a></span>",
      "author": "/u/Turbulent-Spark6633",
      "published_date": "2026-01-04T12:37:12+00:00",
      "source": "Reddit Python",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 217,
      "reading_time": 1,
      "created_at": "2026-01-05T04:00:32.753453+00:00",
      "updated_at": "2026-01-05T04:53:34.181775+00:00",
      "metadata": {
        "processed_at": "2026-01-05T04:53:34.181777+00:00",
        "processing_method": "github_actions"
      }
    }
  ]
}