{
  "last_updated": "2025-10-14T22:40:54.280948+00:00",
  "count": 20,
  "articles": [
    {
      "id": "8595e31d22af6c7653e0fd0407ccd1c1",
      "url": "https://arxiv.org/abs/2510.10791",
      "title": "A compressed code for memory discrimination",
      "content": "arXiv:2510.10791v1 Announce Type: new \nAbstract: The ability to discriminate similar visual stimuli is an important index of memory function. This ability is widely thought to be supported by expanding the dimensionality of relevant neural codes, such that neural representations for similar stimuli are maximally distinct, or ``separated.'' An alternative hypothesis is that discrimination is supported by lossy compression of visual inputs, efficiently coding sensory information by discarding seemingly irrelevant details. A benefit of compression, relative to expansion, is that it allows individuals to retain fewer essential dimensions underlying stimulus variation -- a process linked to higher-order visual processing -- without hindering discrimination. Under this hypothesis, pattern separation is facilitated when more information from similar stimuli can be discarded, rather than preserved. We test the compression versus expansion hypotheses by predicting performance on the canonical mnemonic similarity task. We train neural networks to compress perceptual and semantic factors of stimuli, measuring lossiness using the mathematical framework underlying compression. Consistent with the compression hypothesis, and not the expansion hypothesis, greater lossiness predicts the ease and performance of lure discrimination, especially in deeper convolutional network layers that predict higher-order visual brain activity. We then confirm these predictions across two image sets, four behavioral datasets, and alternative lossiness metrics. Finally, using task fMRI, we identify signatures of lossy compression -- neural dimensionality reduction and information loss -- in higher-order visual regions V4 and IT and hippocampal DG/CA3 and CA1 linked to lure discrimination. These results suggest lossy compression supports mnemonic discrimination by discarding redundant and overlapping information.",
      "author": "Dale Zhou, Sharon Mina Noh, Nora C Harhen, Nidhi V Banavar, C. Brock Kirwan, Michael A Yassa, Aaron M Bornstein",
      "published_date": "2025-10-14T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 253,
      "reading_time": 1,
      "created_at": "2025-10-14T22:40:33.215774+00:00",
      "updated_at": "2025-10-14T22:40:33.215776+00:00"
    },
    {
      "id": "fcb6eb733c8972082d8b09faf72fcf99",
      "url": "https://arxiv.org/abs/2510.10770",
      "title": "The Cost of Simplicity: How Reducing EEG Electrodes Affects Source Localization and BCI Accuracy",
      "content": "arXiv:2510.10770v1 Announce Type: new \nAbstract: Electrode density optimization in electroencephalography (EEG)-based Brain-Computer Interfaces (BCIs) requires balancing practical usability against signal fidelity, particularly for source localization. Reducing electrodes enhances portability but its effects on neural source reconstruction quality and source connectivity - treated as proxies to BCI performance - remain understudied. We address this gap through systematic evaluation of 62-, 32-, and 16-channel configurations using a fixed, fully automated processing pipeline applied to the well-characterized P300 potential. This approach's rationale is to minimize variability and bias inherent to EEG analysis by leveraging the P300's stimulus-locked reproducibility and pipeline standardization. Analyzing 63 sessions (31 subjects) from the Eye-BCI dataset with rigorous artifact correction and channel validation, we demonstrate: (1) Progressive degradation in source reconstruction quality with sparser configurations, including obscured deep neural generators and spatiotemporal distortions; (2) A novel sqrt(Re) scaling law linking electrode reduction ratio (Re) to localization accuracy - a previously unquantified relationship to the best of our knowledge; (3) While reduced configurations preserve basic P300 topography and may suffice for communicative BCIs, higher-density channels are essential for reliable deep source reconstruction. Overall, this study establishes a first step towards quantitative benchmarks for electrode selection, with critical implications for clinical BCIs requiring anatomical precision in applications like neurodegenerative disease monitoring, where compromised spatial resolution could mask pathological signatures. Most importantly, the sqrt(Re) scaling law may provide the first principled method to determine the minimal electrode density required based on acceptable error margins or expected effect sizes.",
      "author": "Eva Guttmann-Flury, Yanyan Wei, Shan Zhao, Jian Zhao, Mohamad Sawan",
      "published_date": "2025-10-14T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 246,
      "reading_time": 1,
      "created_at": "2025-10-14T22:40:33.215739+00:00",
      "updated_at": "2025-10-14T22:40:33.215740+00:00"
    },
    {
      "id": "e3efbfca14fa53d208431deda45c7f79",
      "url": "https://arxiv.org/abs/2510.10733",
      "title": "Does Re-referencing Matter? Large Laplacian Filter Optimizes Single-Trial P300 BCI Performance",
      "content": "arXiv:2510.10733v1 Announce Type: new \nAbstract: Electroencephalography (EEG) provides a non-invasive window into brain activity, enabling Brain-Computer Interfaces (BCIs) for communication and control. However, their performance is limited by signal fidelity issues, among which the choice of re-referencing strategy is a pervasive but often overlooked preprocessing bias. Addressing controversies about its necessity and optimal choice, we adopted a quantified approach to evaluate four strategies - no re-referencing, Common Average Reference (CAR), small Laplacian, and large Laplacian - using 62-channels EEG (31 subjects, 2,520 trials). To our knowledge, this is the first study systematically quantifying their impact on single-trial P300 classification accuracy. Our controlled pipeline isolated re-referencing effects for source-space reconstruction (eLORETA with Phase Lag Index) and anatomically constrained classification. The large Laplacian resolves distributed P3b networks while maintaining P3a specificity, achieving the best P300 peak classification accuracy (81.57% hybrid method; 75.97% majority regions of interest). Performance follows a consistent and statistically significant hierarchy: large Laplacian > CAR > no re-reference > small Laplacian, providing a foundation for unified methodological evaluation.",
      "author": "Eva Guttmann-Flury, Jian Zhao, Mohamad Sawan",
      "published_date": "2025-10-14T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 169,
      "reading_time": 1,
      "created_at": "2025-10-14T22:40:33.215703+00:00",
      "updated_at": "2025-10-14T22:40:33.215705+00:00"
    },
    {
      "id": "6247a3051e57ace57a6ad586a525a3e5",
      "url": "https://arxiv.org/abs/2510.10559",
      "title": "Evidence of Physiological Co-Modulation During Human-Animal Interaction: A Systematic Review",
      "content": "arXiv:2510.10559v1 Announce Type: new \nAbstract: This review examines the evidence in the literature for physiological co-modulation during human-animal interaction. The aim of this work is to identify studies that assessed co-modulation via simultaneous measurement of physiological signals in both species, performing quantitative comparisons, and evaluate the consistency of the findings.\\\\ We searched PubMed, EM-BASE, Scopus, Google Scholar, Animal Studies Repository, and the ''Consensus app'' tool between June and August 2025 (last search: August 5, 2025). Risk of bias was assessed using an adapted version of the ROBINS-I V2 tool. Results were grouped by data analysis method, interaction context, and physiological parameter. Data were synthesised narratively, in structured tables and in barplots. Thirty-seven studies were included, primarily focusing on dogs (n=22) and horses (n=15), framed primarily within the interaction contexts of Animal-Assisted Therapy and Intervention (AAT and AAI) and companionship. Cardiac and hormonal measures were most frequently assessed. Most studies (n = 20) performed correlation analyses. Sample sizes ranged from less than 10 to more than 130 dyads. Co-modulation resulted significant in 22 studies, partial (limited to subsets of data) in 9, and absent in 6. Time-series coupling methods yielded more consistent evidence than discrete-time correlations. Many studies had small samples and did not explicitly test for significant co-modulation. Evidence, while not conclusive, supports physiological co-modulation during human-animal interactions. However, studies' heterogeneity limits generalizability: rather than indicating a universal phenomenon, findings suggest co-modulation may emerge under specific biological and methodological conditions. Future research should explicitly test its presence across contexts.",
      "author": "G. Bargigli, L. Frassineti, A. Lanata', P. Baragli, C. Scopa, A. Vignoli",
      "published_date": "2025-10-14T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 249,
      "reading_time": 1,
      "created_at": "2025-10-14T22:40:33.215673+00:00",
      "updated_at": "2025-10-14T22:40:33.215675+00:00"
    },
    {
      "id": "74b37b5d7145fe2179d8d05bc3a78608",
      "url": "https://arxiv.org/abs/2510.10308",
      "title": "Artificial intelligence as a surrogate brain: Bridging neural dynamical models and data",
      "content": "arXiv:2510.10308v1 Announce Type: new \nAbstract: Recent breakthroughs in artificial intelligence (AI) are reshaping the way we construct computational counterparts of the brain, giving rise to a new class of ``surrogate brains''. In contrast to conventional hypothesis-driven biophysical models, the AI-based surrogate brain encompasses a broad spectrum of data-driven approaches to solve the inverse problem, with the primary objective of accurately predicting future whole-brain dynamics with historical data. Here, we introduce a unified framework of constructing an AI-based surrogate brain that integrates forward modeling, inverse problem solving, and model evaluation. Leveraging the expressive power of AI models and large-scale brain data, surrogate brains open a new window for decoding neural systems and forecasting complex dynamics with high dimensionality, nonlinearity, and adaptability. We highlight that the learned surrogate brain serves as a simulation platform for dynamical systems analysis, virtual perturbation, and model-guided neurostimulation. We envision that the AI-based surrogate brain will provide a functional bridge between theoretical neuroscience and translational neuroengineering.",
      "author": "Yinuo Zhang, Demao Liu, Zhichao Liang, Jiani Cheng, Kexin Lou, Jinqiao Duan, Ting Gao, Bin Hu, Quanying Liu",
      "published_date": "2025-10-14T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 159,
      "reading_time": 1,
      "created_at": "2025-10-14T22:40:33.215638+00:00",
      "updated_at": "2025-10-14T22:40:33.215639+00:00"
    },
    {
      "id": "dd51496e45be65fea76f63488b2523f4",
      "url": "https://arxiv.org/abs/2510.10286",
      "title": "AI-Assisted Geometric Analysis of Cultured Neuronal Networks: Parallels with the Cosmic Web",
      "content": "arXiv:2510.10286v1 Announce Type: new \nAbstract: Building on evidence of structural parallels between brain networks and the cosmic web [1], we apply AI-based geometric analysis to cultured neuronal networks. Isolated neurons self-organize into dendritic lattices shaped by reproducible wiring rules. These lattices show non-random features-frequent dendritic convergence, hub nodes, small-world connectivity, and large voids. Synaptic contacts cluster and strengthen at hubs. Strikingly, these properties mirror the cosmic web: dendritic branches resemble cosmic filaments and synapses map to galaxies. Quantitative metrics align across systems, suggesting shared underlying geometric principles. We invite cross-disciplinary collaboration to interrogate and extend these parallels.",
      "author": "Wolfgang Kurz, Danny Baranes",
      "published_date": "2025-10-14T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 97,
      "reading_time": 1,
      "created_at": "2025-10-14T22:40:33.215608+00:00",
      "updated_at": "2025-10-14T22:40:33.215610+00:00"
    },
    {
      "id": "697c67ff19260f01ea2e1cc337cad99e",
      "url": "https://arxiv.org/abs/2510.10251",
      "title": "Neural Hardware for the Language of Thought: New Rules for an Old Game",
      "content": "arXiv:2510.10251v1 Announce Type: new \nAbstract: The Language of Thought (LOT) hypothesis posits that at least some important cognitive processes involve language-like representations. These representations must be processed by appropriate hardware. Since the organ of biological cognition is the nervous system, whether biological cognition relies on a LOT depends on how neural hardware works. I distinguish between different versions of LOT, articulate their hardware requirements, and consider which versions of LOT are supported by empirical evidence. I argue that the Classical LOT hypothesis (Fodor 1975) is ruled out; the version of LOT that is best supported by empirical evidence is the Nonclassical LOT thesis that some neural representations mirror some of the structure of natural language and represent in a language-like way, yet they encode information nondigitally and are processed by ordinary (nondigital, and hence Nonclassical) neural computations that rely not only on syntactic structure but many other features.",
      "author": "Gualtiero Piccinini",
      "published_date": "2025-10-14T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 148,
      "reading_time": 1,
      "created_at": "2025-10-14T22:40:33.215582+00:00",
      "updated_at": "2025-10-14T22:40:33.215583+00:00"
    },
    {
      "id": "d536f01032cb721f0c41729febb49944",
      "url": "https://arxiv.org/abs/2510.09951",
      "title": "Egocentric Visual Navigation through Hippocampal Sequences",
      "content": "arXiv:2510.09951v1 Announce Type: new \nAbstract: Sequential activation of place-tuned neurons in an animal during navigation is typically interpreted as reflecting the sequence of input from adjacent positions along the trajectory. More recent theories about such place cells suggest sequences arise from abstract cognitive objectives like planning. Here, we propose a mechanistic and parsimonious interpretation to complement these ideas: hippocampal sequences arise from intrinsic recurrent circuitry that propagates activity without readily available input, acting as a temporal memory buffer for extremely sparse inputs.We implement a minimal sequence generator inspired by neurobiology and pair it with an actor-critic learner for egocentric visual navigation. Our agent reliably solves a continuous maze without explicit geometric cues, with performance depending on the length of the recurrent sequence. Crucially, the model outperforms LSTM cores under sparse input conditions (16 channels, ~2.5% activity), but not under dense input, revealing a strong interaction between representational sparsity and memory architecture.In contrast to LSTM agents, hidden sequence units develop localized place fields, distance-dependent spatial kernels, and task-dependent remapping, while inputs orthogonalize and spatial information increases across layers. These phenomena align with neurobiological data and are causal to performance. Together, our results show that sparse input synergizes with sequence-generating dynamics, providing both a mechanistic account of place cell sequences in the mammalian hippocampus and a simple inductive bias for reinforcement learning based on sparse egocentric inputs in navigation tasks.",
      "author": "Xiao-Xiong Lin, Yuk Hoi Yiu, Christian Leibold",
      "published_date": "2025-10-14T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 228,
      "reading_time": 1,
      "created_at": "2025-10-14T22:40:33.215552+00:00",
      "updated_at": "2025-10-14T22:40:33.215554+00:00"
    },
    {
      "id": "c605aeb5e55704c8df79494147ef6f97",
      "url": "https://arxiv.org/abs/2510.09816",
      "title": "A mathematical theory for understanding when abstract representations emerge in neural networks",
      "content": "arXiv:2510.09816v1 Announce Type: new \nAbstract: Recent experiments reveal that task-relevant variables are often encoded in approximately orthogonal subspaces of the neural activity space. These disentangled low-dimensional representations are observed in multiple brain areas and across different species, and are typically the result of a process of abstraction that supports simple forms of out-of-distribution generalization. The mechanisms by which such geometries emerge remain poorly understood, and the mechanisms that have been investigated are typically unsupervised (e.g., based on variational auto-encoders). Here, we show mathematically that abstract representations of latent variables are guaranteed to appear in the last hidden layer of feedforward nonlinear networks when they are trained on tasks that depend directly on these latent variables. These abstract representations reflect the structure of the desired outputs or the semantics of the input stimuli. To investigate the neural representations that emerge in these networks, we develop an analytical framework that maps the optimization over the network weights into a mean-field problem over the distribution of neural preactivations. Applying this framework to a finite-width ReLU network, we find that its hidden layer exhibits an abstract representation at all global minima of the task objective. We further extend these analyses to two broad families of activation functions and deep feedforward architectures, demonstrating that abstract representations naturally arise in all these scenarios. Together, these results provide an explanation for the widely observed abstract representations in both the brain and artificial neural networks, as well as a mathematically tractable toolkit for understanding the emergence of different kinds of representations in task-optimized, feature-learning network models.",
      "author": "Bin Wang, W. Jeffrey Johnston, Stefano Fusi",
      "published_date": "2025-10-14T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 258,
      "reading_time": 1,
      "created_at": "2025-10-14T22:40:33.215508+00:00",
      "updated_at": "2025-10-14T22:40:33.215513+00:00"
    },
    {
      "id": "b9cddfaa6f49fa727c0e6ff206e67f6f",
      "url": "https://www.sciencedirect.com/science/article/pii/S030645222500973X?dgcid=rss_sd_all",
      "title": "Activin A protects against lipopolysaccharide/TNF-\u03b1 induced damage of dopaminergic neurons both in vivo and in vitro by regulating mitochondrial fusion",
      "content": "<p>Publication date: 10 November 2025</p><p><b>Source:</b> Neuroscience, Volume 587</p><p>Author(s): Yue Zhang, Shuxiang Tian, Mingguang Niu, Han Yang, Lulu Liu, Yuyang Kang, Yanyan Yin</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroscience Journal",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 22,
      "reading_time": 1,
      "created_at": "2025-10-14T22:40:27.091227+00:00",
      "updated_at": "2025-10-14T22:40:27.091228+00:00"
    },
    {
      "id": "56703644563a7813e9893ff320446b83",
      "url": "https://www.sciencedirect.com/science/article/pii/S0306452225009832?dgcid=rss_sd_all",
      "title": "C9orf72 related poly-Glycine-Alanine promotes tau phosphorylation and cell death via ERK1/2 interaction in cellular models",
      "content": "<p>Publication date: 10 November 2025</p><p><b>Source:</b> Neuroscience, Volume 587</p><p>Author(s): Jiahan Zhuang, Zixuan Zhang, Hongfu Jin, Ji Qi, Yuanyuan Chen, Lin Ding, Chenglai Fu, Weiwei Cheng</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroscience Journal",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 24,
      "reading_time": 1,
      "created_at": "2025-10-14T22:40:27.091208+00:00",
      "updated_at": "2025-10-14T22:40:27.091209+00:00"
    },
    {
      "id": "978311cba2c05024a239a0ab6d03248a",
      "url": "https://github.com/tempesta-tech/webshield",
      "title": "Show HN: An open source access logs analytics script to block bot attacks",
      "content": "<a href=\"https://news.ycombinator.com/item?id=45583667\">Comments</a>",
      "author": "",
      "published_date": "2025-10-14T19:15:57+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-10-14T22:39:46.720820+00:00",
      "updated_at": "2025-10-14T22:39:46.720821+00:00"
    },
    {
      "id": "51209a1a7812337f88129f0f69d4e12e",
      "url": "https://www.anthropic.com/research/economic-policy-responses",
      "title": "Preparing for AI's economic impact: exploring policy responses",
      "content": "<p>Article URL: <a href=\"https://www.anthropic.com/research/economic-policy-responses\">https://www.anthropic.com/research/economic-policy-responses</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=45583574\">https://news.ycombinator.com/item?id=45583574</a></p>\n<p>Points: 5</p>\n<p># Comments: 5</p>",
      "author": "grantpitt",
      "published_date": "2025-10-14T19:06:27+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-10-14T22:39:45.440489+00:00",
      "updated_at": "2025-10-14T22:39:45.440490+00:00"
    },
    {
      "id": "978311cba2c05024a239a0ab6d03248a",
      "url": "https://github.com/tempesta-tech/webshield",
      "title": "Show HN: An open source access logs analytics script to block bot attacks",
      "content": "<p>This is a small PoC Python project for web server access logs analyzing to classify and dynamically block bad bots, such as L7 (application-level) DDoS bots, web scrappers and so on.<p>We'll be happy to gather initial feedback on usability and features, especialy from people having good or bad experience wit bots.<p>*Requirements*<p>The analyzer relies on 3 Tempesta FW specific features which you still can get with other HTTP servers or accelerators:<p>1. JA5 client fingerprinting (<a href=\"https://tempesta-tech.com/knowledge-base/Traffic-Filtering-by-Fingerprints/\" rel=\"nofollow\">https://tempesta-tech.com/knowledge-base/Traffic-Filtering-b...</a>). This is a HTTP and TLS layers fingerprinting, similar to JA4 (<a href=\"https://blog.foxio.io/ja4%2B-network-fingerprinting\" rel=\"nofollow\">https://blog.foxio.io/ja4%2B-network-fingerprinting</a>) and JA3 fingerprints. The last is also available in Envoy (<a href=\"https://www.envoyproxy.io/docs/envoy/latest/api-v3/extensions/filters/listener/tls_inspector/v3/tls_inspector.proto.html\" rel=\"nofollow\">https://www.envoyproxy.io/docs/envoy/latest/api-v3/extension...</a>) or Nginx module (<a href=\"https://github.com/fooinha/nginx-ssl-ja3\" rel=\"nofollow\">https://github.com/fooinha/nginx-ssl-ja3</a>), so check the documentation for your web server<p>2. Access logs are directly written to Clickhouse analytics database, which can cunsume large data batches and quickly run analytic queries. For other web proxies beside Tempesta FW, you typically need to build a custom pipeline to load access logs into Clickhouse. Such pipeliens aren't so rare though.<p>3. Abbility to block web clients by IP or JA5 hashes. IP blocking is probably available in any HTTP proxy.<p>*How does it work*<p>This is a daemon, which<p>1. Learns normal traffic profiles: means and standard deviations for client requests per second, error responses, bytes per second and so on. Also it remembers client IPs and fingerprints.<p>2. If it sees a spike in z-score (<a href=\"https://en.wikipedia.org/wiki/Standard_score\" rel=\"nofollow\">https://en.wikipedia.org/wiki/Standard_score</a>) for traffic characteristics or can be triggered manually. Next, it goes in data model search mode<p>3. For example, the first model could be top 100 JA5 HTTP hashes, which produce the most error responses per second (typical for password crackers). Or it could be top 1000 IP addresses generating the most requests per second (L7 DDoS). Next, this model is going to be verified<p>4. The daemon repeats the query, but for some time, long enough history, in the past to see if in the past we saw a hige fraction of clients in both the query results. If yes, then the model is bad and we got to previous step to try another one. If not, then we (likely) has found the representative query.<p>5. Transfer the IP addresses or JA5 hashes from the query results into the web proxy blocking configuration and reload the proxy configuration (on-the-fly).</p>\n<hr />\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=45583667\">https://news.ycombinator.com/item?id=45583667</a></p>\n<p>Points: 8</p>\n<p># Comments: 0</p>",
      "author": "krizhanovsky",
      "published_date": "2025-10-14T19:15:57+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 386,
      "reading_time": 1,
      "created_at": "2025-10-14T22:39:45.440468+00:00",
      "updated_at": "2025-10-14T22:39:45.440470+00:00"
    },
    {
      "id": "dd5cc5d19115b48ef21abb3b79ad6300",
      "url": "https://www.sciencedirect.com/science/article/pii/S0306452225009741?dgcid=rss_sd_all",
      "title": "Assessment of elephant claustrum by combined histological analysis and high-resolution micro-CT",
      "content": "<p>Publication date: 10 November 2025</p><p><b>Source:</b> Neuroscience, Volume 587</p><p>Author(s): Chao Fang, Anne Schnurpfeil, Lennart Eigen, Olivia Heise, Tabea Pottek, Johannes Alkofer, Thomas Hildebrandt, Tim Salditt, Robert K. Naumann, Michael Brecht</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroscience Journal",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 29,
      "reading_time": 1,
      "created_at": "2025-10-14T22:19:28.013594+00:00",
      "updated_at": "2025-10-14T22:19:28.013596+00:00"
    },
    {
      "id": "57c97de43338bc136f0d071eccf6ba30",
      "url": "https://www.sciencedirect.com/science/article/pii/S0306452225009777?dgcid=rss_sd_all",
      "title": "Effect of <em>Origanum majorana</em> tea on oxidative stress biomarkers in Parkinson\u2019s disease: a randomized placebo-controlled pilot study",
      "content": "<p>Publication date: 10 November 2025</p><p><b>Source:</b> Neuroscience, Volume 587</p><p>Author(s): Chbili Chahra, Mrad Sawssen, Hassine Anis, Naija Salma, Nouira Manel, Ben Amor Sana, Ben Fredj Maha</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroscience Journal",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 24,
      "reading_time": 1,
      "created_at": "2025-10-14T22:19:28.013572+00:00",
      "updated_at": "2025-10-14T22:19:28.013574+00:00"
    },
    {
      "id": "21e3e2fd33379952546aa13ba12aab53",
      "url": "https://www.sciencedirect.com/science/article/pii/S0306452225009753?dgcid=rss_sd_all",
      "title": "The Smarce1 subunit of the BAF complex performs distinct, stage-specific functions during zebrafish retinal development",
      "content": "<p>Publication date: 10 November 2025</p><p><b>Source:</b> Neuroscience, Volume 587</p><p>Author(s): Laura Ram\u00edrez, Denh\u00ed Schnabel, Flavio R. Zolessi, Hilda Lomel\u00ed</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroscience Journal",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 17,
      "reading_time": 1,
      "created_at": "2025-10-14T22:19:28.013522+00:00",
      "updated_at": "2025-10-14T22:19:28.013548+00:00"
    },
    {
      "id": "ed6c14450b8c0249538bc90041dfc00a",
      "url": "https://www.biorxiv.org/content/10.1101/2025.10.13.682081v1?rss=1",
      "title": "Error-Related Memory Biases Are Specific to Social Stimuli for Socially Anxious Individuals",
      "content": "Social anxiety (SA) is associated with enhanced error monitoring, yet underlying mechanisms remain unclear. Consistent with cognitive models of SA, we propose that stronger error monitoring contributes to SA by strengthening memory encoding of errors (including relevant social cues), negatively biasing what is remembered. Supporting this hypothesis, our prior work demonstrated that high SA individuals exhibit better memory for faces presented during error (vs. correct) trials. To test whether this Memory Bias for Error Events is specific to social stimuli, 140 participants completed a Flanker task with trial-unique faces (social) or objects (non-social) as background images, followed by a surprise memory test. Results revealed that higher SA symptoms were associated with enhanced memory for faces on error (vs. correct) trials, but not for objects. These findings replicate and extend our prior work, demonstrating that SA-related memory biases for errors are specific to social stimuli, rather than reflecting general encoding biases.",
      "author": "Hosseini, K., Mattfeld, A. T., Pettit, J. W., Buzzell, G. A.",
      "published_date": "2025-10-14T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 150,
      "reading_time": 1,
      "created_at": "2025-10-14T22:19:24.340280+00:00",
      "updated_at": "2025-10-14T22:19:24.340285+00:00"
    },
    {
      "id": "0dc00d9486a7591537f1f4acbf60fb48",
      "url": "https://www.nature.com/articles/s41386-025-02226-9",
      "title": "Kappa opioid receptor control of motivated behavior revisited",
      "content": "",
      "author": "",
      "published_date": "2025-10-13T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-10-14T22:19:22.898252+00:00",
      "updated_at": "2025-10-14T22:19:22.898254+00:00"
    },
    {
      "id": "b0fcad499dd2e02275ba784bc9f898ef",
      "url": "https://www.nature.com/articles/s41467-025-64132-4",
      "title": "Dopamine dynamics during stimulus-reward learning in mice can be explained by performance rather than learning",
      "content": "",
      "author": "",
      "published_date": "2025-10-13T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-10-14T22:19:22.898199+00:00",
      "updated_at": "2025-10-14T22:19:22.898200+00:00"
    }
  ]
}