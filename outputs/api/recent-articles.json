{
  "last_updated": "2025-10-01T22:13:15.897894+00:00",
  "count": 20,
  "articles": [
    {
      "id": "4f503efc209479f9b870bfb5bde19f97",
      "url": "https://arxiv.org/abs/2509.25537",
      "title": "Healthy Lifestyles and Self-Improvement Videos on YouTube: A Thematic Analysis of Teen-Targeted Social Media Content",
      "content": "arXiv:2509.25537v1 Announce Type: new \nAbstract: As teenagers increasingly turn to social media for health-related information, understanding the values of teen-targeted content has become important. Although videos on healthy lifestyles and self-improvement are gaining popularity on social media platforms like YouTube, little is known about how these videos benefit and engage with teenage viewers. To address this, we conducted a thematic analysis of 44 YouTube videos and 66,901 comments. We found that these videos provide various advice on teenagers' common challenges, use engaging narratives for authenticity, and foster teen-centered communities through comments. However, a few videos also gave misleading advice to adolescents that can be potentially harmful. Based on our findings, we discuss design implications for creating relatable and intriguing social media content for adolescents. Additionally, we suggest ways for social media platforms to promote healthier and safer experiences for teenagers.",
      "author": "Kyuha Jung, Tyler Kim, Yunan Chen",
      "published_date": "2025-10-01T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 140,
      "reading_time": 1,
      "created_at": "2025-10-01T21:38:25.736424+00:00",
      "updated_at": "2025-10-01T22:13:15.795337+00:00",
      "metadata": {
        "processed_at": "2025-10-01T22:13:15.795346+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "ba103cc111df09142bb2ce13dfcbc549",
      "url": "https://arxiv.org/abs/2509.25513",
      "title": "User Prompting Strategies and ChatGPT Contextual Adaptation Shape Conversational Information-Seeking Experiences",
      "content": "arXiv:2509.25513v1 Announce Type: new \nAbstract: Conversational AI, such as ChatGPT, is increasingly used for information seeking. However, little is known about how ordinary users actually prompt and how ChatGPT adapts its responses in real-world conversational information seeking (CIS). In this study, a nationally representative sample of 937 U.S. adults engaged in multi-turn CIS with ChatGPT on both controversial and non-controversial topics across science, health, and policy contexts. We analyzed both user prompting strategies and the communication styles of ChatGPT responses. The findings revealed behavioral signals of digital divide: only 19.1% of users employed prompting strategies, and these users were disproportionately more educated and Democrat-leaning. Further, ChatGPT demonstrated contextual adaptation: responses to controversial topics contain more cognitive complexity and more external references than to non-controversial topics. Notably, cognitively complex responses were perceived as less favorable but produced more positive issue-relevant attitudes. This study highlights disparities in user prompting behaviors and shows how user prompts and AI responses together shape information-seeking with conversational AI.",
      "author": "Haoning Xue, Yoo Jung Oh, Xinyi Zhou, Xinyu Zhang, Berit Oxley",
      "published_date": "2025-10-01T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 162,
      "reading_time": 1,
      "created_at": "2025-10-01T21:38:25.736395+00:00",
      "updated_at": "2025-10-01T22:13:15.795350+00:00",
      "metadata": {
        "processed_at": "2025-10-01T22:13:15.795352+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "12518e6b2b2e986bef078011dbe9c579",
      "url": "https://arxiv.org/abs/2509.25504",
      "title": "XR Blocks: Accelerating Human-centered AI + XR Innovation",
      "content": "arXiv:2509.25504v1 Announce Type: new \nAbstract: We are on the cusp where Artificial Intelligence (AI) and Extended Reality (XR) are converging to unlock new paradigms of interactive computing. However, a significant gap exists between the ecosystems of these two fields: while AI research and development is accelerated by mature frameworks like JAX and benchmarks like LMArena, prototyping novel AI-driven XR interactions remains a high-friction process, often requiring practitioners to manually integrate disparate, low-level systems for perception, rendering, and interaction. To bridge this gap, we present XR Blocks, a cross-platform framework designed to accelerate human-centered AI + XR innovation. XR Blocks strives to provide a modular architecture with plug-and-play components for core abstraction in AI + XR: user, world, peers; interface, context, and agents. Crucially, it is designed with the mission of \"reducing frictions from idea to reality\", thus accelerating rapid prototyping of AI + XR apps. Built upon accessible technologies (WebXR, three.js, TensorFlow, Gemini), our toolkit lowers the barrier to entry for XR creators. We demonstrate its utility through a set of open-source templates, samples, and advanced demos, empowering the community to quickly move from concept to interactive XR prototype. Site: https://xrblocks.github.io",
      "author": "David Li, Nels Numan, Xun Qian, Yanhe Chen, Zhongyi Zhou, Evgenii Alekseev, Geonsun Lee, Alex Cooper, Min Xia, Scott Chung, Jeremy Nelson, Xiuxiu Yuan, Jolica Dias, Tim Bettridge, Benjamin Hersh, Michelle Huynh, Konrad Piascik, Ricardo Cabello, David Kim, Ruofei Du",
      "published_date": "2025-10-01T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 191,
      "reading_time": 1,
      "created_at": "2025-10-01T21:38:25.736366+00:00",
      "updated_at": "2025-10-01T22:13:15.795355+00:00",
      "metadata": {
        "processed_at": "2025-10-01T22:13:15.795356+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "6751d4ba29952f47f6af983d84f172cd",
      "url": "https://arxiv.org/abs/2509.25499",
      "title": "Atlas of Human-AI Interaction (v1): An Interactive Meta-Science Platform for Large-Scale Research Literature Sensemaking",
      "content": "arXiv:2509.25499v1 Announce Type: new \nAbstract: Human-AI interaction researchers face an overwhelming challenge: synthesizing insights from thousands of empirical studies to understand how AI impacts people and inform effective design. Existing approach for literature reviews cluster papers by similarities, keywords or citations, missing the crucial cause-and-effect relationships that reveal how design decisions impact user outcomes. We introduce the Atlas of Human-AI Interaction, an interactive web interface that provides the first systematic mapping of empirical findings across 1,000+ HCI papers using LLM-powered knowledge extraction. Our approach identifies causal relationships, and visualizes them through an AI-enabled interactive web interface as a navigable knowledge graph. We extracted 2,037 empirical findings, revealing research topic clusters, common themes, and disconnected areas. Expert evaluation with 20 researchers revealed the system's effectiveness for discovering research gaps. This work demonstrates how AI can transform literature synthesis itself, offering a scalable framework for evidence-based design, opening new possibilities for computational meta-science across HCI and beyond.",
      "author": "Chayapatr Archiwaranguprok, Awu Chen, Sheer Karny, Hiroshi Ishii, Pattie Maes, Pat Pataranutaporn",
      "published_date": "2025-10-01T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 155,
      "reading_time": 1,
      "created_at": "2025-10-01T21:38:25.736334+00:00",
      "updated_at": "2025-10-01T22:13:15.795359+00:00",
      "metadata": {
        "processed_at": "2025-10-01T22:13:15.795360+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "863c3da472b0a1909355d8b7dcb7ee7d",
      "url": "https://arxiv.org/abs/2509.25492",
      "title": "Botender: Supporting Communities in Collaboratively Designing AI Agents through Case-Based Provocations",
      "content": "arXiv:2509.25492v1 Announce Type: new \nAbstract: AI agents, or bots, serve important roles in online communities. However, they are often designed by outsiders or a few tech-savvy members, leading to bots that may not align with the broader community's needs. How might communities collectively shape the behavior of community bots? We present Botender, a system that enables communities to collaboratively design LLM-powered bots without coding. With Botender, community members can directly propose, iterate on, and deploy custom bot behaviors tailored to community needs. Botender facilitates testing and iteration on bot behavior through case-based provocations: interaction scenarios generated to spark user reflection and discussion around desirable bot behavior. A validation study found these provocations more useful than standard test cases for revealing improvement opportunities and surfacing disagreements. During a five-day deployment across six Discord servers, Botender supported communities in tailoring bot behavior to their specific needs, showcasing the usefulness of case-based provocations in facilitating collaborative bot design.",
      "author": "Tzu-Sheng Kuo, Sophia Liu, Quan Ze Chen, Joseph Seering, Amy X. Zhang, Haiyi Zhu, Kenneth Holstein",
      "published_date": "2025-10-01T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 155,
      "reading_time": 1,
      "created_at": "2025-10-01T21:38:25.736304+00:00",
      "updated_at": "2025-10-01T22:13:15.795362+00:00",
      "metadata": {
        "processed_at": "2025-10-01T22:13:15.795367+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "b463bcc77eb4a19055464b7208d1af96",
      "url": "https://arxiv.org/abs/2509.25491",
      "title": "LLM-Assisted News Discovery in High-Volume Information Streams: A Case Study",
      "content": "arXiv:2509.25491v1 Announce Type: new \nAbstract: Journalists face mounting challenges in monitoring ever-expanding digital information streams to identify newsworthy content. While traditional automation tools gather information at scale, they struggle with the editorial judgment needed to assess newsworthiness. This paper investigates whether large language models (LLMs) can serve as effective first-pass filters for journalistic monitoring. We develop a prompt-based approach encoding journalistic news values - timeliness, impact, controversy, and generalizability - into LLM instructions to extract and evaluate potential story leads. We validate our approach across multiple models against expert-annotated ground truth, then deploy a real-world monitoring pipeline that processes trade press articles daily. Our evaluation reveals strong performance in extracting relevant leads from source material ($F1=0.94$) and in coarse newsworthiness assessment ($\\pm$1 accuracy up to 92%), but it consistently struggles with nuanced editorial judgments requiring beat expertise. The system proves most valuable as a hybrid tool combining automated monitoring with human review, successfully surfacing novel, high-value leads while filtering obvious noise. We conclude with practical recommendations for integrating LLM-powered monitoring into newsroom workflows that preserves editorial judgment while extending journalistic capacity.",
      "author": "Nick Hagar, Ethan Silver, Clare Spencer, Nicholas Diakopoulos",
      "published_date": "2025-10-01T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 181,
      "reading_time": 1,
      "created_at": "2025-10-01T21:38:25.736275+00:00",
      "updated_at": "2025-10-01T21:38:25.736276+00:00"
    },
    {
      "id": "652dad4caaec29b92ff350a5d8368251",
      "url": "https://arxiv.org/abs/2509.25460",
      "title": "\"Where Can I Park?\" Understanding Human Perspectives and Scalably Detecting Disability Parking from Aerial Imagery",
      "content": "arXiv:2509.25460v1 Announce Type: new \nAbstract: Accessible parking is critical for people with disabilities (PwDs), allowing equitable access to destinations, independent mobility, and community participation. Despite mandates, there has been no large-scale investigation of the quality or allocation of disability parking in the US nor significant research on PwD perspectives and uses of disability parking. In this paper, we first present a semi-structured interview study with 11 PwDs to advance understanding of disability parking uses, concerns, and relevant technology tools. We find that PwDs often adapt to disability parking challenges according to their personal mobility needs and value reliable, real-time accessibility information. Informed by these findings, we then introduce a new deep learning pipeline, called AccessParkCV, and parking dataset for automatically detecting disability parking and inferring quality characteristics (e.g., width) from orthorectified aerial imagery. We achieve a micro-F1=0.89 and demonstrate how our pipeline can support new urban analytics and end-user tools. Together, we contribute new qualitative understandings of disability parking, a novel detection pipeline and open dataset, and design guidelines for future tools.",
      "author": "Jared Hwang, Chu Li, Hanbyul Kang, Maryam Hosseini, Jon E. Froehlich",
      "published_date": "2025-10-01T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 172,
      "reading_time": 1,
      "created_at": "2025-10-01T21:38:25.736244+00:00",
      "updated_at": "2025-10-01T21:38:25.736245+00:00"
    },
    {
      "id": "a41507032d26f246243a270dec0c3ddb",
      "url": "https://arxiv.org/abs/2509.25457",
      "title": "Human vs. AI Safety Perception? Decoding Human Safety Perception with Eye-Tracking Systems, Street View Images, and Explainable AI",
      "content": "arXiv:2509.25457v1 Announce Type: new \nAbstract: The way residents perceive safety plays an important role in how they use public spaces. Studies have combined large-scale street view images and advanced computer vision techniques to measure the perception of safety of urban environments. Despite their success, such studies have often overlooked the specific environmental visual factors that draw human attention and trigger people's feelings of safety perceptions. In this study, we introduce a computational framework that enriches the existing body of literature on place perception by using eye-tracking systems with street view images and deep learning approaches. Eye-tracking systems quantify not only what users are looking at but also how long they engage with specific environmental elements. This allows us to explore the nuance of which visual environmental factors influence human safety perceptions. We conducted our research in Helsingborg, Sweden, where we recruited volunteers outfitted with eye-tracking systems. They were asked to indicate which of the two street view images appeared safer. By examining participants' focus on specific features using Mean Object Ratio in Highlighted Regions (MoRH) and Mean Object Hue (MoH), we identified key visual elements that attract human attention when perceiving safe environments. For instance, certain urban infrastructure and public space features draw more human attention while the sky is less relevant in influencing safety perceptions. These insights offer a more human-centered understanding of which urban features influence human safety perceptions. Furthermore, we compared the real human attention from eye-tracking systems with attention maps obtained from eXplainable Artificial Intelligence (XAI) results. Several XAI models were tested, and we observed that XGradCAM and EigenCAM most closely align with human safety perceptual patterns.",
      "author": "Yuhao Kang, Junda Chen, Liu Liu, Kshitij Sharmad, Martina Mazzarello, Simone Mora, Fabio Duarte, Carlo Ratti",
      "published_date": "2025-10-01T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 271,
      "reading_time": 1,
      "created_at": "2025-10-01T21:38:25.736207+00:00",
      "updated_at": "2025-10-01T21:38:25.736209+00:00"
    },
    {
      "id": "62e8e142ac157eefa4e4017fbeb7b007",
      "url": "https://arxiv.org/abs/2509.25383",
      "title": "Beyond the Pocket: A Large-Scale International Study on User Preferences on Bodily Placements of Commercial Wearables",
      "content": "arXiv:2509.25383v1 Announce Type: new \nAbstract: As wearable technologies continue to evolve-becoming smaller, more powerful, and more deeply embedded in daily life-their integration into diverse user contexts raises critical design challenges. There remains a notable gap in large-scale empirical data on where users actually wear or carry these devices throughout the day, systematically examining user preferences for wearable placement across varied contexts and routines. In this work, we conducted a questionnaire in several countries aimed at capturing real-world habits related to wearable device placement. The results from n = 320 participants reveal how wearable usage patterns shift depending on time of day and context. We propose a set of practical, user-centered guidelines for sensor placement and discuss how they align or diverge from assumptions seen in existing ISWC work. This study contributes to ongoing efforts within the community to design more inclusive, adaptable, and context-aware wearable systems.",
      "author": "Joanna Sorysz, Lars Krupp, Dominique Nshimyimana, Meagan B. Loerakker, Bo Zhou, Paul Lukowicz, Jakob Karolus",
      "published_date": "2025-10-01T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 146,
      "reading_time": 1,
      "created_at": "2025-10-01T21:38:25.736167+00:00",
      "updated_at": "2025-10-01T21:38:25.736170+00:00"
    },
    {
      "id": "e0e6156b7626ec83506824a14a1920f8",
      "url": "https://www.nature.com/articles/s41593-025-02056-4",
      "title": "A bottom-up septal inhibitory circuit mediates anticipatory control of drinking",
      "content": "<p>Nature Neuroscience, Published online: 22 September 2025; <a href=\"https://www.nature.com/articles/s41593-025-02056-4\">doi:10.1038/s41593-025-02056-4</a></p>Xu et al. reveal that a bottom-up neural circuit from the medial septum to the subfornical organ prevents overhydration in mice by integrating oral and gastrointestinal signals before osmolality changes, demonstrating precise drinking control mechanisms.",
      "author": "Zhong Chen",
      "published_date": "2025-09-22T00:00:00+00:00",
      "source": "Nature Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 43,
      "reading_time": 1,
      "created_at": "2025-10-01T21:38:13.229130+00:00",
      "updated_at": "2025-10-01T21:38:13.229132+00:00"
    },
    {
      "id": "c26d89d902991a3e13b4738807303d24",
      "url": "http://www.jneurosci.org/cgi/content/short/45/39/etwij45392025?rss=1",
      "title": "This Week in The Journal",
      "content": "",
      "author": "McKeon, P.",
      "published_date": "2025-09-24T16:30:28+00:00",
      "source": "Journal Neuroscience This Week",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-10-01T21:38:12.061394+00:00",
      "updated_at": "2025-10-01T21:38:12.061396+00:00"
    },
    {
      "id": "45271a80a221a35912e75ec358f4cf54",
      "url": "https://www.frontiersin.org/articles/10.3389/fninf.2025.1633273",
      "title": "Generation of synthetic TSPO PET maps from structural MRI images",
      "content": "IntroductionNeuroinflammation, a pathophysiological process involved in numerous disorders, is typically imaged using [11C]PBR28 (or TSPO) PET. However, this technique is limited by high costs and ionizing radiation, restricting its widespread clinical use. MRI, a more accessible alternative, is commonly used for structural or functional imaging, but when used using traditional approaches has limited sensitivity to specific molecular processes. This study aims to develop a deep learning model to generate TSPO PET images from structural MRI data collected in human subjects.MethodsA total of 204 scans, from participants with knee osteoarthritis (n\u202f=\u202f15 scanned once, 15 scanned twice, 14 scanned three times), back pain (n\u202f=\u202f40 scanned twice, 3 scanned three times), and healthy controls (n\u202f=\u202f28, scanned once), underwent simultaneous 3\u202fT MRI and [11C]PBR28 TSPO PET scans. A 3D U-Net model was trained on 80% of these PET-MRI pairs and validated using 5-fold cross-validation. The model\u2019s accuracy in reconstructed PET from MRI only was assessed using various intensity and noise metrics.ResultsThe model achieved a low voxel-wise mean squared error (0.0033\u202f\u00b1\u202f0.0010) across all folds and a median contrast-to-noise ratio of 0.0640\u202f\u00b1\u202f0.2500 when comparing true to reconstructed PET images. The synthesized PET images accurately replicated the spatial patterns observed in the original PET data. Additionally, the reconstruction accuracy was maintained even after spatial normalization.DiscussionThis study demonstrates that deep learning can accurately synthesize TSPO PET images from conventional, T1-weighted MRI. This approach could enable low-cost, noninvasive neuroinflammation imaging, expanding the clinical applicability of this imaging method.",
      "author": "Marco L. Loggia",
      "published_date": "2025-09-08T00:00:00+00:00",
      "source": "Frontiers Neuroinformatics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 250,
      "reading_time": 1,
      "created_at": "2025-10-01T21:38:08.018947+00:00",
      "updated_at": "2025-10-01T21:38:08.018948+00:00"
    },
    {
      "id": "fad04b7ecea4655c753545c4947e1c04",
      "url": "https://www.frontiersin.org/articles/10.3389/fncom.2025.1635497",
      "title": "Individualized connectomic tACS immediately improves oscillatory network with language facilitation in post-stroke aphasia: a feasibility study of a dysfunctome-based targeting approach",
      "content": "IntroductionPeople with post-stroke aphasia (PSA) exhibit significant interindividual variability attributed to distinctive network disruption patterns across individuals. This complexity limits the effectiveness of conventional one-size-fits-all brain stimulation approaches, but to date no individualized tACS targeting on functional network was studied in PSA. This two-phase study aimed to investigate the immediate network-modulation and language-facilitation effects of dual-site in-phase tACS utilizing a novel individualized targeting method based on individual\u2019s EEG dysfunctome.MethodsIn the first phase, network-based linear regression was used to identify aphasia-severity-predictive dysfunctome from the speech-production EEG data of 15 Cantonese-speaking people with aphasia (PWA). Individualized stimulation targets were determined using two targeting principles. Restoration-based targeting aims to restore a target edge which is centralized within the target dysfunctome but weakly-connected in the individual, whereas enhancement-based targeting selects a strongly-connected target edge. The second phase involved a single-session double-blinded sham-controlled trial with the same group to evaluate the immediate effects of dual-site 7-Hz 1-mA tACS under four conditions: Restoration In-phase (RI), Enhancement In-phase (EI), Enhancement Anti-phase (EA), and Sham (SH).ResultsIn the first phase, we explored a range of frequency bands and EEG tasks and identified a left frontal-temporal theta network under divergent naming task that significantly predicted aphasia severity. The single-session clinical trial in the second phase demonstrated that RI condition produced increases in the target node strength, global network properties, and divergent naming performance, which were absent in sham and the other two real stimulation conditions.DiscussionThis was the first-of-its-kind dysfunctome-based data-driven individualized tACS demonstrated immediate neuromodulatory effects in PSA. The findings suggest that EEG dysfunctome can help pinpointing effective individualized targets for tACS to promote clinically-beneficial functional reorganization. Despite limited generalizability due to the small sample, this methodology holds significant potential for application in longer-term treatment and other network-based disorders.",
      "author": "Mehdi Bakhtiar",
      "published_date": "2025-09-04T00:00:00+00:00",
      "source": "Frontiers Computational Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 289,
      "reading_time": 1,
      "created_at": "2025-10-01T21:38:06.629930+00:00",
      "updated_at": "2025-10-01T21:38:06.629932+00:00"
    },
    {
      "id": "4566cf0c67737b27ff857fbf1d161c0a",
      "url": "https://www.frontiersin.org/articles/10.3389/fncom.2025.1693327",
      "title": "Editorial: Advancements in smart diagnostics for understanding neurological behaviors and biosensing applications",
      "content": "",
      "author": "Zohaib Mushtaq",
      "published_date": "2025-09-16T00:00:00+00:00",
      "source": "Frontiers Computational Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-10-01T21:38:06.629868+00:00",
      "updated_at": "2025-10-01T21:38:06.629869+00:00"
    },
    {
      "id": "3e7bf711d4561e3b8600bf8f1ba15bb5",
      "url": "https://www.frontiersin.org/articles/10.3389/fnbot.2025.1628968",
      "title": "Tri-manual interaction in hybrid BCI-VR systems: integrating gaze, EEG control for enhanced 3D object manipulation",
      "content": "Brain-computer interface (BCI) integration with virtual reality (VR) has progressed from single-limb control to multi-limb coordination, yet achieving intuitive tri-manual operation remains challenging. This study presents a consumer-grade hybrid BCI-VR framework enabling simultaneous control of two biological hands and a virtual third limb through integration of Tobii eye-tracking, NeuroSky single-channel EEG, and non-haptic controllers. The system employs e-Sense attention thresholds (>80% for 300\u202fms) to trigger virtual hand activation combined with gaze-driven targeting within 45\u00b0 visual cones. A soft maximum weighted arbitration algorithm resolves spatiotemporal conflicts between manual and virtual inputs with 92.4% success rate. Experimental validation with eight participants across 160 trials demonstrated 87.5% virtual hand success rate and 41% spatial error reduction (\u03c3\u202f=\u202f0.23\u202fmm vs. 0.39\u202fmm) compared to traditional dual-hand control. The framework achieved 320\u202fms activation latency and 22% NASA-TLX workload reduction through adaptive cognitive load management. Time-frequency analysis revealed characteristic beta-band (15-20\u202fHz) energy modulations during successful virtual limb control, providing neurophysiological evidence for attention-mediated supernumerary limb embodiment. These findings demonstrate that sophisticated algorithmic approaches can compensate for consumer-grade hardware limitations, enabling laboratory-grade precision in accessible tri-manual VR applications for rehabilitation, training, and assistive technologies.",
      "author": "Shaw-mung Lee",
      "published_date": "2025-08-14T00:00:00+00:00",
      "source": "Frontiers Neurorobotics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 192,
      "reading_time": 1,
      "created_at": "2025-10-01T21:38:04.106071+00:00",
      "updated_at": "2025-10-01T21:38:04.106072+00:00"
    },
    {
      "id": "b37600dbebfb0a6b3e72dfb91ae19e22",
      "url": "https://www.frontiersin.org/articles/10.3389/fnbot.2025.1643919",
      "title": "4D trajectory lightweight prediction algorithm based on knowledge distillation technique",
      "content": "IntroductionTo address the challenges of current 4D trajectory prediction\u2014specifically, limited multi-factor feature extraction and excessive computational cost\u2014this study develops a lightweight prediction framework tailored for real-time air-traffic management.MethodsWe propose a hybrid RCBAM\u2013TCN\u2013LSTM architecture enhanced with a teacher\u2013student knowledge distillation mechanism. The Residual Convolutional Block Attention Module (RCBAM) serves as the teacher network to extract high-dimensional spatial features via residual structures and channel\u2013spatial attention. The student network adopts a Temporal Convolutional Network\u2013LSTM (TCN\u2013LSTM) design, integrating dilated causal convolutions and two LSTM layers for efficient temporal modeling. Historical ADS-B trajectory data from Zhuhai Jinwan Airport are preprocessed using cubic spline interpolation and a uniform-step sliding window to ensure data alignment and temporal consistency. In the distillation process, soft labels from the teacher and hard labels from actual observations jointly guide student trainingResultsIn multi-step prediction experiments, the distilled RCBAM\u2013TCN\u2013LSTM model achieved average reductions of 40%\u201360% in MAE, RMSE, and MAPE compared with the original RCBAM and TCN\u2013LSTM models, while improving R\u00b2 by 4%\u20136%. The approach maintained high accuracy across different prediction horizons while reducing computational complexity.DiscussionThe proposed method effectively balances high-precision modeling of spatiotemporal dependencies with lightweight deployment requirements, enabling real-time air-traffic monitoring and early warning on standard CPUs and embedded devices. This framework offers a scalable solution for enhancing the operational safety and efficiency of modern air-traffic control systems.",
      "author": "Weizheng Xie",
      "published_date": "2025-08-22T00:00:00+00:00",
      "source": "Frontiers Neurorobotics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 217,
      "reading_time": 1,
      "created_at": "2025-10-01T21:38:04.106035+00:00",
      "updated_at": "2025-10-01T21:38:04.106037+00:00"
    },
    {
      "id": "ab614dfd3650460cf66ec724ffb0888c",
      "url": "https://www.frontiersin.org/articles/10.3389/fnbot.2025.1562675",
      "title": "Variable admittance control with sEMG-based support for wearable wrist exoskeleton",
      "content": "IntroductionWrist function impairment is common after stroke and heavily impacts the execution of daily tasks. Robotic therapy, and more specifically wearable exoskeletons, have the potential to boost training dose in context-relevant scenarios, promote voluntary effort through motor intent detection, and mitigate the effect of gravity. Portable exoskeletons are often non-backdrivable and it is challenging to make their control safe, reactive and stable. Admittance control is often used in this case, however, this type of control can become unstable when the supported biological joint stiffens. Variable admittance control adapts its parameters dynamically to allow free motion and stabilize the human-robot interaction.MethodsIn this study, we implemented a variable admittance control scheme on a one degree of freedom wearable wrist exoskeleton. The damping parameter of the admittance scheme is adjusted in real-time to cope with instabilities and varying wrist stiffness. In addition to the admittance control scheme, sEMG- and gravity-based controllers were implemented, characterized and optimized on ten healthy participants and tested on six stroke survivors.ResultsThe results show that (1) the variable admittance control scheme could stabilize the interaction but at the cost of a decrease in transparency, and (2) when coupled with the variable admittance controller the sEMG-based control enhanced wrist functionality of stroke survivors in the most extreme angular positions.DiscussionOur variable admittance control scheme with sEMG- and gravity-based support was most beneficial for patients with higher levels of impairment by improving range of motion and promoting voluntary effort. Future work could combine both controllers to customize and fine tune the stability of the support to a wider range of impairment levels and types.",
      "author": "Nicole Wenderoth",
      "published_date": "2025-09-01T00:00:00+00:00",
      "source": "Frontiers Neurorobotics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 262,
      "reading_time": 1,
      "created_at": "2025-10-01T21:38:04.105994+00:00",
      "updated_at": "2025-10-01T21:38:04.105995+00:00"
    },
    {
      "id": "9682f89977500b89d77892cf60cd12a3",
      "url": "https://www.frontiersin.org/articles/10.3389/fnbot.2025.1649870",
      "title": "Imitation-relaxation reinforcement learning for sparse badminton strikes via dynamic trajectory generation",
      "content": "Robotic racket sports provide exceptional benchmarks for evaluating dynamic motion control capabilities in robots. Due to the highly non-linear dynamics of the shuttlecock, the stringent demands on robots' dynamic responses, and the convergence difficulties caused by sparse rewards in reinforcement learning, badminton strikes remain a formidable challenge for robot systems. To address these issues, this study proposes DTG-IRRL, a novel learning framework for badminton strikes that integrates imitation-relaxation reinforcement learning with dynamic trajectory generation. The framework demonstrates significantly improved training efficiency and performance, achieving faster convergence and twice the landing accuracy. Analysis of the reward function within a specific parameter space hyperplane intuitively reveals the convergence difficulties arising from the inherent sparsity of rewards in racket sports and demonstrates the framework's effectiveness in mitigating local and slow convergence. Implemented on hardware with zero-shot transfer, the framework achieves a 90% hitting rate and a 70% landing accuracy, enabling sustained humanrobot rallies. Cross-platform validation using the UR5 robot demonstrates the framework's generalizability while highlighting the requirement for high dynamic performance of robotic arms in racket sports.",
      "author": "Hongtao Wang",
      "published_date": "2025-09-02T00:00:00+00:00",
      "source": "Frontiers Neurorobotics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 174,
      "reading_time": 1,
      "created_at": "2025-10-01T21:38:04.105957+00:00",
      "updated_at": "2025-10-01T21:38:04.105958+00:00"
    },
    {
      "id": "c0c560fa0b8a654d8295d2214702b7b7",
      "url": "https://www.frontiersin.org/articles/10.3389/fnbot.2025.1633697",
      "title": "RSA-TransUNet: a robust structure-adaptive TransUNet for enhanced road crack segmentation",
      "content": "With the advancement of deep learning, road crack segmentation has become increasingly crucial for intelligent transportation safety. Despite notable progress, existing methods still face challenges in capturing fine-grained textures in small crack regions, handling blurred edges and significant width variations, and performing multi-class segmentation. Moreover, the high computational cost of training such models hinders their practical deployment. To tackle these limitations, we propose RSA-TransUNet, a novel model for road crack segmentation. At its core is the Axial-shift MLP Attention (ASMA) mechanism, which integrates axial perception with sparse contextual modeling. Through multi-path axial perturbations and an attention-guided structure, ASMA effectively captures long-range dependencies within row-column patterns, enabling detailed modeling of multi-scale crack features. To improve the model\u2019s adaptability to structural irregularities, we introduce the Adaptive Spline Linear Unit (ASLU), which enhances the model\u2019s capacity to represent nonlinear transformations. ASLU improves responsiveness to microstructural variations, morphological distortions, and local discontinuities, thereby boosting robustness across different domains. We further develop a Structure-aware Multi-stage Evolutionary Optimization (SMEO) strategy, which guides the training process through three phases: structural perception exploration, feature stability enhancement, and global perturbation. This strategy combines breadth sampling, convergence compression, and local escape mechanisms to improve convergence speed, global search efficiency, and generalization performance. Extensive evaluations on the Crack500, CFD, and DeepCrack datasets\u2014including ablation studies and comparative experiments\u2014demonstrate that RSA-TransUNet achieves superior segmentation accuracy and robustness in complex road environments, highlighting its potential for real-world applications.",
      "author": "Ruoli Yang",
      "published_date": "2025-09-16T00:00:00+00:00",
      "source": "Frontiers Neurorobotics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 234,
      "reading_time": 1,
      "created_at": "2025-10-01T21:38:04.105848+00:00",
      "updated_at": "2025-10-01T21:38:04.105850+00:00"
    },
    {
      "id": "7dae0ba536b1bad2078670456df0b8f7",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38873838/?utm_source=BucketBot&utm_medium=rss&utm_campaign=None&utm_content=1BUB2BG5RbxOblm-hBbiJWEhGG43qlVrvGNHOTqBKva9wWrItM&fc=None&ff=20251001173758&v=2.18.0.post9+e462414",
      "title": "The impact of CSF-filled cavities on scalp EEG and its implications",
      "content": "Previous studies have found electroencephalogram (EEG) amplitude and scalp topography differences between neurotypical and neurological/neurosurgical groups, being interpreted at the cognitive level. However, these comparisons are invariably accompanied by anatomical changes. Critical to EEG are the so-called volume currents, which are affected by the spatial distribution of the different tissues in the head. We investigated the effect of cerebrospinal fluid (CSF)-filled cavities on simulated...",
      "author": "Maria Carla Piastra",
      "published_date": "2024-06-14T10:00:00+00:00",
      "source": "Oostenveld Robert",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 64,
      "reading_time": 1,
      "created_at": "2025-10-01T21:37:59.462647+00:00",
      "updated_at": "2025-10-01T21:37:59.462649+00:00"
    }
  ]
}