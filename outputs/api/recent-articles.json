{
  "last_updated": "2025-12-21T19:17:35.169892+00:00",
  "count": 20,
  "articles": [
    {
      "id": "69ceb5d0ae1566822317d810b29f30a6",
      "url": "https://www.reddit.com/r/Python/comments/1psb6fh/i_built_a_terminalnative_sql_playground_to/",
      "title": "I built a terminal-native SQL playground to understand DBMS internals better",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>While using SQL*Plus in my college labs, I realized something\u2014I actually liked working with SQL directly from the terminal. It felt close to the system. But it also felt limiting. You run a query, get results, and everything in between is a black box.</p> <p>So I decided to build TermiBase.</p> <p>It\u2019s a terminal-native SQL playground focused on learning and transparency. You can run SQL queries and see how they are parsed and logically executed step by step, all inside the terminal. It\u2019s not a full DBMS\u2014more of an educational sandbox to understand what really happens under the hood. The project is still evolving, but it\u2019s usable now and open for anyone to try. I\u2019ll be actively updating it and improving the execution explanations over time.</p> <p>Sharing it here in case it\u2019s useful to others who enjoy terminal workflows or are learning databases.</p> <p>Github \ud83d\udd17: <a href=\"https://github.com/tejgokani/TermiBase\">https://github.com/tejgokani/TermiBase</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/mr_vengeance_72\"> /u/mr_vengeance_72 </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1psb6fh/i_built_a_terminalnative_sql_playground_to/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1psb6fh/i_built_a_terminalnative_sql_playground_to/\">[comments]</a></span>",
      "author": "/u/mr_vengeance_72",
      "published_date": "2025-12-21T16:57:54+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 167,
      "reading_time": 1,
      "created_at": "2025-12-21T19:16:30.787351+00:00",
      "updated_at": "2025-12-21T19:16:30.787353+00:00"
    },
    {
      "id": "29928e3e4c82ed79301ab4a358c61963",
      "url": "https://news.ycombinator.com/item?id=46309463",
      "title": "FWS \u2013 pip-installable embedded process supervisor with PTY/pipe/dtach back ends",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46309463\">Comments</a>",
      "author": "",
      "published_date": "2025-12-18T06:19:32+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-21T19:16:29.596256+00:00",
      "updated_at": "2025-12-21T19:16:29.596258+00:00"
    },
    {
      "id": "d7d2e8e77f0c2b74aa4b21ce10440f8d",
      "url": "https://mastodon.online/@mullvadnet/115742530333573065",
      "title": "Mullvad VPN: \"This is a Chat Control 3.0 attempt.\"",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46347080\">Comments</a>",
      "author": "",
      "published_date": "2025-12-21T18:39:46+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-21T19:16:29.596165+00:00",
      "updated_at": "2025-12-21T19:16:29.596166+00:00"
    },
    {
      "id": "906e360d767c918ff021540845d67cad",
      "url": "https://oldmanrahul.com/2025/12/19/ai-code-review-trick/",
      "title": "Get an AI code review in 10 seconds",
      "content": "<p>Article URL: <a href=\"https://oldmanrahul.com/2025/12/19/ai-code-review-trick/\">https://oldmanrahul.com/2025/12/19/ai-code-review-trick/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46346391\">https://news.ycombinator.com/item?id=46346391</a></p>\n<p>Points: 8</p>\n<p># Comments: 3</p>",
      "author": "oldmanrahul",
      "published_date": "2025-12-21T17:21:05+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-21T19:16:28.257468+00:00",
      "updated_at": "2025-12-21T19:16:28.257469+00:00"
    },
    {
      "id": "29254a34b24cbec8b5f22643b0e1c2c6",
      "url": "https://neilthanedar.com/youre-not-burnt-out-youre-existentially-starving/",
      "title": "You're Not Burnt Out. You're Existentially Starving",
      "content": "<p>Article URL: <a href=\"https://neilthanedar.com/youre-not-burnt-out-youre-existentially-starving/\">https://neilthanedar.com/youre-not-burnt-out-youre-existentially-starving/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46346958\">https://news.ycombinator.com/item?id=46346958</a></p>\n<p>Points: 5</p>\n<p># Comments: 4</p>",
      "author": "thanedar",
      "published_date": "2025-12-21T18:28:56+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-21T19:16:28.257389+00:00",
      "updated_at": "2025-12-21T19:16:28.257390+00:00"
    },
    {
      "id": "d7d2e8e77f0c2b74aa4b21ce10440f8d",
      "url": "https://mastodon.online/@mullvadnet/115742530333573065",
      "title": "Mullvad VPN: \"This is a Chat Control 3.0 attempt.\"",
      "content": "<p>Article URL: <a href=\"https://mastodon.online/@mullvadnet/115742530333573065\">https://mastodon.online/@mullvadnet/115742530333573065</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46347080\">https://news.ycombinator.com/item?id=46347080</a></p>\n<p>Points: 51</p>\n<p># Comments: 6</p>",
      "author": "janandonly",
      "published_date": "2025-12-21T18:39:46+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-21T19:16:28.257367+00:00",
      "updated_at": "2025-12-21T19:16:28.257369+00:00"
    },
    {
      "id": "bd9c8f2d27dbdfebab4a0351a6b09761",
      "url": "https://idiallo.com/byte-size/cant-update-to-windows-11-leave-me-alone",
      "title": "I can't upgrade to Windows 11, now leave me alone",
      "content": "<p>Article URL: <a href=\"https://idiallo.com/byte-size/cant-update-to-windows-11-leave-me-alone\">https://idiallo.com/byte-size/cant-update-to-windows-11-leave-me-alone</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46347108\">https://news.ycombinator.com/item?id=46347108</a></p>\n<p>Points: 10</p>\n<p># Comments: 0</p>",
      "author": "firefoxd",
      "published_date": "2025-12-21T18:43:20+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-21T19:16:28.257339+00:00",
      "updated_at": "2025-12-21T19:16:28.257345+00:00"
    },
    {
      "id": "6b32e4bd1febbf92414c4c81f976455e",
      "url": "https://loggingsucks.com/",
      "title": "Logging Sucks",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46346796\">Comments</a>",
      "author": "",
      "published_date": "2025-12-21T18:09:52+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-21T18:51:12.610869+00:00",
      "updated_at": "2025-12-21T18:51:12.610872+00:00"
    },
    {
      "id": "30e3c288e55678b0ee1be353b75c28e8",
      "url": "https://spectrum.ieee.org/co2-battery-energy-storage",
      "title": "CO2 Batteries That Store Grid Energy Take Off Globally",
      "content": "<p>Article URL: <a href=\"https://spectrum.ieee.org/co2-battery-energy-storage\">https://spectrum.ieee.org/co2-battery-energy-storage</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46345506\">https://news.ycombinator.com/item?id=46345506</a></p>\n<p>Points: 10</p>\n<p># Comments: 0</p>",
      "author": "rbanffy",
      "published_date": "2025-12-21T15:27:36+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-21T18:51:11.271725+00:00",
      "updated_at": "2025-12-21T18:51:11.271727+00:00"
    },
    {
      "id": "d645e0391a4f4b384298dba03aee6b95",
      "url": "https://coloradosun.com/2025/12/19/monastery-sells-palantir-ceo/",
      "title": "Mountain home near Aspen, built for monks, sold to Palantir CEO for $120M",
      "content": "<p>Article URL: <a href=\"https://coloradosun.com/2025/12/19/monastery-sells-palantir-ceo/\">https://coloradosun.com/2025/12/19/monastery-sells-palantir-ceo/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46346536\">https://news.ycombinator.com/item?id=46346536</a></p>\n<p>Points: 27</p>\n<p># Comments: 5</p>",
      "author": "mooreds",
      "published_date": "2025-12-21T17:38:48+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-21T18:51:11.271587+00:00",
      "updated_at": "2025-12-21T18:51:11.271588+00:00"
    },
    {
      "id": "6b32e4bd1febbf92414c4c81f976455e",
      "url": "https://loggingsucks.com/",
      "title": "Logging Sucks",
      "content": "<p>Article URL: <a href=\"https://loggingsucks.com/\">https://loggingsucks.com/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46346796\">https://news.ycombinator.com/item?id=46346796</a></p>\n<p>Points: 24</p>\n<p># Comments: 3</p>",
      "author": "FlorinSays",
      "published_date": "2025-12-21T18:09:52+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-21T18:51:11.271567+00:00",
      "updated_at": "2025-12-21T18:51:11.271569+00:00"
    },
    {
      "id": "127e50a59f81d7f144d3bfcdd8f59dc1",
      "url": "https://www.latimes.com/california/story/2025-12-17/day-laborers-protest-noise-machines-home-depot",
      "title": "Day laborers protest noise machines installed at Home Depot",
      "content": "<p>Article URL: <a href=\"https://www.latimes.com/california/story/2025-12-17/day-laborers-protest-noise-machines-home-depot\">https://www.latimes.com/california/story/2025-12-17/day-laborers-protest-noise-machines-home-depot</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46346886\">https://news.ycombinator.com/item?id=46346886</a></p>\n<p>Points: 8</p>\n<p># Comments: 0</p>",
      "author": "geox",
      "published_date": "2025-12-21T18:19:54+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-21T18:51:11.271545+00:00",
      "updated_at": "2025-12-21T18:51:11.271546+00:00"
    },
    {
      "id": "90145c6d925dd8f824fd15af93a03600",
      "url": "https://www.sfgate.com/bayarea/article/waymo-temporarily-suspends-service-sf-amid-power-21254917.php",
      "title": "Waymo temporarily suspends service in SF amid power outage",
      "content": "<p>Article URL: <a href=\"https://www.sfgate.com/bayarea/article/waymo-temporarily-suspends-service-sf-amid-power-21254917.php\">https://www.sfgate.com/bayarea/article/waymo-temporarily-suspends-service-sf-amid-power-21254917.php</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46346930\">https://news.ycombinator.com/item?id=46346930</a></p>\n<p>Points: 6</p>\n<p># Comments: 1</p>",
      "author": "pilingual",
      "published_date": "2025-12-21T18:25:20+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-21T18:51:11.271483+00:00",
      "updated_at": "2025-12-21T18:51:11.271517+00:00"
    },
    {
      "id": "951df1640c5c8172a766ff9895f8231f",
      "url": "https://www.reddit.com/r/Python/comments/1psab2c/i_built_a_python_bytecode_decompiler_covering/",
      "title": "I built a Python bytecode decompiler covering Python 1.0\u20133.14, runs on Node.js",
      "content": "<!-- SC_OFF --><div class=\"md\"><p><strong>What My Project Does</strong></p> <p>depyo is a Python bytecode decompiler that converts .pyc files back to readable Python source. It covers Python versions from 1.0 through 3.14, including modern features:</p> <p>- Pattern matching (match/case)</p> <p>- Exception groups (except*)</p> <p>- Walrus operator (:=)</p> <p>- F-strings</p> <p>- Async/await</p> <p>Quick start:</p> <pre><code>npx depyo file.pyc </code></pre> <p><strong>Target Audience</strong></p> <p>- Security researchers doing malware analysis or reverse engineering</p> <p>- Developers recovering lost source code from .pyc files</p> <p>- Anyone working with legacy Python codebases (yes, Python 1.x still exists in the wild)</p> <p>- CTF players and educators</p> <p>This is a production-ready tool, not a toy project. It has a full test suite covering all supported Python versions.</p> <p><strong>Comparison</strong></p> <table><thead> <tr> <th align=\"left\">Tool</th> <th align=\"left\">Versions</th> <th align=\"left\">Modern features</th> <th align=\"left\">Runtime</th> </tr> </thead><tbody> <tr> <td align=\"left\">depyo</td> <td align=\"left\">1.0\u20133.14</td> <td align=\"left\">Yes (match, except*, f-strings)</td> <td align=\"left\">Node.js</td> </tr> <tr> <td align=\"left\">uncompyle6/decompyle3</td> <td align=\"left\">2.x\u20133.12</td> <td align=\"left\">Partial</td> <td align=\"left\">Python</td> </tr> <tr> <td align=\"left\">pycdc</td> <td align=\"left\">2.x\u20133.x</td> <td align=\"left\">Limited</td> <td align=\"left\">C++</td> </tr> </tbody></table> <p>Main advantages:</p> <p>- Widest version coverage (30 years of Python)</p> <p>- No Python dependency - useful when decompiling old .pyc without version conflicts</p> <p>- Fast (~0.1ms per file)</p> <p>GitHub: <a href=\"https://github.com/skuznetsov/depyo.js\">https://github.com/skuznetsov/depyo.js</a></p> <p>Would love feedback, especially on edge cases!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ComputerMagych\"> /u/ComputerMagych </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1psab2c/i_built_a_python_bytecode_decompiler_covering/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1psab2c/i_built_a_python_bytecode_decompiler_covering/\">[comments]</a></span>",
      "author": "/u/ComputerMagych",
      "published_date": "2025-12-21T16:21:22+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 219,
      "reading_time": 1,
      "created_at": "2025-12-21T18:29:30.084792+00:00",
      "updated_at": "2025-12-21T18:29:30.084794+00:00"
    },
    {
      "id": "69f05ae1fe4e75df8fe54557f7460e5c",
      "url": "https://www.reddit.com/r/Python/comments/1psbzod/rug_0130_released/",
      "title": "rug 0.13.0 released",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>What's rug library:</p> <p>Library for fetching various stock data from the internet (official and unofficial APIs).</p> <p>Source code:</p> <p><a href=\"https://gitlab.com/imn1/rug\">https://gitlab.com/imn1/rug</a></p> <p>Releases including changelog:</p> <p><a href=\"https://gitlab.com/imn1/rug/-/releases\">https://gitlab.com/imn1/rug/-/releases</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/n1___\"> /u/n1___ </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1psbzod/rug_0130_released/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1psbzod/rug_0130_released/\">[comments]</a></span>",
      "author": "/u/n1___",
      "published_date": "2025-12-21T17:31:21+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 46,
      "reading_time": 1,
      "created_at": "2025-12-21T18:29:30.084754+00:00",
      "updated_at": "2025-12-21T18:29:30.084755+00:00"
    },
    {
      "id": "0dc5477bac0197cc967ddd88c3a6cd07",
      "url": "https://www.reddit.com/r/Python/comments/1ps39bq/how_far_into_a_learning_project_do_you_go/",
      "title": "How far into a learning project do you go",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>As a SWE student, it always feels like a race against my peers to land a job. Lately, though, web development has started to feel a bit boring for me and this new project, a custom text editor has been really fun and refreshing.</p> <p>Each new feature I add exposes really interesting problems and design concepts that I will never learn with web dev, and there\u2019s still so much I could implement or optimize. But I can\u2019t help but wonder, how do you know when a project has taken too much of your time and effort? A text editor might not sound impressive on a resume, but the learning experience has been huge.</p> <p>Would love to hear if anyone else has felt the same, or how you decide when to stick with a for fun learning project versus move on to something \u201cmore career-relevant.\u201d</p> <p>Here is the git hub: <a href=\"https://github.com/mihoagg/text_editor\">https://github.com/mihoagg/text_editor</a><br /> Any code review or tips are also much appreciated. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/getrice\"> /u/getrice </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1ps39bq/how_far_into_a_learning_project_do_you_go/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1ps39bq/how_far_into_a_learning_project_do_you_go/\">[comments]</a></span>",
      "author": "/u/getrice",
      "published_date": "2025-12-21T10:11:37+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 183,
      "reading_time": 1,
      "created_at": "2025-12-21T18:29:30.084730+00:00",
      "updated_at": "2025-12-21T18:29:30.084732+00:00"
    },
    {
      "id": "59e1d6d7ab76087f5ecda62e2bde13b6",
      "url": "https://www.reddit.com/r/Python/comments/1ps7gs4/whats_stopping_us_from_having_full_static/",
      "title": "What's stopping us from having full static validation of Python code?",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>I have developed two mypy plugins for Python to help with static checks (<a href=\"https://github.com/diegojromerolopez/mypy-pure\">mypy-pure</a> and <a href=\"https://github.com/diegojromerolopez/mypy-raise\">mypy-raise</a>)</p> <p>I was wondering, how far are we with providing such a high level of static checks for interpreted languages that almost all issues can be catch statically? Is there any work on that on any interpreted programming language, especially Python? What are the static tools that you are using in your Python projects?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/diegojromerolopez\"> /u/diegojromerolopez </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1ps7gs4/whats_stopping_us_from_having_full_static/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1ps7gs4/whats_stopping_us_from_having_full_static/\">[comments]</a></span>",
      "author": "/u/diegojromerolopez",
      "published_date": "2025-12-21T14:14:29+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 92,
      "reading_time": 1,
      "created_at": "2025-12-21T18:29:30.084692+00:00",
      "updated_at": "2025-12-21T18:29:30.084694+00:00"
    },
    {
      "id": "35cf8b93e74f04482a656d6bf2edece0",
      "url": "https://www.reddit.com/r/Python/comments/1ps1ab5/i_built_a_desktop_app_with_pythons_batteries/",
      "title": "I built a desktop app with Python's \"batteries included\" - Tkinter, SQLite, and minor soldering",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>Hi all. I work in a mass spectrometry laboratory at a large hospital in Rome, Italy. We analyze drugs, drugs of abuse, and various substances. I'm also a programmer.</p> <p>**What My Project Does**</p> <p>Inventarium is a laboratory inventory management system. It tracks reagents, consumables, and supplies through the full lifecycle: Products \u2192 Packages (SKUs) \u2192 Batches (lots) \u2192 Labels (individual items with barcodes).</p> <p>Features:</p> <p>- Color-coded stock levels (red/orange/green)</p> <p>- Expiration tracking with days countdown</p> <p>- Barcode scanning for quick unload</p> <p>- Purchase requests workflow</p> <p>- Statistics dashboard</p> <p>- Multi-language (IT/EN/ES)</p> <p>**Target Audience**</p> <p>Small laboratories, research facilities, or anyone needing to track consumables with expiration dates. It's a working tool we use daily - not a tutorial project.</p> <p>**What makes it interesting**</p> <p>I challenged myself to use only Python's &quot;batteries included&quot;:</p> <p>- Tkinter + ttk (GUI)</p> <p>- SQLite (database)</p> <p>- configparser, datetime, os, sys...</p> <p>External dependencies: just Pillow and python-barcode. No Electron, no web framework, no 500MB node_modules.</p> <p>**Screenshots:**</p> <p>- :Dashboard: <a href=\"https://ibb.co/JF2vmbmC\">https://ibb.co/JF2vmbmC</a></p> <p>- Warehouse: <a href=\"https://ibb.co/HTSqHF91\">https://ibb.co/HTSqHF91</a></p> <p>**GitHub:** <a href=\"https://github.com/1966bc/inventarium\">https://github.com/1966bc/inventarium</a></p> <p>Happy to answer questions or hear criticism. Both are useful.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Aggravating-Pain-626\"> /u/Aggravating-Pain-626 </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1ps1ab5/i_built_a_desktop_app_with_pythons_batteries/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1ps1ab5/i_built_a_desktop_app_with_pythons_batteries/\">[comments]</a></span>",
      "author": "/u/Aggravating-Pain-626",
      "published_date": "2025-12-21T08:01:25+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 201,
      "reading_time": 1,
      "created_at": "2025-12-21T18:29:30.084660+00:00",
      "updated_at": "2025-12-21T18:29:30.084664+00:00"
    },
    {
      "id": "e1fa2e76d69cec3266f32e5ca1f4c7d7",
      "url": "https://techcrunch.com/2025/12/21/waymo-suspends-service-in-san-francisco-as-robotaxis-stall-during-blackout/",
      "title": "Waymo suspends service in San Francisco as robotaxis stall during blackout",
      "content": "<p>Article URL: <a href=\"https://techcrunch.com/2025/12/21/waymo-suspends-service-in-san-francisco-as-robotaxis-stall-during-blackout/\">https://techcrunch.com/2025/12/21/waymo-suspends-service-in-san-francisco-as-robotaxis-stall-during-blackout/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46346510\">https://news.ycombinator.com/item?id=46346510</a></p>\n<p>Points: 17</p>\n<p># Comments: 4</p>",
      "author": "SilverElfin",
      "published_date": "2025-12-21T17:35:44+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-21T18:29:27.540195+00:00",
      "updated_at": "2025-12-21T18:29:27.540205+00:00"
    },
    {
      "id": "80d1f642eb4da0958753076107ac0cbe",
      "url": "http://daniellakens.blogspot.com/2025/07/easily-download-files-from-open-science.html",
      "title": "Easily download files from the Open Science Framework with Papercheck",
      "content": "<p>Researchers\nincreasingly use the <a href=\"https://osf.io/\">Open Science Framework</a> (OSF) to share files, such as data\nand code underlying scientific publications, or presentations and materials for\nscientific workshops. The OSF is an amazing service that has contributed\nimmensely to a changed research culture where psychologists share data, code, and\nmaterials. We are very grateful it exists.</p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">But it is\nnot always the most user-friendly. Specifically, downloading files from the OSF\nis a bigger hassle than we (<a href=\"https://debruine.github.io/\">Lisa DeBruine</a>\nand <a href=\"https://www.tue.nl/en/research/researchers/daniel-lakens/\">Daniel\nLakens</a>, the developers of Papercheck) would like it to be. Downloading individual\nfiles is so complex, <a href=\"https://bsky.app/profile/malte.the100.ci/post/3lpf4s6spns2i\">Malte Elson</a>\nrecently posted this meme on Bluesky. </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"NL\"><!--[if gte vml 1]><v:shapetype\n id=\"_x0000_t75\" coordsize=\"21600,21600\" o:spt=\"75\" o:preferrelative=\"t\"\n path=\"m@4@5l@4@11@9@11@9@5xe\" filled=\"f\" stroked=\"f\">\n <v:stroke joinstyle=\"miter\"/>\n <v:formulas>\n  <v:f eqn=\"if lineDrawn pixelLineWidth 0\"/>\n  <v:f eqn=\"sum @0 1 0\"/>\n  <v:f eqn=\"sum 0 0 @1\"/>\n  <v:f eqn=\"prod @2 1 2\"/>\n  <v:f eqn=\"prod @3 21600 pixelWidth\"/>\n  <v:f eqn=\"prod @3 21600 pixelHeight\"/>\n  <v:f eqn=\"sum @0 0 1\"/>\n  <v:f eqn=\"prod @6 1 2\"/>\n  <v:f eqn=\"prod @7 21600 pixelWidth\"/>\n  <v:f eqn=\"sum @8 21600 0\"/>\n  <v:f eqn=\"prod @7 21600 pixelHeight\"/>\n  <v:f eqn=\"sum @10 21600 0\"/>\n </v:formulas>\n <v:path o:extrusionok=\"f\" gradientshapeok=\"t\" o:connecttype=\"rect\"/>\n <o:lock v:ext=\"edit\" aspectratio=\"t\"/>\n</v:shapetype><v:shape id=\"_x0000_i1026\" type=\"#_x0000_t75\" style='width:453.75pt;\n height:276pt;visibility:visible;mso-wrap-style:square'>\n <v:imagedata src=\"file:///C:/Users/DLakens/AppData/Local/Temp/msohtmlclip1/01/clip_image001.jpg\"\n  o:title=\"\"/>\n</v:shape><![endif]--><!--[if !vml]--><img border=\"0\" height=\"368\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEinS5tFoL5qX14Z2OcgT1APMZLGlghAD3BfBhSnJ9pleVbJyRFUFLShqReS2j7SXGozmLMcVQkoM62UhneJDtH4yx3NRnXOkVZZi-Dm-OPwbGaidxr2raF9wzjx5fU92nfPpE3jmGfwZEwHS1WGSB4gUfRfV3XWjOC2-lCjOYR108h3fwORIHOnqxIX9m8\" width=\"605\" /><!--[endif]--></span><span lang=\"EN-US\"></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\"><span>&nbsp;</span></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">Not only is\nthe download button for files difficult to find, but downloading all files\nrelated to a project can be surprisingly effortful. It is possible to download\nall files in a zip folder that will be called \u2018osfstorage-archive.zip\u2019 when\ndownloaded. But as the OSF supports a nested folder structure, you might miss a\nfolder, and you will quickly end up with \u2018osfstorage-archive (1).zip\u2019, \u2018osfstorage-archive\n(2).zip\u2019, etc. Unzipping these archives creates a lot of files without the\norganized folder structure, in folders with meaningless names, making it\ndifficult to understand where files are. </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<h2 style=\"text-align: left;\"><b><span lang=\"EN-US\">The\nosf_file_download function in Papercheck </span></b></h2>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">We have added\na new function to our R package \u2018<a href=\"https://scienceverse.github.io/papercheck/\">Papercheck</a>\u2019 that will download all files and\nfolders in an OSF repository. It saves all files by recreating the folder\nstructure from the OSF in your download folder. Just install Papercheck, load\nthe library, and use the osf_file_download function to grab all files on the OSF:</span></p><p class=\"MsoNormal\"><span lang=\"EN-US\"><br /></span></p>\n\n<div style=\"text-align: left;\"><span style=\"font-family: courier;\"><b><span lang=\"EN-US\">devtools::install_github(\"scienceverse/papercheck\")<br /></span></b><b><span lang=\"EN-US\">library(papercheck)<br /></span></b><b><span lang=\"EN-US\">osf_file_download(\"6nt4v\")</span></b></span></div>\n\n\n\n\n\n<p class=\"MsoNormal\"><b><span lang=\"EN-US\">&nbsp;</span></b></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">All files\nwill be downloaded to your working directory. </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">Are you feeling\nFOMO for missing out on the <a href=\"https://www.kcl.ac.uk/events/open-research-summer-school-2025\">King Open\nResearch Summer School</a> that is going on these days, where <a href=\"https://research.tue.nl/en/persons/sajedeh-rasti\">Sajedeh Rasti</a> talked\nabout Preregistration, and <a href=\"https://research.tue.nl/en/persons/cristian-mesquida-caldentey\">Cristian\nMesquida</a> will give a workshop on using Papercheck? Well, at least it is\nvery easy to download all the files they have shared on the OSF and look at the\npresentations: </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\"><span style=\"font-family: courier;\">osf_file_download(\"b7es8\")</span></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">In the\noutput, we see that by default large files (more than 10mb) are omitted. <span><!--[if gte vml 1]><v:shape id=\"Picture_x0020_1\"\n o:spid=\"_x0000_i1025\" type=\"#_x0000_t75\" alt=\"A screenshot of a computer&#10;&#10;AI-generated content may be incorrect.\"\n style='width:453.75pt;height:292.5pt;visibility:visible;mso-wrap-style:square'>\n <v:imagedata src=\"file:///C:/Users/DLakens/AppData/Local/Temp/msohtmlclip1/01/clip_image003.png\"\n  o:title=\"A screenshot of a computer&#10;&#10;AI-generated content may be incorrect\"/>\n</v:shape><![endif]--><!--[if !vml]--><img alt=\"A screenshot of a computer\n\nAI-generated content may be incorrect.\" border=\"0\" height=\"390\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEj2jH76ywmEeLzL43u6gJl7GKR2lEGlhYS0LOXRPMMovOsJEVdXyamYCvmq96ez3p_GXHLoFz4JDyAKHlARK9pSy8QfzVa7yt1_uEg_H9IJfKgunnYWUwlROXABNcU6TvrA0_hx0KPZfj00b3Cb-Wn_7Bf3sFu9JApZoClcWoh_Vfl5bk1GQVZUH1tuGao\" width=\"605\" /><!--[endif]--></span></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">If you want\nto download all files, regardless of the size, then set the parameter to ignore\nthe maximum file size: </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\"><span style=\"font-family: courier;\">osf_file_download(\"b7es8\",\nmax_file_size = NULL)</span></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">Sometimes\nyou might want to download all files but ignore the file structure on the OSF,\nto just have all the files in one folder. Setting the parameter ignore_folder_structure\n= TRUE will give you all the files on the OSF in a single folder. By default, files will be downloaded into your working directory, but you can also specify\nwhere you want the files to be saved. </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\"><span style=\"font-family: courier;\">osf_file_download(\"6nt4v\",\nignore_folder_structure = TRUE, download_to = \"C:\\\\test_download\")</span></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">We hope\nthis function will make it easier for reviewers to access all supplementary\nfiles stored on the OSF during peer review, and for researchers who want to re-use\ndata, code, or materials shared on the OSF by downloading all the files they\nneed easily. Make sure to install the latest version of Papercheck (0.0.0.9050)\nto get access to this new function. Papercheck is still in active development,\nso report any bugs on <a href=\"https://github.com/scienceverse/papercheck\">GitHub</a>.</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>",
      "author": "noreply@blogger.com (Daniel Lakens)",
      "published_date": "2025-07-22T09:53:00+00:00",
      "source": "Twenty Percent Statistician",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 765,
      "reading_time": 3,
      "created_at": "2025-12-21T17:42:08.997761+00:00",
      "updated_at": "2025-12-21T18:21:38.678392+00:00",
      "metadata": {
        "processed_at": "2025-12-21T18:21:38.678401+00:00",
        "processing_method": "github_actions"
      }
    }
  ]
}