{
  "last_updated": "2025-09-26T06:21:04.638619+00:00",
  "pending_count": 969,
  "processed_count": 31,
  "pending_articles": [
    {
      "id": "bddb79df0f916d4ca8f713f4b38e2fa3",
      "url": "http://www.jneurosci.org/cgi/content/short/45/39/e2175242025?rss=1",
      "title": "Spatial and Temporal Factors Influencing Fixational Saccades",
      "content": "<p>Much research has focused on how perceptual, cognitive, and attentional processes modulate microsaccades, the small rapid gaze shifts that humans perform when attempting to maintain steady gaze on a point. Yet the reasons why these fixational saccades occur in the first place have remained unclear. Long-standing theories have argued for either spatial (i.e., gaze centering) or temporal mechanisms (i.e., a periodical release process). However, this debate has never been resolved, primarily because of uncertainty in determining where the observer looks. Whereas modern eye-trackers enable detection of small eye movements, accurate localization of the line of sight remains challenging. Here, rather than indirectly inferring gaze position from oculomotor activity, we used a gaze-contingent procedure to directly estimate the perceived center of the visual field, a method that has been previously shown to effectively reduce uncertainty. Our results from subjects of both sexes show that the generation of fixational saccades depends on the interaction of spatial and temporal factors. Fixational saccades are remarkably accurate in correcting for fixation errors, even when gaze is minimally displaced. However, fixational saccades also occur when gaze is centered, but their latency increases as the fixation error decreases. These results suggest that fixational saccades serve an important corrective function when needed, but they can only be avoided for a limited period of time when fixation is already accurate.</p>",
      "author": "Wang, J. Z., Cherici, C., Rucci, M.",
      "published_date": "2025-09-24T16:30:28+00:00",
      "source": "Journal Neuroscience Current",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 221,
      "reading_time": 1,
      "created_at": "2025-09-26T05:40:37.619475+00:00",
      "updated_at": "2025-09-26T05:40:37.619476+00:00"
    },
    {
      "id": "2abc94ffb1cecfa2469439e94301d859",
      "url": "http://www.jneurosci.org/cgi/content/short/45/39/e2160242025?rss=1",
      "title": "Left Perisylvian Rhythms Encode Prosody and Syntax during Delayed Sentence Repetition",
      "content": "<p>The human brain must add information to the acoustic speech signal in order to understand language. Many accounts propose that the prosodic structure of utterances (including their syllabic rhythm and speech melody), in combination with stored lexical knowledge, cue and interact with higher order abstract semantic and syntactic information. While cortical rhythms, particularly in the delta and theta band, synchronize to quasi-rhythmic low-level acoustic speech features, it remains unclear how the human brain encodes abstract speech properties in neural rhythms in the absence of an acoustic signal, i.e., when speakers hold planned sentences in working memory. This study disentangles the contributions of prosodic and syntactic features in cortical rhythms during delayed sentence repetition. Using high-resolution ECoG during awake tumor surgery in the left perisylvian cortex in nine patients (five female), we show that the phase of neural rhythms with frequencies ranging from 1 to 48&nbsp;Hz and the broadband gamma power envelope code both low-level acoustic and abstract syntactic speech features during sentence processing and retention. Syntax and prosody coding occurred in the same frequency bands, which argues against the assumption of different frequency channels for processing and representing these speech features. Our data suggest the brain leverages the phase of various neural rhythms to code both acoustic and abstract linguistic features.</p>",
      "author": "Gehrig, J., Bergmann, C., Forster, M.-T., Weismantel, C., Bai, F., Czabanka, M., Martin, A. E., Meyer, A., Kell, C. A.",
      "published_date": "2025-09-24T16:30:28+00:00",
      "source": "Journal Neuroscience Current",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 211,
      "reading_time": 1,
      "created_at": "2025-09-26T05:40:37.619439+00:00",
      "updated_at": "2025-09-26T05:40:37.619441+00:00"
    },
    {
      "id": "cc0d617d47bef1365880c900a1561a9f",
      "url": "http://www.jneurosci.org/cgi/content/short/45/39/e2073242025?rss=1",
      "title": "Hierarchical Organization of Human Visual Feature Attention Control",
      "content": "<p>Attention can be deployed in advance of visual stimuli based on features such as color or direction of motion. This anticipatory feature-based attention involves top-down neural control signals from the frontoparietal network that bias visual cortex to enhance attended information and suppress distraction. For example, anticipatory attention control can enable effective selection based on stimulus color while ignoring distracting information about stimulus motion. Anticipatory attention can also be focused more narrowly, for example, to select specific colors or motion directions that define task-relevant aspects of the stimuli. One important question that remains open is whether anticipatory attention control first biases broad feature dimensions such as color versus motion before biasing the specific feature attributes (e.g., blue vs green). To investigate this, we recorded EEG activity during a task where human participants of either sex were cued to either attend to a motion direction (up or down) or a color (blue or green) on a trial-by-trial basis. Applying multivariate decoding approaches to the EEG alpha band activity (8&ndash;12&nbsp;Hz) during attention control (cue-target interval), we observed significant decoding for both the attended dimensions (motion vs color) and specific feature attributes (up vs down; blue vs green). Importantly, the temporal onset of the dimension-level biasing (motion vs color) preceded that of the attribute-level biasing (up vs down and blue vs green). These findings demonstrate that the top-down control of feature-based attention proceeds in a hierarchical fashion, first biasing the broad feature dimension, and then narrowing to the specific feature attribute.</p>",
      "author": "Meyyappan, S., Ding, M., Mangun, G. R.",
      "published_date": "2025-09-24T16:30:28+00:00",
      "source": "Journal Neuroscience Current",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 247,
      "reading_time": 1,
      "created_at": "2025-09-26T05:40:37.619404+00:00",
      "updated_at": "2025-09-26T05:40:37.619406+00:00"
    },
    {
      "id": "4f10be02f2c7a1ec6d143b7d4c067728",
      "url": "http://www.jneurosci.org/cgi/content/short/45/39/e1018252025?rss=1",
      "title": "Familiarity Gates Socially Transmitted Aggression via the Medial Amygdala",
      "content": "<p>Aggressive behavior can be acquired through observation, providing adaptive advantages but also posing significant social risks. In humans, individuals repeatedly exposed to aggression are more likely to engage in violent behavior later in life. Yet, the environmental factors and neural mechanisms underlying observationally acquired aggression remain unclear. Here, we propose that social familiarity with an aggressor is critical for activating neural circuits in observers that primes aggression. To investigate this, we established a novel behavioral paradigm termed \"socially transmitted aggression (STA),\" in which witness mice observed either familiar or unfamiliar demonstrators attacking intruder mice. Remarkably, male, but not female, witnesses displayed increased aggression only after observing familiar demonstrators, with no effect from unfamiliar ones. Given that excitatory neurons in the posterior&ndash;ventral segment of the medial amygdala (MeApv) have been implicated in aggression priming, we hypothesized these neurons might be involved in STA as well. Supporting this hypothesis, fiber photometry revealed selective activation of excitatory MeApv neurons during familiar, but not unfamiliar, demonstrator attacks. Chemogenetically and optogenetically inhibiting these neurons suppressed STA, while activating them during unfamiliar demonstrator attacks promoted aggression. These results establish social familiarity as essential for the observational transmission of aggression and identify excitatory MeApv neurons as critical mediators of this phenomenon, offering potential avenues for clinical intervention.</p>",
      "author": "Adjei, M. P., Qasem, E., Aaflaq, S., Jacobs, J. T., Skinner, S., Summa, F., Spotanski, C., Thompson, R., Aholt, M. L., Lineberry, T., Nordman, J. C.",
      "published_date": "2025-09-24T16:30:28+00:00",
      "source": "Journal Neuroscience Current",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 210,
      "reading_time": 1,
      "created_at": "2025-09-26T05:40:37.619367+00:00",
      "updated_at": "2025-09-26T05:40:37.619369+00:00"
    },
    {
      "id": "5d0309982d311545b5543bb427d7d77c",
      "url": "http://www.jneurosci.org/cgi/content/short/45/39/e0943252025?rss=1",
      "title": "Perisynaptic Astroglial Response to In Vivo Long-Term Potentiation and Concurrent Long-Term Depression in the Hippocampal Dentate Gyrus",
      "content": "<p>Perisynaptic astroglia provide critical molecular and structural support to regulate synaptic transmission and plasticity in the nanodomain of the axon&ndash;spine interface. Three-dimensional reconstruction from serial section electron microscopy (3DEM) was used to investigate relationships between perisynaptic astroglia and dendritic spine synapses undergoing plasticity in the adult hippocampus. Delta-burst stimulation (DBS) of the medial perforant pathway induced long-term potentiation (LTP) in the middle molecular layer and concurrent long-term depression (cLTD) in the outer molecular layer of the dentate gyrus in awake male rats. The contralateral hippocampus received baseline stimulation as a within-animal control. Brains were obtained 30&nbsp;min or 2&nbsp;h after DBS onset. An automated 3DEM pipeline was developed to enable unbiased quantification of astroglial coverage at the perimeter of the axon&ndash;spine interface. Under all conditions, &gt;85% of synapses had perisynaptic astroglia processes within 120&nbsp;nm of some portion of the perimeter. LTP broadened the distribution of spine sizes while reducing the presence and proximity of perisynaptic astroglia near the axon&ndash;spine interface of large spines. In contrast, cLTD transiently reduced the length of the axon&ndash;spine interface perimeter without substantially altering astroglial apposition. The postsynaptic density was discovered to be displaced from the center of the axon&ndash;spine interface, with this offset increasing during LTP and decreasing during cLTD. Astroglial access to the postsynaptic density was diminished during LTP and enhanced during cLTD, in parallel with changes in spine size. Thus, access of perisynaptic astroglia to synapses is dynamically modulated during LTP and cLTD alongside synaptic remodeling.</p>",
      "author": "Nam, A. J., Kuwajima, M., Parker, P. H., Bowden, J. B., Abraham, W. C., Harris, K. M.",
      "published_date": "2025-09-24T16:30:28+00:00",
      "source": "Journal Neuroscience Current",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 242,
      "reading_time": 1,
      "created_at": "2025-09-26T05:40:37.619330+00:00",
      "updated_at": "2025-09-26T05:40:37.619332+00:00"
    },
    {
      "id": "b846600b42504d4e49f23d049b7c9d14",
      "url": "http://www.jneurosci.org/cgi/content/short/45/39/e0805252025?rss=1",
      "title": "Strengthening Medial Olivocochlear Feedback Reduces the Developmental Impact of Early Noise Exposure",
      "content": "<p>The early onset of peripheral deafness significantly alters the proper development of the auditory system. Likewise, exposure to loud noise during early development produces a similar disruptive effect. Before hearing onset in altricial mammals, cochlear inner hair cells (IHCs) exhibit spontaneous electrical activity that drives auditory circuit development. This activity is modulated by medial olivocochlear (MOC) efferent feedback through &alpha;9&alpha;10 nicotinic cholinergic receptors in IHCs. In adults, these receptors are restricted to outer hair cells, where they mediate MOC feedback to regulate cochlear amplification. Although the MOC system's protective role to prevent noise-induced hearing loss in adulthood is well established, its influence during early developmental stages&mdash;especially in response to exposure to loud noise&mdash;remains largely unexplored. In this study, we investigated the role of MOC feedback during early postnatal development using &alpha;9 knock-out (KO) and &alpha;9 knock-in (KI) mice of either sex, which respectively lack or exhibit enhanced cholinergic activity. Our findings reveal that both increased and absent olivocochlear activity result in altered auditory sensitivity at the onset of hearing, along with long-range alterations in the number and morphology of ribbon synapses. Early noise exposure caused lasting auditory damage in both wild-type and &alpha;9KO mice, with deficits persisting into adulthood. In contrast, &alpha;9KI mice were protected from noise-induced damage, with no long-term effects on auditory function. These results highlight the increased susceptibility of the auditory system during early postnatal development. Moreover, they indicate that an enhanced MOC feedback shields the auditory system from noise damage during this period.</p>",
      "author": "Castagna, V. C., Boero, L. E., Di Guilmi, M. N., Catalano Di Meo, C., Ballestero, J. A., Fuchs, P. A., Lauer, A. M., Elgoyhen, A. B., Gomez-Casati, M. E.",
      "published_date": "2025-09-24T16:30:27+00:00",
      "source": "Journal Neuroscience Current",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 247,
      "reading_time": 1,
      "created_at": "2025-09-26T05:40:37.619292+00:00",
      "updated_at": "2025-09-26T05:40:37.619293+00:00"
    },
    {
      "id": "cbb24422cf8642c1dc9695f01c798a11",
      "url": "http://www.jneurosci.org/cgi/content/short/45/39/e0790252025?rss=1",
      "title": "Multivariate White Matter Microstructure Alterations in Older Adults with Coronary Artery Disease",
      "content": "<p>Patients with coronary artery disease (CAD) face an increased risk of cognitive impairment, dementia, and stroke. While white matter (WM) lesions are frequently reported in patients with CAD, the effects on WM microstructure alterations remain largely unknown. We aimed to identify WM microstructural alterations in individuals with CAD compared with healthy controls (HC) and to examine their relationships with cognitive performance. Forty-three (43) patients with CAD (35 males and 8 females) and 36 HC (26 males and 10 females) aged 50 and older underwent comprehensive neuropsychological testing and multimodal 3&nbsp;T magnetic resonance imaging (MRI). A novel multivariate approach&mdash;the Mahalanobis distance (D2)&mdash;was used to quantify WM abnormalities as the amount of deviation from the HC reference group. D2 integrates multiple MRI-derived diffusion-weighted imaging, R1 relaxometry, and magnetization transfer imaging metrics, while accounting for covariance between metrics. Relationships between WM D2 and cognition (executive function and processing speed) were also assessed. Compared with HCs, patients with CAD had higher D2 values in the whole WM (<i>p</i> = 0.015) and in the right anterior and bilateral middle cerebral artery territories (<i>p</i> &lt; 0.05). Myelin-sensitive metrics, particularly R1 relaxation rate and MT saturation, were the most important contributors to D2. Processing speed was positively associated with greater R1 in both the whole WM and left middle cerebral artery territory. These findings suggest that greater WM microstructural alterations observed in patients with CAD were mainly driven by differences in myelin content. These alterations may contribute to a heightened risk of cognitive impairment.</p>",
      "author": "Tremblay, S. A., Potvin-Jutras, Z., Sabra, D., Rezaei, A., Sanami, S., Gagnon, C., Intzandt, B., Mainville-Berthiaume, A., Wright, L., Leppert, I. R., Tardif, C. L., Steele, C. J., Iglesies-Grau, J., Nigam, A., Bherer, L., Gauthier, C. J.",
      "published_date": "2025-09-24T16:30:27+00:00",
      "source": "Journal Neuroscience Current",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 247,
      "reading_time": 1,
      "created_at": "2025-09-26T05:40:37.619254+00:00",
      "updated_at": "2025-09-26T05:40:37.619256+00:00"
    },
    {
      "id": "d5ad6f19f949485f73ab66f02d3dd597",
      "url": "http://www.jneurosci.org/cgi/content/short/45/39/e0386252025?rss=1",
      "title": "Age-Related Positivity Bias in Emotion Recognition Is Linked to Lower Cognitive Performance and Altered Amygdala-Orbitofrontal Connectivity",
      "content": "<p>Changes in emotion recognition are observed in aging, in dementia, after brain lesions and as a function of mental health factors, such as depression. In aging, older adults have been argued to show a \"positivity bias,\" which has been associated with a relatively spared recognition accuracy for positive emotion and an increased tendency to label emotions as positive. This bias has been suggested to support mental well-being. However, it has also been found in association with cognitive decline and brain lesions. Here, we investigated the behavioral and brain correlates of this age-related positivity bias. We used multimodal brain imaging in a large group of human adults (<i>n</i> = 665, 333 females) drawn from a population-derived cohort across the lifespan, together with a psychometric analysis of an emotion recognition task using facial expressions. Beyond reductions in expression recognition accuracy, older adults showed increased perceptual thresholds for negative emotions and a reduced threshold for the positive emotion, even after accounting for general face recognition abilities. This positivity bias in labeling emotions was strongly associated with lower cognitive performance in older people, but not with (nonclinical) depressive symptoms. It was also associated with reduced gray matter volume in the bilateral anterior hippocampus&ndash;amygdala and increased functional connectivity between these regions and the orbitofrontal cortex. Together, age-related positivity bias is associated with cognitive decline and structural and functional brain differences. A positivity bias in emotion recognition may therefore reflect an early marker of neurodegeneration, a hypothesis that could be tested in future longitudinal studies.</p>",
      "author": "Wolpe, N., Harlev, D., Bergmann, E., Cam-CAN, Henson, R. N.",
      "published_date": "2025-09-24T16:30:27+00:00",
      "source": "Journal Neuroscience Current",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 249,
      "reading_time": 1,
      "created_at": "2025-09-26T05:40:37.619215+00:00",
      "updated_at": "2025-09-26T05:40:37.619216+00:00"
    },
    {
      "id": "1d80988c0d1bbf8e59d3835b55251e83",
      "url": "http://www.jneurosci.org/cgi/content/short/45/39/e0091252025?rss=1",
      "title": "Looking into Working Memory to Verify Potential Search Targets",
      "content": "<p>Finding what you are looking for is a ubiquitous task in everyday life that relies on a two-way comparison between what is currently viewed and internal search goals held in memory. Despite a wealth of studies tracking visual verification among external contents of perception, complementary verification processes among internal contents of memory remain elusive. Building on a recently established gaze marker of internal visual focusing in working memory, we uncover the internal inspection process associated with confirming or dismissing potential search targets. We show how male and female human participants \"look back\" into working memory when faced with external stimuli that are perceived as potential targets and link such internal inspection to the time needed for visual verification. A direct comparison between visual verification among the contents of working memory or perception further revealed how verification in both domains engages frontal theta activity in scalp electroencephalography but also how mnemonic verification is slower to deploy than perceptual verification. This establishes internal verification as an integral component of visual search and provides new ways to look into this underexplored component of human search behavior.</p>",
      "author": "Wang (&#x738B;&#x601D;&#x601D;), S., van Ede, F.",
      "published_date": "2025-09-24T16:30:27+00:00",
      "source": "Journal Neuroscience Current",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 183,
      "reading_time": 1,
      "created_at": "2025-09-26T05:40:37.619170+00:00",
      "updated_at": "2025-09-26T05:40:37.619172+00:00"
    },
    {
      "id": "ff42978145bb2504802122f5c5e1dedf",
      "url": "https://www.frontiersin.org/articles/10.3389/fnins.2025.1668993",
      "title": "Accelerated brain age in Moyamoya disease patients: a deep learning approach and correlation with disease severity",
      "content": "IntroductionThis study aims to utilize a DenseNet based deep learning framework to predict brain age in patients with Moyamoya disease (MMD), examining the relationship between brain age and disease severity to enhance diagnostic and prognostic capabilities.MethodsWe analyzed unenhanced MRI scans from 432 adult MMD patients and 565 normal controls collected between January 2018 and December 2022. Data preprocessing involved converting DICOM files to NIFTI format and labeling based on established diagnostic criteria. A DenseNet121 architecture, implemented using PyTorch, was employed to predict brain age. Statistical analyses included correlation assessments and comparisons between predicted brain age, chronological age, and MRA scores.ResultsThe predicted brain age for MMD patients was significantly higher than their chronological age, averaging 37.9 years versus 35.8 years (p < 0.01). For normal controls, predicted brain age matched chronological age at 36.5 years. Delta age (difference between predicted brain age and chronological age) was significantly elevated in MMD patients (p < 0.001) and positively correlated with MRA scores, indicating a link between arterial stenosis severity and accelerated brain aging.DiscussionThe DenseNet based model effectively predicts brain age, revealing that MMD patients experience accelerated brain aging correlated with disease severity. These findings highlight the potential of brain age prediction as a biomarker for MMD, aiding in personalized treatment strategies and early intervention. Future research should explore multi-center datasets and longitudinal data to validate and extend these findings.",
      "author": "Jun Yang",
      "published_date": "2025-09-25T00:00:00+00:00",
      "source": "Frontiers Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 226,
      "reading_time": 1,
      "created_at": "2025-09-26T05:40:27.981605+00:00",
      "updated_at": "2025-09-26T05:40:27.981607+00:00"
    }
  ],
  "recently_processed": [
    {
      "id": "4d9a5834f6bde0f756801a94775be52a",
      "url": "https://www.nature.com/articles/s41598-025-12695-z",
      "title": "A repeated awakening study exploring the capacity of complexity measures to capture dreaming during propofol sedation",
      "content": "",
      "author": "",
      "published_date": "2025-09-24T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-09-26T05:40:41.431357+00:00",
      "updated_at": "2025-09-26T06:21:04.536935+00:00",
      "metadata": {
        "processed_at": "2025-09-26T06:21:04.536944+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "5770aa3253b596f432935ef747a2ea0c",
      "url": "https://www.nature.com/articles/s41586-025-09544-4",
      "title": "Arousal as a universal embedding for spatiotemporal brain dynamics",
      "content": "",
      "author": "",
      "published_date": "2025-09-24T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-09-26T05:40:41.431338+00:00",
      "updated_at": "2025-09-26T06:21:04.536948+00:00",
      "metadata": {
        "processed_at": "2025-09-26T06:21:04.536950+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "4021a47446b4aacb27926f266f9b7a8b",
      "url": "https://www.nature.com/articles/s41583-025-00975-6",
      "title": "Brain connectivity benefits from enriched environments",
      "content": "",
      "author": "",
      "published_date": "2025-09-24T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-09-26T05:40:41.431299+00:00",
      "updated_at": "2025-09-26T06:21:04.536953+00:00",
      "metadata": {
        "processed_at": "2025-09-26T06:21:04.536954+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "1a5c572304f83c62ebca5be4e8011558",
      "url": "https://www.nature.com/articles/s41386-025-02240-x",
      "title": "Reply to Kim and Jeong: Namesake of PF-05231023: how nomenclature confusion leads to experimental misinterpretation in pharmacologic research",
      "content": "",
      "author": "",
      "published_date": "2025-09-24T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-09-26T05:40:41.431279+00:00",
      "updated_at": "2025-09-26T06:21:04.536956+00:00",
      "metadata": {
        "processed_at": "2025-09-26T06:21:04.536958+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "c26d89d902991a3e13b4738807303d24",
      "url": "http://www.jneurosci.org/cgi/content/short/45/39/etwij45392025?rss=1",
      "title": "This Week in The Journal",
      "content": "",
      "author": "McKeon, P.",
      "published_date": "2025-09-24T16:30:28+00:00",
      "source": "Journal Neuroscience This Week",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-09-26T05:40:39.001952+00:00",
      "updated_at": "2025-09-26T06:21:04.536960+00:00",
      "metadata": {
        "processed_at": "2025-09-26T06:21:04.536962+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "c26d89d902991a3e13b4738807303d24",
      "url": "http://www.jneurosci.org/cgi/content/short/45/39/etwij45392025?rss=1",
      "title": "This Week in The Journal",
      "content": "",
      "author": "McKeon, P.",
      "published_date": "2025-09-24T16:30:28+00:00",
      "source": "Journal Neuroscience This Week",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-09-26T05:40:39.001952+00:00",
      "updated_at": "2025-09-26T06:21:04.536960+00:00",
      "metadata": {
        "processed_at": "2025-09-26T06:21:04.536962+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "5cf06dd1c8477abb17ef4e5c3b5426e0",
      "url": "https://erpinfo.org/blog/2021/12/22/applications-2023",
      "title": "Applications now being accepted for UC-Davis/SDSU ERP Boot Camp, July 31 \u2013 August 9, 2023",
      "content": "<p class=\"\">The next 10-day ERP Boot Camp will be held July 31 \u2013 August 9, 2023 in San Diego, California. We are now taking applications, which will be due by April 1, 2023. <a href=\"https://erpinfo.org/summer-boot-camp\">Click here</a> for more information.</p><p class=\"\">We are currently planning to hold this workshop as an in-person event. However, these plans are subject to change as the COVID-19 pandemic evolves. If the event is held in person, we will require that everyone is fully vaccinated, and we will also implement any other safety measures that are warranted at the time of the workshop.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"980\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/1609175691205-RTD3XM69YGOFMVP23U6T/Boot_Camp_Logo.png?format=1000w\" width=\"1148\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>",
      "author": "Steve Luck",
      "published_date": "2023-01-16T18:31:57+00:00",
      "source": "Erp Boot Camp",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 108,
      "reading_time": 1,
      "created_at": "2025-09-26T03:33:24.861371+00:00",
      "updated_at": "2025-09-26T04:16:55.185054+00:00",
      "metadata": {
        "processed_at": "2025-09-26T04:16:55.185063+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "bd7398ecbbd90ecd3269866b2fd3744f",
      "url": "https://erpinfo.org/blog/2023/6/23/decoding-webinar",
      "title": "ERP Decoding for Everyone: Software and Webinar",
      "content": "<p class=\"\"><strong>You can access the recording </strong><a href=\"https://video.ucdavis.edu/media/Virtual+ERP+Boot+CampA+Decoding+for+Everyone%2C+July+25+2023/1_lmwj6bu0\"><strong>here</strong></a><strong>.<br />You can access the final PDF of the slides </strong><a href=\"https://ucdavis.box.com/s/flf9gzeo12rz2jhxptih7xjl0omka2k7\"><strong>here</strong></a><strong>. <br />You can access the data </strong><a href=\"https://doi.org/10.18115/D5KS6S\"><strong>here</strong></a><strong>.</strong></p><p class=\"\">fMRI research has used decoding methods for over 20 years. These methods make it possible to decode what an individual is perceiving or holding in working memory on the basis of the pattern of BOLD activity across voxels. Remarkably, these methods can also be applied to ERP data, using the pattern of voltage across electrode sites rather than the pattern of activity across voxels to decode the information being represented by the brain (<a href=\"https://erpinfo.org/blog/2018/9/16/decoding\">see this previous blog post</a>). For example, ERPs can be used to decode the identity of a face that is being perceived, the emotional valence of a scene, the identity and semantic category of a word, and the features of an object that is being maintained in working memory. Moreover, decoding methods can be more sensitive than traditional methods for detecting conventional ERP effects (e.g., whether a word is semantically related or unrelated to a previous word in an N400 paradigm).</p><p class=\"\">So far, these methods have mainly been used by a small set of experts. We aim to change that with the upcoming Version 10 of <a href=\"https://erpinfo.org/erplab\">ERPLAB Toolbox</a>. This version of ERPLAB will contain an ERP decoding tool that makes it trivially easy for anyone who knows how to do conventional ERP processing to take advantage of the power of decoding. It should be available in mid-July at <a href=\"https://github.com/ucdavis/erplab/releases\">our GitHub site</a>. You can join the <a href=\"https://github.com/ucdavis/erplab/wiki/ERPLAB-email-list\">ERPLAB email list</a> to receive an announcement when this version is released. Please do not contact us with questions until it has been released and you have tried using it.</p><p class=\"\">On July 25, 2023, we will hold a 2-hour Zoom webinar to explain how decoding works at a conceptual level and show how to implement in ERPLAB Toolbox. The webinar will begin at 9:00 AM Pacific Time (California), 12:00 PM Eastern Time (New York), 5:00 PM British Summer Time (London), 6:00 PM Central European Summer Time (Berlin). </p><p class=\"\">The webinar is co-sponsored by the <a href=\"https://erpinfo.org/the-erp-boot-camp\">ERP Boot Camp</a> and the <a href=\"https://sprweb.org\">Society for Psychophysiological Research</a>. It is completely free, but you must register in advance at <a href=\"https://ucdavis.zoom.us/meeting/register/tJUrc-CtpzorEtBSmZXJINOlLJB9ZR0evpr4\">https://ucdavis.zoom.us/meeting/register/tJUrc-CtpzorEtBSmZXJINOlLJB9ZR0evpr4</a>. Once you register, you will receive an email with your own individual Zoom link. </p><p class=\"\">We will make a recording available a few days after the webinar on the <a href=\"https://erpinfo.org\">ERPinfo.org</a> web site.</p><p class=\"\">Please direct any questions about the webinar to <a href=\"mailto:erpbootcamp@gmail.com\">erpbootcamp@gmail.com</a>.</p>",
      "author": "Steve Luck",
      "published_date": "2023-06-23T21:05:26+00:00",
      "source": "Erp Boot Camp",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 420,
      "reading_time": 2,
      "created_at": "2025-09-26T03:33:24.861345+00:00",
      "updated_at": "2025-09-26T04:16:55.185067+00:00",
      "metadata": {
        "processed_at": "2025-09-26T04:16:55.185069+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "3d370217cb4a351bb54e7854066e15c3",
      "url": "https://erpinfo.org/blog/2024/2/4/optimal-filters",
      "title": "New Papers: Optimal Filter Settings for ERP Research",
      "content": "<p class=\"\">Zhang, G., Garrett, D. R., &amp; Luck, S. J. (in press). Optimal filters for ERP research I: A general approach for selecting filter settings. <em>Psychophysiology</em>. <a href=\"https://doi.org/10.1111/psyp.14531\"><span>https://doi.org/10.1111/psyp.14531</span></a> [<a href=\"https://www.researchgate.net/publication/377773270_Optimal_filters_for_ERP_research_I_A_general_approach_for_selecting_filter_settings\"><span>preprint</span></a>]</p><p class=\"\">Zhang, G., Garrett, D. R., &amp; Luck, S. J. (in press). Optimal filters for ERP research II: Recommended settings for seven common ERP components. <em>Psychophysiology</em>. <a href=\"https://doi.org/10.1111/psyp.14530\"><span>https://doi.org/10.1111/psyp.14530</span></a> [<a href=\"https://www.researchgate.net/publication/377766656_Optimal_filters_for_ERP_research_II_Recommended_settings_for_seven_common_ERP_components\"><span>preprint</span></a>]</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1490\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/d64086cc-e3b4-457d-89df-08d9b3f96439/Filter_Table.png?format=1000w\" width=\"2062\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">What filter settings should you apply to your ERP data? If your filters are too weak to attenuate the noise in your data, your effects may not be statistically significant. If your filters are too strong, they may create artifactual peaks that lead you to draw bogus conclusions.</p><p class=\"\">For years, I have been recommending a bandpass of 0.1\u201330 Hz for most cognitive and affective research in neurotypical young adults. In this kind of research, I have found that filtering from 0.1\u201330 Hz usually does a good job of minimizing noise while creating minimal waveform distortion. </p><p class=\"\">However, this recommendation was based on a combination of informal observations from many experimental paradigms and a careful examination of a couple paradigms, so it was a bit hand-wavy. In addition, the optimal filter settings will depend on the waveshape of the ERP effects and the nature of the noise in a given study, so I couldn\u2019t make any specific recommendations about other experimental paradigms and participant populations. Moreover, different filter settings may be optimal for different scoring methods (e.g., mean amplitude vs. peak amplitude vs. peak latency).</p><p class=\"\">Guanghui Zhang, David Garrett, and I spent the last year focusing on this issue. First we developed a general method that can be used to determine the optimal filter settings for a given dataset and scoring method (see <a href=\"https://doi.org/10.1111/psyp.14531\"><span>this paper</span></a>). Then we applied this method to the <a href=\"https://doi.org/10.1016/j.neuroimage.2020.117465\"><span>ERP CORE</span></a> data to determine the optimal filter settings for the N170, MMN, P3b, N400, N2pc, LRP, and ERN components in neurotypical young adults (see <a href=\"https://doi.org/10.1111/psyp.14530\"><span>this paper</span></a> and the table above).</p><p class=\"\">If you are doing research with these components (or similar components) in neurotypical young adults, you can simply use the filter settings that we identified. If you are using a very different paradigm or testing a very different subject population, you can apply our method to your own data to find the optimal settings. We added some new tools to <a href=\"https://github.com/ucdavis/erplab\"><span>ERPLAB Toolbox</span></a> to make this easier.</p><p class=\"\">One thing that we discovered was that our old recommendation of 0.1\u201330 Hz does a good job of avoiding filter artifacts but is overly conservative for some components. For example, we can raise the low end to 0.5 Hz when measuring N2pc and MMN amplitudes, which gets rid of more noise without producing problematic waveform distortions. And we can go all the way up to 0.9 Hz for the N170 component. However, later/slower components like P3b and N400 require lower cutoffs (no higher than 0.2 Hz).</p><p class=\"\">You might be wondering how we defined the \u201coptimal\u201d filter settings. At one level, the answer is simple: The optimal filter is the one that maximizes the signal-to-noise ratio without producing too much waveform distortion. The complexities arise in quantifying the signal-to-noise ratio, quantifying the waveform distortion, and deciding how much waveform distortion is \u201ctoo much\u201d. We believe we have found reasonably straightforward and practical solutions to these problems, which you can read about in the published papers.</p>",
      "author": "Steve Luck",
      "published_date": "2024-02-04T23:46:20+00:00",
      "source": "Erp Boot Camp",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 568,
      "reading_time": 2,
      "created_at": "2025-09-26T03:33:24.861297+00:00",
      "updated_at": "2025-09-26T04:16:55.185071+00:00",
      "metadata": {
        "processed_at": "2025-09-26T04:16:55.185073+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "c2319578819743fdf0159bf723bcb1b5",
      "url": "https://erpinfo.org/blog/2024/3/5/changes-to-the-2024-erp-boot-camp",
      "title": "Important Changes to the 2024 ERP Boot Camp",
      "content": "<p class=\"\">We are disappointed to announce that we will not be holding a regular 10-day ERP Boot Camp this summer.</p><p class=\"\">We have held Boot Camps nearly every summer since 2007, supported by a series of generous grants from NIMH that allowed us to provide scholarships for all attendees. Unfortunately, although our recent renewal proposal received extremely positive reviews and scores, we were recently given the surprising and disappointing news that the renewal will not be funded this year. We believe that the ERP Boot Camp provides essential training to the field, and we will continue to pursue financial support to continue holding 10-day ERP Boot Camps in the future. </p><p class=\"\">In the meantime, we have partial funding that will allow us to hold a 5-day ERP Boot Camp this summer from July 8-12, 2024 in Davis, California. The workshop will include 5-days of lectures and activities on EEG and ERP measures, including practical and theoretical issues.</p><p class=\"\">Unfortunately, we will not be able to provide scholarships to pay for travel and lodging costs, and we must charge a registration fee. We are very sorry if this causes a hardship. </p><p class=\"\">We are no longer taking applications through our application portal. Instead of a competitive application process, we will simply accept the first 30 people who complete the registration process and pay the registration fee. This provides an opportunity to attend for individuals who might otherwise not make it through our ordinary application process, which is highly competitive. </p><p class=\"\">The registration fee will be $1000 (or $900 for people who register by April 15). The registration fee will cover 6 nights in a single occupancy hotel room (arriving July 7 and departing July 13), daily breakfast at the hotel, a catered lunch for each day of the workshop, and a group dinner. <strong>You must pay the registration fee with a credit card when you register.</strong> There are no exceptions to the registration fee policy.</p><p class=\"\"><strong>Registration is now open</strong> at <a href=\"https://na.eventscloud.com/793175\">https://na.eventscloud.com/793175</a>.</p><p class=\"\">Given that we will accept the first 30 registrants, we encourage you to register as soon as possible. <strong>Registration will close on May 20</strong>, but we anticipate that the workshop will be filled up long before then. </p><p class=\"\">You must pay for your own transportation to Davis. Davis is approximately 20 minutes away from the Sacramento Airport (SMF). You can take the <a href=\"https://www.davisairporter.com/\" target=\"_blank\">Davis Airporter</a> shuttle service or a rideshare service from SMF to Davis. If you are coming from outside North America, you may want to fly into the San Francisco airport (SFO), which is 135 km (84 miles) from Davis. We recommend taking the <a href=\"https://www.davisairporter.com/\" target=\"_blank\">Davis Airporter</a> from SFO to Davis.</p>",
      "author": "Steve Luck",
      "published_date": "2024-03-05T19:34:57+00:00",
      "source": "Erp Boot Camp",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 444,
      "reading_time": 2,
      "created_at": "2025-09-26T03:33:24.861234+00:00",
      "updated_at": "2025-09-26T04:16:55.185075+00:00",
      "metadata": {
        "processed_at": "2025-09-26T04:16:55.185077+00:00",
        "processing_method": "github_actions"
      }
    }
  ]
}