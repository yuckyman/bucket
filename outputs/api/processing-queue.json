{
  "last_updated": "2026-01-06T06:27:01.566649+00:00",
  "pending_count": 644,
  "processed_count": 356,
  "pending_articles": [
    {
      "id": "fa250840ddf6808c93613cad856c7c25",
      "url": "http://doi.org/10.1037/cns0000353",
      "title": "Unmuting lucid dreams: Speech decoding and vocalization in real time.",
      "content": "Since the 1970s, scientists have been searching for ways to communicate with people in lucid dreams (LDs), during which it is possible to maintain consciousness. Previously, dreamers could hear sounds from reality and respond with some simple signals, but they could not speak back. In this study, facial surface electromyography (EMG) was tested as a proof of concept for unmuting people in LDs. Remmyo, an EMG distinctive constructed language, was used. The software was developed to translate facial EMG impulses into Remmyo sounds and letters, translate words into English, and digitally vocalize the final text in English. Four LD practitioners were trained to pronounce a short phrase or a word in Remmyo and were then asked to achieve the same task in LDs under polysomnographic observation. LDs were verified by preagreed eye movements in rapid eye movement (REM) sleep. Four volunteers tried to speak in Remmyo in 15 LDs. Due to software failures, mispronunciations, and missing sounds, the decoding efficiency in real time or in recordings ranged from 13% to 81%. The first phrase and word heard from sleeping people were \u201cno war\u201d and \u201cfreedom.\u201d The later was automatically translated and vocalized in English in real time for 11 times. Despite controversial results, the study shows that, with further development, people could possibly talk in LDs and could be heard in reality with the help of EMG sensors. To achieve this goal, a range of possible obstacles is discussed. This technology could provide opportunities for LD studies and their practical applications. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2023-03-13T00:00:00+00:00",
      "source": "Clinical Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 260,
      "reading_time": 1,
      "created_at": "2026-01-06T05:49:33.286484+00:00",
      "updated_at": "2026-01-06T05:49:33.286486+00:00"
    },
    {
      "id": "3cace5c5d9bdc4eeebb05365c3e99538",
      "url": "http://doi.org/10.1037/cns0000402",
      "title": "Creating a world in the head: The conscious apprehension of neural content originating from internal sources.",
      "content": "Klein et al. (2023) argued that the evolutionary transition from respondent to agent during the Cambrian explosion would be a promising vantage point from which to gain insight into the evolution of organic sentience. They focused on how increased competition for resources\u2014in consequence of the proliferation of new, neurally sophisticated life-forms\u2014made awareness of the external world (in the service of agentic acts) an adaptive priority. The explanatory scope of Klein et al. (2023) was limited to consideration of the conscious apprehension of externally sourced content\u2014that is, content delivered from the sensory registration of objects occupying phenomenal space. But consciousness\u2014at least for humans\u2014takes its objects from internal as well as external sources. In the present article, we extend their analysis to the question of how internally sourced content (i.e., mental states) became the object of conscious apprehension. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2024-09-09T00:00:00+00:00",
      "source": "Clinical Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 145,
      "reading_time": 1,
      "created_at": "2026-01-06T05:49:33.286439+00:00",
      "updated_at": "2026-01-06T05:49:33.286441+00:00"
    },
    {
      "id": "a98346fd966e16c62d8cb8beabf73fe1",
      "url": "https://github.com/wedow/ticket",
      "title": "Show HN: I replaced Beads with a faster, simpler Markdown-based task tracker",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46487580\">Comments</a>",
      "author": "",
      "published_date": "2026-01-04T13:08:12+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-06T05:49:24.445270+00:00",
      "updated_at": "2026-01-06T05:49:24.445271+00:00"
    },
    {
      "id": "64b75adc2a9295d56cf3ca1b932e1658",
      "url": "https://arxiv.org/abs/2601.02082",
      "title": "Realistic adversarial scenario generation via human-like pedestrian model for autonomous vehicle control parameter optimisation",
      "content": "arXiv:2601.02082v1 Announce Type: new \nAbstract: Autonomous vehicles (AVs) are rapidly advancing and are expected to play a central role in future mobility. Ensuring their safe deployment requires reliable interaction with other road users, not least pedestrians. Direct testing on public roads is costly and unsafe for rare but critical interactions, making simulation a practical alternative. Within simulation-based testing, adversarial scenarios are widely used to probe safety limits, but many prioritise difficulty over realism, producing exaggerated behaviours which may result in AV controllers that are overly conservative. We propose an alternative method, instead using a cognitively inspired pedestrian model featuring both inter-individual and intra-individual variability to generate behaviourally plausible adversarial scenarios. We provide a proof of concept demonstration of this method's potential for AV control optimisation, in closed-loop testing and tuning of an AV controller. Our results show that replacing the rule-based CARLA pedestrian with the human-like model yields more realistic gap acceptance patterns and smoother vehicle decelerations. Unsafe interactions occur only for certain pedestrian individuals and conditions, underscoring the importance of human variability in AV testing. Adversarial scenarios generated by this model can be used to optimise AV control towards safer and more efficient behaviour. Overall, this work illustrates how incorporating human-like road user models into simulation-based adversarial testing can enhance the credibility of AV evaluation and provide a practical basis to behaviourally informed controller optimisation.",
      "author": "Yueyang Wang, Mehmet Dogar, Gustav Markkula",
      "published_date": "2026-01-06T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 226,
      "reading_time": 1,
      "created_at": "2026-01-06T05:27:04.849016+00:00",
      "updated_at": "2026-01-06T05:27:04.849017+00:00"
    },
    {
      "id": "748afeacd4e0f27f4423e388566d248a",
      "url": "https://arxiv.org/abs/2601.02047",
      "title": "Escaping the Filter Bubble: Evaluating Electroencephalographic Theta Band Synchronization as Indicator for Selective Exposure in Online News Reading",
      "content": "arXiv:2601.02047v1 Announce Type: new \nAbstract: Selective exposure to online news occurs when users favor information that confirms their beliefs, creating filter bubbles and limiting diverse perspectives. Interactive systems can counter this by recommending different perspectives, but to achieve this, they need a real-time metric for selective exposure. We present an experiment where we evaluate Electroencephalography (EEG) and eye tracking as indicators for selective exposure by using eye tracking to recognize which textual parts participants read and using EEG to quantify the magnitude of selective exposure. Participants read online news while we collected EEG and eye movements with their agreement towards the news. We show that the agreement with news correlates positively with the theta band power in the parietal area. Our results indicate that future interactive systems can sense selective exposure using EEG and eye tracking to propose a more balanced information diet. This work presents an integrated experimental setup that identifies selective exposure using gaze and EEG-based metrics.",
      "author": "Thomas Kr\\\"amer, Daniel Hienert, Francesco Chiossi, Thomas Kosch, Dagmar Kern",
      "published_date": "2026-01-06T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 159,
      "reading_time": 1,
      "created_at": "2026-01-06T05:27:04.848983+00:00",
      "updated_at": "2026-01-06T05:27:04.848985+00:00"
    },
    {
      "id": "84fb84ec86cba737b2a3423a3bba554e",
      "url": "https://arxiv.org/abs/2601.02044",
      "title": "EyeLiveMetrics: Real-time Analysis of Online Reading with Eye Tracking",
      "content": "arXiv:2601.02044v1 Announce Type: new \nAbstract: Existing eye tracking software have certain limitations, especially with respect to monitoring reading online: (1) Most eye tracking software record eye tracking data as raw coordinates and stimuli as screen images/videos, but without inherent links between both. Analysts must draw areas of interest (AOIs) on webpage text for more fine-grained reading analysis. (2) The computation and analysis of fixation and reading metrics are done after the experiment and thus cannot be used for live applications. We present EyeLiveMetrics, a browser plugin that automatically maps raw gaze coordinates to text in real time. The plugin instantly calculates, stores, and provides fixation, saccade, and reading measures on words and paragraphs so that gaze behavior can be analyzed immediately. We also discuss the results of a comparative evaluation. EyeLiveMetrics offers a flexible way to measure reading on the web - for research experiments and live applications.",
      "author": "Daniel Hienert, Heiko Schmidt, Thomas Kr\\\"amer, Dagmar Kern",
      "published_date": "2026-01-06T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 148,
      "reading_time": 1,
      "created_at": "2026-01-06T05:27:04.848955+00:00",
      "updated_at": "2026-01-06T05:27:04.848956+00:00"
    },
    {
      "id": "a6b903597f06a3943dd171d4ab5bba70",
      "url": "https://arxiv.org/abs/2601.01772",
      "title": "EdgeSSVEP: A Fully Embedded SSVEP BCI Platform for Low-Power Real-Time Applications",
      "content": "arXiv:2601.01772v1 Announce Type: new \nAbstract: Brain-Computer Interfaces (BCIs) enable users to interact with machines directly via neural activity, yet their real-world deployment is often hindered by bulky and powerhungry hardware. We present EdgeSSVEP, a fully embedded microcontroller-based Steady-State Visually Evoked Potential (SSVEP) BCI platform that performs real-time EEG acquisition, zero-phase filtering, and on-device classification within a lowpower 240 MHz MCU operating at only 222 mW. The system incorporates an 8-channel EEG front end, supports 5-second stimulus durations, and executes the entire SSVEP decoding pipeline locally, eliminating dependence on PC-based processing. EdgeSSVEP was evaluated using six stimulus frequencies (7, 8, 9, 11, 7.5, and 8.5 Hz) with 10 participants. The device achieved 99.17% classification accuracy and 27.33 bits/min Information Transfer Rate (ITR), while consuming substantially less power than conventional desktop-based systems. The system integrates motion sensing to support artifact detection and improve robustness and signal stability in practical environments. For development and debugging, the system also provides optional TCP data streaming to external clients. Overall, EdgeSSVEP offers a scalable, energy-efficient, and secure embedded BCI platform suitable for assistive communication and neurofeedback applications, with potential extensions to accelerometer-based artifact mitigation and broader real-world deployments.",
      "author": "Manh-Dat Nguyen, Thomas Do, Nguyen Thanh Trung Le, Xuan-The Tran, Fred Chang, Chin-Teng Lin",
      "published_date": "2026-01-06T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 192,
      "reading_time": 1,
      "created_at": "2026-01-06T05:27:04.848928+00:00",
      "updated_at": "2026-01-06T05:27:04.848930+00:00"
    },
    {
      "id": "f47155ec1e3a69271696e1557d61700b",
      "url": "https://arxiv.org/abs/2601.01539",
      "title": "Neural Digital Twins: Toward Next-Generation Brain-Computer Interfaces",
      "content": "arXiv:2601.01539v1 Announce Type: new \nAbstract: Current neural interfaces such as brain-computer interfaces (BCIs) face several fundamental challenges, including frequent recalibration due to neuroplasticity and session-to-session variability, real-time processing latency, limited personalization and generalization across subjects, hardware constraints, surgical risks in invasive systems, and cognitive burden in patients with neurological impairments. These limitations significantly affect the accuracy, stability, and long-term usability of BCIs. This article introduces the concept of the Neural Digital Twin (NDT) as an advanced solution to overcome these barriers. NDT represents a dynamic, personalized computational model of the brain-BCI system that is continuously updated with real-time neural data, enabling prediction of brain states, optimization of control commands, and adaptive tuning of decoding algorithms. The design of NDT draws inspiration from the application of Digital Twin technology in advanced industries such as aerospace and autonomous vehicles, and leverages recent advances in artificial intelligence and neuroscience data acquisition technologies. In this work, we discuss the structure and implementation of NDT and explore its potential applications in next-generation BCIs and neural decoding, highlighting its ability to enhance precision, robustness, and individualized control in neurotechnology.",
      "author": "Mohammad Mahdi Habibi Bina, Sepideh Baghernezhad, Mohammad Reza Daliri, Mohammad Hassan Moradi",
      "published_date": "2026-01-06T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 183,
      "reading_time": 1,
      "created_at": "2026-01-06T05:27:04.848899+00:00",
      "updated_at": "2026-01-06T05:27:04.848900+00:00"
    },
    {
      "id": "ebcc18c177bea7429bab9fffe86408e3",
      "url": "https://arxiv.org/abs/2601.01247",
      "title": "Human-Centered Artificial Intelligence (HCAI): Foundations and Approaches",
      "content": "arXiv:2601.01247v1 Announce Type: new \nAbstract: Artificial Intelligence (AI) is a transformative yet double-edged technology that can advance human welfare while also posing risks to humans and society. In response, the Human-Centered Artificial Intelligence (HCAI) approach has emerged as both a design philosophy and a methodological complement to prevailing technology-centered AI paradigms. Placing humans at the core, HCAI seeks to ensure that AI systems serve, augment, and empower humans rather than harm or replace them. This chapter establishes the conceptual and methodological foundations of HCAI by tracing its evolution and recent advancements. It introduces key HCAI concepts, frameworks, guiding principles, methodologies, and practical strategies that bridge philosophical HCAI principles with operational implementation. Through an analytical review of the emerging characteristics and challenges of AI technologies, the chapter positions HCAI as a holistic paradigm for aligning AI innovation with human values, societal well-being, and sustainable progress. Finally, this chapter outlines the structure and contributions of the Handbook of Human-Centered Artificial Intelligence. The purpose of this chapter is to provide an integrated foundation that connects HCAI conceptual frameworks, principles, methodology, and practices for this handbook, thereby paving the way for the content of subsequent chapters.",
      "author": "Wei Xu",
      "published_date": "2026-01-06T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 192,
      "reading_time": 1,
      "created_at": "2026-01-06T05:27:04.848867+00:00",
      "updated_at": "2026-01-06T05:27:04.848868+00:00"
    },
    {
      "id": "717e948e5424d435f8b1f2f48f2bd312",
      "url": "https://arxiv.org/abs/2601.01227",
      "title": "LiveBo: Empowering Non-Chinese Speaking Students through AI-Driven Real-Life Scenarios in Cantonese",
      "content": "arXiv:2601.01227v1 Announce Type: new \nAbstract: Language learning is a multifaceted process. Insufficient vocabulary can hinder communication and lead to demotivation. For non-Chinese speaking (NCS) students, learning Traditional Chinese (Cantonese) poses distinct challenges, particularly due to the complexity of converting spoken and written forms. To address this issue, this study examines the effectiveness of real-life scenario simulations integrated with interactive social robots in enhancing NCS student engagement and language acquisition. The research employs a quasi-experimental design involving NCS students who interact with an AI-driven, robot-assisted language learning system, LiveBo. The study aims to assess the impact of this innovative approach on active participation and motivation. Data are collected through proficiency tests, questionnaires and semi-structured interviews. Findings indicate that NCS students experience positive improvements in behavioural and emotional engagement, motivation and learning outcomes, highlighting the potential of integrating novel technologies in language education. We plan to compare with the control group in the future. This study highlights the significance of interactive and immersive learning experiences in promoting motivation and enhancing language acquisition among NCS students.",
      "author": "Ka Yan Fung, Kwong Chiu Fung, Yuxing Tao, Tze Leung Rick Lui, Kuen Fung Sin",
      "published_date": "2026-01-06T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 173,
      "reading_time": 1,
      "created_at": "2026-01-06T05:27:04.848837+00:00",
      "updated_at": "2026-01-06T05:27:04.848838+00:00"
    }
  ],
  "recently_processed": [
    {
      "id": "698a3967478d4ba61f5711c9117ea7e6",
      "url": "https://www.embs.org/uncategorized/call-for-applications-ieee-tmrb-editor-in-chief-search/",
      "title": "Call for Applications: IEEE T-MRB Editor in Chief Search",
      "content": "<p>The post <a href=\"https://www.embs.org/uncategorized/call-for-applications-ieee-tmrb-editor-in-chief-search/\">Call for Applications: IEEE T-MRB Editor in Chief Search</a> appeared first on <a href=\"https://www.embs.org\">IEEE EMBS</a>.</p>",
      "author": "Deidre Artis",
      "published_date": "2025-04-03T14:16:16+00:00",
      "source": "Embs",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 18,
      "reading_time": 1,
      "created_at": "2026-01-06T05:50:14.086570+00:00",
      "updated_at": "2026-01-06T06:27:01.461565+00:00",
      "metadata": {
        "processed_at": "2026-01-06T06:27:01.461575+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "3d6b5f8f7d117269f6d483cfe999ae04",
      "url": "https://www.frontiersin.org/articles/10.3389/fncom.2025.1641519",
      "title": "Fractal memory structure in the spatiotemporal learning rule",
      "content": "The spatiotemporal learning rule (STLR) can reproduce synaptic plasticity in the hippocampus. Analysis of the synaptic weights in the network with the STLR is challenging. Consequently, our previous research only focused on the network's outputs. However, a detailed analysis of the STLR requires focusing on the synaptic weights themselves. To address this issue, we mapped the synaptic weights to a distance space and analyzed the characteristics of the STLR. The results indicate that the synaptic weights form a fractal-like structure in Euclidean distance space. Furthermore, three analytical approaches\u2014multi-dimensional scaling, estimating fractal dimension, and modeling with an iterated function system\u2014demonstrate that the STLR forms a fractal structure in the synaptic weights through fractal coding. These findings contribute to clarifying the learning mechanisms in the hippocampus.",
      "author": "Yoshihiko Horio",
      "published_date": "2025-12-16T00:00:00+00:00",
      "source": "Frontiers Computational Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 124,
      "reading_time": 1,
      "created_at": "2026-01-06T05:49:53.279029+00:00",
      "updated_at": "2026-01-06T06:27:01.461579+00:00",
      "metadata": {
        "processed_at": "2026-01-06T06:27:01.461581+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "437dd11491bad5ef899b86bf9271e125",
      "url": "http://doi.org/10.1037/cns0000370",
      "title": "Investigating how individual differences in selective attention relate to schizotypy and altered states of consciousness.",
      "content": "Measures of altered states of consciousness (ASC) are useful for understanding anomalies within conscious experiences. Within psychedelic clinical trials, ASC have been associated with long-term positive treatment outcomes for numerous types of mental illnesses. Schizotypal Personality Scale (STA), a set of personality traits that can be related to psychedelic-induced ASC, is associated with potential changes in selective attention, such as being less bound to previously learned associations (i.e., reduced associative blocking). Given the similarity between schizotypy and psychedelic-induced ASC, we hypothesized that there may be attentional differences in individuals with past experiences of ASC. This study examined how differences in selective attention relate to past experiences of ASC and STA. In Study 1, participants completed a visual categorization task designed to elicit associative blocking, the STA, and the ASC scale. Results revealed slow learning feature\u2013category associations in participants high in ASC and STA. Study 2 tested whether this deficit in performance was due to widened attention by implementing additional inference trials that measured incidental learning of feature\u2013feature associations. Results from Study 2 confirmed that participants high in ASC and STA show deficits in learning categories, but this was not accounted for by wider selective attention per se. Our results suggest that flexible or widened attention may not be the locus of cognitive changes associated with past experiences of ASC. Rather, by showing reliable latency in an error-driven learning task, we add to a comprehensive understanding of the relationships between cognition and ASC. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2023-09-14T00:00:00+00:00",
      "source": "Clinical Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 251,
      "reading_time": 1,
      "created_at": "2026-01-06T05:49:33.286601+00:00",
      "updated_at": "2026-01-06T06:27:01.461584+00:00",
      "metadata": {
        "processed_at": "2026-01-06T06:27:01.461586+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "b84f4acfaa385c55c9bcc74850be8c16",
      "url": "http://doi.org/10.1037/cns0000380",
      "title": "Sensory-processing sensitivity as a confounder in the positive relationship between mindful awareness and psychological distress: A theoretical review.",
      "content": "Mindfulness meditation is credited as a positive driver of promoting psychological well-being and reducing stress, anxiety, and depression symptoms. However, dispositional mindfulness has been somewhat correlated with psychological distress, as awareness has been positively correlated with psychological symptoms and negative affective states in many studies. This counterintuitive phenomenon has been tentatively explained in a variety of ways, including a wrong interpretation of the items of the mindfulness assessment scales in nonmeditators. The most credited explanation is that increasing attention to present-moment experiences would boost affective reaction to negative experiences and therefore exacerbate related psychological symptoms. This hypothesis is unsatisfactory, as there is much contrasting evidence in this regard. Therefore, we propose a new hypothesis: in dispositional studies, the assessment of the awareness skill of mindfulness would be affected by sensory-processing sensitivity, which could be a confounder in its relationship with psychological distress. Sensory-processing sensitivity refers to a temperamental trait characterized by both awareness of sensorial stimulation and reactivity to experience. Thus, highly sensitive persons usually report increased awareness of subtleties in the environment, ease of overstimulation, and increased affective reaction to stimulation. In support of our hypothesis, we showed in particular how the most widely used scale for assessing mindful awareness could be paired with and interpreted as a measure of sensory-processing sensitivity. We then propose a set of testable hypotheses to drive future research on this topic. If supported by future experimental results, our hypothesis would shed new light on the overall field of dispositional mindfulness studies. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2023-11-02T00:00:00+00:00",
      "source": "Clinical Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 257,
      "reading_time": 1,
      "created_at": "2026-01-06T05:49:33.286561+00:00",
      "updated_at": "2026-01-06T06:27:01.461588+00:00",
      "metadata": {
        "processed_at": "2026-01-06T06:27:01.461590+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "a89cc9d9bab0838b2e06072add1ef2ed",
      "url": "http://doi.org/10.1037/cns0000335",
      "title": "A shared perceptual inference for cross-modally induced illusions of self-attribution.",
      "content": "The representation of our own body is malleable. Evidence indicates that multisensory stimulation can trigger an illusory sense of ownership over a fake hand, a partner\u2019s face, or a virtual body. Despite our understanding of the processes supporting the construction of bodily self, we know less about the processes that trigger illusory ownership of nonbody attributes (e.g., voice during articulation) and about whether multisensory stimulation can drive a shared inference across distinct attributes. Here, we compared the classic rubber hand illusion with another multisensory illusion that elicits a sense of ownership over a stranger\u2019s voice during talking. We observed that, given congruent multisensory input, the degree to which one perceived the sense of ownership over the fake hand predicted the degree to which one perceived the sense of ownership over the stranger\u2019s voice, after controlling for task demand and suggestibility. Thus, our results provide evidence for a shared inference supporting subjective sense of self across fundamentally different attributes. We suggest that individual reliance on multisensory signals to drive such an inference can be further explored. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2022-08-25T00:00:00+00:00",
      "source": "Clinical Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 184,
      "reading_time": 1,
      "created_at": "2026-01-06T05:49:33.286519+00:00",
      "updated_at": "2026-01-06T06:27:01.461592+00:00",
      "metadata": {
        "processed_at": "2026-01-06T06:27:01.461593+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "95514f245ada62eea2ae839ba693a005",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.05.697596v1?rss=1",
      "title": "Shaped by meaning, weighted by reliability: New insights into multisensory integration",
      "content": "In everyday perception, sensory information is rarely interpreted in isolation. Instead, observers generate expectations about what is likely to occur next, using contextual information to guide decisions, particularly when sensory input is weak, ambiguous, or uncertain. These expectations can facilitate behaviour when they align with incoming evidence, but impose costs when they conflict, shaping how information from different senses contributes to behaviour. However, it remains unclear what kind of multisensory process is engaged when meaning guides decisions, and whether multisensory facilitation and non-independence reflect a single integrative mechanism or distinct routes shaped by context. Here, we examined how semantic context, visual clarity, and the relationship between auditory and visual signals jointly shape behaviour in a semantic correspondence task using dynamic, naturalistic events. Participants judged whether a target matched a preceding concept prime, establishing an expectation at the level of meaning. Targets were auditory-only, visual-only (clear or blurry), or audiovisual (AV), with AV components conveying either the same or different meanings across modalities. AV facilitation was not a general consequence of stimulus redundancy. When the prime accurately predicted the target and auditory and visual signals conveyed the same meaning, degrading visual input increased the contribution of auditory information, leading to faster responses and violations of the race-model inequality. By contrast, when the prime indicated the target but auditory and visual signals conveyed competing meanings, AV stimulation produced robust behavioural costs relative to vision. When the prime did not match the target, congruent and incongruent audiovisual events produced comparable effects, and race-model violations were observed even when auditory and visual signals encoded different concepts, indicating convergence at the level of the response rather than shared perceptual content. Finally, exploratory clustering revealed two participant subgroups with comparable overall response speed but systematically different multisensory profiles when semantic expectations did not allow reliable anticipation of the upcoming event. Together, these findings show that multisensory effects in semantic decisions are shaped by meaning and arise through two functionally distinct routes: one in which reduced sensory reliability promotes joint use of congruent audiovisual information, and another in which perceptually different signals converge on the same response when semantic expectations are not met.",
      "author": "Sycheva, E., St-Gelais, L., Jerbi, K., Bakhtiari, S., Lepore, F., Hadid, V.",
      "published_date": "2026-01-05T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 356,
      "reading_time": 1,
      "created_at": "2026-01-06T03:40:18.807652+00:00",
      "updated_at": "2026-01-06T04:35:54.489810+00:00",
      "metadata": {
        "processed_at": "2026-01-06T04:35:54.489820+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "22491e792e57181ab46c6058d4e6b095",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.05.697573v1?rss=1",
      "title": "Zebrin molecular identity and cerebellar location determine Purkinje cell vulnerability in Christianson syndrome mice",
      "content": "Ataxia is a major characteristic feature in Christianson syndrome, where Purkinje cells in the anterior cerebellar vermis are vulnerable to degeneration while those in the posterior vermis are resilient. Here, we provide a temporal study of changes in Purkinje cell function, cell vulnerability and innervation of cerebellar nuclei in a mouse model of Christianson syndrome. Purkinje cells express certain molecules in a patterned manner across the cerebellum, such as aldolase C/zebrin-II (zebrin). We show that zebrin patterning appears normal before disease onset in Christianson syndrome mice with no apparent cell death, similar to what has been reported in patients. We observe rapid Purkinje cell death in the anterior lobe of Christianson syndrome mice that is exclusive to zebrin-negative Purkinje cells, with zebrin-positive Purkinje cells showing resilience. Intrinsic firing deficits exclusively in the anterior cerebellum are observed at the same time as the first observed cell death in the anterior cerebellum. In contrast, posterior Purkinje cells degenerated later, but zebrin-negative and zebrin-positive cells were equally susceptible to degeneration. Purkinje cells' innervation in the cerebellar nuclei was also lost in Christianson syndrome mice in a region-specific manner: neurons in the anterior cerebellar nuclei, with predominantly zebrin-negative Purkinje cells' inputs, displayed dramatic loss of Purkinje cells' innervation, while neurons in the posterior cerebellar nuclei, innervated by both zebrin-negative and zebrin-positive terminals, showed greater resiliency. Together, our results highlight that cerebellar location and zebrin molecular identity appear important to the vulnerability of Purkinje cells and their innervation in the cerebellar nuclei in Christianson syndrome.",
      "author": "Masson, L.-C., Tourbina-Kolomiets, J., Marquez, B. T., Watt, A. J., McKinney, R. A.",
      "published_date": "2026-01-05T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 250,
      "reading_time": 1,
      "created_at": "2026-01-06T03:40:18.807597+00:00",
      "updated_at": "2026-01-06T04:35:54.489824+00:00",
      "metadata": {
        "processed_at": "2026-01-06T04:35:54.489825+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "3c8470c23ff8be8a416bb2fa09cb697d",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.05.697753v1?rss=1",
      "title": "HONeD-in on Brain Activity: Deconvolving Passive Diffusion on the Structural Network from Functional Brain Signals",
      "content": "Brain regions perform distinct computations, and their signals propagate through the whole-brain white matter network. Yet, mathematical models that describe this signal propagation via purely passive diffusion can predict a considerable amount of the observed functional connectivity between regions. This raises a critical question: if so much functional connectivity can be explained by a passive process, how can we isolate the active process? Here, we calculate in closed-form an estimate for such an active signal in functional MRI by spatially deconvolving the effect of passive signal spread over the brain's structural connectivity using a higher-order network diffusion (HONeD) model. Across 770 Human Connectome Project subjects, we show that the resulting HONeD-innovation (HONeD-in) signal 1) sparsifies functional connectivity while retaining a well-connected network, 2) remodels resting-state networks (RSNs), 3) mixes the unimodal--multimodal hierarchical organization of RSNs into a circle with no clear hierarchy, and 4) deblurs task-activation maps. Together, our results highlight HONeD deconvolution as a generalizable new way to study resting-state and task fMRI brain signals.",
      "author": "Sipes, B. S., Arab, F., Nagarajan, S., Raj, A.",
      "published_date": "2026-01-05T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 166,
      "reading_time": 1,
      "created_at": "2026-01-06T03:40:18.807542+00:00",
      "updated_at": "2026-01-06T04:35:54.489827+00:00",
      "metadata": {
        "processed_at": "2026-01-06T04:35:54.489829+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "8057d50ed0efb2e0a2ccee59885388e7",
      "url": "https://www.ycombinator.com/companies/gogograndparent/jobs/2vbzAw8-gogograndparent-yc-s16-is-hiring-backend-and-full-stack-engineers",
      "title": "GoGoGrandparent (YC S16) Is Back End Engineers",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46508441\">Comments</a>",
      "author": "",
      "published_date": "2026-01-06T03:32:41+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-06T03:39:37.589484+00:00",
      "updated_at": "2026-01-06T04:35:54.489831+00:00",
      "metadata": {
        "processed_at": "2026-01-06T04:35:54.489833+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "8057d50ed0efb2e0a2ccee59885388e7",
      "url": "https://www.ycombinator.com/companies/gogograndparent/jobs/2vbzAw8-gogograndparent-yc-s16-is-hiring-backend-and-full-stack-engineers",
      "title": "GoGoGrandparent (YC S16) Is Back End Engineers",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46508441\">Comments</a>",
      "author": "",
      "published_date": "2026-01-06T03:32:41+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-06T03:39:37.589484+00:00",
      "updated_at": "2026-01-06T04:35:54.489831+00:00",
      "metadata": {
        "processed_at": "2026-01-06T04:35:54.489833+00:00",
        "processing_method": "github_actions"
      }
    }
  ]
}