{
  "last_updated": "2025-12-03T06:24:48.621223+00:00",
  "pending_count": 698,
  "processed_count": 302,
  "pending_articles": [
    {
      "id": "094f3a35ae7c2b9c5e80b5253fc99489",
      "url": "https://arxiv.org/abs/2512.02785",
      "title": "Perception of AI-Generated Music - The Role of Composer Identity, Personality Traits, Music Preferences, and Perceived Humanness",
      "content": "arXiv:2512.02785v1 Announce Type: new \nAbstract: The rapid rise of AI-generated art has sparked debate about potential biases in how audiences perceive and evaluate such works. This study investigates how composer information and listener characteristics shape the perception of AI-generated music, adopting a mixed-method approach. Using a diverse set of stimuli across various genres from two AI music models, we examine effects of perceived authorship on liking and emotional responses, and explore how attitudes toward AI, personality traits, and music-related variables influence evaluations. We further assess the influence of perceived humanness and analyze open-ended responses to uncover listener criteria for judging AI-generated music. Attitudes toward AI proved to be the best predictor of both liking and emotional intensity of AI-generated music. This quantitative finding was complemented by qualitative themes from our thematic analysis, which identified ethical, cultural, and contextual considerations as important criteria in listeners' evaluations of AI-generated music. Our results offer a nuanced view of how people experience music created by AI tools and point to key factors and methodological considerations for future research on music perception in human-AI interaction.",
      "author": "David Stammer, Hannah Strauss, Peter Knees",
      "published_date": "2025-12-03T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 180,
      "reading_time": 1,
      "created_at": "2025-12-03T05:21:26.939816+00:00",
      "updated_at": "2025-12-03T05:21:26.939817+00:00"
    },
    {
      "id": "7c52ef81c525030841b3c2067a2e9851",
      "url": "https://arxiv.org/abs/2512.02651",
      "title": "Real-Time Multimodal Data Collection Using Smartwatches and Its Visualization in Education",
      "content": "arXiv:2512.02651v1 Announce Type: new \nAbstract: Wearable sensors, such as smartwatches, have become increasingly prevalent across domains like healthcare, sports, and education, enabling continuous monitoring of physiological and behavioral data. In the context of education, these technologies offer new opportunities to study cognitive and affective processes such as engagement, attention, and performance. However, the lack of scalable, synchronized, and high-resolution tools for multimodal data acquisition continues to be a significant barrier to the widespread adoption of Multimodal Learning Analytics in real-world educational settings. This paper presents two complementary tools developed to address these challenges: Watch-DMLT, a data acquisition application for Fitbit Sense 2 smartwatches that enables real-time, multi-user monitoring of physiological and motion signals; and ViSeDOPS, a dashboard-based visualization system for analyzing synchronized multimodal data collected during oral presentations. We report on a classroom deployment involving 65 students and up to 16 smartwatches, where data streams including heart rate, motion, gaze, video, and contextual annotations were captured and analyzed. Results demonstrate the feasibility and utility of the proposed system for supporting fine-grained, scalable, and interpretable Multimodal Learning Analytics in real learning environments.",
      "author": "Alvaro Becerra, Pablo Villegas, Ruth Cobos",
      "published_date": "2025-12-03T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 181,
      "reading_time": 1,
      "created_at": "2025-12-03T05:21:26.939785+00:00",
      "updated_at": "2025-12-03T05:21:26.939787+00:00"
    },
    {
      "id": "69153ed6c7efd43a8b83555f901bb3ac",
      "url": "https://arxiv.org/abs/2512.02608",
      "title": "Investigating the Integrated Digital Interventions Delivered by a Therapeutic Companion Agent for Young Adults with Symptoms of Depression: A Proof-of-Concept Study",
      "content": "arXiv:2512.02608v1 Announce Type: new \nAbstract: Background: Despite the clinical effectiveness of digital interventions for young adults with depression, low engagement and adherence remain persistent challenges. Building a strong digital therapeutic alliance has been proposed to address these barriers. This study highlights the need for a conversational therapeutic companion agent (TCA)-based intervention design. Objective: This study aimed to develop a Wizard-of-Oz TCA-centered prototype integrating social-support-based ecological momentary assessment (EMA), ecological momentary intervention (EMI), behavioral activation, and gamification. We evaluated the six-week proof-of-concept efficacy of this intervention among young adults with depressive symptoms. Methods: Korean young adults aged 20--39 years with mild-to-moderate depressive symptoms (PHQ-9) were recruited online. The intervention group ($n = 29$) received a six-week TCA-based digital intervention, while the control group ($n = 29$), recruited four weeks later, continued their usual routines. The TCA guided four daily behavioral-activation tasks, three mood assessments, meditation, daily summaries, and weekly mission feedback. Both groups were assessed at baseline and at weeks 2, 4, and 6 using the BDI-II, GAD-7, and Q-LES-Q-SF. Results: Of 58 participants, 57 completed the study (one dropout in the intervention group). At week 6, the intervention group showed significantly greater reductions in depressive symptoms and improvements in quality of life than controls. Adherence was 78\\% for EMA, 51\\% for EMI, and 65\\% for daily routines. Conclusions: The TCA-based digital intervention improved depressive symptoms and quality of life with adherence levels comparable to previous digital health interventions. Future studies should refine the TCA design and conduct larger-scale evaluations.",
      "author": "Youngjae Yoo, Minuk Kim, Soyoung Kim, Gayeon Lee, Jinwoo Kim",
      "published_date": "2025-12-03T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 249,
      "reading_time": 1,
      "created_at": "2025-12-03T05:21:26.939754+00:00",
      "updated_at": "2025-12-03T05:21:26.939756+00:00"
    },
    {
      "id": "97485487864ba36937423ef5d33f9b3d",
      "url": "https://arxiv.org/abs/2512.02569",
      "title": "Reframing Human-Robot Interaction Through Extended Reality: Unlocking Safer, Smarter, and More Empathic Interactions with Virtual Robots and Foundation Models",
      "content": "arXiv:2512.02569v1 Announce Type: new \nAbstract: This perspective reframes human-robot interaction (HRI) through extended reality (XR), arguing that virtual robots powered by large foundation models (FMs) can serve as cognitively grounded, empathic agents. Unlike physical robots, XR-native agents are unbound by hardware constraints and can be instantiated, adapted, and scaled on demand, while still affording embodiment and co-presence. We synthesize work across XR, HRI, and cognitive AI to show how such agents can support safety-critical scenarios, socially and cognitively empathic interaction across domains, and outreaching physical capabilities with XR and AI integration. We then discuss how multimodal large FMs (e.g., large language model, large vision model, and vision-language model) enable context-aware reasoning, affect-sensitive situations, and long-term adaptation, positioning virtual robots as cognitive and empathic mediators rather than mere simulation assets. At the same time, we highlight challenges and potential risks, including overtrust, cultural and representational bias, privacy concerns around biometric sensing, and data governance and transparency. The paper concludes by outlining a research agenda for human-centered, ethically grounded XR agents - emphasizing multi-layered evaluation frameworks, multi-user ecosystems, mixed virtual-physical embodiment, and societal and ethical design practices to envision XR-based virtual agents powered by FMs as reshaping future HRI into a more efficient and adaptive paradigm.",
      "author": "Yuchong Zhang, Yong Ma, Danica Kragic",
      "published_date": "2025-12-03T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 204,
      "reading_time": 1,
      "created_at": "2025-12-03T05:21:26.939718+00:00",
      "updated_at": "2025-12-03T05:21:26.939720+00:00"
    },
    {
      "id": "7a9f5e12c2c79e568213fc85e5770a63",
      "url": "https://arxiv.org/abs/2512.02442",
      "title": "A Visual Analytics System to Understand Behaviors of Multi Agents in Reinforcement Learning",
      "content": "arXiv:2512.02442v1 Announce Type: new \nAbstract: Multi-Agent Reinforcement Learning (MARL) is a branch of machine learning in which agents interact and learn optimal policies through trial and error, addressing complex scenarios where multiple agents interact and learn in the same environment at the same time. Analyzing and understanding these complex interactions is challenging, and existing analysis methods are limited in their ability to fully reflect and interpret this complexity. To address these challenges, we provide MARLViz, a visual analytics system for visualizing and analyzing the policies and interactions of agents in MARL environments. The system is designed to visually show the difference in behavior of agents under different environment settings and help users understand complex interaction patterns. In this study, we analyzed agents with similar behaviors and selected scenarios to understand the interactions of the agents, which made it easier to understand the strategies of agents in MARL.",
      "author": "Changhee Lee, Jeongmin Rhee, DongHwa Shin",
      "published_date": "2025-12-03T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 147,
      "reading_time": 1,
      "created_at": "2025-12-03T05:21:26.939686+00:00",
      "updated_at": "2025-12-03T05:21:26.939688+00:00"
    },
    {
      "id": "4c7a96734bec7aba10590231b09fb46e",
      "url": "https://arxiv.org/abs/2512.02288",
      "title": "Artographer: a Curatorial Interface for Art Space Exploration",
      "content": "arXiv:2512.02288v1 Announce Type: new \nAbstract: Relating a piece to previously established works is crucial in creating and engaging with art, but AI interfaces tend to obscure such relationships, rather than helping users explore them. Embedding models present new opportunities to support discovering and relating artwork through spatial interaction. We built Artographer, an art exploration system featuring a zoomable 2-D map, constructed from the similarity-clustered embeddings of 15,000+ historical artworks. Using Artographer as a probe to investigate spatial artwork exploration, we analyzed how 20 participants (including 9 art history scholars) traversed the map, during a goal-driven task and when freely exploring. We observe divergent and convergent exploration behaviors (Jumping, Wandering, Fixation, Revisiting) and identify values enacted by spatial art-finding (Visibility, Agency, Serendipity, Friction.) We situate spatial maps within a space of Curatorial Interfaces, systems that select and present artworks, and discuss centering pluralism and agency in the design of more responsible AI systems for art curation.",
      "author": "Shm Garanganao Almeda, John Joon Young Chung, Bjoern Hartmann, Sophia Liu, Brett Halperin, Yuwen Lu, Max Kreminski",
      "published_date": "2025-12-03T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 155,
      "reading_time": 1,
      "created_at": "2025-12-03T05:21:26.939658+00:00",
      "updated_at": "2025-12-03T05:21:26.939660+00:00"
    },
    {
      "id": "142a93fa1e9d9df0071c499bc9b703b2",
      "url": "https://arxiv.org/abs/2512.02275",
      "title": "Understanding Down Syndrome Stereotypes in LLM-Based Personas",
      "content": "arXiv:2512.02275v1 Announce Type: new \nAbstract: We present a case study of Persona-L, a system that leverages large language models (LLMs) and retrieval-augmented generation (RAG) to model personas of people with Down syndrome. Existing approaches to persona creation can often lead to oversimplified or stereotypical profiles of people with Down Syndrome. To that end, we built stereotype detection capabilities into Persona-L. Through interviews with caregivers and healthcare professionals (N=10), we examine how Down Syndrome stereotypes could manifest in both, content and delivery of LLMs, and interface design. Our findings show the challenges in stereotypes definition, and reveal the potential stereotype emergence from the training data, interface design, and the tone of LLM output. This highlights the need for participatory methods that capture the heterogeneity of lived experiences of people with Down Syndrome.",
      "author": "Chantelle Wu, Peinan Wang, Nafi Nibras, Meida Li, Dajun Yuan, Zhixiao Wang, Jiahuan He, Mona Ali, Mirjana Prpa",
      "published_date": "2025-12-03T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 131,
      "reading_time": 1,
      "created_at": "2025-12-03T05:21:26.939624+00:00",
      "updated_at": "2025-12-03T05:21:26.939626+00:00"
    },
    {
      "id": "a0fea8162a5e1a31c32c09bc157db76e",
      "url": "https://arxiv.org/abs/2512.02263",
      "title": "DepthScape: Authoring 2.5D Designs via Depth Estimation, Semantic Understanding, and Geometry Extraction",
      "content": "arXiv:2512.02263v1 Announce Type: new \nAbstract: 2.5D effects, such as occlusion and perspective foreshortening, enhance visual dynamics and realism by incorporating 3D depth cues into 2D designs. However, creating such effects remains challenging and labor-intensive due to the complexity of depth perception. We introduce DepthScape, a human-AI collaborative system that facilitates 2.5D effect creation by directly placing design elements into 3D reconstructions. Using monocular depth reconstruction, DepthScape transforms images into 3D reconstructions where visual contents are placed to automatically achieve realistic occlusion and perspective foreshortening. To further simplify 3D placement through a 2D viewport, DepthScape uses a vision-language model to analyze source images and extract key visual components as content anchors for direct manipulation editing. We evaluate DepthScape with nine participants of varying design backgrounds, confirming the effectiveness of our creation pipeline. We also test on 100 professional stock images to assess robustness, and conduct an expert evaluation that confirms the quality of DepthScape's results.",
      "author": "Xia Su, Cuong Nguyen, Matheus A. Gadelha, Jon E. Froehlich",
      "published_date": "2025-12-03T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 154,
      "reading_time": 1,
      "created_at": "2025-12-03T05:21:26.939596+00:00",
      "updated_at": "2025-12-03T05:21:26.939597+00:00"
    },
    {
      "id": "18037a3721e6dd03175033cdec225726",
      "url": "https://arxiv.org/abs/2512.02179",
      "title": "Young Children's Anthropomorphism of AI Chatbots and the Role of Parent Co-Presence",
      "content": "arXiv:2512.02179v1 Announce Type: new \nAbstract: Artificial Intelligence (AI) chatbots powered by a large language model (LLM) are entering young children's learning and play, yet little is known about how young children construe these agents or how such construals relate to engagement. We examined anthropomorphism of a social AI chatbot during collaborative storytelling and asked how children's attributions related to their behavior and prefrontal activation. Children at ages 5-6 (N = 23) completed three storytelling sessions: interacting with (1) an AI chatbot only, (2) a parent only, and (3) the AI and a parent together. After the sessions, children completed an interview assessing anthropomorphism toward both the AI chatbot and the parent. Behavioral engagement was indexed by the conversational turn count (CTC) ratio, and concurrent fNIRS measured oxygenated hemoglobin in bilateral vmPFC and dmPFC regions. Children reported higher anthropomorphism for parents than for the AI chatbot overall, although AI ratings were relatively high for perceptive abilities and epistemic states. Anthropomorphism was not associated with CTC. In the right dmPFC, higher perceptive scores were associated with greater activation during the AI-only condition and with lower activation during the AI+Parent condition. Exploratory analyses indicated that higher dmPFC activation during the AI-only condition correlated with higher end-of-session \"scared\" mood ratings. Findings suggest that stronger perceptive anthropomorphism can be associated with greater brain activation related to interpreting the AI's mental states, whereas parent co-presence may help some children interpret and regulate novel AI interactions. These results may have design implications for encouraging parent-AI co-use in early childhood.",
      "author": "Pilyoung Kim, Jenna H. Chin, Yun Xie, Nolan Brady, Tom Yeh, Sujin Yang",
      "published_date": "2025-12-03T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 252,
      "reading_time": 1,
      "created_at": "2025-12-03T05:21:26.939558+00:00",
      "updated_at": "2025-12-03T05:21:26.939564+00:00"
    },
    {
      "id": "f1bb21dbce210f80422914a001e3d982",
      "url": "https://arxiv.org/abs/2511.20532",
      "title": "MIMIC-MJX: Neuromechanical Emulation of Animal Behavior",
      "content": "arXiv:2511.20532v2 Announce Type: replace \nAbstract: The primary output of the nervous system is movement and behavior. While recent advances have democratized pose tracking during complex behavior, kinematic trajectories alone provide only indirect access to the underlying control processes. Here we present MIMIC-MJX, a framework for learning biologically-plausible neural control policies from kinematics. MIMIC-MJX models the generative process of motor control by training neural controllers that learn to actuate biomechanically-realistic body models in physics simulation to reproduce real kinematic trajectories. We demonstrate that our implementation is accurate, fast, data-efficient, and generalizable to diverse animal body models. Policies trained with MIMIC-MJX can be utilized to both analyze neural control strategies and simulate behavioral experiments, illustrating its potential as an integrative modeling framework for neuroscience.",
      "author": "Charles Y. Zhang (Harvard University), Yuanjia Yang (Salk Institute for Biological Studies), Aidan Sirbu (Mila), Elliott T. T. Abe (University of Washington), Emil W\\\"arnberg (Harvard University), Eric J. Leonardis (Salk Institute for Biological Studies), Diego E. Aldarondo (Harvard University), Adam Lee (Harvard University), Aaditya Prasad (Massachusetts Institute of Technology), Jason Foat (Salk Institute for Biological Studies), Kaiwen Bian (Salk Institute for Biological Studies), Joshua Park (Salk Institute for Biological Studies), Rusham Bhatt (Salk Institute for Biological Studies), Hutton Saunders (Salk Institute for Biological Studies), Akira Nagamori (Salk Institute for Biological Studies), Ayesha R. Thanawalla (Salk Institute for Biological Studies), Kee Wui Huang (Salk Institute for Biological Studies), Fabian Plum (Imperial College London), Hendrik K. Beck (Imperial College London), Steven W. Flavell (Massachusetts Institute of Technology), David Labonte (Imperial College London), Blake A. Richards (Mila), Bingni W. Brunton (University of Washington), Eiman Azim (Salk Institute for Biological Studies), Bence P. \\\"Olveczky (Harvard University), Talmo D. Pereira (Salk Institute for Biological Studies)",
      "published_date": "2025-12-03T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 122,
      "reading_time": 1,
      "created_at": "2025-12-03T05:21:25.811909+00:00",
      "updated_at": "2025-12-03T05:21:25.811910+00:00"
    }
  ],
  "recently_processed": [
    {
      "id": "fdc75d13e9c7e260b8387c574c6a2c5a",
      "url": "https://www.sciencedirect.com/science/article/pii/S0306452225011248?dgcid=rss_sd_all",
      "title": "Modified constraint-induced movement therapy combined with intermittent theta-burst stimulation promotes functional recovery in MCAO rats by enhancing synaptic plasticity in the ipsilateral hippocampal CA1",
      "content": "<p>Publication date: 9 January 2026</p><p><b>Source:</b> Neuroscience, Volume 592</p><p>Author(s): Tiantian Jia, Jian Hu, Yuyuan Wang, Congqin Li, Yan Hua, Yulong Bai</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroscience Journal",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 20,
      "reading_time": 1,
      "created_at": "2025-12-03T05:44:44.360799+00:00",
      "updated_at": "2025-12-03T06:24:48.517024+00:00",
      "metadata": {
        "processed_at": "2025-12-03T06:24:48.517033+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "4c9bf85b6fee62899fef0d48c374559d",
      "url": "https://www.sciencedirect.com/science/article/pii/S1053811925006019?dgcid=rss_sd_all",
      "title": "Resolution generalization of deep learning-based dipole inversion networks for QSM",
      "content": "<p>Publication date: 15 December 2025</p><p><b>Source:</b> NeuroImage, Volume 324</p><p>Author(s): Sooyeon Ji, Minjun Kim, Jongho Lee, Hyeong-Geol Shin</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroimage",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 16,
      "reading_time": 1,
      "created_at": "2025-12-03T05:44:42.172347+00:00",
      "updated_at": "2025-12-03T06:24:48.517037+00:00",
      "metadata": {
        "processed_at": "2025-12-03T06:24:48.517039+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "10650446bd00d6310435d76e0596cd68",
      "url": "https://www.sciencedirect.com/science/article/pii/S1053811925006184?dgcid=rss_sd_all",
      "title": "Expertise-related functional connectivity changes in Chinese calligraphy linked to flow experience",
      "content": "<p>Publication date: 15 December 2025</p><p><b>Source:</b> NeuroImage, Volume 324</p><p>Author(s): Qingyan Kong, Yue Wang, Min Li, Buxin Han, Rui Li</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroimage",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 18,
      "reading_time": 1,
      "created_at": "2025-12-03T05:44:42.172328+00:00",
      "updated_at": "2025-12-03T06:24:48.517042+00:00",
      "metadata": {
        "processed_at": "2025-12-03T06:24:48.517043+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "9d414f3b56ac788715b1f6d8b57a6e78",
      "url": "https://fmhy.net/posts/Nov-2025",
      "title": "Monthly Updates [November]",
      "content": "<div class=\"info custom-block\"><p class=\"custom-block-title\">INFO</p>\n<p>These update threads only contains major updates. If you're interested\nin seeing all minor changes you can follow our\n<a href=\"https://github.com/fmhy/FMHYedit/commits/main\" rel=\"noreferrer\" target=\"_blank\">Commits Page</a> on GitHub or\n<a href=\"https://redd.it/17f8msf\" rel=\"noreferrer\" target=\"_blank\">Updates Channel</a> in Discord.</p>\n</div>\n<h1 id=\"wiki-updates\" tabindex=\"-1\">Wiki Updates <a class=\"header-anchor\" href=\"#wiki-updates\"></a></h1>\n<ul>\n<li>\n<p>Added the <strong><a href=\"https://i.ibb.co/hx97zL3W/978676.jpg\" rel=\"noreferrer\" target=\"_blank\">Amoled Theme</a></strong> / <a href=\"https://i.imgur.com/fMrnGmF.png\" rel=\"noreferrer\" target=\"_blank\">2</a> to our site as a <a href=\"https://i.ibb.co/pvkfg3hC/image.png\" rel=\"noreferrer\" target=\"_blank\">Toggle</a> / <a href=\"https://i.imgur.com/qF7exKw.png\" rel=\"noreferrer\" target=\"_blank\">2</a> that can be turned on or off. Thank you to @Land for doing this.</p>\n</li>\n<li>\n<p>Built a <strong><a href=\"https://fmhy-search.dev.zenir.tech/\" rel=\"noreferrer\" target=\"_blank\">External Search Engine</a></strong> that should work better in most cases than the built in VitePress search on our website.</p>\n</li>\n<li>\n<p>Added a <strong><a href=\"https://fmhyclone.pages.dev/\" rel=\"noreferrer\" target=\"_blank\">New Backup</a></strong> of FMHY with daily sync, hosted on GitLab. It also has a backup of the <a href=\"https://fmhyapi.wispy.qzz.io/single-page\" rel=\"noreferrer\" target=\"_blank\">raw markdown</a> page. We also added another <a href=\"https://a-fmhy.pages.dev/\" rel=\"noreferrer\" target=\"_blank\">backup</a> of our website that has the theme on from above on automatically.</p>\n</li>\n<li>\n<p>The Space section has become a bit hard to navigate (60+ lines,) so we've split it into its <a href=\"https://fmhy.net/educational#space\" rel=\"noreferrer\" target=\"_blank\">own head section</a>, with 2 new subsections: <a href=\"https://fmhy.net/educational#astronomy\" rel=\"noreferrer\" target=\"_blank\">Astronomy</a> and <a href=\"https://fmhy.net/educational#spacecraft\" rel=\"noreferrer\" target=\"_blank\">Spacecraft</a>. Astronomy will cover things related to celestial objects or phenomena in the cosmos. Spacecraft will cover things like rockets, launches and the ISS. The head section will be for more general space related things, like NASAs website, news, etc.</p>\n</li>\n<li>\n<p>Remakes / Ports in gaming had over 80 lines, and was pretty disorganized, so we've split it into 3 new sections to make it more comprehensible: <a href=\"https://fmhy.net/gaming#decomps-ports\" rel=\"noreferrer\" target=\"_blank\">Decomps / Ports</a>, <a href=\"https://fmhy.net/gaming#remakes-recreations\" rel=\"noreferrer\" target=\"_blank\">Remakes / Recreations</a> and <a href=\"https://fmhy.net/gaming#revival-projects\" rel=\"noreferrer\" target=\"_blank\">Revival Projects</a>. Also turned Special Interest into its own head category to help organize TOC better.</p>\n</li>\n<li>\n<p>Re-ordered <a href=\"https://fmhy.net/reading#manga\" rel=\"noreferrer\" target=\"_blank\">Manga Sites</a> based on poll results from our Discord. Weeb Central has been moved to #1 spot, and MangaFire + MangaNato have both been starred. Thank you to everyone who took part in voting and gave their thoughts. <a href=\"https://i.ibb.co/j9Sn4hRR/image.png\" rel=\"noreferrer\" target=\"_blank\">Before vs After</a> / <a href=\"https://i.imgur.com/u8zFZTX.png\" rel=\"noreferrer\" target=\"_blank\">2</a>.</p>\n</li>\n<li>\n<p>Cleaned up multiple Audio Streaming sections, and added new ones to help better organize it including: <a href=\"https://fmhy.net/audio#specialty-streaming\" rel=\"noreferrer\" target=\"_blank\">Specialty</a>, <a href=\"https://fmhy.net/audio#genre-specific-streaming\" rel=\"noreferrer\" target=\"_blank\">Genre Specific</a>, <a href=\"https://fmhy.net/audio#radio-directories\" rel=\"noreferrer\" target=\"_blank\">Radio Directories</a>, and <a href=\"https://fmhy.net/audio#lofi-radio\" rel=\"noreferrer\" target=\"_blank\">Lofi Radio</a>. <a href=\"https://github.com/fmhy/edit/pull/4128#issuecomment-3476036920\" rel=\"noreferrer\" target=\"_blank\">Before vs. After</a>. Thank you to @AnarchyDR for doing this.</p>\n</li>\n<li>\n<p>Updated <a href=\"https://fmhy.net/audio\" rel=\"noreferrer\" target=\"_blank\">Audio Streaming</a> table of contents to make it less cluttered and easier to navigate. <a href=\"https://i.ibb.co/0yJbh03H/234243.jpg\" rel=\"noreferrer\" target=\"_blank\">Before vs After</a> / <a href=\"https://i.imgur.com/fhgqKzb.png\" rel=\"noreferrer\" target=\"_blank\">2</a>.</p>\n</li>\n<li>\n<p>Cleaned up <a href=\"https://fmhy.net/gaming#browser-emulators\" rel=\"noreferrer\" target=\"_blank\">Browser Emulators</a>, fixed labels, removed dead sites, bumped sites with multiple, or unique emulators higher, and moved any only serving as EmulatorJS / NeptunJS frontends to storage. <a href=\"https://i.ibb.co/LXdhcDFD/Untitled.png\" rel=\"noreferrer\" target=\"_blank\">Before vs After</a> / <a href=\"https://i.imgur.com/W9x8jY4.png\" rel=\"noreferrer\" target=\"_blank\">2</a>.</p>\n</li>\n<li>\n<p>We removed the &quot;No Torrenting&quot; label from ProtonVPN as you can set it up with a OpenVPN config that allows you to torrent for free. Note that they do expire and must be regenerated sometimes. Guide is listed next to <a href=\"https://fmhy.net/privacy#vpn\" rel=\"noreferrer\" target=\"_blank\">Proton</a>. TY to Wispy and others for figuring this out.</p>\n</li>\n<li>\n<p>Added <a href=\"https://fmhy.net/gaming#tetris\" rel=\"noreferrer\" target=\"_blank\">Tetris</a> Section to Gaming.</p>\n</li>\n<li>\n<p>Fixed ugly formatting in Game Optimization. <a href=\"https://i.ibb.co/Vc99kJhh/image.png\" rel=\"noreferrer\" target=\"_blank\">Before vs After</a> / <a href=\"https://i.imgur.com/HRPUwL3.png\" rel=\"noreferrer\" target=\"_blank\">2</a>.</p>\n</li>\n</ul>\n<hr />\n<h1 id=\"stars-added-\u2b50\" tabindex=\"-1\">Stars Added \u2b50 <a class=\"header-anchor\" href=\"#stars-added-\u2b50\"></a></h1>\n<ul>\n<li>\n<p>Starred <a href=\"https://fmhy.net/file-tools#download-managers\" rel=\"noreferrer\" target=\"_blank\">AB Download Manager</a> in Download Managers. Open source, fast, cross platform, has resumable downloads, and a active dev team.</p>\n</li>\n<li>\n<p>Bumped <a href=\"https://fmhy.net/gaming#rom-sites\" rel=\"noreferrer\" target=\"_blank\">CrocDB</a> to new #1 over Myrient in ROM sites. Croc covers multiple sites (including myrient), has a better UI, and a new rompack feature.</p>\n</li>\n<li>\n<p>Starred <a href=\"https://fmhy.net/video#torrent-apps\" rel=\"noreferrer\" target=\"_blank\">PlayTorrio</a> in Torrent Streaming Apps. New client that is very feature rich. It has similar addons to Stremio, such as Torrentio. It also has Jackett integration, Debrid support, and so many other features we're unable to list them all here.</p>\n</li>\n<li>\n<p>Starred <a href=\"https://fmhy.net/ai#specialized-chatbots\" rel=\"noreferrer\" target=\"_blank\">NotebookLM</a> in Specialized Chatbots. Document chatbots + note taking. Works well for quickly studying, has good audio/video overviews, can generate quizzes, flashcards, etc.</p>\n</li>\n<li>\n<p>Starred <a href=\"https://fmhy.net/video#anime-streaming\" rel=\"noreferrer\" target=\"_blank\">Anidap</a> in Anime Streaming. Has a nice UI, uses hosts that are both unique and fast.</p>\n</li>\n<li>\n<p>Starred <a href=\"https://fmhy.net/video#live-tv\" rel=\"noreferrer\" target=\"_blank\">PlayTorrio IPTV</a> in Live TV / Sports. Fast streams, huge library, good quality, one of the better Live TV sites we've been sent in awhile. Note that Darkness TV is the original, PlayTorrio just improved on their UI.</p>\n</li>\n<li>\n<p>Starred <a href=\"https://fmhy.net/linux-macos#linux-gaming\" rel=\"noreferrer\" target=\"_blank\">Heroic Games Launcher</a> in Linux Gaming. Linux game launcher for Epic, GOG, and prime games, better maintained than Lutris now.</p>\n</li>\n<li>\n<p>Starred <a href=\"https://fmhy.net/reading#curated-recommendations\" rel=\"noreferrer\" target=\"_blank\">ComicBookRoundup</a> in Reading Recommendations. Comic focused review / rating aggregator, similar to Metacritic or Rotten Tomatoes.</p>\n</li>\n<li>\n<p>Starred <a href=\"https://fmhy.net/gaming#rom-sites\" rel=\"noreferrer\" target=\"_blank\">Ziperto</a> in ROM Sites. Been around for a long time now, has a solid library, and uses fast hosts.</p>\n</li>\n<li>\n<p>Starred <a href=\"https://fmhy.net/video#live-sports\" rel=\"noreferrer\" target=\"_blank\">Sportsbite</a> in live sports. Aggregator with lots of hosts, nice UI, covers most big events.</p>\n</li>\n</ul>\n<hr />\n<h1 id=\"things-removed\" tabindex=\"-1\">Things Removed <a class=\"header-anchor\" href=\"#things-removed\"></a></h1>\n<ul>\n<li>\n<p>Removed DramaGo as they seem to have shut down.</p>\n</li>\n<li>\n<p>Unstarred Character.AI as they had to <a href=\"https://deadline.com/2025/09/disney-cease-and-desist-letter-characterai-copyright-infringement-1236566831\" rel=\"noreferrer\" target=\"_blank\">remove a bunch of characters</a> recently due to copyright, and people were already unhappy with their limits / restrictions.</p>\n</li>\n</ul>",
      "author": "",
      "published_date": "2025-11-01T00:00:00+00:00",
      "source": "Fmhy",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 924,
      "reading_time": 4,
      "created_at": "2025-12-03T05:44:02.146986+00:00",
      "updated_at": "2025-12-03T06:24:48.517046+00:00",
      "metadata": {
        "processed_at": "2025-12-03T06:24:48.517047+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "bf00ce07992ad1768ae8f3571d82eaf9",
      "url": "https://arxiv.org/abs/2512.02848",
      "title": "Humans incorrectly reject confident accusatory AI judgments",
      "content": "arXiv:2512.02848v1 Announce Type: new \nAbstract: Automated verbal deception detection using methods from Artificial Intelligence (AI) has been shown to outperform humans in disentangling lies from truths. Research suggests that transparency and interpretability of computational methods tend to increase human acceptance of using AI to support decisions. However, the extent to which humans accept AI judgments for deception detection remains unclear. We experimentally examined how an AI model's accuracy (i.e., its overall performance in deception detection) and confidence (i.e., the model's uncertainty in single-statements predictions) influence human adoption of the model's judgments. Participants (n=373) were presented with veracity judgments of an AI model with high or low overall accuracy and various degrees of prediction confidence. The results showed that humans followed predictions from a highly accurate model more than from a less accurate one. Interestingly, the more confident the model, the more people deviated from it, especially if the model predicted deception. We also found that human interaction with algorithmic predictions either worsened the machine's performance or was ineffective. While this human aversion to accept highly confident algorithmic predictions was partly explained by participants' tendency to overestimate humans' deception detection abilities, we also discuss how truth-default theory and the social costs of accusing someone of lying help explain the findings.",
      "author": "Riccardo Loconte, Merylin Monaro, Pietro Pietrini, Bruno Verschuere, Bennett Kleinberg",
      "published_date": "2025-12-03T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 209,
      "reading_time": 1,
      "created_at": "2025-12-03T05:21:26.939849+00:00",
      "updated_at": "2025-12-03T06:24:48.517049+00:00",
      "metadata": {
        "processed_at": "2025-12-03T06:24:48.517051+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "c21dac6942ed3767b45ef8ca6c689b9d",
      "url": "http://ieeexplore.ieee.org/document/11005463",
      "title": "Hybrid KLT\u2014LSTM Tracking for Robust Organ Motion Monitoring in 2D Ultrasound-Guided End-Organ Therapies",
      "content": "Objective: Recent research highlights the potential of ultrasound (US) stimulation as a noninvasive tool for modulating neural and cellular signaling in the spleen and liver to treat inflammatory diseases and diabetes. However, challenges like nerve activation failures, off-target stimulation, and organ motion during respiration can affect treatment efficacy. This study introduces a novel tracking framework for accurate liver and spleen motion tracking using US imaging to overcome these challenges. Methods: The tracking framework integrates an enhanced Kanade\u2013Lucas\u2013Tomasi (EKLT) tracker with a long short-term memory (LSTM) predictor. The EKLT tracker provides precise annotations that improve LSTM training, while the LSTM compensates for occlusions and noise by making predictions based on prior data and dynamically adjusting the region of interest (ROI). Spleen motion tracking was evaluated using 40 recordings from 10 participants, each undergoing four distinct breathing patterns. Additionally, the method was evaluated on a liver motion dataset from MICCAI, collected from 9 subjects. Results: Spleen tracking was most accurate during slow, shallow breathing, with an average error of 0.4 $\\pm$ 0.4 mm, and had an average error of 1.37 $\\pm$ 0.9 mm during fast, deep breathing. Liver tracking results showed high accuracy with an average error of 0.3 $\\pm$ 0.2 mm. Conclusion: The EKLT-LSTM framework offers advantages over previous tracking models, providing high accuracy in tracking liver and spleen motion under occlusion and noisy conditions. Significance: The EKLT-LSTM is suitable for end-organ modulation applications and can be adapted to other ultrasound-guided therapies and bioelectronic medicine.",
      "author": "",
      "published_date": "2025-05-15T13:17:00+00:00",
      "source": "Transactions Biomedical Engineering",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 244,
      "reading_time": 1,
      "created_at": "2025-12-03T04:02:57.172370+00:00",
      "updated_at": "2025-12-03T04:24:34.001210+00:00",
      "metadata": {
        "processed_at": "2025-12-03T04:24:34.001220+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "2c6df70fdce8d45fe5b34a1294ca7808",
      "url": "http://ieeexplore.ieee.org/document/11005693",
      "title": "Personalizing the Pressure Reactivity Index for Quantifying Cerebral Autoregulation in Neurocritical Care",
      "content": "Objective: The Pressure Reactivity Index (PRx) is a common metric for assessing cerebral autoregulation in neurocritical care. This study aimed to enhance the clinical utility of PRx by developing a personalized PRx algorithm (pPRx) and identifying ideal hyperparameters. Methods: Algorithmic errors were quantified using simulated data and multimodal monitoring data from traumatic brain injury patients from the Track-TBI dataset. Using linear regression, heart rate was identified as a potential cause of PRx error. The pPRx method was developed by reparameterizing PRx averaging to heartbeats. Ideal hyperparameters for the standard PRx algorithm were identified that minimized algorithmic errors. Results: PRx was sensitive to hyperparameters and patient variability. Errors were related to patient heart rates. By parameterizing PRx to heartbeats, the pPRx methodology significantly reduced noise and sensitivity to both patient variability and hyperparameter selection. In the standard PRx algorithm, averaging windows of 10 seconds and correlation windows of 40 samples resulted in the lowest overall error. Conclusion: Personalized PRx enhances the robustness and accuracy of cerebral autoregulation estimation by addressing patient- and hyperparameter-sensitivity. This improvement is crucial for reliable clinical decision-making in neurocritical care. Significance: Robust estimation of cerebral autoregulation would be beneficial for identifying precision medicine targets and improving outcomes for neurocritical care patients. We systematically increased the robustness of PRx to make it more consistent across patient populations.",
      "author": "",
      "published_date": "2025-05-15T13:17:00+00:00",
      "source": "Transactions Biomedical Engineering",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 219,
      "reading_time": 1,
      "created_at": "2025-12-03T04:02:57.172332+00:00",
      "updated_at": "2025-12-03T04:24:34.001224+00:00",
      "metadata": {
        "processed_at": "2025-12-03T04:24:34.001229+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "3f16a84b6fed4ebda85a17a01a8956cb",
      "url": "http://ieeexplore.ieee.org/document/11003421",
      "title": "Quantifying the Role of Duodenal Shape in Flow and Mixing: A Computational Fluid Dynamics Study on Anatomically Diverse Models",
      "content": "Objective: Enzymatic digestion of food and absorption of nutrients in the duodenum are affected by flow and mixing driven by peristaltic contractions. Our understanding of how the duodenum shape varies among individuals and how these anatomical differences affect the transport dynamics is limited. Methods: A landmark-free approach was used to perform statistical shape analysis of the duodenum, then computational fluid dynamics (CFD) simulations with anatomically realistic peristaltic contractions were used to characterize the effect of anatomical variations on flow and mixing. Leveraging the inherent tubular \u2018C\u2019 shape of the duodenum, centerlines and cross-sectional areas were computed for CT data from 34 subjects. The average radius and duodenal orientation in the form of the components of the tangent vectors to the centerline at 60 equally spaced (normalised by the centerline length) locations were used as inputs to a principal component analysis (PCA). Results: CFD simulations revealed similar flow features across all geometries including the location of stagnation points and the presence of reversed flow, and swirling patterns. The most extreme geometry, experiencing the largest magnitude of radial contractions, achieved a mixing state approximately twice that of the mean geometry within a 60 s period. Conclusion: This work provides new insights into duodenal shape variation and its impacts on intestinal fluid dynamics. Significance: The methods and datasets developed here have broader implications for understanding gastrointestinal function, digestion, and drug delivery by establishing quantitative links between anatomical variation and digestive processes.",
      "author": "",
      "published_date": "2025-05-13T13:17:02+00:00",
      "source": "Transactions Biomedical Engineering",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 238,
      "reading_time": 1,
      "created_at": "2025-12-03T03:18:56.649646+00:00",
      "updated_at": "2025-12-03T04:24:34.001232+00:00",
      "metadata": {
        "processed_at": "2025-12-03T04:24:34.001234+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "4abf903e26fec7957658c15efeee3be5",
      "url": "http://ieeexplore.ieee.org/document/11003397",
      "title": "Improving Calibration of EMG-Informed Neuromusculoskeletal Models Through Differentiable Physics and Muscle Synergies",
      "content": "Objective: Electromyogram (EMG)-informed neuromusculoskeletal (NMS) models can predict physiologically plausible muscle forces and joint moments. However, calibrating model parameters (e.g., optimal fiber length, tendon slack length) to the individual is time-consuming, with the optimization often requiring hours to converge and typically not accounting for unrecorded muscle excitations. This study addresses these limitations by incorporating differentiable physics and muscle synergies into the calibration of NMS models. Methods: We implemented an NMS model with auto-differentiable Hill-type muscles, enabling the use of adaptive gradient descent optimizers. Two types of calibration were evaluated: a standard EMG-driven approach and a synergy-hybrid approach that also synthesized unrecorded excitations. These methods were evaluated using upper and lower limb data, each from a single participant. Results: The calibration time was reduced by up to 26 times while maintaining comparable accuracy in joint moment predictions. Compared to the EMG-driven calibration, the synergy-hybrid calibration improved the estimates of model parameters for reduced number of EMG channels. Conclusion: Auto-differentiable Hill-type muscle models greatly reduce NMS model calibration time and enable the synthesis of unrecorded muscle excitations through muscle synergies, facilitating the calibration of all muscle parameters. Significance: This new rapid calibration could support deployment of NMS models in time-sensitive applications, including real-time biomechanical analyses and personalized neurorehabilitation.",
      "author": "",
      "published_date": "2025-05-13T13:17:02+00:00",
      "source": "Transactions Biomedical Engineering",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 206,
      "reading_time": 1,
      "created_at": "2025-12-03T03:18:56.649606+00:00",
      "updated_at": "2025-12-03T04:24:34.001236+00:00",
      "metadata": {
        "processed_at": "2025-12-03T04:24:34.001237+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "cf13b70cdb53d67f33440a96bc36cc1d",
      "url": "http://ieeexplore.ieee.org/document/11245650",
      "title": "Compression-Enabled Joint Entropy Estimation for Seizure Detection on Human Intracortical Electroencephalography",
      "content": "Objective: Of the 1% of the world population with epilepsy, one-third have drug-resistant epilepsy and often turn to surgical intervention. Current epilepsy treatment relies on manual review by epileptologists and could benefit from reliable quantitative electroencephalography (qEEG) approaches to speed up evaluation, minimize inter-reviewer variance, and deliver higher quality and more equitable care. Methods: We present the inverse compression ratio (ICR), an estimate of an upper bound of joint entropy using common compression algorithms, as a potential qEEG method for seizure detection. This technique was tested on our repository of 10 kHz intracortical neurophysiological data across 30 participants (15 adults and 15 children, 240+ total seizures). Results: Single-electrode ICR achieved a F1 score of 0.80 and an area under precision-recall curve of 0.69, outperforming conventional qEEG methods. Multielectrode ICR performed within the top 2% of individual electrodes, potentially eliminating the need for electrode selection. Conclusion: ICR may be useful for automated seizure detection; its integration into clinical systems may translate to broad clinical impact. Significance: We believe this clinical study analyzed the largest volume of continuous, multi-day intracortical neuroelectrophysiology for quantitative methods\u2013with 2,900+ recording hours (420,000+ electrode-hours, amounting to 30+ TB of data). It is also the first demonstration of compression-based multidimensional estimation in a biological or clinical application. By computing an ensemble effect without linear assumptions or parametric modeling, ICR offers a model-free solution to the classically combinatorially intractable problem of high-dimensional joint entropy; its application likely extends beyond epilepsy to other domains of biomedical signal processing.",
      "author": "",
      "published_date": "2025-11-13T13:16:42+00:00",
      "source": "Transactions Biomedical Engineering",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 248,
      "reading_time": 1,
      "created_at": "2025-12-03T03:18:56.649568+00:00",
      "updated_at": "2025-12-03T04:24:34.001240+00:00",
      "metadata": {
        "processed_at": "2025-12-03T04:24:34.001242+00:00",
        "processing_method": "github_actions"
      }
    }
  ]
}