{
  "last_updated": "2026-01-22T06:28:06.816558+00:00",
  "pending_count": 703,
  "processed_count": 297,
  "pending_articles": [
    {
      "id": "0034e844e06f50c554f3ea92b4f7be58",
      "url": "https://iopscience.iop.org/article/10.1088/1741-2552/ae2805",
      "title": "A pretrained foundation model for headache disorders based on magnetoencephalography",
      "content": "Objective. Foundation models have demonstrated transformative potential in medical artificial intelligence but remain underexplored in functional neuroimaging, particularly magnetoencephalography (MEG). This study aims to develop a domain-specific, self-supervised MEG clinical foundation model tailored for headache disorders to address the challenges of high-dimensional data and limited labeled datasets in clinical research. Approach. We developed a transformer-based model pretrained on a large-scale dataset comprising multi-state MEG recordings (resting-state, auditory, and somatosensory stimulation) from 416 participants (362 headache patients and 54 healthy controls). The model utilized a self-supervised masked-signal reconstruction strategy to learn latent spatiotemporal representations of neural activity. We evaluated the model\u2019s performance through signal reconstruction, visualization of attention weights, and downstream classification tasks comparing model-derived features against original MEG signals for migraine diagnosis. Main results. The pretrained model successfully reconstructed both continuous MEG signals and stimulus-specific evoked responses, effectively capturing intrinsic spatiotemporal brain dynamics. Visualization of the model\u2019s attention weights demonstrated spatial alignment with corresponding sensory brain regions, confirming its neurophysiological interpretability. Furthermore, classifiers trained on features extracted from the pretrained model significantly outperformed those using original MEG signals in identifying migraine patients, revealing distinct neural response patterns. Significance. This study introduces a scalable, data-efficient framework for clinical MEG analysis that significantly reduces reliance on manual feature extraction and labeled data. It demonstrates the efficacy of foundation models in decoding complex neural dynamics, offering promising implications for understanding neuropathology and facilitating precision diagnostics in neurology.",
      "author": "Pan Liao, Jie Liang, Dong Qiu, Cunxin Lin, Zhonghua Xiong, Hao Wang, Jia-Hong Gao, Yonggang Wang and Bingjiang Lyu",
      "published_date": "2026-01-08T00:00:00+00:00",
      "source": "Journal Neural Engineering",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 234,
      "reading_time": 1,
      "created_at": "2026-01-22T05:55:26.093994+00:00",
      "updated_at": "2026-01-22T05:55:26.093996+00:00"
    },
    {
      "id": "efbd1fbf2b13b98ed3aa0bd6ef3fc254",
      "url": "http://doi.org/10.1037/bne0000632",
      "title": "Chemogenetic modulation of PAC1-expressing neurons in the bed nucleus of the stria terminalis (BNST) alters anxiety-related behaviors in male mice.",
      "content": "Pituitary adenylate cyclase-activating polypeptide (PACAP, <em>ADCYAP1</em>) is a highly conserved neuropeptide that plays essential roles in numerous physiological functions, and central PACAP signaling has been associated with mechanisms regulating stress-induced psychopathologies. PACAP binds to several receptor subtypes, including PAC1 (<em>ADCYAP1R1</em>), VPAC1 (<em>VIPR1</em>), and VPAC2 (<em>VIPR2</em>), to activate several signaling cascades that can alter neuronal excitability and enhance indices of neuroplasticity, and much of our prior work has suggested that the anxiogenic effects of bed nucleus of the stria terminalis (BNST) PACAP depend on the activation of PAC1 receptors. To complement our previous work that evaluated the roles of BNST PACAP expression and secretion in anxiety-related responses, we employed in the current work chemogenetic approaches in male PAC1-Ires-Cre mice to directly and specifically modulate the activities of BNST PAC1 receptor-expressing neurons. Inhibition of BNST PAC1 receptor neuron activity with clozapine-N-oxide significantly increased open arm exploration without reducing total locomotor activity; conversely, stimulating BNST PAC1 receptor function significantly reduced open arm exploratory activities. In sum, these data are consistent with our prior work suggesting a key role for BNST PACAP receptor activation in anxiety and stress; further, these observations importantly clarify the neural circuits involved in anxiety-like behaviors. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2025-09-01T00:00:00+00:00",
      "source": "Behavioral Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 205,
      "reading_time": 1,
      "created_at": "2026-01-22T05:55:05.039085+00:00",
      "updated_at": "2026-01-22T05:55:05.039087+00:00"
    },
    {
      "id": "08e664e88f4ab84df159a973a76a40e7",
      "url": "http://doi.org/10.1037/bne0000634",
      "title": "Conditioned place preferences for virtual reality cannabis cues.",
      "content": "This study investigated whether 221 undergraduates (123 males, 98 females) with varying levels of cannabis use displayed a conditioned place preference (CPP) for a virtual reality (VR) room that previously contained virtual cannabis stimuli compared to a neutral VR room that was not paired with cannabis cues. We hypothesized that cannabis-using participants (<em>n</em> = 180) would spend a greater amount of time in, report greater subjective enjoyment in, and explicitly prefer a VR room that was previously paired with virtual cannabis stimuli relative to a neutral room, while participants with nonuse (<em>n</em> = 41) would not. Overall, participants did not demonstrate an implicit or explicit CPP for a VR room that was previously paired with cannabis cues. Interestingly, however, participants with recent cannabis use (<em>n</em> = 41) exhibited a significant implicit CPP for the cannabis-cue-paired VR room, while participants with nonrecent cannabis use (<em>n</em> = 113) did not. Furthermore, relative to males with cannabis use (<em>n</em> = 93), females with cannabis use (<em>n</em> = 87) demonstrated a significant explicit CPP for the cannabis-cue-paired context as well as significantly greater cannabis cravings. These findings elucidate the need for further research on the role of acute cannabis intoxication, sex, and cue-induced cravings in modulating CPP for cannabis-associated contexts. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2025-09-01T00:00:00+00:00",
      "source": "Behavioral Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 215,
      "reading_time": 1,
      "created_at": "2026-01-22T05:55:05.039050+00:00",
      "updated_at": "2026-01-22T05:55:05.039051+00:00"
    },
    {
      "id": "5168657f83102357e9854c856d6e8912",
      "url": "http://doi.org/10.1037/bne0000630",
      "title": "Paraventricular thalamic inputs to the ventral pallidum shape reward seeking during threat and fear responding in extinction.",
      "content": "Environmental threats are typically encountered when animals are searching for food and other necessities. Adaptive behavior must balance competition between fear behavior and reward seeking. We gave rats local neuronal deletions of the ventral pallidum (VP) or specifically deleted paraventricular thalamic nucleus (PVT) neurons projecting directly to the VP. Rats were then assessed in a conditioned suppression procedure in which cues predicting unique foot shock probabilities were presented during, but independent from, reward seeking. Foot shock introduction generally suppressed reward seeking in rats, and recovery from shock introduction was facilitated in rats with VP or PVT \u2192 VP pathway deletions. Discriminative fear was observed in controls, and this fear responding reduced over a single extinction session. VP deletion enhanced extinction fear responding, and PVT \u2192 VP pathway deletion abolished within-session fear reductions. The results demonstrate the VP and its inputs from the PVT shape reward seeking in threat settings and govern fear extinction responding. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2025-09-01T00:00:00+00:00",
      "source": "Behavioral Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 163,
      "reading_time": 1,
      "created_at": "2026-01-22T05:55:05.039012+00:00",
      "updated_at": "2026-01-22T05:55:05.039014+00:00"
    },
    {
      "id": "b1cdce7f5e061a4ca5bf268adc4e71f2",
      "url": "http://doi.org/10.1037/bne0000629",
      "title": "Patterns of prefrontal cortical activity associated with attention-demanding and motor aspects of dual-task walking as measured with functional near-infrared spectroscopy.",
      "content": "The ability to engage in everyday tasks, such as walking, requires the integration of cognitive and motor processes. How these processes integrate may be discernable through the relation of brain activity patterns to behavioral performance, particularly in the prefrontal cortex (PFC), examination of which has been restricted because of the limitations in experimental design. We related behavior (cognition, walking) to brain activity, as measured by functional near-infrared spectroscopy, under dual-task conditions (cognition while walking) in healthy young adults. Our probe design enabled us to examine eight regions of interest across PFC and motor cortex to identify key areas related to behavior. Healthy young adults (N = 19) engaged in standing cognition (Serial 3 subtraction), single-task walking, and dual-task walking. We used functional near-infrared spectroscopy to identify regions associated with increases or decreases in activity under dual-task relative to the other conditions. We observed differences in brain activity patterns by task across multiple regions of interest, mostly in PFC. Specifically, more lateral regions were related to attention-demanding tasks, whereas motor tasks were related to relatively medial regions. Our results relate behavior to brain activity, as measured by functional near-infrared spectroscopy, under dual-task conditions. Our finding of relatively lateral PFC activity during attention-demanding tasks provides insights into behavioral and brain processes during experimental analogues of everyday activity, bringing us closer to understanding behavior-brain relations in the real world. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2025-09-01T00:00:00+00:00",
      "source": "Behavioral Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 235,
      "reading_time": 1,
      "created_at": "2026-01-22T05:55:05.038966+00:00",
      "updated_at": "2026-01-22T05:55:05.038971+00:00"
    },
    {
      "id": "e4ce644e22b3482ad1db9b723cdab07b",
      "url": "https://arxiv.org/abs/2601.14641",
      "title": "MIND: Empowering Mental Health Clinicians with Multimodal Data Insights through a Narrative Dashboard",
      "content": "arXiv:2601.14641v1 Announce Type: new \nAbstract: Advances in data collection enable the capture of rich patient-generated data: from passive sensing (e.g., wearables and smartphones) to active self-reports (e.g., cross-sectional surveys and ecological momentary assessments). Although prior research has demonstrated the utility of patient-generated data in mental healthcare, significant challenges remain in effectively presenting these data streams along with clinical data (e.g., clinical notes) for clinical decision-making. Through co-design sessions with five clinicians, we propose MIND, a large language model-powered dashboard designed to present clinically relevant multimodal data insights for mental healthcare. MIND presents multimodal insights through narrative text, complemented by charts communicating underlying data. Our user study (N=16) demonstrates that clinicians perceive MIND as a significant improvement over baseline methods, reporting improved performance to reveal hidden and clinically relevant data insights (p<.001) and support their decision-making (p=.004). Grounded in the study results, we discuss future research opportunities to integrate data narratives in broader clinical practices.",
      "author": "Ruishi Zou, Shiyu Xu, Margaret E Morris, Jihan Ryu, Timothy D. Becker, Nicholas Allen, Anne Marie Albano, Randy Auerbach, Dan Adler, Varun Mishra, Lace Padilla, Dakuo Wang, Ryan Sultan, Xuhai \"Orson\" Xu",
      "published_date": "2026-01-22T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 154,
      "reading_time": 1,
      "created_at": "2026-01-22T05:30:26.928916+00:00",
      "updated_at": "2026-01-22T05:30:26.928918+00:00"
    },
    {
      "id": "4a3f0de0627e8f33b9a4d320c444904f",
      "url": "https://arxiv.org/abs/2601.14639",
      "title": "DesignBridge: Bridging Designer Expertise and User Preferences through AI-Enhanced Co-Design for Fashion",
      "content": "arXiv:2601.14639v1 Announce Type: new \nAbstract: Effective collaboration between designers and users is important for fashion design, which can increase the user acceptance of fashion products and thereby create value. However, it remains an enduring challenge, as traditional designer-centric approaches restrict meaningful user participation, while user-driven methods demand design proficiency, often marginalizing professional creative judgment. Current co-design practices, including workshops and AI-assisted frameworks, struggle with low user engagement, inefficient preference collection, and difficulties in balancing user feedback with design considerations. To address these challenges, we conducted a formative study with designers and users experienced in co-design (N=7), identifying critical challenges for current collaboration between designers and users in the co-design process, and their requirements. Informed by these insights, we introduce DesignBridge, a multi-platform AI-enhanced interactive system that bridges designer expertise and user preferences through three stages: (1) Initial Design Framing, where designers define initial concepts. (2) Preference Expression Collection, where users intuitively articulate preferences via interactive tools. (3) Preference-Integrated Design, where designers use AI-assisted analytics to integrate feedback into cohesive designs. A user study demonstrates that DesignBridge significantly enhances user preference collection and analysis, enabling designers to integrate diverse preferences with professional expertise.",
      "author": "Yuheng Shao, Yuansong Xu, Yifan Jin, Shuhao Zhang, Wenxin Gu, Quan Li",
      "published_date": "2026-01-22T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 192,
      "reading_time": 1,
      "created_at": "2026-01-22T05:30:26.928886+00:00",
      "updated_at": "2026-01-22T05:30:26.928887+00:00"
    },
    {
      "id": "f007e278f0f625eb274c3c679822541b",
      "url": "https://arxiv.org/abs/2601.14611",
      "title": "Seeing to Think? How Source Transparency Design Shapes Interactive Information Seeking and Evaluation in Conversational AI",
      "content": "arXiv:2601.14611v1 Announce Type: new \nAbstract: Conversational AI systems increasingly function as primary interfaces for information seeking, yet how they present sources to support information evaluation remains under-explored. This paper investigates how source transparency design shapes interactive information seeking, trust, and critical engagement. We conducted a controlled between-subjects experiment (N=372) comparing four source presentation interfaces - Collapsible, Hover Card, Footer, and Aligned Sidebar - varying in visibility and accessibility. Using fine-grained behavioral analysis and automated critical thinking assessment, we found that interface design fundamentally alters exploration strategies and evidence integration. While the Hover Card interface facilitated seamless, on-demand verification during the task, the Aligned Sidebar uniquely mitigated the negative effects of information overload: as citation density increased, Sidebar users demonstrated significantly higher critical thinking and synthesis scores compared to other conditions. Our results highlight a trade-off between designs that support workflow fluency and those that enforce reflective verification, offering practical implications for designing adaptive and responsible conversational AI that fosters critical engagement with AI generated content.",
      "author": "Jiangen He, Jiqun Liu",
      "published_date": "2026-01-22T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 165,
      "reading_time": 1,
      "created_at": "2026-01-22T05:30:26.928851+00:00",
      "updated_at": "2026-01-22T05:30:26.928853+00:00"
    },
    {
      "id": "81e792f7cebcf07fca23773c31954407",
      "url": "https://arxiv.org/abs/2601.14589",
      "title": "Designing KRIYA: An AI Companion for Wellbeing Self-Reflection",
      "content": "arXiv:2601.14589v1 Announce Type: new \nAbstract: Most personal wellbeing apps present summative dashboards of health and physical activity metrics, yet many users struggle to translate this information into meaningful understanding. These apps commonly support engagement through goals, reminders, and structured targets, which can reinforce comparison, judgment, and performance anxiety. To explore a complementary approach that prioritizes self-reflection, we design KRIYA, an AI wellbeing companion that supports co-interpretive engagement with personal wellbeing data. KRIYA aims to collaborate with users to explore questions, explanations, and future scenarios through features such as Comfort Zone, Detective Mode, and What-If Planning. We conducted semi-structured interviews with 18 college students interacting with a KRIYA prototype using hypothetical data. Our findings show that through KRIYA interaction, users framed engaging with wellbeing data as interpretation rather than performance, experienced reflection as supportive or pressuring depending on emotional framing, and developed trust through transparency. We discuss design implications for AI companions that support curiosity, self-compassion, and reflective sensemaking of personal health data.",
      "author": "Shanshan Zhu, Wenxuan Song, Jiayue Melissa Shi, Dong Whi Yoo, Karthik S. Bhat, Koustuv Saha",
      "published_date": "2026-01-22T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 162,
      "reading_time": 1,
      "created_at": "2026-01-22T05:30:26.928806+00:00",
      "updated_at": "2026-01-22T05:30:26.928808+00:00"
    },
    {
      "id": "9b32107b41c6e05208a75cd19c7ff276",
      "url": "https://arxiv.org/abs/2601.14587",
      "title": "Explainable OOHRI: Communicating Robot Capabilities and Limitations as Augmented Reality Affordances",
      "content": "arXiv:2601.14587v1 Announce Type: new \nAbstract: Human interaction is essential for issuing personalized instructions and assisting robots when failure is likely. However, robots remain largely black boxes, offering users little insight into their evolving capabilities and limitations. To address this gap, we present explainable object-oriented HRI (X-OOHRI), an augmented reality (AR) interface that conveys robot action possibilities and constraints through visual signifiers, radial menus, color coding, and explanation tags. Our system encodes object properties and robot limits into object-oriented structures using a vision-language model, allowing explanation generation on the fly and direct manipulation of virtual twins spatially aligned within a simulated environment. We integrate the end-to-end pipeline with a physical robot and showcase diverse use cases ranging from low-level pick-and-place to high-level instructions. Finally, we evaluate X-OOHRI through a user study and find that participants effectively issue object-oriented commands, develop accurate mental models of robot limitations, and engage in mixed-initiative resolution.",
      "author": "Lauren W. Wang, Mohamed Kari, Parastoo Abtahi",
      "published_date": "2026-01-22T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 150,
      "reading_time": 1,
      "created_at": "2026-01-22T05:30:26.928774+00:00",
      "updated_at": "2026-01-22T05:30:26.928775+00:00"
    }
  ],
  "recently_processed": [
    {
      "id": "8a37f4aa5925a5559bd2dd315d94013b",
      "url": "https://brain.ieee.org/publications/neuroethics-framework/education/standards-education/education-standards/",
      "title": "Education: Standards",
      "content": "",
      "author": "Adriel Carridice",
      "published_date": "2025-02-13T19:51:15+00:00",
      "source": "Brain",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2026-01-22T05:56:01.265857+00:00",
      "updated_at": "2026-01-22T06:28:06.709994+00:00",
      "metadata": {
        "processed_at": "2026-01-22T06:28:06.710004+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "417111e13e4858f79734781862a95c17",
      "url": "https://brain.ieee.org/publications/neuroethics-framework/education/educational-and-training-resources-education/education-additional-resources/",
      "title": "Education: Additional Resources",
      "content": "Buckingham Shum, S. (2022). The UTS \u201cEdTech Ethics\u201d Deliberative Democracy Consultation: Rationale, Process and Outcomes. Connected Intelligence Centre, University of Technology Sydney, AUS. https://cic.uts.edu.au/projects/edtech-ethics Le\u00f3n Declaration on European neurotechnology (2023): a human-focused and rights-oriented approach October 2023. An informal meeting will be held with all telecommunications and digital ministers from EU member states. https://spanish-presidency.consilium.europa.eu/media/o4rh53jr/le%C3%B3n-declaration.pdf Neurotechnology Report: https://www.perseus-strategies.com/wp-content/uploads/2024/04/FINAL-Consumer-Neurotechnology-Report-Neurorights-Foundation-March-2024-3.pdf Al-Emran, M., Al-Nuaimi, ...",
      "author": "Adriel Carridice",
      "published_date": "2025-02-13T19:54:30+00:00",
      "source": "Brain",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 61,
      "reading_time": 1,
      "created_at": "2026-01-22T05:56:01.265840+00:00",
      "updated_at": "2026-01-22T06:28:06.710008+00:00",
      "metadata": {
        "processed_at": "2026-01-22T06:28:06.710010+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "eddcbadea083b0a5930cbd4a70baf32e",
      "url": "https://brain.ieee.org/publications/neuroethics-framework/education/references/education-references/",
      "title": "Education: References",
      "content": "[1] OECD \u201cNeurotechnology Toolkit To support policymakers in implementing the OECD Recommendation on Responsible Innovation in Neurotechnology,\u201d 2024.: https://www.oecd.org/content/dam/oecd/en/topics/policy-sub-issues/emerging-technologies/neurotech-toolkit.pdf. [2] van Kesteren and Meeter, 2020 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7339924/ [3]\u00a0 Bikson, M., Esmaeilpour, Z., Adair, D., Kronberg, G., Tyler, W. J., Antal, A., Datta, A., Sabel, B. A., Nitsche, M. A., Loo, C., Edwards, D., Ekhtiari, H., Knotkova, H., Woods, A. J., Hampstead, ...",
      "author": "Adriel Carridice",
      "published_date": "2025-02-13T19:57:58+00:00",
      "source": "Brain",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 61,
      "reading_time": 1,
      "created_at": "2026-01-22T05:56:01.265815+00:00",
      "updated_at": "2026-01-22T06:28:06.710012+00:00",
      "metadata": {
        "processed_at": "2026-01-22T06:28:06.710014+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "8bfe7b7f37af142b24b0fcd318868131",
      "url": "https://brain.ieee.org/braininsight-articles/ieee-brain-annual-flagship-workshop-a-success/",
      "title": "IEEE Brain Annual Flagship Workshop a Success",
      "content": "IEEE Brain once again hosted the IEEE Brain Discovery and Neurotechnology Workshop as a satellite event to the 2024 Society of Neuroscience Workshop (SfN). Approximately 180 attended the two-day event, which was held at the University of Illinois Chicago (UIC), October 3-4, 2024 (Figure 1). Groundbreaking solutions with the potential to improve quality of life and address neural disorders require ...",
      "author": "ieeebrain",
      "published_date": "2025-03-03T16:55:37+00:00",
      "source": "Brain",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 61,
      "reading_time": 1,
      "created_at": "2026-01-22T05:56:01.265791+00:00",
      "updated_at": "2026-01-22T06:28:06.710016+00:00",
      "metadata": {
        "processed_at": "2026-01-22T06:28:06.710018+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "2eb57dbdbc858b57282cfad12fa8d826",
      "url": "https://brain.ieee.org/braininsight-articles/ieee-brain-workshop-on-ai-for-neurotechnology/",
      "title": "IEEE Brain Workshop on AI for Neurotechnology",
      "content": "The IEEE Brain Workshop on AI for Neurotechnology was held on June 30, 2024, at the Pacifico Yokohama Conference Center in Japan. This event was part of the World Congress on Computational Intelligence (WCCI 2024) and was conducted in association with the International Joint Conference on Neural Networks (IJCNN). The workshop focused on the application of artificial intelligence to neurotechnology, ...",
      "author": "ieeebrain",
      "published_date": "2025-03-03T17:05:59+00:00",
      "source": "Brain",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 61,
      "reading_time": 1,
      "created_at": "2026-01-22T05:56:01.265767+00:00",
      "updated_at": "2026-01-22T06:28:06.710020+00:00",
      "metadata": {
        "processed_at": "2026-01-22T06:28:06.710022+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "b915afb406e73bb7a7c1832608ee2968",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.17.699936v1?rss=1",
      "title": "The amplitude and latency of the earliest signal in V1 encode bottom-up saliency by feature conjunction",
      "content": "The neural origin of bottom-up saliency for exogenous attention remains highly controversial. In this study, we investigated whether the earliest activity in the primary visual cortex (V1) encodes saliency signals defined by the eye-of-origin and feature-conjunction information. Electroencephalography (EEG) recordings from the human occipital cortex revealed early responses to eye-of-origin (E) and/or orientation (O) singletons, with larger response amplitudes to the double-feature (EO) singletons. The short onset latency (58-70 ms) and polarity reversal of the responses indicate a V1 origin. Importantly, the latency and amplitude of these responses predicted behavioral detection performance. Together, these findings suggest that the timing and amplitude of the earliest signals in V1 represent the saliency of combined feature contrasts for bottom-up attention. These signals unlikely originate from projections of other proposed source areas of saliency, due to the scarcity of necessary monocular neurons to process eye-of-origin information.",
      "author": "Wu, C., Li, X., Li, H., Wang, X., Yin, Z., Wang, Z., Zhang, P., Yang, Z., Zou, J.",
      "published_date": "2026-01-21T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 142,
      "reading_time": 1,
      "created_at": "2026-01-22T03:50:05.337222+00:00",
      "updated_at": "2026-01-22T04:43:34.915607+00:00",
      "metadata": {
        "processed_at": "2026-01-22T04:43:34.915617+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "b37601d09093bbd8cc42468419126021",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.17.700125v1?rss=1",
      "title": "From cognitive abstraction to adaptive behavior: neural bases of concept learning in autistic adolescents",
      "content": "BACKGROUND: Learned knowledge does not consistently generalize to new contexts in autistic individuals, limiting potential for adapting to real-world demands. This challenge is hypothesized to stem from difficulties with forming abstract representations, potentially arising from perceptual processing that favors local details over the gestalt. We tested the prediction that generalization would be primarily based on exemplar-specific representations in autistic youth using computational modelling coupled with neuroimaging. METHODS: Sixty-four autistic adolescents without intellectual disability (69% males; ages 14-18 years) completed a category generalization task during functional magnetic resonance imaging at two time points. Computational models estimated abstract (prototype-based) and specific (exemplar-based) representations and underlying neural correlates. We further examined associations with adaptive functioning and moderation by autistic traits. RESULTS: Contrary to predictions, we observed a consistent prototype-dominant majority, a subgroup who generalized without consistent representational reliance, and a small minority who failed to acquire category structure. Prototypes were represented in bilateral ventromedial prefrontal cortex (VMPFC), inferior parietal lobule (IPL), right frontal pole, and right lateral occipital cortex, while exemplars were represented in bilateral cuneus. Better generalization predicted better real-world adaptive functioning. Moreover, greater prototype-related activation in left IPL predicted better adaptive functioning in participants with higher autistic traits. CONCLUSIONS: These findings challenge the prevailing view that concept learning in autism relies primarily on hyper-specific perceptual processing, identify meaningful variability in representational strategies, and reveal neural pathways through which abstract representation may support real-world adaptive behavior.",
      "author": "Chen, Y., Hawkins, B., Puckett, H., Sharp, K., Lopez, A., Zeithamova, D., Xie, H., Verbalis, A., VanMeter, A. S., Gaillard, W. D., Kenworthy, L., Vaidya, C. J.",
      "published_date": "2026-01-21T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 234,
      "reading_time": 1,
      "created_at": "2026-01-22T03:50:05.337190+00:00",
      "updated_at": "2026-01-22T04:43:34.915621+00:00",
      "metadata": {
        "processed_at": "2026-01-22T04:43:34.915623+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "b33b472cdb8563c7c43c617b484ebda6",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.18.700161v1?rss=1",
      "title": "Divergent excitatory and inhibitory signaling in a head direction circuit",
      "content": "Neural cell types are often clustered into inhibitory, excitatory, or neuromodulatory populations. However, the signaling mechanism between two neurons ultimately depends on their neurotransmitter-receptor pairings. Here, we demonstrate an example of a glutamatergic population of neurons that appears to either excite or inhibit their downstream partners depending on the type of glutamate receptor expressed in the downstream cell type. The upstream population encodes a sinusoidal head direction signal. The downstream partners that are excited by glutamate encode the same signal while the downstream partners that are inhibited by glutamate encode a 180$^degree$ phase-shifted copy. The upstream population therefore appears to pass on two different phases of the same signal by making either excitatory or inhibitory connections to different downstream partners.",
      "author": "Eddy, J., Shenasa, A. H., Monroy Alfaro, P., Fernanda Viveros, M., Turner-Evans, D. B.",
      "published_date": "2026-01-21T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 120,
      "reading_time": 1,
      "created_at": "2026-01-22T03:50:05.337140+00:00",
      "updated_at": "2026-01-22T04:43:34.915625+00:00",
      "metadata": {
        "processed_at": "2026-01-22T04:43:34.915627+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "3940bc586d485dfa10ff0242facb774a",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.17.700100v1?rss=1",
      "title": "Memory erasure by dopamine-gated retrospective learning",
      "content": "Erasing outdated memories is crucial for adaptive behavior. Yet once a cue-outcome association is learned, repeated cue exposure without outcome suppresses conditioned behavior without erasing the underlying memory. This allows rapid behavioral recovery when outcomes are reintroduced. Here, we confirm this limitation for standard prospective extinction protocols that present cues without the associated outcome, but show that true memory erasure is achieved by inverting the paradigm: presenting outcomes without associated cues, i.e., retrospective extinction. We demonstrate that orbitofrontal cortex activity at outcome is necessary for the rapid behavioral recovery following prospective extinction, and that mesolimbic dopamine activity at outcome is necessary for retrospective extinction. These findings reconceptualize extinction mechanisms and suggest complementary strategies to mitigate relapse and erase maladaptive memories.",
      "author": "Jeong, H., Zsembik, L., Farouq, F., Chakraborty, R., Belur, N., Zhou, M., Sanders, A. D., Wang, S. X., Srinivasan, A., Cox, S. M. L., Garr, E., Brooke, S., Janak, P. H., Leyton, M., Chen, R., Namboodiri, V. M. K.",
      "published_date": "2026-01-21T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 120,
      "reading_time": 1,
      "created_at": "2026-01-22T03:50:05.337110+00:00",
      "updated_at": "2026-01-22T04:43:34.915629+00:00",
      "metadata": {
        "processed_at": "2026-01-22T04:43:34.915630+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "3f1b7dbb004c0c5cfefdd86a8ce6e33f",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.18.698509v1?rss=1",
      "title": "Minimal Mimics and Maps of Natural Light for Mammals",
      "content": "Light drives processes that include perception and the regulation of circadian rhythms, sleep, metabolism, and development. These processes are initiated by photopigment molecules, each preferentially absorbing particular wavelengths. Light of a given spectrum stimulates an animal's set of photopigments in a specific profile. Natural light and its variations produce stimulation profiles that promote normal physiology. To mimic these profiles using artificial light, we consider the thermally stable, photoconvertible states of relevant photopigments: ground states of rhodopsin and cone photopigments, and three states of melanopsin. This gives a high-dimensional representation of illumination. Nevertheless, we find that two wavelengths suffice to closely mimic the effects of natural light for mammals, including humans and mice. Adjusting the wavelength ratio allows mimicry of natural light's variations, such as those from twilight to noon. Ratio adjustments also compensate for light's filtering by elements like the eye's optics and laboratory cages. Adding a third wavelength makes natural light mimicry nearly perfect. By contrast, common artificial lighting--designed for low-dimensional, human color space--stimulates photopigments in unnatural proportions. We conclude by providing species-specific maps of photopigment stimulation profiles under natural and artificial illumination, which make our observations intuitive while providing insight into the diverse visual ecologies of mammals.",
      "author": "Morquette, P., Do, M. T. H.",
      "published_date": "2026-01-21T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 199,
      "reading_time": 1,
      "created_at": "2026-01-22T03:50:05.337078+00:00",
      "updated_at": "2026-01-22T04:43:34.915633+00:00",
      "metadata": {
        "processed_at": "2026-01-22T04:43:34.915635+00:00",
        "processing_method": "github_actions"
      }
    }
  ]
}