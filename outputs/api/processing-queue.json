{
  "last_updated": "2025-11-11T22:14:54.210055+00:00",
  "pending_count": 985,
  "processed_count": 15,
  "pending_articles": [
    {
      "id": "239d99da9858bdb1b2399131dde345ea",
      "url": "https://www.sciencedirect.com/science/article/pii/S0006899325006018?dgcid=rss_sd_all",
      "title": "Aerobic exercise modulates plasma oxidized lipid metabolites and neurotransmitters in Parkinson\u2019s disease motor subtypes",
      "content": "<p>Publication date: 15 December 2025</p><p><b>Source:</b> Brain Research, Volume 1869</p><p>Author(s): Yangdanyu Li, Yuning Liu, Zihao Lin, Quanqing Wei, Jie Xiang, Wei Zhang, Liguo Dong, Fujia Li, Jie Zu, Guiyun Cui, Chuanying Xu</p>",
      "author": "",
      "published_date": null,
      "source": "Brain Research",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 31,
      "reading_time": 1,
      "created_at": "2025-11-11T21:40:46.349908+00:00",
      "updated_at": "2025-11-11T21:40:46.349910+00:00"
    },
    {
      "id": "531780bd9b4422343606f0da4ea82642",
      "url": "https://www.sciencedirect.com/science/article/pii/S0006899325005633?dgcid=rss_sd_all",
      "title": "Apprehending relational events: The visual world paradigm and the interplay of event perception and language",
      "content": "<p>Publication date: 15 December 2025</p><p><b>Source:</b> Brain Research, Volume 1869</p><p>Author(s): Alon Hafri, John C. Trueswell</p>",
      "author": "",
      "published_date": null,
      "source": "Brain Research",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 14,
      "reading_time": 1,
      "created_at": "2025-11-11T21:40:46.349837+00:00",
      "updated_at": "2025-11-11T21:40:46.349838+00:00"
    },
    {
      "id": "62fbc07721d3e40326fde5aaed0df13c",
      "url": "https://www.sciencedirect.com/science/article/pii/S0306452225010395?dgcid=rss_sd_all",
      "title": "Seasonal changes in the balance of brain monoamines of hibernating long-tailed ground squirrels (<em>Urocitellus undulatus</em>)",
      "content": "<p>Publication date: 5 December 2025</p><p><b>Source:</b> Neuroscience, Volume 590</p><p>Author(s): Nadezhda M. Zakharova, Yury S. Tarahovsky</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroscience Journal",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 14,
      "reading_time": 1,
      "created_at": "2025-11-11T21:40:45.156522+00:00",
      "updated_at": "2025-11-11T21:40:45.156523+00:00"
    },
    {
      "id": "ff9aefe17ebe2dd9814289080a9642ac",
      "url": "https://www.sciencedirect.com/science/article/pii/S0306452225010498?dgcid=rss_sd_all",
      "title": "Impact of routine rehabilitation training on motor function and activities of daily living in oldest-old patients who have experienced a stroke",
      "content": "<p>Publication date: 5 December 2025</p><p><b>Source:</b> Neuroscience, Volume 590</p><p>Author(s): Yu-Juan Han, Hao-Ming Xu, Shan Han, Pei Dai, Xiao-Ping Kang</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroscience Journal",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 18,
      "reading_time": 1,
      "created_at": "2025-11-11T21:40:45.156505+00:00",
      "updated_at": "2025-11-11T21:40:45.156506+00:00"
    },
    {
      "id": "34d15c19b23cf29f13ca20d5a14f2665",
      "url": "https://www.sciencedirect.com/science/article/pii/S0306452225010590?dgcid=rss_sd_all",
      "title": "Suppression of AKAP150 palmitoylation alleviates seizures in kainic acid-induced epilepsy mice",
      "content": "<p>Publication date: 5 December 2025</p><p><b>Source:</b> Neuroscience, Volume 590</p><p>Author(s): Chen-Chao Chu, Ya-Hui Hu, Hai-Feng Zhang, Gui-Zhou Li, Shi-Yu Wu, Yan-Yu Zang, Jiang Chen, Hao-Yu Wang, Yang-Yang Xu, Hong-Li Guo, Yun Stone Shi, Feng Chen</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroscience Journal",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 33,
      "reading_time": 1,
      "created_at": "2025-11-11T21:40:45.156488+00:00",
      "updated_at": "2025-11-11T21:40:45.156489+00:00"
    },
    {
      "id": "f3ee81748b72f618d907f5bb08738130",
      "url": "https://www.sciencedirect.com/science/article/pii/S0306452225010310?dgcid=rss_sd_all",
      "title": "Mental health and subjective well-being of trans and non-binary population in Colombia",
      "content": "<p>Publication date: 5 December 2025</p><p><b>Source:</b> Neuroscience, Volume 590</p><p>Author(s): Mar\u00eda Fernanda Reyes, Natalie Levy, Daniela Maldonado Salamanca, Minna Lyons, Juan-David Leong\u00f3mez</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroscience Journal",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 20,
      "reading_time": 1,
      "created_at": "2025-11-11T21:40:45.156413+00:00",
      "updated_at": "2025-11-11T21:40:45.156415+00:00"
    },
    {
      "id": "5f2feef4ea2382f4ed7b096aedbe2db3",
      "url": "https://www.sciencedirect.com/science/article/pii/S1053811925005464?dgcid=rss_sd_all",
      "title": "The golden age of online readout: EEG-informed TMS from manual probing to closed-loop neuromodulation",
      "content": "<p>Publication date: 15 November 2025</p><p><b>Source:</b> NeuroImage, Volume 322</p><p>Author(s): Giuseppe Varone, Mana Biabani, Sara Tremblay, Joshua C. Brown, Elisa Kallioniemi, Nigel C. Rogasch</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroimage",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 22,
      "reading_time": 1,
      "created_at": "2025-11-11T21:40:42.674174+00:00",
      "updated_at": "2025-11-11T21:40:42.674176+00:00"
    },
    {
      "id": "f1d316d936d33216f183abf9cb2c0268",
      "url": "https://www.biorxiv.org/content/10.1101/2025.11.10.687664v1?rss=1",
      "title": "Learning-dependent cholinergic plasticity reconfigures cortical circuit dynamics.",
      "content": "Neuromodulation by acetylcholine (ACh) plays a critical role in reshaping neural dynamics in the neocortex as a function of development, behavioral state, and learning 1-6. Prior work suggests cholinergic signaling can act as a gate for the subsequent induction of circuit plasticity 3,7,8. However, modification of ACh release could also be a direct mechanism for the expression of cortical plasticity. Here, we combine widefield and 2-photon imaging in head-fixed mice to show that visual fear conditioning leads to a selective, cue-dependent release of ACh in primary visual cortex that enhances visually-evoked neuronal responses via excitation of layer 1 GABAergic interneurons and resulting disinhibition of local excitatory pyramidal neurons. Cholinergic signaling through muscarinic receptors in visual cortex is necessary for both the enhanced visual response and conditioned fear behavior. Our results demonstrate a novel capacity for conditioned release of ACh in sensory cortex to serve as a mechanism for sensory-guided behavioral learning. Rather than acting as a simple gate, cortical neuromodulation may thus play a central role in the expression of learned behavior.",
      "author": "Moberly, A., Cardin, J. A., Higley, M.",
      "published_date": "2025-11-11T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 172,
      "reading_time": 1,
      "created_at": "2025-11-11T21:40:41.421474+00:00",
      "updated_at": "2025-11-11T21:40:41.421476+00:00"
    },
    {
      "id": "5d2de72db480f7be99e8d92551de8d8a",
      "url": "https://www.nature.com/articles/s41593-025-02102-1",
      "title": "Subsecond dopamine fluctuations do not specify the vigor of ongoing actions",
      "content": "",
      "author": "",
      "published_date": "2025-11-10T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-11-11T21:40:39.630463+00:00",
      "updated_at": "2025-11-11T21:40:39.630465+00:00"
    },
    {
      "id": "5d2de72db480f7be99e8d92551de8d8a",
      "url": "https://www.nature.com/articles/s41593-025-02102-1",
      "title": "Subsecond dopamine fluctuations do not specify the vigor of ongoing actions",
      "content": "<p>Nature Neuroscience, Published online: 10 November 2025; <a href=\"https://www.nature.com/articles/s41593-025-02102-1\">doi:10.1038/s41593-025-02102-1</a></p>Liu and colleagues show that the vigor (that is, speed and amplitude) of dexterous movements is not controlled by ongoing fluctuations in extracellular dopamine within the dorsal striatum of mice.",
      "author": "Nicolas X. Tritsch",
      "published_date": "2025-11-10T00:00:00+00:00",
      "source": "Nature Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 38,
      "reading_time": 1,
      "created_at": "2025-11-11T21:40:38.552089+00:00",
      "updated_at": "2025-11-11T21:40:38.552091+00:00"
    }
  ],
  "recently_processed": [
    {
      "id": "902df770854423011000edd238dd0b09",
      "url": "http://ieeexplore.ieee.org/document/10972321",
      "title": "A Pilot Study on Fabric-Based Pneumatic Soft Gloves for Assisting Patients With Severe Brachial Plexus Injury",
      "content": "Objective: Robotic gloves show promise in hand assistance due to their wearability and home-based potential, yet empirical research remains limited. This pilot study presents a fabric-based pneumatic soft glove, aiming to identify its potential and challenges in clinical practice by evaluating its effectiveness in assisting patients with severe brachial plexus injury (BPI). Methods: The glove integrates a thumb abduction actuator and four bidirectional fabric-based pneumatic actuators (FPAs) with asymmetric chambers for high output force. Sixteen healthy volunteers and five individuals with BPI, all of whom lacked active hand and wrist movements, were recruited. Participants performed object grasping across 25 cm. The healthy group performed seven tasks using objects weighing up to 2 kg, with muscle activities recorded for analysis. The BPI group further performed tasks with eight objects from the action research arm test (ARAT) and twelve objects for activities of daily living (ADLs), encompassing various sizes, weights, and geometries. Results: In the healthy group, sEMG showed a decrease in 89.3% of trials, with 56.0% of these decreases being significant (p$< $0.01). For BPI group, the range of motion (ROM) improved, ranging from 28.5 $\\pm$ 7.9$^{\\circ }$ to 63.1 $\\pm$ 5.1$^{\\circ }$ (thumb) and 10.3 $\\pm$ 17.5$^{\\circ }$ to 122.5 $\\pm$ 19.0$^{\\circ }$ (index finger). With a zero baseline for all tasks, their completion rates were 6.8 $\\pm$ 0.8 out of 8 for ARAT tasks and 10.0 $\\pm$ 1.7 out of 12 for ADLs. Conclusion: The fabric-based pneumatic soft glove significantly enhanced the hand function of patients with severe BPI, demonstrating its potential for hand assistance.",
      "author": "",
      "published_date": "2025-04-22T13:18:18+00:00",
      "source": "Transactions Biomedical Engineering",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 256,
      "reading_time": 1,
      "created_at": "2025-11-11T21:40:57.913045+00:00",
      "updated_at": "2025-11-11T22:14:54.105103+00:00",
      "metadata": {
        "processed_at": "2025-11-11T22:14:54.105115+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "97b029153a3ff523dd3e21c1b2ebeaf8",
      "url": "http://ieeexplore.ieee.org/document/10971951",
      "title": "Building and Sustaining Open-Source Medical Device Projects",
      "content": "The open-source development model has been successfully applied to consumer and enterprise software, and recently to consumer hardware. Medical devices may become a beneficiary of this trend, as open-source medical device development has the potential to reduce costs, democratize patient access, and provide continued support to abandoned devices from failed companies. Unlike the consumer device market, the medical device market is highly regulated and involves considerable manufacturer liability that may limit the use of open-source technology. This review of open-source medical device development explores the current state of development in research and clinical products and suggests best practices for creating sustainable and effective open-source medical devices.",
      "author": "",
      "published_date": "2025-04-21T13:18:20+00:00",
      "source": "Transactions Biomedical Engineering",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 106,
      "reading_time": 1,
      "created_at": "2025-11-11T21:40:57.912999+00:00",
      "updated_at": "2025-11-11T22:14:54.105119+00:00",
      "metadata": {
        "processed_at": "2025-11-11T22:14:54.105121+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "0077ae0d8a956fdc349ff6b154403d02",
      "url": "http://ieeexplore.ieee.org/document/10971210",
      "title": "A Neighbor-Sensitive Multi-Modal Flexible Learning Framework for Improved Prostate Tumor Segmentation in Anisotropic MR Images",
      "content": "Accurate segmentation of prostate tumors from multi-modal magnetic resonance (MR) images is crucial for the diagnosis and treatment of prostate cancer. However, the robustness of existing segmentation methods is limited, mainly because these methods 1) fail to flexibly assess subject-specific information of each MR modality and integrate modality-specific information for accurate tumor delineation, and 2) lack effective utilization of inter-slice information across thick slices in MR images to segment the tumor as a whole 3D volume. In this work, we propose a neighbor-sensitive multi-modal flexible learning network (NesMFle) for accurate prostate tumor segmentation from multi-modal anisotropic MR images. Specifically, we perform multi-modal fusion for each slice by developing a Modality-informativeness Flexible Learning (MFLe) module for selecting and flexibly fusing informative representations of each modality based on inter-modality correlation in a pre-trained manner. After that, we exploit inter-slice feature correlation to derive volumetric tumor segmentation. In particular, we first use a Unet variant equipped with a Sequence Layer, which can coarsely capture slice relationship using 3D convolution and an attention mechanism. Then, we introduce an Activation Mapping Guidance (AMG) module to refine slice-wise representations using information from adjacent slices, ensuring consistent tumor segmentation across neighboring slices based on slice quality assessment on activation maps. Besides, during the network training, we further apply a random mask strategy to each MR modality for improving feature representation efficiency. Experiments on both in-house and public (PICAI) multi-modal prostate tumor datasets demonstrate that our proposed NesMFLe achieves competitive performance compared to state-of-the-art methods.",
      "author": "",
      "published_date": "2025-04-21T13:18:20+00:00",
      "source": "Transactions Biomedical Engineering",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 247,
      "reading_time": 1,
      "created_at": "2025-11-11T21:40:57.912973+00:00",
      "updated_at": "2025-11-11T22:14:54.105124+00:00",
      "metadata": {
        "processed_at": "2025-11-11T22:14:54.105125+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "a8adb8e21ba8ade167865b32c18747a2",
      "url": "http://ieeexplore.ieee.org/document/11235877",
      "title": "Separate Timescales for Spatial and Anatomical Information Processing of Body Stimuli",
      "content": "Observing different body stimuli can influence the speed and accuracy of our responses. Prior work indicates this effect is influenced by factors such as spatial congruence and perspective. We hypothesized that the influence of these factors would vary depending on the amount of time that participants had to process visual stimuli. Experiment 1 was a RT task (n = 29) with stimuli varying in spatial congruence (congruent, incongruent, neutral), perspective (first- or third-person), and stimulus type (body or control). Experiment 2 (n = 50) used the same stimuli in a \u201cForced Response\u201d paradigm, which controlled the time participants had to prepare a response. This allowed us to assess responses as a function of preparation time. Experiment 1 showed effects of spatial congruence, with longer RTs and more errors for spatially incongruent stimuli. This effect was greater for body stimuli. Experiment 2 showed that spatial information was processed faster than anatomical information, inducing incorrect responses at short preparation times for spatially incongruent body stimuli. There was little-to-no corresponding effect for control stimuli. Both experiments also showed weak-to-no effects of perspective, which appear to have been driven by spatial congruence. Our results indicate that spatial information is processed faster than anatomical information during observation of body stimuli. These data are consistent with the dual visual streams hypothesis, whereby spatial information would be processed rapidly via the dorsal stream, whereas anatomical processing would occur later via the ventral stream. These data also indicate differences in processing between body and control stimuli.",
      "author": "",
      "published_date": "2025-11-07T13:16:23+00:00",
      "source": "Cognitive Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 248,
      "reading_time": 1,
      "created_at": "2025-11-11T21:40:55.615995+00:00",
      "updated_at": "2025-11-11T22:14:54.105127+00:00",
      "metadata": {
        "processed_at": "2025-11-11T22:14:54.105132+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "fb588439a33dbfe3eb0b3edf79a54446",
      "url": "http://ieeexplore.ieee.org/document/11235874",
      "title": "Transient Inhibition of the Posterior Parietal Cortex Affects Action-related But Not Action-unrelated Visual Processing during Path Integration",
      "content": "Path integration refers to the ability to monitor self-motion cues to keep track of changes in position and orientation. This function is often assumed to rely predominantly on medial temporal lobe structures containing grid, place, and head direction cells. Recent evidence, however, suggests that key navigational computations may occur outside this system, for example, in posterior parietal areas. Here, we adopted a novel perspective derived from animal research and examined whether human path integration relies on processing streams in the posterior parietal cortex (PPC), depending on the involvement of actively controlled motion as opposed to passive perception of visual optic flow. We compared the effects of inhibiting the PPC via TMS on two path integration tasks in a virtual reality, only one of which involved active control of a visually simulated forward movement. Behavioral performance showed that distance judgments were selectively affected in the action-related path integration task. This finding shows that the processing of actively controlled motion depends on computations in the PPC, whereas passive processing of optic flow is largely independent of the PPC computations. Our results reinforce the hypothesis that the PPC plays a critical role for the integration of goal locations and self-positional signals within an egocentric frame of reference. In addition to the medial temporal lobe, the posterior parietal system is recruited during tasks involving actively controlled movements, whereas medial temporal computations are sufficient for passive monitoring of positional changes.",
      "author": "",
      "published_date": "2025-11-07T13:16:23+00:00",
      "source": "Cognitive Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 235,
      "reading_time": 1,
      "created_at": "2025-11-11T21:40:55.615948+00:00",
      "updated_at": "2025-11-11T22:14:54.105134+00:00",
      "metadata": {
        "processed_at": "2025-11-11T22:14:54.105136+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "16712c82fde7bee131cf339ae97552f5",
      "url": "http://ieeexplore.ieee.org/document/10994678",
      "title": "Evaluation on Human Perception of Various Vibrotactile Encoding Methods Through a High Density Haptic Feedback Interface",
      "content": "High density (HD) haptic interfaces have become increasingly common for entertainment thanks to advancements in virtual reality technology, however their flexibility may make them a useful sensory substitution interface for motor rehabilitation. Yet little research has explored how users interpret different haptic feedback encoding methods. Therefore, this study's objective was to evaluate the effectiveness of various encoding methods for conveying information based on existing sensory substitution strategies, one being a line motion tracking task and the other a direction tracking task. The first encoding method was Perceived Position Encoding (PPE), where information was encoded into the perceived position of stimulation. The second was Perceived Intensity Encoding (PIE), encoded information into the perceived amplitude of the stimuli. Twenty-one participants performed tracking tasks using both the PIE and PPE methods. The results showed similar performance in line motion tracking between the PIE and PPE methods, although the extra motors used in the PPE method appear to introduce uncertainty in users. Nevertheless, users were significantly more accurate with direction tracking when using PPE. These findings highlight the need for task-specific encoding methods, and showcase the versatility of the HD haptic vest as a tool for augmented feedback in motor rehabilitation.",
      "author": "",
      "published_date": "2025-05-09T13:16:51+00:00",
      "source": "Transactions Haptics",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 197,
      "reading_time": 1,
      "created_at": "2025-11-11T19:39:41.781413+00:00",
      "updated_at": "2025-11-11T20:16:48.800806+00:00",
      "metadata": {
        "processed_at": "2025-11-11T20:16:48.800814+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "bbe0f805e4fabfb0ac2476417484aef4",
      "url": "http://ieeexplore.ieee.org/document/10946856",
      "title": "Enhancing Video Experiences for DHH Individuals Through Sound-Inspired Motion Caption-Based Spatiotemporal Tacton",
      "content": "When deaf and hard of hearing (DHH) individuals watch videos, captions are essential for them to understand the linguistic content. Current captions, however, are not suitable for conveying non-verbal sound information, such as background music, sound effects, or speech nuances. In this paper, we designed a multimodal system, Motion Caption Haptic System (MCHS), that enables DHH individuals to encounter sounds in videos through animated caption and spatiotemporal vibration patterns, supporting a more vivid and immersive experience. We elaborately designed motion captions and spatiotemporal haptic patterns for representative sound effects and spoken emotions to work well together through surveys from 27 DHH and 64 hearing participants. An evaluation with 19 DHH individuals demonstrated the capabilities and potential of the MCHS to improve their video viewing experience, along with a discussion of important issues that need to be addressed when designing multimodal captioning systems for the DHH viewers.",
      "author": "",
      "published_date": "2025-04-01T13:17:18+00:00",
      "source": "Transactions Haptics",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 146,
      "reading_time": 1,
      "created_at": "2025-11-11T19:39:41.781376+00:00",
      "updated_at": "2025-11-11T20:16:48.800818+00:00",
      "metadata": {
        "processed_at": "2025-11-11T20:16:48.800820+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "609521b013e1243f77b1eaa5e01eab3e",
      "url": "http://ieeexplore.ieee.org/document/10965524",
      "title": "VibTac: A High-Resolution High-Bandwidth Tactile Sensing Finger for Multi-Modal Perception in Robotic Manipulation",
      "content": "Tactile sensing is pivotal for enhancing robot manipulation abilities by providing crucial feedback for localized information. However, existing sensors often lack the necessary resolution and bandwidth required for intricate tasks. To address this gap, we introduce VibTac, a novel multi-modal tactile sensing finger designed to offer high-resolution and high-bandwidth tactile sensing simultaneously. VibTac seamlessly integrates vision-based and vibration-based tactile sensing modes to achieve high-resolution and high-bandwidth tactile sensing respectively, leveraging a streamlined human-inspired design for versatility in tasks. This paper outlines the key design elements of VibTac and its fabrication methods, highlighting the significance of the Elastomer Gel Pad (EGP) in its sensing mechanism. The sensor's multi-modal performance is validated through 3D reconstruction and spectral analysis to discern tactile stimuli effectively. In experimental trials, VibTac demonstrates its efficacy by achieving over 90% accuracy in insertion tasks involving objects emitting distinct sounds, such as ethernet connectors. Leveraging vision-based tactile sensing for object localization and employing a deep learning model for \u201cclick\u201d sound classification, VibTac showcases its robustness in real-world scenarios.",
      "author": "",
      "published_date": "2025-04-15T13:16:45+00:00",
      "source": "Transactions Haptics",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 169,
      "reading_time": 1,
      "created_at": "2025-11-11T19:39:41.781331+00:00",
      "updated_at": "2025-11-11T20:16:48.800822+00:00",
      "metadata": {
        "processed_at": "2025-11-11T20:16:48.800824+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "6e5289b1927a2560a61773b58736ef16",
      "url": "http://ieeexplore.ieee.org/document/10955171",
      "title": "Age-Related Impact in Illusory Torque Cues Induced by Asymmetric Vibrations",
      "content": "Illusory pulling sensations in the translational or rotational direction are induced by asymmetric vibrations applied to the fingertips. Although previous studies have discussed the involvement of mechanoreceptors associated with skin deformation and spatial processing in the parietal association cortex in the generation of illusory cues, the precise mechanism underlying this phenomenon remains unclear. In this study, we aimed to indirectly estimate the contribution of mechanoreceptors to the perception of illusory pulling torque cues by examining the relationship between vibration thresholds and the properties of these illusions, leveraging the known decline in cutaneous sensation sensitivity associated with aging (N = 40). Our results revealed an age-related increase in vibration thresholds, which is consistent with previous research. While male participants showed consistent sensitivity to illusory pulling cues across age groups, female participants exhibited a decline in sensitivity with age. Moreover, we observed only weak or no correlations between the vibration thresholds and the sensitivity of the illusory pulling cue. Although we were unable to identify any findings that explain the contribution of mechanoreceptors, we discovered a gender difference in the sensitivity to induced illusions among older individuals. These findings offer valuable insights for elucidating the mechanism underlying the illusion.",
      "author": "",
      "published_date": "2025-04-07T13:17:32+00:00",
      "source": "Transactions Haptics",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 197,
      "reading_time": 1,
      "created_at": "2025-11-11T19:39:41.781294+00:00",
      "updated_at": "2025-11-11T20:16:48.800826+00:00",
      "metadata": {
        "processed_at": "2025-11-11T20:16:48.800827+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "7cd5915b404adde9692f79fbf455044d",
      "url": "http://ieeexplore.ieee.org/document/11037651",
      "title": "A Force/Torque Taxonomy for Classifying States During Physical Co-Manipulation",
      "content": "Achieving seamless human-robot collaboration requires a deeper understanding of how agents manage and communicate forces during shared tasks. Force interactions during collaborative manipulation are inherently complex, especially when considering how they evolve over time. To address this complexity, we propose a taxonomy of decomposed force and torque components, providing a structured framework for examining haptic communication and informing the development of robots capable of performing meaningful collaborative manipulation tasks with human partners. We propose a standardized terminology for force decomposition and classification, bridging the varied language in previous literature in the field, and conduct a review of physical human-human interaction and haptic communication. The proposed taxonomy allows for a more effective and nuanced discussion of important force combinations that we expect to occur during collaborative manipulation (between human-human or human-robot teams). We also include example scenarios to illustrate the value of the proposed taxonomy in describing interactions between agents.",
      "author": "",
      "published_date": "2025-06-17T13:16:38+00:00",
      "source": "Transactions Haptics",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 149,
      "reading_time": 1,
      "created_at": "2025-11-11T19:39:41.781260+00:00",
      "updated_at": "2025-11-11T20:16:48.800830+00:00",
      "metadata": {
        "processed_at": "2025-11-11T20:16:48.800831+00:00",
        "processing_method": "github_actions"
      }
    }
  ]
}