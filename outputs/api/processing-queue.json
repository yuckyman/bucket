{
  "last_updated": "2025-10-08T02:54:22.676166+00:00",
  "pending_count": 985,
  "processed_count": 15,
  "pending_articles": [
    {
      "id": "604cffaea5736d8c2935253598862e29",
      "url": "http://ieeexplore.ieee.org/document/11174044",
      "title": "Twenty Years of World Haptics: Retrospective and Future Directions",
      "content": "null",
      "author": "",
      "published_date": "2025-09-19T13:16:57+00:00",
      "source": "Transactions Haptics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 1,
      "reading_time": 1,
      "created_at": "2025-10-08T02:44:32.867918+00:00",
      "updated_at": "2025-10-08T02:44:32.867920+00:00"
    },
    {
      "id": "65fcee7a3858adcf1bad71db41168384",
      "url": "http://ieeexplore.ieee.org/document/11174043",
      "title": "Table of Contents",
      "content": "null",
      "author": "",
      "published_date": "2025-09-19T13:16:57+00:00",
      "source": "Transactions Haptics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 1,
      "reading_time": 1,
      "created_at": "2025-10-08T02:44:32.867898+00:00",
      "updated_at": "2025-10-08T02:44:32.867900+00:00"
    },
    {
      "id": "5f20eba3c36d7a21f4e8668f0d3a88f6",
      "url": "http://ieeexplore.ieee.org/document/11174042",
      "title": "Front Cover",
      "content": "null",
      "author": "",
      "published_date": "2025-09-19T13:16:58+00:00",
      "source": "Transactions Haptics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 1,
      "reading_time": 1,
      "created_at": "2025-10-08T02:44:32.867873+00:00",
      "updated_at": "2025-10-08T02:44:32.867878+00:00"
    },
    {
      "id": "fdb4b0122212d7927163ddd75297ca04",
      "url": "http://ieeexplore.ieee.org/document/10945385",
      "title": "An Exploration of the Electrocorticogram Signatures Evoked by Ultrasound Thalamus Stimulation Under Isoflurane Anesthesia in Rats",
      "content": "Objective: The transcranial ultrasound stimulation (TUS) on the thalamus can indirectly induce cortical response. Studies have shown that general anesthetic induced unconsciousness is related to interruption of thalamocortical connectivity. However, the neural mechanism of how anesthesia levels influence cortical responses during ultrasound thalamus stimulation has never been explored yet. And it remains unknown what cortical responses signatures are evoked by ultrasound thalamus stimulation under different anesthesia levels. Methods: We recorded multichannel electrocorticogram (ECoG) evoked by ultrasound thalamus stimulation of rats at various isoflurane concentrations (i.e., 0.5%, 1.0%, 1.5%, and 2.0% (v/v)). We analyzed ECoG signatures in temporal, spatial, and frequency domains by using the ultrasound-evoked potentials (UEPs), omega complexity (OC), and phase amplitude coupling (PAC), respectively. Results: The pattern of UEPs was influenced by the anesthesia level, and the response amplitude of UEPs increased with the increase in anesthesia level (0.5% vs. 1.0% and 1.5% (v/v), p < 0.05). Also, the OC of stimulated ECoG decreased with the increase in anesthesia level (at the 1.0%, 1.5% and 2.0% (v/v), p < 0.05). The TUS promoted the coupling between the amplitude and the phase (at the 1.5% and 2.0% (v/v), p < 0.05), and the modulation index of PAC was anesthesia level-dependent. Conclusion: The cortical response induced by ultrasound thalamus stimulation is related to the anesthesia level. TUS on the thalamus combined with ECoG (TUS-ECoG) may be a potential non-invasive neuromodulation approach for understanding consciousness. Significance: This work supplied further implications on the neuromodulatory mechanisms and evaluative applications of TUS under general anesthesia.",
      "author": "",
      "published_date": "2025-03-28T13:20:15+00:00",
      "source": "Transactions Biomedical Engineering",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 252,
      "reading_time": 1,
      "created_at": "2025-10-08T02:44:30.611937+00:00",
      "updated_at": "2025-10-08T02:44:30.611939+00:00"
    },
    {
      "id": "a7fb9c9ee1a93dc6f78a5b81eaf19fb7",
      "url": "http://ieeexplore.ieee.org/document/10944577",
      "title": "Pulmonary Hypertension Detection From Heart Sound Analysis",
      "content": "The detection of Pulmonary Hypertension (PH) from the computer analysis of digitized heart sounds is a low-cost and non-invasive solution for early PH detection and screening. We present an extensive cross-domain evaluation methodology with varying animals (humans and porcine animals) and varying auscultation technologies (phonocardiography and seisomocardiography) evaluated across four methods. We introduce PH-ELM, a resource-efficient PH detection model based on the extreme learning machine that is smaller ($300\\times$ fewer parameters), energy efficient ($532\\times$ fewer watts of power), faster ($36\\times$ faster to train, $44\\times$ faster at inference), and more accurate on out-of-distribution testing (improves median accuracy by 0.09 area under the ROC curve (auROC)) in comparison to a previously best performing deep network. We make four observations from our analysis: (a) digital auscultation is a promising technology for the detection of pulmonary hypertension; (b) seismocardiography (SCG) signals and phonocardiography (PCG) signals are interchangeable to train PH detectors; (c) porcine heart sounds in the training data can be used to evaluate PH from human heart sounds (the PH-ELM model preserves 88 to 95% of the best in-distribution baseline performance); (d) predictive performance of PH detection can be mostly preserved with as few as 10 heartbeats and capturing up to approximately 200 heartbeats per subject can improve performance.",
      "author": "",
      "published_date": "2025-03-28T13:20:15+00:00",
      "source": "Transactions Biomedical Engineering",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 206,
      "reading_time": 1,
      "created_at": "2025-10-08T02:44:30.611900+00:00",
      "updated_at": "2025-10-08T02:44:30.611901+00:00"
    },
    {
      "id": "9bfbfb676531bf59b7d5ac58890423d7",
      "url": "https://www.sciencedirect.com/science/article/pii/S0006899325005293?dgcid=rss_sd_all",
      "title": "Network pharmacology combined with experimental verification for exploring the potential antidepressant mechanism of Traditional Chinese Medicine Buyang Huanwu Decoction in lipopolysaccharide-induced depressed mouse model",
      "content": "<p>Publication date: 15 November 2025</p><p><b>Source:</b> Brain Research, Volume 1867</p><p>Author(s): Sashuang Liu, Yihe Wang, Xinyu Zhou, Yijing Zhao, Zhen Wang, Dexiang Liu</p>",
      "author": "",
      "published_date": null,
      "source": "Brain Research",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 21,
      "reading_time": 1,
      "created_at": "2025-10-08T02:44:19.859575+00:00",
      "updated_at": "2025-10-08T02:44:19.859576+00:00"
    },
    {
      "id": "353d19a561e4c924cb62278a300a13e5",
      "url": "https://www.sciencedirect.com/science/article/pii/S0006899325005402?dgcid=rss_sd_all",
      "title": "Recombinant IL-1\u03b2 induces striatal dopamine depletion in aged rats: Involvement of histamine H<sub>1</sub> receptors",
      "content": "<p>Publication date: 15 November 2025</p><p><b>Source:</b> Brain Research, Volume 1867</p><p>Author(s): Ilya D. Ionov, Maria D.Krasilova, Irina I. Pushinskaya, Nicholas P. Gorev, Margarita O. Lyubimova, Lyudmila I.Maltseva, Piotr N. Komikarov</p>",
      "author": "",
      "published_date": null,
      "source": "Brain Research",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 28,
      "reading_time": 1,
      "created_at": "2025-10-08T02:44:19.859536+00:00",
      "updated_at": "2025-10-08T02:44:19.859538+00:00"
    },
    {
      "id": "514cbacf4d2c73ecd6d531562e469cbe",
      "url": "https://www.sciencedirect.com/science/article/pii/S0006899325005281?dgcid=rss_sd_all",
      "title": "Rethinking task importance in the visual world paradigm",
      "content": "<p>Publication date: 15 November 2025</p><p><b>Source:</b> Brain Research, Volume 1867</p><p>Author(s): Falk Huettig, Michael K. Tanenhaus</p>",
      "author": "",
      "published_date": null,
      "source": "Brain Research",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 14,
      "reading_time": 1,
      "created_at": "2025-10-08T02:44:19.859498+00:00",
      "updated_at": "2025-10-08T02:44:19.859499+00:00"
    },
    {
      "id": "ea3aa9c76d0a906374dd5cb24193fd0e",
      "url": "https://www.sciencedirect.com/science/article/pii/S0006899325005165?dgcid=rss_sd_all",
      "title": "Utility of <em>Drosophila</em> for studying hypoxia-inducible factor (HIF) in neurodegenerative diseases: Advantages versus limitations",
      "content": "<p>Publication date: 15 November 2025</p><p><b>Source:</b> Brain Research, Volume 1867</p><p>Author(s): Zoya Serebrovska, Lei Xi, Michael Khetsuriani, Oleksandra Protsenko, Nadiia Morozova, Denis A. Tolstun, Oksana Maksymchuk</p>",
      "author": "",
      "published_date": null,
      "source": "Brain Research",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 24,
      "reading_time": 1,
      "created_at": "2025-10-08T02:44:19.859461+00:00",
      "updated_at": "2025-10-08T02:44:19.859462+00:00"
    },
    {
      "id": "ac3208cf5638b48b260b245ddfd933fd",
      "url": "https://www.sciencedirect.com/science/article/pii/S0006899325005335?dgcid=rss_sd_all",
      "title": "BNIP3L/NIX-mediated mitophagy: Future directions in Alzheimer\u2019s disease",
      "content": "<p>Publication date: 15 November 2025</p><p><b>Source:</b> Brain Research, Volume 1867</p><p>Author(s): Violina Kakoty, Khang Wen Goh, Prashant Kesharwani, Young Tag Ko</p>",
      "author": "",
      "published_date": null,
      "source": "Brain Research",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 19,
      "reading_time": 1,
      "created_at": "2025-10-08T02:44:19.859439+00:00",
      "updated_at": "2025-10-08T02:44:19.859441+00:00"
    }
  ],
  "recently_processed": [
    {
      "id": "609521b013e1243f77b1eaa5e01eab3e",
      "url": "http://ieeexplore.ieee.org/document/10965524",
      "title": "VibTac: A High-Resolution High-Bandwidth Tactile Sensing Finger for Multi-Modal Perception in Robotic Manipulation",
      "content": "Tactile sensing is pivotal for enhancing robot manipulation abilities by providing crucial feedback for localized information. However, existing sensors often lack the necessary resolution and bandwidth required for intricate tasks. To address this gap, we introduce VibTac, a novel multi-modal tactile sensing finger designed to offer high-resolution and high-bandwidth tactile sensing simultaneously. VibTac seamlessly integrates vision-based and vibration-based tactile sensing modes to achieve high-resolution and high-bandwidth tactile sensing respectively, leveraging a streamlined human-inspired design for versatility in tasks. This paper outlines the key design elements of VibTac and its fabrication methods, highlighting the significance of the Elastomer Gel Pad (EGP) in its sensing mechanism. The sensor's multi-modal performance is validated through 3D reconstruction and spectral analysis to discern tactile stimuli effectively. In experimental trials, VibTac demonstrates its efficacy by achieving over 90% accuracy in insertion tasks involving objects emitting distinct sounds, such as ethernet connectors. Leveraging vision-based tactile sensing for object localization and employing a deep learning model for \u201cclick\u201d sound classification, VibTac showcases its robustness in real-world scenarios.",
      "author": "",
      "published_date": "2025-04-15T13:16:45+00:00",
      "source": "Transactions Haptics",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 169,
      "reading_time": 1,
      "created_at": "2025-10-08T02:44:32.868102+00:00",
      "updated_at": "2025-10-08T02:54:22.567415+00:00",
      "metadata": {
        "processed_at": "2025-10-08T02:54:22.567428+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "6e5289b1927a2560a61773b58736ef16",
      "url": "http://ieeexplore.ieee.org/document/10955171",
      "title": "Age-Related Impact in Illusory Torque Cues Induced by Asymmetric Vibrations",
      "content": "Illusory pulling sensations in the translational or rotational direction are induced by asymmetric vibrations applied to the fingertips. Although previous studies have discussed the involvement of mechanoreceptors associated with skin deformation and spatial processing in the parietal association cortex in the generation of illusory cues, the precise mechanism underlying this phenomenon remains unclear. In this study, we aimed to indirectly estimate the contribution of mechanoreceptors to the perception of illusory pulling torque cues by examining the relationship between vibration thresholds and the properties of these illusions, leveraging the known decline in cutaneous sensation sensitivity associated with aging (N = 40). Our results revealed an age-related increase in vibration thresholds, which is consistent with previous research. While male participants showed consistent sensitivity to illusory pulling cues across age groups, female participants exhibited a decline in sensitivity with age. Moreover, we observed only weak or no correlations between the vibration thresholds and the sensitivity of the illusory pulling cue. Although we were unable to identify any findings that explain the contribution of mechanoreceptors, we discovered a gender difference in the sensitivity to induced illusions among older individuals. These findings offer valuable insights for elucidating the mechanism underlying the illusion.",
      "author": "",
      "published_date": "2025-04-07T13:17:32+00:00",
      "source": "Transactions Haptics",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 197,
      "reading_time": 1,
      "created_at": "2025-10-08T02:44:32.868065+00:00",
      "updated_at": "2025-10-08T02:54:22.567432+00:00",
      "metadata": {
        "processed_at": "2025-10-08T02:54:22.567434+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "7cd5915b404adde9692f79fbf455044d",
      "url": "http://ieeexplore.ieee.org/document/11037651",
      "title": "A Force/Torque Taxonomy for Classifying States During Physical Co-Manipulation",
      "content": "Achieving seamless human-robot collaboration requires a deeper understanding of how agents manage and communicate forces during shared tasks. Force interactions during collaborative manipulation are inherently complex, especially when considering how they evolve over time. To address this complexity, we propose a taxonomy of decomposed force and torque components, providing a structured framework for examining haptic communication and informing the development of robots capable of performing meaningful collaborative manipulation tasks with human partners. We propose a standardized terminology for force decomposition and classification, bridging the varied language in previous literature in the field, and conduct a review of physical human-human interaction and haptic communication. The proposed taxonomy allows for a more effective and nuanced discussion of important force combinations that we expect to occur during collaborative manipulation (between human-human or human-robot teams). We also include example scenarios to illustrate the value of the proposed taxonomy in describing interactions between agents.",
      "author": "",
      "published_date": "2025-06-17T13:16:38+00:00",
      "source": "Transactions Haptics",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 149,
      "reading_time": 1,
      "created_at": "2025-10-08T02:44:32.868031+00:00",
      "updated_at": "2025-10-08T02:54:22.567436+00:00",
      "metadata": {
        "processed_at": "2025-10-08T02:54:22.567438+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "bffad7ff78c038ce61497f8206575f26",
      "url": "http://ieeexplore.ieee.org/document/11045422",
      "title": "Haptic Relocation Away From the Fingertip: Where, Why, and How",
      "content": "Tactile haptic devices are often designed to render meaningful, complex, and realistic touch-based information on users\u2019 skin. While fingertips and hands are the most preferred body locations to render haptic feedback, recent trends allow such feedback to be extended to alternative body locations (e.g., wrist, arm, torso, foot) for various scenarios due to reasons such as wearability and needs of the application. In this paper, I address the new concept of haptic relocation. It refers to scenarios in which the expected feedback is related to the fingertips but rendered on a different body location instead \u2013 e.g., contact forces registered by two robotic fingers during teleoperation rendered to the users\u2019 wrist instead of the fingers. I investigated the design choices of wearable haptic devices for haptic relocation concerning different body locations, targeted applications, and actuator selection. I discuss approaches and design choices from the literature by speculating on the possible reasons, and conclude the paper by highlighting some challenges and issues to be mindful of in the future. This paper will guide engineers and researchers in searching for alternative haptic rendering solutions \u2013 especially when fingers and hands are not available for haptic interaction.",
      "author": "",
      "published_date": "2025-06-20T13:16:43+00:00",
      "source": "Transactions Haptics",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 194,
      "reading_time": 1,
      "created_at": "2025-10-08T02:44:32.867999+00:00",
      "updated_at": "2025-10-08T02:54:22.567440+00:00",
      "metadata": {
        "processed_at": "2025-10-08T02:54:22.567441+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "654c67a50800e0d8df1eb841fa063ae1",
      "url": "http://ieeexplore.ieee.org/document/10918829",
      "title": "Tactile\u2013Thermal Interactions: Cooperation and Competition",
      "content": "This review focuses on the interactions between the cutaneous senses, and in particular touch and temperature, as these are the most relevant for developing skin-based display technologies for use in virtual reality (VR) and for designing multimodal haptic devices. A broad spectrum of research is reviewed ranging from studies that have examined the mechanisms involved in thermal intensification and tactile masking, to more applied work that has focused on implementing thermal-tactile illusions such as thermal referral and illusory wetness in VR environments. Research on these tactile-thermal illusions has identified the differences between the senses of cold and warmth in terms of their effects on the perception of object properties and the prevalence of the perceptual experiences elicited. They have also underscored the fundamental spatial and temporal differences between the tactile and thermal senses. The wide-ranging body of research on compound sensations such as wetness and stickiness has highlighted the mechanisms involved in sensing moisture and provided a framework for measuring these sensations in a variety of contexts. Although the interactions between the two senses are complex, it is clear that the addition of thermal inputs to a tactile display enhances both user experience and enables novel sensory experiences.",
      "author": "",
      "published_date": "2025-03-10T13:16:41+00:00",
      "source": "Transactions Haptics",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 198,
      "reading_time": 1,
      "created_at": "2025-10-08T02:44:32.867958+00:00",
      "updated_at": "2025-10-08T02:54:22.567446+00:00",
      "metadata": {
        "processed_at": "2025-10-08T02:54:22.567448+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "78a543035cc17e2ac6f73ecd95cce1ae",
      "url": "http://ieeexplore.ieee.org/document/10750441",
      "title": "Foundation Model for Advancing Healthcare: Challenges, Opportunities and Future Directions",
      "content": "Foundation model, trained on a diverse range of data and adaptable to a myriad of tasks, is advancing healthcare. It fosters the development of healthcare artificial intelligence (AI) models tailored to the intricacies of the medical field, bridging the gap between limited AI models and the varied nature of healthcare practices. The advancement of a healthcare foundation model (HFM) brings forth tremendous potential to augment intelligent healthcare services across a broad spectrum of scenarios. However, despite the imminent widespread deployment of HFMs, there is currently a lack of clear understanding regarding their operation in the healthcare field, their existing challenges, and their future trajectory. To answer these critical inquiries, we present a comprehensive and in-depth examination that delves into the landscape of HFMs. It begins with a comprehensive overview of HFMs, encompassing their methods, data, and applications, to provide a quick understanding of the current progress. Subsequently, it delves into a thorough exploration of the challenges associated with data, algorithms, and computing infrastructures in constructing and widely applying foundation models in healthcare. Furthermore, this survey identifies promising directions for future development in this field. We believe that this survey will enhance the community's understanding of the current progress of HFMs and serve as a valuable source of guidance for future advancements in this domain.",
      "author": "",
      "published_date": "2024-11-12T13:16:56+00:00",
      "source": "Reviews Biomedical Engineering",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 214,
      "reading_time": 1,
      "created_at": "2025-10-07T23:38:32.697298+00:00",
      "updated_at": "2025-10-08T01:04:56.567576+00:00",
      "metadata": {
        "processed_at": "2025-10-08T01:04:56.567586+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "f3ebee0a159c29e785b8640ab568613e",
      "url": "http://ieeexplore.ieee.org/document/10729663",
      "title": "Data- and Physics-Driven Deep Learning Based Reconstruction for Fast MRI: Fundamentals and Methodologies",
      "content": "Magnetic Resonance Imaging (MRI) is a pivotal clinical diagnostic tool, yet its extended scanning times often compromise patient comfort and image quality, especially in volumetric, temporal and quantitative scans. This review elucidates recent advances in MRI acceleration via data and physics-driven models, leveraging techniques from algorithm unrolling models, enhancement-based methods, and plug-and-play models to the emerging full spectrum of generative model-based methods. We also explore the synergistic integration of data models with physics-based insights, encompassing the advancements in multi-coil hardware accelerations like parallel imaging and simultaneous multi-slice imaging, and the optimization of sampling patterns. We then focus on domain-specific challenges and opportunities, including image redundancy exploitation, image integrity, evaluation metrics, data heterogeneity, and model generalization. This work also discusses potential solutions and future research directions, with an emphasis on the role of data harmonization and federated learning for further improving the general applicability and performance of these methods in MRI reconstruction.",
      "author": "",
      "published_date": "2024-10-22T13:18:56+00:00",
      "source": "Reviews Biomedical Engineering",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 151,
      "reading_time": 1,
      "created_at": "2025-10-07T23:38:32.697264+00:00",
      "updated_at": "2025-10-08T01:04:56.567590+00:00",
      "metadata": {
        "processed_at": "2025-10-08T01:04:56.567592+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "b71ad97ebddb2087936b4010c1aaf456",
      "url": "http://ieeexplore.ieee.org/document/10746601",
      "title": "Artificial General Intelligence for Medical Imaging Analysis",
      "content": "Large-scale Artificial General Intelligence (AGI) models, including Large Language Models (LLMs) such as ChatGPT/GPT-4, have achieved unprecedented success in a variety of general domain tasks. Yet, when applied directly to specialized domains like medical imaging, which require in-depth expertise, these models face notable challenges arising from the medical field's inherent complexities and unique characteristics. In this review, we delve into the potential applications of AGI models in medical imaging and healthcare, with a primary focus on LLMs, Large Vision Models, and Large Multimodal Models. We provide a thorough overview of the key features and enabling techniques of LLMs and AGI, and further examine the roadmaps guiding the evolution and implementation of AGI models in the medical sector, summarizing their present applications, potentialities, and associated challenges. In addition, we highlight potential future research directions, offering a holistic view on upcoming ventures. This comprehensive review aims to offer insights into the future implications of AGI in medical imaging, healthcare, and beyond.",
      "author": "",
      "published_date": "2024-11-07T13:17:37+00:00",
      "source": "Reviews Biomedical Engineering",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 159,
      "reading_time": 1,
      "created_at": "2025-10-07T23:38:32.697235+00:00",
      "updated_at": "2025-10-08T01:04:56.567594+00:00",
      "metadata": {
        "processed_at": "2025-10-08T01:04:56.567596+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "3970a7e47edc49703b34feadbd5d1dab",
      "url": "http://ieeexplore.ieee.org/document/10720187",
      "title": "Exhaled Breath Analysis: From Laboratory Test to Wearable Sensing",
      "content": "Breath analysis and monitoring have emerged as pivotal components in both clinical research and daily health management, particularly in addressing the global health challenges posed by respiratory and metabolic disorders. The advancement of breath analysis strategies necessitates a multidisciplinary approach, seamlessly integrating expertise from medicine, biology, engineering, and materials science. Recent innovations in laboratory methodologies and wearable sensing technologies have ushered in an era of precise, real-time, and in situ breath analysis and monitoring. This comprehensive review elucidates the physical and chemical aspects of breath analysis, encompassing respiratory parameters and both volatile and non-volatile constituents. It emphasizes their physiological and clinical significance, while also exploring cutting-edge laboratory testing techniques and state-of-the-art wearable devices. Furthermore, the review delves into the application of sophisticated data processing technologies in the burgeoning field of breathomics and examines the potential of breath control in human-machine interaction paradigms. Additionally, it provides insights into the challenges of translating innovative laboratory and wearable concepts into mainstream clinical and daily practice. Continued innovation and interdisciplinary collaboration will drive progress in breath analysis, potentially revolutionizing personalized medicine through entirely non-invasive breath methodology.",
      "author": "",
      "published_date": "2024-10-16T13:15:55+00:00",
      "source": "Reviews Biomedical Engineering",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 182,
      "reading_time": 1,
      "created_at": "2025-10-07T23:38:32.697204+00:00",
      "updated_at": "2025-10-08T01:04:56.567598+00:00",
      "metadata": {
        "processed_at": "2025-10-08T01:04:56.567600+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "483769689d304d6940ab358e0b085a8c",
      "url": "http://ieeexplore.ieee.org/document/10771694",
      "title": "Earable Multimodal Sensing and Stimulation: A Prospective Toward Unobtrusive Closed-Loop Biofeedback",
      "content": "The human ear has emerged as a bidirectional gateway to the brain's and body's signals. Recent advances in around-the-ear and in-ear sensors have enabled the assessment of biomarkers and physiomarkers derived from brain and cardiac activity using ear-electroencephalography (ear-EEG), photoplethysmography (ear-PPG), and chemical sensing of analytes from the ear, with ear-EEG having been taken beyond-the-lab to outer space. Parallel advances in non-invasive and minimally invasive brain stimulation techniques have leveraged the ear's access to two cranial nerves to modulate brain and body activity. The vestibulocochlear nerve stimulates the auditory cortex and limbic system with sound, while the auricular branch of the vagus nerve indirectly but significantly couples to the autonomic nervous system and cardiac output. Acoustic and current mode stimuli delivered using discreet and unobtrusive earables are an active area of research, aiming to make biofeedback and bioelectronic medicine deliverable outside of the clinic, with remote and continuous monitoring of therapeutic responsivity and long-term adaptation. Leveraging recent advances in ear-EEG, transcutaneous auricular vagus nerve stimulation (taVNS), and unobtrusive acoustic stimulation, we review accumulating evidence that combines their potential into an integrated earable platform for closed-loop multimodal sensing and neuromodulation, towards personalized and holistic therapies that are near, in- and around-the-ear.",
      "author": "",
      "published_date": "2024-11-29T13:16:54+00:00",
      "source": "Reviews Biomedical Engineering",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 200,
      "reading_time": 1,
      "created_at": "2025-10-07T23:38:32.697170+00:00",
      "updated_at": "2025-10-08T01:04:56.567602+00:00",
      "metadata": {
        "processed_at": "2025-10-08T01:04:56.567603+00:00",
        "processing_method": "github_actions"
      }
    }
  ]
}