{
  "last_updated": "2025-10-30T18:21:23.122462+00:00",
  "pending_count": 985,
  "processed_count": 15,
  "pending_articles": [
    {
      "id": "a42022e7aa2272bd80755edaade3bafd",
      "url": "https://www.pnas.org/doi/abs/10.1073/pnas.2512855122?af=R",
      "title": "Neuronal plasticity at puberty in mouse hypothalamic Kiss1 neurons that control fertility",
      "content": "Proceedings of the National Academy of Sciences, Volume 122, Issue 43, October 2025. <br />SignificancePuberty is required for mammals to achieve fertility, which ensures continuation of the species. By the end of puberty, a regular cycle in females allows the periodic release of eggs. This is regulated by hormonal feedback loops between the ...",
      "author": "Yuanxin ZhangLeonie M. PakulatSzabolcs Tak\u00e1csLauren CampbellElisa GallianoErik HrabovszkyWilliam H. ColledgeSusan JonesaDepartment of Physiology, Development and Neuroscience, University of Cambridge, Cambridge CB2 3EG, United KingdombLaboratory of Reproductive Neurobiology, Hungarian Research Network, Institute of Experimental Medicine, Budapest 1083, Hungary",
      "published_date": "2025-10-21T07:00:00+00:00",
      "source": "Pnas Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 54,
      "reading_time": 1,
      "created_at": "2025-10-30T17:42:50.086723+00:00",
      "updated_at": "2025-10-30T17:42:50.086724+00:00"
    },
    {
      "id": "a778033399372a2d88d49c00984d5fa1",
      "url": "https://www.pnas.org/doi/abs/10.1073/pnas.2507291122?af=R",
      "title": "From retinotopic to ordinal coding: Dissecting the cortical stages of visual word recognition",
      "content": "Proceedings of the National Academy of Sciences, Volume 122, Issue 43, October 2025. <br />SignificanceFluent reading requires that the brain encodes the order of letters within a word, yet without regard for where they appear on the retina. Information must be transformed from a retinotopic code into a position-invariant word form. Here, we ...",
      "author": "Aakash AgrawalStanislas DehaeneaCognitive Neuroimaging Unit, Commissariat \u00e0 l\u2019\u00e9nergie atomique et aux \u00e9nergies alternatives, INSERM, Universit\u00e9 Paris-Saclay, NeuroSpin Center, Gif-sur-Yvette 91191, FrancebColl\u00e8ge de France, Universit\u00e9 Paris-Sciences-Lettres, Paris 75005, France",
      "published_date": "2025-10-21T07:00:00+00:00",
      "source": "Pnas Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 54,
      "reading_time": 1,
      "created_at": "2025-10-30T17:42:50.086650+00:00",
      "updated_at": "2025-10-30T17:42:50.086652+00:00"
    },
    {
      "id": "1eae4f6e9da31aa451320cb4b5e6f020",
      "url": "https://www.pnas.org/doi/abs/10.1073/pnas.2503576122?af=R",
      "title": "Descattering and image restoration with a transformer-based neural network in deep tissue imaging",
      "content": "Proceedings of the National Academy of Sciences, Volume 122, Issue 43, October 2025. <br />SignificanceThe significant contributions of this work are threefold. First, it leverages deep learning to extend in vivo imaging depth of two-photon excitation fluorescence microscopy, far beyond the depths achieved by state-of-the-art methods. Second, ...",
      "author": "Xiangcong XuRenlong ZhangChenggui LuoChi ZhangYanping LiDanying LinBin YuLiwei LiuXiaoyu WengYiping WangLingjie KongJia LiJunle QuaState Key Laboratory of Radio Frequency Heterogeneous Integration, Key Laboratory of Optoelectronic Devices and Systems of Ministry of Education and Guangdong Province, College of Physics and Optoelectronic Engineering, Shenzhen University, Shenzhen 518060, ChinabState Key Laboratory of Precision Measurement Technology and Instruments, Department of Precision Instrument, Tsinghua University, Beijing 100084, China",
      "published_date": "2025-10-21T07:00:00+00:00",
      "source": "Pnas Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 48,
      "reading_time": 1,
      "created_at": "2025-10-30T17:42:50.086626+00:00",
      "updated_at": "2025-10-30T17:42:50.086628+00:00"
    },
    {
      "id": "82bde25702e7ab6957f9f70d2d2860a3",
      "url": "https://www.frontiersin.org/articles/10.3389/fncom.2025.1655462",
      "title": "Neuron synchronization analyzed through spatial-temporal attention",
      "content": "Neuronal synchronization refers to the temporal coordination of activity across populations of neurons, a process that underlies coherent information processing, supports the encoding of diverse sensory stimuli, and facilitates adaptive behavior in dynamic environments. Previous studies of synchronization have predominantly emphasized rate coding and pairwise interactions between neurons, which have provided valuable insights into emergent network phenomena but remain insufficient for capturing the full complexity of temporal dynamics in spike trains, particularly the interspike interval. To address this limitation, we performed in vivo neural ensemble recording in the primary olfactory center\u2014the antennal lobe (AL) of the hawk moth Manduca sexta\u2014by stimulating with floral odor blends and systematically varying the concentration of an individual odorant within one of the mixtures. We then applied machine learning methods integrating modern attention mechanisms and generative normalizing flows, enabling the extraction of semi-interpretable attention weights that characterize dynamic neuronal interactions. These learned weights not only recapitulated the established principles of neuronal synchronization but also facilitated the functional classification of two major cell types in the antennal lobe (AL) [local interneurons (LNs) and projection neurons (PNs)]. Furthermore, by experimentally manipulating the excitation/inhibition balance within the circuit, our approach revealed the relationships between synchronization strength and odorant composition, providing new insight into the principles by which olfactory networks encode and integrate complex sensory inputs.",
      "author": "Jeffrey A. Riffell",
      "published_date": "2025-10-16T00:00:00+00:00",
      "source": "Frontiers Computational Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 217,
      "reading_time": 1,
      "created_at": "2025-10-30T17:42:47.597837+00:00",
      "updated_at": "2025-10-30T17:42:47.597841+00:00"
    },
    {
      "id": "8fe0a8acff4ee28593be3c2d26e9cfb0",
      "url": "https://www.frontiersin.org/articles/10.3389/fncom.2025.1616472",
      "title": "Modeling cognition through adaptive neural synchronization: a multimodal framework using EEG, fMRI, and reinforcement learning",
      "content": "IntroductionUnderstanding the cognitive process of thinking as a neural phenomenon remains a central challenge in neuroscience and computational modeling. This study addresses this challenge by presenting a biologically grounded framework that simulates adaptive decision making across cognitive states.MethodsThe model integrates neuronal synchronization, metabolic energy consumption, and reinforcement learning. Neural synchronization is simulated using Kuramoto oscillators, while energy dynamics are constrained by multimodal activity profiles. Reinforcement learning agents\u2014Q-learning and Deep Q-Network (DQN)\u2014modulate external inputs to maintain optimal synchrony with minimal energy cost. The model is validated using real EEG and fMRI data, comparing simulated and empirical outputs across spectral power, phase synchrony, and BOLD activity.ResultsThe DQN agent achieved rapid convergence, stabilizing cumulative rewards within 200 episodes and reducing mean synchronization error by over 40%, outperforming Q-learning in speed and generalization. The model successfully reproduced canonical brain states\u2014focused attention, multitasking, and rest. Simulated EEG showed dominant alpha-band power (3.2\u202f\u00d7\u202f10\u22124\u202fa.u.), while real EEG exhibited beta-dominance (3.2\u202f\u00d7\u202f10\u22124\u202fa.u.), indicating accurate modeling of resting states and tunability for active tasks. Phase Locking Value (PLV) ranged from 0.9806 to 0.9926, with the focused condition yielding the lowest circular variance (0.0456) and a near significant phase shift compared to rest (t\u202f=\u202f\u22122.15, p\u202f=\u202f0.075). Cross-modal validation revealed moderate correlation between simulated and real BOLD signals (r\u202f=\u202f0.30, resting condition), with delayed inputs improving temporal alignment. General Linear Model (GLM) analysis of simulated BOLD data showed high region-specific prediction accuracy (R2\u202f=\u202f0.973\u20130.993, p\u202f<\u202f0.001), particularly in prefrontal, parietal, and anterior cingulate cortices. Voxel-wise correlation and ICA decomposition confirmed structured network dynamics.DiscussionThese findings demonstrate that the framework captures both electrophysiological and spatial aspects of brain activity, respects neuroenergetic constraints, and adaptively regulates brain-like states through reinforcement learning. The model offers a scalable platform for simulating cognition and developing biologically inspired neuroadaptive systems.ConclusionThis work provides a novel and testable approach to modeling thinking as a biologically constrained control problem and lays the groundwork for future applications in cognitive modeling and brain-computer interfaces.",
      "author": "Horace T. Crogman",
      "published_date": "2025-10-16T00:00:00+00:00",
      "source": "Frontiers Computational Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 332,
      "reading_time": 1,
      "created_at": "2025-10-30T17:42:47.597790+00:00",
      "updated_at": "2025-10-30T17:42:47.597792+00:00"
    },
    {
      "id": "35e289e20714665d1b5bac3f8814781e",
      "url": "https://www.frontiersin.org/articles/10.3389/fncom.2025.1601641",
      "title": "Sudden restructuring of memory representations in recurrent neural networks with repeated stimulus presentations",
      "content": "While acquisition curves in human learning averaged at the group level display smooth, gradual changes in performance, individual learning curves across cognitive domains reveal sudden, discontinuous jumps in performance. Similar thresholding effects are a hallmark of a range of nonlinear systems which can be explored using simple, abstract models. Here, I investigate discontinuous changes in learning performance using Amari-Hopfield networks with Hebbian learning rules which are repeatedly exposed to a single stimulus. Simulations reveal that the attractor basin size for a target stimulus increases in discrete jumps rather than gradual changes with repeated stimulus exposure. The distribution of the size of these positive jumps in basin size is best approximated by a lognormal distribution, suggesting that the distribution is heavy-tailed. Examination of the transition graph structure for networks before and after basin size changes reveals that newly acquired states are often organized into hierarchically branching tree structures, and that the distribution of branch sizes is best approximated by a power law distribution. The findings suggest that even simple nonlinear network models of associative learning exhibit discontinuous changes in performance with repeated learning which mirror behavioral results observed in humans. Future work can investigate similar mechanisms in more biologically detailed network models, potentially offering insight into the network mechanisms of learning with repeated exposure or practice.",
      "author": "Jonathon R. Howlett",
      "published_date": "2025-10-22T00:00:00+00:00",
      "source": "Frontiers Computational Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 215,
      "reading_time": 1,
      "created_at": "2025-10-30T17:42:47.597624+00:00",
      "updated_at": "2025-10-30T17:42:47.597626+00:00"
    },
    {
      "id": "372ddb9793ee2134342ee0c69605a2a0",
      "url": "https://www.frontiersin.org/articles/10.3389/fnhum.2025.1725397",
      "title": "Correction: Cognitive dysfunction\u2014an under looked avenue to promote health in incarcerated elderly population through yoga",
      "content": "",
      "author": "Akshay Anand",
      "published_date": "2025-10-27T00:00:00+00:00",
      "source": "Frontiers Human Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-10-30T17:42:46.196927+00:00",
      "updated_at": "2025-10-30T17:42:46.196929+00:00"
    },
    {
      "id": "171f6bb40341ce09041484a4fd97f3df",
      "url": "http://iopscience.iop.org/article/10.1088/1741-2552/ae10e1",
      "title": "Optimizing real-time phase detection in diverse rhythmic biological signals for phase-specific neurostimulation",
      "content": "Objective. Closed-loop, phase-specific neurostimulation is a powerful method to modulate ongoing brain activity for clinical and research applications. Phase-specific stimulation relies on estimating the phase of an ongoing oscillation in real time and issuing a control command at a target phase. Phase detection algorithms based on the fast Fourier transform (FFT) are widely used due to their computational efficiency and robustness. However, it is unclear how algorithm performance depends on the spectral properties of the input signal and how algorithm parameters can be optimized. Approach. We evaluated the in silico performance of three phase detection algorithms [Endpoint-corrected Hilbert transform (ecHT), Hilbert transform (HT), and phase mapping (PM)] on three real-world biological signals with distinct spectral properties (theta oscillations from rodent hippocampal local field potential, alpha oscillations from human electroencephalogram (EEG), and hand movement kinematics from essential tremor patients) to identify the optimal model and parameters. We then validated the performance of an algorithm for estimating theta phase in real-time using rats implanted with electrodes in the hippocampus. Results. First, we found that signal amplitude and frequency variations strongly influence algorithm performance. Frequency-specific signal-to-noise ratio was positively correlated with performance (mean R2 = 0.42 across metrics), while amplitude and frequency variability were negatively correlated (mean R2 = 0.50 across metrics). Second, we showed that the length of the data window used for phase estimation is the key parameter for optimal performance of FFT-based algorithms, where the optimal data window length corresponds to the period of the oscillation (\u223c150 ms for hippocampal theta oscillations, \u223c100 ms for human EEG alpha, and \u223c125 ms for essential tremor kinematics). We validated this finding in vivo by estimating the phase of theta oscillations from the hippocampus of freely behaving rats, where a data window length corresponding to one theta cycle yielded the best performance across all metrics compared with shorter or longer window lengths. Significance. Our findings clarify the relationship between signal properties and algorithm performance and provide a convenient method for optimizing FFT-based phase detection algorithms. We show that a data window length corresponding to one cycle of an oscillation can lead to improved performance.",
      "author": "Mengzhan Liufu, Zachary M Leveroni, Sameera Shridhar, Nan Zhou and Jai Y Yu",
      "published_date": "2025-10-23T23:00:00+00:00",
      "source": "Journal Neural Engineering",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 351,
      "reading_time": 1,
      "created_at": "2025-10-30T17:42:41.083564+00:00",
      "updated_at": "2025-10-30T17:42:41.083565+00:00"
    },
    {
      "id": "e0173ecef10ded08d35e927863a6030e",
      "url": "http://iopscience.iop.org/article/10.1088/1741-2552/ae08ea",
      "title": "Multitarget neurostimulation of the deep brain: clinical opportunities, challenges, and emerging technologies",
      "content": "Recent computational, pre-clinical, and clinical studies have demonstrated the potential for using neuromodulation through simultaneous targeting of multiple deep brain regions. This approach has already been used for therapeutic and systems neuroscience applications. However, the broad clinical adoption of invasive distributed deep brain interfaces remains in its early stages. This review explores the barriers to implementation by addressing three key questions: do the benefits of implanting multiple electrodes justify the associated risks for specific applications? What is the risk-benefit ratio, and what technological advancements will be necessary to encourage clinical adoption? We also examine next-generation technologies that could enable multi-target brain interfaces, including system-on-chip micro-stimulators as well as nanoparticles. We highlight the role of novel machine learning algorithms in the optimization of stimulation parameters and for the guidance of device placement. Emerging hardware accelerators equipped with on-chip AI have demonstrated functionality that can be used to decode and to classify distributed neuronal data. This advance in hardware accelerators has also contributed to the potential for enhanced closed-loop stimulation control of devices. Despite these advances, significant technological and translational barriers persist, limiting the widespread clinical application of multi-target brain interfaces. This review provides a critical analysis of recent prototypes and novel hardware for use in multi-target systems. We will discuss both clinical and research applications. We will focus on the utilization of multi-site technologies to meet the needs of neurological diseases. We conclude that there exists a critical need for further innovation and integration of multi-site technologies into clinical practice.",
      "author": "Michael J Del Sesto, Serban Negoita, Maria Bruzzone Giraldez, Zachary LaJoie, Khaleda Akhter Sathi, Joshua K Wong, Alik S Widge, Michael S Okun and Adam Khalifa",
      "published_date": "2025-10-29T00:00:00+00:00",
      "source": "Journal Neural Engineering",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 249,
      "reading_time": 1,
      "created_at": "2025-10-30T17:42:41.083333+00:00",
      "updated_at": "2025-10-30T17:42:41.083335+00:00"
    },
    {
      "id": "afd96674a60c16b7ed3e463f6d235918",
      "url": "https://pubmed.ncbi.nlm.nih.gov/38873838/?utm_source=BucketBot&utm_medium=rss&utm_campaign=None&utm_content=1BUB2BG5RbxOblm-hBbiJWEhGG43qlVrvGNHOTqBKva9wWrItM&fc=None&ff=20251030134235&v=2.18.0.post22+67771e2",
      "title": "The impact of CSF-filled cavities on scalp EEG and its implications",
      "content": "Previous studies have found electroencephalogram (EEG) amplitude and scalp topography differences between neurotypical and neurological/neurosurgical groups, being interpreted at the cognitive level. However, these comparisons are invariably accompanied by anatomical changes. Critical to EEG are the so-called volume currents, which are affected by the spatial distribution of the different tissues in the head. We investigated the effect of cerebrospinal fluid (CSF)-filled cavities on simulated...",
      "author": "Maria Carla Piastra",
      "published_date": "2024-06-14T10:00:00+00:00",
      "source": "Oostenveld Robert",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 64,
      "reading_time": 1,
      "created_at": "2025-10-30T17:42:39.259679+00:00",
      "updated_at": "2025-10-30T17:42:39.259680+00:00"
    }
  ],
  "recently_processed": [
    {
      "id": "10e7cbd7a57cdb9572fe7ed61cfa90d5",
      "url": "https://www.sciencedirect.com/science/article/pii/S1053811925005610?dgcid=rss_sd_all",
      "title": "Test-retest reproducibility of structural and proxy estimates of brain connectivity at rest",
      "content": "<p>Publication date: 15 November 2025</p><p><b>Source:</b> NeuroImage, Volume 322</p><p>Author(s): Aldana Lizarraga, Arianna Sala, Kathrin Koch, Igor Yakushev</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroimage",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 16,
      "reading_time": 1,
      "created_at": "2025-10-30T17:42:57.268490+00:00",
      "updated_at": "2025-10-30T18:21:23.015739+00:00",
      "metadata": {
        "processed_at": "2025-10-30T18:21:23.015749+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "d0f334a39a923038fcb68d0cbee9dd73",
      "url": "https://www.sciencedirect.com/science/article/pii/S1053811925005592?dgcid=rss_sd_all",
      "title": "Neurocognitive mechanisms of age-related decline in global motion perception",
      "content": "<p>Publication date: 15 November 2025</p><p><b>Source:</b> NeuroImage, Volume 322</p><p>Author(s): Yaxi Hong, Ting Liu, Dan Luo, Ziliang Zhu, Shizhen Yan, Hua Jin</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroimage",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 20,
      "reading_time": 1,
      "created_at": "2025-10-30T17:42:57.268471+00:00",
      "updated_at": "2025-10-30T18:21:23.015753+00:00",
      "metadata": {
        "processed_at": "2025-10-30T18:21:23.015755+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "2e04813de5c8b36c4e83691d63f5fc4d",
      "url": "https://www.sciencedirect.com/science/article/pii/S1053811925005580?dgcid=rss_sd_all",
      "title": "Disrupted temporal structure of the M/EEG meta-states sequencing in Alzheimer\u2019s disease",
      "content": "<p>Publication date: 15 November 2025</p><p><b>Source:</b> NeuroImage, Volume 322</p><p>Author(s): Marina Sandon\u00eds-Fern\u00e1ndez, Pablo N\u00fa\u00f1ez, Miguel A. Tola-Arribas, M\u00f3nica Cano, Hideyuki Hoshi, Yoshihito Shigihara, Jes\u00fas Poza, Carlos G\u00f3mez</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroimage",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 25,
      "reading_time": 1,
      "created_at": "2025-10-30T17:42:57.268450+00:00",
      "updated_at": "2025-10-30T18:21:23.015760+00:00",
      "metadata": {
        "processed_at": "2025-10-30T18:21:23.015761+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "22408adb7ebf0bcd0820733cf6724f30",
      "url": "https://www.sciencedirect.com/science/article/pii/S1053811925005361?dgcid=rss_sd_all",
      "title": "Paired-pulse TMS of premotor cortex produces non-linear suppressive effects on neural activity in the targeted network - a TMS-fMRI study",
      "content": "<p>Publication date: 15 November 2025</p><p><b>Source:</b> NeuroImage, Volume 322</p><p>Author(s): Laerke Gebser Krohne, Sofus Nygaard, Maud Eline Ottenheijm, Marie Louise Liu, Axel Thielscher, Hartwig Roman Siebner, Kristoffer Hougaard Madsen</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroimage",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 27,
      "reading_time": 1,
      "created_at": "2025-10-30T17:42:57.268417+00:00",
      "updated_at": "2025-10-30T18:21:23.015764+00:00",
      "metadata": {
        "processed_at": "2025-10-30T18:21:23.015765+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "fc7bc6dd862b31cbe580ad5f4da30838",
      "url": "http://www.jneurosci.org/cgi/content/short/45/40/etwij45402025?rss=1",
      "title": "This Week in The Journal",
      "content": "",
      "author": "McKeon, P.",
      "published_date": "2025-10-01T16:30:31+00:00",
      "source": "Journal Neuroscience This Week",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-10-30T17:42:52.780342+00:00",
      "updated_at": "2025-10-30T18:21:23.015767+00:00",
      "metadata": {
        "processed_at": "2025-10-30T18:21:23.015769+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "80d1f642eb4da0958753076107ac0cbe",
      "url": "http://daniellakens.blogspot.com/2025/07/easily-download-files-from-open-science.html",
      "title": "Easily download files from the Open Science Framework with Papercheck",
      "content": "<p>Researchers\nincreasingly use the <a href=\"https://osf.io/\">Open Science Framework</a> (OSF) to share files, such as data\nand code underlying scientific publications, or presentations and materials for\nscientific workshops. The OSF is an amazing service that has contributed\nimmensely to a changed research culture where psychologists share data, code, and\nmaterials. We are very grateful it exists.</p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">But it is\nnot always the most user-friendly. Specifically, downloading files from the OSF\nis a bigger hassle than we (<a href=\"https://debruine.github.io/\">Lisa DeBruine</a>\nand <a href=\"https://www.tue.nl/en/research/researchers/daniel-lakens/\">Daniel\nLakens</a>, the developers of Papercheck) would like it to be. Downloading individual\nfiles is so complex, <a href=\"https://bsky.app/profile/malte.the100.ci/post/3lpf4s6spns2i\">Malte Elson</a>\nrecently posted this meme on Bluesky. </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"NL\"><!--[if gte vml 1]><v:shapetype\n id=\"_x0000_t75\" coordsize=\"21600,21600\" o:spt=\"75\" o:preferrelative=\"t\"\n path=\"m@4@5l@4@11@9@11@9@5xe\" filled=\"f\" stroked=\"f\">\n <v:stroke joinstyle=\"miter\"/>\n <v:formulas>\n  <v:f eqn=\"if lineDrawn pixelLineWidth 0\"/>\n  <v:f eqn=\"sum @0 1 0\"/>\n  <v:f eqn=\"sum 0 0 @1\"/>\n  <v:f eqn=\"prod @2 1 2\"/>\n  <v:f eqn=\"prod @3 21600 pixelWidth\"/>\n  <v:f eqn=\"prod @3 21600 pixelHeight\"/>\n  <v:f eqn=\"sum @0 0 1\"/>\n  <v:f eqn=\"prod @6 1 2\"/>\n  <v:f eqn=\"prod @7 21600 pixelWidth\"/>\n  <v:f eqn=\"sum @8 21600 0\"/>\n  <v:f eqn=\"prod @7 21600 pixelHeight\"/>\n  <v:f eqn=\"sum @10 21600 0\"/>\n </v:formulas>\n <v:path o:extrusionok=\"f\" gradientshapeok=\"t\" o:connecttype=\"rect\"/>\n <o:lock v:ext=\"edit\" aspectratio=\"t\"/>\n</v:shapetype><v:shape id=\"_x0000_i1026\" type=\"#_x0000_t75\" style='width:453.75pt;\n height:276pt;visibility:visible;mso-wrap-style:square'>\n <v:imagedata src=\"file:///C:/Users/DLakens/AppData/Local/Temp/msohtmlclip1/01/clip_image001.jpg\"\n  o:title=\"\"/>\n</v:shape><![endif]--><!--[if !vml]--><img border=\"0\" height=\"368\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEinS5tFoL5qX14Z2OcgT1APMZLGlghAD3BfBhSnJ9pleVbJyRFUFLShqReS2j7SXGozmLMcVQkoM62UhneJDtH4yx3NRnXOkVZZi-Dm-OPwbGaidxr2raF9wzjx5fU92nfPpE3jmGfwZEwHS1WGSB4gUfRfV3XWjOC2-lCjOYR108h3fwORIHOnqxIX9m8\" width=\"605\" /><!--[endif]--></span><span lang=\"EN-US\"></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\"><span>&nbsp;</span></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">Not only is\nthe download button for files difficult to find, but downloading all files\nrelated to a project can be surprisingly effortful. It is possible to download\nall files in a zip folder that will be called \u2018osfstorage-archive.zip\u2019 when\ndownloaded. But as the OSF supports a nested folder structure, you might miss a\nfolder, and you will quickly end up with \u2018osfstorage-archive (1).zip\u2019, \u2018osfstorage-archive\n(2).zip\u2019, etc. Unzipping these archives creates a lot of files without the\norganized folder structure, in folders with meaningless names, making it\ndifficult to understand where files are. </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<h2 style=\"text-align: left;\"><b><span lang=\"EN-US\">The\nosf_file_download function in Papercheck </span></b></h2>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">We have added\na new function to our R package \u2018<a href=\"https://scienceverse.github.io/papercheck/\">Papercheck</a>\u2019 that will download all files and\nfolders in an OSF repository. It saves all files by recreating the folder\nstructure from the OSF in your download folder. Just install Papercheck, load\nthe library, and use the osf_file_download function to grab all files on the OSF:</span></p><p class=\"MsoNormal\"><span lang=\"EN-US\"><br /></span></p>\n\n<div style=\"text-align: left;\"><span style=\"font-family: courier;\"><b><span lang=\"EN-US\">devtools::install_github(\"scienceverse/papercheck\")<br /></span></b><b><span lang=\"EN-US\">library(papercheck)<br /></span></b><b><span lang=\"EN-US\">osf_file_download(\"6nt4v\")</span></b></span></div>\n\n\n\n\n\n<p class=\"MsoNormal\"><b><span lang=\"EN-US\">&nbsp;</span></b></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">All files\nwill be downloaded to your working directory. </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">Are you feeling\nFOMO for missing out on the <a href=\"https://www.kcl.ac.uk/events/open-research-summer-school-2025\">King Open\nResearch Summer School</a> that is going on these days, where <a href=\"https://research.tue.nl/en/persons/sajedeh-rasti\">Sajedeh Rasti</a> talked\nabout Preregistration, and <a href=\"https://research.tue.nl/en/persons/cristian-mesquida-caldentey\">Cristian\nMesquida</a> will give a workshop on using Papercheck? Well, at least it is\nvery easy to download all the files they have shared on the OSF and look at the\npresentations: </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\"><span style=\"font-family: courier;\">osf_file_download(\"b7es8\")</span></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">In the\noutput, we see that by default large files (more than 10mb) are omitted. <span><!--[if gte vml 1]><v:shape id=\"Picture_x0020_1\"\n o:spid=\"_x0000_i1025\" type=\"#_x0000_t75\" alt=\"A screenshot of a computer&#10;&#10;AI-generated content may be incorrect.\"\n style='width:453.75pt;height:292.5pt;visibility:visible;mso-wrap-style:square'>\n <v:imagedata src=\"file:///C:/Users/DLakens/AppData/Local/Temp/msohtmlclip1/01/clip_image003.png\"\n  o:title=\"A screenshot of a computer&#10;&#10;AI-generated content may be incorrect\"/>\n</v:shape><![endif]--><!--[if !vml]--><img alt=\"A screenshot of a computer\n\nAI-generated content may be incorrect.\" border=\"0\" height=\"390\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEj2jH76ywmEeLzL43u6gJl7GKR2lEGlhYS0LOXRPMMovOsJEVdXyamYCvmq96ez3p_GXHLoFz4JDyAKHlARK9pSy8QfzVa7yt1_uEg_H9IJfKgunnYWUwlROXABNcU6TvrA0_hx0KPZfj00b3Cb-Wn_7Bf3sFu9JApZoClcWoh_Vfl5bk1GQVZUH1tuGao\" width=\"605\" /><!--[endif]--></span></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">If you want\nto download all files, regardless of the size, then set the parameter to ignore\nthe maximum file size: </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\"><span style=\"font-family: courier;\">osf_file_download(\"b7es8\",\nmax_file_size = NULL)</span></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">Sometimes\nyou might want to download all files but ignore the file structure on the OSF,\nto just have all the files in one folder. Setting the parameter ignore_folder_structure\n= TRUE will give you all the files on the OSF in a single folder. By default, files will be downloaded into your working directory, but you can also specify\nwhere you want the files to be saved. </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\"><span style=\"font-family: courier;\">osf_file_download(\"6nt4v\",\nignore_folder_structure = TRUE, download_to = \"C:\\\\test_download\")</span></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">We hope\nthis function will make it easier for reviewers to access all supplementary\nfiles stored on the OSF during peer review, and for researchers who want to re-use\ndata, code, or materials shared on the OSF by downloading all the files they\nneed easily. Make sure to install the latest version of Papercheck (0.0.0.9050)\nto get access to this new function. Papercheck is still in active development,\nso report any bugs on <a href=\"https://github.com/scienceverse/papercheck\">GitHub</a>.</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>",
      "author": "noreply@blogger.com (Daniel Lakens)",
      "published_date": "2025-07-22T09:53:00+00:00",
      "source": "Twenty Percent Statistician",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 765,
      "reading_time": 3,
      "created_at": "2025-10-30T15:45:48.966496+00:00",
      "updated_at": "2025-10-30T16:19:33.392617+00:00",
      "metadata": {
        "processed_at": "2025-10-30T16:19:33.392627+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "5cf06dd1c8477abb17ef4e5c3b5426e0",
      "url": "https://erpinfo.org/blog/2021/12/22/applications-2023",
      "title": "Applications now being accepted for UC-Davis/SDSU ERP Boot Camp, July 31 \u2013 August 9, 2023",
      "content": "<p class=\"\">The next 10-day ERP Boot Camp will be held July 31 \u2013 August 9, 2023 in San Diego, California. We are now taking applications, which will be due by April 1, 2023. <a href=\"https://erpinfo.org/summer-boot-camp\">Click here</a> for more information.</p><p class=\"\">We are currently planning to hold this workshop as an in-person event. However, these plans are subject to change as the COVID-19 pandemic evolves. If the event is held in person, we will require that everyone is fully vaccinated, and we will also implement any other safety measures that are warranted at the time of the workshop.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"980\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/1609175691205-RTD3XM69YGOFMVP23U6T/Boot_Camp_Logo.png?format=1000w\" width=\"1148\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>",
      "author": "Steve Luck",
      "published_date": "2023-01-16T18:31:57+00:00",
      "source": "Erp Boot Camp",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 108,
      "reading_time": 1,
      "created_at": "2025-10-30T15:45:46.138219+00:00",
      "updated_at": "2025-10-30T16:19:33.392633+00:00",
      "metadata": {
        "processed_at": "2025-10-30T16:19:33.392635+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "bd7398ecbbd90ecd3269866b2fd3744f",
      "url": "https://erpinfo.org/blog/2023/6/23/decoding-webinar",
      "title": "ERP Decoding for Everyone: Software and Webinar",
      "content": "<p class=\"\"><strong>You can access the recording </strong><a href=\"https://video.ucdavis.edu/media/Virtual+ERP+Boot+CampA+Decoding+for+Everyone%2C+July+25+2023/1_lmwj6bu0\"><strong>here</strong></a><strong>.<br />You can access the final PDF of the slides </strong><a href=\"https://ucdavis.box.com/s/flf9gzeo12rz2jhxptih7xjl0omka2k7\"><strong>here</strong></a><strong>. <br />You can access the data </strong><a href=\"https://doi.org/10.18115/D5KS6S\"><strong>here</strong></a><strong>.</strong></p><p class=\"\">fMRI research has used decoding methods for over 20 years. These methods make it possible to decode what an individual is perceiving or holding in working memory on the basis of the pattern of BOLD activity across voxels. Remarkably, these methods can also be applied to ERP data, using the pattern of voltage across electrode sites rather than the pattern of activity across voxels to decode the information being represented by the brain (<a href=\"https://erpinfo.org/blog/2018/9/16/decoding\">see this previous blog post</a>). For example, ERPs can be used to decode the identity of a face that is being perceived, the emotional valence of a scene, the identity and semantic category of a word, and the features of an object that is being maintained in working memory. Moreover, decoding methods can be more sensitive than traditional methods for detecting conventional ERP effects (e.g., whether a word is semantically related or unrelated to a previous word in an N400 paradigm).</p><p class=\"\">So far, these methods have mainly been used by a small set of experts. We aim to change that with the upcoming Version 10 of <a href=\"https://erpinfo.org/erplab\">ERPLAB Toolbox</a>. This version of ERPLAB will contain an ERP decoding tool that makes it trivially easy for anyone who knows how to do conventional ERP processing to take advantage of the power of decoding. It should be available in mid-July at <a href=\"https://github.com/ucdavis/erplab/releases\">our GitHub site</a>. You can join the <a href=\"https://github.com/ucdavis/erplab/wiki/ERPLAB-email-list\">ERPLAB email list</a> to receive an announcement when this version is released. Please do not contact us with questions until it has been released and you have tried using it.</p><p class=\"\">On July 25, 2023, we will hold a 2-hour Zoom webinar to explain how decoding works at a conceptual level and show how to implement in ERPLAB Toolbox. The webinar will begin at 9:00 AM Pacific Time (California), 12:00 PM Eastern Time (New York), 5:00 PM British Summer Time (London), 6:00 PM Central European Summer Time (Berlin). </p><p class=\"\">The webinar is co-sponsored by the <a href=\"https://erpinfo.org/the-erp-boot-camp\">ERP Boot Camp</a> and the <a href=\"https://sprweb.org\">Society for Psychophysiological Research</a>. It is completely free, but you must register in advance at <a href=\"https://ucdavis.zoom.us/meeting/register/tJUrc-CtpzorEtBSmZXJINOlLJB9ZR0evpr4\">https://ucdavis.zoom.us/meeting/register/tJUrc-CtpzorEtBSmZXJINOlLJB9ZR0evpr4</a>. Once you register, you will receive an email with your own individual Zoom link. </p><p class=\"\">We will make a recording available a few days after the webinar on the <a href=\"https://erpinfo.org\">ERPinfo.org</a> web site.</p><p class=\"\">Please direct any questions about the webinar to <a href=\"mailto:erpbootcamp@gmail.com\">erpbootcamp@gmail.com</a>.</p>",
      "author": "Steve Luck",
      "published_date": "2023-06-23T21:05:26+00:00",
      "source": "Erp Boot Camp",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 420,
      "reading_time": 2,
      "created_at": "2025-10-30T15:45:46.138193+00:00",
      "updated_at": "2025-10-30T16:19:33.392637+00:00",
      "metadata": {
        "processed_at": "2025-10-30T16:19:33.392639+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "3d370217cb4a351bb54e7854066e15c3",
      "url": "https://erpinfo.org/blog/2024/2/4/optimal-filters",
      "title": "New Papers: Optimal Filter Settings for ERP Research",
      "content": "<p class=\"\">Zhang, G., Garrett, D. R., &amp; Luck, S. J. (in press). Optimal filters for ERP research I: A general approach for selecting filter settings. <em>Psychophysiology</em>. <a href=\"https://doi.org/10.1111/psyp.14531\"><span>https://doi.org/10.1111/psyp.14531</span></a> [<a href=\"https://www.researchgate.net/publication/377773270_Optimal_filters_for_ERP_research_I_A_general_approach_for_selecting_filter_settings\"><span>preprint</span></a>]</p><p class=\"\">Zhang, G., Garrett, D. R., &amp; Luck, S. J. (in press). Optimal filters for ERP research II: Recommended settings for seven common ERP components. <em>Psychophysiology</em>. <a href=\"https://doi.org/10.1111/psyp.14530\"><span>https://doi.org/10.1111/psyp.14530</span></a> [<a href=\"https://www.researchgate.net/publication/377766656_Optimal_filters_for_ERP_research_II_Recommended_settings_for_seven_common_ERP_components\"><span>preprint</span></a>]</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1490\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/d64086cc-e3b4-457d-89df-08d9b3f96439/Filter_Table.png?format=1000w\" width=\"2062\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">What filter settings should you apply to your ERP data? If your filters are too weak to attenuate the noise in your data, your effects may not be statistically significant. If your filters are too strong, they may create artifactual peaks that lead you to draw bogus conclusions.</p><p class=\"\">For years, I have been recommending a bandpass of 0.1\u201330 Hz for most cognitive and affective research in neurotypical young adults. In this kind of research, I have found that filtering from 0.1\u201330 Hz usually does a good job of minimizing noise while creating minimal waveform distortion. </p><p class=\"\">However, this recommendation was based on a combination of informal observations from many experimental paradigms and a careful examination of a couple paradigms, so it was a bit hand-wavy. In addition, the optimal filter settings will depend on the waveshape of the ERP effects and the nature of the noise in a given study, so I couldn\u2019t make any specific recommendations about other experimental paradigms and participant populations. Moreover, different filter settings may be optimal for different scoring methods (e.g., mean amplitude vs. peak amplitude vs. peak latency).</p><p class=\"\">Guanghui Zhang, David Garrett, and I spent the last year focusing on this issue. First we developed a general method that can be used to determine the optimal filter settings for a given dataset and scoring method (see <a href=\"https://doi.org/10.1111/psyp.14531\"><span>this paper</span></a>). Then we applied this method to the <a href=\"https://doi.org/10.1016/j.neuroimage.2020.117465\"><span>ERP CORE</span></a> data to determine the optimal filter settings for the N170, MMN, P3b, N400, N2pc, LRP, and ERN components in neurotypical young adults (see <a href=\"https://doi.org/10.1111/psyp.14530\"><span>this paper</span></a> and the table above).</p><p class=\"\">If you are doing research with these components (or similar components) in neurotypical young adults, you can simply use the filter settings that we identified. If you are using a very different paradigm or testing a very different subject population, you can apply our method to your own data to find the optimal settings. We added some new tools to <a href=\"https://github.com/ucdavis/erplab\"><span>ERPLAB Toolbox</span></a> to make this easier.</p><p class=\"\">One thing that we discovered was that our old recommendation of 0.1\u201330 Hz does a good job of avoiding filter artifacts but is overly conservative for some components. For example, we can raise the low end to 0.5 Hz when measuring N2pc and MMN amplitudes, which gets rid of more noise without producing problematic waveform distortions. And we can go all the way up to 0.9 Hz for the N170 component. However, later/slower components like P3b and N400 require lower cutoffs (no higher than 0.2 Hz).</p><p class=\"\">You might be wondering how we defined the \u201coptimal\u201d filter settings. At one level, the answer is simple: The optimal filter is the one that maximizes the signal-to-noise ratio without producing too much waveform distortion. The complexities arise in quantifying the signal-to-noise ratio, quantifying the waveform distortion, and deciding how much waveform distortion is \u201ctoo much\u201d. We believe we have found reasonably straightforward and practical solutions to these problems, which you can read about in the published papers.</p>",
      "author": "Steve Luck",
      "published_date": "2024-02-04T23:46:20+00:00",
      "source": "Erp Boot Camp",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 568,
      "reading_time": 2,
      "created_at": "2025-10-30T15:45:46.138144+00:00",
      "updated_at": "2025-10-30T16:19:33.392641+00:00",
      "metadata": {
        "processed_at": "2025-10-30T16:19:33.392643+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "f87e190d517408c7e19116ef6aed8544",
      "url": "https://brain.ieee.org/publications/neuroethics-framework/education/education-legal-issues/education-legal-issues/",
      "title": "Education: Legal Issues",
      "content": "The safety concerns and standards shared in other sections provide an initial foundation for legal protections. However, calls for stricter consumer protection laws must accompany the proliferation of neurotech devices. Special privacy laws must be promulgated to ensure \u201ccognitive privacy\u201d (Nita Farahany, 2012, 2023) [25]\u00a0 and educational autonomy. Raw brain data is uniquely sensitive, and an individual&#8217;s brain pattern may ...",
      "author": "Adriel Carridice",
      "published_date": "2025-02-05T15:33:45+00:00",
      "source": "Brain",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 61,
      "reading_time": 1,
      "created_at": "2025-10-30T15:45:43.619874+00:00",
      "updated_at": "2025-10-30T16:19:33.392645+00:00",
      "metadata": {
        "processed_at": "2025-10-30T16:19:33.392646+00:00",
        "processing_method": "github_actions"
      }
    }
  ]
}