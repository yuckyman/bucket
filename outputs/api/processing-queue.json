{
  "last_updated": "2025-10-01T12:31:15.579288+00:00",
  "pending_count": 985,
  "processed_count": 15,
  "pending_articles": [
    {
      "id": "6071ce99ab68021ed48d4600bdeec843",
      "url": "http://ieeexplore.ieee.org/document/10856214",
      "title": "Table of Contents",
      "content": "null",
      "author": "",
      "published_date": "2025-01-28T13:17:19+00:00",
      "source": "Reviews Biomedical Engineering",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 1,
      "reading_time": 1,
      "created_at": "2025-10-01T11:38:58.985112+00:00",
      "updated_at": "2025-10-01T11:38:58.985113+00:00"
    },
    {
      "id": "f18dbf7099a24df1b7e9875d0258e8eb",
      "url": "http://ieeexplore.ieee.org/document/10856213",
      "title": "IEEE Engineering in Medicine and Biology Society",
      "content": "null",
      "author": "",
      "published_date": "2025-01-28T13:17:20+00:00",
      "source": "Reviews Biomedical Engineering",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 1,
      "reading_time": 1,
      "created_at": "2025-10-01T11:38:58.985093+00:00",
      "updated_at": "2025-10-01T11:38:58.985094+00:00"
    },
    {
      "id": "9b7968741403d6b479424052728c8879",
      "url": "http://ieeexplore.ieee.org/document/10856260",
      "title": "Front Cover",
      "content": "null",
      "author": "",
      "published_date": "2025-01-28T13:17:19+00:00",
      "source": "Reviews Biomedical Engineering",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 1,
      "reading_time": 1,
      "created_at": "2025-10-01T11:38:58.985068+00:00",
      "updated_at": "2025-10-01T11:38:58.985072+00:00"
    },
    {
      "id": "62b33c8c35269d32a56b51c7891f8cd1",
      "url": "http://ieeexplore.ieee.org/document/11153361",
      "title": "Electroencephalographic Functional Connectivity, Heartrate Synchrony, and Eye Movements Reveal Distinct Components within Narrative Engagement and Immersion",
      "content": "Storytelling is a fundamental and universal human behavior, representing a vehicle for cultural information exchange throughout human history. In the present day, consumption of narrative audiovisual media is one of the most common recreational activities worldwide. Despite the importance and ubiquity of storytelling, relatively little is known about the neurocognitive mechanisms by which narrative media capture and sustain our attention. In this study, 40 participants watched 10 short clips from television shows of various genres while electroencephalography, eye tracking, heart rate, and self-report data were recorded. Self-reported immersion and three of the four components of narrative engagement that we examined\u2014attentional focus, emotional engagement, and narrative presence\u2014were associated with interindividual synchrony in heart rate and gaze behavior, but were associated with relatively distinct patterns of neural activity (electroencephalography power amplitude and functional connectivity). Narrative understanding, on the other hand, was not associated with heart rate or gaze synchrony. Furthermore, structural equation modeling revealed directionally opposing relationships between overall alpha-band connectivity and narrative presence on the one hand (positive), and narrative understanding (negative) on the other. These results suggest narrative understanding may be associated with a different set of neurocognitive processes to the other dimensions of narrative engagement. These findings point toward a bifurcated model of narrative engagement and raise interesting theoretical questions about the role of narrative comprehension in this process.",
      "author": "",
      "published_date": "2025-09-08T13:16:44+00:00",
      "source": "Cognitive Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 220,
      "reading_time": 1,
      "created_at": "2025-10-01T11:38:57.911754+00:00",
      "updated_at": "2025-10-01T11:38:57.911755+00:00"
    },
    {
      "id": "d50017c01d1cea4b149c811378d33224",
      "url": "http://ieeexplore.ieee.org/document/11153352",
      "title": "Object Ownership Processing in Peripersonal Space: An Electroencephalographic Study",
      "content": "A fundamental aspect of interacting with objects in the environment is the ability to distinguish between objects that can be directly acted upon in the peripersonal space (PPS) and those out of immediate reach in the extrapersonal space (EPS). Performing appropriate actions also requires integrating social conceptual information related to who owns a particular object. While prior research has demonstrated that spatial and social factors influence object processing, how these factors are integrated is not yet fully understood. To address this issue, the present study explored the neurophysiological correlates of object ownership processing when objects were located in either the PPS or EPS. Facing a virtual character, 28 participants estimated the reachability of self-owned or other-owned objects, placed at different distances. The analysis confirmed that self-owned objects are processed faster when located in PPS, and other-owned objects are processed faster when located in EPS. EEG signals analysis revealed that early ERP components, such as the N1 and anterior N2, were modulated solely by objects' spatial location. In contrast, later components, including the P3 and anterior N400, were influenced by object ownership, although depending on object's location in space. These results suggest an early perceptual prioritization of objects in the PPS and a prioritization of objects that engages the self at a postperceptual stage. Overall, the findings provide new insights into how objects are processed depending on their spatial and social properties, and confirm that virtual reality represents a promising tool to probe neural mechanisms supporting perception and action in social contexts.",
      "author": "",
      "published_date": "2025-09-08T13:16:40+00:00",
      "source": "Cognitive Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 251,
      "reading_time": 1,
      "created_at": "2025-10-01T11:38:57.911715+00:00",
      "updated_at": "2025-10-01T11:38:57.911716+00:00"
    },
    {
      "id": "0935313f19774a2f7dddae3f96606656",
      "url": "http://ieeexplore.ieee.org/document/11153355",
      "title": "Neural Signatures of Recollection Are Sensitive to Memory Quality and Specific Event Features",
      "content": "Episodic memories reflect a bound representation of multimodal features that can be recollected with varying levels of precision. Recent fMRI investigations have demonstrated that the precision and content of information retrieved from memory engage a network of posterior medial-temporal and parietal regions co-activated with the hippocampus. Yet, comparatively, little is known about how memory content and precision affect common neural signatures of memory captured by EEG, where recollection has been associated with changes in ERP and oscillatory measures of neural activity. Here, we used a multifeature paradigm previously reported [Cooper, R. A., & Ritchey, M. Cortico-hippocampal network connections support the multidimensional quality of episodic memory. eLife, 8, e45591, 2019] with continuous measures of memory, in conjunction with scalp EEG, to characterize the content and quality of information that drives ERP and oscillatory markers of episodic memory. A common signature of memory retrieval in the left posterior regions, called the late positive component, was sensitive to overall memory quality and also to precision of recollection for spatial features. The analysis of oscillatory markers during recollection revealed that alpha/beta desynchronization was modulated by overall memory quality and also by individual features in memory. Importantly, we found evidence of a relationship between these two neural markers of memory retrieval, suggesting that they may represent complementary aspects of the recollection experience. These findings demonstrate how time-sensitive and dynamic processes identified with EEG correspond to overall episodic recollection and also to the retrieval of precise features in memory.",
      "author": "",
      "published_date": "2025-09-08T13:16:44+00:00",
      "source": "Cognitive Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 243,
      "reading_time": 1,
      "created_at": "2025-10-01T11:38:57.911678+00:00",
      "updated_at": "2025-10-01T11:38:57.911680+00:00"
    },
    {
      "id": "9fe9c99db697786e3f69c006b914b51d",
      "url": "http://ieeexplore.ieee.org/document/11153362",
      "title": "Transient and Sustained Neuromagnetic Representation of Consonance and Dissonance in Harmonic Sequences",
      "content": "The perception of musical consonance/dissonance (C/D) relies on basic properties of the auditory system, and prior investigations have shown that C/D sounds elicit strongly divergent neurophysiological activity in human auditory cortex. However, studies are missing that assess transient (P1, N1, P2) and sustained cortical C/D representations within a harmonic context, together with the corresponding patterns of neural adaptation. The present magnetoencephalography experiment applied spatio-temporal source analysis to study the early transient and sustained neuromagnetic processing of C/D at the start and within brief harmonic sequences. A total of n = 40 adult listeners (among them numerous amateur musicians) participated in the experiment; the harmonic sequences comprised different blends of C/D dyads with balanced probabilities, in an effort to access simple C/D relations and neural adaptation at an early stage of the processing hierarchy. Consistent with earlier findings, the transient cortical activity was found to reflect vertical (i.e., absolute) C/D aspects in response to the sequence's first dyad, but it mirrored more horizontal aspects (i.e., C/D relations) at the subsequent dyad transitions; moreover, the neuromagnetic responses (particularly, the N1 and P2 waves) exhibited adaptation with different time constants, parts of which pertained to C/D-associated processing. Surprisingly, only few observations appeared to be influenced by the listener's musical expertise, likely due to the high overall level of musicality in our sample. In summary, our data indicate that early neuromagnetic activity reflects not only vertical, but also horizontal, aspects of C/D perception, together with corresponding adaptive mechanisms.",
      "author": "",
      "published_date": "2025-09-08T13:16:44+00:00",
      "source": "Cognitive Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 244,
      "reading_time": 1,
      "created_at": "2025-10-01T11:38:57.911641+00:00",
      "updated_at": "2025-10-01T11:38:57.911643+00:00"
    },
    {
      "id": "e13a1cf054e27d1dbec2cc16b386b9a8",
      "url": "https://www.frontiersin.org/articles/10.3389/fnhum.2025.1647425",
      "title": "Hormonal contraceptive use is associated with reduced central serotonergic activity indexed by the loudness dependence of auditory evoked potentials",
      "content": "ObjectiveHormonal contraceptives (HCs) are linked to mood disturbances, but the neurobiological mechanisms remain unclear. This study investigated whether HC use is associated with altered central serotonergic activity, using the loudness dependence of auditory evoked potentials (LDAEP).MethodsFifty-four healthy women (30 current HC users and 24 non-users) completed EEG recordings to assess LDAEP. Depressive symptoms were quantified using the Beck Depression Inventory-II. Between-group analyses were controlled for age and depressive symptoms, and effects of menstrual cycle phase, HC type, and mood-related side effects were also examined.ResultsHC users showed significantly steeper LDAEP slopes than non-users across components (all p\u202f\u2264\u202f0.028) consistent with reduced central serotonergic activity. This remained significant controlling for age and depressive symptoms. No significant effects of menstrual cycle phase or HC type, but HC users reporting adverse mood effects had more somatic symptoms, without corresponding LDAEP differences.ConclusionThis study is, to our knowledge, among the first to explicitly test an a priori hypothesis that HC use is associated with reduced serotonergic activity indexed by LDAEP in healthy women, and shows that HC use is linked to attenuated central serotonergic activity independent of mood symptoms. These findings underscore the role of sex hormones in shaping serotonergic function and may explain individual variability in mood and antidepressant response.",
      "author": "Stein Andersson",
      "published_date": "2025-10-01T00:00:00+00:00",
      "source": "Frontiers Human Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 206,
      "reading_time": 1,
      "created_at": "2025-10-01T11:38:34.660189+00:00",
      "updated_at": "2025-10-01T11:38:34.660194+00:00"
    },
    {
      "id": "2d4ad511868aac441832da177922b729",
      "url": "https://www.frontiersin.org/articles/10.3389/fnbot.2025.1625074",
      "title": "4D trajectory prediction for inbound flights",
      "content": "IntroductionTo address the challenges of cumulative errors, insufficient modeling of complex spatiotemporal features, and limitations in computational efficiency and generalization ability in 4D trajectory prediction, this paper proposes a high-precision, robust prediction method.MethodsA hybrid model SVMD-DBO-RCBAM is constructed, integrating sequential variational modal decomposition (SVMD), the dung beetle optimization algorithm (DBO), and the ResNet-CBAM network. Innovations include frequency-domain feature decoupling, dynamic parameter optimization, and enhanced spatio-temporal feature focusing.ResultsExperiments show that the model achieves a low longitude MAE of 0.0377 in single-step prediction, a 38.5% reduction compared to the baseline model; in multi-step prediction, the longitude R2 reaches 0.9844, with a 72.9% reduction in cumulative error rate and an IQR of prediction errors less than 10% of traditional models, demonstrating high accuracy and stability.DiscussionExperiments show that the model achieves a low longitude MAE of 0.0377 in single-step prediction, a 38.5% reduction compared to the baseline model; in multi-step prediction, the longitude R2 reaches 0.9844, with a 72.9% reduction in cumulative error rate and an IQR of prediction errors less than 10% of traditional models, demonstrating high accuracy and stability.",
      "author": "Jie Dai",
      "published_date": "2025-09-17T00:00:00+00:00",
      "source": "Frontiers Neurorobotics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 177,
      "reading_time": 1,
      "created_at": "2025-10-01T11:38:33.226797+00:00",
      "updated_at": "2025-10-01T11:38:33.226799+00:00"
    },
    {
      "id": "eebd87c54d84d3574ddacffd8d1965b5",
      "url": "https://www.frontiersin.org/articles/10.3389/fnbot.2025.1675642",
      "title": "Correction: Pre-training, personalization, and self-calibration: all a neural network-based myoelectric decoder needs",
      "content": "",
      "author": "Kianoush Nazarpour",
      "published_date": "2025-09-19T00:00:00+00:00",
      "source": "Frontiers Neurorobotics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-10-01T11:38:33.226765+00:00",
      "updated_at": "2025-10-01T11:38:33.226767+00:00"
    }
  ],
  "recently_processed": [
    {
      "id": "f3ebee0a159c29e785b8640ab568613e",
      "url": "http://ieeexplore.ieee.org/document/10729663",
      "title": "Data- and Physics-Driven Deep Learning Based Reconstruction for Fast MRI: Fundamentals and Methodologies",
      "content": "Magnetic Resonance Imaging (MRI) is a pivotal clinical diagnostic tool, yet its extended scanning times often compromise patient comfort and image quality, especially in volumetric, temporal and quantitative scans. This review elucidates recent advances in MRI acceleration via data and physics-driven models, leveraging techniques from algorithm unrolling models, enhancement-based methods, and plug-and-play models to the emerging full spectrum of generative model-based methods. We also explore the synergistic integration of data models with physics-based insights, encompassing the advancements in multi-coil hardware accelerations like parallel imaging and simultaneous multi-slice imaging, and the optimization of sampling patterns. We then focus on domain-specific challenges and opportunities, including image redundancy exploitation, image integrity, evaluation metrics, data heterogeneity, and model generalization. This work also discusses potential solutions and future research directions, with an emphasis on the role of data harmonization and federated learning for further improving the general applicability and performance of these methods in MRI reconstruction.",
      "author": "",
      "published_date": "2024-10-22T13:18:56+00:00",
      "source": "Reviews Biomedical Engineering",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 151,
      "reading_time": 1,
      "created_at": "2025-10-01T11:38:58.985286+00:00",
      "updated_at": "2025-10-01T12:31:15.475019+00:00",
      "metadata": {
        "processed_at": "2025-10-01T12:31:15.475029+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "b71ad97ebddb2087936b4010c1aaf456",
      "url": "http://ieeexplore.ieee.org/document/10746601",
      "title": "Artificial General Intelligence for Medical Imaging Analysis",
      "content": "Large-scale Artificial General Intelligence (AGI) models, including Large Language Models (LLMs) such as ChatGPT/GPT-4, have achieved unprecedented success in a variety of general domain tasks. Yet, when applied directly to specialized domains like medical imaging, which require in-depth expertise, these models face notable challenges arising from the medical field's inherent complexities and unique characteristics. In this review, we delve into the potential applications of AGI models in medical imaging and healthcare, with a primary focus on LLMs, Large Vision Models, and Large Multimodal Models. We provide a thorough overview of the key features and enabling techniques of LLMs and AGI, and further examine the roadmaps guiding the evolution and implementation of AGI models in the medical sector, summarizing their present applications, potentialities, and associated challenges. In addition, we highlight potential future research directions, offering a holistic view on upcoming ventures. This comprehensive review aims to offer insights into the future implications of AGI in medical imaging, healthcare, and beyond.",
      "author": "",
      "published_date": "2024-11-07T13:17:37+00:00",
      "source": "Reviews Biomedical Engineering",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 159,
      "reading_time": 1,
      "created_at": "2025-10-01T11:38:58.985239+00:00",
      "updated_at": "2025-10-01T12:31:15.475033+00:00",
      "metadata": {
        "processed_at": "2025-10-01T12:31:15.475035+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "3970a7e47edc49703b34feadbd5d1dab",
      "url": "http://ieeexplore.ieee.org/document/10720187",
      "title": "Exhaled Breath Analysis: From Laboratory Test to Wearable Sensing",
      "content": "Breath analysis and monitoring have emerged as pivotal components in both clinical research and daily health management, particularly in addressing the global health challenges posed by respiratory and metabolic disorders. The advancement of breath analysis strategies necessitates a multidisciplinary approach, seamlessly integrating expertise from medicine, biology, engineering, and materials science. Recent innovations in laboratory methodologies and wearable sensing technologies have ushered in an era of precise, real-time, and in situ breath analysis and monitoring. This comprehensive review elucidates the physical and chemical aspects of breath analysis, encompassing respiratory parameters and both volatile and non-volatile constituents. It emphasizes their physiological and clinical significance, while also exploring cutting-edge laboratory testing techniques and state-of-the-art wearable devices. Furthermore, the review delves into the application of sophisticated data processing technologies in the burgeoning field of breathomics and examines the potential of breath control in human-machine interaction paradigms. Additionally, it provides insights into the challenges of translating innovative laboratory and wearable concepts into mainstream clinical and daily practice. Continued innovation and interdisciplinary collaboration will drive progress in breath analysis, potentially revolutionizing personalized medicine through entirely non-invasive breath methodology.",
      "author": "",
      "published_date": "2024-10-16T13:15:55+00:00",
      "source": "Reviews Biomedical Engineering",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 182,
      "reading_time": 1,
      "created_at": "2025-10-01T11:38:58.985208+00:00",
      "updated_at": "2025-10-01T12:31:15.475053+00:00",
      "metadata": {
        "processed_at": "2025-10-01T12:31:15.475054+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "483769689d304d6940ab358e0b085a8c",
      "url": "http://ieeexplore.ieee.org/document/10771694",
      "title": "Earable Multimodal Sensing and Stimulation: A Prospective Toward Unobtrusive Closed-Loop Biofeedback",
      "content": "The human ear has emerged as a bidirectional gateway to the brain's and body's signals. Recent advances in around-the-ear and in-ear sensors have enabled the assessment of biomarkers and physiomarkers derived from brain and cardiac activity using ear-electroencephalography (ear-EEG), photoplethysmography (ear-PPG), and chemical sensing of analytes from the ear, with ear-EEG having been taken beyond-the-lab to outer space. Parallel advances in non-invasive and minimally invasive brain stimulation techniques have leveraged the ear's access to two cranial nerves to modulate brain and body activity. The vestibulocochlear nerve stimulates the auditory cortex and limbic system with sound, while the auricular branch of the vagus nerve indirectly but significantly couples to the autonomic nervous system and cardiac output. Acoustic and current mode stimuli delivered using discreet and unobtrusive earables are an active area of research, aiming to make biofeedback and bioelectronic medicine deliverable outside of the clinic, with remote and continuous monitoring of therapeutic responsivity and long-term adaptation. Leveraging recent advances in ear-EEG, transcutaneous auricular vagus nerve stimulation (taVNS), and unobtrusive acoustic stimulation, we review accumulating evidence that combines their potential into an integrated earable platform for closed-loop multimodal sensing and neuromodulation, towards personalized and holistic therapies that are near, in- and around-the-ear.",
      "author": "",
      "published_date": "2024-11-29T13:16:54+00:00",
      "source": "Reviews Biomedical Engineering",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 200,
      "reading_time": 1,
      "created_at": "2025-10-01T11:38:58.985172+00:00",
      "updated_at": "2025-10-01T12:31:15.475057+00:00",
      "metadata": {
        "processed_at": "2025-10-01T12:31:15.475058+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "1d8d5e8cf0c2514bbeb45a8e0b9c28f5",
      "url": "http://ieeexplore.ieee.org/document/10856220",
      "title": "Editorial: Harnessing Reviews to Advance Biomedical Engineering's New Horizons",
      "content": "null",
      "author": "",
      "published_date": "2025-01-28T13:17:19+00:00",
      "source": "Reviews Biomedical Engineering",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 1,
      "reading_time": 1,
      "created_at": "2025-10-01T11:38:58.985131+00:00",
      "updated_at": "2025-10-01T12:31:15.475060+00:00",
      "metadata": {
        "processed_at": "2025-10-01T12:31:15.475062+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "4f503efc209479f9b870bfb5bde19f97",
      "url": "https://arxiv.org/abs/2509.25537",
      "title": "Healthy Lifestyles and Self-Improvement Videos on YouTube: A Thematic Analysis of Teen-Targeted Social Media Content",
      "content": "arXiv:2509.25537v1 Announce Type: new \nAbstract: As teenagers increasingly turn to social media for health-related information, understanding the values of teen-targeted content has become important. Although videos on healthy lifestyles and self-improvement are gaining popularity on social media platforms like YouTube, little is known about how these videos benefit and engage with teenage viewers. To address this, we conducted a thematic analysis of 44 YouTube videos and 66,901 comments. We found that these videos provide various advice on teenagers' common challenges, use engaging narratives for authenticity, and foster teen-centered communities through comments. However, a few videos also gave misleading advice to adolescents that can be potentially harmful. Based on our findings, we discuss design implications for creating relatable and intriguing social media content for adolescents. Additionally, we suggest ways for social media platforms to promote healthier and safer experiences for teenagers.",
      "author": "Kyuha Jung, Tyler Kim, Yunan Chen",
      "published_date": "2025-10-01T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 140,
      "reading_time": 1,
      "created_at": "2025-10-01T09:42:28.747203+00:00",
      "updated_at": "2025-10-01T10:15:53.564317+00:00",
      "metadata": {
        "processed_at": "2025-10-01T10:15:53.564326+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "ba103cc111df09142bb2ce13dfcbc549",
      "url": "https://arxiv.org/abs/2509.25513",
      "title": "User Prompting Strategies and ChatGPT Contextual Adaptation Shape Conversational Information-Seeking Experiences",
      "content": "arXiv:2509.25513v1 Announce Type: new \nAbstract: Conversational AI, such as ChatGPT, is increasingly used for information seeking. However, little is known about how ordinary users actually prompt and how ChatGPT adapts its responses in real-world conversational information seeking (CIS). In this study, a nationally representative sample of 937 U.S. adults engaged in multi-turn CIS with ChatGPT on both controversial and non-controversial topics across science, health, and policy contexts. We analyzed both user prompting strategies and the communication styles of ChatGPT responses. The findings revealed behavioral signals of digital divide: only 19.1% of users employed prompting strategies, and these users were disproportionately more educated and Democrat-leaning. Further, ChatGPT demonstrated contextual adaptation: responses to controversial topics contain more cognitive complexity and more external references than to non-controversial topics. Notably, cognitively complex responses were perceived as less favorable but produced more positive issue-relevant attitudes. This study highlights disparities in user prompting behaviors and shows how user prompts and AI responses together shape information-seeking with conversational AI.",
      "author": "Haoning Xue, Yoo Jung Oh, Xinyi Zhou, Xinyu Zhang, Berit Oxley",
      "published_date": "2025-10-01T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 162,
      "reading_time": 1,
      "created_at": "2025-10-01T09:42:28.747175+00:00",
      "updated_at": "2025-10-01T10:15:53.564330+00:00",
      "metadata": {
        "processed_at": "2025-10-01T10:15:53.564332+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "12518e6b2b2e986bef078011dbe9c579",
      "url": "https://arxiv.org/abs/2509.25504",
      "title": "XR Blocks: Accelerating Human-centered AI + XR Innovation",
      "content": "arXiv:2509.25504v1 Announce Type: new \nAbstract: We are on the cusp where Artificial Intelligence (AI) and Extended Reality (XR) are converging to unlock new paradigms of interactive computing. However, a significant gap exists between the ecosystems of these two fields: while AI research and development is accelerated by mature frameworks like JAX and benchmarks like LMArena, prototyping novel AI-driven XR interactions remains a high-friction process, often requiring practitioners to manually integrate disparate, low-level systems for perception, rendering, and interaction. To bridge this gap, we present XR Blocks, a cross-platform framework designed to accelerate human-centered AI + XR innovation. XR Blocks strives to provide a modular architecture with plug-and-play components for core abstraction in AI + XR: user, world, peers; interface, context, and agents. Crucially, it is designed with the mission of \"reducing frictions from idea to reality\", thus accelerating rapid prototyping of AI + XR apps. Built upon accessible technologies (WebXR, three.js, TensorFlow, Gemini), our toolkit lowers the barrier to entry for XR creators. We demonstrate its utility through a set of open-source templates, samples, and advanced demos, empowering the community to quickly move from concept to interactive XR prototype. Site: https://xrblocks.github.io",
      "author": "David Li, Nels Numan, Xun Qian, Yanhe Chen, Zhongyi Zhou, Evgenii Alekseev, Geonsun Lee, Alex Cooper, Min Xia, Scott Chung, Jeremy Nelson, Xiuxiu Yuan, Jolica Dias, Tim Bettridge, Benjamin Hersh, Michelle Huynh, Konrad Piascik, Ricardo Cabello, David Kim, Ruofei Du",
      "published_date": "2025-10-01T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 191,
      "reading_time": 1,
      "created_at": "2025-10-01T09:42:28.747146+00:00",
      "updated_at": "2025-10-01T10:15:53.564335+00:00",
      "metadata": {
        "processed_at": "2025-10-01T10:15:53.564337+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "6751d4ba29952f47f6af983d84f172cd",
      "url": "https://arxiv.org/abs/2509.25499",
      "title": "Atlas of Human-AI Interaction (v1): An Interactive Meta-Science Platform for Large-Scale Research Literature Sensemaking",
      "content": "arXiv:2509.25499v1 Announce Type: new \nAbstract: Human-AI interaction researchers face an overwhelming challenge: synthesizing insights from thousands of empirical studies to understand how AI impacts people and inform effective design. Existing approach for literature reviews cluster papers by similarities, keywords or citations, missing the crucial cause-and-effect relationships that reveal how design decisions impact user outcomes. We introduce the Atlas of Human-AI Interaction, an interactive web interface that provides the first systematic mapping of empirical findings across 1,000+ HCI papers using LLM-powered knowledge extraction. Our approach identifies causal relationships, and visualizes them through an AI-enabled interactive web interface as a navigable knowledge graph. We extracted 2,037 empirical findings, revealing research topic clusters, common themes, and disconnected areas. Expert evaluation with 20 researchers revealed the system's effectiveness for discovering research gaps. This work demonstrates how AI can transform literature synthesis itself, offering a scalable framework for evidence-based design, opening new possibilities for computational meta-science across HCI and beyond.",
      "author": "Chayapatr Archiwaranguprok, Awu Chen, Sheer Karny, Hiroshi Ishii, Pattie Maes, Pat Pataranutaporn",
      "published_date": "2025-10-01T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 155,
      "reading_time": 1,
      "created_at": "2025-10-01T09:42:28.747115+00:00",
      "updated_at": "2025-10-01T10:15:53.564339+00:00",
      "metadata": {
        "processed_at": "2025-10-01T10:15:53.564341+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "863c3da472b0a1909355d8b7dcb7ee7d",
      "url": "https://arxiv.org/abs/2509.25492",
      "title": "Botender: Supporting Communities in Collaboratively Designing AI Agents through Case-Based Provocations",
      "content": "arXiv:2509.25492v1 Announce Type: new \nAbstract: AI agents, or bots, serve important roles in online communities. However, they are often designed by outsiders or a few tech-savvy members, leading to bots that may not align with the broader community's needs. How might communities collectively shape the behavior of community bots? We present Botender, a system that enables communities to collaboratively design LLM-powered bots without coding. With Botender, community members can directly propose, iterate on, and deploy custom bot behaviors tailored to community needs. Botender facilitates testing and iteration on bot behavior through case-based provocations: interaction scenarios generated to spark user reflection and discussion around desirable bot behavior. A validation study found these provocations more useful than standard test cases for revealing improvement opportunities and surfacing disagreements. During a five-day deployment across six Discord servers, Botender supported communities in tailoring bot behavior to their specific needs, showcasing the usefulness of case-based provocations in facilitating collaborative bot design.",
      "author": "Tzu-Sheng Kuo, Sophia Liu, Quan Ze Chen, Joseph Seering, Amy X. Zhang, Haiyi Zhu, Kenneth Holstein",
      "published_date": "2025-10-01T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 155,
      "reading_time": 1,
      "created_at": "2025-10-01T09:42:28.747086+00:00",
      "updated_at": "2025-10-01T10:15:53.564343+00:00",
      "metadata": {
        "processed_at": "2025-10-01T10:15:53.564347+00:00",
        "processing_method": "github_actions"
      }
    }
  ]
}