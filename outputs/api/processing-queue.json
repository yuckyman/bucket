{
  "last_updated": "2025-11-05T14:15:23.403914+00:00",
  "pending_count": 984,
  "processed_count": 16,
  "pending_articles": [
    {
      "id": "f1511405e2ace6a320ecb91798b42031",
      "url": "https://www.sciencedirect.com/science/article/pii/S0306452225010292?dgcid=rss_sd_all",
      "title": "Erratum to \u201cNeurotropism of alphaherpesviruses is most prominent in the mesiotemporal, piriform and prefrontal cortices in mice\u201d. [Neuroscience 584 (2025) 367\u2013381]",
      "content": "<p>Publication date: 28 November 2025</p><p><b>Source:</b> Neuroscience, Volume 589</p><p>Author(s): Viktoria Korff, Issam El-Debs, Sonja Br\u00f6er, Barbara G. Klupp, Jens P. Teifke, Thomas C. Mettenleiter, Julia Sehl-Ewert</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroscience Journal",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 25,
      "reading_time": 1,
      "created_at": "2025-11-05T13:33:20.725376+00:00",
      "updated_at": "2025-11-05T13:33:20.725390+00:00"
    },
    {
      "id": "11e3fc7de1a6562547b3d977d9923f55",
      "url": "https://www.sciencedirect.com/science/article/pii/S1053811925005622?dgcid=rss_sd_all",
      "title": "Linking dielectric dispersion and age in brain tissues via water content-based Electric Properties Tomography",
      "content": "<p>Publication date: 15 November 2025</p><p><b>Source:</b> NeuroImage, Volume 322</p><p>Author(s): S\u00e9bastien Marmin, Alessandro Arduino, Matteo Cencini, Marta Lancione, Laura Biagi, Michela Tosetti, Luca Zilberti</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroimage",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 22,
      "reading_time": 1,
      "created_at": "2025-11-05T13:33:18.488507+00:00",
      "updated_at": "2025-11-05T13:33:18.488508+00:00"
    },
    {
      "id": "339cdd93cd79a7f78f14f38e8f7f4d3a",
      "url": "https://www.sciencedirect.com/science/article/pii/S1053811925005634?dgcid=rss_sd_all",
      "title": "Corticospinal motoneuronal synaptic plasticity induction can modulate the speed of learning ballistic finger movements: Possible use in rehabilitation",
      "content": "<p>Publication date: 15 November 2025</p><p><b>Source:</b> NeuroImage, Volume 322</p><p>Author(s): Akira Yamashita, Takenobu Murakami, Shunsuke Kobayashi, Noriaki Hattori, Ichiro Miyai, Ritsuko Hanajima, Yoshikazu Ugawa</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroimage",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 22,
      "reading_time": 1,
      "created_at": "2025-11-05T13:33:18.488486+00:00",
      "updated_at": "2025-11-05T13:33:18.488487+00:00"
    },
    {
      "id": "551fc111106234009488bec53107dacd",
      "url": "https://www.sciencedirect.com/science/article/pii/S1053811925005725?dgcid=rss_sd_all",
      "title": "Olfactory sensation emotion regulation: The implicit emotion regulation function of positive olfactory stimuli during emotional picture processing",
      "content": "<p>Publication date: 15 November 2025</p><p><b>Source:</b> NeuroImage, Volume 322</p><p>Author(s): Jiaotao Cai, Xinran Wang, Jiayi Zhou, Ye di, Ziruo Shen, Shuo An, Bingyang Long, Yicheng Wang, Zitong Li, Yiting Li, Si Chen, Yanmei Wang</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroimage",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 32,
      "reading_time": 1,
      "created_at": "2025-11-05T13:33:18.488466+00:00",
      "updated_at": "2025-11-05T13:33:18.488468+00:00"
    },
    {
      "id": "6e438b97ab033f2ce8ce0a00f4b58357",
      "url": "https://www.sciencedirect.com/science/article/pii/S1053811925005646?dgcid=rss_sd_all",
      "title": "Local modulation of sleep slow waves depends on timing between auditory stimuli",
      "content": "<p>Publication date: 15 November 2025</p><p><b>Source:</b> NeuroImage, Volume 322</p><p>Author(s): Sven Leach, Sara Fattinger, Elena Krugliakova, Jelena Skorucak, Georgia Sousouri, Sophia Snipes, Selina Sch\u00fchle, Maria Laura Ferster, Giulia Da Poian, Walter Karlen, Reto Huber</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroimage",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 32,
      "reading_time": 1,
      "created_at": "2025-11-05T13:33:18.488445+00:00",
      "updated_at": "2025-11-05T13:33:18.488447+00:00"
    },
    {
      "id": "88b3f4bd1c6bfb19342970d2326128ca",
      "url": "https://www.sciencedirect.com/science/article/pii/S1053811925005683?dgcid=rss_sd_all",
      "title": "The hidden gut\u2013brain connection in tinnitus: Insight from a cross-sectional and genetic causal mediation study in over 900,000 individuals",
      "content": "<p>Publication date: 15 November 2025</p><p><b>Source:</b> NeuroImage, Volume 322</p><p>Author(s): Chanmei Fang, Liling Lin, Wan Chen, Qianhui Xu, Zhaopeng Tong, Shan Sun, Yu-Chen Chen, Maojin Liang, Yuexin Cai</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroimage",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 26,
      "reading_time": 1,
      "created_at": "2025-11-05T13:33:18.488421+00:00",
      "updated_at": "2025-11-05T13:33:18.488423+00:00"
    },
    {
      "id": "79f975e71b894123ea96107994fb53a0",
      "url": "https://www.sciencedirect.com/science/article/pii/S105381192500566X?dgcid=rss_sd_all",
      "title": "Breaking down the ear-brain dichotomy: the effects of age-related hearing loss on the cortical language system",
      "content": "<p>Publication date: 15 November 2025</p><p><b>Source:</b> NeuroImage, Volume 322</p><p>Author(s): Stefan Elmer, Vanessa Frei, Julian Ockelmann, Nathalie Giroud</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroimage",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 16,
      "reading_time": 1,
      "created_at": "2025-11-05T13:33:18.488362+00:00",
      "updated_at": "2025-11-05T13:33:18.488376+00:00"
    },
    {
      "id": "a2edcae91a685ef86b23521c69b26379",
      "url": "https://www.biorxiv.org/content/10.1101/2025.11.03.685924v1?rss=1",
      "title": "The hidden phase of memory: EEG signatures of reactivation during post-retrieval rest",
      "content": "Memory retrieval reactivates previously encoded representations, allowing for their modification and strengthening. However, the neural processes that follow reactivation and contribute to long-term retention remain poorly understood. Here, we examined the post-retrieval resting period to identify neural markers of memory reactivation and their relation to subsequent memory performance. Participants learned pairs of nonsense syllables in multisensory contexts and, on the following day, received either a cue-syllable reminder (context + cue syllable; RX) or a context-only reminder (RCTX) while EEG activity was recorded before and after the reminder presentation. Both reminders elicited significant reductions in beta power (25-40)Hz during the post-reminder rest, consistent with memory reactivation. The magnitude of beta decrement correlated with better long-term performance. Graph-theoretical analyses of phase synchronization networks in the beta band revealed that the RCTX reminder produced higher bilateral frontal betweenness centrality, suggesting greater engagement of frontal regions in mediating global information flow when retrieving only contextual cues. Moreover, frontal centrality and network density were predictive of subsequent memory accuracy. These findings demonstrate that memory reactivation extends beyond cue presentation into post-retrieval rest, leaving identifiable oscillatory and topological signatures that influence memory persistence. Our results underscore the crucial role of frontal network dynamics and beta-band activity in facilitating long-term memory.",
      "author": "Bavassi, L., Campos-Arteaga, G., Palacios-Garcia, I., Villena-Gonzalez, M., Campassi, L., Marachlian, E., Balboa, E. R., Forcato, C., Pedreira, M. E.",
      "published_date": "2025-11-04T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 204,
      "reading_time": 1,
      "created_at": "2025-11-05T13:33:17.299151+00:00",
      "updated_at": "2025-11-05T13:33:17.299153+00:00"
    },
    {
      "id": "db50e4d3ddd30eb67c3d2636a8fab646",
      "url": "https://www.biorxiv.org/content/10.1101/2025.11.03.686328v1?rss=1",
      "title": "Reactivating aversive memories in humans: An EEG and Microstates study of post-retrieval processes",
      "content": "Although fear conditioning is one of the most widely used models to study anxiety in humans, much remains to be explored regarding its underlying neural correlates. It is known that the retrieval of consolidated memories can trigger modifications, weakening, strengthening, or updating of the original memory, depending on the cues presented during the reminder. In this study, we employed a three-day threat-conditioning protocol in which an angry face (conditioned stimulus, CS+) was paired with an aversive sound (unconditioned stimulus, US). Our main objective was to identify neural markers of post-retrieval processes triggered by the presentation of the CS+ alone, 24 hours after acquisition. Additionally, we aimed to assess cognitive biases by examining how the perception of the conditioned stimulus changes following conditioning. To this end, we recorded resting-state electroencephalographic (EEG) activity using a 30-channel system at a 256 Hz sampling rate. We analyzed four minutes of resting-state EEG following the presentation of the reminder cue, focusing on memory-related patterns in the frequency domain and microstate dynamics. We compared neural activity after the reminder presentation between two groups: a Reactivation group previously exposed to threat conditioning on the first day and a Control group with no prior conditioning. Our results confirmed successful conditioning (CS+ US association) and memory retention 48 hours later, as evidenced by higher skin conductance responses and greater US expectancy to the CS+. Moreover, participants rated the CS+ face as more aversive than the CS-; face 48 hours after conditioning, compared to their pre-conditioning ratings. Relative to the Control group, the Reactivation group showed decreased beta-band activity (25-30 Hz) in central regions during the 90 seconds following the reminder, which may reflect enhanced post-reactivation processing of the memory, in contrast to participants who saw the face for the first time. Previous research has highlighted the role of reduced beta amplitude in the encoding and retrieval of another type of memory: episodic memory. Furthermore, when analyzing EEG microstates (short-lived, quasi-stable topographies of brain activity that reoccur over time), we found lower global field power for microstates C, A, E, and B in the Reactivation group compared with the Control group. Our findings provide initial evidence for neural correlates associated with post-retrieval processes, including decreased beta activity and microstate level differences related to the post-retrieval processing of an implicit memory.",
      "author": "Cavallino, L., Bavassi, L., Pedreira, M. E.",
      "published_date": "2025-11-04T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 380,
      "reading_time": 1,
      "created_at": "2025-11-05T13:33:17.299110+00:00",
      "updated_at": "2025-11-05T13:33:17.299112+00:00"
    },
    {
      "id": "905f090f530fb33df19d0f98a790af5c",
      "url": "https://www.biorxiv.org/content/10.1101/2025.11.03.686310v1?rss=1",
      "title": "Neural Encoding through Hierarchical Amplitude Modulation",
      "content": "Hierarchical encoding is a structural element of the Free Energy Principle and related information-centric accounts of brain function, but a concrete circuit-level mechanism for it remains elusive. Here we examine Hierarchical Amplitude Modulation (HAM). In this computationally grounded scheme, information is encoded in the envelope of a carrier and slower brain rhythms multiplicatively modulate the amplitude of faster rhythms, creating a cascade of nested oscillatory envelopes. This multiplicative architecture naturally produces intermodulation frequencies (of the form fc + {sum} ai fi). It predicts that oscillation frequency bands should be log-spaced (r {gtrsim} 2-3, depending on the number of modulation layers) to avoid spectral overlap, as in constant-Q filter banks, consistent with the observed logarithmic spacing of canonical brain rhythms (with ratios ~2-3). HAM's log-uniform distribution yields a 1/f global spectral profile and 1/f sideband spectra in the broadband \"aperiodic\" component, with the slope determined by modulation depth and band ratio. We then demonstrate modulation and demodulation in the laminar neural mass model (LaNMM), where a fast excitatory-inhibitory oscillator circuit couples with a slower cortical oscillator (Janse-Rit). Through the network's intrinsic nonlinearities and cross-frequency coupling, amplitude modulation and demodulation are implemented. These results provide a novel circuit-level mechanism for hierarchical predictive coding, linking theoretical principles to observed spectral features of brain activity.",
      "author": "Ruffini, G.",
      "published_date": "2025-11-04T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 211,
      "reading_time": 1,
      "created_at": "2025-11-05T13:33:17.299052+00:00",
      "updated_at": "2025-11-05T13:33:17.299054+00:00"
    }
  ],
  "recently_processed": [
    {
      "id": "1769fa3b8b8616544c9ba8e267a9714d",
      "url": "https://www.sciencedirect.com/science/article/pii/S0006899325005773?dgcid=rss_sd_all",
      "title": "Anticancer properties of new flavonoid lensoside A\u03b2 in combination with temozolomide in an in vitro model of human glioma cells",
      "content": "<p>Publication date: 15 December 2025</p><p><b>Source:</b> Brain Research, Volume 1869</p><p>Author(s): Aleksandra Maciejczyk, Justyna Kapral-Piotrowska, Joanna Sumorek-Wiadro, Adrian Zaj\u0105c, Wies\u0142aw I. Gruszecki, Marta Lemieszek, Iwona Wertel, \u0141ukasz Pecio, Jerzy \u017buchowski, Krystyna Skalicka-Wo\u017aniak, Bo\u017cena Pawlikowska-Pawl\u0119ga, Monika Hu\u0142as-Stasiak, Wojciech Rzeski, Rados\u0142aw Rola, Piotr Dobrowolski, Joanna Jakubowicz-Gil</p>",
      "author": "",
      "published_date": null,
      "source": "Brain Research",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 42,
      "reading_time": 1,
      "created_at": "2025-11-05T13:33:21.849016+00:00",
      "updated_at": "2025-11-05T14:15:23.299780+00:00",
      "metadata": {
        "processed_at": "2025-11-05T14:15:23.299789+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "215473f16a77bd474b2bd29d15d0ee20",
      "url": "https://www.sciencedirect.com/science/article/pii/S0006899325005931?dgcid=rss_sd_all",
      "title": "Fuzzy guided ensemble inference system for brain tumor classification",
      "content": "<p>Publication date: 15 December 2025</p><p><b>Source:</b> Brain Research, Volume 1869</p><p>Author(s): M. Ashwin Kumar, G. Manikandan, L. Richard, P. Sanjana</p>",
      "author": "",
      "published_date": null,
      "source": "Brain Research",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 18,
      "reading_time": 1,
      "created_at": "2025-11-05T13:33:21.848990+00:00",
      "updated_at": "2025-11-05T14:15:23.299793+00:00",
      "metadata": {
        "processed_at": "2025-11-05T14:15:23.299795+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "7013ed2520ae2ddf627c5a7c2140d0cd",
      "url": "https://www.sciencedirect.com/science/article/pii/S0006899325005682?dgcid=rss_sd_all",
      "title": "Epigenetics in neurodegeneration: Emerging biomarkers and translational insights",
      "content": "<p>Publication date: 15 December 2025</p><p><b>Source:</b> Brain Research, Volume 1869</p><p>Author(s): Hemraj Singh, Shaifali Gurjar, Rajeev Taliyan</p>",
      "author": "",
      "published_date": null,
      "source": "Brain Research",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 15,
      "reading_time": 1,
      "created_at": "2025-11-05T13:33:21.848949+00:00",
      "updated_at": "2025-11-05T14:15:23.299798+00:00",
      "metadata": {
        "processed_at": "2025-11-05T14:15:23.299800+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "3786c359f80674b8d07020a3cd7ea93e",
      "url": "https://www.sciencedirect.com/science/article/pii/S0006899325005736?dgcid=rss_sd_all",
      "title": "Neurocognitive basis of inter-subject variability in speech motor control: Interaction of bottom-up and top-down processes",
      "content": "<p>Publication date: 15 December 2025</p><p><b>Source:</b> Brain Research, Volume 1869</p><p>Author(s): Xiao Cai, Qingfang Zhang</p>",
      "author": "",
      "published_date": null,
      "source": "Brain Research",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-11-05T13:33:21.848912+00:00",
      "updated_at": "2025-11-05T14:15:23.299802+00:00",
      "metadata": {
        "processed_at": "2025-11-05T14:15:23.299804+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "ac302d611d32062170718e3eeb8c2a31",
      "url": "https://www.sciencedirect.com/science/article/pii/S0306452225010073?dgcid=rss_sd_all",
      "title": "Standardised and systematic sampling of public engagement in brain health \u2212 Slovenian example",
      "content": "<p>Publication date: 28 November 2025</p><p><b>Source:</b> Neuroscience, Volume 589</p><p>Author(s): I. Muc, L. Blinc, G. Vidmar, S. Kurdija, T. Vovk, M Bresjanac</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroscience Journal",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 20,
      "reading_time": 1,
      "created_at": "2025-11-05T13:33:20.725465+00:00",
      "updated_at": "2025-11-05T14:15:23.299806+00:00",
      "metadata": {
        "processed_at": "2025-11-05T14:15:23.299808+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "a0557799b2b66560bd70d30663a47e77",
      "url": "https://arxiv.org/abs/2511.02515",
      "title": "Emotional Contagion in Code: How GitHub Emoji Reactions Shape Developer Collaboration",
      "content": "arXiv:2511.02515v1 Announce Type: new \nAbstract: Developer communities increasingly rely on emoji reactions to communicate, but we know little about how these emotional signals spread and influence technical discussions. We analyzed 2,098 GitHub issues and pull requests across 50 popular repositories, examining patterns in 106,743 emoji reactions to understand emotional contagion in software development. Our findings reveal a surprisingly positive emotional landscape: 57.4% of discussions carry positive sentiment, with positive emotional cascades outnumbering negative ones 23:1. We identified five distinct patterns, with \"instant enthusiasm\" affecting 45.6% of items--nearly half receive immediate positive reinforcement. Statistical analysis confirms strong emotional contagion (r=0.679, p<0.001) with a massive effect size (d=2.393), suggesting that initial reactions powerfully shape discussion trajectories. These findings challenge assumptions about technical discourse being purely rational, demonstrating that even minimal emotional signals create measurable ripple effects. Our work provides empirical evidence that emoji reactions are not mere decoration but active forces shaping collaborative outcomes in software development.",
      "author": "Obada Kraishan",
      "published_date": "2025-11-05T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 155,
      "reading_time": 1,
      "created_at": "2025-11-05T11:39:53.028440+00:00",
      "updated_at": "2025-11-05T12:31:11.356789+00:00",
      "metadata": {
        "processed_at": "2025-11-05T12:31:11.356803+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "925985bf4847818c1094804a5e5d68af",
      "url": "https://arxiv.org/abs/2511.02468",
      "title": "HAGI++: Head-Assisted Gaze Imputation and Generation",
      "content": "arXiv:2511.02468v1 Announce Type: new \nAbstract: Mobile eye tracking plays a vital role in capturing human visual attention across both real-world and extended reality (XR) environments, making it an essential tool for applications ranging from behavioural research to human-computer interaction. However, missing values due to blinks, pupil detection errors, or illumination changes pose significant challenges for further gaze data analysis. To address this challenge, we introduce HAGI++ - a multi-modal diffusion-based approach for gaze data imputation that, for the first time, uses the integrated head orientation sensors to exploit the inherent correlation between head and eye movements. HAGI++ employs a transformer-based diffusion model to learn cross-modal dependencies between eye and head representations and can be readily extended to incorporate additional body movements. Extensive evaluations on the large-scale Nymeria, Ego-Exo4D, and HOT3D datasets demonstrate that HAGI++ consistently outperforms conventional interpolation methods and deep learning-based time-series imputation baselines in gaze imputation. Furthermore, statistical analyses confirm that HAGI++ produces gaze velocity distributions that closely match actual human gaze behaviour, ensuring more realistic gaze imputations. Moreover, by incorporating wrist motion captured from commercial wearable devices, HAGI++ surpasses prior methods that rely on full-body motion capture in the extreme case of 100% missing gaze data (pure gaze generation). Our method paves the way for more complete and accurate eye gaze recordings in real-world settings and has significant potential for enhancing gaze-based analysis and interaction across various application domains.",
      "author": "Chuhan Jiao, Zhiming Hu, Andreas Bulling",
      "published_date": "2025-11-05T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 232,
      "reading_time": 1,
      "created_at": "2025-11-05T11:39:53.028411+00:00",
      "updated_at": "2025-11-05T12:31:11.356807+00:00",
      "metadata": {
        "processed_at": "2025-11-05T12:31:11.356809+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "81d80692a1233ca3d50394a3c8685c44",
      "url": "https://arxiv.org/abs/2511.02455",
      "title": "OpenCourier: an Open Protocol for Building a Decentralized Ecosystem of Community-owned Delivery Platforms",
      "content": "arXiv:2511.02455v1 Announce Type: new \nAbstract: Although the platform gig economy has reshaped the landscape of work, its centralized operation by select actors has brought about challenges that impedes workers' well-being. We present the architecture and design of OpenCourier, an open protocol that defines communication patterns within a decentralized ecosystem of delivery platforms. Through this protocol, we aim to address three key challenges in the current economy: power imbalances between the platform and workers, information asymmetries caused by black-boxed algorithms and value misalignments in the infrastructure design process. With the OpenCourier protocol, we outline a blueprint for community-owned ecosystem of delivery platforms that centers worker agency, transparency, and bottom-up design.",
      "author": "Yuhan Liu, Varun Nagaraj Rao, Sohyeon Hwang, Janet Vertesi, Andr\\'es Monroy-Hern\\'andez",
      "published_date": "2025-11-05T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 109,
      "reading_time": 1,
      "created_at": "2025-11-05T11:39:53.028372+00:00",
      "updated_at": "2025-11-05T12:31:11.356811+00:00",
      "metadata": {
        "processed_at": "2025-11-05T12:31:11.356813+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "c9ba8e10b698d63a78a875f1be41488c",
      "url": "https://arxiv.org/abs/2511.02428",
      "title": "Can Conversational AI Counsel for Change? A Theory-Driven Approach to Supporting Dietary Intentions in Ambivalent Individuals",
      "content": "arXiv:2511.02428v1 Announce Type: new \nAbstract: Adherence to healthy diets reduces chronic illness risk, yet rates remain low. Large Language Models (LLMs) are increasingly used for health communication but often struggle to engage individuals with ambivalent intentions at a pivotal stage of the Transtheoretical Model (TTM). We developed CounselLLM, an open-source model enhanced through persona design and few-shot, domain-specific prompts grounded in TTM and Motivational Interviewing (MI). In controlled evaluations, CounselLLM showed stronger use of TTM subprocesses and MI affirmations than human counselors, with comparable linguistic robustness but expressed in more concrete terms. A user study then tested CounselLLM in an interactive counseling setting against a baseline system. While knowledge and perceptions did not change, participants' intentions for immediate dietary change increased significantly after interacting with CounselLLM. Participants also rated it as easy to use, understandable, and supportive. These findings suggest theory-driven LLMs can effectively engage ambivalent individuals and provide a scalable approach to digital counseling.",
      "author": "Michelle Bak, Kexin Quan, Tre Tomaszewski, Jessie Chin",
      "published_date": "2025-11-05T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 155,
      "reading_time": 1,
      "created_at": "2025-11-05T11:39:53.028346+00:00",
      "updated_at": "2025-11-05T12:31:11.356815+00:00",
      "metadata": {
        "processed_at": "2025-11-05T12:31:11.356816+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "f02745e73308b544dcbf4fa37b96cba0",
      "url": "https://arxiv.org/abs/2511.02378",
      "title": "Revisiting put-that-there, context aware window interactions via LLMs",
      "content": "arXiv:2511.02378v1 Announce Type: new \nAbstract: We revisit Bolt's classic \"Put-That-There\" concept for modern head-mounted displays by pairing Large Language Models (LLMs) with XR sensor and tech stack. The agent fuses (i) a semantically segmented 3-D environment, (ii) live application metadata, and (iii) users' verbal, pointing, and head-gaze cues to issue JSON window-placement actions. As a result, users can manage a panoramic workspace through: (1) explicit commands (\"Place Google Maps on the coffee table\"), (2) deictic speech plus gestures (\"Put that there\"), or (3) high-level goals (\"I need to send a message\"). Unlike traditional explicit interfaces, our system supports one-to-many action mappings and goal-centric reasoning, allowing the LLM to dynamically infer relevant applications and layout decisions, including interrelationships across tools. This enables seamless, intent-driven interaction without manual window juggling in immersive XR environments.",
      "author": "Riccardo Bovo, Daniele Giunchi, Pasquale Cascarano, Eric J. Gonzalez, Mar Gonzalez-Franco",
      "published_date": "2025-11-05T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 132,
      "reading_time": 1,
      "created_at": "2025-11-05T11:39:53.028316+00:00",
      "updated_at": "2025-11-05T12:31:11.356819+00:00",
      "metadata": {
        "processed_at": "2025-11-05T12:31:11.356820+00:00",
        "processing_method": "github_actions"
      }
    }
  ]
}