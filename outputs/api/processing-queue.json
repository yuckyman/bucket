{
  "last_updated": "2025-12-18T06:25:50.296128+00:00",
  "pending_count": 713,
  "processed_count": 287,
  "pending_articles": [
    {
      "id": "5995fbcde79041f54251fcafb9c3356b",
      "url": "https://arxiv.org/abs/2512.14952",
      "title": "Breathe with Me: Synchronizing Biosignals for User Embodiment in Robots",
      "content": "arXiv:2512.14952v1 Announce Type: cross \nAbstract: Embodiment of users within robotic systems has been explored in human-robot interaction, most often in telepresence and teleoperation. In these applications, synchronized visuomotor feedback can evoke a sense of body ownership and agency, contributing to the experience of embodiment. We extend this work by employing embreathment, the representation of the user's own breath in real time, as a means for enhancing user embodiment experience in robots. In a within-subjects experiment, participants controlled a robotic arm, while its movements were either synchronized or non-synchronized with their own breath. Synchrony was shown to significantly increase body ownership, and was preferred by most participants. We propose the representation of physiological signals as a novel interoceptive pathway for human-robot interaction, and discuss implications for telepresence, prosthetics, collaboration with robots, and shared autonomy.",
      "author": "Iddo Yehoshua Wald, Amber Maimon, Shiyao Zhang, Dennis K\\\"uster, Robert Porzel, Tanja Schultz, Rainer Malaka",
      "published_date": "2025-12-18T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 133,
      "reading_time": 1,
      "created_at": "2025-12-18T05:24:30.570367+00:00",
      "updated_at": "2025-12-18T05:24:30.570368+00:00"
    },
    {
      "id": "11f6521457838285e47a450148bee619",
      "url": "https://arxiv.org/abs/2512.15514",
      "title": "A Constructive Scientific Methodology to Improve Climate Figures from IPCC",
      "content": "arXiv:2512.15514v1 Announce Type: new \nAbstract: We propose a methodology to improve figures from the Intergovernmental Panel on Climate Change (IPCC), ensuring that all modifications remain scientifically rigorous. IPCC figures are notoriously difficult to understand, and although designers have proposed alternatives, these lack formal IPCC validation and can be dismissed by skeptics. To address this gap, our approach starts from official IPCC figures. We gather their associated learning objectives and devise tests to score a pool of figure readers to assess how well they learn the objectives.We define improvement as higher scores obtained by a comparable reader pool after viewing a revised figure, where all modifications undergo review to ensure scientific validity. This assessment gives freedom to designers, who can deviate from the original design while making sure the objectives are still met and improved. We demonstrate the methodology through a case study and describe unexpected challenges encountered during the process.",
      "author": "Lu Ying, Junxiu Tang, Tingying He, Jean-Daniel Fekete",
      "published_date": "2025-12-18T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 150,
      "reading_time": 1,
      "created_at": "2025-12-18T05:24:30.570339+00:00",
      "updated_at": "2025-12-18T05:24:30.570341+00:00"
    },
    {
      "id": "cc7224cabbcc0b6d0d9e9bc74226840c",
      "url": "https://arxiv.org/abs/2512.15491",
      "title": "GazeBlend: Exploring Paired Gaze-Based Input Techniques for Navigation and Selection Tasks on Mobile Devices",
      "content": "arXiv:2512.15491v1 Announce Type: new \nAbstract: The potential of gaze for hands-free mobile interaction is increasingly evident. While each gaze input technique presents distinct advantages and limitations, a combination can amplify strengths and mitigate challenges. We report on the results of a user study (N=24), in which we compared the usability and performance of pairing three popular gaze input techniques: Dwell Time, Pursuits, and Gaze Gestures, for navigation and selection tasks while sitting and walking. Results show that pairing gestures for navigation with either Dwell time or Pursuits for selection improves task completion time and rate compared to using either individually. We discuss the implications of pairing gaze input techniques, such as how Pursuits may negatively impact other techniques, likely due to the visual clutter it adds, how integrating gestures for navigation reduces the chances of unintentional selections, and the impact of motor activity on performance. Our findings provide insights for effective gaze-enabled interfaces.",
      "author": "Omar Namnakani, Yasmeen Abdrabou, Jonathan Grizou, Mohamed Khamis",
      "published_date": "2025-12-18T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 153,
      "reading_time": 1,
      "created_at": "2025-12-18T05:24:30.570309+00:00",
      "updated_at": "2025-12-18T05:24:30.570311+00:00"
    },
    {
      "id": "46794938635c311f38180b09714524ca",
      "url": "https://arxiv.org/abs/2512.15343",
      "title": "Exploring User Acceptance and Concerns toward LLM-powered Conversational Agents in Immersive Extended Reality",
      "content": "arXiv:2512.15343v1 Announce Type: new \nAbstract: The rapid development of generative artificial intelligence (AI) and large language models (LLMs), and the availability of services that make them accessible, have led the general public to begin incorporating them into everyday life. The extended reality (XR) community has also sought to integrate LLMs, particularly in the form of conversational agents, to enhance user experience and task efficiency. When interacting with such conversational agents, users may easily disclose sensitive information due to the naturalistic flow of the conversations, and combining such conversational data with fine-grained sensor data may lead to novel privacy issues. To address these issues, a user-centric understanding of technology acceptance and concerns is essential. Therefore, to this end, we conducted a large-scale crowdsourcing study with 1036 participants, examining user decision-making processes regarding LLM-powered conversational agents in XR, across factors of XR setting type, speech interaction type, and data processing location. We found that while users generally accept these technologies, they express concerns related to security, privacy, social implications, and trust. Our results suggest that familiarity plays a crucial role, as daily generative AI use is associated with greater acceptance. In contrast, previous ownership of XR devices is linked to less acceptance, possibly due to existing familiarity with the settings. We also found that men report higher acceptance with fewer concerns than women. Regarding data type sensitivity, location data elicited the most significant concern, while body temperature and virtual object states were considered least sensitive. Overall, our study highlights the importance of practitioners effectively communicating their measures to users, who may remain distrustful. We conclude with implications and recommendations for LLM-powered XR.",
      "author": "Efe Bozkir, Enkelejda Kasneci",
      "published_date": "2025-12-18T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 270,
      "reading_time": 1,
      "created_at": "2025-12-18T05:24:30.570281+00:00",
      "updated_at": "2025-12-18T05:24:30.570282+00:00"
    },
    {
      "id": "3c0c01f4a4d374d2c82beff04b7bf092",
      "url": "https://arxiv.org/abs/2512.15325",
      "title": "Managing Ambiguity: A Proof of Concept of Human-AI Symbiotic Sense-making based on Quantum-Inspired Cognitive Mechanism of Rogue Variable Detection",
      "content": "arXiv:2512.15325v1 Announce Type: new \nAbstract: Organizations increasingly operate in environments characterized by volatility, uncertainty, complexity, and ambiguity (VUCA), where early indicators of change often emerge as weak, fragmented signals. Although artificial intelligence (AI) is widely used to support managerial decision-making, most AI-based systems remain optimized for prediction and resolution, leading to premature interpretive closure under conditions of high ambiguity. This creates a gap in management science regarding how human-AI systems can responsibly manage ambiguity before it crystallizes into error or crisis. This study addresses this gap by presenting a proof of concept (PoC) of the LAIZA human-AI augmented symbiotic intelligence system and its patented process: Systems and Methods for Quantum-Inspired Rogue Variable Modeling (QRVM), Human-in-the-Loop Decoherence, and Collective Cognitive Inference. The mechanism operationalizes ambiguity as a non-collapsed cognitive state, detects persistent interpretive breakdowns (rogue variables), and activates structured human-in-the-loop clarification when autonomous inference becomes unreliable. Empirically, the article draws on a three-month case study conducted in 2025 within the AI development, involving prolonged ambiguity surrounding employee intentions and intellectual property boundaries. The findings show that preserving interpretive plurality enabled early scenario-based preparation, including proactive patent protection, allowing decisive and disruption-free action once ambiguity collapsed. The study contributes to management theory by reframing ambiguity as a first-class construct and demonstrates the practical value of human-AI symbiosis for organizational resilience in VUCA environments.",
      "author": "Agnieszka Bienkowska, Jacek Malecki, Alexander Mathiesen-Ohman, Katarzyna Tworek",
      "published_date": "2025-12-18T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 221,
      "reading_time": 1,
      "created_at": "2025-12-18T05:24:30.570239+00:00",
      "updated_at": "2025-12-18T05:24:30.570241+00:00"
    },
    {
      "id": "29e0a40896863bd8d480f7dd0c068182",
      "url": "https://arxiv.org/abs/2512.15263",
      "title": "Development of Immersive Virtual and Augmented Reality-Based Joint Attention Training Platform for Children with Autism",
      "content": "arXiv:2512.15263v1 Announce Type: new \nAbstract: Joint Attention (JA), a crucial social skill for developing shared focus, is often impaired in children with Autism Spectrum Disorder (ASD), affecting social communication and highlighting the need for early intervention. Addressing gaps in prior research, such as limited use of immersive technology and reliance on distracting peripherals, we developed a novel JA training platform using Augmented Reality (AR) and Virtual Reality (VR) devices. The platform integrates eye gaze-based interactions to ensure participants undivided attention. To validate the platform, we conducted experiments on ASD (N=19) and Neurotypical (NT) (N=13) participants under a trained pediatric neurologist's supervision. For quantitative analysis, we employed key measures such as the number of correct responses, the duration of establishing eye contact (s), and the duration of registering a response (s), along with correlations to CARS scores and age. Results from AR-based experiments showed NT participants registered responses significantly faster (<0.00001) than ASD participants. A correlation (Spearman coefficient=0.57, p=0.03) was found between ASD participants response time and CARS scores. A similar trend was observed in VR-based experiments. When comparing response accuracy in ASD participants across platforms, AR yielded a higher correctness rate (92.30%) than VR (69.49%), indicating AR's greater effectiveness. These findings suggest that immersive technology can aid JA training in ASD. Future studies should explore long-term benefits and real-world applicability.",
      "author": "Ashirbad Samantaray, Taranjit Kaur, Sapna S Mishra, Kritika Lohia, Chayan Majumder, Sheffali Gulati, Tapan Kumar Gandhi",
      "published_date": "2025-12-18T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 220,
      "reading_time": 1,
      "created_at": "2025-12-18T05:24:30.570191+00:00",
      "updated_at": "2025-12-18T05:24:30.570192+00:00"
    },
    {
      "id": "92ac0707834dd156e8050e3e904850cb",
      "url": "https://arxiv.org/abs/2512.15220",
      "title": "Lessons Learnt from Expert-Centred Studies Exploring Opportunities and Challenges for Immersive Forensic Investigation",
      "content": "arXiv:2512.15220v1 Announce Type: new \nAbstract: Research studies involving human participants present challenges, including strict ethical considerations, participant recruitment, costs, and many human factors. While human-computer interaction researchers are familiar with these challenges and current solutions, expert-centred studies can be even more challenging in ways that researchers may not anticipate. This issue is particularly important as research grants are increasingly based on practical and real-world problems, which necessitate close collaboration with experts. In this paper, we reflect on and discuss the challenges, solutions, and specific requirements that arose during our expert-centred studies conducted over three years of a PhD study exploring immersive forensic investigation.",
      "author": "Vahid Pooryousef, Tim Dwyer, Richard Bassed, Maxime Cordeil, Lonni Besan\\c{c}on",
      "published_date": "2025-12-18T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 103,
      "reading_time": 1,
      "created_at": "2025-12-18T05:24:30.570157+00:00",
      "updated_at": "2025-12-18T05:24:30.570159+00:00"
    },
    {
      "id": "2f411bbee77065c793de78ffd7bd5e62",
      "url": "https://arxiv.org/abs/2512.15117",
      "title": "I am here for you\": How relational conversational AI appeals to adolescents, especially those who are socially and emotionally vulnerable",
      "content": "arXiv:2512.15117v1 Announce Type: new \nAbstract: General-purpose conversational AI chatbots and AI companions increasingly provide young adolescents with emotionally supportive conversations, raising questions about how conversational style shapes anthropomorphism and emotional reliance. In a preregistered online experiment with 284 adolescent-parent dyads, youth aged 11-15 and their parents read two matched transcripts in which a chatbot responded to an everyday social problem using either a relational style (first-person, affiliative, commitment language) or a transparent style (explicit nonhumanness, informational tone). Adolescents more often preferred the relational than the transparent style, whereas parents were more likely to prefer transparent style than adolescents. Adolescents rated the relational chatbot as more human-like, likable, trustworthy and emotionally close, while perceiving both styles as similarly helpful. Adolescents who preferred relational style had lower family and peer relationship quality and higher stress and anxiety than those preferring transparent style or both chatbots. These findings identify conversational style as a key design lever for youth AI safety, showing that relational framing heightens anthropomorphism, trust and emotional closeness and can be especially appealing to socially and emotionally vulnerable adolescents, who may be at increased risk for emotional reliance on conversational AI.",
      "author": "Pilyoung Kim, Yun Xie, Sujin Yang",
      "published_date": "2025-12-18T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 190,
      "reading_time": 1,
      "created_at": "2025-12-18T05:24:30.570131+00:00",
      "updated_at": "2025-12-18T05:24:30.570133+00:00"
    },
    {
      "id": "63d13b387c540ee755d76e925da23834",
      "url": "https://arxiv.org/abs/2512.14977",
      "title": "Human-Centered AI Maturity Model (HCAI-MM): An Organizational Design Perspective",
      "content": "arXiv:2512.14977v1 Announce Type: new \nAbstract: Human-centered artificial intelligence (HCAI) is an approach to AI design, development, and deployment that prioritizes human needs, values, and experiences, ensuring that technology enhances human capabilities, well-being, and workforce empowerment. While HCAI has gained prominence in academic discourse and organizational practice, its implementation remains constrained by the absence of methodological guidance and structured frameworks. In particular, HCAI and organizational design practices are often treated separately, despite their interdependence in shaping effective socio-technical systems. This chapter addresses this gap by introducing the Human-Centered AI Maturity Model (HCAI-MM), a structured framework that enables organizations to evaluate, monitor, and advance their capacity to design and implement HCAI solutions. The model specifies stages of maturity, metrics, tools, governance mechanisms, and best practices, supported by case studies, while also incorporating an organizational design methodology that operationalizes maturity progression. Encompassing dimensions such as human-AI collaboration, explainability, fairness, and user experience, the HCAI-MM provides a roadmap for organizations to move from novice to advanced levels of maturity, aligning AI technologies with human values and organizational design principles.",
      "author": "Stuart Winby, Wei Xu",
      "published_date": "2025-12-18T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 175,
      "reading_time": 1,
      "created_at": "2025-12-18T05:24:30.570099+00:00",
      "updated_at": "2025-12-18T05:24:30.570101+00:00"
    },
    {
      "id": "c7b19644eeafa9d506d04cb28f00e6c5",
      "url": "https://arxiv.org/abs/2512.14965",
      "title": "Analyzing Social Media Claims regarding Youth Online Safety Features to Identify Problem Areas and Communication Gaps",
      "content": "arXiv:2512.14965v1 Announce Type: new \nAbstract: Social media platforms have faced increasing scrutiny over whether and how they protect youth online. While online risks to children have been well-documented by prior research, how social media platforms communicate about these risks and their efforts to improve youth safety have not been holistically examined. To fill this gap, we analyzed N=352 press releases and safety-related blogs published between 2019 and 2024 by four platforms popular among youth: YouTube, TikTok, Meta (Facebook and Instagram), and Snapchat. Leveraging both inductive and deductive qualitative approaches, we developed a comprehensive framework of seven problem areas where risks arise, and a taxonomy of safety features that social media platforms claim address these risks. Our analysis revealed uneven emphasis across problem areas, with most communications focused on Content Exposure and Interpersonal Communication, whereas less emphasis was placed on Content Creation, Data Access, and Platform Access. Additionally, we identified three problematic communication practices related to their described safety features, including discrepancies between feature implementation and availability, unclear or inconsistent explanations of safety feature operation, and a lack of evidence regarding the effectiveness of safety features in mitigating risks once implemented. Based on these findings, we discuss the communication gaps between risks and the described safety features, as well as the tensions in achieving transparency in platform communication. Our analysis of platform communication informs guidelines for responsibly communicating about youth safety features.",
      "author": "Renkai Ma, Dominique Geissler, Stefan Feuerriegel, Tobias Lauinger, Damon McCoy, Pamela Wisniewski",
      "published_date": "2025-12-18T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 231,
      "reading_time": 1,
      "created_at": "2025-12-18T05:24:30.570063+00:00",
      "updated_at": "2025-12-18T05:24:30.570066+00:00"
    }
  ],
  "recently_processed": [
    {
      "id": "8bfe7b7f37af142b24b0fcd318868131",
      "url": "https://brain.ieee.org/braininsight-articles/ieee-brain-annual-flagship-workshop-a-success/",
      "title": "IEEE Brain Annual Flagship Workshop a Success",
      "content": "IEEE Brain once again hosted the IEEE Brain Discovery and Neurotechnology Workshop as a satellite event to the 2024 Society of Neuroscience Workshop (SfN). Approximately 180 attended the two-day event, which was held at the University of Illinois Chicago (UIC), October 3-4, 2024 (Figure 1). Groundbreaking solutions with the potential to improve quality of life and address neural disorders require ...",
      "author": "ieeebrain",
      "published_date": "2025-03-03T16:55:37+00:00",
      "source": "Brain",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 61,
      "reading_time": 1,
      "created_at": "2025-12-18T05:47:55.549970+00:00",
      "updated_at": "2025-12-18T06:25:50.191006+00:00",
      "metadata": {
        "processed_at": "2025-12-18T06:25:50.191015+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "2eb57dbdbc858b57282cfad12fa8d826",
      "url": "https://brain.ieee.org/braininsight-articles/ieee-brain-workshop-on-ai-for-neurotechnology/",
      "title": "IEEE Brain Workshop on AI for Neurotechnology",
      "content": "The IEEE Brain Workshop on AI for Neurotechnology was held on June 30, 2024, at the Pacifico Yokohama Conference Center in Japan. This event was part of the World Congress on Computational Intelligence (WCCI 2024) and was conducted in association with the International Joint Conference on Neural Networks (IJCNN). The workshop focused on the application of artificial intelligence to neurotechnology, ...",
      "author": "ieeebrain",
      "published_date": "2025-03-03T17:05:59+00:00",
      "source": "Brain",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 61,
      "reading_time": 1,
      "created_at": "2025-12-18T05:47:55.549948+00:00",
      "updated_at": "2025-12-18T06:25:50.191020+00:00",
      "metadata": {
        "processed_at": "2025-12-18T06:25:50.191022+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "0da023b5bfd7e782a65cd0692c1a2b38",
      "url": "https://www.nature.com/articles/d41586-025-04066-5",
      "title": "More than half of researchers now use AI for peer review, often against guidance",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46309124\">Comments</a>",
      "author": "",
      "published_date": "2025-12-18T05:20:41+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-18T05:46:58.700613+00:00",
      "updated_at": "2025-12-18T06:25:50.191024+00:00",
      "metadata": {
        "processed_at": "2025-12-18T06:25:50.191026+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "47359ecf88cebee3299a8a63eb87d1ac",
      "url": "https://www.theregister.com/2025/12/05/vizio_gpl_source_code_ruling/",
      "title": "Judge hints Vizio TV buyers may have rights to source code licensed under GPL",
      "content": "<p>Article URL: <a href=\"https://www.theregister.com/2025/12/05/vizio_gpl_source_code_ruling/\">https://www.theregister.com/2025/12/05/vizio_gpl_source_code_ruling/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46308893\">https://news.ycombinator.com/item?id=46308893</a></p>\n<p>Points: 8</p>\n<p># Comments: 0</p>",
      "author": "pabs3",
      "published_date": "2025-12-18T04:27:53+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-18T05:46:57.307123+00:00",
      "updated_at": "2025-12-18T06:25:50.191028+00:00",
      "metadata": {
        "processed_at": "2025-12-18T06:25:50.191030+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "28587b461b4cb1202f354f48132d557e",
      "url": "https://www.omgubuntu.co.uk/2025/12/mozilla-new-ceo-firefox-ai-browser-strategy",
      "title": "Mozilla's New CEO Confirms Firefox Will Become an \"AI Browser\"",
      "content": "<p>Article URL: <a href=\"https://www.omgubuntu.co.uk/2025/12/mozilla-new-ceo-firefox-ai-browser-strategy\">https://www.omgubuntu.co.uk/2025/12/mozilla-new-ceo-firefox-ai-browser-strategy</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46309039\">https://news.ycombinator.com/item?id=46309039</a></p>\n<p>Points: 7</p>\n<p># Comments: 3</p>",
      "author": "LopRabbit",
      "published_date": "2025-12-18T05:01:00+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-18T05:46:57.307101+00:00",
      "updated_at": "2025-12-18T06:25:50.191032+00:00",
      "metadata": {
        "processed_at": "2025-12-18T06:25:50.191034+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "0da023b5bfd7e782a65cd0692c1a2b38",
      "url": "https://www.nature.com/articles/d41586-025-04066-5",
      "title": "More than half of researchers now use AI for peer review, often against guidance",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46309124\">Comments</a>",
      "author": "",
      "published_date": "2025-12-18T05:20:41+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-18T05:46:58.700613+00:00",
      "updated_at": "2025-12-18T06:25:50.191024+00:00",
      "metadata": {
        "processed_at": "2025-12-18T06:25:50.191026+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "ed50b1e7c08ac29ca5464ed7766bea3c",
      "url": "http://www.jneurosci.org/cgi/content/short/45/47/etwij45472025?rss=1",
      "title": "This Week in The Journal",
      "content": "",
      "author": "McKeon, P.",
      "published_date": "2025-11-19T17:30:30+00:00",
      "source": "Journal Neuroscience This Week",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-12-18T04:08:00.953202+00:00",
      "updated_at": "2025-12-18T04:30:10.232189+00:00",
      "metadata": {
        "processed_at": "2025-12-18T04:30:10.232199+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "2860e952aadea89abed187f1d97d1f7c",
      "url": "http://www.jneurosci.org/cgi/content/short/45/49/etwij45492025?rss=1",
      "title": "This Week in The Journal",
      "content": "",
      "author": "McKeon, P.",
      "published_date": "2025-12-03T17:30:36+00:00",
      "source": "Journal Neuroscience This Week",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-12-18T04:08:00.953161+00:00",
      "updated_at": "2025-12-18T04:30:10.232203+00:00",
      "metadata": {
        "processed_at": "2025-12-18T04:30:10.232205+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "92e2db12c7d63a64e0e1bc1e3d5e0c9f",
      "url": "https://jsomers.net/blog/speed-matters",
      "title": "Working quickly is more important than it seems (2015)",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46270918\">Comments</a>",
      "author": "",
      "published_date": "2025-12-15T05:54:28+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-18T04:07:24.184608+00:00",
      "updated_at": "2025-12-18T04:30:10.232207+00:00",
      "metadata": {
        "processed_at": "2025-12-18T04:30:10.232209+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "1a8a30971d651a14bf4cbaac5b9cbad9",
      "url": "https://news.ycombinator.com/item?id=46307973",
      "title": "Ask HN: Those making $500/month on side projects in 2025 \u2013 Show and tell",
      "content": "<p>It's the time of the year again, so I'd be interested hear what new (and old) ideas have come up.\nPreviously asked on:<p>2024 \u2192 https://news.ycombinator.com/item?id=42373343<p>2023 \u2192 https://news.ycombinator.com/item?id=38467691<p>2022 \u2192 https://news.ycombinator.com/item?id=34190421<p>2021 \u2192 https://news.ycombinator.com/item?id=29667095<p>2020 \u2192 https://news.ycombinator.com/item?id=24947167<p>2019 \u2192 https://news.ycombinator.com/item?id=20899863<p>2018 \u2192 https://news.ycombinator.com/item?id=17790306<p>2017 \u2192 https://news.ycombinator.com/item?id=15148804</p>\n<hr />\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46307973\">https://news.ycombinator.com/item?id=46307973</a></p>\n<p>Points: 29</p>\n<p># Comments: 2</p>",
      "author": "cvbox",
      "published_date": "2025-12-18T01:36:54+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 50,
      "reading_time": 1,
      "created_at": "2025-12-18T04:07:22.811858+00:00",
      "updated_at": "2025-12-18T04:30:10.232213+00:00",
      "metadata": {
        "processed_at": "2025-12-18T04:30:10.232215+00:00",
        "processing_method": "github_actions"
      }
    }
  ]
}