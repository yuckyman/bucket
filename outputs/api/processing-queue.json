{
  "last_updated": "2025-12-26T06:25:30.817267+00:00",
  "pending_count": 681,
  "processed_count": 319,
  "pending_articles": [
    {
      "id": "69eaa8157f6142d9fc2b0b517efcf1c2",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.23.696299v1?rss=1",
      "title": "Portable quantum-sensor magnetomyography decodes fine hand movements",
      "content": "Optically pumped magnetometers (OPMs) are compact quantum sensors that can measure the magnetic fields generated by muscle activity (magnetomyography, MMG) without skin contact. This contact-free alternative to surface electromyography (EMG) has remained mostly confined to magnetically shielded rooms and simple tasks, limiting translation. Here, we show that a portable OPM-MMG system operated inside a compact magnetic shield can robustly decode fine finger movements and recover EMG-like muscle activation patterns. Eight participants executed flexion- extension combinations spanning 15 finger actions while we recorded triaxial MMG and bipolar EMG concurrently. MMG supported robust multi-class and finger-specific decoding, recovering a representational geometry that closely matched EMG. Orientation analyses showed that components orthogonal to the muscle axis contributed most significantly to discriminability, providing actionable guidance for OPM array design. Our results show that OPM-MMG in a portable shielded environment preserves task-relevant neuromuscular information and approaches EMG-level structure without skin contact or a magnetically shielded room. Our findings open a path toward hygienic, rapid-setup assessment and human-machine interfacing in clinics and rehabilitation settings.",
      "author": "Greco, A., Middelmann, T., Mehring, C., Marquetand, J., Siegel, M.",
      "published_date": "2025-12-25T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 168,
      "reading_time": 1,
      "created_at": "2025-12-26T05:24:05.380904+00:00",
      "updated_at": "2025-12-26T05:24:05.380906+00:00"
    },
    {
      "id": "26b2f2f90a46c19b23e5a95f8af138a7",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.23.696068v1?rss=1",
      "title": "Task-irrelevant stimuli boost phasic pupil-linked arousal but not memory formation",
      "content": "Brainstem arousal systems, especially the locus coeruleus-noradrenaline system, respond transiently to behaviorally relevant events, which is reflected in pupil dilations. The strength of these pupil-linked arousal responses during encoding of stimulus material predicts the success of its later retrieval. The pupil also dilates in response to task-irrelevant sounds. Here, we evaluated whether the effect of task-irrelevant white noise sounds on pupil-linked arousal can also be used to manipulate memory formation. Task-irrelevant white-noise sounds played before, during or after the presentation of memoranda (images or spoken words) evoked robust pupil dilations. Trial-to-trial variations in the amplitude of pupil responses during word encoding also predicted memory success. Yet, the task-irrelevant sounds did not increase memory success. These sounds may not trigger the same central arousal processes as endogenous variations of arousal that are relevant for memory formation, such as those occurring in states of increased emotionality.",
      "author": "Hebisch, J., Van Puyenbroeck, P., Schwabe, L., de Gee, J. W., Donner, T. H.",
      "published_date": "2025-12-25T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 144,
      "reading_time": 1,
      "created_at": "2025-12-26T05:24:05.380856+00:00",
      "updated_at": "2025-12-26T05:24:05.380858+00:00"
    },
    {
      "id": "3228a7de1eec2996760ba4ba8e86c3e6",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.25.696413v1?rss=1",
      "title": "Thalamocortical coupling and cortical E-I balance generate diverse anesthetic \u03b1-spindles for interpretable EEG decoding",
      "content": "Anesthesia is a common clinical procedure, yet its hallmark EEG motifs--spindles oscillating in the broad alpha-range between 4 and 16 Hz--are not enough interpretable from the neuronal circuit perspective and for predictive medicine. To fill this gap, we investigate here the neuronal mechanisms and mathematical principles of brain spindles by recording and modeling large-scale thalamo-cortical neuronal ensembles in mice under anesthesia. We report irregular weakly synchronized firing of thalamic and cortical neurons associated with spindle patterns, indicating an emergent network rather than cellular dynamics. The consecutive loss of balance between the firing of excitatory and inhibitory cortical neurons and the increased firing fluctuations, together play in favor of larger spindle amplitude. In addition, the continuous range of spindle frequencies observed reflects a tight equilibrium of interactions between the thalamus and cortex. To create a possible numerical twin of this complex dynamics that could be used during clinical anesthesia, we built a computational model that comprises a reciprocally connected excitatory and inhibitory representation of cortical and thalamic networks driven by random fluctuations. The model parsimoniously explains the changes in spindle dynamics when increasing the anesthesia dose. This model thus links in vivo brain sub-network dynamics with EEG for the readout of anesthetized brain states.",
      "author": "David, F., Sun, C., Michel, P.-O., Sibille, J., Rouach, N., Holcman, D.",
      "published_date": "2025-12-25T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 203,
      "reading_time": 1,
      "created_at": "2025-12-26T05:24:05.380826+00:00",
      "updated_at": "2025-12-26T05:24:05.380827+00:00"
    },
    {
      "id": "0a59818a7abceabfd22f03c02345ac81",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.25.696484v1?rss=1",
      "title": "Empathy Accelerates Subjective Time Perception, Independent of Physiology but Not of Visual Attention",
      "content": "Recent work suggests that empathic engagement can influence cognitive and perceptual processes, yet its impact on time perception remains unclear. Whereas internal clock models would predict that empathy-induced physiological arousal lengthen perceived duration, other frameworks offer opposite predictions. Specifically, findings that empathy reduces perceived distance, combined with construal level, and motivational dimensional theory, together predict that empathy accelerate the subjective passage of time. Moreover, although eye-movements are crucial in empathy, it remains unclear how visual attention modulates time perception during empathic experiences. Thus, we employed an empathy-for-pain and duration estimation task, while measuring participants heart rate, skin conductance, and eye-movements, to investigate how empathy and physiological arousal influence time perception. Our findings show that empathy leads to a faster perceived passage of time. Despite increases in physiological arousal during empathy, arousal was not associated with changes in time perception. Instead, greater visual attention to the eyes predicted stronger temporal contraction. Furthermore, trait empathy and autism quotient were related to this effect, whereas alexithymia was not. These results provide the first empirical evidence that empathy alters time perception, elucidate the contribution of physiological and visual mechanisms to this phenomenon and extend current theories of time perception and empathy.",
      "author": "Golbabaei, S., Hosseinnezhad, M., Karami, Z., Borhani, K.",
      "published_date": "2025-12-25T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 197,
      "reading_time": 1,
      "created_at": "2025-12-26T05:24:05.380791+00:00",
      "updated_at": "2025-12-26T05:24:05.380792+00:00"
    },
    {
      "id": "d29ab62ec6b8cb0af3c0dfa190ba2c34",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.25.696470v1?rss=1",
      "title": "Tracking Satb2-positive retinal ganglion cells in zebrafish unveils developmental functional reorganization",
      "content": "Retinal ganglion cells (RGCs) relay visual information to the brain, and their functional properties are crucial for visually guided behavior. However, functional maturation of RGCs across development remains elusive. Here, we investigated the developmental maturation of a genetically defined RGC subtype expressing Satb2 in zebrafish, which allowed single-layer-resolved analysis of the tectal neuropil. Using in vivo calcium imaging, we characterized visual response properties of Satb2-positive RGC axon terminals at two developmental stages. At the early stage, responses segregated into seven functional clusters with diverse tuning profiles. By later stage, these responses reorganized into five clusters, indicating developmental restructuring of functional identities. Longitudinal imaging of individual RGC axons revealed that while some response types remain stable across development, others exhibit pronounced plasticity. In particular, certain RGC cluster acquired additional tuning features and converged into motion-sensitive cluster, coinciding with a marked expansion of motion-responsive cluster and reflecting progressive functional specialization. Visual deprivation experiments revealed that core visual tuning is genetically determined, whereas visual experience is crucial for fine-tuning of the particular functional subtype. Together, our findings provide a single-cell-resolved view of retinal circuit maturation and reveal how stable and flexible responses are integrated during the development of vertebrate vision.",
      "author": "Urazbayeva, A., Kubo, F.",
      "published_date": "2025-12-25T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 197,
      "reading_time": 1,
      "created_at": "2025-12-26T05:24:05.380754+00:00",
      "updated_at": "2025-12-26T05:24:05.380756+00:00"
    },
    {
      "id": "23420e0250f75cf29523f6d16651d51c",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.24.696343v1?rss=1",
      "title": "Stimulus sensitivity in noisy neural systems",
      "content": "Understanding how neural populations encode sensory information requires a precise definition of neuronal sensitivity to stimuli. While tuning curves and firing rates offer intuitive insights, theoretical frameworks based on signal-to-noise ratio and decoding efficiency identify Fisher information as the canonical measure of sensitivity, due to its relation with decoding performance. However, this relation holds only under restrictive conditions--when many neurons encode the same stimulus feature or when neural noise is weak. In realistic settings, such as when complex or high-dimensional stimuli are represented by a small ensemble of neurons, Fisher information becomes ill-defined or misleading. To overcome these limitations, we investigate two complementary information-theoretic quantities--the stimulus-specific information (ISSI) and the local information (Iloc)--and propose them as robust alternatives for quantifying sensitivity. We show that ISSI and Iloc converge with Fisher information when signal to noise is large, yet remain meaningful and interpretable beyond that regime. Importantly, these measures capture distinct aspects of sensitivity: ISSI quantifies how observing a response reduces stimulus uncertainty, whereas Iloc reflects how small stimulus perturbations reshape the systems posterior beliefs. Together, they offer a unifying perspective linking information-theoretic and statistical notions of sensitivity, bridging theoretical analysis and experimental investigation of neural coding.",
      "author": "Paris, C., Laquitaine, S., Chalk, M., Ferrari, U.",
      "published_date": "2025-12-25T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 196,
      "reading_time": 1,
      "created_at": "2025-12-26T05:24:05.380711+00:00",
      "updated_at": "2025-12-26T05:24:05.380716+00:00"
    },
    {
      "id": "3d6b5f8f7d117269f6d483cfe999ae04",
      "url": "https://www.frontiersin.org/articles/10.3389/fncom.2025.1641519",
      "title": "Fractal memory structure in the spatiotemporal learning rule",
      "content": "The spatiotemporal learning rule (STLR) can reproduce synaptic plasticity in the hippocampus. Analysis of the synaptic weights in the network with the STLR is challenging. Consequently, our previous research only focused on the network's outputs. However, a detailed analysis of the STLR requires focusing on the synaptic weights themselves. To address this issue, we mapped the synaptic weights to a distance space and analyzed the characteristics of the STLR. The results indicate that the synaptic weights form a fractal-like structure in Euclidean distance space. Furthermore, three analytical approaches\u2014multi-dimensional scaling, estimating fractal dimension, and modeling with an iterated function system\u2014demonstrate that the STLR forms a fractal structure in the synaptic weights through fractal coding. These findings contribute to clarifying the learning mechanisms in the hippocampus.",
      "author": "Yoshihiko Horio",
      "published_date": "2025-12-16T00:00:00+00:00",
      "source": "Frontiers Computational Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 124,
      "reading_time": 1,
      "created_at": "2025-12-26T05:23:55.633131+00:00",
      "updated_at": "2025-12-26T05:23:55.633135+00:00"
    },
    {
      "id": "e533e42c8519cc6178e085ef3d6fd4bf",
      "url": "https://www.frontiersin.org/articles/10.3389/fnhum.2025.1708257",
      "title": "Task-constrained self-initiated attention shifts are indexed by frontal-midline theta ramping",
      "content": "In everyday vision, we often shift attention internally without external cues. These self-initiated attention shifts are fundamental to voluntary behavior but are poorly understood because most studies use cue-based paradigms that predetermine when and where to shift attention. To address this gap, we designed a multi-sequential-choice rapid serial visual presentation (RSVP) paradigm with identical visual inputs to dissociate internal and external determinants of attention across three voluntary shift types: task-constrained self-initiated, externally instructed, and unconstrained free-viewing. Participants viewed four simultaneous streams of letters and made overt attention shifts among them, while EEG was recorded. We time-locked theta (4\u20137 Hz) and alpha (8\u201312 Hz) oscillations to shift onset and found distinct signatures for each condition. Notably, a frontal-midline theta ramping was observed before self-initiated shifts but not before instructed or free-viewing shifts, suggesting a preparatory buildup of cognitive control specific to internally driven shifts. Concurrently, sustained suppression of posterior alpha occurred before self-initiated shifts. In contrast, instructed and free-viewing shifts showed relatively higher posterior alpha. These findings suggest that internally generated, goal-driven shifts engage an anticipatory frontal control mechanism indexed by theta increase and reduce posterior inhibition, whereas externally cued or unguided shifts do not. By isolating these condition-specific neural dynamics under identical external stimuli, our study identifies a unique oscillatory signature, frontal-midline theta ramping, associated with task-constrained self-initiated attention shifts.",
      "author": "Satoshi Shioiri",
      "published_date": "2025-12-16T00:00:00+00:00",
      "source": "Frontiers Human Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 220,
      "reading_time": 1,
      "created_at": "2025-12-26T05:23:54.027107+00:00",
      "updated_at": "2025-12-26T05:23:54.027109+00:00"
    },
    {
      "id": "437dd11491bad5ef899b86bf9271e125",
      "url": "http://doi.org/10.1037/cns0000370",
      "title": "Investigating how individual differences in selective attention relate to schizotypy and altered states of consciousness.",
      "content": "Measures of altered states of consciousness (ASC) are useful for understanding anomalies within conscious experiences. Within psychedelic clinical trials, ASC have been associated with long-term positive treatment outcomes for numerous types of mental illnesses. Schizotypal Personality Scale (STA), a set of personality traits that can be related to psychedelic-induced ASC, is associated with potential changes in selective attention, such as being less bound to previously learned associations (i.e., reduced associative blocking). Given the similarity between schizotypy and psychedelic-induced ASC, we hypothesized that there may be attentional differences in individuals with past experiences of ASC. This study examined how differences in selective attention relate to past experiences of ASC and STA. In Study 1, participants completed a visual categorization task designed to elicit associative blocking, the STA, and the ASC scale. Results revealed slow learning feature\u2013category associations in participants high in ASC and STA. Study 2 tested whether this deficit in performance was due to widened attention by implementing additional inference trials that measured incidental learning of feature\u2013feature associations. Results from Study 2 confirmed that participants high in ASC and STA show deficits in learning categories, but this was not accounted for by wider selective attention per se. Our results suggest that flexible or widened attention may not be the locus of cognitive changes associated with past experiences of ASC. Rather, by showing reliable latency in an error-driven learning task, we add to a comprehensive understanding of the relationships between cognition and ASC. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2023-09-14T00:00:00+00:00",
      "source": "Clinical Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 251,
      "reading_time": 1,
      "created_at": "2025-12-26T05:23:33.070450+00:00",
      "updated_at": "2025-12-26T05:23:33.070452+00:00"
    },
    {
      "id": "9cbd4ead9980b71744b8c8a3382bf698",
      "url": "https://www.nakedcapitalism.com/2025/12/in-their-total-war-on-online-privacy-the-liberal-democracies-of-the-collective-west-are-now-turning-their-sights-on-vpns.html",
      "title": "Governments in the West Are Turning Their Sights on VPNs",
      "content": "<p>Article URL: <a href=\"https://www.nakedcapitalism.com/2025/12/in-their-total-war-on-online-privacy-the-liberal-democracies-of-the-collective-west-are-now-turning-their-sights-on-vpns.html\">https://www.nakedcapitalism.com/2025/12/in-their-total-war-on-online-privacy-the-liberal-democracies-of-the-collective-west-are-now-turning-their-sights-on-vpns.html</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46388185\">https://news.ycombinator.com/item?id=46388185</a></p>\n<p>Points: 28</p>\n<p># Comments: 2</p>",
      "author": "indigodaddy",
      "published_date": "2025-12-26T00:58:17+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-26T05:23:22.961226+00:00",
      "updated_at": "2025-12-26T05:23:22.961228+00:00"
    }
  ],
  "recently_processed": [
    {
      "id": "c2029e5d1c9b0d15ec3eaab794141760",
      "url": "https://www.frontiersin.org/articles/10.3389/fnhum.2025.1753714",
      "title": "Editorial: Exercising body & brain: the effects of physical exercise on brain health",
      "content": "",
      "author": "Vijaya Majumdar",
      "published_date": "2025-12-16T00:00:00+00:00",
      "source": "Frontiers Human Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-12-26T05:46:21.251193+00:00",
      "updated_at": "2025-12-26T06:25:30.709044+00:00",
      "metadata": {
        "processed_at": "2025-12-26T06:25:30.709053+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "ef1d360d604223946bde97ad8fab7bd1",
      "url": "https://www.frontiersin.org/articles/10.3389/fnbot.2025.1574044",
      "title": "Path planning of industrial robots based on the adaptive field cooperative sampling algorithm",
      "content": "For the low efficiency and poor generalization ability of path planning algorithm of industrial robots, this work proposes an adaptive field co-sampling algorithm (AFCS). Firstly, the environment complexity function is proposed to make full use of environment information and improve its generalization ability of the traditional rapidly random search tree algorithm (RRT) algorithm. Then an optimal sampling strategy is proposed to make the improvement of the efficiency and optimal direction of RRT algorithm. Finally, this article designs a collaborative extension strategy, which introduces the improved artificial potential field algorithm (APF) into the traditional RRT algorithm to determine the new nodes, so as to improve the orientation and expansion efficiency of the algorithm. The proposed AFCS algorithm completes simulation experiments in two environments with different complexity. Compared with the traditional RRT, RRT* and tRRT algorithm, the results show that the AFCS algorithm has achieved great improvement in environmental adaptability, stability and efficiency. At last, ROKAE industrial robot is taken as the object to build a simulation environment for the path planning, which further verifies the practicability of the algorithm.",
      "author": "Lv Wei",
      "published_date": "2025-11-13T00:00:00+00:00",
      "source": "Frontiers Neurorobotics",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 178,
      "reading_time": 1,
      "created_at": "2025-12-26T05:46:19.800400+00:00",
      "updated_at": "2025-12-26T06:25:30.709058+00:00",
      "metadata": {
        "processed_at": "2025-12-26T06:25:30.709060+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "3abe551d012031cecab1405c8ab3ac96",
      "url": "https://docs.python.org/3.15/library/profiling.sampling.html",
      "title": "Tachyon: High frequency statistical sampling profiler",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46353257\">Comments</a>",
      "author": "",
      "published_date": "2025-12-22T11:21:42+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-26T05:45:54.088631+00:00",
      "updated_at": "2025-12-26T06:25:30.709062+00:00",
      "metadata": {
        "processed_at": "2025-12-26T06:25:30.709064+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "36ad1c6191b6df29269dd41c8bf3a5ae",
      "url": "https://github.com/thu-ml/TurboDiffusion",
      "title": "TurboDiffusion: 100\u2013200\u00d7 Acceleration for Video Diffusion Models",
      "content": "<p>Article URL: <a href=\"https://github.com/thu-ml/TurboDiffusion\">https://github.com/thu-ml/TurboDiffusion</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46388907\">https://news.ycombinator.com/item?id=46388907</a></p>\n<p>Points: 8</p>\n<p># Comments: 0</p>",
      "author": "meander_water",
      "published_date": "2025-12-26T03:19:49+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-26T05:45:52.716252+00:00",
      "updated_at": "2025-12-26T06:25:30.709069+00:00",
      "metadata": {
        "processed_at": "2025-12-26T06:25:30.709070+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "d0060152fc0ea38d8b96fc4ddab8b6ab",
      "url": "https://imgur.com/nUJCI3o",
      "title": "Rob Pike Goes Nuclear over GenAI",
      "content": "<p>Article URL: <a href=\"https://imgur.com/nUJCI3o\">https://imgur.com/nUJCI3o</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46389444\">https://news.ycombinator.com/item?id=46389444</a></p>\n<p>Points: 16</p>\n<p># Comments: 1</p>",
      "author": "signa11",
      "published_date": "2025-12-26T05:27:05+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-26T05:45:52.716223+00:00",
      "updated_at": "2025-12-26T06:25:30.709073+00:00",
      "metadata": {
        "processed_at": "2025-12-26T06:25:30.709074+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "a89cc9d9bab0838b2e06072add1ef2ed",
      "url": "http://doi.org/10.1037/cns0000335",
      "title": "A shared perceptual inference for cross-modally induced illusions of self-attribution.",
      "content": "The representation of our own body is malleable. Evidence indicates that multisensory stimulation can trigger an illusory sense of ownership over a fake hand, a partner\u2019s face, or a virtual body. Despite our understanding of the processes supporting the construction of bodily self, we know less about the processes that trigger illusory ownership of nonbody attributes (e.g., voice during articulation) and about whether multisensory stimulation can drive a shared inference across distinct attributes. Here, we compared the classic rubber hand illusion with another multisensory illusion that elicits a sense of ownership over a stranger\u2019s voice during talking. We observed that, given congruent multisensory input, the degree to which one perceived the sense of ownership over the fake hand predicted the degree to which one perceived the sense of ownership over the stranger\u2019s voice, after controlling for task demand and suggestibility. Thus, our results provide evidence for a shared inference supporting subjective sense of self across fundamentally different attributes. We suggest that individual reliance on multisensory signals to drive such an inference can be further explored. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2022-08-25T00:00:00+00:00",
      "source": "Clinical Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 184,
      "reading_time": 1,
      "created_at": "2025-12-26T04:10:37.649412+00:00",
      "updated_at": "2025-12-26T04:31:23.739831+00:00",
      "metadata": {
        "processed_at": "2025-12-26T04:31:23.739841+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "fa250840ddf6808c93613cad856c7c25",
      "url": "http://doi.org/10.1037/cns0000353",
      "title": "Unmuting lucid dreams: Speech decoding and vocalization in real time.",
      "content": "Since the 1970s, scientists have been searching for ways to communicate with people in lucid dreams (LDs), during which it is possible to maintain consciousness. Previously, dreamers could hear sounds from reality and respond with some simple signals, but they could not speak back. In this study, facial surface electromyography (EMG) was tested as a proof of concept for unmuting people in LDs. Remmyo, an EMG distinctive constructed language, was used. The software was developed to translate facial EMG impulses into Remmyo sounds and letters, translate words into English, and digitally vocalize the final text in English. Four LD practitioners were trained to pronounce a short phrase or a word in Remmyo and were then asked to achieve the same task in LDs under polysomnographic observation. LDs were verified by preagreed eye movements in rapid eye movement (REM) sleep. Four volunteers tried to speak in Remmyo in 15 LDs. Due to software failures, mispronunciations, and missing sounds, the decoding efficiency in real time or in recordings ranged from 13% to 81%. The first phrase and word heard from sleeping people were \u201cno war\u201d and \u201cfreedom.\u201d The later was automatically translated and vocalized in English in real time for 11 times. Despite controversial results, the study shows that, with further development, people could possibly talk in LDs and could be heard in reality with the help of EMG sensors. To achieve this goal, a range of possible obstacles is discussed. This technology could provide opportunities for LD studies and their practical applications. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2023-03-13T00:00:00+00:00",
      "source": "Clinical Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 260,
      "reading_time": 1,
      "created_at": "2025-12-26T04:10:37.649376+00:00",
      "updated_at": "2025-12-26T04:31:23.739845+00:00",
      "metadata": {
        "processed_at": "2025-12-26T04:31:23.739847+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "3cace5c5d9bdc4eeebb05365c3e99538",
      "url": "http://doi.org/10.1037/cns0000402",
      "title": "Creating a world in the head: The conscious apprehension of neural content originating from internal sources.",
      "content": "Klein et al. (2023) argued that the evolutionary transition from respondent to agent during the Cambrian explosion would be a promising vantage point from which to gain insight into the evolution of organic sentience. They focused on how increased competition for resources\u2014in consequence of the proliferation of new, neurally sophisticated life-forms\u2014made awareness of the external world (in the service of agentic acts) an adaptive priority. The explanatory scope of Klein et al. (2023) was limited to consideration of the conscious apprehension of externally sourced content\u2014that is, content delivered from the sensory registration of objects occupying phenomenal space. But consciousness\u2014at least for humans\u2014takes its objects from internal as well as external sources. In the present article, we extend their analysis to the question of how internally sourced content (i.e., mental states) became the object of conscious apprehension. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2024-09-09T00:00:00+00:00",
      "source": "Clinical Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 145,
      "reading_time": 1,
      "created_at": "2025-12-26T04:10:37.649329+00:00",
      "updated_at": "2025-12-26T04:31:23.739850+00:00",
      "metadata": {
        "processed_at": "2025-12-26T04:31:23.739852+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "4dc92cbf63e410e4d59f6ffd2f7dec90",
      "url": "http://doi.org/10.1037/cns0000406",
      "title": "Not all minds think alike: Examining the impact of time and task on visual and verbal thought.",
      "content": "Research suggests that individuals have different phenomenological experiences across various tasks. However, little is known about how these experiences vary by task or over time. This study examined participants\u2019 experiences of task-unrelated thoughts (i.e., TUTs), visual, and verbal thoughts across two experimental sessions and two different tasks. In addition, we examined relations between participants\u2019 thoughts and key individual difference factors. In Session 1, participants (<em>n</em> = 85) engaged in a focused-attention meditation and a reading task, then completed a second identical session with a new text. Throughout both tasks, participants were prompted to report on the characteristics of their thoughts. Participants\u2019 ratings of TUT, visual, and verbal thoughts were subject to change over time. Furthermore, on average, participants visualized more and had fewer TUTs while reading compared to meditation; however, no task difference was found for verbal-thinking reports. This suggests that visual imagery is more malleable than verbal-thinking. There was a strong negative correlation between visual and verbal thoughts, suggesting that at any given time, individuals\u2019 thoughts tended to be either predominantly visual or verbal. Finally, individual differences in the tendency to become immersed in narratives and motivation to engage with other people\u2019s perspectives (i.e., mind-reading motivation) were related to higher reports of visual imagery during reading, whereas verbal-thinking was negatively associated with mind-reading motivation and unrelated to TUT. Overall, this study revealed that individuals\u2019 phenomenological experiences vary during tasks and across time, providing a foundation for future work to examine why and how variability in these phenomenological experiences emerge. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2024-10-14T00:00:00+00:00",
      "source": "Clinical Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 259,
      "reading_time": 1,
      "created_at": "2025-12-26T04:10:37.649280+00:00",
      "updated_at": "2025-12-26T04:31:23.739854+00:00",
      "metadata": {
        "processed_at": "2025-12-26T04:31:23.739855+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "1345eb0c41fa55e61c1833a198faa5d9",
      "url": "https://github.com/ruvnet/wifi-densepose",
      "title": "WiFi DensePose: WiFi-based dense human pose estimation system through walls",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46388904\">Comments</a>",
      "author": "",
      "published_date": "2025-12-26T03:18:47+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-26T04:10:27.959274+00:00",
      "updated_at": "2025-12-26T04:31:23.739857+00:00",
      "metadata": {
        "processed_at": "2025-12-26T04:31:23.739859+00:00",
        "processing_method": "github_actions"
      }
    }
  ]
}