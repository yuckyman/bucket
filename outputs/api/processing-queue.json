{
  "last_updated": "2025-10-06T06:22:11.025685+00:00",
  "pending_count": 980,
  "processed_count": 20,
  "pending_articles": [
    {
      "id": "609521b013e1243f77b1eaa5e01eab3e",
      "url": "http://ieeexplore.ieee.org/document/10965524",
      "title": "VibTac: A High-Resolution High-Bandwidth Tactile Sensing Finger for Multi-Modal Perception in Robotic Manipulation",
      "content": "Tactile sensing is pivotal for enhancing robot manipulation abilities by providing crucial feedback for localized information. However, existing sensors often lack the necessary resolution and bandwidth required for intricate tasks. To address this gap, we introduce VibTac, a novel multi-modal tactile sensing finger designed to offer high-resolution and high-bandwidth tactile sensing simultaneously. VibTac seamlessly integrates vision-based and vibration-based tactile sensing modes to achieve high-resolution and high-bandwidth tactile sensing respectively, leveraging a streamlined human-inspired design for versatility in tasks. This paper outlines the key design elements of VibTac and its fabrication methods, highlighting the significance of the Elastomer Gel Pad (EGP) in its sensing mechanism. The sensor's multi-modal performance is validated through 3D reconstruction and spectral analysis to discern tactile stimuli effectively. In experimental trials, VibTac demonstrates its efficacy by achieving over 90% accuracy in insertion tasks involving objects emitting distinct sounds, such as ethernet connectors. Leveraging vision-based tactile sensing for object localization and employing a deep learning model for \u201cclick\u201d sound classification, VibTac showcases its robustness in real-world scenarios.",
      "author": "",
      "published_date": "2025-04-15T13:16:45+00:00",
      "source": "Transactions Haptics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 169,
      "reading_time": 1,
      "created_at": "2025-10-06T05:41:16.111934+00:00",
      "updated_at": "2025-10-06T05:41:16.111935+00:00"
    },
    {
      "id": "6e5289b1927a2560a61773b58736ef16",
      "url": "http://ieeexplore.ieee.org/document/10955171",
      "title": "Age-Related Impact in Illusory Torque Cues Induced by Asymmetric Vibrations",
      "content": "Illusory pulling sensations in the translational or rotational direction are induced by asymmetric vibrations applied to the fingertips. Although previous studies have discussed the involvement of mechanoreceptors associated with skin deformation and spatial processing in the parietal association cortex in the generation of illusory cues, the precise mechanism underlying this phenomenon remains unclear. In this study, we aimed to indirectly estimate the contribution of mechanoreceptors to the perception of illusory pulling torque cues by examining the relationship between vibration thresholds and the properties of these illusions, leveraging the known decline in cutaneous sensation sensitivity associated with aging (N = 40). Our results revealed an age-related increase in vibration thresholds, which is consistent with previous research. While male participants showed consistent sensitivity to illusory pulling cues across age groups, female participants exhibited a decline in sensitivity with age. Moreover, we observed only weak or no correlations between the vibration thresholds and the sensitivity of the illusory pulling cue. Although we were unable to identify any findings that explain the contribution of mechanoreceptors, we discovered a gender difference in the sensitivity to induced illusions among older individuals. These findings offer valuable insights for elucidating the mechanism underlying the illusion.",
      "author": "",
      "published_date": "2025-04-07T13:17:32+00:00",
      "source": "Transactions Haptics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 197,
      "reading_time": 1,
      "created_at": "2025-10-06T05:41:16.111894+00:00",
      "updated_at": "2025-10-06T05:41:16.111896+00:00"
    },
    {
      "id": "7cd5915b404adde9692f79fbf455044d",
      "url": "http://ieeexplore.ieee.org/document/11037651",
      "title": "A Force/Torque Taxonomy for Classifying States During Physical Co-Manipulation",
      "content": "Achieving seamless human-robot collaboration requires a deeper understanding of how agents manage and communicate forces during shared tasks. Force interactions during collaborative manipulation are inherently complex, especially when considering how they evolve over time. To address this complexity, we propose a taxonomy of decomposed force and torque components, providing a structured framework for examining haptic communication and informing the development of robots capable of performing meaningful collaborative manipulation tasks with human partners. We propose a standardized terminology for force decomposition and classification, bridging the varied language in previous literature in the field, and conduct a review of physical human-human interaction and haptic communication. The proposed taxonomy allows for a more effective and nuanced discussion of important force combinations that we expect to occur during collaborative manipulation (between human-human or human-robot teams). We also include example scenarios to illustrate the value of the proposed taxonomy in describing interactions between agents.",
      "author": "",
      "published_date": "2025-06-17T13:16:38+00:00",
      "source": "Transactions Haptics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 149,
      "reading_time": 1,
      "created_at": "2025-10-06T05:41:16.111845+00:00",
      "updated_at": "2025-10-06T05:41:16.111847+00:00"
    },
    {
      "id": "bffad7ff78c038ce61497f8206575f26",
      "url": "http://ieeexplore.ieee.org/document/11045422",
      "title": "Haptic Relocation Away From the Fingertip: Where, Why, and How",
      "content": "Tactile haptic devices are often designed to render meaningful, complex, and realistic touch-based information on users\u2019 skin. While fingertips and hands are the most preferred body locations to render haptic feedback, recent trends allow such feedback to be extended to alternative body locations (e.g., wrist, arm, torso, foot) for various scenarios due to reasons such as wearability and needs of the application. In this paper, I address the new concept of haptic relocation. It refers to scenarios in which the expected feedback is related to the fingertips but rendered on a different body location instead \u2013 e.g., contact forces registered by two robotic fingers during teleoperation rendered to the users\u2019 wrist instead of the fingers. I investigated the design choices of wearable haptic devices for haptic relocation concerning different body locations, targeted applications, and actuator selection. I discuss approaches and design choices from the literature by speculating on the possible reasons, and conclude the paper by highlighting some challenges and issues to be mindful of in the future. This paper will guide engineers and researchers in searching for alternative haptic rendering solutions \u2013 especially when fingers and hands are not available for haptic interaction.",
      "author": "",
      "published_date": "2025-06-20T13:16:43+00:00",
      "source": "Transactions Haptics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 194,
      "reading_time": 1,
      "created_at": "2025-10-06T05:41:16.111813+00:00",
      "updated_at": "2025-10-06T05:41:16.111815+00:00"
    },
    {
      "id": "654c67a50800e0d8df1eb841fa063ae1",
      "url": "http://ieeexplore.ieee.org/document/10918829",
      "title": "Tactile\u2013Thermal Interactions: Cooperation and Competition",
      "content": "This review focuses on the interactions between the cutaneous senses, and in particular touch and temperature, as these are the most relevant for developing skin-based display technologies for use in virtual reality (VR) and for designing multimodal haptic devices. A broad spectrum of research is reviewed ranging from studies that have examined the mechanisms involved in thermal intensification and tactile masking, to more applied work that has focused on implementing thermal-tactile illusions such as thermal referral and illusory wetness in VR environments. Research on these tactile-thermal illusions has identified the differences between the senses of cold and warmth in terms of their effects on the perception of object properties and the prevalence of the perceptual experiences elicited. They have also underscored the fundamental spatial and temporal differences between the tactile and thermal senses. The wide-ranging body of research on compound sensations such as wetness and stickiness has highlighted the mechanisms involved in sensing moisture and provided a framework for measuring these sensations in a variety of contexts. Although the interactions between the two senses are complex, it is clear that the addition of thermal inputs to a tactile display enhances both user experience and enables novel sensory experiences.",
      "author": "",
      "published_date": "2025-03-10T13:16:41+00:00",
      "source": "Transactions Haptics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 198,
      "reading_time": 1,
      "created_at": "2025-10-06T05:41:16.111772+00:00",
      "updated_at": "2025-10-06T05:41:16.111774+00:00"
    },
    {
      "id": "604cffaea5736d8c2935253598862e29",
      "url": "http://ieeexplore.ieee.org/document/11174044",
      "title": "Twenty Years of World Haptics: Retrospective and Future Directions",
      "content": "null",
      "author": "",
      "published_date": "2025-09-19T13:16:57+00:00",
      "source": "Transactions Haptics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 1,
      "reading_time": 1,
      "created_at": "2025-10-06T05:41:16.111729+00:00",
      "updated_at": "2025-10-06T05:41:16.111731+00:00"
    },
    {
      "id": "65fcee7a3858adcf1bad71db41168384",
      "url": "http://ieeexplore.ieee.org/document/11174043",
      "title": "Table of Contents",
      "content": "null",
      "author": "",
      "published_date": "2025-09-19T13:16:57+00:00",
      "source": "Transactions Haptics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 1,
      "reading_time": 1,
      "created_at": "2025-10-06T05:41:16.111709+00:00",
      "updated_at": "2025-10-06T05:41:16.111711+00:00"
    },
    {
      "id": "5f20eba3c36d7a21f4e8668f0d3a88f6",
      "url": "http://ieeexplore.ieee.org/document/11174042",
      "title": "Front Cover",
      "content": "null",
      "author": "",
      "published_date": "2025-09-19T13:16:58+00:00",
      "source": "Transactions Haptics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 1,
      "reading_time": 1,
      "created_at": "2025-10-06T05:41:16.111683+00:00",
      "updated_at": "2025-10-06T05:41:16.111687+00:00"
    },
    {
      "id": "fdb4b0122212d7927163ddd75297ca04",
      "url": "http://ieeexplore.ieee.org/document/10945385",
      "title": "An Exploration of the Electrocorticogram Signatures Evoked by Ultrasound Thalamus Stimulation Under Isoflurane Anesthesia in Rats",
      "content": "Objective: The transcranial ultrasound stimulation (TUS) on the thalamus can indirectly induce cortical response. Studies have shown that general anesthetic induced unconsciousness is related to interruption of thalamocortical connectivity. However, the neural mechanism of how anesthesia levels influence cortical responses during ultrasound thalamus stimulation has never been explored yet. And it remains unknown what cortical responses signatures are evoked by ultrasound thalamus stimulation under different anesthesia levels. Methods: We recorded multichannel electrocorticogram (ECoG) evoked by ultrasound thalamus stimulation of rats at various isoflurane concentrations (i.e., 0.5%, 1.0%, 1.5%, and 2.0% (v/v)). We analyzed ECoG signatures in temporal, spatial, and frequency domains by using the ultrasound-evoked potentials (UEPs), omega complexity (OC), and phase amplitude coupling (PAC), respectively. Results: The pattern of UEPs was influenced by the anesthesia level, and the response amplitude of UEPs increased with the increase in anesthesia level (0.5% vs. 1.0% and 1.5% (v/v), p < 0.05). Also, the OC of stimulated ECoG decreased with the increase in anesthesia level (at the 1.0%, 1.5% and 2.0% (v/v), p < 0.05). The TUS promoted the coupling between the amplitude and the phase (at the 1.5% and 2.0% (v/v), p < 0.05), and the modulation index of PAC was anesthesia level-dependent. Conclusion: The cortical response induced by ultrasound thalamus stimulation is related to the anesthesia level. TUS on the thalamus combined with ECoG (TUS-ECoG) may be a potential non-invasive neuromodulation approach for understanding consciousness. Significance: This work supplied further implications on the neuromodulatory mechanisms and evaluative applications of TUS under general anesthesia.",
      "author": "",
      "published_date": "2025-03-28T13:20:15+00:00",
      "source": "Transactions Biomedical Engineering",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 252,
      "reading_time": 1,
      "created_at": "2025-10-06T05:41:13.656714+00:00",
      "updated_at": "2025-10-06T05:41:13.656716+00:00"
    },
    {
      "id": "a7fb9c9ee1a93dc6f78a5b81eaf19fb7",
      "url": "http://ieeexplore.ieee.org/document/10944577",
      "title": "Pulmonary Hypertension Detection From Heart Sound Analysis",
      "content": "The detection of Pulmonary Hypertension (PH) from the computer analysis of digitized heart sounds is a low-cost and non-invasive solution for early PH detection and screening. We present an extensive cross-domain evaluation methodology with varying animals (humans and porcine animals) and varying auscultation technologies (phonocardiography and seisomocardiography) evaluated across four methods. We introduce PH-ELM, a resource-efficient PH detection model based on the extreme learning machine that is smaller ($300\\times$ fewer parameters), energy efficient ($532\\times$ fewer watts of power), faster ($36\\times$ faster to train, $44\\times$ faster at inference), and more accurate on out-of-distribution testing (improves median accuracy by 0.09 area under the ROC curve (auROC)) in comparison to a previously best performing deep network. We make four observations from our analysis: (a) digital auscultation is a promising technology for the detection of pulmonary hypertension; (b) seismocardiography (SCG) signals and phonocardiography (PCG) signals are interchangeable to train PH detectors; (c) porcine heart sounds in the training data can be used to evaluate PH from human heart sounds (the PH-ELM model preserves 88 to 95% of the best in-distribution baseline performance); (d) predictive performance of PH detection can be mostly preserved with as few as 10 heartbeats and capturing up to approximately 200 heartbeats per subject can improve performance.",
      "author": "",
      "published_date": "2025-03-28T13:20:15+00:00",
      "source": "Transactions Biomedical Engineering",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 206,
      "reading_time": 1,
      "created_at": "2025-10-06T05:41:13.656677+00:00",
      "updated_at": "2025-10-06T05:41:13.656679+00:00"
    }
  ],
  "recently_processed": [
    {
      "id": "3352595883ccb35de24e20a19b774dd2",
      "url": "https://brain.ieee.org/braininsight-articles/ieee-journal-on-flexible-electronics/",
      "title": "Call for Papers: IEEE Brain Special Issue",
      "content": "In a unique interdisciplinary collaboration with the IEEE\u2019s Society on Social Implications of Technology (SSIT) and IEEE Brain, J-FLEX is joining forces to explore both the technology of the Internet-of-Medical-Things (IoMT) solutions and medical wearables/implantables. &#160;",
      "author": "ieeebrain",
      "published_date": "2025-03-03T17:16:40+00:00",
      "source": "Brain",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 36,
      "reading_time": 1,
      "created_at": "2025-10-06T05:41:18.008219+00:00",
      "updated_at": "2025-10-06T06:22:10.919992+00:00",
      "metadata": {
        "processed_at": "2025-10-06T06:22:10.920002+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "626415b9abcab4a79433d23aa150042f",
      "url": "https://brain.ieee.org/braininsight-articles/ieee-brain-joins-the-american-brain-coalition-as-a-nonprofit-member/",
      "title": "IEEE Brain Joins the American Brain Coalition",
      "content": "IEEE Brain is pleased to announce its acceptance as a nonprofit member of the American Brain Coalition (ABC), a prestigious alliance of over 150 organizations dedicated to advancing brain research, advocacy, and improving treatments for individuals affected by brain conditions. The ABC Board has enthusiastically welcomed IEEE Brain into its network, reinforcing a shared commitment to fostering innovation and collaboration ...",
      "author": "ieeebrain",
      "published_date": "2025-03-03T17:22:08+00:00",
      "source": "Brain",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 61,
      "reading_time": 1,
      "created_at": "2025-10-06T05:41:18.008194+00:00",
      "updated_at": "2025-10-06T06:22:10.920006+00:00",
      "metadata": {
        "processed_at": "2025-10-06T06:22:10.920008+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "ac6f3ab92725084e2b49600ca6243d2a",
      "url": "https://brain.ieee.org/braininsight-articles/call-for-papers-ieee-transactions-on-human-machine-systems/",
      "title": "Call for Papers: IEEE Transactions on Human-Machine Systems",
      "content": "Special Issue on Brain Discovery and Neurotechnology: Featured Research from 2024 IEEE Brain Discovery &#38; Neurotechnology Workshop\u00a0 &#160; This special issue is motivated by the success of the IEEE Brain Discovery and Neurotechnology Workshop held in October 2024. This annual workshop is sponsored by the IEEE Brain Technical Community. It is intended to foster interactions among researchers and clinical practitioners ...",
      "author": "Adriel Carridice",
      "published_date": "2025-06-18T14:50:14+00:00",
      "source": "Brain",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 61,
      "reading_time": 1,
      "created_at": "2025-10-06T05:41:18.008164+00:00",
      "updated_at": "2025-10-06T06:22:10.920010+00:00",
      "metadata": {
        "processed_at": "2025-10-06T06:22:10.920012+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "16712c82fde7bee131cf339ae97552f5",
      "url": "http://ieeexplore.ieee.org/document/10994678",
      "title": "Evaluation on Human Perception of Various Vibrotactile Encoding Methods Through a High Density Haptic Feedback Interface",
      "content": "High density (HD) haptic interfaces have become increasingly common for entertainment thanks to advancements in virtual reality technology, however their flexibility may make them a useful sensory substitution interface for motor rehabilitation. Yet little research has explored how users interpret different haptic feedback encoding methods. Therefore, this study's objective was to evaluate the effectiveness of various encoding methods for conveying information based on existing sensory substitution strategies, one being a line motion tracking task and the other a direction tracking task. The first encoding method was Perceived Position Encoding (PPE), where information was encoded into the perceived position of stimulation. The second was Perceived Intensity Encoding (PIE), encoded information into the perceived amplitude of the stimuli. Twenty-one participants performed tracking tasks using both the PIE and PPE methods. The results showed similar performance in line motion tracking between the PIE and PPE methods, although the extra motors used in the PPE method appear to introduce uncertainty in users. Nevertheless, users were significantly more accurate with direction tracking when using PPE. These findings highlight the need for task-specific encoding methods, and showcase the versatility of the HD haptic vest as a tool for augmented feedback in motor rehabilitation.",
      "author": "",
      "published_date": "2025-05-09T13:16:51+00:00",
      "source": "Transactions Haptics",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 197,
      "reading_time": 1,
      "created_at": "2025-10-06T05:41:16.111996+00:00",
      "updated_at": "2025-10-06T06:22:10.920014+00:00",
      "metadata": {
        "processed_at": "2025-10-06T06:22:10.920016+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "bbe0f805e4fabfb0ac2476417484aef4",
      "url": "http://ieeexplore.ieee.org/document/10946856",
      "title": "Enhancing Video Experiences for DHH Individuals Through Sound-Inspired Motion Caption-Based Spatiotemporal Tacton",
      "content": "When deaf and hard of hearing (DHH) individuals watch videos, captions are essential for them to understand the linguistic content. Current captions, however, are not suitable for conveying non-verbal sound information, such as background music, sound effects, or speech nuances. In this paper, we designed a multimodal system, Motion Caption Haptic System (MCHS), that enables DHH individuals to encounter sounds in videos through animated caption and spatiotemporal vibration patterns, supporting a more vivid and immersive experience. We elaborately designed motion captions and spatiotemporal haptic patterns for representative sound effects and spoken emotions to work well together through surveys from 27 DHH and 64 hearing participants. An evaluation with 19 DHH individuals demonstrated the capabilities and potential of the MCHS to improve their video viewing experience, along with a discussion of important issues that need to be addressed when designing multimodal captioning systems for the DHH viewers.",
      "author": "",
      "published_date": "2025-04-01T13:17:18+00:00",
      "source": "Transactions Haptics",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 146,
      "reading_time": 1,
      "created_at": "2025-10-06T05:41:16.111964+00:00",
      "updated_at": "2025-10-06T06:22:10.920018+00:00",
      "metadata": {
        "processed_at": "2025-10-06T06:22:10.920019+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "62b33c8c35269d32a56b51c7891f8cd1",
      "url": "http://ieeexplore.ieee.org/document/11153361",
      "title": "Electroencephalographic Functional Connectivity, Heartrate Synchrony, and Eye Movements Reveal Distinct Components within Narrative Engagement and Immersion",
      "content": "Storytelling is a fundamental and universal human behavior, representing a vehicle for cultural information exchange throughout human history. In the present day, consumption of narrative audiovisual media is one of the most common recreational activities worldwide. Despite the importance and ubiquity of storytelling, relatively little is known about the neurocognitive mechanisms by which narrative media capture and sustain our attention. In this study, 40 participants watched 10 short clips from television shows of various genres while electroencephalography, eye tracking, heart rate, and self-report data were recorded. Self-reported immersion and three of the four components of narrative engagement that we examined\u2014attentional focus, emotional engagement, and narrative presence\u2014were associated with interindividual synchrony in heart rate and gaze behavior, but were associated with relatively distinct patterns of neural activity (electroencephalography power amplitude and functional connectivity). Narrative understanding, on the other hand, was not associated with heart rate or gaze synchrony. Furthermore, structural equation modeling revealed directionally opposing relationships between overall alpha-band connectivity and narrative presence on the one hand (positive), and narrative understanding (negative) on the other. These results suggest narrative understanding may be associated with a different set of neurocognitive processes to the other dimensions of narrative engagement. These findings point toward a bifurcated model of narrative engagement and raise interesting theoretical questions about the role of narrative comprehension in this process.",
      "author": "",
      "published_date": "2025-09-08T13:16:44+00:00",
      "source": "Cognitive Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 220,
      "reading_time": 1,
      "created_at": "2025-10-06T03:35:10.381603+00:00",
      "updated_at": "2025-10-06T04:17:28.489287+00:00",
      "metadata": {
        "processed_at": "2025-10-06T04:17:28.489298+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "d50017c01d1cea4b149c811378d33224",
      "url": "http://ieeexplore.ieee.org/document/11153352",
      "title": "Object Ownership Processing in Peripersonal Space: An Electroencephalographic Study",
      "content": "A fundamental aspect of interacting with objects in the environment is the ability to distinguish between objects that can be directly acted upon in the peripersonal space (PPS) and those out of immediate reach in the extrapersonal space (EPS). Performing appropriate actions also requires integrating social conceptual information related to who owns a particular object. While prior research has demonstrated that spatial and social factors influence object processing, how these factors are integrated is not yet fully understood. To address this issue, the present study explored the neurophysiological correlates of object ownership processing when objects were located in either the PPS or EPS. Facing a virtual character, 28 participants estimated the reachability of self-owned or other-owned objects, placed at different distances. The analysis confirmed that self-owned objects are processed faster when located in PPS, and other-owned objects are processed faster when located in EPS. EEG signals analysis revealed that early ERP components, such as the N1 and anterior N2, were modulated solely by objects' spatial location. In contrast, later components, including the P3 and anterior N400, were influenced by object ownership, although depending on object's location in space. These results suggest an early perceptual prioritization of objects in the PPS and a prioritization of objects that engages the self at a postperceptual stage. Overall, the findings provide new insights into how objects are processed depending on their spatial and social properties, and confirm that virtual reality represents a promising tool to probe neural mechanisms supporting perception and action in social contexts.",
      "author": "",
      "published_date": "2025-09-08T13:16:40+00:00",
      "source": "Cognitive Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 251,
      "reading_time": 1,
      "created_at": "2025-10-06T03:35:10.381565+00:00",
      "updated_at": "2025-10-06T04:17:28.489302+00:00",
      "metadata": {
        "processed_at": "2025-10-06T04:17:28.489303+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "0935313f19774a2f7dddae3f96606656",
      "url": "http://ieeexplore.ieee.org/document/11153355",
      "title": "Neural Signatures of Recollection Are Sensitive to Memory Quality and Specific Event Features",
      "content": "Episodic memories reflect a bound representation of multimodal features that can be recollected with varying levels of precision. Recent fMRI investigations have demonstrated that the precision and content of information retrieved from memory engage a network of posterior medial-temporal and parietal regions co-activated with the hippocampus. Yet, comparatively, little is known about how memory content and precision affect common neural signatures of memory captured by EEG, where recollection has been associated with changes in ERP and oscillatory measures of neural activity. Here, we used a multifeature paradigm previously reported [Cooper, R. A., & Ritchey, M. Cortico-hippocampal network connections support the multidimensional quality of episodic memory. eLife, 8, e45591, 2019] with continuous measures of memory, in conjunction with scalp EEG, to characterize the content and quality of information that drives ERP and oscillatory markers of episodic memory. A common signature of memory retrieval in the left posterior regions, called the late positive component, was sensitive to overall memory quality and also to precision of recollection for spatial features. The analysis of oscillatory markers during recollection revealed that alpha/beta desynchronization was modulated by overall memory quality and also by individual features in memory. Importantly, we found evidence of a relationship between these two neural markers of memory retrieval, suggesting that they may represent complementary aspects of the recollection experience. These findings demonstrate how time-sensitive and dynamic processes identified with EEG correspond to overall episodic recollection and also to the retrieval of precise features in memory.",
      "author": "",
      "published_date": "2025-09-08T13:16:44+00:00",
      "source": "Cognitive Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 243,
      "reading_time": 1,
      "created_at": "2025-10-06T03:35:10.381528+00:00",
      "updated_at": "2025-10-06T04:17:28.489306+00:00",
      "metadata": {
        "processed_at": "2025-10-06T04:17:28.489307+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "9fe9c99db697786e3f69c006b914b51d",
      "url": "http://ieeexplore.ieee.org/document/11153362",
      "title": "Transient and Sustained Neuromagnetic Representation of Consonance and Dissonance in Harmonic Sequences",
      "content": "The perception of musical consonance/dissonance (C/D) relies on basic properties of the auditory system, and prior investigations have shown that C/D sounds elicit strongly divergent neurophysiological activity in human auditory cortex. However, studies are missing that assess transient (P1, N1, P2) and sustained cortical C/D representations within a harmonic context, together with the corresponding patterns of neural adaptation. The present magnetoencephalography experiment applied spatio-temporal source analysis to study the early transient and sustained neuromagnetic processing of C/D at the start and within brief harmonic sequences. A total of n = 40 adult listeners (among them numerous amateur musicians) participated in the experiment; the harmonic sequences comprised different blends of C/D dyads with balanced probabilities, in an effort to access simple C/D relations and neural adaptation at an early stage of the processing hierarchy. Consistent with earlier findings, the transient cortical activity was found to reflect vertical (i.e., absolute) C/D aspects in response to the sequence's first dyad, but it mirrored more horizontal aspects (i.e., C/D relations) at the subsequent dyad transitions; moreover, the neuromagnetic responses (particularly, the N1 and P2 waves) exhibited adaptation with different time constants, parts of which pertained to C/D-associated processing. Surprisingly, only few observations appeared to be influenced by the listener's musical expertise, likely due to the high overall level of musicality in our sample. In summary, our data indicate that early neuromagnetic activity reflects not only vertical, but also horizontal, aspects of C/D perception, together with corresponding adaptive mechanisms.",
      "author": "",
      "published_date": "2025-09-08T13:16:44+00:00",
      "source": "Cognitive Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 244,
      "reading_time": 1,
      "created_at": "2025-10-06T03:35:10.381490+00:00",
      "updated_at": "2025-10-06T04:17:28.489309+00:00",
      "metadata": {
        "processed_at": "2025-10-06T04:17:28.489311+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "3126a4e56a81b2be3ee1af1e1e87dffc",
      "url": "http://ieeexplore.ieee.org/document/11153357",
      "title": "An Emergentist Account of Language in the Brain\u2014Seeking Neural Synergies Behind Human Uniqueness",
      "content": "Cognitive neuroscience has become increasingly open to views of human cognitive faculties as emergent properties\u2014as higher-level products of synergies between brain structures handling qualitatively different functions. This new perspective mitigates claims that cognitive abilities are tied to localized, domain-specific brain systems. In this changing landscape, the neurobiology of language has lagged behind, with virtually no mature theory apt to guide an exploration of language as an emergent function of the human brain. Combining evidence that linguistic processing is distributed across neurocognitive systems supporting (among others) semantic cognition, executive functions, and articulatory-motor control with recent advances in studying neural synergies, we propose a model of language as a deeply synergistic phenomenon that is both decoupled from its lower-level constituents and capable of exerting downward causal powers over them, accounting for its key role in human adaptive behavior. In considering the implications it has in our understanding of the place of language within the broader infrastructure of human behavior, this novel perspective aims to move the neurobiology of language forward in a new era of the cognitive neuroscience.",
      "author": "",
      "published_date": "2025-09-08T13:16:44+00:00",
      "source": "Cognitive Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 176,
      "reading_time": 1,
      "created_at": "2025-10-06T03:35:10.381453+00:00",
      "updated_at": "2025-10-06T04:17:28.489316+00:00",
      "metadata": {
        "processed_at": "2025-10-06T04:17:28.489317+00:00",
        "processing_method": "github_actions"
      }
    }
  ]
}