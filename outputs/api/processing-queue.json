{
  "last_updated": "2026-01-19T06:31:28.956857+00:00",
  "pending_count": 683,
  "processed_count": 317,
  "pending_articles": [
    {
      "id": "54baf09f2fc7cd3930ec355e72dda99f",
      "url": "https://arxiv.org/abs/2601.11049",
      "title": "Predicting Biased Human Decision-Making with Large Language Models in Conversational Settings",
      "content": "arXiv:2601.11049v1 Announce Type: new \nAbstract: We examine whether large language models (LLMs) can predict biased decision-making in conversational settings, and whether their predictions capture not only human cognitive biases but also how those effects change under cognitive load. In a pre-registered study (N = 1,648), participants completed six classic decision-making tasks via a chatbot with dialogues of varying complexity. Participants exhibited two well-documented cognitive biases: the Framing Effect and the Status Quo Bias. Increased dialogue complexity resulted in participants reporting higher mental demand. This increase in cognitive load selectively, but significantly, increased the effect of the biases, demonstrating the load-bias interaction. We then evaluated whether LLMs (GPT-4, GPT-5, and open-source models) could predict individual decisions given demographic information and prior dialogue. While results were mixed across choice problems, LLM predictions that incorporated dialogue context were significantly more accurate in several key scenarios. Importantly, their predictions reproduced the same bias patterns and load-bias interactions observed in humans. Across all models tested, the GPT-4 family consistently aligned with human behavior, outperforming GPT-5 and open-source models in both predictive accuracy and fidelity to human-like bias patterns. These findings advance our understanding of LLMs as tools for simulating human decision-making and inform the design of conversational agents that adapt to user biases.",
      "author": "Stephen Pilli, Vivek Nallur",
      "published_date": "2026-01-19T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 208,
      "reading_time": 1,
      "created_at": "2026-01-19T05:33:28.762220+00:00",
      "updated_at": "2026-01-19T05:33:28.762222+00:00"
    },
    {
      "id": "841988df0f4e7830ecd2f2043cf4130e",
      "url": "https://arxiv.org/abs/2601.11043",
      "title": "Haptic Light-Emitting Diodes: Miniature, Luminous Tactile Actuators",
      "content": "arXiv:2601.11043v1 Announce Type: new \nAbstract: We present Haptic Light-Emitting Diodes (HLEDs), luminous thermopneumatic actuators that directly convert pulsed light into mechanical forces and displacements. Each device packages a miniature surface-mount LED in a gas-filled cavity that contains a low-inertia graphite photoabsorber. The cavity is sealed by an elastic membrane, which functions as a working diaphragm. Brief optical pulses heat the photoabsorber, which heats the gas. The resulting rapid pressure increases generate forces and displacements at the working diaphragm. Millimeter-scale HLEDs produce forces exceeding 0.4 N and displacements of 1 mm at low voltages, with 5 to 100 ms response times, making them attractive as actuators providing tactile feedback in human-machine interfaces. Perceptual testing revealed that the strength of tactile feedback increased linearly with optical power. HLEDs devices are mechanically simple and efficient to fabricate. Unusually, these actuators are also light-emitting, as a fraction of optical energy is transmitted through the membrane. These opto-mechanical actuators have many potential applications in tactile displays, human interface engineering, wearable computing, and other areas.",
      "author": "Max Linnander, Yon Visell",
      "published_date": "2026-01-19T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 169,
      "reading_time": 1,
      "created_at": "2026-01-19T05:33:28.762186+00:00",
      "updated_at": "2026-01-19T05:33:28.762187+00:00"
    },
    {
      "id": "e99a3418564be8509dc5fc279eefe42b",
      "url": "https://arxiv.org/abs/2601.10957",
      "title": "\"I'm Constantly Getting Comments Like, 'Oh, You're Blind. You're Like the Only Woman That I Stand a Chance With.'\": A Study of Blind TikTokers' Intersectional Experiences of Gender and Sexuality",
      "content": "arXiv:2601.10957v1 Announce Type: new \nAbstract: Social media platforms are important venues for identity expression, and the Human-Computer Interaction community has been paying growing attention to how marginalized groups express their identities on these platforms. Joining the emerging literature on intersectional experiences, we study blind TikTokers (\"BlindTokers\") who are also women and/or LGBTQ+. Using interview data from \\rev{41} participants, we identify their intersectional experiences as mediated by TikTok's socio-technical affordances. We argue that BlindTokers' intersectional marginalization is infrastructural: TikTok's classification and moderation features interact with social norms in ways that push them aside and distort how they are treated on the platform. We use this infrastructure perspective to understand what these experiences are, how they were formed, and how they become harmful. We further recognize participants' infrastructuring work to address these problems. This study guides future social media design with accessible creator tools, inclusive identity options, and context-aware moderation developed in partnership with communities.",
      "author": "Yao Lyu, Jessica Shen, Alina Faisal, John M. Carroll",
      "published_date": "2026-01-19T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 153,
      "reading_time": 1,
      "created_at": "2026-01-19T05:33:28.762154+00:00",
      "updated_at": "2026-01-19T05:33:28.762156+00:00"
    },
    {
      "id": "7c82f8739d5e13e8f991338dfa0d3606",
      "url": "https://arxiv.org/abs/2601.10956",
      "title": "\"My Brother Is a School Principal, Earns About $80,000 Per Year... But When the Kids See Me, 'Wow, Uncle, You Have 1500 Followers on TikTok!'\": A Study of Blind TikTokers' Alternative Professional Development Experiences",
      "content": "arXiv:2601.10956v1 Announce Type: new \nAbstract: One's profession is an essential part of modern life. Traditionally, professional development has been criticized for excluding people with disabilities. People with visual impairments, for example, face disproportionately low employment rates, highlighting persistent gaps in professional opportunities. Recently, there has been growing research on social media platforms as spaces for more equitable career development approaches. In this paper, we present an interview study on the professional development experiences of 60 people with visual impairments on TikTok (also known as \"BlindTokers\"). We report BlindTokers' goals, strategies, and challenges, supported by detailed examples and in-depth analysis. Based on the findings, we identify that BlindTokers' practices reveal an alternative professional development approach that is more flexible, inclusive, personalized, and diversified than traditional models. Our study also extends professional development research by foregrounding emerging digital skills and proposing design implications to foster more equitable and inclusive professional opportunities.",
      "author": "Yao Lyu, Tawanna Dillahunt, Jiaying Liu, John M. Carroll",
      "published_date": "2026-01-19T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 149,
      "reading_time": 1,
      "created_at": "2026-01-19T05:33:28.762123+00:00",
      "updated_at": "2026-01-19T05:33:28.762125+00:00"
    },
    {
      "id": "a29c03203e3effdcf790e0c0c0b0cb29",
      "url": "https://arxiv.org/abs/2601.10824",
      "title": "Bridging Psychological Safety and Skill Guidance: An Adaptive Robotic Interview Coach",
      "content": "arXiv:2601.10824v1 Announce Type: new \nAbstract: Social robots hold promise for reducing job interview anxiety, yet designing agents that provide both psychological safety and instructional guidance remains challenging. Through a three-phase iterative design study (N = 8), we empirically mapped this tension. Phase I revealed a \"Safety-Guidance Gap\": while a Person-Centered Therapy (PCT) robot established safety (d = 3.27), users felt insufficiently coached. Phase II identified a \"Scaffolding Paradox\": rigid feedback caused cognitive overload, while delayed feedback lacked specificity. In Phase III, we resolved these tensions by developing an Agency-Driven Interaction Layer. Synthesizing our empirical findings, we propose the Adaptive Scaffolding Ecosystem, a conceptual framework that redefines robotic coaching not as a static script, but as a dynamic balance between affective support and instructional challenge, mediated by user agency.",
      "author": "Wanqi Zhang, Jiangen He, Marielle Santos",
      "published_date": "2026-01-19T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 128,
      "reading_time": 1,
      "created_at": "2026-01-19T05:33:28.762087+00:00",
      "updated_at": "2026-01-19T05:33:28.762091+00:00"
    },
    {
      "id": "27cb4b3993cbfaea8521647d41020180",
      "url": "https://arxiv.org/abs/2508.08435",
      "title": "Fast weight programming and linear transformers: from machine learning to neurobiology",
      "content": "arXiv:2508.08435v4 Announce Type: replace-cross \nAbstract: Recent advances in artificial neural networks for machine learning, and language modeling in particular, have established a family of recurrent neural network (RNN) architectures that, unlike conventional RNNs with vector-form hidden states, use two-dimensional (2D) matrix-form hidden states. Such 2D-state RNNs, known as Fast Weight Programmers (FWPs), can be interpreted as a neural network whose synaptic weights (called fast weights) dynamically change over time as a function of input observations, and serve as short-term memory storage; corresponding synaptic weight modifications are controlled or programmed by another network (the programmer) whose parameters are trained (e.g., by gradient descent). In this Primer, we review the technical foundations of FWPs, their computational characteristics, and their connections to transformers and state space models. We also discuss connections between FWPs and models of synaptic plasticity in the brain, suggesting a convergence of natural and artificial intelligence.",
      "author": "Kazuki Irie, Samuel J. Gershman",
      "published_date": "2026-01-19T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 146,
      "reading_time": 1,
      "created_at": "2026-01-19T05:33:27.695859+00:00",
      "updated_at": "2026-01-19T05:33:27.695861+00:00"
    },
    {
      "id": "ebc9bb0eb717e28a4cc12217783ee5d5",
      "url": "https://arxiv.org/abs/2509.15832",
      "title": "Overcoming Output Dimension Collapse: When Sparsity Enables Zero-shot Brain-to-Image Reconstruction at Small Data Scales",
      "content": "arXiv:2509.15832v2 Announce Type: replace \nAbstract: Advances in brain-to-image reconstruction are enabling us to externalize the subjective visual experiences encoded in the brain as images. A key challenge in this task is data scarcity: a translator that maps brain activity to latent image features is trained on a limited number of brain-image pairs, making the translator a bottleneck for zero-shot reconstruction beyond the training stimuli. In this paper, we provide a theoretical analysis of two translator designs widely used in recent reconstruction pipelines: naive multivariate linear regression and sparse multivariate linear regression. We define the data scale as the ratio of the number of training samples to the latent feature dimensionality and characterize the behavior of each model across data scales. We first show that the naive linear regression model, which uses a shared set of input variables for all outputs, suffers from ``output dimension collapse'' at small data scales, restricting generalization beyond the training data. We then analyze sparse linear regression models in a student--teacher framework and derive expressions for the prediction error in terms of data scale and other sparsity-related parameters. Our analysis clarifies when variable selection can reduce prediction error at small data scales by exploiting the sparsity of the brain-to-feature mapping. Our findings provide quantitative guidelines for diagnosing output dimension collapse and for designing effective translators and feature representations for zero-shot reconstruction.",
      "author": "Kenya Otsuka, Yoshihiro Nagano, Yukiyasu Kamitani",
      "published_date": "2026-01-19T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 225,
      "reading_time": 1,
      "created_at": "2026-01-19T05:33:27.695822+00:00",
      "updated_at": "2026-01-19T05:33:27.695823+00:00"
    },
    {
      "id": "e94e7fa7d4b2653cd98c65aa2c9404b4",
      "url": "https://arxiv.org/abs/2506.21828",
      "title": "Fetal Sleep: A Cross-Species Review of Physiology, Measurement, and Classification",
      "content": "arXiv:2506.21828v2 Announce Type: replace \nAbstract: Study Objectives: Fetal sleep is a vital yet underexplored aspect of prenatal neurodevelopment. Its cyclic organization reflects the maturation of central neural circuits, and disturbances in these patterns may offer some of the earliest detectable signs of neurological compromise. This is the first review to integrate more than seven decades of research into a unified, cross-species synthesis of fetal sleep. We examine: (i) Physiology and Ontogeny-comparing human fetuses with animal models; and (ii) Methodological Evolution-transitioning from invasive neurophysiology to non-invasive monitoring and deep learning frameworks.\n  Methods: A structured narrative synthesis was guided by a systematic literature search across four databases (PubMed, Scopus, IEEE Xplore, and Google Scholar). From 2,925 identified records, 171 studies involving fetal sleep-related physiology, sleep-state classification, or signal-based monitoring were included in this review.\n  Results: Across the 171 studies, fetal sleep states become clearly observable as the brain matures. In fetal sheep and baboons, organized cycling between active and quiet sleep emerges at approximately 80%-90% gestation. In humans, this differentiation occurs later, around 95% gestation, with full maturation reached near term. Despite extensive animal research, no unified, clinically validated framework exists for defining fetal sleep states, limiting translation into routine obstetric practice.\n  Conclusions: By integrating evidence across species, methodologies, and clinical contexts, this review provides the scientific foundation for developing objective, multimodal, and non-invasive fetal sleep monitoring technologies-tools that may ultimately support earlier detection of neurological compromise and guide timely prenatal intervention.",
      "author": "Weitao Tang, Johann Vargas-Calixto, Nasim Katebi, Robert Galinsky, Gari D. Clifford, Faezeh Marzbanrad",
      "published_date": "2026-01-19T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 240,
      "reading_time": 1,
      "created_at": "2026-01-19T05:33:27.695789+00:00",
      "updated_at": "2026-01-19T05:33:27.695790+00:00"
    },
    {
      "id": "0da10b0511ba7c62b36cf2e863d3a061",
      "url": "https://arxiv.org/abs/2412.04172",
      "title": "Neuromodulation and homeostasis: complementary mechanisms for robust neural function",
      "content": "arXiv:2412.04172v2 Announce Type: replace \nAbstract: Neurons depend on two interdependent mechanisms-homeostasis and neuromodulation-to maintain robust and adaptable functionality. Homeostasis stabilizes neuronal activity by adjusting ionic conductances, whereas neuromodulation dynamically modifies ionic properties in response to external signals. Combining these mechanisms in conductance-based models often produces unreliable outcomes, particularly when sharp neuromodulation interferes with homeostatic tuning. This study explores how a biologically inspired neuromodulation controller can harmonize with homeostasis to ensure reliable neuronal function. Using computational models of stomatogastric ganglion and dopaminergic neurons, we demonstrate that controlled neuromodulation preserves neuronal firing patterns while maintaining intracellular calcium levels. Unlike sharp neuromodulation, the neuromodulation controller integrates activity-dependent feedback through mechanisms mimicking G-protein-coupled receptor cascades. The interaction between these controllers critically depends on the existence of an intersection in conductance space, representing a balance between target calcium levels and neuromodulated firing patterns. Maximizing neuronal degeneracy enhances the likelihood of such intersections, enabling robust modulation and compensation for channel blockades. We further show that this controller pairing extends to network-level activity, reliably modulating central pattern generators in crustaceans. These findings suggest that targeting neuromodulation pathways-rather than ion channels directly-may offer safer pharmacological strategies to manage neuronal dysfunctions. This study highlights the complementary roles of homeostasis and neuromodulation, proposing a unified control framework for maintaining robust and adaptive neural activity under physiological and pathological conditions.",
      "author": "Arthur Fyon, Guillaume Drion",
      "published_date": "2026-01-19T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 219,
      "reading_time": 1,
      "created_at": "2026-01-19T05:33:27.695754+00:00",
      "updated_at": "2026-01-19T05:33:27.695755+00:00"
    },
    {
      "id": "2b17ec68efc698d797afe962c7a67c85",
      "url": "https://arxiv.org/abs/2601.11108",
      "title": "Simple Models, Rich Representations: Visual Decoding from Primate Intracortical Neural Signals",
      "content": "arXiv:2601.11108v1 Announce Type: new \nAbstract: Understanding how neural activity gives rise to perception is a central challenge in neuroscience. We address the problem of decoding visual information from high-density intracortical recordings in primates, using the THINGS Ventral Stream Spiking Dataset. We systematically evaluate the effects of model architecture, training objectives, and data scaling on decoding performance. Results show that decoding accuracy is mainly driven by modeling temporal dynamics in neural signals, rather than architectural complexity. A simple model combining temporal attention with a shallow MLP achieves up to 70% top-1 image retrieval accuracy, outperforming linear baselines as well as recurrent and convolutional approaches. Scaling analyses reveal predictable diminishing returns with increasing input dimensionality and dataset size. Building on these findings, we design a modular generative decoding pipeline that combines low-resolution latent reconstruction with semantically conditioned diffusion, generating plausible images from 200 ms of brain activity. This framework provides principles for brain-computer interfaces and semantic neural decoding.",
      "author": "Matteo Ciferri, Matteo Ferrante, Nicola Toschi",
      "published_date": "2026-01-19T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 156,
      "reading_time": 1,
      "created_at": "2026-01-19T05:33:27.695719+00:00",
      "updated_at": "2026-01-19T05:33:27.695721+00:00"
    }
  ],
  "recently_processed": [
    {
      "id": "f113c1f40f68774b237147f08d8c7c0a",
      "url": "https://arxiv.org/abs/2601.11218",
      "title": "Game Accessibility Through Shared Control for People With Upper-Limb Impairments",
      "content": "arXiv:2601.11218v1 Announce Type: new \nAbstract: Accessing video games is challenging for people with upper-limb impairments, especially when multiple inputs are required in rapid succession. Human cooperation, where a copilot assists the main player, has been proposed as a solution, but relying on a human assistant poses limitations in terms of availability and co-location. An alternative solution is to use partial automation, where the player is assisted by a software agent. In this work, we present a study with 13 participants with upper-limb impairments, comparatively evaluating how participants collaborate with their copilot in human cooperation and partial automation. The experiment is supported by GamePals, a modular framework that enables both human cooperation and partial automation on existing third-party video games.",
      "author": "Sergio Mascetti, Matteo Manzoni, Filippo Corti, Dragan Ahmetovic",
      "published_date": "2026-01-19T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 119,
      "reading_time": 1,
      "created_at": "2026-01-19T05:33:28.762384+00:00",
      "updated_at": "2026-01-19T06:31:28.860220+00:00",
      "metadata": {
        "processed_at": "2026-01-19T06:31:28.860245+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "1e5fce3332fc4cd5b51f584a895bac55",
      "url": "https://arxiv.org/abs/2601.11171",
      "title": "Noisy Graph Patterns via Ordered Matrices",
      "content": "arXiv:2601.11171v1 Announce Type: new \nAbstract: The high-level structure of a graph is a crucial ingredient for the analysis and visualization of relational data. However, discovering the salient graph patterns that form this structure is notoriously difficult for two reasons. (1) Finding important patterns, such as cliques and bicliques, is computationally hard. (2) Real-world graphs contain noise, and therefore do not always exhibit patterns in their pure form. Defining meaningful noisy patterns and detecting them efficiently is a currently unsolved challenge. In this paper, we propose to use well-ordered matrices as a tool to both define and effectively detect noisy patterns. Specifically, we represent a graph as its adjacency matrix and optimally order it using Moran's $I$. Standard graph patterns (cliques, bicliques, and stars) now translate to rectangular submatrices. Using Moran's $I$, we define a permitted level of noise for such patterns. A combination of exact algorithms and heuristics allows us to efficiently decompose the matrix into noisy patterns. We also introduce a novel motif simplification that visualizes noisy patterns while explicitly encoding the level of noise. We showcase our techniques on several real-world data sets.",
      "author": "Jules Wulms, Wouter Meulemans, Bettina Speckmann",
      "published_date": "2026-01-19T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 185,
      "reading_time": 1,
      "created_at": "2026-01-19T05:33:28.762358+00:00",
      "updated_at": "2026-01-19T06:31:28.860249+00:00",
      "metadata": {
        "processed_at": "2026-01-19T06:31:28.860251+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "78731ea080a68e9c32adb7e279352f6e",
      "url": "https://arxiv.org/abs/2601.11103",
      "title": "AI Twin: Enhancing ESL Speaking Practice through AI Self-Clones of a Better Me",
      "content": "arXiv:2601.11103v1 Announce Type: new \nAbstract: Advances in AI have enabled ESL learners to practice speaking through conversational systems. However, most tools rely on explicit correction, which can interrupt the conversation and undermine confidence. Grounded in second language acquisition and motivational psychology, we present AI Twin, a system that rephrases learner utterances into more fluent English and delivers them in the learner's voice. Embodying a more confident and proficient version of the learner, AI Twin reinforces motivation through alignment with their aspirational Ideal L2 Self. Also, its use of implicit feedback through rephrasing preserves conversational flow and fosters an emotionally supportive environment. In a within-subject study with 20 adult ESL learners, we compared AI Twin with explicit correction and a non-personalized rephrasing agent. Results show that AI Twin elicited higher emotional engagement, with participants describing the experience as more motivating. These findings highlight the potential of self-representative AI for personalized, psychologically grounded support in ESL learning.",
      "author": "Minju Park, Seunghyun Lee, Juhwan Ma, Dongwook Yoon",
      "published_date": "2026-01-19T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 155,
      "reading_time": 1,
      "created_at": "2026-01-19T05:33:28.762327+00:00",
      "updated_at": "2026-01-19T06:31:28.860253+00:00",
      "metadata": {
        "processed_at": "2026-01-19T06:31:28.860255+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "ee9e239e91a7e9f3ae47545bf319c3cf",
      "url": "https://arxiv.org/abs/2601.11072",
      "title": "More Human or More AI? Visualizing Human-AI Collaboration Disclosures in Journalistic News Production",
      "content": "arXiv:2601.11072v1 Announce Type: new \nAbstract: Within journalistic editorial processes, disclosing AI usage is currently limited to simplistic labels, which misses the nuance of how humans and AI collaborated on a news article. Through co-design sessions (N=10), we elicited 69 disclosure designs and implemented four prototypes that visually disclose human-AI collaboration in journalism. We then ran a within-subjects lab study (N=32) to examine how disclosure visualizations (Textual, Role-based Timeline, Task-based Timeline, Chatbot) and collaboration ratios (Primarily Human vs. Primarily AI) influenced visualization perceptions, gaze patterns, and post-experience responses. We found that textual disclosures were least effective in communicating human-AI collaboration, whereas Chatbot offered the most in-depth information. Furthermore, while role-based timelines amplified AI contribution in primarily human articles, task-based timeline shifted perceptions toward human involvement in primarily AI articles. We contribute Human-AI collaboration disclosure visualizations and their evaluation, and cautionary considerations on how visualizations can alter perceptions of AI's actual role during news article creation.",
      "author": "Amber Kusters, Pooja Prajod, Pablo Cesar, Abdallah El Ali",
      "published_date": "2026-01-19T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 154,
      "reading_time": 1,
      "created_at": "2026-01-19T05:33:28.762286+00:00",
      "updated_at": "2026-01-19T06:31:28.860257+00:00",
      "metadata": {
        "processed_at": "2026-01-19T06:31:28.860259+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "daac2decd938bb93fbd28e11a1153b34",
      "url": "https://arxiv.org/abs/2601.11060",
      "title": "Children's Expectations, Engagement, and Evaluation of an LLM-enabled Spherical Visualization Platform in the Classroom",
      "content": "arXiv:2601.11060v1 Announce Type: new \nAbstract: We present our first stage results from deploying an LLM-augmented visualization software in a classroom setting to engage primary school children with earth-related datasets. Motivated by the growing interest in conversational AI as a means to support inquiry-based learning, we investigate children's expectations, engagement, and evaluation of a spoken LLM interface with a shared, immersive visualization system in a formal educational context. Our system integrates a speech-capable large language model with an interactive spherical display. It enables children to ask natural-language questions and receive coordinated verbal explanations and visual responses through the LLM-augmented visualization updating in real time based on spoken queries. We report on a classroom study with Swedish children aged 9-10, combining structured observation and small-group discussions to capture expectations prior to interaction, interaction patterns during facilitated sessions, and children's reflections on their encounter afterward. Our results provide empirical insights into children's initial encounters with an LLM-enabled visualization platform within a classroom setting and their expectations, interactions, and evaluations of the system. These findings inform the technology's potential for educational use and highlight important directions for future research.",
      "author": "Emelie F\\\"alton, Isabelle Str\\\"omstedt, Mathis Brossier, Andreas G\\\"oransson, Konrad Sch\\\"onborn, Amy Loutfi, Erik Sunden, Mujtaba Fadhil Jawad, Yadgar Suleiman, Johanna Bj\\\"orklund, Mario Romero, Anders Ynnerman, Lonni Besan\\c{c}on",
      "published_date": "2026-01-19T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 185,
      "reading_time": 1,
      "created_at": "2026-01-19T05:33:28.762252+00:00",
      "updated_at": "2026-01-19T06:31:28.860261+00:00",
      "metadata": {
        "processed_at": "2026-01-19T06:31:28.860263+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "98c795ecc7af540b431020ec45da0e1d",
      "url": "https://iopscience.iop.org/article/10.1088/1741-2552/ae2955",
      "title": "sEEG-based brain-computer interfacing in a large adult and pediatric cohort",
      "content": "Objective. Stereoelectroencephalography (sEEG) is a mesoscale intracranial monitoring technique that records from the brain volumetrically with depth electrodes. sEEG is typically used for monitoring of epileptic foci, but can also serve as a useful tool to study distributed brain dynamics. Herein, we detail the implementation of sEEG-based brain-computer interfacing (BCI) across a diverse and large patient cohort. Approach. Across 27 subjects (15 female, 31 total feedback experiments), we identified channels with increases in broadband during hand, tongue, or foot movements using a simple block-design screening task. Subsequently, broadband power in these channels was coupled to continuous movement of a cursor on a screen during both overt movement and kinesthetic imagery. Main results. 26 subjects (29 out of 31 feedback conditions) established successful control, defined as more than 80 percent accuracy, during the overt movement BCI task, while only 12 (of the same 31 conditions) achieved control during the motor imagery BCI task. In successful imagery BCI, broadband power in the reinforced control channel(s) in the two target conditions separated into distinct subpopulations. Outside of the control channel(s), we demonstrate that imagery BCI engages unique subnetworks of the motor system compared to cued movement or kinesthetic imagery alone. Significance. Pericentral sEEG-based motor BCI utilizing overt movement and kinesthetic imagery is robust across a diverse patient cohort with inconsistent accuracy during imagined movement. Cued movement, kinesthetic imagery, and feedback engage the motor network uniquely, providing the opportunity to understand the network dynamics underlying BCI control and improve future BCIs.",
      "author": "Michael A Jensen, Gerwin Schalk, Nuri Ince, Dora Hermes, Greg A Worrell, Peter Brunner, Nathan P Staff and Kai J Miller",
      "published_date": "2025-12-30T00:00:00+00:00",
      "source": "Journal Neural Engineering",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 247,
      "reading_time": 1,
      "created_at": "2026-01-19T03:52:10.113764+00:00",
      "updated_at": "2026-01-19T04:47:24.162525+00:00",
      "metadata": {
        "processed_at": "2026-01-19T04:47:24.162536+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "7c35f09f1bfd2c6ea50a82a703f96a43",
      "url": "https://www.cl.cam.ac.uk/archive/rm135/Bigraphs-draft.pdf",
      "title": "The Space and Motion of Communicating Agents (2008) [pdf]",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46639897\">Comments</a>",
      "author": "",
      "published_date": "2026-01-15T21:55:36+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-19T03:51:47.803249+00:00",
      "updated_at": "2026-01-19T04:47:24.162540+00:00",
      "metadata": {
        "processed_at": "2026-01-19T04:47:24.162542+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "ff401b1fb5f5446c0b0841d311fc95f8",
      "url": "https://rijnard.com/blog/the-code-only-agent",
      "title": "The Code-Only Agent",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46674416\">Comments</a>",
      "author": "",
      "published_date": "2026-01-19T02:27:07+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-19T03:51:47.803230+00:00",
      "updated_at": "2026-01-19T04:47:24.162545+00:00",
      "metadata": {
        "processed_at": "2026-01-19T04:47:24.162546+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "ff401b1fb5f5446c0b0841d311fc95f8",
      "url": "https://rijnard.com/blog/the-code-only-agent",
      "title": "The Code-Only Agent",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46674416\">Comments</a>",
      "author": "",
      "published_date": "2026-01-19T02:27:07+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-19T03:51:47.803230+00:00",
      "updated_at": "2026-01-19T04:47:24.162545+00:00",
      "metadata": {
        "processed_at": "2026-01-19T04:47:24.162546+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "5a9bbd27b80e3e346cf63e1386458f86",
      "url": "https://www.alilleybrinker.com/mini/gas-town-decoded/",
      "title": "Gas Town Decoded",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46624883\">Comments</a>",
      "author": "",
      "published_date": "2026-01-14T22:39:33+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-19T03:51:47.803192+00:00",
      "updated_at": "2026-01-19T04:47:24.162549+00:00",
      "metadata": {
        "processed_at": "2026-01-19T04:47:24.162550+00:00",
        "processing_method": "github_actions"
      }
    }
  ]
}