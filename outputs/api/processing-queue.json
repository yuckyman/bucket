{
  "last_updated": "2025-10-10T22:13:13.567268+00:00",
  "pending_count": 985,
  "processed_count": 15,
  "pending_articles": [
    {
      "id": "6835349f348bec1ac060b82a8148764c",
      "url": "https://arxiv.org/abs/2510.07960",
      "title": "A Systematic Evaluation of Self-Supervised Learning for Label-Efficient Sleep Staging with Wearable EEG",
      "content": "arXiv:2510.07960v1 Announce Type: new \nAbstract: Wearable EEG devices have emerged as a promising alternative to polysomnography (PSG). As affordable and scalable solutions, their widespread adoption results in the collection of massive volumes of unlabeled data that cannot be analyzed by clinicians at scale. Meanwhile, the recent success of deep learning for sleep scoring has relied on large annotated datasets. Self-supervised learning (SSL) offers an opportunity to bridge this gap, leveraging unlabeled signals to address label scarcity and reduce annotation effort. In this paper, we present the first systematic evaluation of SSL for sleep staging using wearable EEG. We investigate a range of well-established SSL methods and evaluate them on two sleep databases acquired with the Ikon Sleep wearable EEG headband: BOAS, a high-quality benchmark containing PSG and wearable EEG recordings with consensus labels, and HOGAR, a large collection of home-based, self-recorded, and unlabeled recordings. Three evaluation scenarios are defined to study label efficiency, representation quality, and cross-dataset generalization. Results show that SSL consistently improves classification performance by up to 10% over supervised baselines, with gains particularly evident when labeled data is scarce. SSL achieves clinical-grade accuracy above 80% leveraging only 5% to 10% of labeled data, while the supervised approach requires twice the labels. Additionally, SSL representations prove robust to variations in population characteristics, recording environments, and signal quality. Our findings demonstrate the potential of SSL to enable label-efficient sleep staging with wearable EEG, reducing reliance on manual annotations and advancing the development of affordable sleep monitoring systems.",
      "author": "Emilio Estevan, Mar\\'ia Sierra-Torralba, Eduardo L\\'opez-Larraz, Luis Montesano",
      "published_date": "2025-10-10T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 248,
      "reading_time": 1,
      "created_at": "2025-10-10T21:37:55.030398+00:00",
      "updated_at": "2025-10-10T21:37:55.030400+00:00"
    },
    {
      "id": "cd326e608ffe5456dd923dd19e94657d",
      "url": "https://arxiv.org/abs/2510.07829",
      "title": "The Rise of the Knowledge Sculptor: A New Archetype for Knowledge Work in the Age of Generative AI",
      "content": "arXiv:2510.07829v1 Announce Type: new \nAbstract: In the Generative Age, the nature of knowledge work is transforming. Traditional models that emphasise the organisation and retrieval of pre-existing information are increasingly inadequate in the face of generative AI (GenAI) systems capable of autonomous content creation. This paper introduces the Knowledge Sculptor (KS), a new professional archetype for Human-GenAI collaboration that transforms raw AI output into trustworthy, actionable knowledge. Grounded in a socio-technical perspective, the KS is conceptualised through a framework of competencies, including architecting a vision, iterative dialogue, information sculpting, and curiosity-driven synthesis. A practice-based vignette illustrates the KS role in action, and in a self-referential approach, the paper itself serves as an artefact of the sculpting process it describes.",
      "author": "Cathal Doyle",
      "published_date": "2025-10-10T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 118,
      "reading_time": 1,
      "created_at": "2025-10-10T21:37:55.030362+00:00",
      "updated_at": "2025-10-10T21:37:55.030364+00:00"
    },
    {
      "id": "17535effb200f0c4b4d17c5e1fedf587",
      "url": "https://arxiv.org/abs/2510.07754",
      "title": "Human-in-the-Loop Optimization with Model-Informed Priors",
      "content": "arXiv:2510.07754v1 Announce Type: new \nAbstract: Human-in-the-loop optimization identifies optimal interface designs by iteratively observing user performance. However, it often requires numerous iterations due to the lack of prior information. While recent approaches have accelerated this process by leveraging previous optimization data, collecting user data remains costly and often impractical. We present a conceptual framework, Human-in-the-Loop Optimization with Model-Informed Priors (HOMI), which augments human-in-the-loop optimization with a training phase where the optimizer learns adaptation strategies from diverse, synthetic user data generated with predictive models before deployment. To realize HOMI, we introduce Neural Acquisition Function+ (NAF+), a Bayesian optimization method featuring a neural acquisition function trained with reinforcement learning. NAF+ learns optimization strategies from large-scale synthetic data, improving efficiency in real-time optimization with users. We evaluate HOMI and NAF+ with mid-air keyboard optimization, a representative VR input task. Our work presents a new approach for more efficient interface adaptation by bridging in situ and in silico optimization processes.",
      "author": "Yi-Chi Liao, Jo\\~ao Belo, Hee-Seung Moon, J\\\"urgen Steimle, Anna Maria Feit",
      "published_date": "2025-10-10T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 156,
      "reading_time": 1,
      "created_at": "2025-10-10T21:37:55.030335+00:00",
      "updated_at": "2025-10-10T21:37:55.030336+00:00"
    },
    {
      "id": "2acb51e56a4a01d13ed9d536ffeb7991",
      "url": "https://arxiv.org/abs/2510.07610",
      "title": "The Slow Space Editor : Broadening Access to Restorative XR",
      "content": "arXiv:2510.07610v1 Announce Type: new \nAbstract: The Slow Space Editor is a 2D tool for creating 3D spaces. It was built as part of a research-through-design project that investigates how Virtual and Mixed Reality (XR) environments might be used for reflection and attention restoration. In this phase, we seek to radically simplify the creation of virtual environments, thereby broadening the potential group of users who could benefit from them. The research described in this paper has three aspects. First, we define the concept of \"slow space,\" situating it alongside existing research in HCI and environmental psychology. Second, we report on a series of interviews with professional designers about how slow spaces are created in the physical world. Third, we share the design of the tool itself, focussing on the benefits of providing a simple method for users to control their environments. We conclude with our findings from a 19-person qualitative study of the tool.",
      "author": "Nate Laffan, Ashley Hom, Andrea Nadine Castillo, Elizabeth Gitelman, Rebecca Zhao, Nikita Shenoy, Kaia Rae Schweig, Katherine Isbister",
      "published_date": "2025-10-10T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 153,
      "reading_time": 1,
      "created_at": "2025-10-10T21:37:55.030305+00:00",
      "updated_at": "2025-10-10T21:37:55.030307+00:00"
    },
    {
      "id": "fe99a45b70d7a40d3ee7b41761213248",
      "url": "https://arxiv.org/abs/2510.07609",
      "title": "IGUANA: Immersive Guidance, Navigation, and Control for Consumer UAV",
      "content": "arXiv:2510.07609v1 Announce Type: new \nAbstract: As the markets for unmanned aerial vehicles (UAVs) and mixed reality (MR) headsets continue to grow, recent research has increasingly explored their integration, which enables more intuitive, immersive, and situationally aware control systems. We present IGUANA, an MR-based immersive guidance, navigation, and control system for consumer UAVs. IGUANA introduces three key elements beyond conventional control interfaces: (1) a 3D terrain map interface with draggable waypoint markers and live camera preview for high-level control, (2) a novel spatial control metaphor that uses a virtual ball as a physical analogy for low-level control, and (3) a spatial overlay that helps track the UAV when it is not visible with the naked eye or visual line of sight is interrupted. We conducted a user study to evaluate our design, both quantitatively and qualitatively, and found that (1) the 3D map interface is intuitive and easy to use, relieving users from manual control and suggesting improved accuracy and consistency with lower perceived workload relative to conventional dual-stick controller, (2) the virtual ball interface is intuitive but limited by the lack of physical feedback, and (3) the spatial overlay is very useful in enhancing the users' situational awareness.",
      "author": "Victor Victor, Tania Krisanty, Matthew McGinity, Stefan Gumhold, Uwe A{\\ss}mann",
      "published_date": "2025-10-10T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 198,
      "reading_time": 1,
      "created_at": "2025-10-10T21:37:55.030276+00:00",
      "updated_at": "2025-10-10T21:37:55.030278+00:00"
    },
    {
      "id": "8e9e179fb464c187a7ee4bbba1d6964c",
      "url": "https://arxiv.org/abs/2510.07322",
      "title": "A LoRa IoT Framework with Machine Learning for Remote Livestock Monitoring in Smart Agriculture",
      "content": "arXiv:2510.07322v1 Announce Type: new \nAbstract: This work presents AgroTrack, a LoRa-based IoT framework for remote livestock monitoring in smart agriculture. The system is designed for low-power, long-range communication and supports real-time tracking and basic health assessment of free-range livestock through GPS, motion, and temperature sensors integrated into wearable collars. Data is collected and transmitted via LoRa to gateways and forwarded to a cloud platform for visualization, alerts, and analytics. To enhance its practical deployment, AgroTrack incorporates advanced analytics, including machine learning models for predictive health alerts and behavioral anomaly detection. This integration transforms the framework from a basic monitoring tool into an intelligent decision-support system, enabling farmers to improve livestock management, operational efficiency, and sustainability in rural environments.",
      "author": "Hitesh Mohapatra",
      "published_date": "2025-10-10T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 118,
      "reading_time": 1,
      "created_at": "2025-10-10T21:37:55.030243+00:00",
      "updated_at": "2025-10-10T21:37:55.030245+00:00"
    },
    {
      "id": "8aef26e3def5420d229cd626051a6e75",
      "url": "https://arxiv.org/abs/2510.07321",
      "title": "How human is the machine? Evidence from 66,000 Conversations with Large Language Models",
      "content": "arXiv:2510.07321v1 Announce Type: new \nAbstract: When Artificial Intelligence (AI) is used to replace consumers (e.g., synthetic data), it is often assumed that AI emulates established consumers, and more generally human behaviors. Ten experiments with Large Language Models (LLMs) investigate if this is true in the domain of well-documented biases and heuristics. Across studies we observe four distinct types of deviations from human-like behavior. First, in some cases, LLMs reduce or correct biases observed in humans. Second, in other cases, LLMs amplify these same biases. Third, and perhaps most intriguingly, LLMs sometimes exhibit biases opposite to those found in humans. Fourth, LLMs' responses to the same (or similar) prompts tend to be inconsistent (a) within the same model after a time delay, (b) across models, and (c) among independent research studies. Such inconsistencies can be uncharacteristic of humans and suggest that, at least at one point, LLMs' responses differed from humans. Overall, unhuman-like responses are problematic when LLMs are used to mimic or predict consumer behavior. These findings complement research on synthetic consumer data by showing that sources of bias are not necessarily human-centric. They also contribute to the debate about the tasks for which consumers, and more generally humans, can be replaced by AI.",
      "author": "Antonios Stamatogiannakis, Arsham Ghodsinia, Sepehr Etminanrad, Dilney Gon\\c{c}alves, David Santos",
      "published_date": "2025-10-10T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 204,
      "reading_time": 1,
      "created_at": "2025-10-10T21:37:55.030211+00:00",
      "updated_at": "2025-10-10T21:37:55.030215+00:00"
    },
    {
      "id": "ff9f7d97218d63dfc4876538f55ebe5b",
      "url": "https://arxiv.org/abs/2205.10723",
      "title": "Stochastic Models of Neuronal Growth",
      "content": "arXiv:2205.10723v2 Announce Type: replace-cross \nAbstract: Neuronal circuits arise as axons and dendrites extend, navigate, and connect to target cells. Axonal growth, in particular, integrates deterministic guidance from substrate mechanics and geometry with stochastic fluctuations generated by signaling, molecular detection, cytoskeletal assembly, and growth cone dynamics. A comprehensive quantitative description of this process remains incomplete. We review stochastic models in which Langevin dynamics and the associates Fokker-Planck equation capture axonal motion and turning under combined biases and noise. Paired with experiments, these models yield key parameters, including effective diffusion (motility) coefficients, speed and angle distributions, mean-square displacement, and mechanical measures of cell-substrate coupling, thereby linking single-cell biophysics and intercellular interactions to collective growth statistics and network formation. We further couple the Fokker-Planck description to a mechanochemical actin-myosin-clutch model and perform a linear stability analysis of the resulting dynamics. Routh--Hurwitz criteria identify regimes of steady extension, damped oscillations, and Hopf bifurcations that generate sustained limit cycles. Together, these results clarify the mechanisms that govern axonal guidance and connectivity and inform the design of engineered substrates and neuroprosthetic scaffolds aimed at enhancing nerve repair and regeneration.",
      "author": "Cristian Staii",
      "published_date": "2025-10-10T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 183,
      "reading_time": 1,
      "created_at": "2025-10-10T21:37:53.930651+00:00",
      "updated_at": "2025-10-10T21:37:53.930653+00:00"
    },
    {
      "id": "3903706a5d25ebc1aa80360bf9a59f28",
      "url": "https://arxiv.org/abs/2509.23896",
      "title": "A Computational Perspective on NeuroAI and Synthetic Biological Intelligence",
      "content": "arXiv:2509.23896v2 Announce Type: replace \nAbstract: NeuroAI is an emerging field at the intersection of neuroscience and artificial intelligence, where insights from brain function guide the design of intelligent systems. A central area within this field is synthetic biological intelligence (SBI), which combines the adaptive learning properties of biological neural networks with engineered hardware and software. SBI systems provide a platform for modeling neural computation, developing biohybrid architectures, and enabling new forms of embodied intelligence. In this review, we organize the NeuroAI landscape into three interacting domains: hardware, software, and wetware. We outline computational frameworks that integrate biological and non-biological systems and highlight recent advances in organoid intelligence, neuromorphic computing, and neuro-symbolic learning. These developments collectively point toward a new class of systems that compute through interactions between living neural tissue and digital algorithms.",
      "author": "Dhruvik Patel, Md Sayed Tanveer, Jesus Gonzalez-Ferrer, Alon Loeffler, Brett J. Kagan, Mohammed A. Mostajo-Radji, Ge Wang",
      "published_date": "2025-10-10T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 133,
      "reading_time": 1,
      "created_at": "2025-10-10T21:37:53.930620+00:00",
      "updated_at": "2025-10-10T21:37:53.930622+00:00"
    },
    {
      "id": "549da4b14f3a4b20187dea9100776d3f",
      "url": "https://arxiv.org/abs/2505.08831",
      "title": "Neural encoding of real world face perception",
      "content": "arXiv:2505.08831v2 Announce Type: replace \nAbstract: Social perception unfolds as we freely interact with people around us. We investigated the neural basis of real world face perception using multi electrode intracranial recordings in humans during spontaneous interactions with friends, family, and others. Computational models reconstructed the faces participants looked at during natural interactions, including facial expressions and motion, from brain activity alone. The results highlighted a critical role for the social vision pathway, a network of areas spanning parietal, temporal, and occipital cortex. This network was more sharply tuned to subtle expressions compared to intense expressions, which was confirmed with controlled psychophysical experiments. These findings reveal that the human social vision pathway encodes facial expressions and motion as deviations from a neutral expression prototype during natural social interactions in real life.",
      "author": "Arish Alreja, Michael J. Ward, Lisa S. Parker, R. Mark Richardson, Louis-Philippe Morency, Taylor J. Abel, Avniel Singh Ghuman",
      "published_date": "2025-10-10T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 130,
      "reading_time": 1,
      "created_at": "2025-10-10T21:37:53.930593+00:00",
      "updated_at": "2025-10-10T21:37:53.930595+00:00"
    }
  ],
  "recently_processed": [
    {
      "id": "5d49304b30e3f1cca1ea313fc654375e",
      "url": "https://www.embs.org/uncategorized/call-for-adcom-nominations/",
      "title": "Open Call for AdCom Nominations",
      "content": "<p>The post <a href=\"https://www.embs.org/uncategorized/call-for-adcom-nominations/\">Open Call for AdCom Nominations</a> appeared first on <a href=\"https://www.embs.org\">IEEE EMBS</a>.</p>",
      "author": "Nancy Zimmerman",
      "published_date": "2025-05-02T17:09:21+00:00",
      "source": "Embs",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 14,
      "reading_time": 1,
      "created_at": "2025-10-10T21:37:56.557396+00:00",
      "updated_at": "2025-10-10T22:13:13.462837+00:00",
      "metadata": {
        "processed_at": "2025-10-10T22:13:13.462847+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "3727d0ebc34094cb889f4f09a3e22f0e",
      "url": "https://www.embs.org/press/embc-eic-sunghoon-ivan-lee/",
      "title": "IEEE EMBS Appoints Sunghoon \u201cIvan\u201d Lee, Ph.D., as Editor-in-Chief of EMBC Proceedings, the Leading Biomedical Engineering Conference Publication",
      "content": "<p>(Piscataway, N.J., August 12, 2025) Sunghoon \u201cIvan\u201d Lee, Ph.D., a Donna M. and Robert J. Manning Faculty Fellow and an Associate Professor of computer science, electrical and computer engineering, and&#8230; <a class=\"continue\" href=\"https://www.embs.org/press/embc-eic-sunghoon-ivan-lee/\">Continue Reading<span> IEEE EMBS Appoints Sunghoon \u201cIvan\u201d Lee, Ph.D., as Editor-in-Chief of EMBC Proceedings, the Leading Biomedical Engineering Conference Publication</span></a></p>\n<p>The post <a href=\"https://www.embs.org/press/embc-eic-sunghoon-ivan-lee/\">IEEE EMBS Appoints Sunghoon \u201cIvan\u201d Lee, Ph.D., as Editor-in-Chief of EMBC Proceedings, the Leading Biomedical Engineering Conference Publication</a> appeared first on <a href=\"https://www.embs.org\">IEEE EMBS</a>.</p>",
      "author": "Nancy Zimmerman",
      "published_date": "2025-08-19T14:41:24+00:00",
      "source": "Embs",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 79,
      "reading_time": 1,
      "created_at": "2025-10-10T21:37:56.557376+00:00",
      "updated_at": "2025-10-10T22:13:13.462853+00:00",
      "metadata": {
        "processed_at": "2025-10-10T22:13:13.462855+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "549175845c3e5a33324ec1d03a43ab51",
      "url": "https://arxiv.org/abs/2510.08104",
      "title": "Development of Mental Models in Human-AI Collaboration: A Conceptual Framework",
      "content": "arXiv:2510.08104v1 Announce Type: new \nAbstract: Artificial intelligence has become integral to organizational decision-making and while research has explored many facets of this human-AI collaboration, the focus has mainly been on designing the AI agent(s) and the way the collaboration is set up - generally assuming a human decision-maker to be \"fixed\". However, it has largely been neglected that decision-makers' mental models evolve through their continuous interaction with AI systems. This paper addresses this gap by conceptualizing how the design of human-AI collaboration influences the development of three complementary and interdependent mental models necessary for this collaboration. We develop an integrated socio-technical framework that identifies the mechanisms driving the mental model evolution: data contextualization, reasoning transparency, and performance feedback. Our work advances human-AI collaboration literature through three key contributions: introducing three distinct mental models (domain, information processing, complementarity-awareness); recognizing the dynamic nature of mental models; and establishing mechanisms that guide the purposeful design of effective human-AI collaboration.",
      "author": "Joshua Holstein, Gerhard Satzger",
      "published_date": "2025-10-10T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 156,
      "reading_time": 1,
      "created_at": "2025-10-10T21:37:55.030492+00:00",
      "updated_at": "2025-10-10T22:13:13.462857+00:00",
      "metadata": {
        "processed_at": "2025-10-10T22:13:13.462859+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "861cb2481303e2f9c4c998a2aaf920b7",
      "url": "https://arxiv.org/abs/2510.07987",
      "title": "Quantifying Locomotion Differences Between Virtual Reality Users With and Without Motor Impairments",
      "content": "arXiv:2510.07987v1 Announce Type: new \nAbstract: Today's virtual reality (VR) systems and environments assume that users have typical abilities, which can make VR inaccessible to people with physical impairments. However, there is not yet an understanding of how inaccessible locomotion techniques are, and which interactions make them inaccessible. To this end, we conducted a study in which people with and without upper-body impairments navigated a virtual environment with six locomotion techniques to quantify performance differences among groups. We found that groups performed similarly with Sliding Looking on all performance measures, suggesting that this might be a good default locomotion technique for VR apps. To understand the nature of performance differences with the other techniques, we collected low-level interaction data from the controllers and headset and analyzed interaction differences with a set of movement-, button-, and target-related metrics. We found that movement-related metrics from headset data reveal differences among groups with all techniques, suggesting these are good metrics for identifying whether a user has an upper-body impairment. We also identify movement-, button, and target- related metrics that can explain performance differences between groups for particular locomotion techniques.",
      "author": "Rachel L. Franz, Jacob O. Wobbrock",
      "published_date": "2025-10-10T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 185,
      "reading_time": 1,
      "created_at": "2025-10-10T21:37:55.030463+00:00",
      "updated_at": "2025-10-10T22:13:13.462861+00:00",
      "metadata": {
        "processed_at": "2025-10-10T22:13:13.462863+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "bc92261b448981f22adaab2651955f07",
      "url": "https://arxiv.org/abs/2510.07967",
      "title": "Pre/Absence: Prompting Cultural Awareness and Understanding for Lost Architectural Heritage in Virtual Reality",
      "content": "arXiv:2510.07967v1 Announce Type: new \nAbstract: Lost architectural heritage presents interpretive challenges due to vanished structures and fragmented historical records. Using Hanyuan Hall of the Tang dynasty's Daming Palace as a case study, we conducted a formative investigation with archaeologists, heritage administrators, and visitors to identify key issues in current interpretation practices. We found that these practices often compress complex cultural layers into factual summaries and rely on linear narratives that overlook the continuing reinterpretations following a site's disappearance. In response, we designed Pre/Absence, a virtual reality experience grounded in the presence-absence dialectic to interweave tangible and vanished aspects of heritage within a spatiotemporal narrative. A mixed-method study with 28 participants compared Pre/Absence to a paper-based experience. Both improved users' factual understanding, but the VR experience more strongly enhanced cultural awareness, evoked emotional engagement with loss, and encouraged critical reflection on the evolving social and political meanings of heritage. The findings suggest that VR can move beyond static reconstruction to engage users as co-constructors of cultural meaning, providing a nuanced framework for critical heritage narrative design in human-computer interaction.",
      "author": "Yaning Li, Ke Zhao, Shucheng Zheng, Xingyu Chen, Chenyi Chen, Wenxi Dai, Weile Jiang, Qi Dong, Yiqing Zhao, Meng Li, Lin-Ping Yuan",
      "published_date": "2025-10-10T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 178,
      "reading_time": 1,
      "created_at": "2025-10-10T21:37:55.030428+00:00",
      "updated_at": "2025-10-10T22:13:13.462865+00:00",
      "metadata": {
        "processed_at": "2025-10-10T22:13:13.462869+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "2eb57dbdbc858b57282cfad12fa8d826",
      "url": "https://brain.ieee.org/braininsight-articles/ieee-brain-workshop-on-ai-for-neurotechnology/",
      "title": "IEEE Brain Workshop on AI for Neurotechnology",
      "content": "The IEEE Brain Workshop on AI for Neurotechnology was held on June 30, 2024, at the Pacifico Yokohama Conference Center in Japan. This event was part of the World Congress on Computational Intelligence (WCCI 2024) and was conducted in association with the International Joint Conference on Neural Networks (IJCNN). The workshop focused on the application of artificial intelligence to neurotechnology, ...",
      "author": "ieeebrain",
      "published_date": "2025-03-03T17:05:59+00:00",
      "source": "Brain",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 61,
      "reading_time": 1,
      "created_at": "2025-10-10T19:38:38.301126+00:00",
      "updated_at": "2025-10-10T20:15:03.297364+00:00",
      "metadata": {
        "processed_at": "2025-10-10T20:15:03.297375+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "3352595883ccb35de24e20a19b774dd2",
      "url": "https://brain.ieee.org/braininsight-articles/ieee-journal-on-flexible-electronics/",
      "title": "Call for Papers: IEEE Brain Special Issue",
      "content": "In a unique interdisciplinary collaboration with the IEEE\u2019s Society on Social Implications of Technology (SSIT) and IEEE Brain, J-FLEX is joining forces to explore both the technology of the Internet-of-Medical-Things (IoMT) solutions and medical wearables/implantables. &#160;",
      "author": "ieeebrain",
      "published_date": "2025-03-03T17:16:40+00:00",
      "source": "Brain",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 36,
      "reading_time": 1,
      "created_at": "2025-10-10T19:38:38.301104+00:00",
      "updated_at": "2025-10-10T20:15:03.297380+00:00",
      "metadata": {
        "processed_at": "2025-10-10T20:15:03.297382+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "626415b9abcab4a79433d23aa150042f",
      "url": "https://brain.ieee.org/braininsight-articles/ieee-brain-joins-the-american-brain-coalition-as-a-nonprofit-member/",
      "title": "IEEE Brain Joins the American Brain Coalition",
      "content": "IEEE Brain is pleased to announce its acceptance as a nonprofit member of the American Brain Coalition (ABC), a prestigious alliance of over 150 organizations dedicated to advancing brain research, advocacy, and improving treatments for individuals affected by brain conditions. The ABC Board has enthusiastically welcomed IEEE Brain into its network, reinforcing a shared commitment to fostering innovation and collaboration ...",
      "author": "ieeebrain",
      "published_date": "2025-03-03T17:22:08+00:00",
      "source": "Brain",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 61,
      "reading_time": 1,
      "created_at": "2025-10-10T19:38:38.301080+00:00",
      "updated_at": "2025-10-10T20:15:03.297384+00:00",
      "metadata": {
        "processed_at": "2025-10-10T20:15:03.297386+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "ac6f3ab92725084e2b49600ca6243d2a",
      "url": "https://brain.ieee.org/braininsight-articles/call-for-papers-ieee-transactions-on-human-machine-systems/",
      "title": "Call for Papers: IEEE Transactions on Human-Machine Systems",
      "content": "Special Issue on Brain Discovery and Neurotechnology: Featured Research from 2024 IEEE Brain Discovery &#38; Neurotechnology Workshop\u00a0 &#160; This special issue is motivated by the success of the IEEE Brain Discovery and Neurotechnology Workshop held in October 2024. This annual workshop is sponsored by the IEEE Brain Technical Community. It is intended to foster interactions among researchers and clinical practitioners ...",
      "author": "Adriel Carridice",
      "published_date": "2025-06-18T14:50:14+00:00",
      "source": "Brain",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 61,
      "reading_time": 1,
      "created_at": "2025-10-10T19:38:38.301051+00:00",
      "updated_at": "2025-10-10T20:15:03.297388+00:00",
      "metadata": {
        "processed_at": "2025-10-10T20:15:03.297389+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "16712c82fde7bee131cf339ae97552f5",
      "url": "http://ieeexplore.ieee.org/document/10994678",
      "title": "Evaluation on Human Perception of Various Vibrotactile Encoding Methods Through a High Density Haptic Feedback Interface",
      "content": "High density (HD) haptic interfaces have become increasingly common for entertainment thanks to advancements in virtual reality technology, however their flexibility may make them a useful sensory substitution interface for motor rehabilitation. Yet little research has explored how users interpret different haptic feedback encoding methods. Therefore, this study's objective was to evaluate the effectiveness of various encoding methods for conveying information based on existing sensory substitution strategies, one being a line motion tracking task and the other a direction tracking task. The first encoding method was Perceived Position Encoding (PPE), where information was encoded into the perceived position of stimulation. The second was Perceived Intensity Encoding (PIE), encoded information into the perceived amplitude of the stimuli. Twenty-one participants performed tracking tasks using both the PIE and PPE methods. The results showed similar performance in line motion tracking between the PIE and PPE methods, although the extra motors used in the PPE method appear to introduce uncertainty in users. Nevertheless, users were significantly more accurate with direction tracking when using PPE. These findings highlight the need for task-specific encoding methods, and showcase the versatility of the HD haptic vest as a tool for augmented feedback in motor rehabilitation.",
      "author": "",
      "published_date": "2025-05-09T13:16:51+00:00",
      "source": "Transactions Haptics",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 197,
      "reading_time": 1,
      "created_at": "2025-10-10T19:38:36.853672+00:00",
      "updated_at": "2025-10-10T20:15:03.297392+00:00",
      "metadata": {
        "processed_at": "2025-10-10T20:15:03.297393+00:00",
        "processing_method": "github_actions"
      }
    }
  ]
}