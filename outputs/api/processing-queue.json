{
  "last_updated": "2025-11-09T22:13:40.494197+00:00",
  "pending_count": 985,
  "processed_count": 15,
  "pending_articles": [
    {
      "id": "79d603b3db5911be59b9e07e11acc674",
      "url": "https://erpinfo.org/blog/2024/6/28/recording-and-slides-now-available-for-erplab-studio-webinar",
      "title": "Recording and slides now available for ERPLAB Studio webinar",
      "content": "<p class=\"\">We held a webinar to demonstration ERPLAB Studio on 28 June 2024.</p><p class=\"\"><a href=\"https://youtu.be/k-nGv00rTP8\">Click here</a> to access a recording.</p><p class=\"\"><a href=\"https://ucdavis.box.com/s/4fseqz6327dtuouauj12rgvivy1d1nmo\">Click here </a>to access a PDF of the slides.</p>",
      "author": "Steve Luck",
      "published_date": "2024-06-28T22:21:45+00:00",
      "source": "Erp Boot Camp",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 30,
      "reading_time": 1,
      "created_at": "2025-11-09T21:38:39.375859+00:00",
      "updated_at": "2025-11-09T21:38:39.375860+00:00"
    },
    {
      "id": "f485a145c3b839418e3d039dc3a92ea6",
      "url": "https://erpinfo.org/blog/2025/3/20/new-paper-oddball",
      "title": "New Paper: Does the P3b component reflect working memory updating?",
      "content": "<p class=\"\">Carrasco, C. D., Simmons, A. M., Kiat, J. E., &amp; Luck, S. J. (in press). Enhanced working memory representations for rare events. <em>Psychophysiology</em>. <a href=\"https://doi.org/10.1111/psyp.70038\">https://doi.org/10.1111/psyp.70038</a> [<a href=\"https://doi.org/10.1101/2024.03.20.585952\">preprint</a>]</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n<hr />\n\n\n  <p class=\"\">For decades, many ERP researchers have believed that the P3b wave (sometimes called P300) is a scalp manifestation of a process that updates working memory. This idea originated with Manny Donchin\u2019s <em>context updating</em> hypothesis of the P3b (<a href=\"https://doi.org/10.1111/j.1469-8986.1981.tb01815.x\">Donchin, 1981</a>). Donchin\u2019s idea of <em>context</em> was pretty different from working memory, but as this hypothesis percolated through the field over time, it gradually morphed into the idea that the P3b reflects the updating of working memory.</p><p class=\"\">Rolf Verleger mounted a major attack on the original context updating hypothesis in a classic review article in BBS (<a href=\"https://doi.org/10.1017/S0140525X00058015\">Verleger, 1988</a>), which was followed by a vigorous rebuttal by <a href=\"https://doi.org/10.1017/S0140525X00058027\">Donchin and Coles (1988)</a>. These are interesting papers to read, but they did not settle the issue. In the ensuing years, as the field became more focused on working memory instead of context, I\u2019m aware of no studies that directly tested the hypothesis that the P3b reflects working memory updating. </p><p class=\"\">One reason for the lack of direct evidence is that the oddball paradigms typically used to elicit the P3b do not provide a sensitive assessment of working memory. In a typical paradigm, for example, participants would see a sequence of 90% Xs and 10% Os, and the task would be to press one button for X and another button for O. The responses are made immediately, so it is not necessary to store the stimuli in working memory. Even if participants were asked to make a delayed response, the Xs and Os are so easily discriminable that memory performance would likely be at ceiling.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"698\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/f1d6cee6-5eab-4240-bda0-1a2b7bf4bf88/Figure_1.png?format=1000w\" width=\"720\" />\n\n            \n          \n        \n          \n        \n\n        \n          \n          <figcaption class=\"image-caption-wrapper\">\n            <p class=\"\">Figure 1</p>\n          </figcaption>\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">A few years ago, my lab (especially Carlos Carrasco, Aaron Simmons, and John Kiat) got interested in trying to test the working memory encoding hypothesis. We ran a couple of experiments, but we couldn\u2019t quite figure out the right design. Finally, we figured it out. We used a modified oddball paradigm in which a little dot appeared at one of many locations around an circle (see Figure 1). </p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1112\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/f68d38c2-c87c-4512-b0a7-fbecd75969ff/Figure_2.png?format=1000w\" width=\"1728\" />\n\n            \n          \n        \n          \n        \n\n        \n          \n          <figcaption class=\"image-caption-wrapper\">\n            <p class=\"\">Figure 2</p>\n          </figcaption>\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">On each trial, participants pressed one button if the circle was close to one of the four cardinal axes (left, right, top, and bottom) and a different button if it was close to one of the four diagonals (upper left, upper right, lower left, and lower right). One of these two categories was rare (the <em>oddballs</em>) and the other was frequent (the <em>standards</em>; counterbalanced across trial blocks). As is usual in oddball paradigms, the P3b was much larger for trials in the rare category than for trials in the frequent category (see Figure 2).</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1256\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/89260e9e-be6e-48b1-adc4-58b77a418deb/Figure_3.png?format=1000w\" width=\"1996\" />\n\n            \n          \n        \n          \n        \n\n        \n          \n          <figcaption class=\"image-caption-wrapper\">\n            <p class=\"\">Figure 3</p>\n          </figcaption>\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">The main question was whether the location of the dot was encoded in working memory better for the oddball trials than for the standard trials. To assess this, the experimental design contained occasional <em>probe</em> trials on which participants used the mouse to click on the exact location of the dot (see Figure 3). That is, after participants made the cardinal/diagonal buttonpress responses, they were sometimes then asked to click on the remembered location of the dot. This happened on only 12.5% of trials, selected at random, so that participants would mainly focus on the oddball task. </p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"706\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/166f7236-f77b-431b-8ebf-9633580dcf31/Figure_4.png?format=1000w\" width=\"1800\" />\n\n            \n          \n        \n          \n        \n\n        \n          \n          <figcaption class=\"image-caption-wrapper\">\n            <p class=\"\">Figure 4</p>\n          </figcaption>\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">We looked at the accuracy of these probe responses, calculated as the (absolute value of the) angular distance between the true location and the reported location. As shown in Figure 4, the response error of the probe responses was reduced for the oddball trials relative to the standard trials. In other words, working memory was better for the P3b-eliciting oddball trials than for the standards. Moreover, we found that participants with large P3b amplitudes on oddball trials had smaller response errors on oddball trials (whereas this correlation was not present for standards).</p><p class=\"\">At first glance, these findings seem like support for the idea that the P3b reflects working memory updating. However, the story is not that simple. For example, when we looked at single-trial P3b amplitudes, response errors were not lower for trials with larger P3b amplitudes than for trials with smaller P3b amplitudes.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1122\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/a7a11955-3619-4499-9ef4-61f72a408561/Figure_5.png?format=1000w\" width=\"1378\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">We also used ERP decoding to test whether the exact location of the dot was better stored in working memory on oddball trials than on standard trials (<a href=\"https://erpinfo.org/blog/2023/6/23/decoding-webinar\">click here</a> for information about how ERP decoding works and how you can decode your own data using ERPLAB Toolbox). As shown in Figure 5, we could decode the location of the dot better on oddball trials than on standard trials during the period following the P3b component. Note, however, that this was a pretty small difference that only barely crossed the threshold for statistical significance (p = .048). I would really like to see this effect replicated before fully believing it. However, the behavioral effect was rock solid (and replicated in a follow-up experiment).</p><p class=\"\">What can we conclude from these findings? When we started the project, I knew that it would be difficult to draw any strong causal conclusions about the relationship between the P3b component and working memory updating. That is, even if we saw both a larger P3b and improved working memory on oddball trials, this would just be a correlation and could potentially be explained by a third variable such as attention. But if we saw a big difference in working memory between oddballs and standards, and if we found that working memory was better on trials with larger P3b amplitudes, this would be at least consistent with the idea that the process that produces the P3b on the scalp is also involved in working memory encoding.</p><p class=\"\">However, although we saw an enormous difference in P3b amplitude between oddball trials and standard trials, we saw only small differences in working memory between oddballs and standards, whether measured via behavioral response errors on probe trials or EEG decoding accuracy. If the process that generates the scalp P3b voltage plays a major role in working memory encoding, then we would have expected a much larger working memory difference between oddballs and standards. Moreover, although we found that participants with larger P3b amplitudes had smaller response errors, we did not find any evidence that working memory was any better on trials with larger P3b amplitudes (even though we looked very hard for such a relationship). The bottom line is that, although I was really hoping we would finally provide some direct evidence for the working memory encoding hypothesis, the results of this study have actually convinced me that the P3b is probably not related to working memory encoding.</p><p class=\"\">What, then, explains the small but statistically significant differences in working memory accuracy between oddballs and standards, along with the subjectwise correlation between P3b amplitude and behavioral response errors? A very plausible explanation is that both the P3b component and working memory encoding are facilitated by increased attention. That is, there are several sources of evidence that rare events trigger increased attention, and this could independently produce a larger P3b and improved working memory.</p><p class=\"\">Of course, this is just one experiment, so I wouldn\u2019t say that the working memory encoding hypothesis is completely dead. But given our new findings and the general lack of direct evidence for the hypothesis, it\u2019s on life support.</p><p class=\"\">If the P3b doesn\u2019t reflect working memory encoding, then what does it reflect? This seems like a significant question: the P3b is huge and is observed across a broad range of experimental paradigms, and it\u2019s reasonable to assume that the underlying process must be important for the brain to devote so many watts of energy to it. In fact, I find it embarrassing that our field has not answered this question in the 60 years since <a href=\"https://doi.org/10.1126/science.150.3700.1187\">the P3b was first discovered</a>.</p><p class=\"\">My best bet is that the P3b is related to the process of making decisions about actions (where the term <em>actions</em> is broadly construed to include the withholding of responses and mental actions such as counting). This is related to the fact that the amplitude of the P3b is related to the probability of a task-defined category, not the probability of a physical stimulus category. Rolf Verleger has a nice review of the evidence for this idea (<a href=\"https://doi.org/10.1111/psyp.13542\">Verleger, 2020</a>). But it is still not clear to me why the brain devotes so many watts of energy to creating a large P3b when a rare task-defined category occurs. Verleger notes that several hypotheses about the P3b are compatible with the finding of a larger P3b for oddballs than for standards, but in my view these hypotheses have a hard time explaining the enormous size of the P3b observed for oddballs. This is a longstanding mystery in need of a solution!</p>",
      "author": "Steve Luck",
      "published_date": "2025-03-21T03:42:26+00:00",
      "source": "Erp Boot Camp",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 1547,
      "reading_time": 7,
      "created_at": "2025-11-09T21:38:39.375833+00:00",
      "updated_at": "2025-11-09T21:38:39.375836+00:00"
    },
    {
      "id": "11da1006ee59369caf1a8b22a800f02c",
      "url": "https://erpinfo.org/blog/2025/8/20/boot-camp-summer-2026",
      "title": "10-Day ERP Boot Camp to be held June 15-24, 2026 in Davis, California",
      "content": "<p class=\"\">We have received another 5 years of funding from the National Institute of Mental Health, so we plan to hold ERP Boot Camps in each of the next 5 summers. The next one will be June 15-24, 2026 in Davis, California. The application portal will open around January 1, 2026.</p><p class=\"\">As in most previous years, all attendees will receive a scholarship that covers most or all travel and lodging expenses. There will be no registration fee.</p><p class=\"\"><a href=\"https://erpinfo.org/summer-boot-camp\">Click here</a> for more information about the ERP Boot Camp.</p><p class=\"\">If you would like to receive announcements about upcoming boot camps, <a href=\"https://erpinfo.org/bootcamp-email-list\">join our email list</a>. If you have any questions after reading this page and the <a href=\"https://erpinfo.org/application-info\">application information</a> page, please email us at <a href=\"mailto:erpbootcamp@gmail.com\">erpbootcamp@gmail.com</a>.</p>",
      "author": "Steve Luck",
      "published_date": "2025-08-20T15:07:14+00:00",
      "source": "Erp Boot Camp",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 125,
      "reading_time": 1,
      "created_at": "2025-11-09T21:38:39.375618+00:00",
      "updated_at": "2025-11-09T21:38:39.375621+00:00"
    },
    {
      "id": "8a37f4aa5925a5559bd2dd315d94013b",
      "url": "https://brain.ieee.org/publications/neuroethics-framework/education/standards-education/education-standards/",
      "title": "Education: Standards",
      "content": "",
      "author": "Adriel Carridice",
      "published_date": "2025-02-13T19:51:15+00:00",
      "source": "Brain",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-11-09T21:38:36.099970+00:00",
      "updated_at": "2025-11-09T21:38:36.099971+00:00"
    },
    {
      "id": "417111e13e4858f79734781862a95c17",
      "url": "https://brain.ieee.org/publications/neuroethics-framework/education/educational-and-training-resources-education/education-additional-resources/",
      "title": "Education: Additional Resources",
      "content": "Buckingham Shum, S. (2022). The UTS \u201cEdTech Ethics\u201d Deliberative Democracy Consultation: Rationale, Process and Outcomes. Connected Intelligence Centre, University of Technology Sydney, AUS. https://cic.uts.edu.au/projects/edtech-ethics Le\u00f3n Declaration on European neurotechnology (2023): a human-focused and rights-oriented approach October 2023. An informal meeting will be held with all telecommunications and digital ministers from EU member states. https://spanish-presidency.consilium.europa.eu/media/o4rh53jr/le%C3%B3n-declaration.pdf Neurotechnology Report: https://www.perseus-strategies.com/wp-content/uploads/2024/04/FINAL-Consumer-Neurotechnology-Report-Neurorights-Foundation-March-2024-3.pdf Al-Emran, M., Al-Nuaimi, ...",
      "author": "Adriel Carridice",
      "published_date": "2025-02-13T19:54:30+00:00",
      "source": "Brain",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 61,
      "reading_time": 1,
      "created_at": "2025-11-09T21:38:36.099952+00:00",
      "updated_at": "2025-11-09T21:38:36.099954+00:00"
    },
    {
      "id": "eddcbadea083b0a5930cbd4a70baf32e",
      "url": "https://brain.ieee.org/publications/neuroethics-framework/education/references/education-references/",
      "title": "Education: References",
      "content": "[1] OECD \u201cNeurotechnology Toolkit To support policymakers in implementing the OECD Recommendation on Responsible Innovation in Neurotechnology,\u201d 2024.: https://www.oecd.org/content/dam/oecd/en/topics/policy-sub-issues/emerging-technologies/neurotech-toolkit.pdf. [2] van Kesteren and Meeter, 2020 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7339924/ [3]\u00a0 Bikson, M., Esmaeilpour, Z., Adair, D., Kronberg, G., Tyler, W. J., Antal, A., Datta, A., Sabel, B. A., Nitsche, M. A., Loo, C., Edwards, D., Ekhtiari, H., Knotkova, H., Woods, A. J., Hampstead, ...",
      "author": "Adriel Carridice",
      "published_date": "2025-02-13T19:57:58+00:00",
      "source": "Brain",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 61,
      "reading_time": 1,
      "created_at": "2025-11-09T21:38:36.099928+00:00",
      "updated_at": "2025-11-09T21:38:36.099929+00:00"
    },
    {
      "id": "8bfe7b7f37af142b24b0fcd318868131",
      "url": "https://brain.ieee.org/braininsight-articles/ieee-brain-annual-flagship-workshop-a-success/",
      "title": "IEEE Brain Annual Flagship Workshop a Success",
      "content": "IEEE Brain once again hosted the IEEE Brain Discovery and Neurotechnology Workshop as a satellite event to the 2024 Society of Neuroscience Workshop (SfN). Approximately 180 attended the two-day event, which was held at the University of Illinois Chicago (UIC), October 3-4, 2024 (Figure 1). Groundbreaking solutions with the potential to improve quality of life and address neural disorders require ...",
      "author": "ieeebrain",
      "published_date": "2025-03-03T16:55:37+00:00",
      "source": "Brain",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 61,
      "reading_time": 1,
      "created_at": "2025-11-09T21:38:36.099904+00:00",
      "updated_at": "2025-11-09T21:38:36.099906+00:00"
    },
    {
      "id": "209424afdd2e0eada6c56131b4992826",
      "url": "https://www.sciencedirect.com/science/article/pii/S0006899325005943?dgcid=rss_sd_all",
      "title": "Bempedoic Acid mitigates BCG-induced depression in mice by modulating TNF-\u03b1/NF-\u03baB signaling and restoring brain serotonin contents",
      "content": "<p>Publication date: 15 December 2025</p><p><b>Source:</b> Brain Research, Volume 1869</p><p>Author(s): Ritesh S. Tarwani, Sanjay N. Awathale, Sameer N. Goyal, Abdulla K. Sherikar, Pradip P. Bawane, Kartik T. Nakhate</p>",
      "author": "",
      "published_date": null,
      "source": "Brain Research",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 27,
      "reading_time": 1,
      "created_at": "2025-11-09T21:38:21.029209+00:00",
      "updated_at": "2025-11-09T21:38:21.029211+00:00"
    },
    {
      "id": "9226a53d8e6b3cec4bcb41ea5036f717",
      "url": "https://www.sciencedirect.com/science/article/pii/S0006899325005797?dgcid=rss_sd_all",
      "title": "High-frequency transcranial magnetic stimulation decreases dorsal striatum dopamine D2 receptors in a rat model of depression",
      "content": "<p>Publication date: 15 December 2025</p><p><b>Source:</b> Brain Research, Volume 1869</p><p>Author(s): Palma-Anzures Irving Eduardo, Verdugo-Diaz Leticia</p>",
      "author": "",
      "published_date": null,
      "source": "Brain Research",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 14,
      "reading_time": 1,
      "created_at": "2025-11-09T21:38:21.029189+00:00",
      "updated_at": "2025-11-09T21:38:21.029190+00:00"
    },
    {
      "id": "5cd7ea45a372413b9687e29a3fc1caee",
      "url": "https://www.sciencedirect.com/science/article/pii/S000689932500589X?dgcid=rss_sd_all",
      "title": "RAGE signaling pathway in glioblastoma and cognitive decline: Insights into inflammatory mechanisms and therapeutic implications",
      "content": "<p>Publication date: 15 December 2025</p><p><b>Source:</b> Brain Research, Volume 1869</p><p>Author(s): Jemema Agnes Tripena Raj, Geofrey John, Shubham Ghanekar, Gokula Krishnan Thiruselvan, Janmay Shah, Deepak Ande, Abhishek Chatterjee, Jayant S. Goda</p>",
      "author": "",
      "published_date": null,
      "source": "Brain Research",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 29,
      "reading_time": 1,
      "created_at": "2025-11-09T21:38:21.029152+00:00",
      "updated_at": "2025-11-09T21:38:21.029153+00:00"
    }
  ],
  "recently_processed": [
    {
      "id": "a07bb58009d0c700eba383662b3fed57",
      "url": "http://daniellakens.blogspot.com/2025/09/type-s-and-m-errors-as-rhetorical-tool.html",
      "title": "Type S and M errors as a \u201crhetorical tool\u201d",
      "content": "<p><i>Update 30/09/2025: I have added a reply by Andrew Gelman below my original blog post.</i>&nbsp;</p><p>We recently\nposted a preprint criticizing the idea of Type S and M errors (<a href=\"https://osf.io/2phzb_v1\">https://osf.io/2phzb_v1</a>). From our abstract:\n\u201cWhile these concepts have been proposed to be useful both when designing a\nstudy (prospective) and when evaluating results (retroactive), we argue that\nthese statistics do not facilitate the proper design of studies, nor the\nmeaningful interpretation of results.\u201d</p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">In a recent\n<a href=\"https://statmodeling.stat.columbia.edu/2025/09/25/on-the-poor-statistical-properties-of-the-p-curve-meta-analytic-procedure/#comment-2403979\" target=\"_blank\">blog post</a> that is mainly on p-curve analysis, Gelman writes briefly about Type\nS and M errors, stating that he does not see them as tools that should be used\nregularly, but that they mainly function as a \u2018rhetorical tool\u2019:</span></p>\n\n<p class=\"MsoNormal\"><i><span lang=\"EN-US\">I offer\na three well-known examples of statistical ideas arising in the field of\nscience criticism, three methods whose main value is rhetorical:</span></i></p>\n\n<p class=\"MsoNormal\"><i><span lang=\"EN-US\">[\u2026]</span></i></p>\n\n<p class=\"MsoNormal\"><i><span lang=\"EN-US\">2. The\nconcepts of Type M and Type S errors, which I developed with Francis Tuerlinckx\nin 2000 and John Carlin in 2014. This has been an influential idea\u2013ok, not as\ninfluential as Ioannidis\u2019s paper!\u2013and I like it a lot, but it doesn\u2019t\ncorrespond to a method that I will typically use in practice. To me, the value\nof the concepts of Type M and Type S errors is they help us understand certain\nexisting statistical procedures, such as selection on statistical significance,\nthat have serious problems. There\u2019s mathematical content here for sure, but I\nfundamentally think of these error calculations as having rhetorical value for\nthe design of studies and interpretation of reported results.</span></i></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">The main\nsentence of interest here is that Gelman says this is not a method he would use\nin practice. I was surprised, because in their article Gelman and Carlin (2014)\nrecommend the calculation of Type S and M errors more forcefully: \u201cWe suggest\nthat design calculations be performed after as well as before data collection\nand analysis.\u201d Throughout their article, they compare design calculations where\nType S and M errors are calculated to power analyses, which are widely seen as\na requirement before data collection of any hypothesis testing study. For\nexample, in the abstract they write \u201cpower analysis is flawed in that a narrow\nemphasis on statistical significance is placed as the primary focus of study\ndesign. In noisy, small-sample settings, statistically significant results can\noften be misleading. To help researchers address this problem in the context of\ntheir own studies, we recommend design calculations\u201d.</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">They also say\ndesign calculations are useful when interpreting results, and that they add\nsomething to p-values and effect sizes, which again seems to suggest they can complement\nordinary data analysis: \u201cOur retrospective analysis provided useful insight, beyond\nwhat was revealed by the estimate, confidence interval, and p value that came\nfrom the original data summary.\u201d (Gelman &amp; Carlin, 2014, p. 646). In\ngeneral, they seem to suggest design analyses are done before or after data analysis:\n\u201cFirst, it is indeed preferable to do a design analysis ahead of time, but a\nresearcher can analyze data in many different ways\u2014indeed, an important part of\ndata analysis is the discovery of unanticipated patterns (Tukey, 1977) so that it\nis unreasonable to suppose that all potential analyses could have been\ndetermined ahead of time. The second reason for performing postdata design\ncalculations is that they can be a useful way to interpret the results from a\ndata analysis, as we next demonstrate in two examples.\u201d (Gelman &amp; Carlin,\n2014, p. 643).</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">One the other\nhand, in a single sentence in the discussion, they also write: \u201cOur goal in\ndeveloping this software is not so much to provide a tool for routine use but\nrather to demonstrate that such calculations are possible and to allow\nresearchers to play around and get a sense of the sizes of Type S errors and Type\nM errors in realistic data settings.\u201d</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">Maybe I\nhave always misinterpreted Gelman and Carlin, 2014, in that I took it as a\npaper that recommended the regular use of Type S and M errors, and I should\nhave understood that the sentence in the discussion made it clear that this was\nnever their intention. If the idea is to replace Type 1 and 2 errors, and\nhence, replace power analysis and the interpretation of data, design analysis\nshould be part of every hypothesis testing study. Sentences such as \u201cthe\nrequirement of design analysis can stimulate engagement with the existing literature\nin the subject-matter field\u201d seemed to suggest to me that design analyses could\nbe a requirement for all studies. But maybe I was wrong. </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">Or maybe I\nwasn\u2019t. </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">In this <a href=\"https://statmodeling.stat.columbia.edu/2016/11/13/more-on-my-paper-with-john-carlin-on-type-m-and-type-s-errors/\">blog\npost</a>, Gelman writes: \u201cNow, one odd thing about my paper with Carlin is that\nit gives some tools that I recommend others use when designing and evaluating\ntheir research, but I would not typically use these tools directly myself!\nBecause I am not wanting to summarize inference by statistical significance.\u201d So,\nhere there seems to be the idea that others routinely use Type S and M errors. And\nin a very early version of the paper with Carlin, available <a href=\"https://statmodeling.stat.columbia.edu/wp-content/uploads/2016/11/retropower.pdf\">here</a>,\nthe opening sentence also suggests routine use: \u201cThe present article proposes\nan ideal that every statistical analysis be followed up with a power\ncalculation to better understand the inference from the data. As the quotations\nabove illustrate, however, our suggestion contradicts the advice of many\nrespected statisticians. Our resolution of this apparent disagreement is that\nwe perform retrospective power analysis in a different way and for a different\npurpose than is typically recommended in the literature.\u201d</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">Of course,\none good thing about science is that people change their beliefs about things.\nMaybe Gelman one time thought Type S and M errors should be part of \u2018every\nstatistical analysis\u2019 but now sees the tool mainly as a \u2018rhetorical device\u2019. And\nthat is perfectly fine. It is also good to know, because I regular see people\nwho suggest that Type S and M error should routinely be used in practice. I\nguess I can now point them to a blog post where Gelman himself disagrees with\nthat suggestion.</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">As we explain\nin our preprint, the idea of Type S errors is conceptually incoherent, and any\nprobabilities calculated will be identical to the Type 1 error in directional\ntests, or the false discovery rate, as all that Type S errors do is remove the\npossibility of an effect being 0 from the distribution, but this probability is\nitself 0. We also explain how other tools are better to educate researchers\nabout effect size inflation in studies selected for significance (for which\nGelman would recommend Type M errors), and we actually recommend p-uniform for\nthis, or just teaching people about critical effect sizes.</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">Personally,\nI don\u2019t like rhetorical tools. Although in our preprint we agree that teaching\nthe idea of Type S and M errors can be useful in education, there are also conceptually\ncoherent and practically useful statistical ideas that we can teach instead to\nachieve the same understanding. Rhetorical tools might be useful to convince\npeople who do not think logically about a topic, but I prefer to have a\nslightly higher bar for the scientists that I aim to educate about good\nresearch practices, and I think they are able to understand the problem of low\nstatistical power and selection bias without rhetorical tools. </span></p><p class=\"MsoNormal\"><span lang=\"EN-US\"><br /></span></p><div>--Reply by Andrew Gelman--</div><p class=\"MsoNormal\"><span lang=\"EN-US\"></span></p><div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">Hi, Daniel. &nbsp;Thanks for your comments. &nbsp;It's always good to see that people are reading our articles and blog posts. &nbsp;I think you are a little bit confused about what we wrote, but ultimately that's our fault for not being clear, so I appreciate the opportunity to clarify.</div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">So you don't need to consider this comment as a \"rebuttal\" to your post. &nbsp;For convenience I'll go through several of your statements one by one, but my goal is to clarify.</div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">First, I guess I should've avoided the word \"rhetorical.\" &nbsp;In my post, I characterized Ioannidis's 2005 claim, type M and S errors, and multiverse analysis as \"rhetorical tools\" that have been been useful in the field of science criticism but which I would not use in my own analyses. &nbsp;I could've added to this many other statistical methods including p-values and Bayes factors.</div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">When I describe a statistical method as \"rhetorical\" in this context, I'm not saying it's mathematically invalid or that it's conceptually incoherent (to use your term), nor am I saying these methods should not be used! &nbsp;All these tools can be useful; they just rely on very strong assumptions. &nbsp;P-values and Bayes factors are measures of evidence relative to a null hypothesis (not just an assumption that a particular parameter equals zero, but an entire set of assumptions about the data-generating process) that is irrelevant in the science and decision problems I've seen--but these methods are clearly defined and theoretically justified, and many practitioners get a lot out of them. &nbsp;I very rarely would use p-values or Bayes factors in my work because I'm very rarely interested in this sort of discrepancy from a null hypothesis.</div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">A related point comes up in my paper with Hill and Yajima, \"Why we (usually) don't have to worry about multiple comparisons\" (https://sites.stat.columbia.edu/gelman/research/published/multiple2f.pdf). &nbsp;Multiple comparisons corrections can be important, indeed I've criticized some published work for misinterpreting evidence by not accounting for multiple comparisons or multiple potential comparisons--but it doesn't come up so much in the context of multilevel modeling.</div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">Ioannidis (2005) is a provocative paper that I think has a lot of value--but you have to be really careful to try to directly apply such an analysis to real data. &nbsp; He's making some really strong assumptions! &nbsp;The logic of his paper is clear, though. &nbsp;O'Rourke and I discuss the challenges of moving from that sort of model to larger conclusions in our 2013 paper (https://sites.stat.columbia.edu/gelman/research/published/GelmanORourkeBiostatistics.pdf).</div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">The multiverse is a cool idea, and researchers have found it to be useful. &nbsp;The sociologists Cristobal Young and Erin Cumberworth recently published a book on it (https://www.cambridge.org/core/books/multiverse-analysis/D53C3AB449F6747B4A319174E5C95FA1). &nbsp;I don't think I'd apply the method in my own applied research, though, because the whole idea of the multiverse is to consider all the possible analyses you might have done on a dataset, and if I get to that point I'm more inclined to fit a multilevel model that subsumes all these analyses. &nbsp;I have found multiverse analysis to be useful in understanding research published by others, and maybe it would be useful for my own work too, given that my final published analyses never really include all the possibilities of what I might have done. &nbsp;The point is that this is yet another useful method that can have conceptual value even if I might not apply it to my own work. &nbsp;Again, the term \"rhetorical\" might be misleading, as these are real methods that, like all statistical methods, are appropriate in some settings and not in others.</div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">So please don't let your personal dislike of the term \"rhetorical tools\" to dissuade you from taking seriously the tools that I happen to have characterized as \"rhetorical,\" as these include p-values, multiple comparisons corrections, Bayesian analysis with point priors, and all sorts of other methods that are rigorously defined and can be useful in many applied settings, including some of yours!</div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">OK, now on to Type M and Type S errors. &nbsp;You seem to imply that at some time I thought that these \"should be part of \u2018every statistical analysis,'\" but I can assure you that I have never believed or written such a thing. &nbsp;You put the phrase \"every statistical analysis,\" but this is your phrase, not mine.</div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">One very obvious way to see that I never thought Type M and Type S errors \"should be part of \u2018every statistical analysis'\" is that, since the appearance of that article in 2014, I've published dozens of applied papers, and in only very few of these did I look at Type M and Type S errors.</div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">What is that? &nbsp;Why is it that my colleagues and I came up with this idea that has been influential, and which I indeed think can be very useful and which I do think should often be used by practitioners, but I only use it myself?</div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">The reason is that the focus of our work on Type M and Type S errors has been to understand selection on statistical significance (as in that notorious estimate that early childhood intervention increases adult earnings by 42% on average, but with that being the result of an inferential procedure that, under any reasonable assumptions, greatly overestimates the magnitude of any real effect; that is, Type M error). &nbsp;In my applied work it's very rare that I condition on statistical significance, and so this sort of use of Type M and S errors is not so relevant. &nbsp;So it's perfectly coherent for me to say that Type M and S error analysis is valuable in a wide range of settings that that I think these tools should be applied very widely, without believing that they should be part of \"every statistical analysis\" or that I should necessarily use them for my own analyses.</div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">That said, more recently I've been thinking that Type M and S errors are a useful approach to understanding statistical estimates more generally, not just for estimates that are conditioned on statistical significance. &nbsp;I'm working with Erik van Zwet and Witold Wi\u0119cek on applying these ideas to Bayesian inferences as well. &nbsp;So I'm actually finding these methods to be more, not less, valuable for statistical understanding, and not just for \"people who do not think logically about a topic\" (in your phrasing). &nbsp;Our papers on these topics are published in real journals and of course they're intended for people who &lt;em&gt;do&lt;/em&gt; think logically about the topic! &nbsp;And, just to be clear, I believe that you're thinking logically in your post too; I just think you've been misled by my terminology (again, I accept the blame for that), and also you work on different sorts of problems than I do, so it makes sense that a method that I find useful might not be so helpful to you. &nbsp;There are many ways to Rome, which is another point I was making in that blog post.</div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">Finally, a few things in your post that I did not address above:</div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">1. &nbsp;You quote from my blog post, where I wrote, \u201cNow, one odd thing about my paper with Carlin is that it gives some tools that I recommend others use when designing and evaluating their research, but I would not typically use these tools directly myself! Because I am not wanting to summarize inference by statistical significance.\u201d &nbsp;That's exactly my point above! &nbsp;You had it right there.</div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">2. &nbsp;You wrote, \"Maybe I have always misinterpreted Gelman and Carlin, 2014, in that I took it as a paper that recommended the regular use of Type S and M errors, and I should have understood that the sentence in the discussion made it clear that this was never their intention.\" &nbsp;So, just to clarify, yes in our paper we recommended the regular use of Type M and S errors, and we still recommend that!</div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">3. &nbsp;You write that our \"sentences such as 'the requirement of design analysis can stimulate engagement with the existing literature in the subject-matter field' seemed to suggest to me that design analyses could be a requirement for all studies.\" &nbsp;That's right--I actually do think that design analysis should be done for all studies!</div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">OK, nothing is done all the time. &nbsp;I guess that some studies are so cheap that there's no need for a design analysis--or maybe we could say that in such studies the design analysis is implicit. &nbsp;For example, if I'm doing A/B testing in a company, and they've done lots of A/B tests before, and I think the new effect will be comparable to previous things being studied, then maybe I just go with the same design as in previous experiments, without performing a formal design analysis. &nbsp;But one could argue that this corresponds to some implicit calculation.</div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">In any case, yeah, in general I think that a design analysis should come before any study. &nbsp;Indeed, that is what I tell students and colleagues: &nbsp;never collect data before doing a simulation study first. &nbsp;Often we do fake-data simulation after the data come in, to validate our model-fitting strategies, but for a while I've been thinking it's best to do it before.</div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">This is not controversial advice in statistics, to recommend a design analysis before gathering data! &nbsp;Indeed, in medical research it's basically a requirement. &nbsp;In our paper, Carlin and I argue--and I still believe--that a design analysis using Type M and S errors is more valuable than the traditional Type 1 and 2 errors. &nbsp;But in any case I consider \"design analysis\" to be the general term, with \"power analysis\" being a special case (design analysis looking at the probability of attaining statistical significance). &nbsp;I don't think traditional power analysis is useless--one way you can see this is that we demonstrate power calculations in chapter 16 of Regression and Other Stories, a book that came out several years after my paper with Carlin--; I just think it can be misleading, especially if it is done without consideration of Type M and S errors.</div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">Thanks again for your comments. &nbsp;It's good to have an opportunity to clarify my thinking, and these are important issues in statistics.</div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">P.S. &nbsp;If you see something on our blog that you disagree with, feel free to comment there directly, as that way you can also reach readers of the original post.</div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\"><br /></div><div style=\"border: 0px; color: inherit; font: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">--</div></div><p class=\"MsoNormal\"><span lang=\"EN-US\">References:&nbsp;</span></p><p class=\"MsoNormal\"><span lang=\"EN-US\"></span></p>Lakens, D., Cristian, Xavier-Quintais, G., Rasti, S., Toffalini, E., &amp; Alto\u00e8, G. (2025). Rethinking Type S and M Errors. OSF. <a href=\"https://doi.org/10.31234/osf.io/2phzb_v1\">https://doi.org/10.31234/osf.io/2phzb_v1</a><br /> <br />Gelman, A., &amp; Carlin, J. (2014). Beyond Power Calculations: Assessing Type S (Sign) and Type M (Magnitude) Errors. Perspectives on Psychological Science, 9(6), 641\u2013651. <a href=\"https://doi.org/10.1177/1745691614551642\">https://doi.org/10.1177/1745691614551642</a>",
      "author": "noreply@blogger.com (Daniel Lakens)",
      "published_date": "2025-09-28T05:19:00+00:00",
      "source": "Twenty Percent Statistician",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 3572,
      "reading_time": 17,
      "created_at": "2025-11-09T21:38:42.154018+00:00",
      "updated_at": "2025-11-09T22:13:40.387848+00:00",
      "metadata": {
        "processed_at": "2025-11-09T22:13:40.387858+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "2a6bc54de609dadc09bfa1dff034bc9f",
      "url": "http://daniellakens.blogspot.com/2025/10/why-we-should-stop-using-statistical.html",
      "title": "Why we should stop using statistical techniques that have not been adequately vetted by experts in psychology",
      "content": "<p>&nbsp;<span lang=\"EN-US\">In a recent\npost on Bluesky, where Richard Morey reflects on a paper he published with\nClintin Davis-Stober that points out concerns with the p-curve method </span><span lang=\"EN-US\">(Morey\n&amp; Davis-Stober, 2025)</span><span lang=\"EN-US\">, he writes:</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p><div class=\"separator\" style=\"clear: both; text-align: center;\"><span lang=\"EN-US\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEjI0KItLxSX7t6TUpviOMhEMyZxxqsTENrz1FD9oLkCXms1pd4RNjtqs8H0iF8XkF_CjLPyK_HBNrchCgipO50ZrJzgKp8YG9sxg--Wln27EPWIzafjI0GGZ-ZoP-_em5netnWNoZi0TYZiQ3IES_HDC0bA6pRqyReRSNTVX90tC98y9SLtCIVCM8nwxTk\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" height=\"240\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEjI0KItLxSX7t6TUpviOMhEMyZxxqsTENrz1FD9oLkCXms1pd4RNjtqs8H0iF8XkF_CjLPyK_HBNrchCgipO50ZrJzgKp8YG9sxg--Wln27EPWIzafjI0GGZ-ZoP-_em5netnWNoZi0TYZiQ3IES_HDC0bA6pRqyReRSNTVX90tC98y9SLtCIVCM8nwxTk\" width=\"276\" /></a></span></div><span lang=\"EN-US\"><br /></span><p></p>\n\n<p class=\"MsoNormal\"><b><i><span lang=\"EN-US\">Also,\nI think people should stop using forensic meta-analytic techniques that have\nnot been adequately vetted by experts in statistics. The p-curve papers have\nvery little statistical detail, and were published in psych journals. They did\nnot get the scrutiny appropriate to their popularity. </span></i></b></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">Although I\nunderstand this post as an affective response, I also think this kind of thought is extremely dangerous and undermines science. In this blog post I want to\nunpack some of the consequences of thoughts like this, and how to deal with quality\ncontrol instead. </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<h4 style=\"text-align: left;\"><b><span lang=\"EN-US\">Adequately\nvetted by experts</span></b></h4>\n\n<p class=\"MsoNormal\"><b><span lang=\"EN-US\">&nbsp;</span></b></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">I am a big\nfan of better vetting of scientific work by experts. I would like expert\nstatisticians to vet the power analysis and statistical analyses in all your\npapers. But there are some problems. The first is in identifying expert\nstatisticians. There are many statisticians, but some get things wrong. Of\ncourse, those are not the experts that we want to do the vetting. So how do we\nidentify expert statisticians? </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">Let\u2019s see\nif we can identify expert statisticians by looking at Sue Duval and Richard\nTweedie. A look at their CV might convince you they are experts in statistics.\nBut wait! They developed the \u2018trim-and-fill\u2019 method. The abstract of their\nclassic 2000 paper is below: </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\"><!--[if gte vml 1]><v:shapetype id=\"_x0000_t75\" coordsize=\"21600,21600\"\n o:spt=\"75\" o:preferrelative=\"t\" path=\"m@4@5l@4@11@9@11@9@5xe\" filled=\"f\"\n stroked=\"f\">\n <v:stroke joinstyle=\"miter\"/>\n <v:formulas>\n  <v:f eqn=\"if lineDrawn pixelLineWidth 0\"/>\n  <v:f eqn=\"sum @0 1 0\"/>\n  <v:f eqn=\"sum 0 0 @1\"/>\n  <v:f eqn=\"prod @2 1 2\"/>\n  <v:f eqn=\"prod @3 21600 pixelWidth\"/>\n  <v:f eqn=\"prod @3 21600 pixelHeight\"/>\n  <v:f eqn=\"sum @0 0 1\"/>\n  <v:f eqn=\"prod @6 1 2\"/>\n  <v:f eqn=\"prod @7 21600 pixelWidth\"/>\n  <v:f eqn=\"sum @8 21600 0\"/>\n  <v:f eqn=\"prod @7 21600 pixelHeight\"/>\n  <v:f eqn=\"sum @10 21600 0\"/>\n </v:formulas>\n <v:path o:extrusionok=\"f\" gradientshapeok=\"t\" o:connecttype=\"rect\"/>\n <o:lock v:ext=\"edit\" aspectratio=\"t\"/>\n</v:shapetype><v:shape id=\"Picture_x0020_1\" o:spid=\"_x0000_i1025\" type=\"#_x0000_t75\"\n alt=\"A text on a white background&#10;&#10;AI-generated content may be incorrect.\"\n style='width:453.6pt;height:236.4pt;visibility:visible;mso-wrap-style:square'>\n <v:imagedata src=\"file:///C:/Users/dlakens/AppData/Local/Temp/msohtmlclip1/01/clip_image001.png\"\n  o:title=\"A text on a white background&#10;&#10;AI-generated content may be incorrect\"/>\n</v:shape><![endif]--><!--[if !vml]--><img alt=\"A text on a white background\n\nAI-generated content may be incorrect.\" height=\"315\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEjNQGtDVWd6fAsr74eSXC5MwUIPmkJoeyGpou9GpoC2BVd61xCcNR7O1NJ3SFBh1oN0eswtpjtUXPz7wOFO05hRWSmUrKBieaeU8dv6__8tbCUWd50Lf3I0ln7VaBtYlAYwGL3D-xQbUzTz8lS82_urZuQ6GIwA9WjTfd4Nxp-cwGSQfwlpaumRNrX_C2Y\" width=\"605\" /><!--[endif]--></span><span lang=\"EN-US\"></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">It turns\nout that, unlike they write in their abstract, the point estimate for the\nmeta-analytic effect size after adjusting for missing studies is not\napproximately correct at all </span><!--[if supportFields]><span lang=EN-US\nstyle='mso-ansi-language:EN-US'><span style='mso-element:field-begin'></span><span\nstyle='mso-spacerun:yes'>\u00a0</span>ADDIN ZOTERO_ITEM CSL_CITATION\n{&quot;citationID&quot;:&quot;cDKmwvMe&quot;,&quot;properties&quot;:{&quot;formattedCitation&quot;:&quot;(Peters\net al., 2007; Terrin et al., 2003)&quot;,&quot;plainCitation&quot;:&quot;(Peters\net al., 2007; Terrin et al.,\n2003)&quot;,&quot;noteIndex&quot;:0},&quot;citationItems&quot;:[{&quot;id&quot;:265,&quot;uris&quot;:[&quot;http://zotero.org/users/371621/items/Q9S5KI2H&quot;],&quot;itemData&quot;:{&quot;id&quot;:265,&quot;type&quot;:&quot;article-journal&quot;,&quot;abstract&quot;:&quot;The\ntrim and fill method allows estimation of an adjusted meta-analysis estimate in\nthe presence of publication bias. To date, the performance of the trim and fill\nmethod has had little assessment. In this paper, we provide a more\ncomprehensive examination of different versions of the trim and fill method in\na number of simulated meta-analysis scenarios, comparing results with those\nfrom usual unadjusted meta-analysis models and two simple alternatives, namely\nuse of the estimate from: (i) the largest; or (ii) the most precise study in\nthe meta-analysis. Findings suggest a great deal of variability in the\nperformance of the different approaches. When there is large between-study\nheterogeneity the trim and fill method can underestimate the true positive\neffect when there is no publication bias. However, when publication bias is\npresent the trim and fill method can give estimates that are less biased than\nthe usual meta-analysis models. Although results suggest that the use of the estimate\nfrom the largest or most precise study seems a reasonable approach in the\npresence of publication bias, when between-study heterogeneity exists our\nsimulations show that these estimates are quite biased. We conclude that in the\npresence of publication bias use of the trim and fill method can help to reduce\nthe bias in pooled estimates, even though the performance of this method is not\nideal. However, because we do not know whether funnel plot asymmetry is truly\ncaused by publication bias, and because there is great variability in the\nperformance of different trim and fill estimators and models in various\nmeta-analysis scenarios, we recommend use of the trim and fill method as a form\nof sensitivity analysis as intended by the authors of the method.&quot;,&quot;container-title&quot;:&quot;Statistics\nin\nMedicine&quot;,&quot;DOI&quot;:&quot;10.1002/sim.2889&quot;,&quot;ISSN&quot;:&quot;0277-6715&quot;,&quot;issue&quot;:&quot;25&quot;,&quot;journalAbbreviation&quot;:&quot;Stat\nMed&quot;,&quot;language&quot;:&quot;eng&quot;,&quot;note&quot;:&quot;PMID:\n17476644&quot;,&quot;page&quot;:&quot;4544-4562&quot;,&quot;source&quot;:&quot;PubMed&quot;,&quot;title&quot;:&quot;Performance\nof the trim and fill method in the presence of publication bias and\nbetween-study\nheterogeneity&quot;,&quot;volume&quot;:&quot;26&quot;,&quot;author&quot;:[{&quot;family&quot;:&quot;Peters&quot;,&quot;given&quot;:&quot;Jaime\nL.&quot;},{&quot;family&quot;:&quot;Sutton&quot;,&quot;given&quot;:&quot;Alex\nJ.&quot;},{&quot;family&quot;:&quot;Jones&quot;,&quot;given&quot;:&quot;David\nR.&quot;},{&quot;family&quot;:&quot;Abrams&quot;,&quot;given&quot;:&quot;Keith\nR.&quot;},{&quot;family&quot;:&quot;Rushton&quot;,&quot;given&quot;:&quot;Lesley&quot;}],&quot;issued&quot;:{&quot;date-parts&quot;:[[&quot;2007&quot;,11,10]]}}},{&quot;id&quot;:264,&quot;uris&quot;:[&quot;http://zotero.org/users/371621/items/DMQP989N&quot;],&quot;itemData&quot;:{&quot;id&quot;:264,&quot;type&quot;:&quot;article-journal&quot;,&quot;abstract&quot;:&quot;It\nis known that the existence of publication bias can influence the conclusions\nof a meta-analysis. Some methods have been developed to deal with publication\nbias, but issues remain. One particular method called 'trim and fill' is\ndesigned to adjust for publication bias. The method, which is intuitively\nappealing and comprehensible by non-statisticians, is based on a simple and\npopular graphical tool called the funnel plot. We present a simulation study\ndesigned to evaluate the behaviour of this method. Our results indicate that\nwhen the studies are heterogeneous (that is, when they estimate different\neffects), trim and fill may inappropriately adjust for publication bias where\nnone exists. We found that trim and fill may spuriously adjust for non-existent\nbias if (i) the variability among studies causes some precisely estimated\nstudies to have effects far from the global mean or (ii) an inverse\nrelationship between treatment efficacy and sample size is introduced by the\nstudies' a priori power calculations. The results suggest that the funnel plot\nitself is inappropriate for heterogeneous meta-analyses. Selection modelling is\nan alternative method warranting further study. It performed better than trim\nand fill in our simulations, although its frequency of convergence varied,\ndepending on the simulation parameters.&quot;,&quot;container-title&quot;:&quot;Statistics\nin\nMedicine&quot;,&quot;DOI&quot;:&quot;10.1002/sim.1461&quot;,&quot;ISSN&quot;:&quot;0277-6715&quot;,&quot;issue&quot;:&quot;13&quot;,&quot;journalAbbreviation&quot;:&quot;Stat\nMed&quot;,&quot;language&quot;:&quot;eng&quot;,&quot;note&quot;:&quot;PMID:\n12820277&quot;,&quot;page&quot;:&quot;2113-2126&quot;,&quot;source&quot;:&quot;PubMed&quot;,&quot;title&quot;:&quot;Adjusting\nfor publication bias in the presence of\nheterogeneity&quot;,&quot;volume&quot;:&quot;22&quot;,&quot;author&quot;:[{&quot;family&quot;:&quot;Terrin&quot;,&quot;given&quot;:&quot;Norma&quot;},{&quot;family&quot;:&quot;Schmid&quot;,&quot;given&quot;:&quot;Christopher\nH.&quot;},{&quot;family&quot;:&quot;Lau&quot;,&quot;given&quot;:&quot;Joseph&quot;},{&quot;family&quot;:&quot;Olkin&quot;,&quot;given&quot;:&quot;Ingram&quot;}],&quot;issued&quot;:{&quot;date-parts&quot;:[[&quot;2003&quot;,7,15]]}}}],&quot;schema&quot;:&quot;https://github.com/citation-style-language/schema/raw/master/csl-citation.json&quot;}\n<span style='mso-element:field-separator'></span></span><![endif]--><span lang=\"EN-US\">(Peters\net al., 2007; Terrin et al., 2003)</span><!--[if supportFields]><span\nlang=EN-US style='mso-ansi-language:EN-US'><span style='mso-element:field-end'></span></span><![endif]--><span lang=\"EN-US\">. So clearly, Duval and Tweedie are\nstatisticians, but not the expert statisticians that we want to vet others.\nThey got things wrong, and more problematically, they got things wrong in the\nJournal of the American Statistical Association. </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">In some\ncases, the problems in the work by statisticians is so easy to spot, even a\nlowly psychologist like myself can point out the problems. When a team of\nbiostatisticians proposed a \u2018second generation p-value\u2019, without mentioning\nequivalence tests anywhere in their paper, two psychologists (myself and Marie\nDelacre) had to point out that the statistic they had invented was very similar\nto an equivalence test, except that it had a number of undesirable properties </span><!--[if supportFields]><span\nlang=EN-US style='mso-ansi-language:EN-US'><span style='mso-element:field-begin'></span><span\nstyle='mso-spacerun:yes'>\u00a0</span>ADDIN ZOTERO_ITEM CSL_CITATION {&quot;citationID&quot;:&quot;VLPjEywR&quot;,&quot;properties&quot;:{&quot;formattedCitation&quot;:&quot;(Lakens\n&amp; Delacre, 2020)&quot;,&quot;plainCitation&quot;:&quot;(Lakens &amp;\nDelacre,\n2020)&quot;,&quot;noteIndex&quot;:0},&quot;citationItems&quot;:[{&quot;id&quot;:2326,&quot;uris&quot;:[&quot;http://zotero.org/users/371621/items/GPTQUMXG&quot;],&quot;itemData&quot;:{&quot;id&quot;:2326,&quot;type&quot;:&quot;article-journal&quot;,&quot;abstract&quot;:&quot;To\nmove beyond the limitations of null-hypothesis tests, statistical approaches\nhave been developed where the observed data are compared against a range of\nvalues that are equivalent to the absence of a meaningful effect. Specifying a\nrange of values around zero allows researchers to statistically reject the\npresence of effects large enough to matter, and prevents practically\ninsignificant effects from being interpreted as a statistically significant\ndifference. We compare the behavior of the recently proposed second generation\np-value (Blume, D\u2019Agostino McGowan, Dupont, &amp; Greevy, 2018) with the more\nestablished Two One-Sided Tests (TOST) equivalence testing procedure\n(Schuirmann, 1987). We show that the two approaches yield almost identical\nresults under optimal conditions. Under suboptimal conditions (e.g., when the\nconfidence interval is wider than the equivalence range, or when confidence\nintervals are asymmetric) the second generation p-value becomes difficult to\ninterpret. The second generation p-value is interpretable in a dichotomous\nmanner (i.e., when the SGPV equals 0 or 1 because the confidence intervals lies\ncompletely within or outside of the equivalence range), but this dichotomous\ninterpretation does not require calculations. We conclude that equivalence\ntests yield more consistent p-values, distinguish between datasets that yield\nthe same second generation p-value, and allow for easier control of Type I and\nType II error rates.&quot;,&quot;container-title&quot;:&quot;Meta-Psychology&quot;,&quot;DOI&quot;:&quot;10.15626/MP.2018.933&quot;,&quot;ISSN&quot;:&quot;2003-2714&quot;,&quot;language&quot;:&quot;en&quot;,&quot;license&quot;:&quot;Copyright\n(c) 2020 Daniel Lakens, Marie Delacre&quot;,&quot;page&quot;:&quot;1-11&quot;,&quot;source&quot;:&quot;open.lnu.se&quot;,&quot;title&quot;:&quot;Equivalence\nTesting and the Second Generation\nP-Value&quot;,&quot;volume&quot;:&quot;4&quot;,&quot;author&quot;:[{&quot;family&quot;:&quot;Lakens&quot;,&quot;given&quot;:&quot;Dani\u00ebl&quot;},{&quot;family&quot;:&quot;Delacre&quot;,&quot;given&quot;:&quot;Marie&quot;}],&quot;issued&quot;:{&quot;date-parts&quot;:[[&quot;2020&quot;,7,13]]}}}],&quot;schema&quot;:&quot;https://github.com/citation-style-language/schema/raw/master/csl-citation.json&quot;}\n<span style='mso-element:field-separator'></span></span><![endif]--><span lang=\"EN-US\">(Lakens\n&amp; Delacre, 2020)</span><!--[if supportFields]><span lang=EN-US\nstyle='mso-ansi-language:EN-US'><span style='mso-element:field-end'></span></span><![endif]--><span lang=\"EN-US\">. I guess based on this anecdotal\nexperience, there is nothing left but to create the rule that we should stop\nusing statistical tests that have not been adequately vetted by experts in\npsychology.</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">Although it\ngreatly helps to have expertise in topics that you want to scrutinize,\nsometimes the most fatal criticism comes from elsewhere. Experts make mistakes \u2013\noverconfidence is a thing. I recently very confidently made a statement in a\n(signed) peer review, that (I am still examining the topic) I might have been\nwrong about. I don\u2019t want to be the expert to \u2018vet\u2019 a method and allow it to be\nused based on my authority. More importantly, I think no one should want a\nscience where authorities tell us which methods are vetted, and which are not.\nIt would undermine the very core of what science is to me \u2013 a fallible system\nof knowledge generation which relies on open mutual criticism. </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<h4 style=\"text-align: left;\"><b><span lang=\"EN-US\">Scrutiny\nappropriate to their popularity</span></b></h4>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">I am a big\nfan of increasing our scrutiny based on how popular something is. Indeed, this\nis exactly what Peder Isager, myself, and our collaborators propose in our work\non the Replication Value: The more popular a finding is, and the less certain,\nthe more deserving of an independent direct replication the study is </span><!--[if supportFields]><span\nlang=EN-US style='mso-ansi-language:EN-US'><span style='mso-element:field-begin'></span><span\nstyle='mso-spacerun:yes'>\u00a0</span>ADDIN ZOTERO_ITEM CSL_CITATION\n{&quot;citationID&quot;:&quot;qs7GmZE3&quot;,&quot;properties&quot;:{&quot;formattedCitation&quot;:&quot;(Isager\net al., 2023, 2024)&quot;,&quot;plainCitation&quot;:&quot;(Isager et al., 2023,\n2024)&quot;,&quot;noteIndex&quot;:0},&quot;citationItems&quot;:[{&quot;id&quot;:3512,&quot;uris&quot;:[&quot;http://zotero.org/users/371621/items/AEHH9HZT&quot;],&quot;itemData&quot;:{&quot;id&quot;:3512,&quot;type&quot;:&quot;article-journal&quot;,&quot;abstract&quot;:&quot;Robust\nscientific knowledge is contingent upon replication of original findings.\nHowever, replicating researchers are constrained by resources, and will almost\nalways have to choose one replication effort to focus on from a set of\npotential candidates. To select a candidate efficiently in these cases, we need\nmethods for deciding which out of all candidates considered would be the most\nuseful to replicate, given some overall goal researchers wish to achieve. In\nthis article we assume that the overall goal researchers wish to achieve is to\nmaximize the utility gained by conducting the replication study. We then\npropose a general rule for study selection in replication research based on the\nreplication value of the set of claims considered for replication. The\nreplication value of a claim is defined as the maximum expected utility we\ncould gain by conducting a replication of the claim, and is a function of (a)\nthe value of being certain about the claim, and (b) uncertainty about the claim\nbased on current evidence. We formalize this definition in terms of a causal\ndecision model, utilizing concepts from decision theory and causal graph\nmodeling. We discuss the validity of using replication value as a measure of\nexpected utility gain, and we suggest approaches for deriving quantitative\nestimates of replication value. Our goal in this article is not to define\nconcrete guidelines for study selection, but to provide the necessary\ntheoretical foundations on which such concrete guidelines could be built.\n(PsycInfo Database Record (c) 2023 APA, all rights\nreserved).&quot;,&quot;container-title&quot;:&quot;Psychological Methods&quot;,&quot;DOI&quot;:&quot;10.1037/met0000438&quot;,&quot;ISSN&quot;:&quot;1939-1463&quot;,&quot;issue&quot;:&quot;2&quot;,&quot;journalAbbreviation&quot;:&quot;Psychol\nMethods&quot;,&quot;language&quot;:&quot;eng&quot;,&quot;note&quot;:&quot;PMID:\n34928679&quot;,&quot;page&quot;:&quot;438-451&quot;,&quot;source&quot;:&quot;PubMed&quot;,&quot;title&quot;:&quot;Deciding\nwhat to replicate: A decision model for replication study selection under\nresource and knowledge constraints&quot;,&quot;title-short&quot;:&quot;Deciding\nwhat to\nreplicate&quot;,&quot;volume&quot;:&quot;28&quot;,&quot;author&quot;:[{&quot;family&quot;:&quot;Isager&quot;,&quot;given&quot;:&quot;Peder\nMortvedt&quot;},{&quot;family&quot;:&quot;Aert&quot;,&quot;given&quot;:&quot;Robbie\nC.\nM.&quot;,&quot;non-dropping-particle&quot;:&quot;van&quot;},{&quot;family&quot;:&quot;Bahn\u00edk&quot;,&quot;given&quot;:&quot;\u0160t\u011bp\u00e1n&quot;},{&quot;family&quot;:&quot;Brandt&quot;,&quot;given&quot;:&quot;Mark\nJ.&quot;},{&quot;family&quot;:&quot;DeSoto&quot;,&quot;given&quot;:&quot;K.\nAndrew&quot;},{&quot;family&quot;:&quot;Giner-Sorolla&quot;,&quot;given&quot;:&quot;Roger&quot;},{&quot;family&quot;:&quot;Krueger&quot;,&quot;given&quot;:&quot;Joachim\nI.&quot;},{&quot;family&quot;:&quot;Perugini&quot;,&quot;given&quot;:&quot;Marco&quot;},{&quot;family&quot;:&quot;Ropovik&quot;,&quot;given&quot;:&quot;Ivan&quot;},{&quot;family&quot;:&quot;Veer&quot;,&quot;given&quot;:&quot;Anna\nE.&quot;,&quot;non-dropping-particle&quot;:&quot;van\n't&quot;},{&quot;family&quot;:&quot;Vranka&quot;,&quot;given&quot;:&quot;Marek&quot;},{&quot;family&quot;:&quot;Lakens&quot;,&quot;given&quot;:&quot;Dani\u00ebl&quot;}],&quot;issued&quot;:{&quot;date-parts&quot;:[[&quot;2023&quot;,4]]}}},{&quot;id&quot;:181,&quot;uris&quot;:[&quot;http://zotero.org/users/371621/items/QYUHTHX2&quot;],&quot;itemData&quot;:{&quot;id&quot;:181,&quot;type&quot;:&quot;article-journal&quot;,&quot;abstract&quot;:&quot;Replication\nof published results is crucial for ensuring the robustness and self-correction\nof research, yet replications are scarce in many fields. Replicating\nresearchers will therefore often have to decide which of several relevant\ncandidates to target for replication. Formal strategies for efficient study\nselection have been proposed, but none have been explored for practical\nfeasibility \u2013 a prerequisite for validation. Here we move one step closer to\nefficient replication study selection by exploring the feasibility of a\nparticular selection strategy that estimates replication value as a function of\ncitation impact and sample size (Isager, van 't Veer, &amp; Lakens, 2021). We\ntested our strategy on a sample of fMRI studies in social neuroscience. We\nfirst report our efforts to generate a representative candidate set of\nreplication targets. We then explore the feasibility and reliability of\nestimating replication value for the targets in our set, resulting in a dataset\nof 1358 studies ranked on their value of prioritising them for replication. In\naddition, we carefully examine possible measures, test auxiliary assumptions,\nand identify boundary conditions of measuring value and uncertainty. We end our\nreport by discussing how future validation studies might be designed. Our study\ndemonstrates the importance of investigating how to implement study selection\nstrategies in practice. Our sample and study design can be extended to explore\nthe feasibility of other formal study selection strategies that have been\nproposed.&quot;,&quot;container-title&quot;:&quot;Cortex&quot;,&quot;DOI&quot;:&quot;10.1016/j.cortex.2023.10.012&quot;,&quot;ISSN&quot;:&quot;0010-9452&quot;,&quot;journalAbbreviation&quot;:&quot;Cortex&quot;,&quot;page&quot;:&quot;330-346&quot;,&quot;source&quot;:&quot;ScienceDirect&quot;,&quot;title&quot;:&quot;Exploring\na formal approach to selecting studies for replication: A feasibility study in\nsocial neuroscience&quot;,&quot;title-short&quot;:&quot;Exploring a formal\napproach to selecting studies for replication&quot;,&quot;volume&quot;:&quot;171&quot;,&quot;author&quot;:[{&quot;family&quot;:&quot;Isager&quot;,&quot;given&quot;:&quot;Peder\nM.&quot;},{&quot;family&quot;:&quot;Lakens&quot;,&quot;given&quot;:&quot;Dani\u00ebl&quot;},{&quot;family&quot;:&quot;Leeuwen&quot;,&quot;given&quot;:&quot;Thed&quot;,&quot;non-dropping-particle&quot;:&quot;van&quot;},{&quot;family&quot;:&quot;Veer&quot;,&quot;given&quot;:&quot;Anna\nE.&quot;,&quot;non-dropping-particle&quot;:&quot;van\n't&quot;}],&quot;issued&quot;:{&quot;date-parts&quot;:[[&quot;2024&quot;,2,1]]}}}],&quot;schema&quot;:&quot;https://github.com/citation-style-language/schema/raw/master/csl-citation.json&quot;}\n<span style='mso-element:field-separator'></span></span><![endif]--><span lang=\"EN-US\">(Isager\net al., 2023, 2024)</span><!--[if supportFields]><span lang=EN-US\nstyle='mso-ansi-language:EN-US'><span style='mso-element:field-end'></span></span><![endif]--><span lang=\"EN-US\">.</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">There are\ntwo challenges. The first is that at the moment that a method is first\npublished we do not know how popular it will become. So there is a time where\nmethods exists, and are used, without being criticized, as their popularity\ntakes some time to become clear. The first paper on p-curve analysis was\npublished in 2014 </span><!--[if supportFields]><span lang=EN-US\nstyle='mso-ansi-language:EN-US'><span style='mso-element:field-begin'></span><span\nstyle='mso-spacerun:yes'>\u00a0</span>ADDIN ZOTERO_ITEM CSL_CITATION\n{&quot;citationID&quot;:&quot;UNZvWnUX&quot;,&quot;properties&quot;:{&quot;formattedCitation&quot;:&quot;(Simonsohn\net al., 2014)&quot;,&quot;plainCitation&quot;:&quot;(Simonsohn et al.,\n2014)&quot;,&quot;noteIndex&quot;:0},&quot;citationItems&quot;:[{&quot;id&quot;:1042,&quot;uris&quot;:[&quot;http://zotero.org/users/371621/items/R8U39QMV&quot;],&quot;itemData&quot;:{&quot;id&quot;:1042,&quot;type&quot;:&quot;article-journal&quot;,&quot;container-title&quot;:&quot;Perspectives\non Psychological Science&quot;,&quot;issue&quot;:&quot;6&quot;,&quot;page&quot;:&quot;666\u2013681&quot;,&quot;source&quot;:&quot;Google\nScholar&quot;,&quot;title&quot;:&quot;p-Curve and Effect Size Correcting for\nPublication Bias Using Only Significant\nResults&quot;,&quot;volume&quot;:&quot;9&quot;,&quot;author&quot;:[{&quot;family&quot;:&quot;Simonsohn&quot;,&quot;given&quot;:&quot;Uri&quot;},{&quot;family&quot;:&quot;Nelson&quot;,&quot;given&quot;:&quot;Leif\nD.&quot;},{&quot;family&quot;:&quot;Simmons&quot;,&quot;given&quot;:&quot;Joseph\nP.&quot;}],&quot;issued&quot;:{&quot;date-parts&quot;:[[&quot;2014&quot;]]}}}],&quot;schema&quot;:&quot;https://github.com/citation-style-language/schema/raw/master/csl-citation.json&quot;}\n<span style='mso-element:field-separator'></span></span><![endif]--><span lang=\"EN-US\">(Simonsohn\net al., 2014)</span><!--[if supportFields]><span lang=EN-US style='mso-ansi-language:\nEN-US'><span style='mso-element:field-end'></span></span><![endif]--><span lang=\"EN-US\">, with an update in 2015 </span><!--[if supportFields]><span\nlang=EN-US style='mso-ansi-language:EN-US'><span style='mso-element:field-begin'></span><span\nstyle='mso-spacerun:yes'>\u00a0</span>ADDIN ZOTERO_ITEM CSL_CITATION\n{&quot;citationID&quot;:&quot;mqnLfToq&quot;,&quot;properties&quot;:{&quot;formattedCitation&quot;:&quot;(Simonsohn\net al., 2015)&quot;,&quot;plainCitation&quot;:&quot;(Simonsohn et al.,\n2015)&quot;,&quot;noteIndex&quot;:0},&quot;citationItems&quot;:[{&quot;id&quot;:16638,&quot;uris&quot;:[&quot;http://zotero.org/users/371621/items/D6HYJU25&quot;],&quot;itemData&quot;:{&quot;id&quot;:16638,&quot;type&quot;:&quot;article-journal&quot;,&quot;abstract&quot;:&quot;When\nstudies examine true effects, they generate right-skewed p-curves,\ndistributions of statistically significant results with more low (.01 s) than\nhigh (.04 s) p values. What else can cause a right-skewed p-curve? First, we\nconsider the possibility that researchers report only the smallest significant\np value (as conjectured by Ulrich &amp; Miller, 2015), concluding that it is a\nvery uncommon problem. We then consider more common problems, including (a)\np-curvers selecting the wrong p values, (b) fake data, (c) honest errors, and\n(d) ambitiously p-hacked (beyond p &lt; .05) results. We evaluate the impact of\nthese common problems on the validity of p-curve analysis, and provide\npractical solutions that substantially increase its\nrobustness.&quot;,&quot;container-title&quot;:&quot;Journal of Experimental\nPsychology.\nGeneral&quot;,&quot;DOI&quot;:&quot;10.1037/xge0000104&quot;,&quot;ISSN&quot;:&quot;1939-2222&quot;,&quot;issue&quot;:&quot;6&quot;,&quot;journalAbbreviation&quot;:&quot;J\nExp Psychol\nGen&quot;,&quot;language&quot;:&quot;eng&quot;,&quot;note&quot;:&quot;PMID:\n26595842&quot;,&quot;page&quot;:&quot;1146-1152&quot;,&quot;source&quot;:&quot;PubMed&quot;,&quot;title&quot;:&quot;Better\nP-curves: Making P-curve analysis more robust to errors, fraud, and ambitious\nP-hacking, a Reply to Ulrich and Miller\n(2015)&quot;,&quot;title-short&quot;:&quot;Better\nP-curves&quot;,&quot;volume&quot;:&quot;144&quot;,&quot;author&quot;:[{&quot;family&quot;:&quot;Simonsohn&quot;,&quot;given&quot;:&quot;Uri&quot;},{&quot;family&quot;:&quot;Simmons&quot;,&quot;given&quot;:&quot;Joseph\nP.&quot;},{&quot;family&quot;:&quot;Nelson&quot;,&quot;given&quot;:&quot;Leif\nD.&quot;}],&quot;issued&quot;:{&quot;date-parts&quot;:[[&quot;2015&quot;,12]]}}}],&quot;schema&quot;:&quot;https://github.com/citation-style-language/schema/raw/master/csl-citation.json&quot;}\n<span style='mso-element:field-separator'></span></span><![endif]--><span lang=\"EN-US\">(Simonsohn\net al., 2015)</span><!--[if supportFields]><span lang=EN-US style='mso-ansi-language:\nEN-US'><span style='mso-element:field-end'></span></span><![endif]--><span lang=\"EN-US\">. A very compelling criticism of\np-curve that pointed out strong limitations was published in a preprint in\n2017, and appeared in print 2 years later </span><!--[if supportFields]><span\nlang=EN-US style='mso-ansi-language:EN-US'><span style='mso-element:field-begin'></span><span\nstyle='mso-spacerun:yes'>\u00a0</span>ADDIN ZOTERO_ITEM CSL_CITATION\n{&quot;citationID&quot;:&quot;rJyeU3HM&quot;,&quot;properties&quot;:{&quot;formattedCitation&quot;:&quot;(Carter\net al., 2019)&quot;,&quot;plainCitation&quot;:&quot;(Carter et al., 2019)&quot;,&quot;noteIndex&quot;:0},&quot;citationItems&quot;:[{&quot;id&quot;:2016,&quot;uris&quot;:[&quot;http://zotero.org/users/371621/items/3BWXYXY5&quot;],&quot;itemData&quot;:{&quot;id&quot;:2016,&quot;type&quot;:&quot;article-journal&quot;,&quot;abstract&quot;:&quot;Publication\nbias and questionable research practices in primary research can lead to badly\noverestimated effects in meta-analysis. Methodologists have proposed a variety\nof statistical approaches to correct for such overestimation. However, it is\nnot clear which methods work best for data typically seen in psychology. Here,\nwe present a comprehensive simulation study in which we examined how some of\nthe most promising meta-analytic methods perform on data that might\nrealistically be produced by research in psychology. We simulated several\nlevels of questionable research practices, publication bias, and heterogeneity,\nand used study sample sizes empirically derived from the literature. Our\nresults clearly indicated that no single meta-analytic method consistently\noutperformed all the others. Therefore, we recommend that meta-analysts in\npsychology focus on sensitivity analyses\u2014that is, report on a variety of\nmethods, consider the conditions under which these methods fail (as indicated\nby simulation studies such as ours), and then report how conclusions might\nchange depending on which conditions are most plausible. Moreover, given the\ndependence of meta-analytic methods on untestable assumptions, we strongly\nrecommend that researchers in psychology continue their efforts to improve the\nprimary literature and conduct large-scale, preregistered replications. We\nprovide detailed results and simulation code at https://osf.io/rf3ys and\ninteractive figures at\nhttp://www.shinyapps.org/apps/metaExplorer/.&quot;,&quot;container-title&quot;:&quot;Advances\nin Methods and Practices in Psychological\nScience&quot;,&quot;DOI&quot;:&quot;10.1177/2515245919847196&quot;,&quot;ISSN&quot;:&quot;2515-2459&quot;,&quot;issue&quot;:&quot;2&quot;,&quot;journalAbbreviation&quot;:&quot;Advances\nin Methods and Practices in Psychological\nScience&quot;,&quot;language&quot;:&quot;en&quot;,&quot;page&quot;:&quot;115-144&quot;,&quot;source&quot;:&quot;SAGE\nJournals&quot;,&quot;title&quot;:&quot;Correcting for Bias in Psychology: A\nComparison of Meta-Analytic\nMethods&quot;,&quot;title-short&quot;:&quot;Correcting for Bias in\nPsychology&quot;,&quot;volume&quot;:&quot;2&quot;,&quot;author&quot;:[{&quot;family&quot;:&quot;Carter&quot;,&quot;given&quot;:&quot;Evan\nC.&quot;},{&quot;family&quot;:&quot;Sch\u00f6nbrodt&quot;,&quot;given&quot;:&quot;Felix\nD.&quot;},{&quot;family&quot;:&quot;Gervais&quot;,&quot;given&quot;:&quot;Will\nM.&quot;},{&quot;family&quot;:&quot;Hilgard&quot;,&quot;given&quot;:&quot;Joseph&quot;}],&quot;issued&quot;:{&quot;date-parts&quot;:[[&quot;2019&quot;,6,1]]}}}],&quot;schema&quot;:&quot;https://github.com/citation-style-language/schema/raw/master/csl-citation.json&quot;}\n<span style='mso-element:field-separator'></span></span><![endif]--><span lang=\"EN-US\">(Carter\net al., 2019)</span><!--[if supportFields]><span lang=EN-US style='mso-ansi-language:\nEN-US'><span style='mso-element:field-end'></span></span><![endif]--><span lang=\"EN-US\">. It convincingly showed that\np-curve does not work well under heterogeneity, and there often is\nheterogeneity. Other methods, such as z-curve analysis, were developed and\nshowed better performance under heterogeneity </span><!--[if supportFields]><span\nlang=EN-US style='mso-ansi-language:EN-US'><span style='mso-element:field-begin'></span><span\nstyle='mso-spacerun:yes'>\u00a0</span>ADDIN ZOTERO_ITEM CSL_CITATION\n{&quot;citationID&quot;:&quot;MQpoUbbs&quot;,&quot;properties&quot;:{&quot;formattedCitation&quot;:&quot;(Brunner\n&amp; Schimmack, 2020)&quot;,&quot;plainCitation&quot;:&quot;(Brunner &amp;\nSchimmack,\n2020)&quot;,&quot;noteIndex&quot;:0},&quot;citationItems&quot;:[{&quot;id&quot;:261,&quot;uris&quot;:[&quot;http://zotero.org/users/371621/items/L58VDF5E&quot;],&quot;itemData&quot;:{&quot;id&quot;:261,&quot;type&quot;:&quot;article-journal&quot;,&quot;abstract&quot;:&quot;In\nscientific fields that use significance tests, statistical power is important\nfor successful replications of significant results because it is the long-run\nsuccess rate in a series of exact replication studies. For any population of\nsignificant results, there is a population of power values of the statistical\ntests on which conclusions are based. We give exact theoretical results showing\nhow selection for significance affects the distribution of statistical power in\na heterogeneous population of significance tests. In a set of large-scale\nsimulation studies, we compare four methods for estimating population mean\npower of a set of studies selected for significance (a maximum likelihood\nmodel, extensions of p-curve and p-uniform, &amp;amp; z-curve). The p-uniform\nand p-curve methods performed well with a fixed effects size and varying sample\nsizes. However, when there was substantial variability in effect sizes as well\nas sample sizes, both methods systematically overestimate mean power. With\nheterogeneity in effect sizes, the maximum likelihood model produced the most\naccurate estimates when the distribution of effect sizes matched the\nassumptions of the model, but z-curve produced more accurate estimates when the\nassumptions of the maximum likelihood model were not met. We recommend the use\nof z-curve to estimate the typical power of significant results, which has\nimplications for the replicability of significant results in psychology\njournals.&quot;,&quot;container-title&quot;:&quot;Meta-Psychology&quot;,&quot;DOI&quot;:&quot;10.15626/MP.2018.874&quot;,&quot;ISSN&quot;:&quot;2003-2714&quot;,&quot;language&quot;:&quot;en&quot;,&quot;license&quot;:&quot;Copyright\n(c) 2020 Jerry Brunner, Ulrich\nSchimmack&quot;,&quot;source&quot;:&quot;open.lnu.se&quot;,&quot;title&quot;:&quot;Estimating\nPopulation Mean Power Under Conditions of Heterogeneity and Selection for\nSignificance&quot;,&quot;URL&quot;:&quot;https://open.lnu.se/index.php/metapsychology/article/view/874&quot;,&quot;volume&quot;:&quot;4&quot;,&quot;author&quot;:[{&quot;family&quot;:&quot;Brunner&quot;,&quot;given&quot;:&quot;Jerry&quot;},{&quot;family&quot;:&quot;Schimmack&quot;,&quot;given&quot;:&quot;Ulrich&quot;}],&quot;accessed&quot;:{&quot;date-parts&quot;:[[&quot;2022&quot;,3,16]]},&quot;issued&quot;:{&quot;date-parts&quot;:[[&quot;2020&quot;,5,31]]}}}],&quot;schema&quot;:&quot;https://github.com/citation-style-language/schema/raw/master/csl-citation.json&quot;}\n<span style='mso-element:field-separator'></span></span><![endif]--><span lang=\"EN-US\">(Brunner\n&amp; Schimmack, 2020)</span><!--[if supportFields]><span lang=EN-US\nstyle='mso-ansi-language:EN-US'><span style='mso-element:field-end'></span></span><![endif]--><span lang=\"EN-US\">. </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">It seems a\nbit of a stretch to say the p-curve method did not get scrutiny appropriate to\nits popularity when there were many papers that criticized it, relatively\nquickly </span><!--[if supportFields]><span lang=EN-US style='mso-ansi-language:\nEN-US'><span style='mso-element:field-begin'></span><span\nstyle='mso-spacerun:yes'>\u00a0</span>ADDIN ZOTERO_ITEM CSL_CITATION\n{&quot;citationID&quot;:&quot;LqMzfpTk&quot;,&quot;properties&quot;:{&quot;formattedCitation&quot;:&quot;(Aert\net al., 2016; Bishop &amp; Thompson, 2016; Ulrich &amp; Miller, 2018)&quot;,&quot;plainCitation&quot;:&quot;(Aert\net al., 2016; Bishop &amp; Thompson, 2016; Ulrich &amp; Miller,\n2018)&quot;,&quot;noteIndex&quot;:0},&quot;citationItems&quot;:[{&quot;id&quot;:1415,&quot;uris&quot;:[&quot;http://zotero.org/users/371621/items/B8XNF95F&quot;],&quot;itemData&quot;:{&quot;id&quot;:1415,&quot;type&quot;:&quot;article-journal&quot;,&quot;abstract&quot;:&quot;Because\nof overwhelming evidence of publication bias in psychology, techniques to\ncorrect meta-analytic estimates for such bias are greatly needed. The\nmethodology on which the p-uniform and p-curve methods are based has great\npromise for providing accurate meta-analytic estimates in the presence of\npublication bias. However, in this article, we show that in some situations,\np-curve behaves erratically, whereas p-uniform may yield implausible estimates\nof negative effect size. Moreover, we show that (and explain why) p-curve and\np-uniform result in overestimation of effect size under moderate-to-large heterogeneity\nand may yield unpredictable bias when researchers employ p-hacking. We offer\nhands-on recommendations on applying and interpreting results of meta-analyses\nin general and p-uniform and p-curve in particular. Both methods as well as\ntraditional methods are applied to a meta-analysis on the effect of weight on\njudgments of importance. We offer guidance for applying p-uniform or p-curve\nusing R and a user-friendly web application for applying\np-uniform.&quot;,&quot;container-title&quot;:&quot;Perspectives on\nPsychological Science&quot;,&quot;DOI&quot;:&quot;10.1177/1745691616650874&quot;,&quot;ISSN&quot;:&quot;1745-6916,\n1745-6924&quot;,&quot;issue&quot;:&quot;5&quot;,&quot;journalAbbreviation&quot;:&quot;Perspectives\non Psychological Science&quot;,&quot;language&quot;:&quot;en&quot;,&quot;page&quot;:&quot;713-729&quot;,&quot;source&quot;:&quot;pps.sagepub.com&quot;,&quot;title&quot;:&quot;Conducting\nMeta-Analyses Based on p Values Reservations and Recommendations for Applying\np-Uniform and p-Curve&quot;,&quot;volume&quot;:&quot;11&quot;,&quot;author&quot;:[{&quot;family&quot;:&quot;Aert&quot;,&quot;given&quot;:&quot;Robbie\nC.\nM.&quot;,&quot;dropping-particle&quot;:&quot;van&quot;},{&quot;family&quot;:&quot;Wicherts&quot;,&quot;given&quot;:&quot;Jelte\nM.&quot;},{&quot;family&quot;:&quot;Assen&quot;,&quot;given&quot;:&quot;Marcel\nA. L. M.&quot;,&quot;dropping-particle&quot;:&quot;van&quot;}],&quot;issued&quot;:{&quot;date-parts&quot;:[[&quot;2016&quot;,9,1]]}}},{&quot;id&quot;:1428,&quot;uris&quot;:[&quot;http://zotero.org/users/371621/items/4D4RN5DG&quot;],&quot;itemData&quot;:{&quot;id&quot;:1428,&quot;type&quot;:&quot;article-journal&quot;,&quot;container-title&quot;:&quot;PeerJ&quot;,&quot;page&quot;:&quot;e1715&quot;,&quot;source&quot;:&quot;Google\nScholar&quot;,&quot;title&quot;:&quot;Problems in using p-curve analysis and\ntext-mining to detect rate of p-hacking and evidential\nvalue&quot;,&quot;volume&quot;:&quot;4&quot;,&quot;author&quot;:[{&quot;family&quot;:&quot;Bishop&quot;,&quot;given&quot;:&quot;Dorothy\nVM&quot;},{&quot;family&quot;:&quot;Thompson&quot;,&quot;given&quot;:&quot;Paul\nA.&quot;}],&quot;issued&quot;:{&quot;date-parts&quot;:[[&quot;2016&quot;]]}}},{&quot;id&quot;:3024,&quot;uris&quot;:[&quot;http://zotero.org/users/371621/items/UNQY68HR&quot;],&quot;itemData&quot;:{&quot;id&quot;:3024,&quot;type&quot;:&quot;article-journal&quot;,&quot;abstract&quot;:&quot;p-curves\nprovide a useful window for peeking into the file drawer in a way that might\nreveal p-hacking (Simonsohn, Nelson, &amp; Simmons, 2014a). The properties of\np-curves are commonly investigated by computer simulations. On the basis of\nthese simulations, it has been proposed that the skewness of this curve can be\nused as a diagnostic tool to decide whether the significant p values within a\ncertain domain of research suggest the presence of p-hacking or actually\ndemonstrate that there is a true effect. Here we introduce a rigorous\nmathematical approach that allows the properties of p-curves to be examined\nwithout simulations. This approach allows the computation of a p-curve for any\nstatistic whose sampling distribution is known and thereby allows a thorough\nevaluation of its properties. For example, it shows under which conditions\np-curves would exhibit the shape of a monotone decreasing function. In addition,\nwe used weighted distribution functions to analyze how 2 different types of\npublication bias (i.e., cliff effects and gradual publication bias) influence\nthe shapes of p-curves. The results of 2 survey experiments with more than\n1,000 participants support the existence of a cliff effect at p = .05 and also\nsuggest that researchers tend to be more likely to recommend submission of an\narticle as the level of statistical significance increases beyond this p level.\nThis gradual bias produces right-skewed p-curves mimicking the existence of\nreal effects even when no such effects are actually present. (PsycINFO Database\nRecord (c) 2018 APA, all rights\nreserved)&quot;,&quot;container-title&quot;:&quot;Psychological\nMethods&quot;,&quot;DOI&quot;:&quot;10.1037/met0000125&quot;,&quot;ISSN&quot;:&quot;1939-1463&quot;,&quot;issue&quot;:&quot;3&quot;,&quot;note&quot;:&quot;publisher-place:\nUS\\npublisher: American Psychological\nAssociation&quot;,&quot;page&quot;:&quot;546-560&quot;,&quot;source&quot;:&quot;APA\nPsycNet&quot;,&quot;title&quot;:&quot;Some properties of p-curves, with an\napplication to gradual publication\nbias&quot;,&quot;volume&quot;:&quot;23&quot;,&quot;author&quot;:[{&quot;family&quot;:&quot;Ulrich&quot;,&quot;given&quot;:&quot;Rolf&quot;},{&quot;family&quot;:&quot;Miller&quot;,&quot;given&quot;:&quot;Jeff&quot;}],&quot;issued&quot;:{&quot;date-parts&quot;:[[&quot;2018&quot;]]}}}],&quot;schema&quot;:&quot;https://github.com/citation-style-language/schema/raw/master/csl-citation.json&quot;}\n<span style='mso-element:field-separator'></span></span><![endif]--><span lang=\"EN-US\">(Aert et\nal., 2016; Bishop &amp; Thompson, 2016; Ulrich &amp; Miller, 2018)</span><!--[if supportFields]><span\nlang=EN-US style='mso-ansi-language:EN-US'><span style='mso-element:field-end'></span></span><![endif]--><span lang=\"EN-US\">. What is fair to say is that\nstatisticians failed to engage with an incredibly important topic (test for\npublication bias) that addressed a clear need in many scientific communities,\nas most of the criticism was by psychological methodologists. I fully agree\nthat statisticians should have engaged more with this technique. I believe the\nreason that they didn\u2019t is because there is a real problem in the reward\nstructure in statistics, where statisticians get greater rewards inside their\nfield by proposing a 12<sup>th</sup> approach to compute confidence intervals\naround a non-parametric effect size estimate for a test that no one uses, than\nto help psychologists solve a problem they really need a solution for. Indeed,\nfor a statistician, publication bias is a very messy business, and there will\nnever be a sufficiently rigorous test for publication bias to get credit from\nfellow statisticians. There are no beautiful mathematical solutions, no\ncreative insights, there is only the messy reality of a literature that is\nbiased by human actions that we can never adequately capture in a model. The\nfact that empirical researchers often don\u2019t know where to begin to evaluate the\nreliability of claims in their publication-bias-ridden field is not something\nstatisticians care about. But they should care about it. &nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">I hope\nstatisticians will start to scrutinize things appropriate to their popularity.\nIf a statistical technique is cited 500 times, 3 statisticians need to drop\nwhatever they are doing, and scrutinize the hell out of this technique. We can\nrandomly select them for \u2018statisticians duty\u2019.</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><b><span lang=\"EN-US\">Quality\ncontrol in science</span></b></p>\n\n<p class=\"MsoNormal\"><b><span lang=\"EN-US\">&nbsp;</span></b></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">It might\ncome as a surprise, but I don\u2019t actually think we should stop using methods\nthat are not adequately vetted by psychologists, or statisticians for that\nmatter, because I don\u2019t want a science where authorities tell others which\nmethods they can use. Scrutiny is important, but we can\u2019t know how extensively methods\nshould be vetted, we don\u2019t know how to identify experts, everyone \u2013 including \u2018experts\u2019\n\u2013 is fallible. It is na\u00efve to think \u2018expert vetting\u2019 will lead to clear answers\nabout the methods we should use, and should not use. If we can\u2019t even reach\nagreement about the use of p-values, no one should believe we will ever reach\nagreement about the use of methods to detect publication bias, which will\nalways be messy at best. &nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">I like my\nscience free from authority arguments. Everyone should do their best to\ncriticize everyone else, and if they are able, themselves. Some people will be\nin a better position to criticize some papers than others, but it is difficult\nto predict where the most fatal criticism will come from. Treating statistics\npapers published in a statistics journal as superior to papers in a psychology\njournal is too messy to be a good idea, and boil down to a form of elitism that\nI can\u2019t condone. Sometimes even a lowly 20% statistician can point out flaws in\nmethods proposed by card-carrying statisticians. </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">What we can\ndo better is implementing actual quality control. Journal peer review will not\nsuffice, because it is only as good as the two or three peers that happen to be\nwilling and available to review a paper. But it is a start. We should enable\nresearchers to see how well papers are peer reviewed by journals. Without\ntransparency, we can\u2019t calibrate our trust </span><!--[if supportFields]><span\nlang=EN-US style='mso-ansi-language:EN-US'><span style='mso-element:field-begin'></span><span\nstyle='mso-spacerun:yes'>\u00a0</span>ADDIN ZOTERO_ITEM CSL_CITATION\n{&quot;citationID&quot;:&quot;DuUONcRk&quot;,&quot;properties&quot;:{&quot;formattedCitation&quot;:&quot;(Vazire,\n2017)&quot;,&quot;plainCitation&quot;:&quot;(Vazire, 2017)&quot;,&quot;noteIndex&quot;:0},&quot;citationItems&quot;:[{&quot;id&quot;:2227,&quot;uris&quot;:[&quot;http://zotero.org/users/371621/items/6IRLDTML&quot;],&quot;itemData&quot;:{&quot;id&quot;:2227,&quot;type&quot;:&quot;article-journal&quot;,&quot;abstract&quot;:&quot;Article:\nQuality Uncertainty Erodes Trust in\nScience&quot;,&quot;container-title&quot;:&quot;Collabra:\nPsychology&quot;,&quot;DOI&quot;:&quot;10.1525/collabra.74&quot;,&quot;ISSN&quot;:&quot;2474-7394&quot;,&quot;issue&quot;:&quot;1&quot;,&quot;language&quot;:&quot;eng&quot;,&quot;license&quot;:&quot;Authors\nwho publish with this journal agree to the following terms:<span\nstyle='mso-spacerun:yes'>\u00a0\u00a0\u00a0 </span>Authors retain copyright and grant the\njournal right of first publication with the work simultaneously licensed under\na<span style='mso-spacerun:yes'>\u00a0 </span>Creative Commons Attribution\nLicense<span style='mso-spacerun:yes'>\u00a0 </span>that allows others to share the\nwork with an acknowledgement of the work's authorship and initial publication in\nthis journal.<span style='mso-spacerun:yes'>\u00a0 </span>Authors are able to enter\ninto separate, additional contractual arrangements for the non-exclusive\ndistribution of the journal's published version of the work (e.g., post it to\nan institutional repository or publish it in a book), with an acknowledgement\nof its initial publication in this journal.<span style='mso-spacerun:yes'>\u00a0\n</span>Authors are permitted and encouraged to post their work online (e.g., in\ninstitutional repositories or on their website) prior to and during the\nsubmission process, as it can lead to productive exchanges, as well as earlier\nand greater citation of published work (See<span style='mso-spacerun:yes'>\u00a0\n</span>The Effect of Open Access ).<span style='mso-spacerun:yes'>\u00a0 </span>All\nthird-party images reproduced on this journal are shared under Educational Fair\nUse. For more information on<span style='mso-spacerun:yes'>\u00a0 </span>Educational\nFair Use , please see<span style='mso-spacerun:yes'>\u00a0 </span>this useful\nchecklist prepared by Columbia University Libraries .<span\nstyle='mso-spacerun:yes'>\u00a0\u00a0 </span>All copyright<span\nstyle='mso-spacerun:yes'>\u00a0 </span>of third-party content posted here for\nresearch purposes belongs to its original owners.<span\nstyle='mso-spacerun:yes'>\u00a0 </span>Unless otherwise stated all references to\ncharacters and comic art presented on this journal are \u00a9, \u00ae or \u2122 of their\nrespective owners. No challenge to any owner\u2019s rights is intended or should be\ninferred.&quot;,&quot;page&quot;:&quot;1&quot;,&quot;source&quot;:&quot;collabra.org&quot;,&quot;title&quot;:&quot;Quality\nUncertainty Erodes Trust in\nScience&quot;,&quot;volume&quot;:&quot;3&quot;,&quot;author&quot;:[{&quot;family&quot;:&quot;Vazire&quot;,&quot;given&quot;:&quot;Simine&quot;}],&quot;issued&quot;:{&quot;date-parts&quot;:[[&quot;2017&quot;,2,28]]}}}],&quot;schema&quot;:&quot;https://github.com/citation-style-language/schema/raw/master/csl-citation.json&quot;}\n<span style='mso-element:field-separator'></span></span><![endif]--><span lang=\"EN-US\">(Vazire,\n2017)</span><!--[if supportFields]><span lang=EN-US style='mso-ansi-language:\nEN-US'><span style='mso-element:field-end'></span></span><![endif]--><span lang=\"EN-US\">. Peer reviews should be open, for\nall papers, including papers proposing new statistical methods.</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">If we want\nour statistical methods to be of high quality, we need to specify quality\nstandards. Morey and Davis-Stober point out the limitations of simulation-based\ntests of a method and convincingly argue for the value of evaluating the\nmathematical properties of a testing procedure. If as a field we agree that an\nevaluation of the mathematical properties of a test is desirable, we should\ntrack whether this evaluation has been performed, or not. We could have a long\nchecklist of desirable quality control standards \u2013 e.g., a method has been\ntested on real datasets, it has been compared to similar methods, those\ncomparisons have been performed objectively based on a well-justified set of\ncriteria, etc. </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">One could\ncreate a database where for each method the quality standards that have been\nmet and that have not been met are listed. If considered useful, the database\ncould also track how often a method is used, by tracking citations, and listing\npapers that have implemented the method (as opposed to those merely discussing\nthe method). When statistical methods become widely used, the database would point\nresearchers to which methods deserve more scrutiny. The case of magnitude-based\ninference in sport science reveals the importance of a public call for scrutiny\nwhen a method becomes widely popular, especially when this popularity is\nlimited to a single field. </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">The more\ncomplex methods are, the more limitations they have. This will be true for all\nmethods that aim to deal with publication bias, because the way scientists bias\nthe literature is difficult to quantify. Maybe as a field we will come to agree\nthat tests for bias are never accurate enough, and we will recommend people to\njust look at the distribution of p-values without performing a test. Alternatively,\nwe might believe that it is useful to have a testing procedure that too often\nsuggests a literature contains at least some non-zero effects, because we feel\nwe need some way to intersubjectively point out that there is bias in a\nliterature, even if this is based on an imperfect test. Such discussions\nrequire a wide range of stakeholders, and the opinion of statisticians about\nthe statistical properties of a test is only one source of input in this\ndiscussion. Imperfect procedures are implemented all the time, if they are the\nbest we have, and doing nothing is also not working. </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">Statistical\nmethods are rarely perfect from their inception, and all have limitations. Although\nI understand the feeling, banning all tests that have not been adequately vetted\nby an expert is inherently unscientific. Such a suggestion would destroy the\nvery core of science \u2013 an institution that promotes mutual criticism, while\naccepting our fallibility. As Popper </span><!--[if supportFields]><span\nlang=EN-US style='mso-ansi-language:EN-US'><span style='mso-element:field-begin'></span><span\nstyle='mso-spacerun:yes'>\u00a0</span>ADDIN ZOTERO_ITEM CSL_CITATION\n{&quot;citationID&quot;:&quot;wYdMdVAJ&quot;,&quot;properties&quot;:{&quot;formattedCitation&quot;:&quot;(1962)&quot;,&quot;plainCitation&quot;:&quot;(1962)&quot;,&quot;noteIndex&quot;:0},&quot;citationItems&quot;:[{&quot;id&quot;:111,&quot;uris&quot;:[&quot;http://zotero.org/users/371621/items/VEWU8MII&quot;],&quot;itemData&quot;:{&quot;id&quot;:111,&quot;type&quot;:&quot;book&quot;,&quot;event-place&quot;:&quot;London&quot;,&quot;publisher&quot;:&quot;Routledge&quot;,&quot;publisher-place&quot;:&quot;London&quot;,&quot;source&quot;:&quot;Google\nScholar&quot;,&quot;title&quot;:&quot;Conjectures and refutations: The growth\nof scientific knowledge&quot;,&quot;title-short&quot;:&quot;Conjectures and\nrefutations: The growth of scientific knowledge&quot;,&quot;author&quot;:[{&quot;family&quot;:&quot;Popper&quot;,&quot;given&quot;:&quot;Karl\nR&quot;}],&quot;issued&quot;:{&quot;date-parts&quot;:[[&quot;1962&quot;]]}},&quot;suppress-author&quot;:true}],&quot;schema&quot;:&quot;https://github.com/citation-style-language/schema/raw/master/csl-citation.json&quot;}\n<span style='mso-element:field-separator'></span></span><![endif]--><span lang=\"EN-US\">(1962)</span><!--[if supportFields]><span\nlang=EN-US style='mso-ansi-language:EN-US'><span style='mso-element:field-end'></span></span><![endif]--><span lang=\"EN-US\"> reminds us: \u201c</span>if we respect truth, we must search for it by\npersistently searching for our errors: by indefatigable rational criticism, and\nself-criticism.\u201d<span lang=\"EN-US\"></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p><p class=\"MsoNormal\"><span lang=\"EN-US\"><br /></span></p><p class=\"MsoNormal\"><span lang=\"EN-US\"><br /></span></p><p class=\"MsoNormal\"><span lang=\"EN-US\"><br /></span></p><h4 style=\"text-align: left;\"><span lang=\"EN-US\">References</span></h4>\n\n<p class=\"MsoBibliography\" style=\"line-height: normal;\"><!--[if supportFields]><span\nlang=EN-US style='mso-ansi-language:EN-US'><span style='mso-element:field-begin'></span></span><span\nlang=NL><span style='mso-spacerun:yes'>\u00a0</span>ADDIN ZOTERO_BIBL\n{&quot;uncited&quot;:[],&quot;omitted&quot;:[],&quot;custom&quot;:[]}\nCSL_BIBLIOGRAPHY </span><span lang=EN-US style='mso-ansi-language:EN-US'><span\nstyle='mso-element:field-separator'></span></span><![endif]--><span lang=\"NL\">Aert, R. C. M. van, Wicherts, J. M., &amp;\nAssen, M. A. L. M. van. </span><span lang=\"EN-US\">(2016). Conducting Meta-Analyses Based on p\nValues Reservations and Recommendations for Applying p-Uniform and p-Curve. <i>Perspectives\non Psychological Science</i>, <i>11</i>(5), 713\u2013729.\nhttps://doi.org/10.1177/1745691616650874</span></p>\n\n<p class=\"MsoBibliography\" style=\"line-height: normal;\"><span lang=\"EN-US\">Bishop, D. V., &amp;\nThompson, P. A. (2016). Problems in using p-curve analysis and text-mining to\ndetect rate of p-hacking and evidential value. <i>PeerJ</i>, <i>4</i>, e1715.</span></p>\n\n<p class=\"MsoBibliography\" style=\"line-height: normal;\"><span lang=\"EN-US\">Brunner, J., &amp;\nSchimmack, U. (2020). Estimating Population Mean Power Under Conditions of\nHeterogeneity and Selection for Significance. </span><i><span lang=\"NL\">Meta-Psychology</span></i><span lang=\"NL\">, <i>4</i>.\nhttps://doi.org/10.15626/MP.2018.874</span></p>\n\n<p class=\"MsoBibliography\" style=\"line-height: normal;\"><span lang=\"NL\">Carter, E. C., Sch\u00f6nbrodt, F. D., Gervais,\nW. M., &amp; Hilgard, J. (2019). </span><span lang=\"EN-US\">Correcting for Bias in Psychology: A Comparison\nof Meta-Analytic Methods. <i>Advances in Methods and Practices in Psychological\nScience</i>, <i>2</i>(2), 115\u2013144. https://doi.org/10.1177/2515245919847196</span></p>\n\n<p class=\"MsoBibliography\" style=\"line-height: normal;\"><span lang=\"NL\">Isager, P. M., Lakens, D., van Leeuwen, T.,\n&amp; van \u2019t Veer, A. E. (2024). </span><span lang=\"EN-US\">Exploring a formal approach to selecting studies\nfor replication: A feasibility study in social neuroscience. </span><i><span lang=\"NL\">Cortex</span></i><span lang=\"NL\">, <i>171</i>, 330\u2013346.\nhttps://doi.org/10.1016/j.cortex.2023.10.012</span></p>\n\n<p class=\"MsoBibliography\" style=\"line-height: normal;\"><span lang=\"NL\">Isager, P. M., van Aert, R. C. M., Bahn\u00edk,\n\u0160., Brandt, M. J., DeSoto, K. A., Giner-Sorolla, R., Krueger, J. I., Perugini,\nM., Ropovik, I., van \u2019t Veer, A. E., Vranka, M., &amp; Lakens, D. (2023). </span><span lang=\"EN-US\">Deciding\nwhat to replicate: A decision model for replication study selection under\nresource and knowledge constraints. <i>Psychological Methods</i>, <i>28</i>(2),\n438\u2013451. https://doi.org/10.1037/met0000438</span></p>\n\n<p class=\"MsoBibliography\" style=\"line-height: normal;\"><span lang=\"EN-US\">Lakens, D., &amp;\nDelacre, M. (2020). Equivalence Testing and the Second Generation P-Value. <i>Meta-Psychology</i>,\n<i>4</i>, 1\u201311. https://doi.org/10.15626/MP.2018.933</span></p>\n\n<p class=\"MsoBibliography\" style=\"line-height: normal;\"><span lang=\"EN-US\">Morey, R. D., &amp;\nDavis-Stober, C. P. (n.d.). On the poor statistical properties of the P-curve\nmeta-analytic procedure. <i>Journal of the American Statistical Association</i>,\n<i>0</i>(ja), 1\u201319. https://doi.org/10.1080/01621459.2025.2544397</span></p>\n\n<p class=\"MsoBibliography\" style=\"line-height: normal;\"><span lang=\"EN-US\">Peters, J. L.,\nSutton, A. J., Jones, D. R., Abrams, K. R., &amp; Rushton, L. (2007).\nPerformance of the trim and fill method in the presence of publication bias and\nbetween-study heterogeneity. <i>Statistics in Medicine</i>, <i>26</i>(25),\n4544\u20134562. https://doi.org/10.1002/sim.2889</span></p>\n\n<p class=\"MsoBibliography\" style=\"line-height: normal;\"><span lang=\"EN-US\">Popper, K. R.\n(1962). <i>Conjectures and refutations: The growth of scientific knowledge</i>.\nRoutledge.</span></p>\n\n<p class=\"MsoBibliography\" style=\"line-height: normal;\"><span lang=\"EN-US\">Simonsohn, U.,\nNelson, L. D., &amp; Simmons, J. P. (2014). P-Curve and Effect Size Correcting\nfor Publication Bias Using Only Significant Results. <i>Perspectives on\nPsychological Science</i>, <i>9</i>(6), 666\u2013681.</span></p>\n\n<p class=\"MsoBibliography\" style=\"line-height: normal;\"><span lang=\"EN-US\">Simonsohn, U.,\nSimmons, J. P., &amp; Nelson, L. D. (2015). Better P-curves: Making P-curve\nanalysis more robust to errors, fraud, and ambitious P-hacking, a Reply to\nUlrich and Miller (2015). <i>Journal of Experimental Psychology. General</i>, <i>144</i>(6),\n1146\u20131152. https://doi.org/10.1037/xge0000104</span></p>\n\n<p class=\"MsoBibliography\" style=\"line-height: normal;\"><span lang=\"EN-US\">Terrin, N., Schmid,\nC. H., Lau, J., &amp; Olkin, I. (2003). Adjusting for publication bias in the\npresence of heterogeneity. <i>Statistics in Medicine</i>, <i>22</i>(13),\n2113\u20132126. https://doi.org/10.1002/sim.1461</span></p>\n\n<p class=\"MsoBibliography\" style=\"line-height: normal;\"><span lang=\"EN-US\">Ulrich, R., &amp;\nMiller, J. (2018). Some properties of p-curves, with an application to gradual\npublication bias. <i>Psychological Methods</i>, <i>23</i>(3), 546\u2013560.\nhttps://doi.org/10.1037/met0000125</span></p>\n\n<p class=\"MsoBibliography\" style=\"line-height: normal;\"><span lang=\"EN-US\">Vazire, S. (2017).\nQuality Uncertainty Erodes Trust in Science. </span><i><span lang=\"NL\">Collabra: Psychology</span></i><span lang=\"NL\">, <i>3</i>(1), 1.\nhttps://doi.org/10.1525/collabra.74</span></p>\n\n<!--[if supportFields]><span lang=EN-US style='font-size:11.0pt;line-height:\n107%;font-family:\"Arial\",sans-serif;mso-fareast-font-family:Aptos;mso-fareast-theme-font:\nminor-latin;mso-bidi-font-family:\"Times New Roman\";mso-bidi-theme-font:minor-bidi;\nmso-ansi-language:EN-US;mso-fareast-language:EN-US;mso-bidi-language:AR-SA'><span\nstyle='mso-element:field-end'></span></span><![endif]-->",
      "author": "noreply@blogger.com (Daniel Lakens)",
      "published_date": "2025-10-29T07:35:00+00:00",
      "source": "Twenty Percent Statistician",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 5516,
      "reading_time": 27,
      "created_at": "2025-11-09T21:38:42.153690+00:00",
      "updated_at": "2025-11-09T22:13:40.387862+00:00",
      "metadata": {
        "processed_at": "2025-11-09T22:13:40.387864+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "d1b3a64c1957f2b048e1e94f5d37c6e5",
      "url": "https://erpinfo.org/blog/2024/3/15/registration-full",
      "title": "Registration is now full for the 2024 ERP Boot Camp",
      "content": "<p class=\"\">The demand for the<a href=\"https://erpinfo.org/2024-erp-boot-camp\"> 2024 ERP Boot Camp</a> was far beyond our expectations, and we reached our maximum registration of 30 people within one day. We already have a waiting list of over 30 people, so we have closed the registration site.</p><p class=\"\">We realize that this is very disappointing to many people. We hope to offer another workshop like this next summer, or possibly earlier.</p><p class=\"\">If you would like to get announcements about upcoming boot camps and webinars, you should <a href=\"https://erpinfo.org/bootcamp-email-list\">join our email list</a>.</p><p class=\"\">You may also consider hosting a <a href=\"https://erpinfo.org/mini-erp-boot-camps\">Mini ERP Boot Camp</a> at your institution (in person or over Zoom).</p>",
      "author": "Steve Luck",
      "published_date": "2024-03-16T15:14:42+00:00",
      "source": "Erp Boot Camp",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 106,
      "reading_time": 1,
      "created_at": "2025-11-09T21:38:39.376016+00:00",
      "updated_at": "2025-11-09T22:13:40.387867+00:00",
      "metadata": {
        "processed_at": "2025-11-09T22:13:40.387868+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "e1385798428586a67ced89a895faeb47",
      "url": "https://erpinfo.org/blog/2024/6/10/erp-core-decoding-paper",
      "title": "New Paper: Using Multivariate Pattern Analysis to Increase Effect Sizes for ERP Amplitude Comparisons",
      "content": "<p class=\"\">Carrasco, C. D., Bahle, B., Simmons, A. M., &amp; Luck, S. J. (2024). Using multivariate pattern analysis to increase effect sizes for event-related potential analyses. Psychophysiology, 61, e14570. <a href=\"https://doi.org/10.1111/psyp.14570\">https://doi.org/10.1111/psyp.14570</a> [<a href=\"https://doi.org/10.1101/2023.11.07.566051\">preprint</a>]</p><p class=\"\">Multivariate pattern analysis (MVPA) can be used to \u201cdecode\u201d subtle information from ERP signals, such as which of several faces a participant is perceiving or the orientation that someone is holding in working memory (see <a href=\"https://erpinfo.org/blog/2018/9/16/decoding\">this previous blog post</a>). This approach is so powerful that we started wondering whether it might also give us greater statistical power in more typical experiments where the goal is to determine whether an ERP component differs in amplitude across experimental conditions. For example, might we more easily be able to tell if N400 amplitude is different between two different classes of words by using decoding? If so, that might make it possible to detect effects that would otherwise be too small to be significant.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"688\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/08f353c7-f484-4e87-b5d3-a256fe1206e2/N170_ES.png?format=1000w\" width=\"971\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">To address this question, we compared decoding with the conventional ERP analysis approach with using the 6 experimental paradigms in the <a href=\"https://doi.org/10.18115/D5JW4R\">ERP CORE</a>. In the conventional ERP analysis, we measured the mean amplitude during the standard measurement window from each participant in the two conditions of the paradigm (e.g., faces versus cars for N170, deviants versus standards for MMN). We quantified the magnitude of the difference between conditions using Cohen\u2019s <em>dz</em> (the variant of Cohen\u2019s <em>d</em> corresponding to a paired <em>t</em> test). For example, the effect size in the conventional ERP comparison of faces versus cars in the N170 paradigm was approximately 1.7 (see the figure).</p><p class=\"\">We also applied decoding to each paradigm. For example, in the N170 paradigm, we trained a support vector machine (SVM) to distinguish between ERPs elicited by faces and ERPs elicited by cars. This was done separately for each subject, and we converted the decoding accuracy into Cohen\u2019s <em>dz</em> so that it could be compared with the <em>dz</em> from the conventional ERP analysis. As you can see from the bar labeled SVM in the figure above, the effect size for the SVM-based decoding analysis was almost twice as large as the effect size for the conventional ERP analysis. That\u2019s a huge difference!</p><p class=\"\">We found a similar benefit for SVM-based decoding over conventional ERP analyses in 7 of the 10 cases we tested (see the figure below). In the other 3 cases, the ERP and SVM effects were approximately equivalent. So, there doesn\u2019t seem to be a downside to using decoding, at least in terms of effect size. But there can be a big benefit.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1371\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/d16f0782-7205-4d50-95e1-c6729cbc153e/All_Components.png?format=1000w\" width=\"4641\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">Because decoding has many possible benefits, we\u2019ve added it into <a href=\"ERPLAB Toolbox\">ERPLAB Toolbox</a>. It\u2019s super easy to use, and we\u2019ve created <a href=\"https://erpinfo.org/blog/2023/6/23/decoding-webinar\">detailed documentation and a video</a> to explain how it works at a conceptual level and to show you how to use it.</p><p class=\"\">We encourage you to apply it to your own data. It may give you the power to detect effects that are too small to be detected with conventional ERP analyses.</p>",
      "author": "Steve Luck",
      "published_date": "2024-06-10T18:01:45+00:00",
      "source": "Erp Boot Camp",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 525,
      "reading_time": 2,
      "created_at": "2025-11-09T21:38:39.375989+00:00",
      "updated_at": "2025-11-09T22:13:40.387870+00:00",
      "metadata": {
        "processed_at": "2025-11-09T22:13:40.387872+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "906f73f5c36ba087882a0ad17e01fc20",
      "url": "https://erpinfo.org/blog/2024/6/11/erplab-studio",
      "title": "New software package: ERPLAB Studio",
      "content": "<p class=\"\">We are excited to announce the release of a new EEG/ERP analysis package, <a href=\"https://github.com/ucdavis/erplab/releases\">ERPLAB Studio</a>. We think it\u2019s a huge improvement over the classic EEGLAB user interface. See our cheesy <a href=\"https://www.youtube.com/watch?v=lIaKVQ9DD6E\">\u201cadvertisement\u201d video</a> to get a quick overview. </p><p class=\"\">Rather than operating as an EEGLAB plugin, ERPLAB Studio is a standalone Matlab program that provides a more efficient and user-friendly interface to the most commonly used EEGLAB and ERPLAB routines.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1080\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/c874d4ec-5186-4de9-981b-58010c7a06e1/Interface.jpeg?format=1000w\" width=\"1920\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">With ERPLAB Studio, you automatically see the EEG or ERP waveforms as soon as you load a file. And as soon as you perform an operation, you see what the new EEG/ERP looks like. For example, when you filter the data, you immediately see the filtered waveforms.</p><p class=\"\">You can even select multiple datasets and apply an operation like artifact detection on all of them in one step. And then you can immediately see the results, such as which EEG epochs have been marked with artifacts.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1080\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/b45f514d-2d21-4a5a-8be6-f3a8ff99c388/Artifacts.jpeg?format=1000w\" width=\"1920\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">We give you access to EEGLAB\u2019s ICA-based artifact correction tools, but with a nice bonus. You can plot the ICA activations in the same window with the EEG data, making it easy to see which ICA components correspond to specific artifacts such as eyeblinks.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1080\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/8bc191da-9040-4042-ae9c-550cd98def7d/ICA.jpeg?format=1000w\" width=\"1920\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">The program has an EEG tab for processing continuous and epoched EEG data, and an ERP tab for processing averaged ERPs.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1080\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/84bdd9df-b02e-4fc5-83b9-1139a91938f5/Tabs.jpg?format=1000w\" width=\"1920\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">The automatic ERP plotting makes it easy for you to view the data laid out according to the electrode locations. And we have an Advanced Waveform Viewer that can make publication-quality plots.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1080\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/a932631f-fc30-415f-b11d-660d2bf90da5/ERP.jpeg?format=1000w\" width=\"1920\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">ERPLAB Studio is mainly just a new user interface. Under the hood, we\u2019re running the same EEGLAB and ERPLAB routines you\u2019ve always used. And scripting is identical.</p><p class=\"\">ERPLAB Studio is included in <a href=\"https://github.com/ucdavis/erplab/releases\">version 11 and higher of ERPLAB</a>. You simply follow our <a href=\"https://github.com/ucdavis/erplab/wiki/installation\">download/installation instructions</a> and then type estudio from the Matlab command line. </p><p class=\"\">If you\u2019re new to ERPLAB, we strongly recommend that you go through our <a href=\"https://github.com/ucdavis/erplab/wiki/ERPLAB-Studio-Tutorial\" target=\"_blank\">tutorial</a> before starting to process your own data. </p><p class=\"\">If you already know how to use the original version of ERPLAB (which we now call ERPLAB Classic), you can quickly learn how to use ERPLAB Studio with our <a href=\"https://ucdavis.box.com/s/i4jfv22gv6rj9t5obctuk6yaruxqomcc\">Transition Guide</a>.</p><p class=\"\">We also have a <a href=\"https://github.com/ucdavis/erplab/wiki/ERPLAB-Studio-Manual\">manual</a> that describes every feature in detail. </p>",
      "author": "Steve Luck",
      "published_date": "2024-06-12T02:02:16+00:00",
      "source": "Erp Boot Camp",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 444,
      "reading_time": 2,
      "created_at": "2025-11-09T21:38:39.375921+00:00",
      "updated_at": "2025-11-09T22:13:40.387874+00:00",
      "metadata": {
        "processed_at": "2025-11-09T22:13:40.387875+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "9fe9c99db697786e3f69c006b914b51d",
      "url": "http://ieeexplore.ieee.org/document/11153362",
      "title": "Transient and Sustained Neuromagnetic Representation of Consonance and Dissonance in Harmonic Sequences",
      "content": "The perception of musical consonance/dissonance (C/D) relies on basic properties of the auditory system, and prior investigations have shown that C/D sounds elicit strongly divergent neurophysiological activity in human auditory cortex. However, studies are missing that assess transient (P1, N1, P2) and sustained cortical C/D representations within a harmonic context, together with the corresponding patterns of neural adaptation. The present magnetoencephalography experiment applied spatio-temporal source analysis to study the early transient and sustained neuromagnetic processing of C/D at the start and within brief harmonic sequences. A total of n = 40 adult listeners (among them numerous amateur musicians) participated in the experiment; the harmonic sequences comprised different blends of C/D dyads with balanced probabilities, in an effort to access simple C/D relations and neural adaptation at an early stage of the processing hierarchy. Consistent with earlier findings, the transient cortical activity was found to reflect vertical (i.e., absolute) C/D aspects in response to the sequence's first dyad, but it mirrored more horizontal aspects (i.e., C/D relations) at the subsequent dyad transitions; moreover, the neuromagnetic responses (particularly, the N1 and P2 waves) exhibited adaptation with different time constants, parts of which pertained to C/D-associated processing. Surprisingly, only few observations appeared to be influenced by the listener's musical expertise, likely due to the high overall level of musicality in our sample. In summary, our data indicate that early neuromagnetic activity reflects not only vertical, but also horizontal, aspects of C/D perception, together with corresponding adaptive mechanisms.",
      "author": "",
      "published_date": "2025-09-08T13:16:44+00:00",
      "source": "Cognitive Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 244,
      "reading_time": 1,
      "created_at": "2025-11-09T19:38:44.544333+00:00",
      "updated_at": "2025-11-09T20:14:44.525898+00:00",
      "metadata": {
        "processed_at": "2025-11-09T20:14:44.525907+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "3126a4e56a81b2be3ee1af1e1e87dffc",
      "url": "http://ieeexplore.ieee.org/document/11153357",
      "title": "An Emergentist Account of Language in the Brain\u2014Seeking Neural Synergies Behind Human Uniqueness",
      "content": "Cognitive neuroscience has become increasingly open to views of human cognitive faculties as emergent properties\u2014as higher-level products of synergies between brain structures handling qualitatively different functions. This new perspective mitigates claims that cognitive abilities are tied to localized, domain-specific brain systems. In this changing landscape, the neurobiology of language has lagged behind, with virtually no mature theory apt to guide an exploration of language as an emergent function of the human brain. Combining evidence that linguistic processing is distributed across neurocognitive systems supporting (among others) semantic cognition, executive functions, and articulatory-motor control with recent advances in studying neural synergies, we propose a model of language as a deeply synergistic phenomenon that is both decoupled from its lower-level constituents and capable of exerting downward causal powers over them, accounting for its key role in human adaptive behavior. In considering the implications it has in our understanding of the place of language within the broader infrastructure of human behavior, this novel perspective aims to move the neurobiology of language forward in a new era of the cognitive neuroscience.",
      "author": "",
      "published_date": "2025-09-08T13:16:44+00:00",
      "source": "Cognitive Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 176,
      "reading_time": 1,
      "created_at": "2025-11-09T19:38:44.544296+00:00",
      "updated_at": "2025-11-09T20:14:44.525914+00:00",
      "metadata": {
        "processed_at": "2025-11-09T20:14:44.525916+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "c307ab5dab9f6c7578186615c5aa70b9",
      "url": "http://ieeexplore.ieee.org/document/11153359",
      "title": "Impact of Transcutaneous Vagus Nerve Stimulation on Event-related Potentials during a Response Inhibition Task",
      "content": "As an emerging neuromodulation technique, transcutaneous auricular vagus nerve stimulation (taVNS) has shown promise in enhancing cognitive abilities. The present study used a combination of the go/no-go task and the stop-signal task experimental paradigm to examine the cognitive effects of taVNS on participants' EEG measures. Sixty-one healthy participants were randomly assigned to either the stimulation group or the sham group. Participants in the stimulation group received 100 Hz and 25 Hz stimulation in a counterbalanced order. We compared behavioral and EEG data before and after stimulation, and observed significant effects. The findings revealed that a 100-Hz taVNS significantly reduced participants' N2 latency in the stop trial, indicating potential improvement response inhibition. In addition, we noted a decreasing trend in alpha, theta, and delta band power during response inhibition after receiving a 100-Hz taVNS. These results suggest that a 100-Hz taVNS can enhance participants' response inhibition abilities, indicating its potential as a therapeutic approach for modulating cognitive functions.",
      "author": "",
      "published_date": "2025-09-08T13:16:40+00:00",
      "source": "Cognitive Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 157,
      "reading_time": 1,
      "created_at": "2025-11-09T19:38:44.544263+00:00",
      "updated_at": "2025-11-09T20:14:44.525918+00:00",
      "metadata": {
        "processed_at": "2025-11-09T20:14:44.525920+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "4b601b9c934f95d9db5ecc44c2eee1e3",
      "url": "http://ieeexplore.ieee.org/document/11153356",
      "title": "Confidence and Insight into Working Memory Are Shaped by Attention and Recent Performance",
      "content": "Working memory is capacity-limited, and our ability to access information from working memory is variable, but selective attention to working memory contents can improve performance. People are able to make introspective judgments regarding the quality of their memories, and these judgments are linked to objective memory performance. However, it remains unknown whether benefits of internally directed attention on memory performance occur alongside commensurate changes in introspective judgments. Across two experiments, we used retrospective cues (retrocues) during working-memory maintenance to direct attention to items in memory. We then examined their consequence on introspective judgments. In the second experiment, we provided trial-wise feedback on performance. We found that selective attention improved confidence judgments and not just performance of the probed item. We were also able to judge participants' genuine insight into working-memory contents through the correlation between confidence judgments and memory quality. Neurophysiologically, alpha desynchronization correlated first with memory error and then confidence during retrocueing, suggesting a sequential process of attentional enhancement of memory contents and introspective insight. Furthermore, we showed that participants can use feedback on the accuracy of confidence judgments to update their beliefs across time, according to performance. Our results emphasize flexibility in working memory by showing we can selectively modulate our confidence about its contents based on internally directed attention or objective feedback.",
      "author": "",
      "published_date": "2025-09-08T13:16:44+00:00",
      "source": "Cognitive Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 215,
      "reading_time": 1,
      "created_at": "2025-11-09T19:38:44.544232+00:00",
      "updated_at": "2025-11-09T20:14:44.525922+00:00",
      "metadata": {
        "processed_at": "2025-11-09T20:14:44.525924+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "edffc2279f9aa7e39f9716ed7c09c8f0",
      "url": "https://www.sciencedirect.com/science/article/pii/S0006899325005748?dgcid=rss_sd_all",
      "title": "Antidepressant-like and memory-enhancing effects of 2-phenyl-3-(phenylselanyl)benzofuran on a lipopolysaccharide-induced depression model in male mice: behavioral, biochemical, and molecular insights",
      "content": "<p>Publication date: 15 December 2025</p><p><b>Source:</b> Brain Research, Volume 1869</p><p>Author(s): Ta\u00eds da Silva Teixeira Rech, Mariana Parron Paim, Natalia Gon\u00e7alves Tavares, Ila Yasmim Reis Arouche Dantas, Jos\u00e9 Sebasti\u00e3o Santos Neto, Gabriel da Silva Zani, Silvia de Oliveira H\u00fcbner, C\u00e9sar Augusto Br\u00fcning, Cristiani Folharini Bortolatto</p>",
      "author": "",
      "published_date": null,
      "source": "Brain Research",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 43,
      "reading_time": 1,
      "created_at": "2025-11-09T19:38:35.922334+00:00",
      "updated_at": "2025-11-09T20:14:44.525926+00:00",
      "metadata": {
        "processed_at": "2025-11-09T20:14:44.525927+00:00",
        "processing_method": "github_actions"
      }
    }
  ]
}