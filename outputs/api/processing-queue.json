{
  "last_updated": "2026-01-15T10:19:21.115660+00:00",
  "pending_count": 731,
  "processed_count": 269,
  "pending_articles": [
    {
      "id": "d46d99fedb4cadcf74fbf9d3f7de8713",
      "url": "http://doi.org/10.1037/drm0000313",
      "title": "Dreaming about pain: Dreams series of a chronic pain patient.",
      "content": "The occurrence of physical pain in the dreams of healthy individuals is relatively rare, while patient populations report pain more frequently in their dreams. This study conducted dream content analysis on a long dream series (N = 4,254) from a patient diagnosed with a chronic pain-inducing illness at a young age. We found that 9.76% of the dream reports referenced pain, experienced by the dreamer, other characters, or as a thematic element. The dreamer frequently reported pain in her whole body, limbs, and joints, suggesting a correspondence with her waking-life experiences with pain. The emotional tone of the pain dreams was predominantly negative, though occasional positive emotions reflecting relief from pain were observed. These findings highlight the multifaceted ways of integrating pain into dream content and suggest continuity between waking-life pain and pain dreams. Future research should explore the exact relationship between waking-life pain intensity and pain dream frequency in chronic pain patients to better understand pain as a sensory characteristic of dreaming. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2025-06-09T00:00:00+00:00",
      "source": "Dreaming",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 172,
      "reading_time": 1,
      "created_at": "2026-01-15T09:51:59.931561+00:00",
      "updated_at": "2026-01-15T09:51:59.931562+00:00"
    },
    {
      "id": "0da11a4a836b8d1cc39ad32e143d0538",
      "url": "http://doi.org/10.1037/drm0000324",
      "title": "Interpretability of rapid eye movement and nonrapid eye movement dreams.",
      "content": "This study examined whether rapid eye movement (REM) sleep mentation provides more pertinent material for dream interpretation compared to non-REM (NREM) sleep mentation. Seventeen participants spent three consecutive nights at a sleep laboratory, where awakenings were scheduled to collect dream reports from both REM and NREM sleep. Participants interpreted their dreams using guided questions based on the Hill cognitive-experiential model. External judges evaluated dreamers\u2019 insight and the interpretation process. Results indicated that REM dream reports contained significantly longer and more complex narratives compared to NREM dream reports. Participants did not generate more associations from REM dreams than from NREM dreams; however, they derived more meaningful insight from REM dreams. Additionally, participants were significantly more likely to report gaining inspiration or solving problems through REM dreams than through NREM dreams, with a moderate effect size. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2025-10-16T00:00:00+00:00",
      "source": "Dreaming",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 143,
      "reading_time": 1,
      "created_at": "2026-01-15T09:51:59.931524+00:00",
      "updated_at": "2026-01-15T09:51:59.931527+00:00"
    },
    {
      "id": "5d45953ad97a989a64d1bd571eab3bda",
      "url": "http://doi.org/10.1037/drm0000323",
      "title": "Measuring dream recall frequency with questionnaire scales and diaries: Reliability and validity.",
      "content": "Research has demonstrated that we very likely dream every night in every sleep stage; however, the ability to recall a dream upon awakening shows large interindividual as well as intraindividual differences. Over the years, researchers studied the reliability and validity of different dream recall measures. In this study, 81 persons (59 women, 22 men) with a mean age of 24.44 \u00b1 8.49 years completed four different retrospective measures of dream recall and a dream diary over a 4-week period. The findings indicate that all dream recall measures (retrospective and prospective) showed high intercorrelations. As all retrospective measuring (last night, last week, last 28 days) yielded comparable estimates of dream recall frequency, it can be argued that underestimation due to memory might be rather small. In addition, we found the expected logbook enhancement effect, that is, dream recall increased during the 4-week period keeping the diary. The internal consistency (reliability of measuring interindividual differences in dream recall with diaries) was sufficiently high for a 2-week period and very high for the 4-week interval. Lastly, the frequency of \u201cwhite dreams\u201d was not related to the retrospectively elicited dream recall frequency and, thus, indicates that participants do not include \u201cwhite dreaming\u201d in their dream recall frequency estimates. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2025-10-20T00:00:00+00:00",
      "source": "Dreaming",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 213,
      "reading_time": 1,
      "created_at": "2026-01-15T09:51:59.931473+00:00",
      "updated_at": "2026-01-15T09:51:59.931475+00:00"
    },
    {
      "id": "ce665d7dd92e5429875519aa49007a16",
      "url": "http://doi.org/10.1037/drm0000318",
      "title": "A study on the dreams of Miao and Han college students in Guizhou Province.",
      "content": "The goal of this study attempts to explore the differences in attitude toward dreams and their possible cultural causes between Han (the majority ethnicity in China) and Miao ethnicity by comparing the dreams from these two groups. Both quantitative (Attitude Towards Dreams Scale and Typical Dream Questionnaire) and qualitative analysis of dream contents have been utilized to explore the dreams of Han and Miao college students in Guizhou Province, where the largest percentage of the Miao ethnic group in the world now resides. The results showed that: (a) There is a significant difference in the themes of typical dreams from Miao and Han college students, which is related to geographical and cultural factors. (b) Miao college students generally have richer dream contents, but a more peaceful attitude toward dreams; this is likely because they have more psychological resources; therefore, dreams are mostly viewed as only one of the channels for them to communicate with their ancestors and nature. Compared to their Han counterparts, Miao college students have more psychological resources because of their cultural identity. The Miao ethnic group\u2019s unique culture is ever present in their unconscious, allowing for more ordinary attitudes toward their dreams. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2025-08-04T00:00:00+00:00",
      "source": "Dreaming",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 204,
      "reading_time": 1,
      "created_at": "2026-01-15T09:51:59.931436+00:00",
      "updated_at": "2026-01-15T09:51:59.931437+00:00"
    },
    {
      "id": "fe29090922ac85ebab441eefe64c5ad4",
      "url": "http://doi.org/10.1037/drm0000314",
      "title": "Cultural influences on dream: A comparative study of Tibetan and Han Chinese populations.",
      "content": "This study sought to compare the dream experiences of Tibetan and Han Chinese populations by employing the Attitudes Toward Dreams Scale, Dream Intensity Scale, and Frequency of Dream Sharing Scale, with a focus on analyzing the influence of cultural differences on these dimensions. The sample comprised 311 Tibetan and 320 Han Chinese participants. The results revealed that Tibetans demonstrated more positive attitudes toward dreams, experienced dreams with greater intensity, and shared dreams more frequently than Han Chinese. Moreover, the attitudes of the Tibetans toward dreams were more indicative of dream intensity and the frequency of dream sharing compared to Han Chinese. Additionally, dream intensity completely mediated in the relationship between attitudes toward dreams and the frequency of dream sharing in both Tibetan and Han Chinese populations. The findings indicate that different cultural contexts demonstrate unique attitudes toward dreams, including variations in dream intensity and the frequency of dream sharing. The Tibetan population, closely intertwined with nature and characterized by a unified set of religious beliefs, such as Tibetan Buddhism, likely has heightened positive perceptions of dreams. This is reflected in their elevated attitudes toward dreams, increased dream intensity, and more frequent dream sharing, as well as a stronger interconnection among these dimensions. Conversely, the Han Chinese, characterized by their widespread distribution and diverse religious beliefs, tend to prioritize material reality over spiritual practices such as dreaming, especially in the context of rapid urban development. These findings shed light on the cultural influences on dreaming. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2025-06-02T00:00:00+00:00",
      "source": "Dreaming",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 253,
      "reading_time": 1,
      "created_at": "2026-01-15T09:51:59.931401+00:00",
      "updated_at": "2026-01-15T09:51:59.931402+00:00"
    },
    {
      "id": "3b6d4945098fec0dcab76af069f743f4",
      "url": "http://doi.org/10.1037/drm0000319",
      "title": "The Oneiric Circle and the Misioneros del Temporal in Morelos, Mexico.",
      "content": "The Misioneros del Temporal is an agricultural community of \u201critual specialists\u201d located in the state of Morelos, Mexico. For this community, dream content serves as a bridge between individual experiences and collective life, linking the ecological environment with their cosmovision. Dreams function both as a means of communication with the divine and as tools for ritual action. This research is based on semistructured interviews, participation in rituals, and participant observation. Additionally, a domain analysis was conducted, with results presented that illustrate the relationship between the most common dreams, their meanings, and associated ritual actions. The study further describes the dynamics through which dreams are shared within the community. The findings suggest that dreams become public forms through their narration and gain meaning through the community\u2019s underlying cosmovision and collective validation. From a cognitive anthropology perspective, this study emphasizes the importance of analyzing the social, cultural, and ecological contexts in which these forms of knowledge emerge. It also highlights the need for dialogue with the individuals involved to better understand the processes of knowledge generation, transmission, and ritual action. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2025-08-11T00:00:00+00:00",
      "source": "Dreaming",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 187,
      "reading_time": 1,
      "created_at": "2026-01-15T09:51:59.931356+00:00",
      "updated_at": "2026-01-15T09:51:59.931358+00:00"
    },
    {
      "id": "329e701ba368cdc25816839a409550e9",
      "url": "https://www.reddit.com/r/Python/comments/1qddgxf/handling_30m_rows_pandascolab_chunking_vs/",
      "title": "Handling 30M rows pandas/colab - Chunking vs Sampling vs Lossing Context?",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m working with a fairly large dataset (CSV) (~3 crore / 30 million rows). Due to memory and compute limits (I\u2019m currently using Google Colab), I can\u2019t load the entire dataset into memory at once.</p> <p>What I\u2019ve done so far:</p> <ul> <li>Randomly sampled ~1 lakh (100k) rows</li> <li>Performed EDA on the sample to understand distributions, correlations, and basic patterns</li> </ul> <p>However, I\u2019m concerned that sampling may lose important data context, especially:</p> <ul> <li>Outliers or rare events</li> <li>Long-tail behavior</li> <li>Rare categories that may not appear in the sample</li> </ul> <p>So I\u2019m considering an alternative approach using pandas chunking:</p> <ul> <li>Read the data with chunksize=1_000_000</li> <li>Define separate functions for:</li> <li>preprocessing</li> <li>EDA/statistics</li> <li>feature engineering</li> </ul> <p>Apply these functions to each chunk</p> <p>Store the processed chunks in a list</p> <p>Concatenate everything at the end into a final DataFrame</p> <p>My questions:</p> <ol> <li><p>Is this chunk-based approach actually safe and scalable for ~30M rows in pandas?</p></li> <li><p>Which types of preprocessing / feature engineering are not safe to do chunk-wise due to missing global context?</p></li> <li><p>If sampling can lose data context, what\u2019s the recommended way to analyze and process such large datasets while still capturing outliers and rare patterns?</p></li> <li><p>Specifically for Google Colab, what are best practices here?</p></li> </ol> <p>-Multiple passes over data? -Storing intermediate results to disk (Parquet/CSV)? -Using Dask/Polars instead of pandas?</p> <p>I\u2019m trying to balance:</p> <p>-Limited RAM -Correct statistical behavior -Practical workflows (not enterprise Spark clusters)</p> <p>Would love to hear how others handle large datasets like this in Colab or similar constrained environments</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/insidePassenger0\"> /u/insidePassenger0 </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1qddgxf/handling_30m_rows_pandascolab_chunking_vs/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1qddgxf/handling_30m_rows_pandascolab_chunking_vs/\">[comments]</a></span>",
      "author": "/u/insidePassenger0",
      "published_date": "2026-01-15T07:45:51+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 270,
      "reading_time": 1,
      "created_at": "2026-01-15T09:29:22.263397+00:00",
      "updated_at": "2026-01-15T09:29:22.263398+00:00"
    },
    {
      "id": "9ebec58112f98d5521828d6a57906aee",
      "url": "https://www.reddit.com/r/Python/comments/1qdel5w/whats_your_default_python_project_setup_in_2026/",
      "title": "What's your default Python project setup in 2026?",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>When starting something new, do you default to:</p> <ul> <li><code>venv</code> or <code>poetry</code>?</li> <li><code>requests</code> vs <code>httpx</code>?</li> <li><code>pandas</code> vs lighter tools?</li> <li>type checking or not?</li> </ul> <p>Not looking for best, just interested in real-world defaults people actually use.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/crowpng\"> /u/crowpng </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1qdel5w/whats_your_default_python_project_setup_in_2026/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1qdel5w/whats_your_default_python_project_setup_in_2026/\">[comments]</a></span>",
      "author": "/u/crowpng",
      "published_date": "2026-01-15T08:55:22+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 57,
      "reading_time": 1,
      "created_at": "2026-01-15T09:29:22.263354+00:00",
      "updated_at": "2026-01-15T09:29:22.263356+00:00"
    },
    {
      "id": "8c72126abfa802ba1dfd01b0cc6aa235",
      "url": "https://www.reddit.com/r/Python/comments/1qcjqqc/dcinput_i_got_tired_of_rewriting_interactive/",
      "title": "dc-input: I got tired of rewriting interactive input logic, so I built this",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>Hi all! I wanted to share a small library I\u2019ve been working on. Feedback is very welcome, especially on UX, edge cases or missing features.</p> <p><a href=\"https://github.com/jdvanwijk/dc-input\">https://github.com/jdvanwijk/dc-input</a></p> <p><strong>What my project does</strong></p> <p>I often end up writing small scripts or internal tools that need structured user input, and I kept re-implementing variations of this:</p> <pre><code>from dataclasses import dataclass @dataclass class User: name: str age: int | None while True: name = input(&quot;Name: &quot;).strip() if name: break print(&quot;Name is required&quot;) while True: age_raw = input(&quot;Age (optional): &quot;).strip() if not age_raw: age = None break try: age = int(age_raw) break except ValueError: print(&quot;Age must be an integer&quot;) user = User(name=name, age=age) </code></pre> <p>This gets tedious (and brittle) once you add nesting, optional sections, repetition, undo, etc.</p> <p>So I built <strong>dc-input</strong>, which lets you do this instead:</p> <pre><code>from dataclasses import dataclass from dc_input import get_input @dataclass class User: name: str age: int | None user = get_input(User) </code></pre> <p>The library walks the dataclass schema and derives an interactive input session from it (nested dataclasses, optional fields, repeatable containers, defaults, undo support, custom parsers via <code>Annotated</code>, etc.).</p> <p>For an interactive session example, see: <a href=\"https://asciinema.org/a/767996\">https://asciinema.org/a/767996</a></p> <p><strong>Target Audience</strong></p> <p>This has been mostly been useful for me in internal scripts and small tools where I want structured input without turning the whole thing into a CLI framework.</p> <p><strong>Comparison</strong></p> <p>Compared to prompt libraries like prompt_toolkit and questionary, dc-input is higher-level: you don\u2019t design prompts or control flow by hand \u2014 the structure of your data <em>is</em> the control flow. This makes <code>dc-input</code> more opinionated and less flexible than those examples, so it won\u2019t fit every workflow; but in return you get very fast setup, strong guarantees about correctness, and excellent support for traversing nested data-structures.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Emotional-Pipe-335\"> /u/Emotional-Pipe-335 </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1qcjqqc/dcinput_i_got_tired_of_rewriting_interactive/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1qcjqqc/dcinput_i_got_tired_of_rewriting_interactive/\">[comments]</a></span>",
      "author": "/u/Emotional-Pipe-335",
      "published_date": "2026-01-14T10:19:17+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 308,
      "reading_time": 1,
      "created_at": "2026-01-15T09:29:22.263329+00:00",
      "updated_at": "2026-01-15T09:29:22.263331+00:00"
    },
    {
      "id": "a2d9da4ad906ae3decc740c900e9d81e",
      "url": "https://www.reddit.com/r/Python/comments/1qcmi4t/ive_published_a_new_audio_dspsynthesis_package_to/",
      "title": "I\u2019ve published a new audio DSP/Synthesis package to PyPI",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>**What My Project Does** - It\u2019s called audio-dsp. It is a comprehensive collection of DSP tools including Synthesizers, Effects, Sequencers, MIDI tools, and Utilities.</p> <p>**Target Audience** - I am a music producer (25 years) and programmer (15 years), so I built this with a focus on high-quality rendering and creative design. If you are a creative coder or audio dev looking to generate sound rather than just analyze it, this is for you.</p> <p>**Comparison** - Most Python audio libraries focus on analysis (like librosa) or pure math (scipy). My library is different because it focuses on musicality and synthesis. It provides the building blocks for creating music and complex sound textures programmatically.</p> <p>Try it out:</p> <p>pip install audio-dsp</p> <p>GitHub: <a href=\"https://github.com/Metallicode/python_audio_dsp\">https://github.com/Metallicode/python_audio_dsp</a></p> <p>I\u2019d love to hear your feedback!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/D0m1n1qu36ry5\"> /u/D0m1n1qu36ry5 </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1qcmi4t/ive_published_a_new_audio_dspsynthesis_package_to/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1qcmi4t/ive_published_a_new_audio_dspsynthesis_package_to/\">[comments]</a></span>",
      "author": "/u/D0m1n1qu36ry5",
      "published_date": "2026-01-14T12:53:28+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 148,
      "reading_time": 1,
      "created_at": "2026-01-15T09:29:22.263274+00:00",
      "updated_at": "2026-01-15T09:29:22.263276+00:00"
    }
  ],
  "recently_processed": [
    {
      "id": "961067587112d5e2f4f1370110478f71",
      "url": "https://www.sciencedirect.com/science/article/pii/S0006899326000193?dgcid=rss_sd_all",
      "title": "Aperiodic slope reflects glutamatergic tone in the human brain",
      "content": "<p>Publication date: 1 March 2026</p><p><b>Source:</b> Brain Research, Volume 1874</p><p>Author(s): Aislin A. Sheldon, Hannah R. Moser, Kamar S. Abdullahi, Karly D. Allison, Carter B. Mulder, Samantha A. Montoya, Scott R. Sponheim, Ma\u0142gorzata Marja\u0144ska, Michael-Paul Schallmo</p>",
      "author": "",
      "published_date": null,
      "source": "Brain Research",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 34,
      "reading_time": 1,
      "created_at": "2026-01-15T09:52:37.108221+00:00",
      "updated_at": "2026-01-15T10:19:21.006727+00:00",
      "metadata": {
        "processed_at": "2026-01-15T10:19:21.006737+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "4d6dbe18e6e3de153038f79152a9f900",
      "url": "https://www.sciencedirect.com/science/article/pii/S0006899326000156?dgcid=rss_sd_all",
      "title": "Elevated FKBP5 expression associates with epilepsy-related molecular changes and promotes neuronal hyperexcitability",
      "content": "<p>Publication date: 1 March 2026</p><p><b>Source:</b> Brain Research, Volume 1874</p><p>Author(s): Meng Cai, Shuyang Wang, Mingsu Liu, Bin Lai, Chen Chen, Jing Ding, Xin Wang</p>",
      "author": "",
      "published_date": null,
      "source": "Brain Research",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 23,
      "reading_time": 1,
      "created_at": "2026-01-15T09:52:37.108199+00:00",
      "updated_at": "2026-01-15T10:19:21.006741+00:00",
      "metadata": {
        "processed_at": "2026-01-15T10:19:21.006743+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "3e2c8953079ea3e91debfc61d0675d5e",
      "url": "https://www.sciencedirect.com/science/article/pii/S0006899326000259?dgcid=rss_sd_all",
      "title": "Multi-biofluid metabolomics coupled with gene network reveals stage-specific alterations in mild cognitive impairment and Alzheimer\u2019s disease in an ethnically mixed cohort",
      "content": "<p>Publication date: 1 March 2026</p><p><b>Source:</b> Brain Research, Volume 1874</p><p>Author(s): Andr\u00e9 Sim\u00f5es Cadaxo, Juliana Cordovil Cotrin, Ana Paula Valente, Fl\u00e1via Gomes Lopes, Renato Peixoto Veras, Daniel Simpl\u00edcio Torres, Raquel Quimas Molina da Costa, Gilson Costa dos Santos Junior, C\u00edntia Barros Santos-Rebou\u00e7as</p>",
      "author": "",
      "published_date": null,
      "source": "Brain Research",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 40,
      "reading_time": 1,
      "created_at": "2026-01-15T09:52:37.108179+00:00",
      "updated_at": "2026-01-15T10:19:21.006748+00:00",
      "metadata": {
        "processed_at": "2026-01-15T10:19:21.006750+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "d04782f24c7e30eb7be47a30c21b0c36",
      "url": "https://www.sciencedirect.com/science/article/pii/S0006899326000247?dgcid=rss_sd_all",
      "title": "Key optogenetic advances in retinal prostheses: A comparative narrative review",
      "content": "<p>Publication date: 1 March 2026</p><p><b>Source:</b> Brain Research, Volume 1874</p><p>Author(s): Laila Zahran, Reham H. Elnabawy</p>",
      "author": "",
      "published_date": null,
      "source": "Brain Research",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 14,
      "reading_time": 1,
      "created_at": "2026-01-15T09:52:37.108100+00:00",
      "updated_at": "2026-01-15T10:19:21.006752+00:00",
      "metadata": {
        "processed_at": "2026-01-15T10:19:21.006754+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "9b33b227664397684e43d7e81f0d2e8c",
      "url": "https://www.pnas.org/doi/abs/10.1073/pnas.2500436123?af=R",
      "title": "Prior novelty invigorates future mesolimbic target detection",
      "content": "Proceedings of the National Academy of Sciences, Volume 123, Issue 2, January 2026. <br />SignificanceSurviving in dynamic environments requires coordinated neural mechanisms to detect, learn from, and respond to change. However, neural regions that support novelty detection and goal-oriented behavior have yet to be described as a sequential ...",
      "author": "Blake L. ElliottKathleen J. O\u2019BrienMatthew FainLauren M. EllmanVishnu P. MurtyaDepartment of Psychology and Neuroscience, Temple University, Philadelphia, PA 19122bDepartment of Psychology, University of Oregon, Eugene, OR 97403cDepartment of Cognitive Science, University of California, San Diego, CA 92037",
      "published_date": "2026-01-05T08:00:00+00:00",
      "source": "Pnas Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 49,
      "reading_time": 1,
      "created_at": "2026-01-15T09:52:25.978313+00:00",
      "updated_at": "2026-01-15T10:19:21.006756+00:00",
      "metadata": {
        "processed_at": "2026-01-15T10:19:21.006758+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "366ce651cd84440b89acdc276fad26cc",
      "url": "https://www.nature.com/articles/s41746-026-02346-6",
      "title": "Remote digital cognitive assessment for aging and dementia using the Oxford Cognitive Testing Portal OCTAL",
      "content": "",
      "author": "",
      "published_date": "2026-01-15T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2026-01-15T07:27:11.996465+00:00",
      "updated_at": "2026-01-15T08:27:31.675892+00:00",
      "metadata": {
        "processed_at": "2026-01-15T08:27:31.675901+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "ed6cd510886ff02fc4c2c364d6129a7a",
      "url": "https://github.com/cjpais/Handy",
      "title": "Handy \u2013 free open source speech-to-text app",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46628397\">Comments</a>",
      "author": "",
      "published_date": "2026-01-15T05:23:18+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-15T07:26:34.012435+00:00",
      "updated_at": "2026-01-15T08:27:31.675907+00:00",
      "metadata": {
        "processed_at": "2026-01-15T08:27:31.675909+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "ed6cd510886ff02fc4c2c364d6129a7a",
      "url": "https://github.com/cjpais/Handy",
      "title": "Handy \u2013 free open source speech-to-text app",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46628397\">Comments</a>",
      "author": "",
      "published_date": "2026-01-15T05:23:18+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-15T07:26:34.012435+00:00",
      "updated_at": "2026-01-15T08:27:31.675907+00:00",
      "metadata": {
        "processed_at": "2026-01-15T08:27:31.675909+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "cf1895af51cf4c2e97e9e112e5aea548",
      "url": "https://www.biorxiv.org/content/10.64898/2026.01.14.699350v1?rss=1",
      "title": "A glucocorticoid-responsive polygenic signature in the anterior cingulate cortex moderates the association of early-life adversity and vulnerability for depression",
      "content": "Stress exposure is a major risk factor for psychopathology, yet how stress mediators shape long-term psychiatric vulnerability in humans remains unclear. Glucocorticoids, central effectors of the stress response, regulate gene expression through tissue-specific transcriptional programs, suggesting that glucocorticoid-responsive networks may shape sensitivity to adversity. Using RNA-sequencing following chronic glucocorticoid exposure in a non-human primate model, we identified a gene co-expression network specific to the anterior cingulate cortex (ACC) that was highly preserved across human post-mortem brain datasets relevant to depression. We derived an expression-based polygenic score (ePGS) reflecting genetic variation in network activity and tested its interaction with adversity in the UK Biobank. The ACC-specific glucocorticoid-responsive ePGS moderated the association between adversity and depressive symptoms in adult females, with the strongest effects for early-life adversity. Network genes were enriched for neurodevelopmental processes and showed stronger co-expression during childhood, highlighting a developmentally sensitive, region-specific mechanism linking stress exposure to depression risk.",
      "author": "Mar Arcego, D., Pokhvisneva, I., Buschdorf, J.-P., O'Toole, N., Patel, S., Sobreira de Lima, R. M., Elgbeili, G., Lee, P., Frosi, G., Fiori, L., Nagy, C., Silveira, P. P., Turecki, G., Meaney, M. J.",
      "published_date": "2026-01-14T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 150,
      "reading_time": 1,
      "created_at": "2026-01-15T06:36:41.081611+00:00",
      "updated_at": "2026-01-15T08:27:31.675917+00:00",
      "metadata": {
        "processed_at": "2026-01-15T08:27:31.675919+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "55f59f5a68319425ee190739948f2714",
      "url": "https://www.frontiersin.org/articles/10.3389/fnhum.2025.1718713",
      "title": "Levels of shared autonomy in brain-robot interfaces: enabling multi-robot multi-human collaboration for activities of daily living",
      "content": "Individuals with ALS and other severe motor impairments often rely on caregivers for daily tasks, which limits their independence and sense of control. Brain-robot interfaces (BRIs) have the potential to restore autonomy, but many existing systems are task-specific and highly automated, which reduces the users' sense of empowerment and limits opportunities to exercise autonomy. In particular, shared autonomy approaches hold promise for overcoming current BRI limitations, by balancing user control with increased robot capabilities. In this work, we introduce a collaborative BRI that integrates non-invasive EEG, EMG, and eye tracking to enable multi-user, multi-robot interaction in a shared kitchen environment with mobile manipulators. Our system modulates assistance through three levels of autonomy\u2014Assisted Teleoperation, Shared Autonomy, and Full Automation\u2014allowing users to retain meaningful control over task execution while reducing effort for routine operations. We conducted a controlled user study comparing autonomy conditions, evaluating performance, workload, ease of use, and agency. Our results show that, while Full Automation was generally preferred by users due to lower workload and higher usability, Shared Autonomy provided higher reliability and preserved user agency, especially in the presence of noisy EEG decoding. Although there was significant individual variability in EEG decoding performance, our post-hoc analysis revealed the potential benefits of customizing pipelines for each user. Finally, we note that our findings are specific to the multi-modal configuration tested and should not be interpreted as a universal claim about the superiority of any autonomy level, and, furthermore, our user study was limited by the use of healthy adults rather than target population (e.g., individuals with ALS), gender imbalance, and a relatively small sample size, which may affect generalizability. Project website: https://coopopen.github.io/.",
      "author": "Kai Arulkumaran",
      "published_date": "2026-01-15T00:00:00+00:00",
      "source": "Frontiers Human Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 273,
      "reading_time": 1,
      "created_at": "2026-01-15T06:36:30.935959+00:00",
      "updated_at": "2026-01-15T08:27:31.675921+00:00",
      "metadata": {
        "processed_at": "2026-01-15T08:27:31.675922+00:00",
        "processing_method": "github_actions"
      }
    }
  ]
}