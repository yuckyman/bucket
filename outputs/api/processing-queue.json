{
  "last_updated": "2026-01-29T06:40:08.959332+00:00",
  "pending_count": 712,
  "processed_count": 288,
  "pending_articles": [
    {
      "id": "1ae6031e74c73097b0df3bb0bb283568",
      "url": "https://xmake.io/",
      "title": "Xmake: A cross-platform build utility based on Lua",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46753037\">Comments</a>",
      "author": "",
      "published_date": "2026-01-25T11:12:47+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-29T06:07:15.156225+00:00",
      "updated_at": "2026-01-29T06:07:15.156227+00:00"
    },
    {
      "id": "698a3967478d4ba61f5711c9117ea7e6",
      "url": "https://www.embs.org/uncategorized/call-for-applications-ieee-tmrb-editor-in-chief-search/",
      "title": "Call for Applications: IEEE T-MRB Editor in Chief Search",
      "content": "<p>The post <a href=\"https://www.embs.org/uncategorized/call-for-applications-ieee-tmrb-editor-in-chief-search/\">Call for Applications: IEEE T-MRB Editor in Chief Search</a> appeared first on <a href=\"https://www.embs.org\">IEEE EMBS</a>.</p>",
      "author": "Deidre Artis",
      "published_date": "2025-04-03T14:16:16+00:00",
      "source": "Embs",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 18,
      "reading_time": 1,
      "created_at": "2026-01-29T05:30:01.428550+00:00",
      "updated_at": "2026-01-29T05:30:01.428552+00:00"
    },
    {
      "id": "6180193191d50495d0300d3fd016ab1d",
      "url": "https://arxiv.org/abs/2601.20437",
      "title": "Remember Me, Not Save Me: A Collective Memory System for Evolving Virtual Identities in Augmented Reality",
      "content": "arXiv:2601.20437v1 Announce Type: new \nAbstract: This paper presents \"Remember Me, Not Save Me,\" an AR & AI system enabling virtual citizens to develop personality through collective dialogue. Core innovations include: Dynamic Collective Memory (DCM) model with narrative tension mechanisms for handling contradictory memories; State-Reflective Avatar for ambient explainability; and Geo-Cultural Context Anchoring for local identity. Deployed at the 2024 Jinan Biennale, the system demonstrated stable personality emergence (ISTP type via Apply Magic Sauce analysis) from over 2,500 public interactions. We provide a framework for designing evolving digital entities that transform collective memory into coherent identity.",
      "author": "Tongzhou Yu, Han Lin",
      "published_date": "2026-01-29T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 95,
      "reading_time": 1,
      "created_at": "2026-01-29T05:29:59.737183+00:00",
      "updated_at": "2026-01-29T05:29:59.737185+00:00"
    },
    {
      "id": "fb4d929277c2838353d4042260dd1014",
      "url": "https://arxiv.org/abs/2601.20402",
      "title": "GuideAI: A Real-time Personalized Learning Solution with Adaptive Interventions",
      "content": "arXiv:2601.20402v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have emerged as powerful learning tools, but they lack awareness of learners' cognitive and physiological states, limiting their adaptability to the user's learning style. Contemporary learning techniques primarily focus on structured learning paths, knowledge tracing, and generic adaptive testing but fail to address real-time learning challenges driven by cognitive load, attention fluctuations, and engagement levels. Building on findings from a formative user study (N=66), we introduce GuideAI, a multi-modal framework that enhances LLM-driven learning by integrating real-time biosensory feedback including eye gaze tracking, heart rate variability, posture detection, and digital note-taking behavior. GuideAI dynamically adapts learning content and pacing through cognitive optimizations (adjusting complexity based on learning progress markers), physiological interventions (breathing guidance and posture correction), and attention-aware strategies (redirecting focus using gaze analysis). Additionally, GuideAI supports diverse learning modalities, including text-based, image-based, audio-based, and video-based instruction, across varied knowledge domains. A preliminary study (N = 25) assessed GuideAI's impact on knowledge retention and cognitive load through standardized assessments. The results show statistically significant improvements in both problem-solving capability and recall-based knowledge assessments. Participants also experienced notable reductions in key NASA-TLX measures including mental demand, frustration levels, and effort, while simultaneously reporting enhanced perceived performance. These findings demonstrate GuideAI's potential to bridge the gap between current LLM-based learning systems and individualized learner needs, paving the way for adaptive, cognition-aware education at scale.",
      "author": "Ananya Shukla, Chaitanya Modi, Satvik Bajpai, Siddharth Siddharth",
      "published_date": "2026-01-29T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 231,
      "reading_time": 1,
      "created_at": "2026-01-29T05:29:59.737157+00:00",
      "updated_at": "2026-01-29T05:29:59.737159+00:00"
    },
    {
      "id": "0e1d7543db212c9352df4608d8275258",
      "url": "https://arxiv.org/abs/2601.20311",
      "title": "DiagLink: A Dual-User Diagnostic Assistance System by Synergizing Experts with LLMs and Knowledge Graphs",
      "content": "arXiv:2601.20311v1 Announce Type: new \nAbstract: The global shortage and uneven distribution of medical expertise continue to hinder equitable access to accurate diagnostic care. While existing intelligent diagnostic system have shown promise, most struggle with dual-user interaction, and dynamic knowledge integration -- limiting their real-world applicability. In this study, we present DiagLink, a dual-user diagnostic assistance system that synergizes large language models (LLMs), knowledge graphs (KGs), and medical experts to support both patients and physicians. DiagLink uses guided dialogues to elicit patient histories, leverages LLMs and KGs for collaborative reasoning, and incorporates physician oversight for continuous knowledge validation and evolution. The system provides a role-adaptive interface, dynamically visualized history, and unified multi-source evidence to improve both trust and usability. We evaluate DiagLink through user study, use cases and expert interviews, demonstrating its effectiveness in improving user satisfaction and diagnostic efficiency, while offering insights for the design of future AI-assisted diagnostic systems.",
      "author": "Zihan Zhou, Yinan Liu, Yuyang Xie, Bin Wang, Xiaochun Yang, Zezheng Feng",
      "published_date": "2026-01-29T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 150,
      "reading_time": 1,
      "created_at": "2026-01-29T05:29:59.737118+00:00",
      "updated_at": "2026-01-29T05:29:59.737119+00:00"
    },
    {
      "id": "44064db91b264ca87ac6cb864ac5139b",
      "url": "https://arxiv.org/abs/2601.20194",
      "title": "An Autonomous Agent Framework for Feature-Label Extraction from Device Dialogues and Automatic Multi-Dimensional Device Hosting Planning Based on Large Language Models",
      "content": "arXiv:2601.20194v1 Announce Type: new \nAbstract: With the deep integration of artificial intelligence and smart home technologies, the intelligent transformation of traditional household appliances has become an inevitable trend. This paper presents AirAgent--an LLM-driven autonomous agent framework designed for home air systems. Leveraging a voice-based dialogue interface, AirAgent autonomously and personally manages indoor air quality through comprehensive perception, reasoning, and control. The framework innovatively adopts a two-layer cooperative architecture: Memory-Based Tag Extraction and Reasoning-Driven Planning. First, a dynamic memory tag extraction module continuously updates personalized user profiles. Second, a reasoning-planning model integrates real-time environmental sensor data, user states, and domain-specific prior knowledge (e.g., public health guidelines) to generate context-aware decisions. To support both interpretability and execution, we design a semi-streaming output mechanism that uses special tokens to segment the model's output stream in real time, simultaneously producing human-readable Chain-of-Thought explanations and structured, device-executable control commands. The system handles planning across 25 distinct complex dimensions while satisfying more than 20 customized constraints. As a result, AirAgent endows home air systems with proactive perception, service, and orchestration capabilities, enabling seamless, precise, and personalized air management responsive to dynamic indoor and outdoor conditions. Experimental results demonstrate up to 94.9 percent accuracy and more than 20 percent improvement in user experience metrics compared to competing commercial solutions.",
      "author": "Huichao Men, Yizhen Hu, Yu Gao, Xiaofeng Mou, Yi Xu, Xinhua Xiao",
      "published_date": "2026-01-29T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 212,
      "reading_time": 1,
      "created_at": "2026-01-29T05:29:59.737088+00:00",
      "updated_at": "2026-01-29T05:29:59.737090+00:00"
    },
    {
      "id": "eba703a43f6d49fd92907ad0aee9508a",
      "url": "https://arxiv.org/abs/2601.20161",
      "title": "Supporting Informed Self-Disclosure: Design Recommendations for Presenting AI-Estimates of Privacy Risks to Users",
      "content": "arXiv:2601.20161v1 Announce Type: new \nAbstract: People candidly discuss sensitive topics online under the perceived safety of anonymity; yet, for many, this perceived safety is tenuous, as miscalibrated risk perceptions can lead to over-disclosure. Recent advances in Natural Language Processing (NLP) afford an unprecedented opportunity to present users with quantified disclosure-based re-identification risk (i.e., \"population risk estimates\", PREs). How can PREs be presented to users in a way that promotes informed decision-making, mitigating risk without encouraging unnecessary self-censorship? Using design fictions and comic-boarding, we story-boarded five design concepts for presenting PREs to users and evaluated them through an online survey with N = 44 Reddit users. We found participants had detailed conceptions of how PREs may impact risk awareness and motivation, but envisioned needing additional context and support to effectively interpret and act on risks. We distill our findings into four key design recommendations for how best to present users with quantified privacy risks to support informed disclosure decision-making.",
      "author": "Isadora Krsek, Meryl Ye, Wei Xu, Alan Ritter, Laura Dabbish, Sauvik Das",
      "published_date": "2026-01-29T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 158,
      "reading_time": 1,
      "created_at": "2026-01-29T05:29:59.737054+00:00",
      "updated_at": "2026-01-29T05:29:59.737056+00:00"
    },
    {
      "id": "d85f6b40aec9d5cacede17b73e63166e",
      "url": "https://arxiv.org/abs/2601.20100",
      "title": "Taming Toxic Talk: Using chatbots to intervene with users posting toxic comments",
      "content": "arXiv:2601.20100v1 Announce Type: new \nAbstract: Generative AI chatbots have proven surprisingly effective at persuading people to change their beliefs and attitudes in lab settings. However, the practical implications of these findings are not yet clear. In this work, we explore the impact of rehabilitative conversations with generative AI chatbots on users who share toxic content online. Toxic behaviors -- like insults or threats of violence, are widespread in online communities. Strategies to deal with toxic behavior are typically punitive, such as removing content or banning users. Rehabilitative approaches are rarely attempted, in part due to the emotional and psychological cost of engaging with aggressive users. In collaboration with seven large Reddit communities, we conducted a large-scale field experiment (N=893) to invite people who had recently posted toxic content to participate in conversations with AI chatbots. A qualitative analysis of the conversations shows that many participants engaged in good faith and even expressed remorse or a desire to change. However, we did not observe a significant change in toxic behavior in the following month compared to a control group. We discuss possible explanations for our findings, as well as theoretical and practical implications based on our results.",
      "author": "Jeremy Foote, Deepak Kumar, Bedadyuti Jha, Ryan Funkhouser, Loizos Bitsikokos, Hitesh Goel, Hsuen-Chi Chiu",
      "published_date": "2026-01-29T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 196,
      "reading_time": 1,
      "created_at": "2026-01-29T05:29:59.737024+00:00",
      "updated_at": "2026-01-29T05:29:59.737025+00:00"
    },
    {
      "id": "997f9672b5e967541bd5879df383c81d",
      "url": "https://arxiv.org/abs/2601.20086",
      "title": "Evaluating Actionability in Explainable AI",
      "content": "arXiv:2601.20086v1 Announce Type: new \nAbstract: A core assumption of Explainable AI (XAI) is that explanations are useful to users -- that is, users will do something with the explanations. Prior work, however, does not clearly connect the information provided in explanations to user actions to evaluate effectiveness. In this paper, we articulate this connection. We conducted a formative study through 14 interviews with end users in education and medicine. We contribute a catalog of information and associated actions. Our catalog maps 12 categories of information that participants described relying on to take 60 different actions. We show how AI Creators can use the catalog's specificity and breadth to articulate how they expect information in their explanations to lead to user actions and test their assumptions. We use an exemplar XAI system to illustrate this approach. We conclude by discussing how our catalog expands the design space for XAI systems to support actionability.",
      "author": "Gennie Mansi, Julia Kim, Mark Riedl",
      "published_date": "2026-01-29T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 152,
      "reading_time": 1,
      "created_at": "2026-01-29T05:29:59.736991+00:00",
      "updated_at": "2026-01-29T05:29:59.736993+00:00"
    },
    {
      "id": "24c8145368d8335073baff360aa38482",
      "url": "https://arxiv.org/abs/2601.20085",
      "title": "Editrail: Understanding AI Usage by Visualizing Student-AI Interaction in Code",
      "content": "arXiv:2601.20085v1 Announce Type: new \nAbstract: Programming instructors have diverse philosophies about integrating generative AI into their classes. Some encourage students to use AI, while others restrict or forbid it. Regardless of their approach, all instructors benefit from understanding how their students actually use AI while writing code. Such insight helps instructors assess whether AI use aligns with their pedagogical goals, enables timely intervention when they find unproductive usage patterns, and establishes effective policies for AI use. However, our survey with programming instructors found that many instructors lack visibility into how students use AI in their code-writing processes. To address this challenge, we introduce Editrail, an interactive system that enables instructors to track students' AI usage, create personalized assessments, and provide timely interventions, all within the workflow of monitoring coding histories. We found that Editrail enables instructors to detect AI use that conflicts with pedagogical goals accurately and to determine when and which students require intervention.",
      "author": "Ashley Ge Zhang, Yan-Ru Jhou, Yinuo Yang, Shamita Rao, Maryam Arab, Yan Chen, Steve Oney",
      "published_date": "2026-01-29T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 155,
      "reading_time": 1,
      "created_at": "2026-01-29T05:29:59.736958+00:00",
      "updated_at": "2026-01-29T05:29:59.736960+00:00"
    }
  ],
  "recently_processed": [
    {
      "id": "3df256d524e3fc7842bdb6b5772d75c7",
      "url": "https://www.sciencedirect.com/science/article/pii/S0006899326000223?dgcid=rss_sd_all",
      "title": "Genetics of Autism Spectrum Disorder underscores the role of altered spontaneous neuronal activity as a catalyst for the neurodevelopmental anomalies",
      "content": "<p>Publication date: 15 March 2026</p><p><b>Source:</b> Brain Research, Volume 1875</p><p>Author(s): Sarani Dey, Abhijit Das</p>",
      "author": "",
      "published_date": null,
      "source": "Brain Research",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2026-01-29T06:08:01.032684+00:00",
      "updated_at": "2026-01-29T06:40:08.847018+00:00",
      "metadata": {
        "processed_at": "2026-01-29T06:40:08.847029+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "2b5e21d5c9d66628fd1b2e60407de021",
      "url": "https://www.sciencedirect.com/science/article/pii/S0006899326000260?dgcid=rss_sd_all",
      "title": "The oral-gut-brain axis in periodontitis: microbial signaling in systemic and neuroinflammatory disease",
      "content": "<p>Publication date: 15 March 2026</p><p><b>Source:</b> Brain Research, Volume 1875</p><p>Author(s): V. Pravin, Chitra Vellapandian, V. Naveen Kumar</p>",
      "author": "",
      "published_date": null,
      "source": "Brain Research",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 16,
      "reading_time": 1,
      "created_at": "2026-01-29T06:08:01.032665+00:00",
      "updated_at": "2026-01-29T06:40:08.847033+00:00",
      "metadata": {
        "processed_at": "2026-01-29T06:40:08.847035+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "29eedc82df2c87e25f86837177f4003c",
      "url": "https://www.sciencedirect.com/science/article/pii/S1053811926000613?dgcid=rss_sd_all",
      "title": "A watershed algorithm GUI for personalized fMRI-guided rTMS target",
      "content": "<p>Publication date: 15 February 2026</p><p><b>Source:</b> NeuroImage, Volume 327</p><p>Author(s): Zi-Jian Feng, Ziyu Wei, Liquan Hong, Hongli Fang, Yu Han, Peifeng Yang, Dongsheng Lv, Yu-Feng Zang</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroimage",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 24,
      "reading_time": 1,
      "created_at": "2026-01-29T06:07:57.566491+00:00",
      "updated_at": "2026-01-29T06:40:08.847038+00:00",
      "metadata": {
        "processed_at": "2026-01-29T06:40:08.847039+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "6e6ce3e7a4bd63e3be884b39f3175024",
      "url": "https://www.frontiersin.org/articles/10.3389/fnbot.2025.1757770",
      "title": "Editorial: Machine learning and applied neuroscience, volume II",
      "content": "",
      "author": "Ganesh R. Naik",
      "published_date": "2026-01-20T00:00:00+00:00",
      "source": "Frontiers Neurorobotics",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2026-01-29T06:07:43.011517+00:00",
      "updated_at": "2026-01-29T06:40:08.847041+00:00",
      "metadata": {
        "processed_at": "2026-01-29T06:40:08.847043+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "5b46d7cf0b0030cf012f7c2d1d5b3185",
      "url": "http://doi.org/10.1037/drm0000321",
      "title": "The significance of dreams and dreaming in the traditional culture of Luo people in Kenya.",
      "content": "This article comprises two parts. Part I deals with Augustine Nwoye\u2019s classification of dreams in Africa, a theoretical background that has been used here purposively to explain the significance of dreams and dreaming to the Luo people in Kenya. This article is therefore deliberately anchored on Nwoye\u2019s African theoretical framework on dreams and dreaming. Part II of this article examines different types of dreams from the cultural perspective of the Luo traditional community, dreams that exemplify Nwoye\u2019s tripartite division of dreams and their sources. This article is particularly concerned with the meaning and significance of dreams and dreaming and what cultural practices and beliefs about dreams and dreaming might reveal about the ethical, epistemological, and metaphysical worldview of the Luo. Culturally, dreams serve various functions such as: sourcing names, counseling, healing, communication with ancestral spirits, mourning, solving personal and societal problems, prediction, divination, and fortune-telling, among many other pertinent issues. Dreams have social, cultural, epistemological, and metaphysical functions. These functions have been articulated in this article, \u201cThe Significance of Dreams and Dreaming.\u201d This article is one among only a few publications on the topic concerning the value of dreams and dreaming in the beliefs, customs, traditions, and beliefs of this community, the Luo in Kenya. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2025-10-23T00:00:00+00:00",
      "source": "Dreaming",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 214,
      "reading_time": 1,
      "created_at": "2026-01-29T06:07:21.069593+00:00",
      "updated_at": "2026-01-29T06:40:08.847045+00:00",
      "metadata": {
        "processed_at": "2026-01-29T06:40:08.847047+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "fbfb88f9188fc7569ab7f253efae55d8",
      "url": "https://www.nature.com/articles/s44271-026-00399-7",
      "title": "Long-term effects of working memory retrieval from prioritized and deprioritized states",
      "content": "",
      "author": "",
      "published_date": "2026-01-28T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2026-01-29T02:06:51.014059+00:00",
      "updated_at": "2026-01-29T04:03:43.864332+00:00",
      "metadata": {
        "processed_at": "2026-01-29T04:03:43.864344+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "fa250840ddf6808c93613cad856c7c25",
      "url": "http://doi.org/10.1037/cns0000353",
      "title": "Unmuting lucid dreams: Speech decoding and vocalization in real time.",
      "content": "Since the 1970s, scientists have been searching for ways to communicate with people in lucid dreams (LDs), during which it is possible to maintain consciousness. Previously, dreamers could hear sounds from reality and respond with some simple signals, but they could not speak back. In this study, facial surface electromyography (EMG) was tested as a proof of concept for unmuting people in LDs. Remmyo, an EMG distinctive constructed language, was used. The software was developed to translate facial EMG impulses into Remmyo sounds and letters, translate words into English, and digitally vocalize the final text in English. Four LD practitioners were trained to pronounce a short phrase or a word in Remmyo and were then asked to achieve the same task in LDs under polysomnographic observation. LDs were verified by preagreed eye movements in rapid eye movement (REM) sleep. Four volunteers tried to speak in Remmyo in 15 LDs. Due to software failures, mispronunciations, and missing sounds, the decoding efficiency in real time or in recordings ranged from 13% to 81%. The first phrase and word heard from sleeping people were \u201cno war\u201d and \u201cfreedom.\u201d The later was automatically translated and vocalized in English in real time for 11 times. Despite controversial results, the study shows that, with further development, people could possibly talk in LDs and could be heard in reality with the help of EMG sensors. To achieve this goal, a range of possible obstacles is discussed. This technology could provide opportunities for LD studies and their practical applications. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2023-03-13T00:00:00+00:00",
      "source": "Clinical Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 260,
      "reading_time": 1,
      "created_at": "2026-01-29T02:06:23.146136+00:00",
      "updated_at": "2026-01-29T04:03:43.864349+00:00",
      "metadata": {
        "processed_at": "2026-01-29T04:03:43.864350+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "3cace5c5d9bdc4eeebb05365c3e99538",
      "url": "http://doi.org/10.1037/cns0000402",
      "title": "Creating a world in the head: The conscious apprehension of neural content originating from internal sources.",
      "content": "Klein et al. (2023) argued that the evolutionary transition from respondent to agent during the Cambrian explosion would be a promising vantage point from which to gain insight into the evolution of organic sentience. They focused on how increased competition for resources\u2014in consequence of the proliferation of new, neurally sophisticated life-forms\u2014made awareness of the external world (in the service of agentic acts) an adaptive priority. The explanatory scope of Klein et al. (2023) was limited to consideration of the conscious apprehension of externally sourced content\u2014that is, content delivered from the sensory registration of objects occupying phenomenal space. But consciousness\u2014at least for humans\u2014takes its objects from internal as well as external sources. In the present article, we extend their analysis to the question of how internally sourced content (i.e., mental states) became the object of conscious apprehension. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2024-09-09T00:00:00+00:00",
      "source": "Clinical Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 145,
      "reading_time": 1,
      "created_at": "2026-01-29T02:06:23.146091+00:00",
      "updated_at": "2026-01-29T04:03:43.864353+00:00",
      "metadata": {
        "processed_at": "2026-01-29T04:03:43.864372+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "ac3e9f05a46b4c55345efa291a4b1c72",
      "url": "https://www.mcsweeneys.net/articles/please-dont-say-mean-things-about-the-ai-that-i-just-invested-a-billion-dollars-in",
      "title": "Please Don't Say Mean Things about the AI I Just Invested a Billion Dollars In",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46803356\">Comments</a>",
      "author": "",
      "published_date": "2026-01-28T23:36:23+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-29T02:06:14.480760+00:00",
      "updated_at": "2026-01-29T04:03:43.864374+00:00",
      "metadata": {
        "processed_at": "2026-01-29T04:03:43.864376+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "ac3e9f05a46b4c55345efa291a4b1c72",
      "url": "https://www.mcsweeneys.net/articles/please-dont-say-mean-things-about-the-ai-that-i-just-invested-a-billion-dollars-in",
      "title": "Please Don't Say Mean Things about the AI I Just Invested a Billion Dollars In",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46803356\">Comments</a>",
      "author": "",
      "published_date": "2026-01-28T23:36:23+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-29T02:06:14.480760+00:00",
      "updated_at": "2026-01-29T04:03:43.864374+00:00",
      "metadata": {
        "processed_at": "2026-01-29T04:03:43.864376+00:00",
        "processing_method": "github_actions"
      }
    }
  ]
}