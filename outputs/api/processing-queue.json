{
  "last_updated": "2025-12-25T06:25:52.191098+00:00",
  "pending_count": 679,
  "processed_count": 321,
  "pending_articles": [
    {
      "id": "66779daa1cdab930a398f62257c1219b",
      "url": "https://arxiv.org/abs/2512.21246",
      "title": "Learning Factors in AI-Augmented Education: A Comparative Study of Middle and High School Students",
      "content": "arXiv:2512.21246v1 Announce Type: new \nAbstract: The increasing integration of AI tools in education has led prior research to explore their impact on learning processes. Nevertheless, most existing studies focus on higher education and conventional instructional contexts, leaving open questions about how key learning factors are related in AI-mediated learning environments and how these relationships may vary across different age groups. Addressing these gaps, our work investigates whether four critical learning factors, experience, clarity, comfort, and motivation, maintain coherent interrelationships in AI-augmented educational settings, and how the structure of these relationships differs between middle and high school students. The study was conducted in authentic classroom contexts where students interacted with AI tools as part of programming learning activities to collect data on the four learning factors and students' perceptions. Using a multimethod quantitative analysis, which combined correlation analysis and text mining, we revealed markedly different dimensional structures between the two age groups. Middle school students exhibit strong positive correlations across all dimensions, indicating holistic evaluation patterns whereby positive perceptions in one dimension generalise to others. In contrast, high school students show weak or near-zero correlations between key dimensions, suggesting a more differentiated evaluation process in which dimensions are assessed independently. These findings reveal that perception dimensions actively mediate AI-augmented learning and that the developmental stage moderates their interdependencies. This work establishes a foundation for the development of AI integration strategies that respond to learners' developmental levels and account for age-specific dimensional structures in student-AI interactions.",
      "author": "Gaia Ebli, Bianca Raimondi, Maurizio Gabbrielli",
      "published_date": "2025-12-25T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 244,
      "reading_time": 1,
      "created_at": "2025-12-25T05:27:42.085687+00:00",
      "updated_at": "2025-12-25T05:27:42.085689+00:00"
    },
    {
      "id": "2ff5c778262db4e85aba3ce0dc24c51a",
      "url": "https://arxiv.org/abs/2512.21105",
      "title": "Volatile Organic Compounds for Stress Detection: A Scoping Review and Exploratory Feasibility Study with Low-Cost Sensors",
      "content": "arXiv:2512.21105v1 Announce Type: new \nAbstract: Volatile organic compounds (VOCs) represent a novel but underexplored modality for emotion recognition. This paper presents a systematic evidence synthesis and exploratory investigation of VOC-based affective computing using low-cost sensors. Study 1, a systematic scoping review following PRISMA-ScR guidelines, analyzed 16 studies from 610 records across breath, sweat, skin, and urine biosources. Evidence indicates that stress and affective states are reflected in VOC signatures (aldehydes, ketones, fatty acids, sulfur compounds), though with considerable heterogeneity. Current research relies predominantly on laboratory-grade GC-MS or PTR-MS, while wearable sensors provide pattern-level outputs without compound-specific identification - a critical gap for practical systems. Study 2 (n=25) investigated whether low-cost TVOC sensors (BME688, ENS160) combined with physiological monitoring (HR, HRV, GSR) can detect laboratory-induced stress. Exploratory analysis revealed that high cardiovascular reactors exhibited elevated TVOC during arithmetic stress (d=1.38), though requiring replication in larger samples. Substantial interindividual variability emerged (CV>80%), with coupling patterns moderated by baseline emission levels and temporal lags of 30-80 seconds. Random Forest-based multimodal classification achieved 77.3% accuracy (5-fold CV). SHAP analysis indicated VOC sensors contributed 24.9% of model performance. Leave-one-subject-out validation yielded 65.3% accuracy, highlighting the need for individual calibration. This work provides three contributions: (1) comprehensive mapping of VOC biomarker evidence and technological gaps, (2) initial demonstration that low-cost sensors can capture stress-related VOC patterns in multimodal fusion, and (3) identification of key implementation challenges. Findings require replication in larger samples (n>=50).",
      "author": "Nicolai Plintz, Marcus Vetter, Dirk Ifenthaler",
      "published_date": "2025-12-25T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 237,
      "reading_time": 1,
      "created_at": "2025-12-25T05:27:42.085652+00:00",
      "updated_at": "2025-12-25T05:27:42.085654+00:00"
    },
    {
      "id": "e2594c234e9cb7ef7a38b3c0a70ffc6d",
      "url": "https://arxiv.org/abs/2512.21041",
      "title": "When LLMs fall short in Deductive Coding: Model Comparison and Human AI Collaboration Workflow Design",
      "content": "arXiv:2512.21041v1 Announce Type: new \nAbstract: With generative artificial intelligence driving the growth of dialogic data in education, automated coding is a promising direction for learning analytics to improve efficiency. This surge highlights the need to understand the nuances of student-AI interactions, especially those rare yet crucial. However, automated coding may struggle to capture these rare codes due to imbalanced data, while human coding remains time-consuming and labour-intensive. The current study examined the potential of large language models (LLMs) to approximate or replace humans in deductive, theory-driven coding, while also exploring how human-AI collaboration might support such coding tasks at scale. We compared the coding performance of small transformer classifiers (e.g., BERT) and LLMs in two datasets, with particular attention to imbalanced head-tail distributions in dialogue codes. Our results showed that LLMs did not outperform BERT-based models and exhibited systematic errors and biases in deductive coding tasks. We designed and evaluated a human-AI collaborative workflow that improved coding efficiency while maintaining coding reliability. Our findings reveal both the limitations of LLMs -- especially their difficulties with semantic similarity and theoretical interpretations and the indispensable role of human judgment -- while demonstrating the practical promise of human-AI collaborative workflows for coding.",
      "author": "Zijian Li, Luzhen Tang, Mengyu Xia, Xinyu Li, Naping Chen, Dragan Ga\\v{s}evi\\'c, Yizhou Fan",
      "published_date": "2025-12-25T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 199,
      "reading_time": 1,
      "created_at": "2025-12-25T05:27:42.085616+00:00",
      "updated_at": "2025-12-25T05:27:42.085618+00:00"
    },
    {
      "id": "b8de5c3154b68eae5ffa193b9b484e49",
      "url": "https://arxiv.org/abs/2512.21034",
      "title": "A Design Study Process Model for Medical Visualization",
      "content": "arXiv:2512.21034v1 Announce Type: new \nAbstract: We introduce a design study process model for medical visualization based on the analysis of existing medical visualization and visual analysis works, and our own interdisciplinary research experience. With a literature review of related works covering various data types and applications, we identify features of medical visualization and visual analysis research and formulate our model thereafter. Compared to previous design study process models, our new model emphasizes: distinguishing between different stakeholders and target users before initiating specific designs, distinguishing design stages according to analytic logic or cognitive habits, and classifying task types as inferential or descriptive, and further hypothesis-based or hypothesis-free based on whether they involve multiple subgroups. In addition, our model refines previous models according to the characteristics of medical problems and provides referable guidance for each step. These improvements make the visualization design targeted, generalizable, and operational, which can adapt to the complexity and diversity of medical problems. We apply this model to guide the design of a visual analysis method and reanalyze three medical visualization-related works. These examples suggest that the new process model can provide a systematic theoretical framework and practical guidance for interdisciplinary medical visualization research. We give recommendations that future researchers can refer to, report on reflections on the model, and delineate it from existing models.",
      "author": "Mengjie Fan, Liang Zhou",
      "published_date": "2025-12-25T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 217,
      "reading_time": 1,
      "created_at": "2025-12-25T05:27:42.085580+00:00",
      "updated_at": "2025-12-25T05:27:42.085581+00:00"
    },
    {
      "id": "f1ecc649b4a29a5976ad4c649ed26187",
      "url": "https://arxiv.org/abs/2512.20938",
      "title": "Pioneering Multimodal Emotion Recognition in the Era of Large Models: From Closed Sets to Open Vocabularies",
      "content": "arXiv:2512.20938v1 Announce Type: new \nAbstract: Recent advances in multimodal large language models (MLLMs) have demonstrated remarkable multi- and cross-modal integration capabilities. However, their potential for fine-grained emotion understanding remains systematically underexplored. While open-vocabulary multimodal emotion recognition (MER-OV) has emerged as a promising direction to overcome the limitations of closed emotion sets, no comprehensive evaluation of MLLMs in this context currently exists. To address this, our work presents the first large-scale benchmarking study of MER-OV on the OV-MERD dataset, evaluating 19 mainstream MLLMs, including general-purpose, modality-specialized, and reasoning-enhanced architectures. Through systematic analysis of model reasoning capacity, fusion strategies, contextual utilization, and prompt design, we provide key insights into the capabilities and limitations of current MLLMs for MER-OV. Our evaluation reveals that a two-stage, trimodal (audio, video, and text) fusion approach achieves optimal performance in MER-OV, with video emerging as the most critical modality. We further identify a surprisingly narrow gap between open- and closed-source LLMs. These findings establish essential benchmarks and offer practical guidelines for advancing open-vocabulary and fine-grained affective computing, paving the way for more nuanced and interpretable emotion AI systems. Associated code will be made publicly available upon acceptance.",
      "author": "Jing Han, Zhiqiang Gao, Shihao Gao, Jialing Liu, Hongyu Chen, Zixing Zhang, Bj\\\"orn W. Schuller",
      "published_date": "2025-12-25T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 190,
      "reading_time": 1,
      "created_at": "2025-12-25T05:27:42.085546+00:00",
      "updated_at": "2025-12-25T05:27:42.085547+00:00"
    },
    {
      "id": "58babdec160cecf2028b049a1316f358",
      "url": "https://arxiv.org/abs/2512.20621",
      "title": "Cooperation Through Indirect Reciprocity in Child-Robot Interactions",
      "content": "arXiv:2512.20621v1 Announce Type: new \nAbstract: Social interactions increasingly involve artificial agents, such as conversational or collaborative bots. Understanding trust and prosociality in these settings is fundamental to improve human-AI teamwork. Research in biology and social sciences has identified mechanisms to sustain cooperation among humans. Indirect reciprocity (IR) is one of them. With IR, helping someone can enhance an individual's reputation, nudging others to reciprocate in the future. Transposing IR to human-AI interactions is however challenging, as differences in human demographics, moral judgements, and agents' learning dynamics can affect how interactions are assessed. To study IR in human-AI groups, we combine laboratory experiments and theoretical modelling. We investigate whether 1) indirect reciprocity can be transposed to children-robot interactions; 2) artificial agents can learn to cooperate given children's strategies; and 3) how differences in learning algorithms impact human-AI cooperation. We find that IR extends to children and robots solving coordination dilemmas. Furthermore, we observe that the strategies revealed by children provide a sufficient signal for multi-armed bandit algorithms to learn cooperative actions. Beyond the experimental scenarios, we observe that cooperating through multi-armed bandit algorithms is highly dependent on the strategies revealed by humans.",
      "author": "Isabel Neto, Alexandre S. Pires, Filipa Correia, Fernando P. Santos",
      "published_date": "2025-12-25T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 191,
      "reading_time": 1,
      "created_at": "2025-12-25T05:27:42.085512+00:00",
      "updated_at": "2025-12-25T05:27:42.085514+00:00"
    },
    {
      "id": "4599f64c829c7df40f931ccfb49f54e0",
      "url": "https://arxiv.org/abs/2512.20620",
      "title": "Uncovering Patterns of Brain Activity from EEG Data Consistently Associated with Cybersickness Using Neural Network Interpretability Maps",
      "content": "arXiv:2512.20620v1 Announce Type: new \nAbstract: Cybersickness poses a serious challenge for users of virtual reality (VR) technology. Consequently, there has been significant effort to track its occurrence during VR use with brain activity through electroencephalography (EEG). However, a significant confound in current methods for detecting sickness from EEG is they do not account for the simultaneous processing of the sickening visual stimulus that is present in the brain data from VR. Using event-related potentials (ERPs) from an auditory stimulus shown to reflect cybersickness impacts, we can more precisely target EEG cybersickness features and use those to achieve better performance in online cybersickness classification. In this article, we introduce a method utilizing trained convolutional neural networks and transformer models and plot interpretability maps from integrated gradients and class activation to give a visual representation of what the model determined was most useful in sickness classification from an EEG dataset consisting of ERPs recorded during the elicitation of cybersickness. Across 12 runs of our method with three different neural networks, the models consistently pointed to a surprising finding: that amplitudes recorded at an electrode placed on the scalp near the left prefrontal cortex were important in the classification of cybersickness. These results help clarify a hidden pattern in other related research and point to exciting opportunities for future investigation: that this scalp location could be used as a tagged feature for better real-time cybersickness classification with EEG. We provide our code at: [anonymized].",
      "author": "Jacqueline Yau, Katherine J. Mimnaugh, Evan G. Center, Timo Ojala, Steven M. LaValle, Wenzhen Yuan, Nancy Amato, Minje Kim, Kara Federmeier",
      "published_date": "2025-12-25T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 241,
      "reading_time": 1,
      "created_at": "2025-12-25T05:27:42.085471+00:00",
      "updated_at": "2025-12-25T05:27:42.085475+00:00"
    },
    {
      "id": "3cb3b586ca59c29f68af79979ff8d20a",
      "url": "https://arxiv.org/abs/2511.20950",
      "title": "Stabilizing Fractional Dynamical Networks Suppresses Epileptic Seizures",
      "content": "arXiv:2511.20950v3 Announce Type: replace-cross \nAbstract: Medically uncontrolled epileptic seizures affect nearly 15 million people worldwide, resulting in enormous economic and psychological burdens. Treatment of medically refractory epilepsy is essential for patients to achieve remission, improve psychological functioning, and enhance social and vocational outcomes. Here, we show a state-of-the-art method that stabilizes fractional dynamical networks modeled from intracranial EEG data, effectively suppressing seizure activity in 34 out of 35 total spontaneous episodes from patients at the University of Pennsylvania and the Mayo Clinic. We perform a multi-scale analysis and show that the fractal behavior and stability properties of these data distinguish between four epileptic states: interictal, pre-ictal, ictal, and post-ictal. Furthermore, the simulated controlled signals exhibit substantial amplitude reduction ($49\\%$ average). These findings highlight the potential of fractional dynamics to characterize seizure-related brain states and demonstrate its capability to suppress epileptic activity.",
      "author": "Yaoyue Wang, Arian Ashourvan, Guilherme Ramos, Paul Bogdan, Emily Pereira",
      "published_date": "2025-12-25T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 141,
      "reading_time": 1,
      "created_at": "2025-12-25T05:27:40.938651+00:00",
      "updated_at": "2025-12-25T05:27:40.938653+00:00"
    },
    {
      "id": "514b9621ebca6fc7f5557417e2312150",
      "url": "https://arxiv.org/abs/2507.11783",
      "title": "EEG Foundation Models: A Critical Review of Current Progress and Future Directions",
      "content": "arXiv:2507.11783v3 Announce Type: replace-cross \nAbstract: Premise. Patterns of electrical brain activity recorded via electroencephalography (EEG) offer immense value for scientific and clinical investigations. The inability of supervised EEG encoders to learn robust EEG patterns and their over-reliance on expensive signal annotations have sparked a transition towards general-purpose self-supervised EEG encoders, i.e., EEG foundation models (EEG-FMs), for robust and scalable EEG feature extraction. However, the real-world readiness of early EEG-FMs and the rubrics for long-term research progress remain unclear. Objective. In this work, we conduct a review of ten early EEG-FMs to capture common trends and identify key directions for future development of EEG-FMs. Methods. We comparatively analyze each EEG-FM using three fundamental pillars of foundation modeling, namely the representation of input data, self-supervised modeling, and the evaluation strategy. Based on this analysis, we present a critical synthesis of EEG-FM methodology, empirical findings, and outstanding research gaps. Results. We find that most EEG-FMs adopt a sequence-based modeling scheme that relies on transformer-based backbones and the reconstruction of masked temporal EEG sequences for self-supervision. However, model evaluations remain heterogeneous and largely limited, making it challenging to assess their practical off-the-shelf utility. In addition to adopting standardized and realistic evaluations, future work should demonstrate more substantial scaling effects and make principled and trustworthy choices throughout the EEG representation learning pipeline. Significance. Our review indicates that the development of benchmarks, software tools, technical methodologies, and applications in collaboration with domain experts may advance the translational utility and real-world adoption of EEG-FMs.",
      "author": "Gayal Kuruppu, Neeraj Wagh, Vaclav Kremen, Sandipan Pati, Gregory Worrell, Yogatheesan Varatharajah",
      "published_date": "2025-12-25T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 247,
      "reading_time": 1,
      "created_at": "2025-12-25T05:27:40.938624+00:00",
      "updated_at": "2025-12-25T05:27:40.938625+00:00"
    },
    {
      "id": "51d9d7064ba2a6e36976f0cac9a2b502",
      "url": "https://arxiv.org/abs/2412.07327",
      "title": "Gradient Diffusion: Sensitivity-Matrix Co-Simulation Enables Activity Adaptation and Learnable Plasticity in Neural Simulators",
      "content": "arXiv:2412.07327v4 Announce Type: replace \nAbstract: Computational neuroscience relies on large-scale dynamical-systems models of neurons, with a vast amount of offline, pre-simulation, tuned parameters, with models often tied to their brain simulators. These fixed parameters lead to stiff models, that show unnatural behaviour when introduced to new environments, or when combined into larger networks. In contrast to offline tuning, in biology, cells continuously adapt via homeostatic plasticity to stay in desired dynamical regimes. In this work, we aim to introduce such online tuning of cellular parameters into brain simulation. We show that the sensitivity equation of a biorealistic neural models has the same shape as a general neuron model, and can be simulated within existing brain simulators. Via co-simulation with the sensitivity equation, we enable both offline, and online tuning of activity of arbitrary biophysically realistic brain models. Furthermore, we show that this opens the possibility to study the biological mechanisms underlying homeostatic plasticity, via both meta-learning plasticity mechanism as well as treating online tuning as a black-box plasticity mechanism. Through the generality of our methods, we hope that more computational science fields can capitalize on the similarity between the simulated model and its gradient system.",
      "author": "Lennart P. L. Landsmeer, Mario Negrello, Said Hamdioui, Christos Strydis",
      "published_date": "2025-12-25T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 195,
      "reading_time": 1,
      "created_at": "2025-12-25T05:27:40.938551+00:00",
      "updated_at": "2025-12-25T05:27:40.938553+00:00"
    }
  ],
  "recently_processed": [
    {
      "id": "01749a8ddc23a0bf4312d50999f964ce",
      "url": "http://doi.org/10.1037/neu0001018",
      "title": "Inhibitory control underpins the relationship between cognitive and psychological inflexibility after a moderate to severe traumatic brain injury.",
      "content": "Objective: Cognitive flexibility is proposed as being one \u201cbuilding block\u201d of psychological inflexibility/flexibility, yet empirical studies examining these associations are scarce. This study aims to examine the relationship between these constructs in those with a moderate to severe traumatic brain injury who demonstrate impairments in cognitive flexibility. Method: A total of 66 individuals with a traumatic brain injury were administered a battery of cognitive flexibility measures in conjunction with their standard neuropsychological assessment, general (Acceptance and Action Questionnaire\u2013II [AAQ-II]) and context-specific (Acceptance and Action Questionnaire\u2013Acquired Brain Injury [AAQ-ABI]) measures of psychological inflexibility and psychological distress (Depression Anxiety Stress Scale\u201321). Results: Linear regression modeling found the Stroop color\u2013word interference score was the only measure of cognitive flexibility that was significantly associated with AAQ-ABI (\u03b2 = \u2212.14, <em>p</em> < .001), a finding that remained when controlling for Full-Scale Intelligence Quotient and education. Similarly, the Stroop color\u2013word interference score significantly predicted the AAQ-II (\u03b2 = \u22120.13, <em>p</em> = .024). Simple mediation analysis found the AAQ-ABI and AAQ-II fully mediated the relationship between the Stroop color\u2013word interference score and psychological distress. Conclusions: This research provides support for the theory of cognitive flexibility being an essential component of psychological inflexibility. Inhibitory control may be an important process within cognitive flexibility that contributes to psychological inflexibility. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2025-05-08T00:00:00+00:00",
      "source": "Neuropsychology",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 219,
      "reading_time": 1,
      "created_at": "2025-12-25T05:48:22.950789+00:00",
      "updated_at": "2025-12-25T06:25:52.082883+00:00",
      "metadata": {
        "processed_at": "2025-12-25T06:25:52.082892+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "3fc2201af4baa7be2ba11a7614df7a90",
      "url": "https://blocksandfiles.com/2025/12/17/jedec-sphbm4/",
      "title": "JEDEC developing reduced pin count HBM4 standard to enable higher capacity",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46314540\">Comments</a>",
      "author": "",
      "published_date": "2025-12-18T16:11:50+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-25T05:48:15.801277+00:00",
      "updated_at": "2025-12-25T06:25:52.082896+00:00",
      "metadata": {
        "processed_at": "2025-12-25T06:25:52.082898+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "c0377bf418764d287772e08eebf7f8c0",
      "url": "https://arxiv.org/abs/2512.20847",
      "title": "YCB-Handovers Dataset: Analyzing Object Weight Impact on Human Handovers to Adapt Robotic Handover Motion",
      "content": "arXiv:2512.20847v1 Announce Type: cross \nAbstract: This paper introduces the YCB-Handovers dataset, capturing motion data of 2771 human-human handovers with varying object weights. The dataset aims to bridge a gap in human-robot collaboration research, providing insights into the impact of object weight in human handovers and readiness cues for intuitive robotic motion planning. The underlying dataset for object recognition and tracking is the YCB (Yale-CMU-Berkeley) dataset, which is an established standard dataset used in algorithms for robotic manipulation, including grasping and carrying objects. The YCB-Handovers dataset incorporates human motion patterns in handovers, making it applicable for data-driven, human-inspired models aimed at weight-sensitive motion planning and adaptive robotic behaviors. This dataset covers an extensive range of weights, allowing for a more robust study of handover behavior and weight variation. Some objects also require careful handovers, highlighting contrasts with standard handovers. We also provide a detailed analysis of the object's weight impact on the human reaching motion in these handovers.",
      "author": "Parag Khanna, Karen Jane Dsouza, Chunyu Wang, M{\\aa}rten Bj\\\"orkman, Christian Smith",
      "published_date": "2025-12-25T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 157,
      "reading_time": 1,
      "created_at": "2025-12-25T05:27:42.085779+00:00",
      "updated_at": "2025-12-25T06:25:52.082901+00:00",
      "metadata": {
        "processed_at": "2025-12-25T06:25:52.082902+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "7f67b6df5eaabc4b9ff037b51a32cf0a",
      "url": "https://arxiv.org/abs/2512.20714",
      "title": "From Pilots to Practices: A Scoping Review of GenAI-Enabled Personalization in Computer Science Education",
      "content": "arXiv:2512.20714v1 Announce Type: cross \nAbstract: Generative AI enables personalized computer science education at scale, yet questions remain about whether such personalization supports or undermines learning. This scoping review synthesizes 32 studies (2023-2025) purposively sampled from 259 records to map personalization mechanisms and effectiveness signals in higher-education computer science contexts. We identify five application domains: intelligent tutoring, personalized materials, formative feedback, AI-augmented assessment, and code review, and analyze how design choices shape learning outcomes. Designs incorporating explanation-first guidance, solution withholding, graduated hint ladders, and artifact grounding (student code, tests, and rubrics) consistently show more positive learning processes than unconstrained chat interfaces. Successful implementations share four patterns: context-aware tutoring anchored in student artifacts, multi-level hint structures requiring reflection, composition with traditional CS infrastructure (autograders and rubrics), and human-in-the-loop quality assurance. We propose an exploration-first adoption framework emphasizing piloting, instrumentation, learning-preserving defaults, and evidence-based scaling. Recurrent risks include academic integrity, privacy, bias and equity, and over-reliance, and we pair these with operational mitigation. The evidence supports generative AI as a mechanism for precision scaffolding when embedded in audit-ready workflows that preserve productive struggle while scaling personalized support.",
      "author": "Iman Reihanian, Yunfei Hou, Qingquan Sun",
      "published_date": "2025-12-25T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 184,
      "reading_time": 1,
      "created_at": "2025-12-25T05:27:42.085750+00:00",
      "updated_at": "2025-12-25T06:25:52.082905+00:00",
      "metadata": {
        "processed_at": "2025-12-25T06:25:52.082906+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "b40b75b4bd9fd29932eb436a9f0b29ff",
      "url": "https://arxiv.org/abs/2512.20679",
      "title": "Signal, Noise, and Burnout: A Human-Information Interaction Analysis of Voter Verification in a High-Volatility Environment",
      "content": "arXiv:2512.20679v1 Announce Type: cross \nAbstract: The 2024 U.S. Presidential Election unfolded within an information environment of unprecedented volatility, challenging citizens to navigate a torrent of rapidly evolving, often contradictory information while determining what to believe. This study investigates the cognitive mechanisms underlying epistemic self-efficacy - the perceived ability to distinguish accurate news from misinformation - across different information channels during this high-stakes election cycle. Drawing on data from the Pew Research Center's American Trends Panel (Wave 155, September 2024, N = 9,360), we test three hypotheses: (H1) whether reliance on social media predicts lower epistemic self-efficacy compared to mainstream news sources; (H2) whether perceived exposure to inaccurate information mediates this relationship; and (H3) whether information fatigue moderates the cognitive burden of verification across platforms. Contrary to expectations rooted in algorithmic filtering theory, we find no significant differences in reported difficulty determining truth between social media and mainstream news users. Instead, epistemic burden is driven by demographics (age, education) and universal information fatigue, suggesting a \"leveling\" of the information landscape during periods of extreme volatility. This finding challenges platform-deterministic theories and suggests that interventions to support informed citizenship must address cognitive resilience and attention management rather than platform choice alone.",
      "author": "Kijung Lee",
      "published_date": "2025-12-25T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 199,
      "reading_time": 1,
      "created_at": "2025-12-25T05:27:42.085719+00:00",
      "updated_at": "2025-12-25T06:25:52.082908+00:00",
      "metadata": {
        "processed_at": "2025-12-25T06:25:52.082910+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "1e3e8792f67d6c6d08a80494a557bbb3",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.22.696017v1?rss=1",
      "title": "Corticolimbic structure-function coupling is sensitive to childhood adversity and buffers adversity-related symptoms during development",
      "content": "Childhood adversity is a potent predictor of mental health problems across the lifespan, and a rich cross-species literature implicates stress-sensitive corticolimbic circuits in adversity-related psychopathology. Structure-function coupling (SFC) is a promising multimodal marker that is sensitive to developmental plasticity. While emerging evidence suggests cortical SFC is sensitive to adversity exposure during early childhood, it is unknown how SFC in stress-sensitive corticolimbic circuits links adversity exposure with mental health across development. We examined associations between adversity exposure, transdiagnostic symptomatology, and both amygdala-cortical and hippocampal-cortical SFC across development in a large sample of youth (N = 607, 39% F). Results revealed that adversity exposure moderated age-related change in amygdala-vmPFC SFC (p = .007), such that youth exposed to higher, but not lower, levels of adversity showed an age-related increase in amygdala-vmPFC SFC. Further, amygdala-vmPFC SFC buffered the effect of adversity on internalizing symptoms (p = .012), such that those youth with higher adversity exposure who had stronger amygdala-vmPFC SFC also displayed lower internalizing symptoms. Separately, higher adversity exposure was associated with lower hippocampal-limbic network SFC (p = .037), which moderated the effect of adversity on internalizing symptoms (p = .010). These findings highlight that structural and functional neurodevelopment of amygdala-vmPFC and hippocampal-limbic network connections may adapt in distinct ways to support mental health following adversity, with implications for risk and resilience against internalizing psychopathology.",
      "author": "Sisk, L. M., Keding, T. J., Drew, A., Ma, E., Shafiei, G., Cieslak, M., Satterthwaite, T. D., Gee, D. G.",
      "published_date": "2025-12-24T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 222,
      "reading_time": 1,
      "created_at": "2025-12-25T04:22:53.248437+00:00",
      "updated_at": "2025-12-25T04:34:25.838313+00:00",
      "metadata": {
        "processed_at": "2025-12-25T04:34:25.838322+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "425831c23a69a11d14d20e428064f46f",
      "url": "https://www.nature.com/articles/s41598-025-31775-8",
      "title": "Transcriptional responses in feeder time-trained foragers suggest diverse interactions between the circadian clock and mushroom bodies in honey bees",
      "content": "",
      "author": "",
      "published_date": "2025-12-25T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-12-25T04:22:51.961733+00:00",
      "updated_at": "2025-12-25T04:34:25.838326+00:00",
      "metadata": {
        "processed_at": "2025-12-25T04:34:25.838328+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "4b6fd878bd5c023fad2ac10d76396849",
      "url": "https://www.nature.com/articles/s41467-025-67731-3",
      "title": "mGluR4\u2013NPDC1 complex mediates \u03b1-synuclein fibril-induced neurodegeneration",
      "content": "",
      "author": "",
      "published_date": "2025-12-25T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-12-25T04:22:51.961708+00:00",
      "updated_at": "2025-12-25T04:34:25.838333+00:00",
      "metadata": {
        "processed_at": "2025-12-25T04:34:25.838335+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "3ca494c83d4c7c886bdcfc3ecdb9ce89",
      "url": "https://labs.acme.byu.edu/Pages/intro.html",
      "title": "Python Applied Mathematics Labs",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46381839\">Comments</a>",
      "author": "",
      "published_date": "2025-12-25T03:33:52+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-25T04:22:15.867401+00:00",
      "updated_at": "2025-12-25T04:34:25.838337+00:00",
      "metadata": {
        "processed_at": "2025-12-25T04:34:25.838339+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "3ca494c83d4c7c886bdcfc3ecdb9ce89",
      "url": "https://labs.acme.byu.edu/Pages/intro.html",
      "title": "Python Applied Mathematics Labs",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46381839\">Comments</a>",
      "author": "",
      "published_date": "2025-12-25T03:33:52+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-25T04:22:15.867401+00:00",
      "updated_at": "2025-12-25T04:34:25.838337+00:00",
      "metadata": {
        "processed_at": "2025-12-25T04:34:25.838339+00:00",
        "processing_method": "github_actions"
      }
    }
  ]
}