{
  "last_updated": "2026-01-01T06:26:25.038529+00:00",
  "pending_count": 650,
  "processed_count": 350,
  "pending_articles": [
    {
      "id": "1059422b10b19d220dd7ef5be6e7aeaf",
      "url": "https://arxiv.org/abs/2512.23835",
      "title": "Explaining News Bias Detection: A Comparative SHAP Analysis of Transformer Model Decision Mechanisms",
      "content": "arXiv:2512.23835v1 Announce Type: cross \nAbstract: Automated bias detection in news text is heavily used to support journalistic analysis and media accountability, yet little is known about how bias detection models arrive at their decisions or why they fail. In this work, we present a comparative interpretability study of two transformer-based bias detection models: a bias detector fine-tuned on the BABE dataset and a domain-adapted pre-trained RoBERTa model fine-tuned on the BABE dataset, using SHAP-based explanations. We analyze word-level attributions across correct and incorrect predictions to characterize how different model architectures operationalize linguistic bias. Our results show that although both models attend to similar categories of evaluative language, they differ substantially in how these signals are integrated into predictions. The bias detector model assigns stronger internal evidence to false positives than to true positives, indicating a misalignment between attribution strength and prediction correctness and contributing to systematic over-flagging of neutral journalistic content. In contrast, the domain-adaptive model exhibits attribution patterns that better align with prediction outcomes and produces 63\\% fewer false positives. We further demonstrate that model errors arise from distinct linguistic mechanisms, with false positives driven by discourse-level ambiguity rather than explicit bias cues. These findings highlight the importance of interpretability-aware evaluation for bias detection systems and suggest that architectural and training choices critically affect both model reliability and deployment suitability in journalistic contexts.",
      "author": "Himel Ghosh",
      "published_date": "2026-01-01T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 224,
      "reading_time": 1,
      "created_at": "2026-01-01T05:29:03.168447+00:00",
      "updated_at": "2026-01-01T05:29:03.168448+00:00"
    },
    {
      "id": "336cfb879953db0585cb2cdac2ac492a",
      "url": "https://arxiv.org/abs/2512.24939",
      "title": "Vibe Coding, Interface Flattening",
      "content": "arXiv:2512.24939v1 Announce Type: new \nAbstract: Large language models are reshaping programming by enabling 'vibe coding': the development of softwares through natural-language interaction with model-driven toolchains. This article argues that vibe coding is best understood as interface flattening, a reconfiguration in which previously distinct modalities (GUI, CLI, and API) appear to converge into a single conversational surface, even as the underlying chain of translation from intention to machinic effect lengthens and thickens. Drawing on Friedrich Kittler's materialist media theory and Alexander Galloway's account of interfaces as sites of protocol control, the paper situates programming as a historically localised interface arrangement rather than an essential relation to computation. Through a materialist reconstruction of the contemporary vibe-coding stack, it shows how remote compute infrastructures, latency and connectivity, structured outputs, function/tool calling, and interoperability standards such as the Model Context Protocol relocate control and meaning-making power to model and protocol providers. The apparent democratisation of technical capability therefore depends on new dependencies and new literacies. By foregrounding the tension between experiential flattening and infrastructural thickening, I demonstrate how LLM-mediated development redistributes symbolic labour/power, obscures responsibility, and privatises competencies previously dispersed across programming communities, contributing a critical lens on the political economy of AI-mediated human-computer interaction.",
      "author": "Hongrui Jin",
      "published_date": "2026-01-01T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 201,
      "reading_time": 1,
      "created_at": "2026-01-01T05:29:03.168413+00:00",
      "updated_at": "2026-01-01T05:29:03.168414+00:00"
    },
    {
      "id": "162ec865c159dd497c9148019ca2c91f",
      "url": "https://arxiv.org/abs/2512.24632",
      "title": "ReflecToMeet: An AI-Assisted Reflection Based System to Enhance Collaborative Preparedness",
      "content": "arXiv:2512.24632v1 Announce Type: new \nAbstract: In collaborative settings, difficulties in sustaining a consistent pace and engagement often lead to task drift, reducing preparedness and overall effectiveness between meetings. To address this challenge, we conducted a formative study and developed ReflecToMeet, an AI assisted system that integrates theory driven reflective prompts with mechanisms for sharing teammates reflections. Informed by ten formative interviews, the system was evaluated in a mixed method study across three conditions: deeper reflection, regular reflection, and a control condition with unstructured reflection. Participants in the control condition demonstrated less deliberate thought and weaker collaboration, which led to stress and misalignment during team meetings. In contrast, structured reflection supported greater organization and steadier progress. The deeper reflection condition further facilitated confidence, teamwork, and idea generation, although it imposed a higher cognitive load. We conclude by discussing design implications for AI agents that facilitate reflection to enhance collaboration and broader considerations for AI assisted systems aimed at sustaining collaborative goals.",
      "author": "Md Nazmus Sakib, Naga Manogna Rayasam, Ishika Tarin, Sanorita Dey",
      "published_date": "2026-01-01T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 160,
      "reading_time": 1,
      "created_at": "2026-01-01T05:29:03.168379+00:00",
      "updated_at": "2026-01-01T05:29:03.168381+00:00"
    },
    {
      "id": "7074273a4d377d3727624b76ccd3bf7c",
      "url": "https://arxiv.org/abs/2512.24237",
      "title": "A Framing and Analysis of Applicative Tangible Interfaces",
      "content": "arXiv:2512.24237v1 Announce Type: new \nAbstract: The investigation of tangible user interfaces commenced approximately thirty years ago. Questions on its commercial potential become more pressing as the field becomes mature. To take the field one step further -- as the emergence of components contributed to the commercial development of graphical user interfaces -- this article suggests that applicative tangible user interfaces could also be split into components. These components are composed of the aggregation, combination, or coupling of physical items and fulfil four roles that are described through a new interaction model. This article successfully distributed among these four components' roles all of the 159 physical items from a representative collection of 35 applications. Further examination of these applicative tangible interfaces coincides with four research phases in the field and identifies three main paths for future research to fully realize the potential of tangible user interfaces.",
      "author": "Guillaume Riviere",
      "published_date": "2026-01-01T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 145,
      "reading_time": 1,
      "created_at": "2026-01-01T05:29:03.168349+00:00",
      "updated_at": "2026-01-01T05:29:03.168351+00:00"
    },
    {
      "id": "527e7419a92247fbbbaf15cd3b784332",
      "url": "https://arxiv.org/abs/2512.24166",
      "title": "External Human-Machine Interface based on Intent Recognition: Framework Design and Experimental Validation",
      "content": "arXiv:2512.24166v1 Announce Type: new \nAbstract: Increasing autonomous vehicles (AVs) in transportation systems makes effective interactions between AVs and pedestrians indispensable. External human--machine interface (eHMI), which employs visual or auditory cues to explicitly convey vehicle behaviors can compensate for the loss of human-like interactions and enhance AV--pedestrian cooperation. To facilitate faster intent convergence between pedestrian and AVs, this study incorporates an adaptive interaction mechanism into eHMI based on pedestrian intent recognition, namely IR-eHMI. IR-eHMI dynamically detects and infers the behavioral intentions of both pedestrians and AVs through identifying their cooperation states. The proposed interaction framework is implemented and evaluated on a virtual reality (VR) experimental platform to demonstrate its effectiveness through statistical analysis. Experimental results show that IR-eHMI significantly improves crossing efficiency, reduces gaze distraction while maintaining interaction safety compared to traditional fixed-distance eHMI. This adaptive and explicit interaction mode introduces an innovative procedural paradigm for AV--pedestrian cooperation.",
      "author": "Boya Sun, Haotian Shi, Ying Ni, Shaocheng Jia, Haoyang Liang",
      "published_date": "2026-01-01T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 147,
      "reading_time": 1,
      "created_at": "2026-01-01T05:29:03.168321+00:00",
      "updated_at": "2026-01-01T05:29:03.168323+00:00"
    },
    {
      "id": "359e0ac60885fa52c94a901d4afd5d85",
      "url": "https://arxiv.org/abs/2512.23907",
      "title": "Deletion Considered Harmful",
      "content": "arXiv:2512.23907v1 Announce Type: new \nAbstract: In a world of information overload, understanding how we can most effectively manage information is crucial to success. We set out to understand how people view deletion, the removal of material no longer needed: does it help by reducing clutter and improving the signal to noise ratio, or does the effort required to decide to delete something make it not worthwhile? How does deletion relate to other strategies like filing; do people who spend extensive time in filing also prune their materials too? We studied the behaviour of 51 knowledge workers though a series of questionnaires and interviews to evaluate a range of tactics they used aimed at organizing, filing, and retrieving digital resources. Our study reveals that deletion is consistently under-adopted compared to other tactics such as Filing, Coverage, Ontology, and Timeliness. Moreover, the empirical data indicate that deletion is actually detrimental to retrieval success and satisfaction. In this paper, we examine the practice of deletion, review the related literature, and present detailed statistical results and clustering outcomes that underscore its adverse effects.",
      "author": "Paul Englefield, Russell Beale",
      "published_date": "2026-01-01T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 179,
      "reading_time": 1,
      "created_at": "2026-01-01T05:29:03.168291+00:00",
      "updated_at": "2026-01-01T05:29:03.168293+00:00"
    },
    {
      "id": "17c9c2e2f6144772dafbb9f587cf12d9",
      "url": "https://arxiv.org/abs/2512.23859",
      "title": "Seeking Late Night Life Lines: Experiences of Conversational AI Use in Mental Health Crisis",
      "content": "arXiv:2512.23859v1 Announce Type: new \nAbstract: Online, people often recount their experiences turning to conversational AI agents (e.g., ChatGPT, Claude, Copilot) for mental health support -- going so far as to replace their therapists. These anecdotes suggest that AI agents have great potential to offer accessible mental health support. However, it's unclear how to meet this potential in extreme mental health crisis use cases. In this work, we explore the first-person experience of turning to a conversational AI agent in a mental health crisis. From a testimonial survey (n = 53) of lived experiences, we find that people use AI agents to fill the in-between spaces of human support; they turn to AI due to lack of access to mental health professionals or fears of burdening others. At the same time, our interviews with mental health experts (n = 16) suggest that human-human connection is an essential positive action when managing a mental health crisis. Using the stages of change model, our results suggest that a responsible AI crisis intervention is one that increases the user's preparedness to take a positive action while de-escalating any intended negative action. We discuss the implications of designing conversational AI agents as bridges towards human-human connection rather than ends in themselves.",
      "author": "Leah Hope Ajmani, Arka Ghosh, Benjamin Kaveladze, Eugenia Kim, Keertana Namuduri, Theresa Nguyen, Ebele Okoli, Jessica Schleider, Denae Ford, Jina Suh",
      "published_date": "2026-01-01T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 206,
      "reading_time": 1,
      "created_at": "2026-01-01T05:29:03.168254+00:00",
      "updated_at": "2026-01-01T05:29:03.168258+00:00"
    },
    {
      "id": "03391a470f5c1b0fbbbad4865b77d8b7",
      "url": "https://arxiv.org/abs/2509.05041",
      "title": "Dynamical Learning in Deep Asymmetric Recurrent Neural Networks",
      "content": "arXiv:2509.05041v2 Announce Type: replace-cross \nAbstract: We investigate recurrent neural networks with asymmetric interactions and demonstrate that the inclusion of self-couplings or sparse excitatory inter-module connections leads to the emergence of a densely connected manifold of dynamically accessible stable configurations. This representation manifold is exponentially large in system size and is reachable through simple local dynamics, despite constituting a subdominant subset of the global configuration space. We further show that learning can be implemented directly on this structure via a fully local, gradient-free mechanism that selectively stabilizes a single task-relevant network configuration. Unlike error-driven or contrastive learning schemes, this approach does not require explicit comparisons between network states obtained with and without output supervision. Instead, transient supervisory signals bias the dynamics toward the representation manifold, after which local plasticity consolidates the attained configuration, effectively shaping the latent representation space. Numerical evaluations on standard image classification benchmarks indicate performance comparable to that of multilayer perceptrons trained using backpropagation. More generally, these results suggest that the dynamical accessibility of fixed points and the stabilization of internal network dynamics constitute viable alternative principles for learning in recurrent systems, with conceptual links to statistical physics and potential implications for biologically motivated and neuromorphic computing architectures.",
      "author": "Davide Badalotti, Carlo Baldassi, Marc M\\'ezard, Mattia Scardecchia, Riccardo Zecchina",
      "published_date": "2026-01-01T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 200,
      "reading_time": 1,
      "created_at": "2026-01-01T05:29:02.065050+00:00",
      "updated_at": "2026-01-01T05:29:02.065052+00:00"
    },
    {
      "id": "27cb4b3993cbfaea8521647d41020180",
      "url": "https://arxiv.org/abs/2508.08435",
      "title": "Fast weight programming and linear transformers: from machine learning to neurobiology",
      "content": "arXiv:2508.08435v3 Announce Type: replace-cross \nAbstract: Recent advances in artificial neural networks for machine learning, and language modeling in particular, have established a family of recurrent neural network (RNN) architectures that, unlike conventional RNNs with vector-form hidden states, use two-dimensional (2D) matrix-form hidden states. Such 2D-state RNNs, known as Fast Weight Programmers (FWPs), can be interpreted as a neural network whose synaptic weights (called fast weights) dynamically change over time as a function of input observations, and serve as short-term memory storage; corresponding synaptic weight modifications are controlled or programmed by another network (the programmer) whose parameters are trained (e.g., by gradient descent). In this Primer, we review the technical foundations of FWPs, their computational characteristics, and their connections to transformers and state space models. We also discuss connections between FWPs and models of synaptic plasticity in the brain, suggesting a convergence of natural and artificial intelligence.",
      "author": "Kazuki Irie, Samuel J. Gershman",
      "published_date": "2026-01-01T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 146,
      "reading_time": 1,
      "created_at": "2026-01-01T05:29:02.065018+00:00",
      "updated_at": "2026-01-01T05:29:02.065019+00:00"
    },
    {
      "id": "127baab7ee7165f6a2cd675ddbca7917",
      "url": "https://arxiv.org/abs/2404.12895",
      "title": "From self-organizing systems to subjective temporal extension",
      "content": "arXiv:2404.12895v5 Announce Type: replace \nAbstract: The self-simulational theory of temporal extension describes an information-theoretically formalized mechanism by which the width of subjective temporality emerges from the architecture of self-modelling. In this paper, the perspective of the free energy principle will be assumed to cast the emergence of subjective temporal extension from first principles of the physics of self-organization and to formalize subjective temporal extension using information geometry. Using active inference, a deep parametric generative model of temporal inference is simulated, which realizes the described dynamics on a computational level. Two variations of time-perception naturally emerge from the simulated computational model. This concerns the intentional binding effect (i.e., the compression of the temporal interval between voluntarily initiated actions and subsequent sensory consequences) and empirically documented alterations of subjective time experience in deep states of meditative absorption (i.e., in minimal phenomenal experience). Generally, numerous systematic and domain-specific alterations of subjective temporal experience are computationally explained in a unified manner, as enabled by integration with current active inference accounts mapping onto the respective domains. This concerns, next to attentional and central tendency effects, the temporality-modulating role of valence, impulsivity, boredom, flow-states, near death-experiences, and various psychopathologies, amongst others. The self-simulational theory of temporal extension, from the perspective of the free energy principle, explains how the width of the subjective temporal moment emerges and varies from first principles, accounting for why sometimes, subjective time seems to fly, and sometimes, moments feel like eternities; with the computational mechanism being readily deployable synthetically.",
      "author": "Jan Erik Bellingrath",
      "published_date": "2026-01-01T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 247,
      "reading_time": 1,
      "created_at": "2026-01-01T05:29:02.064988+00:00",
      "updated_at": "2026-01-01T05:29:02.064990+00:00"
    }
  ],
  "recently_processed": [
    {
      "id": "86240da3eaca0f7ab44548529db5e4cd",
      "url": "https://www.frontiersin.org/articles/10.3389/fnbot.2025.1628368",
      "title": "A simple robot suggests trunk rotation is essential for emergence of inside leading limb during quadruped galloping turns",
      "content": "During turning maneuvers in the galloping gait of quadruped animals, a strong relationship exists between the turning direction and the sequence in which the forelimbs make ground contact: the outer forelimb acts as the \u201ctrailing limb\u201d while the inner forelimb serves as the \u201cleading limb.\u201d However, the control mechanisms underlying this behavior remain largely unclear. Understanding these mechanisms could deepen biological knowledge and assist in developing more agile robots. To address this issue, we hypothesized that decentralized interlimb coordination mechanism and trunk movement are essential for the emergence of an inside leading limb in a galloping turn. To test the hypothesis, we developed a quasi-quadruped robot with simplified wheeled hind limbs and variable trunk roll and yaw angles. For forelimb coordination, we implemented a simple decentralized control based on local load-dependent sensory feedback, utilizing trunk roll inclination and yaw bending as turning methods. Our experimental results confirmed that in addition to the decentralized control from previous studies which reproduces animal locomotion in a straight line, adjusting the trunk roll angle spontaneously generates a ground contact sequence similar to gallop turning in quadruped animals. Furthermore, roll inclination showed a greater influence than yaw bending on differentiating the leading and trailing limbs. This study suggests that physical interactions serve as a universal mechanism of locomotor control in both forward and turning movements of quadrupedal animals.",
      "author": "Akio Ishiguro",
      "published_date": "2025-10-23T00:00:00+00:00",
      "source": "Frontiers Neurorobotics",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 223,
      "reading_time": 1,
      "created_at": "2026-01-01T05:52:18.110257+00:00",
      "updated_at": "2026-01-01T06:26:24.930634+00:00",
      "metadata": {
        "processed_at": "2026-01-01T06:26:24.930643+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "7d358a50de2869f89d49bd22afee1514",
      "url": "https://www.frontiersin.org/articles/10.3389/fnbot.2025.1705970",
      "title": "Effective and efficient self-supervised masked model based on mixed feature training",
      "content": "Under the influence of Masked Language Modeling (MLM), Masked Image Modeling (MIM) employs an attention mechanism to perform masked training on images. However, processing a single image requires numerous iterations and substantial computational resources to reconstruct the masked regions, resulting in high computational complexity and significant time costs. To address this issue, we propose an Effective and Efficient self-supervised Masked model based on Mixed feature training (EESMM). First, we stack two images for encoding and input the fused features into the network, which not only reduces computational complexity but also enables the learning of more features. Second, during decoding, we obtain the decoding features corresponding to the original images based on the decoding features of the two input original images and the mixed images, and then construct a corresponding loss function to enhance feature representation. EESMM significantly reduces pre-training time without sacrificing accuracy, achieving 83% accuracy on ImageNet in just 363 h using four V100 GPUs\u2013only one-tenth of the training time required by SimMIM. This validates that the method can substantially accelerate the pre-training process without noticeable performance degradation.",
      "author": "Chunliu Cai",
      "published_date": "2025-10-30T00:00:00+00:00",
      "source": "Frontiers Neurorobotics",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 179,
      "reading_time": 1,
      "created_at": "2026-01-01T05:52:18.110218+00:00",
      "updated_at": "2026-01-01T06:26:24.930647+00:00",
      "metadata": {
        "processed_at": "2026-01-01T06:26:24.930649+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "886e0430756947999bc2ccba29b8466c",
      "url": "https://arxiv.org/abs/2512.24415",
      "title": "Language Model Agents Under Attack: A Cross Model-Benchmark of Profit-Seeking Behaviors in Customer Service",
      "content": "arXiv:2512.24415v1 Announce Type: cross \nAbstract: Customer-service LLM agents increasingly make policy-bound decisions (refunds, rebooking, billing disputes), but the same ``helpful'' interaction style can be exploited: a small fraction of users can induce unauthorized concessions, shifting costs to others and eroding trust in agentic workflows. We present a cross-domain benchmark of profit-seeking direct prompt injection in customer-service interactions, spanning 10 service domains and 100 realistic attack scripts grouped into five technique families. Across five widely used models under a unified rubric with uncertainty reporting, attacks are highly domain-dependent (airline support is most exploitable) and technique-dependent (payload splitting is most consistently effective). We release data and evaluation code to support reproducible auditing and to inform the design of oversight and recovery workflows for trustworthy, human centered agent interfaces.",
      "author": "Jingyu Zhang",
      "published_date": "2026-01-01T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 126,
      "reading_time": 1,
      "created_at": "2026-01-01T05:29:03.168535+00:00",
      "updated_at": "2026-01-01T06:26:24.930652+00:00",
      "metadata": {
        "processed_at": "2026-01-01T06:26:24.930654+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "1bd34c06df7a6614b9368bc2bcf507a1",
      "url": "https://arxiv.org/abs/2512.24029",
      "title": "Evaluation of Impression Difference of a Domestic Mobile Manipulator with Autonomous and/or Remote Control in Fetch-and-Carry Tasks",
      "content": "arXiv:2512.24029v1 Announce Type: cross \nAbstract: A single service robot can present two distinct agencies: its onboard autonomy and an operator-mediated agency, yet users experience them through one physical body. We formalize this dual-agency structure as a User-Robot-Operator triad in an autonomous remote-control setting that combines autonomous execution with remote human support. Prior to the recent surge of language-based and multimodal interfaces, we developed and evaluated an early-stage prototype in 2020 that combined natural-language text chat with freehand sketch annotations over the robot's live camera view to support remote intervention. We evaluated three modes - autonomous, remote, and hybrid - in controlled fetch-and-carry tasks using a domestic mobile manipulator (HSR) on a World Robot Summit 2020 rule-compliant test field. The results show systematic mode-dependent differences in user-rated affinity and additional insights on perceived security, indicating that switching or blending agency within one robot measurably shapes human impressions. These findings provide empirical guidance for designing human-in-the-loop mobile manipulation in domestic physical tasks.",
      "author": "Takashi Yamamoto, Hiroaki Yaguchi, Shohei Kato, Hiroyuki Okada",
      "published_date": "2026-01-01T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 160,
      "reading_time": 1,
      "created_at": "2026-01-01T05:29:03.168508+00:00",
      "updated_at": "2026-01-01T06:26:24.930656+00:00",
      "metadata": {
        "processed_at": "2026-01-01T06:26:24.930657+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "3b2813d27a4bd8476db2ed6b46094d6f",
      "url": "https://arxiv.org/abs/2512.23844",
      "title": "From Correctness to Collaboration: Toward a Human-Centered Framework for Evaluating AI Agent Behavior in Software Engineering",
      "content": "arXiv:2512.23844v1 Announce Type: cross \nAbstract: As Large Language Models (LLMs) evolve from code generators into collaborative partners for software engineers, our methods for evaluation are lagging. Current benchmarks, focused on code correctness, fail to capture the nuanced, interactive behaviors essential for successful human-AI partnership. To bridge this evaluation gap, this paper makes two core contributions. First, we present a foundational taxonomy of desirable agent behaviors for enterprise software engineering, derived from an analysis of 91 sets of user-defined agent rules. This taxonomy defines four key expectations of agent behavior: Adhere to Standards and Processes, Ensure Code Quality and Reliability, Solving Problems Effectively, and Collaborating with the User.\n  Second, recognizing that these expectations are not static, we introduce the Context-Adaptive Behavior (CAB) Framework. This emerging framework reveals how behavioral expectations shift along two empirically-derived axes: the Time Horizon (from immediate needs to future ideals), established through interviews with 15 expert engineers, and the Type of Work (from enterprise production to rapid prototyping, for example), identified through a prompt analysis of a prototyping agent. Together, these contributions offer a human-centered foundation for designing and evaluating the next generation of AI agents, moving the field's focus from the correctness of generated code toward the dynamics of true collaborative intelligence.",
      "author": "Tao Dong, Harini Sampath, Ja Young Lee, Sherry Y. Shi, Andrew Macvean",
      "published_date": "2026-01-01T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 206,
      "reading_time": 1,
      "created_at": "2026-01-01T05:29:03.168479+00:00",
      "updated_at": "2026-01-01T06:26:24.930659+00:00",
      "metadata": {
        "processed_at": "2026-01-01T06:26:24.930661+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "b3cd4fc4257e4deef4e24f2c3cdd8b67",
      "url": "https://brain.ieee.org/publications/neuroethics-framework/education/education-social-and-cultural-issues/education-social-and-cultural-issues/",
      "title": "Education: Social and Cultural Issues",
      "content": "Devices that therapeutically aid users with cognitive and learning disabilities/differences should not be equally applied to a general population seeking learning advantages. It must not be assumed that therapies able to improve cognition for mental and cognitive disorders (such as executive control and working memory) would work similarly on nondisabled people linearly to improve their cognition above standard levels. Although ...",
      "author": "Adriel Carridice",
      "published_date": "2025-02-05T15:45:23+00:00",
      "source": "Brain",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 61,
      "reading_time": 1,
      "created_at": "2026-01-01T03:55:26.864122+00:00",
      "updated_at": "2026-01-01T04:43:31.108920+00:00",
      "metadata": {
        "processed_at": "2026-01-01T04:43:31.108929+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "1348eff8059203eea8f1cf0c47dfeafd",
      "url": "https://brain.ieee.org/podcasts/qa-with-dr-richard-carson-professor-of-biomedical-engineering-and-radiology-biomedical-imaging-yale-university-and-yale-school-of-medicine/",
      "title": "Q&A with Dr. Richard Carson, Professor of Biomedical Engineering and Radiology & Biomedical Imaging, Yale University and Yale School of Medicine",
      "content": "",
      "author": "Adriel Carridice",
      "published_date": "2025-11-04T18:24:59+00:00",
      "source": "Brain",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2026-01-01T03:55:26.863931+00:00",
      "updated_at": "2026-01-01T04:43:31.108933+00:00",
      "metadata": {
        "processed_at": "2026-01-01T04:43:31.108935+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "bad5757f306a00dd069fd23d649636a6",
      "url": "http://ieeexplore.ieee.org/document/10856219",
      "title": "IEEE Reviews in Biomedical Engineering (R-BME)",
      "content": "null",
      "author": "",
      "published_date": "2025-01-28T13:17:19+00:00",
      "source": "Reviews Biomedical Engineering",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 1,
      "reading_time": 1,
      "created_at": "2026-01-01T03:55:21.689590+00:00",
      "updated_at": "2026-01-01T04:43:31.108937+00:00",
      "metadata": {
        "processed_at": "2026-01-01T04:43:31.108939+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "01a0c9001a6aac267cb0072bda62db43",
      "url": "http://doi.org/10.1037/pmu0000303",
      "title": "Implicit learning of melodic structure: A role for pitch?",
      "content": "Growing evidence suggests that pitch influences musical processing, with melodic processing being enhanced in higher pitch ranges (e.g., Fujioka et al., 2005) and rhythmic processing being enhanced in lower pitches, and these effects may have a basis in elementary properties of the auditory system (e.g., Hove et al., 2014). As such, pitch may constitute a fundamental constraint on the mechanisms that underpin musical learning. One such mechanism is implicit learning: the ability to learn from mere exposure without intention and without a clear awareness of what has been learned. The present study examined whether the high pitch effects that enhance melodic processing extend to implicit learning of melodic structure as well. In an artificial melodic grammar experiment, it was found that participants learned melodic structure better when instantiated in a lower rather than a higher pitch range. We propose that hearing melodies in lower pitch ranges attracts more attention, because melodic information is usually instantiated in higher pitches, and lower pitch melodies may cause attention to shift leading to more learning. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2024-01-22T00:00:00+00:00",
      "source": "Psychomusicology",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 180,
      "reading_time": 1,
      "created_at": "2026-01-01T03:54:36.284468+00:00",
      "updated_at": "2026-01-01T04:43:31.108941+00:00",
      "metadata": {
        "processed_at": "2026-01-01T04:43:31.108943+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "f5d48b717c919893f96492998ce36e60",
      "url": "http://doi.org/10.1037/cns0000368",
      "title": "Autonomous sensory meridian response (ASMR): A PRISMA-guided systematic review.",
      "content": "The present PRISMA-guided article systematically reviews the current state of research on the autonomous sensory meridian response (ASMR). A systematic literature search was conducted in Pubmed, SCOPUS, and Web of Science (last search: March 2022) selecting all studies that conducted quantitative scientific research on the ASMR phenomenon. Fifty-four studies focusing on ASMR were retrieved (total participant number: <em>n</em> = 11,140). ASMR can be linked to several mental health-related variables (e.g., improved mood) and personality traits (e.g., neuroticism). On the neurobiological level, ASMR has been associated with altered electrophysiological response patterns (tentatively suggesting \u03b4 wave decreases), activation of specific brain areas (particularly the anterior cingulate gyrus and movement-related regions), and atypical functional connectivity patterns as well as physiological changes such as heart rate reduction. Future studies should evaluate the link between ASMR and additional psychological constructs, reveal more specific neurobiological outcome patterns and conduct long-term ASMR intervention studies. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2023-11-02T00:00:00+00:00",
      "source": "Clinical Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 156,
      "reading_time": 1,
      "created_at": "2026-01-01T03:54:34.626793+00:00",
      "updated_at": "2026-01-01T04:43:31.108945+00:00",
      "metadata": {
        "processed_at": "2026-01-01T04:43:31.108947+00:00",
        "processing_method": "github_actions"
      }
    }
  ]
}