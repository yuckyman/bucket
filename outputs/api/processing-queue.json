{
  "last_updated": "2025-10-06T10:16:07.047154+00:00",
  "pending_count": 985,
  "processed_count": 15,
  "pending_articles": [
    {
      "id": "c307ab5dab9f6c7578186615c5aa70b9",
      "url": "http://ieeexplore.ieee.org/document/11153359",
      "title": "Impact of Transcutaneous Vagus Nerve Stimulation on Event-related Potentials during a Response Inhibition Task",
      "content": "As an emerging neuromodulation technique, transcutaneous auricular vagus nerve stimulation (taVNS) has shown promise in enhancing cognitive abilities. The present study used a combination of the go/no-go task and the stop-signal task experimental paradigm to examine the cognitive effects of taVNS on participants' EEG measures. Sixty-one healthy participants were randomly assigned to either the stimulation group or the sham group. Participants in the stimulation group received 100 Hz and 25 Hz stimulation in a counterbalanced order. We compared behavioral and EEG data before and after stimulation, and observed significant effects. The findings revealed that a 100-Hz taVNS significantly reduced participants' N2 latency in the stop trial, indicating potential improvement response inhibition. In addition, we noted a decreasing trend in alpha, theta, and delta band power during response inhibition after receiving a 100-Hz taVNS. These results suggest that a 100-Hz taVNS can enhance participants' response inhibition abilities, indicating its potential as a therapeutic approach for modulating cognitive functions.",
      "author": "",
      "published_date": "2025-09-08T13:16:40+00:00",
      "source": "Cognitive Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 157,
      "reading_time": 1,
      "created_at": "2025-10-06T09:42:53.492060+00:00",
      "updated_at": "2025-10-06T09:42:53.492062+00:00"
    },
    {
      "id": "4b601b9c934f95d9db5ecc44c2eee1e3",
      "url": "http://ieeexplore.ieee.org/document/11153356",
      "title": "Confidence and Insight into Working Memory Are Shaped by Attention and Recent Performance",
      "content": "Working memory is capacity-limited, and our ability to access information from working memory is variable, but selective attention to working memory contents can improve performance. People are able to make introspective judgments regarding the quality of their memories, and these judgments are linked to objective memory performance. However, it remains unknown whether benefits of internally directed attention on memory performance occur alongside commensurate changes in introspective judgments. Across two experiments, we used retrospective cues (retrocues) during working-memory maintenance to direct attention to items in memory. We then examined their consequence on introspective judgments. In the second experiment, we provided trial-wise feedback on performance. We found that selective attention improved confidence judgments and not just performance of the probed item. We were also able to judge participants' genuine insight into working-memory contents through the correlation between confidence judgments and memory quality. Neurophysiologically, alpha desynchronization correlated first with memory error and then confidence during retrocueing, suggesting a sequential process of attentional enhancement of memory contents and introspective insight. Furthermore, we showed that participants can use feedback on the accuracy of confidence judgments to update their beliefs across time, according to performance. Our results emphasize flexibility in working memory by showing we can selectively modulate our confidence about its contents based on internally directed attention or objective feedback.",
      "author": "",
      "published_date": "2025-09-08T13:16:44+00:00",
      "source": "Cognitive Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 215,
      "reading_time": 1,
      "created_at": "2025-10-06T09:42:53.492030+00:00",
      "updated_at": "2025-10-06T09:42:53.492031+00:00"
    },
    {
      "id": "a47557cc5e826f075324e7184c294afd",
      "url": "http://ieeexplore.ieee.org/document/11153351",
      "title": "Perceptual Decoupling Underlies Internal Shielding Benefit during Switches between External and Internal Attention: Evidence from Early Sensory Event-related Potential Components",
      "content": "People need to often switch attention between external and internal sources of information, that is, external and internal attention, respectively. There has been a recent surge of research interest in this type of attentional flexibility, which has revealed that it is characterized by an asymmetrical cost, being larger for switching toward internal than external attention. This cost asymmetry has been explained in terms of an internal shielding benefit, that is, the maintenance of stable internal attention against external interference. Although it is currently unclear how internal information might be shielded from external input during switches, a likely candidate is perceptual decoupling. In this study, we instructed participants to repeat external or internal attention, or to switch between them from trial to trial, while simultaneously recording 64-channel EEG. At the behavioral level, we replicated the switch cost asymmetry. Our ERP analysis provided evidence for three different processing stages. First, participants prepared more strongly for an upcoming internal than external attentional selection, as reflected in the increased contingent negative variation component. Second, during internal trials, participants moreover showed a blunted sensory response, most notable in the P1 and N1 components, reflecting perceptual decoupling. Finally, we found an increased P2 component when switching toward internal attention compared with repeating it, indicating more stable perceptual decoupling on internal repetition trials, in line with an internal shielding benefit. We integrate these findings here with behavioral accounts of the cost asymmetry and conclude that perceptual decoupling provides a potential mechanism for the internal shielding benefit of attention.",
      "author": "",
      "published_date": "2025-09-08T13:16:44+00:00",
      "source": "Cognitive Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 251,
      "reading_time": 1,
      "created_at": "2025-10-06T09:42:53.491995+00:00",
      "updated_at": "2025-10-06T09:42:53.491996+00:00"
    },
    {
      "id": "e0899403e0a8c6fb0b591f26e5e5d1b5",
      "url": "http://ieeexplore.ieee.org/document/11153358",
      "title": "Lexical and Information Structure Functions of Prosody and Their Relevance for Spoken Communication: Evidence from Psychometric and Electroencephalographic Data",
      "content": "Prosody not only distinguishes \u201clexical\u201d meaning but also plays a key role in information packaging by highlighting the most relevant constituent of the discourse, namely, \u201cfocus\u201d information. The present study investigated the role of lexical and focus functions of prosody in the coherent interpretation of linguistic input. To this end, we manipulated the correctness of prosodic markers in the context and scrutinized how listeners evaluate these violations\u2014whether they result in lexical or focus anomalies\u2014using psychometric and EEG measures. Psychometric data from 40 participants indicated that prosodic violations were judged as incorrect by the listeners both at the lexical and focus levels, with focus level violations leading to lower correctness scores than lexical level violations, and combined violations receiving the lowest scores. EEG data from 20 participants documented a strong N400 effect (350\u2013550 msec) in response to combined violations, and a late posterior negativity (600\u2013900 msec) present only for combined violations and focus-level violations. Consistent with the psychometric data, the EEG data suggest that prosodic violations at the focus level result in higher costs for comprehension than prosodic violations at the lexical level, whereas combined prosodic violations most significantly disrupt the interpretation. Taken together, these findings suggest that the language comprehension system is sensitive to accurate representations of both lexical and information structure prosody, and benefits from the interaction between them; however, they are weighted differently based on their relevance for a functioning spoken communication.",
      "author": "",
      "published_date": "2025-09-08T13:16:44+00:00",
      "source": "Cognitive Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 234,
      "reading_time": 1,
      "created_at": "2025-10-06T09:42:53.491950+00:00",
      "updated_at": "2025-10-06T09:42:53.491952+00:00"
    },
    {
      "id": "7c4031974efdff1e7f6c52ab82a8e379",
      "url": "http://ieeexplore.ieee.org/document/11153363",
      "title": "Musical Structure Influences the Perception of Sound Location",
      "content": "The perception of multilayered auditory stimuli, such as music or speech, relies on the integration of progressively more complex and abstract features as they are processed along the auditory pathway. To investigate whether higher-level musical structure modulates auditory perception or merely the interpretation of perceived information, we examined the interaction between sound location\u2014a low-level feature\u2014and musical phrases, which are structures spanning across seconds and require temporal integration of information within continuous stimuli. This was to observe whether musical phrase boundaries modulate pre-attentive and explicit sensitivity to the location changes. Participants listened to melodies with randomized location changes and either actively reported detection of change or passively listened while EEG data were collected. Analysis of mismatch negativity responses revealed significantly larger amplitudes for location changes occurring at phrase boundaries, suggesting that musical grouping enhances the perceptual salience of these changes, conveyed by physically identical cues. Behaviorally, participants showed no difference in sensitivity but were more likely to report location changes at phrase boundaries, even when no change occurred. These findings demonstrate that higher-level musical structure modulates pre-attentive auditory processing and influences perception of spatial location. This effect appears to rely on fundamental auditory mechanisms rather than musical expertise, highlighting the dynamic interaction between abstract musical structure and low-level sensory processing.",
      "author": "",
      "published_date": "2025-09-08T13:16:44+00:00",
      "source": "Cognitive Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 209,
      "reading_time": 1,
      "created_at": "2025-10-06T09:42:53.491899+00:00",
      "updated_at": "2025-10-06T09:42:53.491904+00:00"
    },
    {
      "id": "698a3967478d4ba61f5711c9117ea7e6",
      "url": "https://www.embs.org/uncategorized/call-for-applications-ieee-tmrb-editor-in-chief-search/",
      "title": "Call for Applications: IEEE T-MRB Editor in Chief Search",
      "content": "<p>The post <a href=\"https://www.embs.org/uncategorized/call-for-applications-ieee-tmrb-editor-in-chief-search/\">Call for Applications: IEEE T-MRB Editor in Chief Search</a> appeared first on <a href=\"https://www.embs.org\">IEEE EMBS</a>.</p>",
      "author": "Deidre Artis",
      "published_date": "2025-04-03T14:16:16+00:00",
      "source": "Embs",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 18,
      "reading_time": 1,
      "created_at": "2025-10-06T09:42:52.275677+00:00",
      "updated_at": "2025-10-06T09:42:52.275679+00:00"
    },
    {
      "id": "0538cf39a75749ed45e73a2f60084b3a",
      "url": "https://www.embs.org/ojemb/search-for-editor-in-chief/#new_tab",
      "title": "Call for Applications Editor-in-Chief: IEEE Open Journal of Engineering in Medicine and Biology",
      "content": "<p>The post <a href=\"https://www.embs.org/ojemb/search-for-editor-in-chief/#new_tab\">Call for Applications Editor-in-Chief: IEEE Open Journal of Engineering in Medicine and Biology</a> appeared first on <a href=\"https://www.embs.org\">IEEE EMBS</a>.</p>",
      "author": "Deidre Artis",
      "published_date": "2025-04-04T13:34:20+00:00",
      "source": "Embs",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 22,
      "reading_time": 1,
      "created_at": "2025-10-06T09:42:52.275658+00:00",
      "updated_at": "2025-10-06T09:42:52.275659+00:00"
    },
    {
      "id": "f7f416118a32b0e243911d8ef725d75c",
      "url": "https://www.embs.org/blog-post/change-foi-for-ieee-embs/",
      "title": "Notice to IEEE EMBS Members: Change to Field of Interest",
      "content": "<p>The post <a href=\"https://www.embs.org/blog-post/change-foi-for-ieee-embs/\">Notice to IEEE EMBS Members: Change to Field of Interest</a> appeared first on <a href=\"https://www.embs.org\">IEEE EMBS</a>.</p>",
      "author": "Nancy Zimmerman",
      "published_date": "2025-04-27T21:41:29+00:00",
      "source": "Embs",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 19,
      "reading_time": 1,
      "created_at": "2025-10-06T09:42:52.275638+00:00",
      "updated_at": "2025-10-06T09:42:52.275640+00:00"
    },
    {
      "id": "1afc4c4e54184a244c216bb5b044f863",
      "url": "https://www.embs.org/blog-post/change-foi-for-ieee-embs/#new_tab",
      "title": "Notice to IEEE EMBS Members: Change to Field of Interest",
      "content": "<p>The post <a href=\"https://www.embs.org/blog-post/change-foi-for-ieee-embs/#new_tab\">Notice to IEEE EMBS Members: Change to Field of Interest</a> appeared first on <a href=\"https://www.embs.org\">IEEE EMBS</a>.</p>",
      "author": "Nancy Zimmerman",
      "published_date": "2025-04-27T21:46:11+00:00",
      "source": "Embs",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 19,
      "reading_time": 1,
      "created_at": "2025-10-06T09:42:52.275619+00:00",
      "updated_at": "2025-10-06T09:42:52.275621+00:00"
    },
    {
      "id": "5d49304b30e3f1cca1ea313fc654375e",
      "url": "https://www.embs.org/uncategorized/call-for-adcom-nominations/",
      "title": "Open Call for AdCom Nominations",
      "content": "<p>The post <a href=\"https://www.embs.org/uncategorized/call-for-adcom-nominations/\">Open Call for AdCom Nominations</a> appeared first on <a href=\"https://www.embs.org\">IEEE EMBS</a>.</p>",
      "author": "Nancy Zimmerman",
      "published_date": "2025-05-02T17:09:21+00:00",
      "source": "Embs",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 14,
      "reading_time": 1,
      "created_at": "2025-10-06T09:42:52.275599+00:00",
      "updated_at": "2025-10-06T09:42:52.275600+00:00"
    }
  ],
  "recently_processed": [
    {
      "id": "62b33c8c35269d32a56b51c7891f8cd1",
      "url": "http://ieeexplore.ieee.org/document/11153361",
      "title": "Electroencephalographic Functional Connectivity, Heartrate Synchrony, and Eye Movements Reveal Distinct Components within Narrative Engagement and Immersion",
      "content": "Storytelling is a fundamental and universal human behavior, representing a vehicle for cultural information exchange throughout human history. In the present day, consumption of narrative audiovisual media is one of the most common recreational activities worldwide. Despite the importance and ubiquity of storytelling, relatively little is known about the neurocognitive mechanisms by which narrative media capture and sustain our attention. In this study, 40 participants watched 10 short clips from television shows of various genres while electroencephalography, eye tracking, heart rate, and self-report data were recorded. Self-reported immersion and three of the four components of narrative engagement that we examined\u2014attentional focus, emotional engagement, and narrative presence\u2014were associated with interindividual synchrony in heart rate and gaze behavior, but were associated with relatively distinct patterns of neural activity (electroencephalography power amplitude and functional connectivity). Narrative understanding, on the other hand, was not associated with heart rate or gaze synchrony. Furthermore, structural equation modeling revealed directionally opposing relationships between overall alpha-band connectivity and narrative presence on the one hand (positive), and narrative understanding (negative) on the other. These results suggest narrative understanding may be associated with a different set of neurocognitive processes to the other dimensions of narrative engagement. These findings point toward a bifurcated model of narrative engagement and raise interesting theoretical questions about the role of narrative comprehension in this process.",
      "author": "",
      "published_date": "2025-09-08T13:16:44+00:00",
      "source": "Cognitive Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 220,
      "reading_time": 1,
      "created_at": "2025-10-06T09:42:53.492240+00:00",
      "updated_at": "2025-10-06T10:16:06.944404+00:00",
      "metadata": {
        "processed_at": "2025-10-06T10:16:06.944415+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "d50017c01d1cea4b149c811378d33224",
      "url": "http://ieeexplore.ieee.org/document/11153352",
      "title": "Object Ownership Processing in Peripersonal Space: An Electroencephalographic Study",
      "content": "A fundamental aspect of interacting with objects in the environment is the ability to distinguish between objects that can be directly acted upon in the peripersonal space (PPS) and those out of immediate reach in the extrapersonal space (EPS). Performing appropriate actions also requires integrating social conceptual information related to who owns a particular object. While prior research has demonstrated that spatial and social factors influence object processing, how these factors are integrated is not yet fully understood. To address this issue, the present study explored the neurophysiological correlates of object ownership processing when objects were located in either the PPS or EPS. Facing a virtual character, 28 participants estimated the reachability of self-owned or other-owned objects, placed at different distances. The analysis confirmed that self-owned objects are processed faster when located in PPS, and other-owned objects are processed faster when located in EPS. EEG signals analysis revealed that early ERP components, such as the N1 and anterior N2, were modulated solely by objects' spatial location. In contrast, later components, including the P3 and anterior N400, were influenced by object ownership, although depending on object's location in space. These results suggest an early perceptual prioritization of objects in the PPS and a prioritization of objects that engages the self at a postperceptual stage. Overall, the findings provide new insights into how objects are processed depending on their spatial and social properties, and confirm that virtual reality represents a promising tool to probe neural mechanisms supporting perception and action in social contexts.",
      "author": "",
      "published_date": "2025-09-08T13:16:40+00:00",
      "source": "Cognitive Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 251,
      "reading_time": 1,
      "created_at": "2025-10-06T09:42:53.492202+00:00",
      "updated_at": "2025-10-06T10:16:06.944419+00:00",
      "metadata": {
        "processed_at": "2025-10-06T10:16:06.944421+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "0935313f19774a2f7dddae3f96606656",
      "url": "http://ieeexplore.ieee.org/document/11153355",
      "title": "Neural Signatures of Recollection Are Sensitive to Memory Quality and Specific Event Features",
      "content": "Episodic memories reflect a bound representation of multimodal features that can be recollected with varying levels of precision. Recent fMRI investigations have demonstrated that the precision and content of information retrieved from memory engage a network of posterior medial-temporal and parietal regions co-activated with the hippocampus. Yet, comparatively, little is known about how memory content and precision affect common neural signatures of memory captured by EEG, where recollection has been associated with changes in ERP and oscillatory measures of neural activity. Here, we used a multifeature paradigm previously reported [Cooper, R. A., & Ritchey, M. Cortico-hippocampal network connections support the multidimensional quality of episodic memory. eLife, 8, e45591, 2019] with continuous measures of memory, in conjunction with scalp EEG, to characterize the content and quality of information that drives ERP and oscillatory markers of episodic memory. A common signature of memory retrieval in the left posterior regions, called the late positive component, was sensitive to overall memory quality and also to precision of recollection for spatial features. The analysis of oscillatory markers during recollection revealed that alpha/beta desynchronization was modulated by overall memory quality and also by individual features in memory. Importantly, we found evidence of a relationship between these two neural markers of memory retrieval, suggesting that they may represent complementary aspects of the recollection experience. These findings demonstrate how time-sensitive and dynamic processes identified with EEG correspond to overall episodic recollection and also to the retrieval of precise features in memory.",
      "author": "",
      "published_date": "2025-09-08T13:16:44+00:00",
      "source": "Cognitive Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 243,
      "reading_time": 1,
      "created_at": "2025-10-06T09:42:53.492167+00:00",
      "updated_at": "2025-10-06T10:16:06.944423+00:00",
      "metadata": {
        "processed_at": "2025-10-06T10:16:06.944425+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "9fe9c99db697786e3f69c006b914b51d",
      "url": "http://ieeexplore.ieee.org/document/11153362",
      "title": "Transient and Sustained Neuromagnetic Representation of Consonance and Dissonance in Harmonic Sequences",
      "content": "The perception of musical consonance/dissonance (C/D) relies on basic properties of the auditory system, and prior investigations have shown that C/D sounds elicit strongly divergent neurophysiological activity in human auditory cortex. However, studies are missing that assess transient (P1, N1, P2) and sustained cortical C/D representations within a harmonic context, together with the corresponding patterns of neural adaptation. The present magnetoencephalography experiment applied spatio-temporal source analysis to study the early transient and sustained neuromagnetic processing of C/D at the start and within brief harmonic sequences. A total of n = 40 adult listeners (among them numerous amateur musicians) participated in the experiment; the harmonic sequences comprised different blends of C/D dyads with balanced probabilities, in an effort to access simple C/D relations and neural adaptation at an early stage of the processing hierarchy. Consistent with earlier findings, the transient cortical activity was found to reflect vertical (i.e., absolute) C/D aspects in response to the sequence's first dyad, but it mirrored more horizontal aspects (i.e., C/D relations) at the subsequent dyad transitions; moreover, the neuromagnetic responses (particularly, the N1 and P2 waves) exhibited adaptation with different time constants, parts of which pertained to C/D-associated processing. Surprisingly, only few observations appeared to be influenced by the listener's musical expertise, likely due to the high overall level of musicality in our sample. In summary, our data indicate that early neuromagnetic activity reflects not only vertical, but also horizontal, aspects of C/D perception, together with corresponding adaptive mechanisms.",
      "author": "",
      "published_date": "2025-09-08T13:16:44+00:00",
      "source": "Cognitive Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 244,
      "reading_time": 1,
      "created_at": "2025-10-06T09:42:53.492131+00:00",
      "updated_at": "2025-10-06T10:16:06.944427+00:00",
      "metadata": {
        "processed_at": "2025-10-06T10:16:06.944428+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "3126a4e56a81b2be3ee1af1e1e87dffc",
      "url": "http://ieeexplore.ieee.org/document/11153357",
      "title": "An Emergentist Account of Language in the Brain\u2014Seeking Neural Synergies Behind Human Uniqueness",
      "content": "Cognitive neuroscience has become increasingly open to views of human cognitive faculties as emergent properties\u2014as higher-level products of synergies between brain structures handling qualitatively different functions. This new perspective mitigates claims that cognitive abilities are tied to localized, domain-specific brain systems. In this changing landscape, the neurobiology of language has lagged behind, with virtually no mature theory apt to guide an exploration of language as an emergent function of the human brain. Combining evidence that linguistic processing is distributed across neurocognitive systems supporting (among others) semantic cognition, executive functions, and articulatory-motor control with recent advances in studying neural synergies, we propose a model of language as a deeply synergistic phenomenon that is both decoupled from its lower-level constituents and capable of exerting downward causal powers over them, accounting for its key role in human adaptive behavior. In considering the implications it has in our understanding of the place of language within the broader infrastructure of human behavior, this novel perspective aims to move the neurobiology of language forward in a new era of the cognitive neuroscience.",
      "author": "",
      "published_date": "2025-09-08T13:16:44+00:00",
      "source": "Cognitive Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 176,
      "reading_time": 1,
      "created_at": "2025-10-06T09:42:53.492095+00:00",
      "updated_at": "2025-10-06T10:16:06.944433+00:00",
      "metadata": {
        "processed_at": "2025-10-06T10:16:06.944435+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "3d370217cb4a351bb54e7854066e15c3",
      "url": "https://erpinfo.org/blog/2024/2/4/optimal-filters",
      "title": "New Papers: Optimal Filter Settings for ERP Research",
      "content": "<p class=\"\">Zhang, G., Garrett, D. R., &amp; Luck, S. J. (in press). Optimal filters for ERP research I: A general approach for selecting filter settings. <em>Psychophysiology</em>. <a href=\"https://doi.org/10.1111/psyp.14531\"><span>https://doi.org/10.1111/psyp.14531</span></a> [<a href=\"https://www.researchgate.net/publication/377773270_Optimal_filters_for_ERP_research_I_A_general_approach_for_selecting_filter_settings\"><span>preprint</span></a>]</p><p class=\"\">Zhang, G., Garrett, D. R., &amp; Luck, S. J. (in press). Optimal filters for ERP research II: Recommended settings for seven common ERP components. <em>Psychophysiology</em>. <a href=\"https://doi.org/10.1111/psyp.14530\"><span>https://doi.org/10.1111/psyp.14530</span></a> [<a href=\"https://www.researchgate.net/publication/377766656_Optimal_filters_for_ERP_research_II_Recommended_settings_for_seven_common_ERP_components\"><span>preprint</span></a>]</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1490\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/d64086cc-e3b4-457d-89df-08d9b3f96439/Filter_Table.png?format=1000w\" width=\"2062\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">What filter settings should you apply to your ERP data? If your filters are too weak to attenuate the noise in your data, your effects may not be statistically significant. If your filters are too strong, they may create artifactual peaks that lead you to draw bogus conclusions.</p><p class=\"\">For years, I have been recommending a bandpass of 0.1\u201330 Hz for most cognitive and affective research in neurotypical young adults. In this kind of research, I have found that filtering from 0.1\u201330 Hz usually does a good job of minimizing noise while creating minimal waveform distortion. </p><p class=\"\">However, this recommendation was based on a combination of informal observations from many experimental paradigms and a careful examination of a couple paradigms, so it was a bit hand-wavy. In addition, the optimal filter settings will depend on the waveshape of the ERP effects and the nature of the noise in a given study, so I couldn\u2019t make any specific recommendations about other experimental paradigms and participant populations. Moreover, different filter settings may be optimal for different scoring methods (e.g., mean amplitude vs. peak amplitude vs. peak latency).</p><p class=\"\">Guanghui Zhang, David Garrett, and I spent the last year focusing on this issue. First we developed a general method that can be used to determine the optimal filter settings for a given dataset and scoring method (see <a href=\"https://doi.org/10.1111/psyp.14531\"><span>this paper</span></a>). Then we applied this method to the <a href=\"https://doi.org/10.1016/j.neuroimage.2020.117465\"><span>ERP CORE</span></a> data to determine the optimal filter settings for the N170, MMN, P3b, N400, N2pc, LRP, and ERN components in neurotypical young adults (see <a href=\"https://doi.org/10.1111/psyp.14530\"><span>this paper</span></a> and the table above).</p><p class=\"\">If you are doing research with these components (or similar components) in neurotypical young adults, you can simply use the filter settings that we identified. If you are using a very different paradigm or testing a very different subject population, you can apply our method to your own data to find the optimal settings. We added some new tools to <a href=\"https://github.com/ucdavis/erplab\"><span>ERPLAB Toolbox</span></a> to make this easier.</p><p class=\"\">One thing that we discovered was that our old recommendation of 0.1\u201330 Hz does a good job of avoiding filter artifacts but is overly conservative for some components. For example, we can raise the low end to 0.5 Hz when measuring N2pc and MMN amplitudes, which gets rid of more noise without producing problematic waveform distortions. And we can go all the way up to 0.9 Hz for the N170 component. However, later/slower components like P3b and N400 require lower cutoffs (no higher than 0.2 Hz).</p><p class=\"\">You might be wondering how we defined the \u201coptimal\u201d filter settings. At one level, the answer is simple: The optimal filter is the one that maximizes the signal-to-noise ratio without producing too much waveform distortion. The complexities arise in quantifying the signal-to-noise ratio, quantifying the waveform distortion, and deciding how much waveform distortion is \u201ctoo much\u201d. We believe we have found reasonably straightforward and practical solutions to these problems, which you can read about in the published papers.</p>",
      "author": "Steve Luck",
      "published_date": "2024-02-04T23:46:20+00:00",
      "source": "Erp Boot Camp",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 568,
      "reading_time": 2,
      "created_at": "2025-10-06T07:40:02.276625+00:00",
      "updated_at": "2025-10-06T08:19:55.516001+00:00",
      "metadata": {
        "processed_at": "2025-10-06T08:19:55.516033+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "c2319578819743fdf0159bf723bcb1b5",
      "url": "https://erpinfo.org/blog/2024/3/5/changes-to-the-2024-erp-boot-camp",
      "title": "Important Changes to the 2024 ERP Boot Camp",
      "content": "<p class=\"\">We are disappointed to announce that we will not be holding a regular 10-day ERP Boot Camp this summer.</p><p class=\"\">We have held Boot Camps nearly every summer since 2007, supported by a series of generous grants from NIMH that allowed us to provide scholarships for all attendees. Unfortunately, although our recent renewal proposal received extremely positive reviews and scores, we were recently given the surprising and disappointing news that the renewal will not be funded this year. We believe that the ERP Boot Camp provides essential training to the field, and we will continue to pursue financial support to continue holding 10-day ERP Boot Camps in the future. </p><p class=\"\">In the meantime, we have partial funding that will allow us to hold a 5-day ERP Boot Camp this summer from July 8-12, 2024 in Davis, California. The workshop will include 5-days of lectures and activities on EEG and ERP measures, including practical and theoretical issues.</p><p class=\"\">Unfortunately, we will not be able to provide scholarships to pay for travel and lodging costs, and we must charge a registration fee. We are very sorry if this causes a hardship. </p><p class=\"\">We are no longer taking applications through our application portal. Instead of a competitive application process, we will simply accept the first 30 people who complete the registration process and pay the registration fee. This provides an opportunity to attend for individuals who might otherwise not make it through our ordinary application process, which is highly competitive. </p><p class=\"\">The registration fee will be $1000 (or $900 for people who register by April 15). The registration fee will cover 6 nights in a single occupancy hotel room (arriving July 7 and departing July 13), daily breakfast at the hotel, a catered lunch for each day of the workshop, and a group dinner. <strong>You must pay the registration fee with a credit card when you register.</strong> There are no exceptions to the registration fee policy.</p><p class=\"\"><strong>Registration is now open</strong> at <a href=\"https://na.eventscloud.com/793175\">https://na.eventscloud.com/793175</a>.</p><p class=\"\">Given that we will accept the first 30 registrants, we encourage you to register as soon as possible. <strong>Registration will close on May 20</strong>, but we anticipate that the workshop will be filled up long before then. </p><p class=\"\">You must pay for your own transportation to Davis. Davis is approximately 20 minutes away from the Sacramento Airport (SMF). You can take the <a href=\"https://www.davisairporter.com/\" target=\"_blank\">Davis Airporter</a> shuttle service or a rideshare service from SMF to Davis. If you are coming from outside North America, you may want to fly into the San Francisco airport (SFO), which is 135 km (84 miles) from Davis. We recommend taking the <a href=\"https://www.davisairporter.com/\" target=\"_blank\">Davis Airporter</a> from SFO to Davis.</p>",
      "author": "Steve Luck",
      "published_date": "2024-03-05T19:34:57+00:00",
      "source": "Erp Boot Camp",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 444,
      "reading_time": 2,
      "created_at": "2025-10-06T07:40:02.276557+00:00",
      "updated_at": "2025-10-06T08:19:55.516038+00:00",
      "metadata": {
        "processed_at": "2025-10-06T08:19:55.516040+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "d1b3a64c1957f2b048e1e94f5d37c6e5",
      "url": "https://erpinfo.org/blog/2024/3/15/registration-full",
      "title": "Registration is now full for the 2024 ERP Boot Camp",
      "content": "<p class=\"\">The demand for the<a href=\"https://erpinfo.org/2024-erp-boot-camp\"> 2024 ERP Boot Camp</a> was far beyond our expectations, and we reached our maximum registration of 30 people within one day. We already have a waiting list of over 30 people, so we have closed the registration site.</p><p class=\"\">We realize that this is very disappointing to many people. We hope to offer another workshop like this next summer, or possibly earlier.</p><p class=\"\">If you would like to get announcements about upcoming boot camps and webinars, you should <a href=\"https://erpinfo.org/bootcamp-email-list\">join our email list</a>.</p><p class=\"\">You may also consider hosting a <a href=\"https://erpinfo.org/mini-erp-boot-camps\">Mini ERP Boot Camp</a> at your institution (in person or over Zoom).</p>",
      "author": "Steve Luck",
      "published_date": "2024-03-16T15:14:42+00:00",
      "source": "Erp Boot Camp",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 106,
      "reading_time": 1,
      "created_at": "2025-10-06T07:40:02.276507+00:00",
      "updated_at": "2025-10-06T08:19:55.516043+00:00",
      "metadata": {
        "processed_at": "2025-10-06T08:19:55.516044+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "e1385798428586a67ced89a895faeb47",
      "url": "https://erpinfo.org/blog/2024/6/10/erp-core-decoding-paper",
      "title": "New Paper: Using Multivariate Pattern Analysis to Increase Effect Sizes for ERP Amplitude Comparisons",
      "content": "<p class=\"\">Carrasco, C. D., Bahle, B., Simmons, A. M., &amp; Luck, S. J. (2024). Using multivariate pattern analysis to increase effect sizes for event-related potential analyses. Psychophysiology, 61, e14570. <a href=\"https://doi.org/10.1111/psyp.14570\">https://doi.org/10.1111/psyp.14570</a> [<a href=\"https://doi.org/10.1101/2023.11.07.566051\">preprint</a>]</p><p class=\"\">Multivariate pattern analysis (MVPA) can be used to \u201cdecode\u201d subtle information from ERP signals, such as which of several faces a participant is perceiving or the orientation that someone is holding in working memory (see <a href=\"https://erpinfo.org/blog/2018/9/16/decoding\">this previous blog post</a>). This approach is so powerful that we started wondering whether it might also give us greater statistical power in more typical experiments where the goal is to determine whether an ERP component differs in amplitude across experimental conditions. For example, might we more easily be able to tell if N400 amplitude is different between two different classes of words by using decoding? If so, that might make it possible to detect effects that would otherwise be too small to be significant.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"688\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/08f353c7-f484-4e87-b5d3-a256fe1206e2/N170_ES.png?format=1000w\" width=\"971\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">To address this question, we compared decoding with the conventional ERP analysis approach with using the 6 experimental paradigms in the <a href=\"https://doi.org/10.18115/D5JW4R\">ERP CORE</a>. In the conventional ERP analysis, we measured the mean amplitude during the standard measurement window from each participant in the two conditions of the paradigm (e.g., faces versus cars for N170, deviants versus standards for MMN). We quantified the magnitude of the difference between conditions using Cohen\u2019s <em>dz</em> (the variant of Cohen\u2019s <em>d</em> corresponding to a paired <em>t</em> test). For example, the effect size in the conventional ERP comparison of faces versus cars in the N170 paradigm was approximately 1.7 (see the figure).</p><p class=\"\">We also applied decoding to each paradigm. For example, in the N170 paradigm, we trained a support vector machine (SVM) to distinguish between ERPs elicited by faces and ERPs elicited by cars. This was done separately for each subject, and we converted the decoding accuracy into Cohen\u2019s <em>dz</em> so that it could be compared with the <em>dz</em> from the conventional ERP analysis. As you can see from the bar labeled SVM in the figure above, the effect size for the SVM-based decoding analysis was almost twice as large as the effect size for the conventional ERP analysis. That\u2019s a huge difference!</p><p class=\"\">We found a similar benefit for SVM-based decoding over conventional ERP analyses in 7 of the 10 cases we tested (see the figure below). In the other 3 cases, the ERP and SVM effects were approximately equivalent. So, there doesn\u2019t seem to be a downside to using decoding, at least in terms of effect size. But there can be a big benefit.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1371\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/d16f0782-7205-4d50-95e1-c6729cbc153e/All_Components.png?format=1000w\" width=\"4641\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">Because decoding has many possible benefits, we\u2019ve added it into <a href=\"ERPLAB Toolbox\">ERPLAB Toolbox</a>. It\u2019s super easy to use, and we\u2019ve created <a href=\"https://erpinfo.org/blog/2023/6/23/decoding-webinar\">detailed documentation and a video</a> to explain how it works at a conceptual level and to show you how to use it.</p><p class=\"\">We encourage you to apply it to your own data. It may give you the power to detect effects that are too small to be detected with conventional ERP analyses.</p>",
      "author": "Steve Luck",
      "published_date": "2024-06-10T18:01:45+00:00",
      "source": "Erp Boot Camp",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 525,
      "reading_time": 2,
      "created_at": "2025-10-06T07:40:02.276480+00:00",
      "updated_at": "2025-10-06T08:19:55.516046+00:00",
      "metadata": {
        "processed_at": "2025-10-06T08:19:55.516048+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "906f73f5c36ba087882a0ad17e01fc20",
      "url": "https://erpinfo.org/blog/2024/6/11/erplab-studio",
      "title": "New software package: ERPLAB Studio",
      "content": "<p class=\"\">We are excited to announce the release of a new EEG/ERP analysis package, <a href=\"https://github.com/ucdavis/erplab/releases\">ERPLAB Studio</a>. We think it\u2019s a huge improvement over the classic EEGLAB user interface. See our cheesy <a href=\"https://www.youtube.com/watch?v=lIaKVQ9DD6E\">\u201cadvertisement\u201d video</a> to get a quick overview. </p><p class=\"\">Rather than operating as an EEGLAB plugin, ERPLAB Studio is a standalone Matlab program that provides a more efficient and user-friendly interface to the most commonly used EEGLAB and ERPLAB routines.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1080\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/c874d4ec-5186-4de9-981b-58010c7a06e1/Interface.jpeg?format=1000w\" width=\"1920\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">With ERPLAB Studio, you automatically see the EEG or ERP waveforms as soon as you load a file. And as soon as you perform an operation, you see what the new EEG/ERP looks like. For example, when you filter the data, you immediately see the filtered waveforms.</p><p class=\"\">You can even select multiple datasets and apply an operation like artifact detection on all of them in one step. And then you can immediately see the results, such as which EEG epochs have been marked with artifacts.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1080\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/b45f514d-2d21-4a5a-8be6-f3a8ff99c388/Artifacts.jpeg?format=1000w\" width=\"1920\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">We give you access to EEGLAB\u2019s ICA-based artifact correction tools, but with a nice bonus. You can plot the ICA activations in the same window with the EEG data, making it easy to see which ICA components correspond to specific artifacts such as eyeblinks.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1080\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/8bc191da-9040-4042-ae9c-550cd98def7d/ICA.jpeg?format=1000w\" width=\"1920\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">The program has an EEG tab for processing continuous and epoched EEG data, and an ERP tab for processing averaged ERPs.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1080\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/84bdd9df-b02e-4fc5-83b9-1139a91938f5/Tabs.jpg?format=1000w\" width=\"1920\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">The automatic ERP plotting makes it easy for you to view the data laid out according to the electrode locations. And we have an Advanced Waveform Viewer that can make publication-quality plots.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1080\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/a932631f-fc30-415f-b11d-660d2bf90da5/ERP.jpeg?format=1000w\" width=\"1920\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">ERPLAB Studio is mainly just a new user interface. Under the hood, we\u2019re running the same EEGLAB and ERPLAB routines you\u2019ve always used. And scripting is identical.</p><p class=\"\">ERPLAB Studio is included in <a href=\"https://github.com/ucdavis/erplab/releases\">version 11 and higher of ERPLAB</a>. You simply follow our <a href=\"https://github.com/ucdavis/erplab/wiki/installation\">download/installation instructions</a> and then type estudio from the Matlab command line. </p><p class=\"\">If you\u2019re new to ERPLAB, we strongly recommend that you go through our <a href=\"https://github.com/ucdavis/erplab/wiki/ERPLAB-Studio-Tutorial\" target=\"_blank\">tutorial</a> before starting to process your own data. </p><p class=\"\">If you already know how to use the original version of ERPLAB (which we now call ERPLAB Classic), you can quickly learn how to use ERPLAB Studio with our <a href=\"https://ucdavis.box.com/s/i4jfv22gv6rj9t5obctuk6yaruxqomcc\">Transition Guide</a>.</p><p class=\"\">We also have a <a href=\"https://github.com/ucdavis/erplab/wiki/ERPLAB-Studio-Manual\">manual</a> that describes every feature in detail. </p>",
      "author": "Steve Luck",
      "published_date": "2024-06-12T02:02:16+00:00",
      "source": "Erp Boot Camp",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 444,
      "reading_time": 2,
      "created_at": "2025-10-06T07:40:02.276411+00:00",
      "updated_at": "2025-10-06T08:19:55.516050+00:00",
      "metadata": {
        "processed_at": "2025-10-06T08:19:55.516052+00:00",
        "processing_method": "github_actions"
      }
    }
  ]
}