{
  "last_updated": "2025-09-11T22:12:58.419599+00:00",
  "pending_count": 985,
  "processed_count": 15,
  "pending_articles": [
    {
      "id": "676bc1789355a4f0ef520e6bc6804f07",
      "url": "https://arxiv.org/abs/2509.08357",
      "title": "Personalized Inhibition Training with Eye-Tracking: Enhancing Student Learning and Teacher Assessment in Educational Games",
      "content": "arXiv:2509.08357v1 Announce Type: new \nAbstract: Eye tracking (ET) can help to understand visual attention and cognitive processes in interactive environments. This study presents a comprehensive eye-tracking analysis framework of the Inhibitory Control Game, named the ReStroop game, which is an educational intervention aimed at improving inhibitory control skills in children through a recycling-themed sorting task, for educational assessment that processes raw gaze data through unified algorithms for fixation detection, performance evaluation, and personalized intervention planning. The system employs dual-threshold eye movement detection (I-VT and advanced clustering), comprehensive Area of Interest (AOI) analysis, and evidence-based risk assessment to transform gaze patterns into actionable educational insights. We evaluated this framework across three difficulty levels and revealed critical attention deficits, including low task relevance, elevated attention scatter, and compromised processing efficiency. The multi-dimensional risk assessment identified high to moderate risk levels, triggering personalized interventions including focus training, attention regulation support, and environmental modifications. The system successfully distinguishes between adaptive learning and cognitive overload, providing early warning indicators for educational intervention. Results demonstrate the system's effectiveness in objective attention assessment, early risk identification, and the generation of evidence-based recommendations for students, teachers, and specialists, supporting data-driven educational decision-making and personalized learning approaches.",
      "author": "Abdul Rehman, Ilona Heldal, Diana Stilwell, Paula Costa Ferreira, Jerry Chun-Wei Lin",
      "published_date": "2025-09-11T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 198,
      "reading_time": 1,
      "created_at": "2025-09-11T21:38:02.791045+00:00",
      "updated_at": "2025-09-11T21:38:02.791047+00:00"
    },
    {
      "id": "d2244f0e0693fcf44adc5a52ed33f34f",
      "url": "https://arxiv.org/abs/2509.08353",
      "title": "An Adaptive Scoring Framework for Attention Assessment in NDD Children via Serious Games",
      "content": "arXiv:2509.08353v1 Announce Type: new \nAbstract: This paper introduces an innovative adaptive scoring framework for children with Neurodevelopmental Disorders (NDD) that is attributed to the integration of multiple metrics, such as spatial attention patterns, temporal engagement, and game performance data, to create a comprehensive assessment of learning that goes beyond traditional game scoring. The framework employs a progressive difficulty adaptation method, which focuses on specific stimuli for each level and adjusts weights dynamically to accommodate increasing cognitive load and learning complexity. Additionally, it includes capabilities for temporal analysis, such as detecting engagement periods, providing rewards for sustained attention, and implementing an adaptive multiplier framework based on performance levels. To avoid over-rewarding high performers while maximizing improvement potential for students who are struggling, the designed framework features an adaptive temporal impact framework that adjusts performance scales accordingly. We also established a multi-metric validation framework using Mean Absolute Error (MAE), Root Mean Square Error (RMSE), Pearson correlation, and Spearman correlation, along with defined quality thresholds for assessing deployment readiness in educational settings. This research bridges the gap between technical eye-tracking metrics and educational insights by explicitly mapping attention patterns to learning behaviors, enabling actionable pedagogical interventions.",
      "author": "Abdul Rehman, Ilona Heldal, Cristina Costescu, Carmen David, Jerry Chun-Wei Lin",
      "published_date": "2025-09-11T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 193,
      "reading_time": 1,
      "created_at": "2025-09-11T21:38:02.791012+00:00",
      "updated_at": "2025-09-11T21:38:02.791014+00:00"
    },
    {
      "id": "f1ef1c9951f379b8d956def045981115",
      "url": "https://arxiv.org/abs/2509.08213",
      "title": "A Priest, a Rabbi, and an Atheist Walk Into an Error Bar: Religious Meditations on Uncertainty Visualization",
      "content": "arXiv:2509.08213v1 Announce Type: new \nAbstract: In this provocation, we suggest that much (although not all) current uncertainty visualization simplifies the myriad forms of uncertainty into error bars around an estimate. This apparent simplification into error bars comes only as a result of a vast metaphysics around uncertainty and probability underlying modern statistics. We use examples from religion to present alternative views of uncertainty (metaphysical or otherwise) with the goal of enriching our conception of what kind of uncertainties we ought to visualize, and what kinds of people we might be visualizing those uncertainties for.",
      "author": "Michael Correll, Lane Harrison",
      "published_date": "2025-09-11T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 94,
      "reading_time": 1,
      "created_at": "2025-09-11T21:38:02.790979+00:00",
      "updated_at": "2025-09-11T21:38:02.790981+00:00"
    },
    {
      "id": "fc92b8c2d5d2154ede7b5d5bfa022bdb",
      "url": "https://arxiv.org/abs/2509.08203",
      "title": "Componentization: Decomposing Monolithic LLM Responses into Manipulable Semantic Units",
      "content": "arXiv:2509.08203v1 Announce Type: new \nAbstract: Large Language Models (LLMs) often produce monolithic text that is hard to edit in parts, which can slow down collaborative workflows. We present componentization, an approach that decomposes model outputs into modular, independently editable units while preserving context. We describe Modular and Adaptable Output Decomposition (MAOD), which segments responses into coherent components and maintains links among them, and we outline the Component-Based Response Architecture (CBRA) as one way to implement this idea. Our reference prototype, MAODchat, uses a microservices design with state-machine-based decomposition agents, vendor-agnostic model adapters, and real-time component manipulation with recomposition.\n  In an exploratory study with four participants from academic, engineering, and product roles, we observed that component-level editing aligned with several common workflows and enabled iterative refinement and selective reuse. Participants also mentioned possible team workflows. Our contributions are: (1) a definition of componentization for transforming monolithic outputs into manipulable units, (2) CBRA and MAODchat as a prototype architecture, (3) preliminary observations from a small user study, (4) MAOD as an algorithmic sketch for semantic segmentation, and (5) example Agent-to-Agent protocols for automated decomposition. We view componentization as a promising direction for turning passive text consumption into more active, component-level collaboration.",
      "author": "Ryan Lingo, Rajeev Chhajer, Martin Arroyo, Luka Brkljacic, Ben Davis, Nithin Santhanam",
      "published_date": "2025-09-11T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 199,
      "reading_time": 1,
      "created_at": "2025-09-11T21:38:02.790951+00:00",
      "updated_at": "2025-09-11T21:38:02.790953+00:00"
    },
    {
      "id": "570efa6f363544b569e7e449b757fe43",
      "url": "https://arxiv.org/abs/2509.08108",
      "title": "Understanding the Video Content Creation Journey of Creators with Sensory Impairment in Kenya",
      "content": "arXiv:2509.08108v1 Announce Type: new \nAbstract: Video content creation offers vital opportunities for expression and participation, yet remains largely inaccessible to creators with sensory impairments, especially in low-resource settings. We conducted interviews with 20 video creators with visual and hearing impairments in Kenya to examine their tools, challenges, and collaborative practices. Our findings show that accessibility barriers and infrastructural limitations shape video creation as a staged, collaborative process involving trusted human partners and emerging AI tools. Across workflows, creators actively negotiated agency and trust, maintaining creative control while bridging sensory gaps. We discuss the need for flexible, interdependent collaboration models, inclusive human-AI workflows, and diverse storytelling practices. This work broadens accessibility research in HCI by examining how technology and social factors intersect in low-resource contexts, suggesting ways to better support disabled creators globally.",
      "author": "Lan Xiao, Maryam Bandukda, Franklin Mingzhe Li, Mark Colley, Catherine Holloway",
      "published_date": "2025-09-11T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 132,
      "reading_time": 1,
      "created_at": "2025-09-11T21:38:02.790909+00:00",
      "updated_at": "2025-09-11T21:38:02.790913+00:00"
    },
    {
      "id": "e1171c53fdb22efae2cbee26718893f5",
      "url": "https://arxiv.org/abs/2306.13802",
      "title": "Using topological data analysis to compare inter-subject variability across resting state functional MRI brain representations",
      "content": "arXiv:2306.13802v3 Announce Type: replace-cross \nAbstract: In neuroimaging, extensive post-processing of resting-state functional MRI (rfMRI) data is necessary for its application and investigation in relation to brain-behavior associations. Such post-processing is used to derive brain representations, lower dimensional feature sets used for brain-behavior association studies. A brain representation involves a choice of dimension reduction (a parcellation into regions or networks) and a choice of feature type, such as spatial topography, connectivity matrix, amplitude. However, widespread variability in rfMRI brain representations has hindered both reproducibility and knowledge accumulation across the field. Brain representation choice effects measurements of inter-subject variability, which muddies the comparison and integration of findings. We leveraged persistent homology on the subject-space topologies induced by 34 different brain representations to enable direct comparison of brain representations in the context of individual differences. Our findings reveal the importance of considering feature type when comparing results derived from different brain representations, suggesting best practices for assessing the replicability and generalizability of brain-behavior research in rfMRI data.",
      "author": "Ty Easley, Kevin Freese, Elizabeth Munch, Janine Bijsterbosch",
      "published_date": "2025-09-11T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 164,
      "reading_time": 1,
      "created_at": "2025-09-11T21:38:01.701689+00:00",
      "updated_at": "2025-09-11T21:38:01.701691+00:00"
    },
    {
      "id": "7f02bf86f51ffecf7e6b74d7cc41e6e9",
      "url": "https://arxiv.org/abs/2509.06810",
      "title": "Reward function compression facilitates goal-dependent reinforcement learning",
      "content": "arXiv:2509.06810v2 Announce Type: replace \nAbstract: Reinforcement learning agents learn from rewards, but humans can uniquely assign value to novel, abstract outcomes in a goal-dependent manner. However, this flexibility is cognitively costly, making learning less efficient. Here, we propose that goal-dependent learning is initially supported by a capacity-limited working memory system. With consistent experience, learners create a \"compressed\" reward function (a simplified rule defining the goal) which is then transferred to long-term memory and applied automatically upon receiving feedback. This process frees up working memory resources, boosting learning efficiency. We test this theory across six experiments. Consistent with our predictions, our findings demonstrate that learning is parametrically impaired by the size of the goal space, but improves when the goal space structure allows for compression. We also find faster reward processing to correlate with better learning performance, supporting the idea that as goal valuation becomes more automatic, more resources are available for learning. We leverage computational modeling to support this interpretation. Our work suggests that efficient goal-directed learning relies on compressing complex goal information into a stable reward function, shedding light on the cognitive mechanisms of human motivation. These findings generate new insights into the neuroscience of intrinsic motivation and could help improve behavioral techniques that support people in achieving their goals.",
      "author": "Gaia Molinaro, Anne G. E. Collins",
      "published_date": "2025-09-11T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 211,
      "reading_time": 1,
      "created_at": "2025-09-11T21:38:01.701630+00:00",
      "updated_at": "2025-09-11T21:38:01.701631+00:00"
    },
    {
      "id": "46025760cff1cabf2e37d70360a9c3ec",
      "url": "https://arxiv.org/abs/2503.06286",
      "title": "A 7T fMRI dataset of synthetic images for out-of-distribution modeling of vision",
      "content": "arXiv:2503.06286v2 Announce Type: replace \nAbstract: Large-scale datasets of brain responses such as the Natural Scenes Dataset (NSD) are boosting computational neuroscience research by enabling models of the brain with performances beyond what was possible just a decade ago. However, these datasets lack out-of-distribution (OOD) components, which are crucial for the development of more robust models. Here, we address this limitation by releasing NSD-synthetic, a dataset consisting of 7T fMRI responses from the same eight NSD participants for 284 synthetic images. We show that NSD-synthetic's fMRI responses reliably encode stimulus-related information and are OOD with respect to NSD. Furthermore, we provide a proof of principle that OOD generalization tests on NSD-synthetic reveal differences between models of the brain that are not detected with the original NSD data; we demonstrate that the degree of OOD (quantified as the distance between a set of responses and the training data used for modeling) is predictive of the magnitude of model failures; and we show that the concept of OOD is not restricted to artificial stimuli but can be usefully applied even within the domain of naturalistic stimuli. These results showcase how NSD-synthetic enables OOD generalization tests that facilitate the development of more robust models of visual processing and the formulation of more accurate theories of human vision.",
      "author": "Alessandro T. Gifford, Radoslaw M. Cichy, Thomas Naselaris, Kendrick Kay",
      "published_date": "2025-09-11T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 213,
      "reading_time": 1,
      "created_at": "2025-09-11T21:38:01.701597+00:00",
      "updated_at": "2025-09-11T21:38:01.701599+00:00"
    },
    {
      "id": "b97b6c8cdb5bdfa2aff53d9a69a0cacf",
      "url": "https://arxiv.org/abs/2509.08779",
      "title": "ADHDeepNet From Raw EEG to Diagnosis: Improving ADHD Diagnosis through Temporal-Spatial Processing, Adaptive Attention Mechanisms, and Explainability in Raw EEG Signals",
      "content": "arXiv:2509.08779v1 Announce Type: cross \nAbstract: Attention Deficit Hyperactivity Disorder (ADHD) is a common brain disorder in children that can persist into adulthood, affecting social, academic, and career life. Early diagnosis is crucial for managing these impacts on patients and the healthcare system but is often labor-intensive and time-consuming. This paper presents a novel method to improve ADHD diagnosis precision and timeliness by leveraging Deep Learning (DL) approaches and electroencephalogram (EEG) signals. We introduce ADHDeepNet, a DL model that utilizes comprehensive temporal-spatial characterization, attention modules, and explainability techniques optimized for EEG signals. ADHDeepNet integrates feature extraction and refinement processes to enhance ADHD diagnosis. The model was trained and validated on a dataset of 121 participants (61 ADHD, 60 Healthy Controls), employing nested cross-validation for robust performance. The proposed two-stage methodology uses a 10-fold cross-subject validation strategy. Initially, each iteration optimizes the model's hyper-parameters with inner 2-fold cross-validation. Then, Additive Gaussian Noise (AGN) with various standard deviations and magnification levels is applied for data augmentation. ADHDeepNet achieved 100% sensitivity and 99.17% accuracy in classifying ADHD/HC subjects. To clarify model explainability and identify key brain regions and frequency bands for ADHD diagnosis, we analyzed the learned weights and activation patterns of the model's primary layers. Additionally, t-distributed Stochastic Neighbor Embedding (t-SNE) visualized high-dimensional data, aiding in interpreting the model's decisions. This study highlights the potential of DL and EEG in enhancing ADHD diagnosis accuracy and efficiency.",
      "author": "Ali Amini, Mohammad Alijanpour, Behnam Latifi, Ali Motie Nasrabadi",
      "published_date": "2025-09-11T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 233,
      "reading_time": 1,
      "created_at": "2025-09-11T21:38:01.701564+00:00",
      "updated_at": "2025-09-11T21:38:01.701566+00:00"
    },
    {
      "id": "cfe7e03f4a5f0f377b53f6df8e972abd",
      "url": "https://arxiv.org/abs/2509.08442",
      "title": "Spherical Brownian Bridge Diffusion Models for Conditional Cortical Thickness Forecasting",
      "content": "arXiv:2509.08442v1 Announce Type: cross \nAbstract: Accurate forecasting of individualized, high-resolution cortical thickness (CTh) trajectories is essential for detecting subtle cortical changes, providing invaluable insights into neurodegenerative processes and facilitating earlier and more precise intervention strategies. However, CTh forecasting is a challenging task due to the intricate non-Euclidean geometry of the cerebral cortex and the need to integrate multi-modal data for subject-specific predictions. To address these challenges, we introduce the Spherical Brownian Bridge Diffusion Model (SBDM). Specifically, we propose a bidirectional conditional Brownian bridge diffusion process to forecast CTh trajectories at the vertex level of registered cortical surfaces. Our technical contribution includes a new denoising model, the conditional spherical U-Net (CoS-UNet), which combines spherical convolutions and dense cross-attention to integrate cortical surfaces and tabular conditions seamlessly. Compared to previous approaches, SBDM achieves significantly reduced prediction errors, as demonstrated by our experiments based on longitudinal datasets from the ADNI and OASIS. Additionally, we demonstrate SBDM's ability to generate individual factual and counterfactual CTh trajectories, offering a novel framework for exploring hypothetical scenarios of cortical development.",
      "author": "Ivan Stoyanov, Fabian Bongratz, Christian Wachinger",
      "published_date": "2025-09-11T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 173,
      "reading_time": 1,
      "created_at": "2025-09-11T21:38:01.701530+00:00",
      "updated_at": "2025-09-11T21:38:01.701531+00:00"
    }
  ],
  "recently_processed": [
    {
      "id": "6a78ace4c736083f37ec2330b4f03b5f",
      "url": "https://arxiv.org/abs/2509.08539",
      "title": "Motion-Based User Identification across XR and Metaverse Applications by Deep Classification and Similarity Learning",
      "content": "arXiv:2509.08539v1 Announce Type: new \nAbstract: This paper examines the generalization capacity of two state-of-the-art classification and similarity learning models in reliably identifying users based on their motions in various Extended Reality (XR) applications. We developed a novel dataset containing a wide range of motion data from 49 users in five different XR applications: four XR games with distinct tasks and action patterns, and an additional social XR application with no predefined task sets. The dataset is used to evaluate the performance and, in particular, the generalization capacity of the two models across applications. Our results indicate that while the models can accurately identify individuals within the same application, their ability to identify users across different XR applications remains limited. Overall, our results provide insight into current models generalization capabilities and suitability as biometric methods for user verification and identification. The results also serve as a much-needed risk assessment of hazardous and unwanted user identification in XR and Metaverse applications. Our cross-application XR motion dataset and code are made available to the public to encourage similar research on the generalization of motion-based user identification in typical Metaverse application use cases.",
      "author": "Lukas Schach, Christian Rack, Ryan P. McMahan, Marc Erich Latoschik",
      "published_date": "2025-09-11T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 189,
      "reading_time": 1,
      "created_at": "2025-09-11T21:38:02.791223+00:00",
      "updated_at": "2025-09-11T22:12:58.318569+00:00",
      "metadata": {
        "processed_at": "2025-09-11T22:12:58.318578+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "cbca39a58874b315212cdaef9205bfc0",
      "url": "https://arxiv.org/abs/2509.08514",
      "title": "Bias in the Loop: How Humans Evaluate AI-Generated Suggestions",
      "content": "arXiv:2509.08514v1 Announce Type: new \nAbstract: Human-AI collaboration increasingly drives decision-making across industries, from medical diagnosis to content moderation. While AI systems promise efficiency gains by providing automated suggestions for human review, these workflows can trigger cognitive biases that degrade performance. We know little about the psychological factors that determine when these collaborations succeed or fail. We conducted a randomized experiment with 2,784 participants to examine how task design and individual characteristics shape human responses to AI-generated suggestions. Using a controlled annotation task, we manipulated three factors: AI suggestion quality in the first three instances, task burden through required corrections, and performance-based financial incentives. We collected demographics, attitudes toward AI, and behavioral data to assess four performance metrics: accuracy, correction activity, overcorrection, and undercorrection. Two patterns emerged that challenge conventional assumptions about human-AI collaboration. First, requiring corrections for flagged AI errors reduced engagement and increased the tendency to accept incorrect suggestions, demonstrating how cognitive shortcuts influence collaborative outcomes. Second, individual attitudes toward AI emerged as the strongest predictor of performance, surpassing demographic factors. Participants skeptical of AI detected errors more reliably and achieved higher accuracy, while those favorable toward automation exhibited dangerous overreliance on algorithmic suggestions. The findings reveal that successful human-AI collaboration depends not only on algorithmic performance but also on who reviews AI outputs and how review processes are structured. Effective human-AI collaborations require consideration of human psychology: selecting diverse evaluator samples, measuring attitudes, and designing workflows that counteract cognitive biases.",
      "author": "Jacob Beck, Stephanie Eckman, Christoph Kern, Frauke Kreuter",
      "published_date": "2025-09-11T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 242,
      "reading_time": 1,
      "created_at": "2025-09-11T21:38:02.791178+00:00",
      "updated_at": "2025-09-11T22:12:58.318583+00:00",
      "metadata": {
        "processed_at": "2025-09-11T22:12:58.318585+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "7c61ff75c8a5a742af2ce4e8c7c0f204",
      "url": "https://arxiv.org/abs/2509.08459",
      "title": "Printegrated Circuits: Personal Fabrication of 3D Printed Devices with Embedded PCBs",
      "content": "arXiv:2509.08459v1 Announce Type: new \nAbstract: Consumer-level multi-material 3D printing with conductive thermoplastics enables fabrication of interactive elements for bespoke tangible devices. However, large feature sizes, high resistance materials, and limitations of printable control circuitry mean that deployable devices cannot be printed without post-print assembly steps. To address these challenges, we present Printegrated Circuits, a technique that uses traditional electronics as material to 3D print self-contained interactive objects. Embedded PCBs are placed into recesses during a pause in the print, and through a process we term \\textit{Prinjection}, conductive filament is injected into their plated-through holes. This automatically creates reliable electrical and mechanical contact, eliminating the need for manual wiring or bespoke connectors. We describe the custom machine code generation that supports our approach, and characterise its electrical and mechanical properties. With our 6 demonstrations, we highlight how the Printegrated Circuits process fits into existing design and prototyping workflows as well as informs future research agendas.",
      "author": "Oliver Child, Ollie Hanton, Jack Dawson, Steve Hodges, Mike Fraser",
      "published_date": "2025-09-11T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 154,
      "reading_time": 1,
      "created_at": "2025-09-11T21:38:02.791137+00:00",
      "updated_at": "2025-09-11T22:12:58.318587+00:00",
      "metadata": {
        "processed_at": "2025-09-11T22:12:58.318589+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "dd9ecfa353dbf5c36757a8d7874f519c",
      "url": "https://arxiv.org/abs/2509.08444",
      "title": "GlyphWeaver: Unlocking Glyph Design Creativity with Uniform Glyph DSL and AI",
      "content": "arXiv:2509.08444v1 Announce Type: new \nAbstract: Expressive glyph visualizations provide a powerful and versatile means to represent complex multivariate data through compact visual encodings, but creating custom glyphs remains challenging due to the gap between design creativity and technical implementation. We present GlyphWeaver, a novel interactive system to enable an easy creation of expressive glyph visualizations. Our system comprises three key components: a glyph domain-specific language (GDSL), a GDSL operation management mechanism, and a multimodal interaction interface. The GDSL is a hierarchical container model, where each container is independent and composable, providing a rigorous yet practical foundation for complex glyph visualizations. The operation management mechanism restricts modifications of the GDSL to atomic operations, making it accessible without requiring direct coding. The multimodal interaction interface enables direct manipulation, natural language commands, and parameter adjustments. A multimodal large language model acts as a translator, converting these inputs into GDSL operations. GlyphWeaver significantly lowers the barrier for designers, who often do not have extensive programming skills, to create sophisticated glyph visualizations. A case study and user interviews with 13 participants confirm its substantial gains in design efficiency and effectiveness of producing creative glyph visualizations.",
      "author": "Can Liu, Shiwei Chen, Zhibang Jiang, Yong Wang",
      "published_date": "2025-09-11T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 190,
      "reading_time": 1,
      "created_at": "2025-09-11T21:38:02.791108+00:00",
      "updated_at": "2025-09-11T22:12:58.318591+00:00",
      "metadata": {
        "processed_at": "2025-09-11T22:12:58.318593+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "d465e969e01804609fdff1762cfcc021",
      "url": "https://arxiv.org/abs/2509.08404",
      "title": "HyperMOOC: Augmenting MOOC Videos with Concept-based Embedded Visualizations",
      "content": "arXiv:2509.08404v1 Announce Type: new \nAbstract: Massive Open Online Courses (MOOCs) have become increasingly popular worldwide. However, learners primarily rely on watching videos, easily losing knowledge context and reducing learning effectiveness. We propose HyperMOOC, a novel approach augmenting MOOC videos with concept-based embedded visualizations to help learners maintain knowledge context. Informed by expert interviews and literature review, HyperMOOC employs multi-glyph designs for different knowledge types and multi-stage interactions for deeper understanding. Using a timeline-based radial visualization, learners can grasp cognitive paths of concepts and navigate courses through hyperlink-based interactions. We evaluated HyperMOOC through a user study with 36 MOOC learners and interviews with two instructors. Results demonstrate that HyperMOOC enhances learners' learning effect and efficiency on MOOCs, with participants showing higher satisfaction and improved course understanding compared to traditional video-based learning approaches.",
      "author": "Li Ye, Lei Wang, Lihong Cai, Ruiqi Yu, Yong Wang, Yigang Wang, Wei Chen, Zhiguang Zhou",
      "published_date": "2025-09-11T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 131,
      "reading_time": 1,
      "created_at": "2025-09-11T21:38:02.791073+00:00",
      "updated_at": "2025-09-11T22:12:58.318595+00:00",
      "metadata": {
        "processed_at": "2025-09-11T22:12:58.318599+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "16f19e2c015242805e56672b244ef04b",
      "url": "https://www.sciencedirect.com/science/article/pii/S0306452225008905?dgcid=rss_sd_all",
      "title": "Unveiling the influence of facial expressions on EEG-based biometric system performance in ADHD and healthy children",
      "content": "<p>Publication date: 15 October 2025</p><p><b>Source:</b> Neuroscience, Volume 585</p><p>Author(s): Maryam Safardoost, Zahra Tabanfar, Farnaz Ghassemi</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroscience Journal",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 14,
      "reading_time": 1,
      "created_at": "2025-09-11T19:38:31.239318+00:00",
      "updated_at": "2025-09-11T20:12:59.158316+00:00",
      "metadata": {
        "processed_at": "2025-09-11T20:12:59.158326+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "da8e68bd1b4b8d36f56ccbb2bf655697",
      "url": "https://www.biorxiv.org/content/10.1101/2025.09.10.675423v1?rss=1",
      "title": "Spectral envelopes of rhythmic facial movements predict intention and motor cortical representations",
      "content": "Animals, including humans, use coordinated facial movements to sample the environment, ingest nutrients, and communicate. To study these behaviors and the neural signals that underlie them, we introduce face-rhythm, a tool for quantitatively tracking, extracting, and interpreting facial movements. The approach utilizes markerless point tracking, spectral analysis, and tensor component analysis to extract demixed components of behavior from videos of facial movements. Face-rhythm is fully unsupervised and allows for the discovery of uninstructed behaviors; when applied to videos of facial behavior, face-rhythm identifies interpretable behaviors such as whisking, sniffing, and snout movements. Analysis of videos of mice in various behavioral conditions, including a classical conditioning protocol, a brain-machine interface (BMI) task, and natural behaviors outside of a task structure, revealed robust signatures of uninstructed facial movements in all regimes. The expression of these facial movements predicted internal belief states during classical conditioning and was correlated with instructed neural activity when the BMI was activated. Furthermore, facial behaviors identified by face-rhythm were highly represented in face-associated areas of primary motor cortex (M1). We found that M1 neural activity encodes a mixed representation of both the phase of facial movements as well as the phase-invariant spectral envelope of movement patterns, with higher-frequency facial movements being more likely to be represented as phase-invariant. Our results demonstrate that face-rhythm provides a novel and flexible approach for decomposing continuous face movements into natural behavioral motifs that are closely linked to neural activity patterns.",
      "author": "Hakim, R., Heo, G., Jaggi, A., Musall, S., Datta, S. R., Sabatini, B. L.",
      "published_date": "2025-09-11T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 238,
      "reading_time": 1,
      "created_at": "2025-09-11T19:38:27.750718+00:00",
      "updated_at": "2025-09-11T20:12:59.158330+00:00",
      "metadata": {
        "processed_at": "2025-09-11T20:12:59.158332+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "c838443b4202f94a60372f0805f4cc46",
      "url": "https://www.biorxiv.org/content/10.1101/2025.09.10.674743v1?rss=1",
      "title": "CA2 neurons show abnormal responses to social stimuli in a rat model of Fragile X syndrome",
      "content": "Fragile X Syndrome (FXS) is a neurodevelopmental disorder that is highly comorbid with autism spectrum disorders and can cause abnormal social behaviors. The CA2 subregion of the hippocampus is essential for social memory processing and social recognition. A social interaction induces changes in CA2 neuronal firing; however, it is unknown whether these changes are impaired in FXS models. Here, we examined CA2 activity in a rat model of Fragile X Syndrome (Fmr1 knockout rats). In Fmr1 knockout rats, we observed impaired CA2 cell responses to social stimuli, despite similar social behaviors. Further, in CA2 of Fmr1 knockout rats, we found reduced expression of oxytocin receptors and impaired whole cell responses to oxytocin. Together, these results raise the possibility that abnormal CA2 activity contributes to impaired social behavior in FXS and may suggest novel treatment targets for FXS patients.",
      "author": "Donahue, M. M., Robson, E., Marron, A. M., Fernandez, E. J., Hill, M., Mably, A. J., Trimper, J. B., Brager, D. H., Colgin, L. L.",
      "published_date": "2025-09-11T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 138,
      "reading_time": 1,
      "created_at": "2025-09-11T19:38:27.750680+00:00",
      "updated_at": "2025-09-11T20:12:59.158335+00:00",
      "metadata": {
        "processed_at": "2025-09-11T20:12:59.158336+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "d139648a051909c4baae92218ad035aa",
      "url": "https://www.biorxiv.org/content/10.1101/2025.09.10.675377v1?rss=1",
      "title": "Fractionation of sex differences in human cortical anatomy",
      "content": "Humans show reproducible sex differences in regional cortical volume (CV), but it remains unclear how these arise from underlying sex-biases in the two biologically dissociable determinants of CV: surface area (SA) and cortical thickness (CT). Moreover, limited access to experimental methods in humans has hindered direct studies of the causal drivers of regional sex differences in the human cortex, although rodent models have argued for both chromosomal and gonadal contributions to sex-biased mammalian cortical development. Here, we first use structural neuroimaging data in two independent human cohorts (combined N=1,754; 967 females) to quantify and spatially resolve the differential contributions of SA and CT to observed sex differences in CV. These dissociable facets of sex-biased cortical organization are highly reproducible and align with distinct functional networks and histo-molecular signatures. We then leverage complementary neuroimaging data in clinical case-control cohorts (combined N=313) featuring variations in X and Y chromosome dosage (sex chromosome aneuploidies) and testicular hormone production (isolated GnRH deficiency) to establish that regions of sex-biased CV, SA and CT in humans are enriched for congruent anatomical effects of X-chromosome dosage (e.g., primary sensory and insular cortices) and gonadal hormones (e.g. dorsomedial frontal and temporo-parietal-occipital regions). Taken together, these findings substantially advance both the breadth and granularity of our understanding regarding sex-biased cortical organization in humans - disambiguating sex effects on regional CV, SA and CT and nominating their potential genetic and endocrine causes.",
      "author": "Lee, H. M., Liu, S., Guma, E., Levitis, E., Shafee, R., Dugan, G., Lalonde, F. M., Clasen, L., DeCasien, A., Chakravarty, M., Lerch, J., Wagstyl, K., Delaney, A., Raznahan, A.",
      "published_date": "2025-09-11T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 232,
      "reading_time": 1,
      "created_at": "2025-09-11T19:38:27.750650+00:00",
      "updated_at": "2025-09-11T20:12:59.158338+00:00",
      "metadata": {
        "processed_at": "2025-09-11T20:12:59.158340+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "62d10b7050974a302f68ca6494a4a401",
      "url": "https://www.biorxiv.org/content/10.1101/2025.09.10.675374v1?rss=1",
      "title": "Spatiomolecular mapping reveals anatomical organization of heterogeneous cell types in the human nucleus accumbens",
      "content": "The nucleus accumbens (NAc) is a key component of the mesolimbic dopamine system that critically regulates many behaviors related to reward and motivation. The NAc is implicated in several neuropsychiatric disorders, including major depressive disorder, schizophrenia, and substance use disorders. Rodent studies have identified spatial organization of heterogeneous medium spiny neuron (MSN) subtypes across the NAc core and shell, but the extent to which this cellular diversity and spatial organization is conserved in the human brain remains unclear. Here, we generated a spatiomolecular atlas of NAc cell types and spatial domains by integrating spatial transcriptomics and single-nucleus RNA sequencing data from postmortem NAc tissue from 10 neurotypical adult donors. We identified 20 transcriptionally unique cell populations and 8 spatial domains, including specialized D1 islands composed of distinct dopamine receptor 1 (DRD1) MSN subtypes, which were enriched for OPRM1. In contrast to a discrete core vs. shell division, we observed continuous spatial gradients of gene expression across MSN domains, suggesting a more complex organization of DRD1 and DRD2 MSNs. Cross-species comparisons demonstrated conservation of MSN subtypes and spatial features between human, rodent, and nonhuman primate NAc. Genetic enrichment analysis with stratified linkage disequilibrium score regression revealed specific spatial domains associated with risk for psychiatric and addiction-related traits. To investigate this further, we spatially mapped ligand-receptor interactions involving neuropsychiatric risk genes. Finally, we leveraged existing rodent NAc data to identify drug-responsive transcriptional programs and predict their spatial distribution in the human NAc. Collectively, we provide a spatiomolecular framework for understanding the human NAc and its relevance to neuropsychiatric disease.",
      "author": "Ravichandran, P., Bach, S. V., Phillips, R. A., Valentine, M. R., Eagles, N. J., Du, Y., Rosario, I. D., Miller, R. A., Divecha, H. R., Tippani, M., Montgomery, K. D., Kleinman, J. E., Han, S., Page, S. C., Hyde, T. M., Torres, L. C., Battle, A., Martinowich, K., Hicks, S. C., Maynard, K.",
      "published_date": "2025-09-11T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 257,
      "reading_time": 1,
      "created_at": "2025-09-11T19:38:27.750613+00:00",
      "updated_at": "2025-09-11T20:12:59.158342+00:00",
      "metadata": {
        "processed_at": "2025-09-11T20:12:59.158344+00:00",
        "processing_method": "github_actions"
      }
    }
  ]
}