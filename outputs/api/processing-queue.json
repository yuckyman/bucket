{
  "last_updated": "2026-01-26T06:30:20.357598+00:00",
  "pending_count": 706,
  "processed_count": 294,
  "pending_articles": [
    {
      "id": "dfe659db88246ddf53f2222fcde9bbdb",
      "url": "https://whythere.life",
      "title": "Show HN: WhyThere \u2013 Compare cities side-by-side to decide where to move",
      "content": "<p>Article URL: <a href=\"https://whythere.life\">https://whythere.life</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46761547\">https://news.ycombinator.com/item?id=46761547</a></p>\n<p>Points: 4</p>\n<p># Comments: 0</p>",
      "author": "daversa",
      "published_date": "2026-01-26T03:31:02+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2026-01-26T05:54:54.750921+00:00",
      "updated_at": "2026-01-26T05:54:54.750923+00:00"
    },
    {
      "id": "e383bc2b59fb44dc82d633e65d9f0289",
      "url": "https://arxiv.org/abs/2601.16751",
      "title": "\"What I Sign Is Not What I See\": Towards Explainable and Trustworthy Cryptocurrency Wallet Signatures",
      "content": "arXiv:2601.16751v1 Announce Type: new \nAbstract: Cryptocurrency wallets have become the primary gateway to decentralized applications, yet users often face significant difficulty in discerning what a wallet signature actually does or entails. Prior work has mainly focused on mitigating protocol vulnerabilities, with limited attention to how users perceive and interpret what they are authorizing. To examine this usability-security gap, we conducted two formative studies investigating how users interpret authentic signing requests and what cues they rely on to assess risk. Findings reveal that users often misread critical parameters, underestimate high-risk signatures, and rely on superficial familiarity rather than understanding transaction intent. Building on these insights, we designed the Signature Semantic Decoder -- a prototype framework that reconstructs and visualizes the intent behind wallet signatures prior to confirmation. Through structured parsing and semantic labeling, it demonstrates how signing data can be transformed into plain-language explanations with contextual risk cues. In a between-subjects user study (N = 128), participants using the prototype achieved higher accuracy in identifying risky signatures, improved clarity and decision confidence, and lower cognitive workload compared with the baseline wallet interface. Our study reframes wallet signing as a problem of interpretability within secure interaction design and offers design implications for more transparent and trustworthy cryptocurrency wallet interfaces.",
      "author": "Yuyang Qin, Haihan Duan",
      "published_date": "2026-01-26T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 207,
      "reading_time": 1,
      "created_at": "2026-01-26T05:09:16.594029+00:00",
      "updated_at": "2026-01-26T05:09:16.594031+00:00"
    },
    {
      "id": "603f5e7b36b624f184a171681bb88d1d",
      "url": "https://arxiv.org/abs/2601.16740",
      "title": "Evaluating Generative AI in the Lab: Methodological Challenges and Guidelines",
      "content": "arXiv:2601.16740v1 Announce Type: new \nAbstract: Generative AI (GenAI) systems are inherently non-deterministic, producing varied outputs even for identical inputs. While this variability is central to their appeal, it challenges established HCI evaluation practices that typically assume consistent and predictable system behavior. Designing controlled lab studies under such conditions therefore remains a key methodological challenge. We present a reflective multi-case analysis of four lab-based user studies with GenAI-integrated prototypes, spanning conversational in-car assistant systems and image generation tools for design workflows. Through cross-case reflection and thematic analysis across all study phases, we identify five methodological challenges and propose eighteen practice-oriented recommendations, organized into five guidelines. These challenges represent methodological constructs that are either amplified, redefined, or newly introduced by GenAI's stochastic nature: (C1) reliance on familiar interaction patterns, (C2) fidelity-control trade-offs, (C3) feedback and trust, (C4) gaps in usability evaluation, and (C5) interpretive ambiguity between interface and system issues. Our guidelines address these challenges through strategies such as reframing onboarding to help participants manage unpredictability, extending evaluation with constructs such as trust and intent alignment, and logging system events, including hallucinations and latency, to support transparent analysis. This work contributes (1) a methodological reflection on how GenAI's stochastic nature unsettles lab-based HCI evaluation and (2) eighteen recommendations that help researchers design more transparent, robust, and comparable studies of GenAI systems in controlled settings.",
      "author": "Hyerim Park, Khanh Huynh, Malin Eiband, Jeremy Dillmann, Sven Mayer, Michael Sedlmair",
      "published_date": "2026-01-26T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 222,
      "reading_time": 1,
      "created_at": "2026-01-26T05:09:16.593972+00:00",
      "updated_at": "2026-01-26T05:09:16.593973+00:00"
    },
    {
      "id": "9fa3c46cf1a7f3a82b07533b781262ce",
      "url": "https://arxiv.org/abs/2601.16720",
      "title": "Watching AI Think: User Perceptions of Visible Thinking in Chatbots",
      "content": "arXiv:2601.16720v1 Announce Type: new \nAbstract: People increasingly turn to conversational agents such as ChatGPT to seek guidance for their personal problems. As these systems grow in capability, many now display elements of \"thinking\": short reflective statements that reveal a model's intentions or values before responding. While initially introduced to promote transparency, such visible thinking can also anthropomorphise the agent and shape user expectations. Yet little is known about how these displays affect user perceptions in help-seeking contexts. We conducted a 3 x 2 mixed design experiment examining the impact of 'Thinking Content' (None, Emotionally-Supportive, Expertise-Supportive) and 'Conversation Context' (Habit-related vs. Feelings-related problems) on users' perceptions of empathy, warmth, competence, and engagement. Participants interacted with a chatbot that either showed no visible thinking or presented value-oriented reflections prior to its response. Our findings contribute to understanding how thinking transparency influences user experience in supportive dialogues, and offer implications for designing conversational agents that communicate intentions in sensitive, help-seeking scenarios.",
      "author": "Samuel Rhys Cox, Jade Martin-Lise, Simo Hosio, Niels van Berkel",
      "published_date": "2026-01-26T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 158,
      "reading_time": 1,
      "created_at": "2026-01-26T05:09:16.593937+00:00",
      "updated_at": "2026-01-26T05:09:16.593939+00:00"
    },
    {
      "id": "3d6b80db15af6d50433f812764d054db",
      "url": "https://arxiv.org/abs/2601.16708",
      "title": "Make the Unhearable Visible: Exploring Visualization for Musical Instrument Practice",
      "content": "arXiv:2601.16708v1 Announce Type: new \nAbstract: We explore the potential of visualization to support musicians in instrument practice through real-time feedback and reflection on their playing. Musicians often struggle to observe the patterns in their playing and interpret them with respect to their goals. Our premise is that these patterns can be made visible with interactive visualization: we can make the unhearable visible. However, understanding the design of such visualizations is challenging: the diversity of needs, including different instruments, skills, musical attributes, and genres, means that any single use case is unlikely to illustrate the broad potential and opportunities. To address this challenge, we conducted a design exploration study where we created and iterated on 33 designs, each focusing on a subset of needs, for example, only one musical skill. Our designs are grounded in our own experience as musicians and the ideas and feedback of 18 musicians with various musical backgrounds and we evaluated them with 13 music learners and teachers. This paper presents the results of our exploration, focusing on a few example designs as instances of possible instrument practice visualizations. From our work, we draw design considerations that contribute to future research and products for visual instrument education.",
      "author": "Frank Heyen, Michael Gleicher, Michael Sedlmair",
      "published_date": "2026-01-26T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 200,
      "reading_time": 1,
      "created_at": "2026-01-26T05:09:16.593907+00:00",
      "updated_at": "2026-01-26T05:09:16.593909+00:00"
    },
    {
      "id": "1ae28e271aa3d1e7a16f2adaa0cebd45",
      "url": "https://arxiv.org/abs/2601.16658",
      "title": "Talking about privacy always feels like opening a can of worms. How Intimate Partners Navigate Boundary-Setting in Mobile Phone Without Words",
      "content": "arXiv:2601.16658v1 Announce Type: new \nAbstract: Mobile phones, as simultaneously personal and shared technologies, complicate how partners manage digital privacy in intimate relationships. While prior research has examined device-access practices, explicit privacy-rule negotiation, and toxic practices such as surveillance, little is known about how couples manage digital privacy without direct discussion in everyday relationships. To address this gap, we ask: How is digital privacy managed nonverbally and across different media on mobile phones? Drawing on 20 semi-structured interviews, we find that partners often regulate privacy practices through privacy silence -- the intentional avoidance of privacy-related conversations. We identify five motivations for leaving boundaries unspoken: perceiving privacy as unnecessary in intimacy, assuming implicit respect for boundaries, signaling trust and closeness, avoiding potential conflict or harm, and responding to broader societal and cultural expectations that discourage explicit privacy talk. We also identify a hierarchical grouping of content-specific privacy sensitivities, ranging from highly private domains such as financial data to lower-risk domains such as streaming accounts, and show how these priorities shift across relationship stages. These findings show how silence, culture, and content sensitivity shape everyday boundary-setting and underscore the relational and emotional dynamics underpinning mobile phone privacy management.",
      "author": "Sima Amirkhani, Mahla Fatemeh Alizadeh, Farzaneh Gerami, Dave Randall, Gunnar Stevens",
      "published_date": "2026-01-26T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 195,
      "reading_time": 1,
      "created_at": "2026-01-26T05:09:16.593875+00:00",
      "updated_at": "2026-01-26T05:09:16.593877+00:00"
    },
    {
      "id": "18e3561f6977d3718834d2bc7baea9f5",
      "url": "https://arxiv.org/abs/2601.16656",
      "title": "Generative Confidants: How do People Experience Trust in Emotional Support from Generative AI?",
      "content": "arXiv:2601.16656v1 Announce Type: new \nAbstract: People are increasingly turning to generative AI (e.g., ChatGPT, Gemini, Copilot) for emotional support and companionship. While trust is likely to play a central role in enabling these informal and unsupervised interactions, we still lack an understanding of how people develop and experience it in this context. Seeking to fill this gap, we recruited 24 frequent users of generative AI for emotional support and conducted a qualitative study consisting of diary entries about interactions, transcripts of chats with AI, and in-depth interviews. Our results suggest important novel drivers of trust in this context: familiarity emerging from personalisation, nuanced mental models of generative AI, and awareness of people's control over conversations. Notably, generative AI's homogeneous use of personalised, positive, and persuasive language appears to promote some of these trust-building factors. However, this also seems to discourage other trust-related behaviours, such as remembering that generative AI is a machine trained to converse in human language. We present implications for future research that are likely to become critical as the use of generative AI for emotional support increasingly overlaps with therapeutic work.",
      "author": "Riccardo Volpato, Simone Stumpf, Lisa DeBruine",
      "published_date": "2026-01-26T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 184,
      "reading_time": 1,
      "created_at": "2026-01-26T05:09:16.593842+00:00",
      "updated_at": "2026-01-26T05:09:16.593843+00:00"
    },
    {
      "id": "c134d07d443febf041111707408cb4ed",
      "url": "https://arxiv.org/abs/2601.16639",
      "title": "HapticMatch: An Exploration for Generative Material Haptic Simulation and Interaction",
      "content": "arXiv:2601.16639v1 Announce Type: new \nAbstract: High-fidelity haptic feedback is essential for immersive virtual environments, yet authoring realistic tactile textures remains a significant bottleneck for designers. We introduce HapticMatch, a visual-to-tactile generation framework designed to democratize haptic content creation. We present a novel dataset containing precisely aligned pairs of micro-scale optical images, surface height maps, and friction-induced vibrations for 100 diverse materials. Leveraging this data, we explore and demonstrate that conditional generative models like diffusion and flow-matching can synthesize high-fidelity, renderable surface geometries directly from standard RGB photos. By enabling a \"Scan-to-Touch\" workflow, HapticMatch allows interaction designers to rapidly prototype multimodal surface sensations without specialized recording equipment, bridging the gap between visual and tactile immersion in VR/AR interfaces.",
      "author": "Mingxin Zhang, Yu Yao, Yasutoshi Makino, Hiroyuki Shinoda, Masashi Sugiyama",
      "published_date": "2026-01-26T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 117,
      "reading_time": 1,
      "created_at": "2026-01-26T05:09:16.593810+00:00",
      "updated_at": "2026-01-26T05:09:16.593811+00:00"
    },
    {
      "id": "33e9db9396c2e163efd84f9b4bca0d5d",
      "url": "https://arxiv.org/abs/2601.16583",
      "title": "Who You Explain To Matters: Learning by Explaining to Conversational Agents with Different Pedagogical Roles",
      "content": "arXiv:2601.16583v1 Announce Type: new \nAbstract: Conversational agents are increasingly used in education for learning support. An application is \"learning by explaining\", where learners explain their understanding to an agent. However, existing research focuses on single roles, leaving it unclear how different pedagogical roles influence learners' interaction patterns, learning outcomes and experiences. We conducted a between-subjects study (N=96) comparing agents with three pedagogical roles (Tutee, Peer, Challenger) and a control condition while learning an economics concept. We found that different pedagogical roles shaped learning dynamics, including interaction patterns and experiences. Specifically, the Tutee agent elicited the most cognitive investment but led to high pressure. The Peer agent fostered high absorption and interest through collaborative dialogue. The Challenger agent promoted cognitive and metacognitive acts, enhancing critical thinking with moderate pressure. The findings highlight how agent roles shape different learning dynamics, guiding the design of educational agents tailored to specific pedagogical goals and learning phases.",
      "author": "Zhengtao Xu, Junti Zhang, Anthony Tang, Yi-Chieh Lee",
      "published_date": "2026-01-26T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 152,
      "reading_time": 1,
      "created_at": "2026-01-26T05:09:16.593782+00:00",
      "updated_at": "2026-01-26T05:09:16.593784+00:00"
    },
    {
      "id": "52baa9cba2dec1cdf3cf7511400e6755",
      "url": "https://arxiv.org/abs/2601.16356",
      "title": "The Behavioral Fabric of LLM-Powered GUI Agents: Human Values and Interaction Outcomes",
      "content": "arXiv:2601.16356v1 Announce Type: new \nAbstract: Large Language Model (LLM)-powered web GUI agents are increasingly automating everyday online tasks. Despite their popularity, little is known about how users' preferences and values impact agents' reasoning and behavior. In this work, we investigate how both explicit and implicit user preferences, as well as the underlying user values, influence agent decision-making and action trajectories. We built a controlled testbed of 14 common interactive web tasks, spanning shopping, travel, dining, and housing, each replicated from real websites and integrated with a low-fidelity LLM-based recommender system. We injected 12 human preferences and values as personas into four state-of-the-art agents and systematically analyzed their task behaviors. Our results show that preference and value-infused prompts consistently guided agents toward outcomes that reflected these preferences and values. While the absence of user preference or value guidance led agents to exhibit a strong efficiency bias and employ shortest-path strategies, their presence steered agents' behavior trajectories through the greater use of corresponding filters and interactive web features. Despite their influence, dominant interface cues, such as discounts and advertisements, frequently overrode these effects, shortening the agents' action trajectories and inducing rationalizations that masked rather than reflected value-consistent reasoning. The contributions of this paper are twofold: (1) an open-source testbed for studying the influence of values in agent behaviors, and (2) an empirical investigation of how user preferences and values shape web agent behaviors.",
      "author": "Simret Araya Gebreegziabher, Yukun Yang, Charles Chiang, Hojun Yoo, Chaoran Chen, Hyo Jin Do, Zahra Ashktorab, Werner Geyer, Diego G\\'omez-Zar\\'a, Toby Jia-Jun Li",
      "published_date": "2026-01-26T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 231,
      "reading_time": 1,
      "created_at": "2026-01-26T05:09:16.593750+00:00",
      "updated_at": "2026-01-26T05:09:16.593752+00:00"
    }
  ],
  "recently_processed": [
    {
      "id": "9b7968741403d6b479424052728c8879",
      "url": "http://ieeexplore.ieee.org/document/10856260",
      "title": "Front Cover",
      "content": "null",
      "author": "",
      "published_date": "2025-01-28T13:17:19+00:00",
      "source": "Reviews Biomedical Engineering",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 1,
      "reading_time": 1,
      "created_at": "2026-01-26T05:55:49.913086+00:00",
      "updated_at": "2026-01-26T06:30:20.249998+00:00",
      "metadata": {
        "processed_at": "2026-01-26T06:30:20.250007+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "7441f8a9c001207bbbea8adb1642b1f2",
      "url": "https://www.nature.com/articles/s41593-025-02192-x",
      "title": "Who delivers evidence matters",
      "content": "<p>Nature Neuroscience, Published online: 07 January 2026; <a href=\"https://www.nature.com/articles/s41593-025-02192-x\">doi:10.1038/s41593-025-02192-x</a></p>Who delivers evidence matters",
      "author": "Henrietta Howells",
      "published_date": "2026-01-07T00:00:00+00:00",
      "source": "Nature Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 12,
      "reading_time": 1,
      "created_at": "2026-01-26T05:55:34.109199+00:00",
      "updated_at": "2026-01-26T06:30:20.250012+00:00",
      "metadata": {
        "processed_at": "2026-01-26T06:30:20.250014+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "8d486873b6728e5969fb54b3a44976e8",
      "url": "https://www.frontiersin.org/articles/10.3389/fninf.2025.1679196",
      "title": "Cross-modal privacy-preserving synthesis and mixture-of-experts ensemble for robust ASD prediction",
      "content": "IntroductionAutism Spectrum Disorder (ASD) diagnosis remains complex due to limited access to large-scale multimodal datasets and privacy concerns surrounding clinical data. Traditional methods rely heavily on resource-intensive clinical assessments and are constrained by unimodal or non-adaptive learning models. To address these limitations, this study introduces AutismSynthGen, a privacy-preserving framework for synthesizing multimodal ASD data and enhancing prediction accuracy.Materials and methodsThe proposed system integrates a Multimodal Autism Data Synthesis Network (MADSN), which employs transformer-based encoders and cross-modal attention within a conditional GAN to generate synthetic data across structural MRI, EEG, behavioral vectors, and severity scores. Differential privacy is enforced via DP-SGD (\u03b5\u202f\u2264\u202f1.0). A complementary Adaptive Multimodal Ensemble Learning (AMEL) module, consisting of five heterogeneous experts and a gating network, is trained on both real and synthetic data. Evaluation is conducted on the ABIDE, NDAR, and SSC datasets using metrics such as AUC, F1 score, MMD, KS statistic, and BLEU.ResultsSynthetic augmentation improved model performance, yielding validation AUC gains of \u2265 0.04. AMEL achieved an AUC of 0.98 and an F1 score of 0.99 on real data and approached near-perfect internal performance (AUC\u202f\u2248\u202f1.00, F1\u202f\u2248\u202f1.00) when synthetic data were included. Distributional metrics (MMD\u202f=\u202f0.04; KS\u202f=\u202f0.03) and text similarity (BLEU\u202f=\u202f0.70) demonstrated high fidelity between the real and synthetic samples. Ablation studies confirmed the importance of cross-modal attention and entropy-regularized expert gating.DiscussionAutismSynthGen offers a scalable, privacy-compliant solution for augmenting limited multimodal datasets and enhancing ASD prediction. Future directions include semi-supervised learning, explainable AI for clinical trust, and deployment in federated environments to broaden accessibility while maintaining privacy.",
      "author": "Karthiga M.",
      "published_date": "2025-11-19T00:00:00+00:00",
      "source": "Frontiers Neuroinformatics",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 262,
      "reading_time": 1,
      "created_at": "2026-01-26T05:55:29.146974+00:00",
      "updated_at": "2026-01-26T06:30:20.250017+00:00",
      "metadata": {
        "processed_at": "2026-01-26T06:30:20.250018+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "051b00eb368bb3d8d8ce021fb514a810",
      "url": "https://fmhy.net/posts/changelog-sites",
      "title": "Changelog Sites",
      "content": "<p><strong><a href=\"https://changes.fmhy.bid/\" rel=\"noreferrer\" target=\"_blank\">https://changes.fmhy.bid/</a></strong></p>\n<p>This covers changes that occur in both the #Recently-Added and #Monthly-Update channels in our Discord.</p>\n<hr />\n<p><strong><a href=\"https://fmhy-tracker.pages.dev/\" rel=\"noreferrer\" target=\"_blank\">https://fmhy-tracker.pages.dev/</a></strong></p>\n<p>This covers links that have been added, updated, or removed by watching GitHub for changes.</p>\n<hr />\n<p>Note that we will also continue to make the monthly posts same as always, and you can still follow updates by joining our <a href=\"https://redd.it/17f8msf\" rel=\"noreferrer\" target=\"_blank\">Discord</a>, or watching the <a href=\"https://github.com/fmhy/edit/commits/main/\" rel=\"noreferrer\" target=\"_blank\">Commits Page</a> on GitHub yourself.</p>\n<p>We hope you guys like them, if you have any suggestions or questions feel free to let us know.</p>",
      "author": "",
      "published_date": "2025-12-12T00:00:00+00:00",
      "source": "Fmhy",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 99,
      "reading_time": 1,
      "created_at": "2026-01-26T05:54:58.496432+00:00",
      "updated_at": "2026-01-26T06:30:20.250021+00:00",
      "metadata": {
        "processed_at": "2026-01-26T06:30:20.250022+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "23e750187081436c0ce9ec098162cd82",
      "url": "https://microclimates.solofounders.com/",
      "title": "SF Microclimates",
      "content": "<p>Article URL: <a href=\"https://microclimates.solofounders.com/\">https://microclimates.solofounders.com/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46761219\">https://news.ycombinator.com/item?id=46761219</a></p>\n<p>Points: 9</p>\n<p># Comments: 0</p>",
      "author": "rmason",
      "published_date": "2026-01-26T02:38:55+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2026-01-26T05:54:54.750941+00:00",
      "updated_at": "2026-01-26T06:30:20.250025+00:00",
      "metadata": {
        "processed_at": "2026-01-26T06:30:20.250026+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "8833e50834715c781e18728053121c1b",
      "url": "https://www.nature.com/articles/s41593-025-02193-w",
      "title": "Neuropixels go ultra",
      "content": "<p>Nature Neuroscience, Published online: 07 January 2026; <a href=\"https://www.nature.com/articles/s41593-025-02193-w\">doi:10.1038/s41593-025-02193-w</a></p>Neuropixels go ultra",
      "author": "Luis A. Mejia",
      "published_date": "2026-01-07T00:00:00+00:00",
      "source": "Nature Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 11,
      "reading_time": 1,
      "created_at": "2026-01-26T04:03:09.442578+00:00",
      "updated_at": "2026-01-26T04:52:14.575627+00:00",
      "metadata": {
        "processed_at": "2026-01-26T04:52:14.575640+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "c6cc6c0b308e5a4481cc864c896cba8b",
      "url": "https://iopscience.iop.org/article/10.1088/1741-2552/ae2f01",
      "title": "Potential of EEG and EEG/MEG skull conductivity estimation to improve source analysis in presurgical evaluation of epilepsy",
      "content": "Objective. Conductivity estimation exploiting evoked potentials and fields is a promising method to reduce the uncertainty of electroencephalography (EEG) and combined EEG/magnetoencephalography (MEG) source analysis due to inter-individual variations of tissue conductivities. Approaches for skull conductivity estimation based on evoked potentials and fields have been proposed in several studies, but the current knowledge about their sensitivity towards uncertainties of other tissue conductivities and the effects on source analysis accuracy is insufficient. In this study, we analyze this sensitivity for EEG and EEG/MEG skull conductivity estimation and to what extent skull conductivity estimation improves the EEG, MEG, and combined EEG/MEG source analysis of interictal epileptic discharges (IEDs). Approach. We simulated EEG and MEG measurements of evoked brain activity and IEDs for randomly assigned tissue conductivities and performed EEG and EEG/MEG skull conductivity estimation for the simulated measurements. Following, we performed EEG, MEG, and combined EEG/MEG source analysis of the simulated IEDs and compared the results with and without using the individually estimated skull conductivities. Main results. We find that EEG/MEG skull conductivity estimation is more accurate than EEG skull conductivity estimation, especially when considering realistic noise levels, whereas the type of the evoked brain activity only had a minor influence on the accuracy of the conductivity estimation. Both EEG and EEG/MEG skull conductivity estimation clearly improve source analysis accuracy for EEG and combined EEG/MEG source analysis, reducing the uncertainty of the source localization from a few centimeters to less than one centimeter for most sources. However, we find that the effect of the conductivity estimation is less pronounced for sources at the base of the brain. Significance. EEG and EEG/MEG conductivity estimation exploiting evoked potentials and fields has the potential to become a valuable tool to reduce uncertainty in source analysis of IEDs, while it only requires little additional measurement effort.",
      "author": "Johannes Vorwerk, Stefan Rampp, Carsten H Wolters and Daniel Baumgarten",
      "published_date": "2026-01-12T00:00:00+00:00",
      "source": "Journal Neural Engineering",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 300,
      "reading_time": 1,
      "created_at": "2026-01-26T04:02:56.689121+00:00",
      "updated_at": "2026-01-26T04:52:14.575644+00:00",
      "metadata": {
        "processed_at": "2026-01-26T04:52:14.575646+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "7867db2ff2fdadad4b4707273879b191",
      "url": "https://www.reddit.com/r/Python/comments/1qn3wfi/python_modules_retry_framework_openssh_client_w/",
      "title": "Python modules: retry framework, OpenSSH client w/ fast conn pooling, and parallel task-tree schedul",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m the author of <code>bzfs</code>, a Python CLI for ZFS snapshot replication across fleets of machines (<a href=\"https://github.com/whoschek/bzfs\">https://github.com/whoschek/bzfs</a>).</p> <p>Building a replication engine forces you to get a few things right: retries must be disciplined (no &quot;accidental retry&quot;), remote command execution must be fast, predictable and scalable, and parallelism must respect hierarchical dependencies.</p> <p>The modules below are the pieces I ended up extracting; they\u2019re Apache-2.0, have zero dependencies, and installed via <code>pip install bzfs</code> (Python <code>&gt;=3.9</code>).</p> <p>Where these fit well:</p> <ul> <li>Wrapping flaky operations with <em>explicit</em>, policy-driven retries (subprocess calls, API calls, distributed systems glue)</li> <li>Running lots of SSH commands with low startup latency (OpenSSH multiplexing + safe pooling)</li> <li>Processing hierarchical resources in parallel without breaking parent/child ordering constraints</li> </ul> <p>Modules:</p> <ul> <li><code>bzfs_main.util.retry</code> \u2014 retries are opt-in via <code>RetryableError</code> (prevents accidental retries), jittered exponential backoff w/ cap, elapsed-time budgets, cancellation + hooks <a href=\"https://github.com/whoschek/bzfs/blob/main/bzfs_main/util/retry.py\">https://github.com/whoschek/bzfs/blob/main/bzfs_main/util/retry.py</a></li> <li><code>bzfs_main.util.connection</code> \u2014 thread-safe SSH command runner + connection pool using OpenSSH multiplexing (ControlMaster/ControlPersist); with <code>connection_lease</code> for safe low latency connection reuse across processes <a href=\"https://github.com/whoschek/bzfs/blob/main/bzfs_main/util/connection.py\">https://github.com/whoschek/bzfs/blob/main/bzfs_main/util/connection.py</a> <a href=\"https://github.com/whoschek/bzfs/blob/main/bzfs_main/util/connection_lease.py\">https://github.com/whoschek/bzfs/blob/main/bzfs_main/util/connection_lease.py</a></li> <li><code>bzfs_main.util.parallel_tasktree</code> \u2014 dependency-aware scheduler for hierarchical workloads (ancestors finish before descendants start), customizable completion callbacks <a href=\"https://github.com/whoschek/bzfs/blob/main/bzfs_main/util/parallel_tasktree.py\">https://github.com/whoschek/bzfs/blob/main/bzfs_main/util/parallel_tasktree.py</a></li> </ul> <p>Example (SSH + retries, self-contained):</p> <pre><code>import logging from subprocess import DEVNULL, PIPE from bzfs_main.util.connection import ( ConnectionPool, create_simple_minijob, create_simple_miniremote, ) from bzfs_main.util.retry import Retry, RetryPolicy, RetryableError, call_with_retries log = logging.getLogger(__name__) remote = create_simple_miniremote(log=log, ssh_user_host=&quot;alice@127.0.0.1&quot;) pool = ConnectionPool(remote, connpool_name=&quot;example&quot;) job = create_simple_minijob() def run_cmd(retry: Retry) -&gt; str: try: with pool.connection() as conn: return conn.run_ssh_command( cmd=[&quot;echo&quot;, &quot;hello&quot;], job=job, check=True, stdin=DEVNULL, stdout=PIPE, stderr=PIPE, text=True, ).stdout except Exception as exc: raise RetryableError(display_msg=&quot;ssh&quot;) from exc retry_policy = RetryPolicy( max_retries=5, min_sleep_secs=0, initial_max_sleep_secs=0.1, max_sleep_secs=2, max_elapsed_secs=30, ) print(call_with_retries(run_cmd, policy=retry_policy, log=log)) pool.shutdown() </code></pre> <p>If you use these modules in non-ZFS automation (deployment tooling, fleet ops, data movement, CI), I\u2019m interested in what you build with them and what you optimize for.</p> <p>Target Audience</p> <p>It is a production ready solution. So everyone is potentially concerned.</p> <p>Comparison</p> <p>Paramiko, Ansible and Tenacity are related tools.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/werwolf9\"> /u/werwolf9 </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1qn3wfi/python_modules_retry_framework_openssh_client_w/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1qn3wfi/python_modules_retry_framework_openssh_client_w/\">[comments]</a></span>",
      "author": "/u/werwolf9",
      "published_date": "2026-01-26T02:50:18+00:00",
      "source": "Reddit Python",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 342,
      "reading_time": 1,
      "created_at": "2026-01-26T04:02:34.599681+00:00",
      "updated_at": "2026-01-26T04:52:14.575649+00:00",
      "metadata": {
        "processed_at": "2026-01-26T04:52:14.575650+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "d411e29ee7202325cb0234d60851c561",
      "url": "https://archive.org/details/DeltaSingleHandleBallFaucets",
      "title": "Delta single handle ball faucets (1963)",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46714981\">Comments</a>",
      "author": "",
      "published_date": "2026-01-22T03:37:03+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-26T04:02:33.255461+00:00",
      "updated_at": "2026-01-26T04:52:14.575653+00:00",
      "metadata": {
        "processed_at": "2026-01-26T04:52:14.575654+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "9f92b84d815600c0117b9aec39a12060",
      "url": "https://www.bbc.co.uk/programmes/m002pqg6",
      "title": "The Science of Fermentation (The Food Programme)",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46733306\">Comments</a>",
      "author": "",
      "published_date": "2026-01-23T15:03:08+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2026-01-26T04:02:33.255442+00:00",
      "updated_at": "2026-01-26T04:52:14.575656+00:00",
      "metadata": {
        "processed_at": "2026-01-26T04:52:14.575658+00:00",
        "processing_method": "github_actions"
      }
    }
  ]
}