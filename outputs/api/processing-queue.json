{
  "last_updated": "2025-12-12T06:26:09.148689+00:00",
  "pending_count": 740,
  "processed_count": 260,
  "pending_articles": [
    {
      "id": "246648cffd19dac9d5a8c65ec237eb29",
      "url": "https://arxiv.org/abs/2512.09931",
      "title": "ExaCraft: Dynamic Learning Context Adaptation for Personalized Educational Examples",
      "content": "arXiv:2512.09931v1 Announce Type: cross \nAbstract: Learning is most effective when it's connected to relevant, relatable examples that resonate with learners on a personal level. However, existing educational AI tools don't focus on generating examples or adapting to learners' changing understanding, struggles, or growing skills. We've developed ExaCraft, an AI system that generates personalized examples by adapting to the learner's dynamic context. Through the Google Gemini AI and Python Flask API, accessible via a Chrome extension, ExaCraft combines user-defined profiles (including location, education, profession, and complexity preferences) with real-time analysis of learner behavior. This ensures examples are both culturally relevant and tailored to individual learning needs. The system's core innovation is its ability to adapt to five key aspects of the learning context: indicators of struggle, mastery patterns, topic progression history, session boundaries, and learning progression signals. Our demonstration will show how ExaCraft's examples evolve from basic concepts to advanced technical implementations, responding to topic repetition, regeneration requests, and topic progression patterns in different use cases.",
      "author": "Akaash Chatterjee (Indian Institute of Technology Jodhpur), Suman Kundu (Indian Institute of Technology Jodhpur)",
      "published_date": "2025-12-12T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 165,
      "reading_time": 1,
      "created_at": "2025-12-12T05:24:15.356848+00:00",
      "updated_at": "2025-12-12T05:24:15.356850+00:00"
    },
    {
      "id": "b2f67bf2bd4bdcb2db92ee9f2f6c94ae",
      "url": "https://arxiv.org/abs/2512.10918",
      "title": "CompanionCast: A Multi-Agent Conversational AI Framework with Spatial Audio for Social Co-Viewing Experiences",
      "content": "arXiv:2512.10918v1 Announce Type: new \nAbstract: Social presence is central to the enjoyment of watching content together, yet modern media consumption is increasingly solitary. We investigate whether multi-agent conversational AI systems can recreate the dynamics of shared viewing experiences across diverse content types. We present CompanionCast, a general framework for orchestrating multiple role-specialized AI agents that respond to video content using multimodal inputs, speech synthesis, and spatial audio. Distinctly, CompanionCast integrates an LLM-as-a-Judge module that iteratively scores and refines conversations across five dimensions (relevance, authenticity, engagement, diversity, personality consistency). We validate this framework through sports viewing, a domain with rich dynamics and strong social traditions, where a pilot study with soccer fans suggests that multi-agent interaction improves perceived social presence compared to solo viewing. We contribute: (1) a generalizable framework for orchestrating multi-agent conversations around multimodal video content, (2) a novel evaluator-agent pipeline for conversation quality control, and (3) exploratory evidence of increased social presence in AI-mediated co-viewing. We discuss challenges and future directions for applying this approach to diverse viewing contexts including entertainment, education, and collaborative watching experiences.",
      "author": "Yiyang Wang, Chen Chen, Tica Lin, Vishnu Raj, Josh Kimball, Alex Cabral, Josiah Hester",
      "published_date": "2025-12-12T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 178,
      "reading_time": 1,
      "created_at": "2025-12-12T05:24:15.356818+00:00",
      "updated_at": "2025-12-12T05:24:15.356819+00:00"
    },
    {
      "id": "93276278ba05c7e2b111e6049e86ccfa",
      "url": "https://arxiv.org/abs/2512.10257",
      "title": "Reject or Not?: A Benchmark for Voice Assistant Query Rejection in Smart Home Scenario and an Improved Method Based on LLMs",
      "content": "arXiv:2512.10257v1 Announce Type: new \nAbstract: In smart-home voice assistant scenario, deciding whether to accept or reject a user query is the first step before any downstream processing. To address the limited query-rejection capability of current voice assistants, this paper presents the first Chinese-oriented open-source benchmark and evaluation suite for smart homes, together with a personalized query-rejection method based on large language models. On the data side, we construct the first multimodal query-rejection dataset tailored for domestic scenarios, containing 11,913 manually labeled text-speech pairs that systematically cover twelve typical dialogue types (e.g., chit-chat, non-human sounds, valid commands, ambiguous references, device-irrelevant requests). Fine-grained labels, conversational context and multi-turn information are provided to support both zero-shot and fine-tuning evaluations across language and multimodal large models. On the method side, we propose a three-tier collaborative architecture: first, a Qwen-2.5-3B adapter fine-tuned to model family-agnostic semantic boundaries; second, a dynamic household-level historical dialogue module to capture personalized habits; third, a household-specific RAG knowledge base that explicitly memorizes and revises past false-rejection cases. Experiments show that the proposed approach significantly outperforms zero-shot and fine-tuned general LLMs on the constructed dataset, with pronounced gains in rejection accuracy for family-specific expressions and complex multi-turn scenarios. This work provides a reproducible data foundation, evaluation standard and extensible technical framework for reliability research in smart-home voice interaction.",
      "author": "Huichao Men, Yizhen Hu, Yingyang He, Yu Gao, Xiaofeng Mou, Yi Xu",
      "published_date": "2025-12-12T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 217,
      "reading_time": 1,
      "created_at": "2025-12-12T05:24:15.356785+00:00",
      "updated_at": "2025-12-12T05:24:15.356787+00:00"
    },
    {
      "id": "572d170170bf86e9aea3b2f7de3ced85",
      "url": "https://arxiv.org/abs/2512.10234",
      "title": "InFerActive: Towards Scalable Human Evaluation of Large Language Models through Interactive Inference",
      "content": "arXiv:2512.10234v1 Announce Type: new \nAbstract: Human evaluation remains the gold standard for evaluating outputs of Large Language Models (LLMs). The current evaluation paradigm reviews numerous individual responses, leading to significant scalability challenges. LLM outputs can be more efficiently represented as a tree structure, reflecting their autoregressive generation process and stochastic token selection. However, conventional tree visualization cannot scale to the exponentially large trees generated by modern sampling methods of LLMs. To address this problem, we present InFerActive, an interactive inference system for scalable human evaluation. InFerActive enables on-demand exploration through probability-based filtering and evaluation features, while bridging the semantic gap between computational tokens and human-readable text through adaptive visualization techniques. Through a technical evaluation and user study (N=12), we demonstrate that InFerActive significantly improves evaluation efficiency and enables more comprehensive assessment of model behavior. We further conduct expert case studies that demonstrate InFerActive's practical applicability and potential for transforming LLM evaluation workflows.",
      "author": "Junhyeong Hwangbo, Soohyun Lee, Minsoo Cheong, Hyeon Jeon, Jinwook Seo",
      "published_date": "2025-12-12T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 152,
      "reading_time": 1,
      "created_at": "2025-12-12T05:24:15.356745+00:00",
      "updated_at": "2025-12-12T05:24:15.356747+00:00"
    },
    {
      "id": "5c8db1c2419d80b9f1dcbc61291c4875",
      "url": "https://arxiv.org/abs/2512.10196",
      "title": "HyFinBall: a Hybrid User Interface for Coordinated 2D+3D Visualization in Semi-Immersive VR",
      "content": "arXiv:2512.10196v1 Announce Type: new \nAbstract: Sophisticated 3D visualization applications usually provide coordinated 2D and 3D views. Normally 3D input device is used for 3D tasks since they perform better than traditional 2D input devices. However, they do not perform better for 2D tasks. This paper presents a bimanual hybrid user interface that supports four interaction modes: a dual 6-degree-of-freedom (DOF) input device mode, a dual planar constrained 3DOF input device mode, a dual 2-finger multi-touch mode, and 3D hand and finger gestures. The application is a multi-dimensional visualization with coordinated 3D and 2D views on a desktop VR system. The input devices are buttonballs with seamless switching between 3D and 2D device modes, as well as between free-hand finger input and device usage. The 3D and 2D device mode switch automatically switches a buttonball's visual representation between a 3D cursor and a 2D cursor while changing the available user interaction techniques between 3D and 2D interaction techniques to interact with the coordinated views. The paper also provides two formal user studies to evaluate HyFinBall for various dimensional tasks, including 3D, 2D, and cross-dimensional tasks. Our experimental results show the benefits of the HyFinBall interface for cross-dimensional tasks that require 3D and 2D interactions.",
      "author": "Isaac Cho, Zachary Wartell",
      "published_date": "2025-12-12T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 203,
      "reading_time": 1,
      "created_at": "2025-12-12T05:24:15.356714+00:00",
      "updated_at": "2025-12-12T05:24:15.356716+00:00"
    },
    {
      "id": "c69bcb50d68d8be4e0dac001c144f3d6",
      "url": "https://arxiv.org/abs/2512.10172",
      "title": "Offscript: Automated Auditing of Instruction Adherence in LLMs",
      "content": "arXiv:2512.10172v1 Announce Type: new \nAbstract: Large Language Models (LLMs) and generative search systems are increasingly used for information seeking by diverse populations with varying preferences for knowledge sourcing and presentation. While users can customize LLM behavior through custom instructions and behavioral prompts, no mechanism exists to evaluate whether these instructions are being followed effectively. We present Offscript, an automated auditing tool that efficiently identifies potential instruction following failures in LLMs. In a pilot study analyzing custom instructions sourced from Reddit, Offscript detected potential deviations from instructed behavior in 86.4% of conversations, 22.2% of which were confirmed as material violations through human review. Our findings suggest that automated auditing serves as a viable approach for evaluating compliance to behavioral instructions related to information seeking.",
      "author": "Nicholas Clark, Ryan Bai, Tanu Mitra",
      "published_date": "2025-12-12T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 123,
      "reading_time": 1,
      "created_at": "2025-12-12T05:24:15.356672+00:00",
      "updated_at": "2025-12-12T05:24:15.356678+00:00"
    },
    {
      "id": "bafd3e4b8432b24bbc745812beb5ada4",
      "url": "https://arxiv.org/abs/2507.01098",
      "title": "Proof of a perfect platonic representation hypothesis",
      "content": "arXiv:2507.01098v2 Announce Type: replace-cross \nAbstract: In this note, we elaborate on and explain in detail the proof given by Ziyin et al. (2025) of the ``perfect\" Platonic Representation Hypothesis (PRH) for the embedded deep linear network model (EDLN). We show that if trained with the stochastic gradient descent (SGD), two EDLNs with different widths and depths and trained on different data will become Perfectly Platonic, meaning that every possible pair of layers will learn the same representation up to a rotation. Because most of the global minima of the loss function are not Platonic, that SGD only finds the perfectly Platonic solution is rather extraordinary. The proof also suggests at least six ways the PRH can be broken. We also show that in the EDLN model, the emergence of the Platonic representations is due to the same reason as the emergence of progressive sharpening. This implies that these two seemingly unrelated phenomena in deep learning can, surprisingly, have a common cause. Overall, the theory and proof highlight the importance of understanding emergent \"entropic forces\" due to the irreversibility of SGD training and their role in representation learning. The goal of this note is to be instructive while avoiding jargon and lengthy technical details.",
      "author": "Liu Ziyin, Isaac Chuang",
      "published_date": "2025-12-12T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 203,
      "reading_time": 1,
      "created_at": "2025-12-12T05:24:14.152299+00:00",
      "updated_at": "2025-12-12T05:24:14.152301+00:00"
    },
    {
      "id": "783f12d737d787f62baa6b1acfd0999f",
      "url": "https://arxiv.org/abs/2509.04454",
      "title": "Mechanisms for anesthesia, unawareness, respiratory depression, memory replay and sleep: MHb > IPN > PAG + DRN + MRN > claustrum > cortical slow waves",
      "content": "arXiv:2509.04454v3 Announce Type: replace \nAbstract: My findings show what causes loss of awareness, anesthesia, memory replay, opioid induced respiratory depression (OIRD), and slow-wave sleep (SWS). Opiates are fast pain relievers and anesthetics that can cause respiratory arrest. I found how mu-opioids and anesthetics by activating medial habenula (MHb) and/or interpeduncular nucleus (IPN) induce unawareness and slowdown respiration. MHb projects to IPN and both increase their glucose intake during anesthesia (Herkenham, 1981). The question is: What is the MHb-IPN circuit doing? I found that it promotes SWS, memory replay, sharp-wave ripples, spindles, hippocampo-cortical replay, synaptogenesis, rest and recovery, by activating median raphe (MRN) serotonin, and by inhibiting the theta state circuit, new memories encoding, awareness, arousal, alert wakefulness, and REM sleep. It causes also natural slowdown of respiration and heart rate, while it inhibits locomotion and arousal. This extended model adds role of the dentate gyrus>posterior septum>MHb>IPN>MRN>hippocampus + BF + claustrum>cortical slow-waves in memory replay, ripples, loss of awareness, SWS, and anesthesia. It proposes new neural mechanism for anesthetic ketamine, nitrous oxide, and phencyclidine effects: activation of the IPN>MRN>claustrum>cortical SWA circuit by the 5-HT2a receptors in the IPN and claustrum. My model shows why are ketamine and psychedelics anxiolytic and antidepressant. How they by activating the 5-HT2a receptors in vACC/infralimbic cortex increase safety, well-being signal, socializing, and cognitive flexibility, and attenuate fear, worries, anger, impulsivity, self-defence, and wanting. This model claims that mu-opioids, acetylcholine, nicotine, endocannabinoids, adenosine, GLP-1RA, and substance P activate the MHb-IPN-MRN circuit which promotes rest, recovery, repair, serotonin-BDNF-protein production, spines growth, and anti-inflammatory state.",
      "author": "Karin Vadovi\\v{c}ov\\'a",
      "published_date": "2025-12-12T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 256,
      "reading_time": 1,
      "created_at": "2025-12-12T05:24:14.152212+00:00",
      "updated_at": "2025-12-12T05:24:14.152213+00:00"
    },
    {
      "id": "de360f3f476ad0416e00b0ce3c4513c8",
      "url": "https://arxiv.org/abs/2502.15440",
      "title": "State-space kinetic Ising model reveals task-dependent entropy flow in sparsely active nonequilibrium neuronal dynamics",
      "content": "arXiv:2502.15440v3 Announce Type: replace \nAbstract: Neuronal ensemble activity, including coordinated and oscillatory patterns, exhibits hallmarks of nonequilibrium systems with time-asymmetric trajectories to maintain their organization. However, assessing time asymmetry from neuronal spiking activity remains challenging. The kinetic Ising model provides a framework for studying the causal, nonequilibrium dynamics in spiking recurrent neural networks. Recent theoretical advances in this model have enabled time-asymmetry estimation from large-scale steady-state data. Yet, neuronal activity often exhibits time-varying firing rates and coupling strengths, violating the steady-state assumption. To overcome this limitation, we developed a state-space kinetic Ising model that accounts for nonstationary and nonequilibrium properties of neural systems. This approach incorporates a mean-field method for estimating time-varying entropy flow, a key measure for maintaining the system's organization through dissipation. Applying this method to mouse visual cortex data revealed greater variability in causal couplings during task engagement despite reduced neuronal activity with increased sparsity. Moreover, higher-performing mice exhibited increased coupling-related entropy flow per spike during task engagement, suggesting more efficient computation in the higher-performing mice. These findings underscore the model's utility in uncovering intricate asymmetric causal dynamics in neuronal ensembles and linking them to behavior through the thermodynamic underpinnings of neural computation.",
      "author": "Ken Ishihara, Hideaki Shimazaki",
      "published_date": "2025-12-12T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 196,
      "reading_time": 1,
      "created_at": "2025-12-12T05:24:14.152174+00:00",
      "updated_at": "2025-12-12T05:24:14.152175+00:00"
    },
    {
      "id": "3928666ff0946874b8b1253e5b1df60f",
      "url": "https://arxiv.org/abs/2512.10011",
      "title": "Spatial Spiking Neural Networks Enable Efficient and Robust Temporal Computation",
      "content": "arXiv:2512.10011v1 Announce Type: cross \nAbstract: The efficiency of modern machine intelligence depends on high accuracy with minimal computational cost. In spiking neural networks (SNNs), synaptic delays are crucial for encoding temporal structure, yet existing models treat them as fully trainable, unconstrained parameters, leading to large memory footprints, higher computational demand, and a departure from biological plausibility. In the brain, however, delays arise from physical distances between neurons embedded in space. Building on this principle, we introduce Spatial Spiking Neural Networks (SpSNNs), a framework in which neurons learn coordinates in a finite-dimensional Euclidean space and delays emerge from inter-neuron distances. This replaces per-synapse delay learning with position learning, substantially reducing parameter count while retaining temporal expressiveness. Across the Yin-Yang and Spiking Heidelberg Digits benchmarks, SpSNNs outperform SNNs with unconstrained delays despite using far fewer parameters. Performance consistently peaks in 2D and 3D networks rather than infinite-dimensional delay spaces, revealing a geometric regularization effect. Moreover, dynamically sparsified SpSNNs maintain full accuracy even at 90% sparsity, matching standard delay-trained SNNs while using up to 18x fewer parameters. Because learned spatial layouts map naturally onto hardware geometries, SpSNNs lend themselves to efficient neuromorphic implementation. Methodologically, SpSNNs compute exact delay gradients via automatic differentiation with custom-derived rules, supporting arbitrary neuron models and architectures. Altogether, SpSNNs provide a principled platform for exploring spatial structure in temporal computation and offer a hardware-friendly substrate for scalable, energy-efficient neuromorphic intelligence.",
      "author": "Lennart P. L. Landsmeer, Amirreza Movahedin, Mario Negrello, Said Hamdioui, Christos Strydis",
      "published_date": "2025-12-12T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 231,
      "reading_time": 1,
      "created_at": "2025-12-12T05:24:14.152142+00:00",
      "updated_at": "2025-12-12T05:24:14.152143+00:00"
    }
  ],
  "recently_processed": [
    {
      "id": "0adbf76a60a38e99e1fe333e7ad9a143",
      "url": "https://www.danieleteti.it/post/html-first-frameworks-htmx-revolution-en/#building-with-html-instead-of-fighting-with-javascript-layers-",
      "title": "The HTML-First Approach: Why Htmx and Lightweight Frameworks Are Revolutionizin",
      "content": "<p>Article URL: <a href=\"https://www.danieleteti.it/post/html-first-frameworks-htmx-revolution-en/#building-with-html-instead-of-fighting-with-javascript-layers-\">https://www.danieleteti.it/post/html-first-frameworks-htmx-revolution-en/#building-with-html-instead-of-fighting-with-javascript-layers-</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46239445\">https://news.ycombinator.com/item?id=46239445</a></p>\n<p>Points: 10</p>\n<p># Comments: 0</p>",
      "author": "todsacerdoti",
      "published_date": "2025-12-12T00:37:42+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-12T05:46:13.534540+00:00",
      "updated_at": "2025-12-12T06:26:09.044074+00:00",
      "metadata": {
        "processed_at": "2025-12-12T06:26:09.044083+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "5e148265dd0f3ead7b90275271106ab2",
      "url": "https://arxiv.org/abs/2512.10110",
      "title": "Generate-Then-Validate: A Novel Question Generation Approach Using Small Language Models",
      "content": "arXiv:2512.10110v1 Announce Type: cross \nAbstract: We explore the use of small language models (SLMs) for automatic question generation as a complement to the prevalent use of their large counterparts in learning analytics research. We present a novel question generation pipeline that leverages both the text generation and the probabilistic reasoning abilities of SLMs to generate high-quality questions. Adopting a \"generate-then-validate\" strategy, our pipeline first performs expansive generation to create an abundance of candidate questions and refine them through selective validation based on novel probabilistic reasoning. We conducted two evaluation studies, one with seven human experts and the other with a large language model (LLM), to assess the quality of the generated questions. Most judges (humans or LLMs) agreed that the generated questions had clear answers and generally aligned well with the intended learning objectives. Our findings suggest that an SLM can effectively generate high-quality questions when guided by a well-designed pipeline that leverages its strengths.",
      "author": "Yumou Wei, John Stamper, Paulo F. Carvalho",
      "published_date": "2025-12-12T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 155,
      "reading_time": 1,
      "created_at": "2025-12-12T05:24:15.356971+00:00",
      "updated_at": "2025-12-12T06:26:09.044088+00:00",
      "metadata": {
        "processed_at": "2025-12-12T06:26:09.044090+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "637fe6fb1dfe3cd73e15fa20257e4084",
      "url": "https://arxiv.org/abs/2512.10065",
      "title": "Linear socio-demographic representations emerge in Large Language Models from indirect cues",
      "content": "arXiv:2512.10065v1 Announce Type: cross \nAbstract: We investigate how LLMs encode sociodemographic attributes of human conversational partners inferred from indirect cues such as names and occupations. We show that LLMs develop linear representations of user demographics within activation space, wherein stereotypically associated attributes are encoded along interpretable geometric directions. We first probe residual streams across layers of four open transformer-based LLMs (Magistral 24B, Qwen3 14B, GPT-OSS 20B, OLMo2-1B) prompted with explicit demographic disclosure. We show that the same probes predict demographics from implicit cues: names activate census-aligned gender and race representations, while occupations trigger representations correlated with real-world workforce statistics. These linear representations allow us to explain demographic inferences implicitly formed by LLMs during conversation. We demonstrate that these implicit demographic representations actively shape downstream behavior, such as career recommendations. Our study further highlights that models that pass bias benchmark tests may still harbor and leverage implicit biases, with implications for fairness when applied at scale.",
      "author": "Paul Bouchaud, Pedro Ramaciotti",
      "published_date": "2025-12-12T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 155,
      "reading_time": 1,
      "created_at": "2025-12-12T05:24:15.356942+00:00",
      "updated_at": "2025-12-12T06:26:09.044092+00:00",
      "metadata": {
        "processed_at": "2025-12-12T06:26:09.044094+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "34304dc9d156c05cfd5da8ddae14b0d2",
      "url": "https://arxiv.org/abs/2512.10058",
      "title": "Mind the Gap! Pathways Towards Unifying AI Safety and Ethics Research",
      "content": "arXiv:2512.10058v1 Announce Type: cross \nAbstract: While much research in artificial intelligence (AI) has focused on scaling capabilities, the accelerating pace of development makes countervailing work on producing harmless, \"aligned\" systems increasingly urgent. Yet research on alignment has diverged along two largely parallel tracks: safety--centered on scaled intelligence, deceptive or scheming behaviors, and existential risk--and ethics--focused on present harms, the reproduction of social bias, and flaws in production pipelines. Although both communities warn of insufficient investment in alignment, they disagree on what alignment means or ought to mean. As a result, their efforts have evolved in relative isolation, shaped by distinct methodologies, institutional homes, and disciplinary genealogies.\n  We present a large-scale, quantitative study showing the structural split between AI safety and AI ethics. Using a bibliometric and co-authorship network analysis of 6,442 papers from twelve major ML and NLP conferences (2020-2025), we find that over 80% of collaborations occur within either the safety or ethics communities, and cross-field connectivity is highly concentrated: roughly 5% of papers account for more than 85% of bridging links. Removing a small number of these brokers sharply increases segregation, indicating that cross-disciplinary exchange depends on a handful of actors rather than broad, distributed collaboration. These results show that the safety-ethics divide is not only conceptual but institutional, with implications for research agendas, policy, and venues. We argue that integrating technical safety work with normative ethics--via shared benchmarks, cross-institutional venues, and mixed-method methodologies--is essential for building AI systems that are both robust and just.",
      "author": "Dani Roytburg, Beck Miller",
      "published_date": "2025-12-12T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 247,
      "reading_time": 1,
      "created_at": "2025-12-12T05:24:15.356913+00:00",
      "updated_at": "2025-12-12T06:26:09.044096+00:00",
      "metadata": {
        "processed_at": "2025-12-12T06:26:09.044098+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "f60ee20cca667440802aac5f2786980b",
      "url": "https://arxiv.org/abs/2512.09932",
      "title": "Suzume-chan: Your Personal Navigator as an Embodied Information Hub",
      "content": "arXiv:2512.09932v1 Announce Type: cross \nAbstract: Access to expert knowledge often requires real-time human communication. Digital tools improve access to information but rarely create the sense of connection needed for deep understanding. This study addresses this issue using Social Presence Theory, which explains how a feeling of \"being together\" enhances communication. An \"Embodied Information Hub\" is proposed as a new way to share knowledge through physical and conversational interaction. The prototype, Suzume-chan, is a small, soft AI agent running locally with a language model and retrieval-augmented generation (RAG). It learns from spoken explanations and responds through dialogue, reducing psychological distance and making knowledge sharing warmer and more human-centered.",
      "author": "Maya Grace Torii, Takahito Murakami, Shuka Koseki, Yoichi Ochiai",
      "published_date": "2025-12-12T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 107,
      "reading_time": 1,
      "created_at": "2025-12-12T05:24:15.356875+00:00",
      "updated_at": "2025-12-12T06:26:09.044100+00:00",
      "metadata": {
        "processed_at": "2025-12-12T06:26:09.044102+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "6dfecf7dfcf3b12770e8023576c8b46c",
      "url": "https://www.isaaa.org/kc/cropbiotechupdate/article/default.asp?ID=21607",
      "title": "CRISPR Fungus: Protein-Packed, Sustainable, and Tastes Like Meat",
      "content": "<p>Article URL: <a href=\"https://www.isaaa.org/kc/cropbiotechupdate/article/default.asp?ID=21607\">https://www.isaaa.org/kc/cropbiotechupdate/article/default.asp?ID=21607</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46239629\">https://news.ycombinator.com/item?id=46239629</a></p>\n<p>Points: 7</p>\n<p># Comments: 2</p>",
      "author": "rguiscard",
      "published_date": "2025-12-12T00:59:46+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-12T04:08:57.699062+00:00",
      "updated_at": "2025-12-12T04:30:12.855418+00:00",
      "metadata": {
        "processed_at": "2025-12-12T04:30:12.855429+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "20f6fe1eaebfebef3c264e4ba0516d7a",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.09.688708v1?rss=1",
      "title": "Non-uniform effects of remaining field spread on the estimation of M/EEG activity and connectivity between regions of interest",
      "content": "In M/EEG analyses, it is often convenient to extract time series of activity originating from the regions of interest (ROIs). However, due to the spread of electric and magnetic fields, M/EEG recordings capture activity from all sources within the brain. Commonly used approaches for the extraction of ROI activity only partially alleviate this problem, and field spread remains a challenge even at the level of ROI time series. Because of the remaining field spread (RFS), the extracted time series captures activity not only from the considered ROI but also from other regions (not necessarily neighboring ones). The amount of RFS can strongly affect the validity of interpretations: with more RFS, the extracted time series becomes less representative of the ROI. However, neither the amount nor the pattern of RFS is usually known. In this study, we apply the cross-talk function (CTF) to analyze contributions of all sources across the brain to the extracted ROI time series, thereby quantifying the degree of RFS. With CTF, we show that the effect of RFS on the extraction of ROI activity and on the estimation of inter-regional connectivity is highly non-uniform across the cortex. In particular, ROIs farther away from the recording sensors are more likely to capture activity and connectivity from other areas. Finally, we validate this observation in simulations and complement it by investigating spurious and ghost interactions in real data. Overall, our results illustrate how CTF can be used as a diagnostic tool to quantify the effects of RFS and to evaluate pipelines for the extraction of ROI activity.",
      "author": "Kapralov, N., Studenova, A., Eguinoa, R., Nolte, G., Haufe, S., Villringer, A., Nikulin, V.",
      "published_date": "2025-12-11T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 258,
      "reading_time": 1,
      "created_at": "2025-12-12T03:24:46.063756+00:00",
      "updated_at": "2025-12-12T04:30:12.855434+00:00",
      "metadata": {
        "processed_at": "2025-12-12T04:30:12.855436+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "0437a2fb3f6f3a2ff8412a88feb61b40",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.09.691422v1?rss=1",
      "title": "Thermodynamics of consciousness: A non-invasive perturbational framework",
      "content": "The quest for reliable and objective measures of consciousness is critical in basic and clinical neuroscience. Across species, the Perturbational Complexity Index (PCI) has emerged as a robust empirical marker by directly perturbing the brain, yet its underlying principles of physics are not fully understood. Here, we bridge this gap by introducing a non-invasive framework based on generative whole-brain models of non-equilibrium brain dynamics. Using these models, we identified violations of the Fluctuation-Dissipation Theorem (FDT) in humans and rodents across wakefulness, anesthesia, and disorders of consciousness. Mirroring the patterns observed with PCI, we found decreased FDT violations in unresponsive disorders of consciousness and anesthesia compared to conscious conditions. This reveals a close link between PCI and non-equilibrium dynamics in spontaneous brain signals, grounding PCI in fundamental principles of physics. Overall, this framework offers new complementary, non-invasive, model-based avenues for understanding the nature of consciousness and for developing objective tools to assess its loss and recovery in health and disease. It also provides a principled foundation for discovering novel strategies to restore consciousness.",
      "author": "Berjaga-Buisan, T., Monti, J. M., Cortada, M., Colombo, M. A., Geli, S. M., Gaglioti, G., Sarasso, S., Kringelbach, M. L., Corbetta, M., Sanchez-Vives, M. V., Massimini, M., Perl, Y. S., Deco, G.",
      "published_date": "2025-12-11T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 172,
      "reading_time": 1,
      "created_at": "2025-12-12T03:24:46.063703+00:00",
      "updated_at": "2025-12-12T04:30:12.855439+00:00",
      "metadata": {
        "processed_at": "2025-12-12T04:30:12.855440+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "ab11ac7069b74eda694a539a47b87f7d",
      "url": "https://www.nature.com/articles/s41380-025-03380-8",
      "title": "Antidepressant-like effects of extinction learning as an animal model of behavioral therapy",
      "content": "",
      "author": "",
      "published_date": "2025-12-12T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-12-12T03:24:44.455387+00:00",
      "updated_at": "2025-12-12T04:30:12.855443+00:00",
      "metadata": {
        "processed_at": "2025-12-12T04:30:12.855444+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "0ff4cd7bba2bd339d25240c89c3ef785",
      "url": "https://www.reddit.com/r/Python/comments/1pkewoj/fixed_ssl_connection_broken_certificate/",
      "title": "FIXED - SSL connection broken, certificate verification error, unable to get local issuer certificat",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>I just spent 20+ hours agonizing over the fact that my new machine was constantly throwing SSL errors refusing to let me connect to PyPI and for the life of me I could not figure out what was wrong and I just want to share here so that if anyone has the same issue, please know that hope is not lost.</p> <p>It's the stupid Windows Store, and I just need to share it because I was about to scream and I don't want you to scream too :(</p> <p>1.Disable Windows Store Python aliases:</p> <p>Windows Settings &gt; Apps &gt; Advanced App Settings &gt; App Execution Aliases</p> <p>Turn OFF:</p> <ul> <li>python.exe</li> <li>python3.exe</li> <li>py.exe</li> </ul> <p>This stops Windows Store from hijacking Python.</p> <ol> <li>Delete the Windows Store Python stubs:</li> </ol> <p>Open CMD as Admin, then run:</p> <p>takeown /F &quot;%LocalAppData%\\Microsoft\\WindowsApps&quot; /R /D Y</p> <p>icacls &quot;%LocalAppData%\\Microsoft\\WindowsApps&quot; /grant %USERNAME%:F /T</p> <p>del &quot;%LocalAppData%\\Microsoft\\WindowsApps\\python*.exe&quot;</p> <p>del &quot;%LocalAppData%\\Microsoft\\WindowsApps\\py*.exe&quot;</p> <p>This step is CRITICAL.</p> <p>If you skip it, Python will stay broken.</p> <ol> <li>Completely wipe and reinstall Python using Python Install Manager FROM THE PYTHON WEBSITE. Do not use the Windows Store!!!</li> </ol> <p>Still in Admin CMD:</p> <p>pymanager uninstall PythonCore\\* --purge</p> <p>pymanager install PythonCore\\3.12 --update</p> <ol> <li>Fix PATH:</li> </ol> <p>setx PATH &quot;%LocalAppData%\\Python\\bin;%LocalAppData%\\Python\\pythoncore-3.12-64;%LocalAppData%\\Python\\pythoncore-3.12-64\\Scripts;%PATH%&quot; /M</p> <p>Close CMD and open a new one.</p> <ol> <li>Repair SSL by forcing Python to use the certifi bundle:</li> </ol> <p>python -m pip install certifi --user</p> <p>python -m certifi</p> <p>You should get a .pem file path.</p> <p>Use that path below (Admin CMD):</p> <p>setx SSL_CERT_FILE &quot;&lt;path&gt;&quot; /M</p> <p>setx REQUESTS_CA_BUNDLE &quot;&lt;path&gt;&quot; /M</p> <p>setx CURL_CA_BUNDLE &quot;&lt;path&gt;&quot; /M</p> <ol> <li>Test:</li> </ol> <p>python --version</p> <p>pip --version</p> <p>pip install &lt;anything&gt;</p> <p>At this point, everything should work normally and all SSL/pip issues should be gone. I think. Hopefully. I don't know. Please don't cry. I am now going to go to bed for approximately 3 days</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/AmbiguousLemur\"> /u/AmbiguousLemur </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1pkewoj/fixed_ssl_connection_broken_certificate/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1pkewoj/fixed_ssl_connection_broken_certificate/\">[comments]</a></span>",
      "author": "/u/AmbiguousLemur",
      "published_date": "2025-12-12T01:23:33+00:00",
      "source": "Reddit Python",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 320,
      "reading_time": 1,
      "created_at": "2025-12-12T03:24:06.996672+00:00",
      "updated_at": "2025-12-12T04:30:12.855446+00:00",
      "metadata": {
        "processed_at": "2025-12-12T04:30:12.855448+00:00",
        "processing_method": "github_actions"
      }
    }
  ]
}