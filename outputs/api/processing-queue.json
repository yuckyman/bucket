{
  "last_updated": "2025-11-11T03:10:21.700321+00:00",
  "pending_count": 979,
  "processed_count": 21,
  "pending_articles": [
    {
      "id": "1348eff8059203eea8f1cf0c47dfeafd",
      "url": "https://brain.ieee.org/podcasts/qa-with-dr-richard-carson-professor-of-biomedical-engineering-and-radiology-biomedical-imaging-yale-university-and-yale-school-of-medicine/",
      "title": "Q&A with Dr. Richard Carson, Professor of Biomedical Engineering and Radiology & Biomedical Imaging, Yale University and Yale School of Medicine",
      "content": "",
      "author": "Adriel Carridice",
      "published_date": "2025-11-04T18:24:59+00:00",
      "source": "Brain",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-11-11T01:41:31.019209+00:00",
      "updated_at": "2025-11-11T01:41:31.019215+00:00"
    },
    {
      "id": "21edf5ffd9853f7b13856eb1a1b27eef",
      "url": "http://ieeexplore.ieee.org/document/10976660",
      "title": "Inverse Problem Approach to Aberration Correction for In Vivo Transcranial Imaging Based on a Sparse Representation of Contrast-Enhanced Ultrasound Data",
      "content": "Objective: Transcranial ultrasound imaging is currently limited by attenuation and aberration induced by the skull. First used in contrast-enhanced ultrasound (CEUS), highly echoic microbubbles allowed for the development of novel imaging modalities such as ultrasound localization microscopy (ULM). Herein, we develop an inverse problem approach to aberration correction (IPAC) that leverages the sparsity of microbubble signals. Methods: We propose to use the a priori knowledge of the medium based upon microbubble localization and wave propagation to build a forward model to link the measured signals directly to the aberration function. A standard least-squares inversion is then used to retrieve the aberration function. We first validated IPAC on simulated data of a vascular network using plane wave as well as divergent wave emissions. We then evaluated the reproducibility of IPAC in vivo in 5 mouse brains. Results: We showed that aberration correction improved the contrast of CEUS images by 4.6 dB. For ULM images, IPAC yielded sharper vessels, reduced vessel duplications, and improved the resolution from 21.1 $\\mu$m to 18.3 $\\mu$m. Aberration correction also improved hemodynamic quantification for velocity magnitude and flow direction. Conclusion: We showed that IPAC can perform skull-induced aberration correction and improved power Doppler as well as ULM images acquired on the mouse brain. Significance: This technique is promising for more reliable transcranial imaging of the brain vasculature with potential non-invasive clinical applications.",
      "author": "",
      "published_date": "2025-04-25T13:17:31+00:00",
      "source": "Transactions Biomedical Engineering",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 225,
      "reading_time": 1,
      "created_at": "2025-11-11T01:41:27.304440+00:00",
      "updated_at": "2025-11-11T01:41:27.304442+00:00"
    },
    {
      "id": "ea005bf9a4d1debaee7a63b57743133e",
      "url": "http://ieeexplore.ieee.org/document/10974669",
      "title": "CLaI: Collaborative Learning and Inference for Low-Resolution Physiological Signals: Validation in Clinical Event Detection and Prediction",
      "content": "While machine learning (ML) techniques have been applied to detection and prediction tasks in clinical data, most methods rely on high-resolution data, which is not routinely available in most Intensive Care Units (ICUs), and perform poorly when faced with class imbalance. Here, we introduce and validate Collaborative Learning and Inference (CLaI) for detection and prediction of events from learned latent representations of multivariate physiological time series, leveraging similarities across patients. Our method offers a new way to detect and predict events using low-resolution physiological time series. We evaluate its performance on predicting intracranial hypertension and sepsis using the KidsBrainIT (minute-by-minute resolution) and MIMIC-IV (hourly resolution) datasets, respectively, comparing our approach with classification-based and sequence-to-sequence benchmarks from existing studies. Additional experiments on sepsis detection, robustness to class imbalance, and generalizability\u2014demonstrated via seizure detection using the CHB-MIT scalp electroencephalogram dataset\u2014confirm that CLaI effectively handles class imbalance, consistently achieving competitive performance and the highest F1 score. Overall, our approach introduces a novel method for analyzing routinely collected ICU physiological time series by leveraging patient similarity thus enabling ML interpretability through case-based reasoning.",
      "author": "",
      "published_date": "2025-04-23T13:18:26+00:00",
      "source": "Transactions Biomedical Engineering",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 179,
      "reading_time": 1,
      "created_at": "2025-11-11T01:41:27.304402+00:00",
      "updated_at": "2025-11-11T01:41:27.304404+00:00"
    },
    {
      "id": "bad5757f306a00dd069fd23d649636a6",
      "url": "http://ieeexplore.ieee.org/document/10856219",
      "title": "IEEE Reviews in Biomedical Engineering (R-BME)",
      "content": "null",
      "author": "",
      "published_date": "2025-01-28T13:17:19+00:00",
      "source": "Reviews Biomedical Engineering",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 1,
      "reading_time": 1,
      "created_at": "2025-11-11T01:41:26.221380+00:00",
      "updated_at": "2025-11-11T01:41:26.221382+00:00"
    },
    {
      "id": "ce8bd55d20f47657ee01d134756851e8",
      "url": "http://ieeexplore.ieee.org/document/10759750",
      "title": "Utilizing Neurons to Interrogate Cancer: Integrative Analysis of Cancer Omics Data With Deep Learning Models",
      "content": "Genomics plays an essential role in the early detection, classification, and targeted cancer therapy based on the analysis of precise alterations at the molecular level. Using the most reliable approach is essential for the exact interrogation and cross-examination of complex and multi-high-dimensional \u201cMulti-omics\u201d cancer genomics data. In recent years, deep learning has been successfully utilized to deal with large cancer genomics data and has the potential to transform predictive biology. This review aims to explore the recent advancements in the application of deep learning models in basic cancer omics research, including different methodologies for the interrogation of bulk cancer omics data and the importance of cross-platform data integration. The paper provides insights into advantages, limitations, potential for improvement, research gaps, future direction, and an in-depth comparison of the models currently used in the field of cancer genomics, highlighting the crucial need for collaboration and interdisciplinary research in the field.",
      "author": "",
      "published_date": "2024-11-21T13:20:46+00:00",
      "source": "Reviews Biomedical Engineering",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 149,
      "reading_time": 1,
      "created_at": "2025-11-11T01:41:26.221359+00:00",
      "updated_at": "2025-11-11T01:41:26.221361+00:00"
    },
    {
      "id": "2eb1c3423e2abdc6249e1ab529cb9548",
      "url": "http://ieeexplore.ieee.org/document/11235895",
      "title": "Odor-induced Sustained Neural Activity during Memory Encoding",
      "content": "How long do the neural and cognitive effects of a brief odor experience last? This study investigated whether short exposures to pleasant and unpleasant odors can induce sustained changes in brain activity and influence memory formation for events occurring several seconds later. Using EEG, we combined univariate ERP analyses with time-resolved multivariate decoding to track neural responses during a 6-sec delay between odor presentation and visual memory encoding. We found that brief odor cues elicited sustained neural activity that persisted well beyond odor offset. Unpleasant odors, in particular, were associated with higher sustained ERP amplitudes compared with pleasant ones. Behaviorally, participants showed greater confidence in recognizing images that had been preceded by unpleasant odors, suggesting that even brief olfactory experiences can modulate memory encoding for temporally distant events. These findings demonstrate that brief olfactory cues have a lasting effect on both neural activity and subsequent memory performance.",
      "author": "",
      "published_date": "2025-11-07T13:16:23+00:00",
      "source": "Cognitive Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 147,
      "reading_time": 1,
      "created_at": "2025-11-11T01:41:25.142114+00:00",
      "updated_at": "2025-11-11T01:41:25.142116+00:00"
    },
    {
      "id": "dc7ce2a8ec06e8af7eb9f14cdda9e2c2",
      "url": "http://ieeexplore.ieee.org/document/11235893",
      "title": "Incidental Encoding of Objects during Search Is Stronger Than Intentional Memorization due to Increased Recollection Rather Than Familiarity",
      "content": "Most memory is not formed deliberately but as a by-product of natural behavior. These incidental representations, when generated during visual search, can be stronger than intentionally memorized content (search superiority effect). However, it is unknown if the search superiority effect is purely quantitative (stronger memory) or also driven by differences in the degrees of recollection and familiarity, two hallmark processes supporting recognition memory. Here, we use signal detection modeling, introspective judgments, event-related EEG potentials, and eye tracking measures to answer this question. In a preregistered study, 30 participants searched for objects in scenes and intentionally memorized others before completing a surprise recognition memory test. Behavioral data from remember\u2013know judgments and receiver operating characteristics indicate that search targets were more often recollected compared with intentionally memorized objects, whereas the two tasks did not lead to differences in familiarity. Surprisingly, the neural signatures did not fully align with the behavioral findings regarding recollection and familiarity. That is, both search targets and intentionally memorized objects elicited a more positive-going mid-frontal negativity peaking at around 400\u2009msec post stimulus onset (FN400), which is associated with familiarity, as well as a more positive-going parietal late component (LPC), indicative of recollection. Both components showed no differences between tasks, indicating equal contributions of recollection and familiarity to remembering searched and memorized objects. Furthermore, the LPC was, as expected, sensitive to differences between recollected and familiar objects when these were intentionally memorized, but it was not affected by these differences for searched objects. Overall, our findings indicate that search superiority relies predominantly on increased recollection. The fact that established neural markers of recollection (LPC) behaved as anticipated for intentionally memorized objects but carried no predictive power for incidentally memorized objects implies that memories established in more ecologically valid tasks might involve neural processes different from those activated in commonly used settings that are more reductionist.",
      "author": "",
      "published_date": "2025-11-07T13:16:23+00:00",
      "source": "Cognitive Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 307,
      "reading_time": 1,
      "created_at": "2025-11-11T01:41:25.142082+00:00",
      "updated_at": "2025-11-11T01:41:25.142084+00:00"
    },
    {
      "id": "c5a6fc34a9c14ac12b805c16e3e0c299",
      "url": "http://ieeexplore.ieee.org/document/11235889",
      "title": "On the Causal Role of the Right Lateral Prefrontal Cortex in Active Forgetting",
      "content": "Extensive research has demonstrated that people can intentionally forget by inhibiting the retrieval of unwanted memories, a phenomenon known as suppression-induced forgetting (SIF). Although neuroimaging studies have linked retrieval suppression to the right lateral prefrontal cortex (LPFC), direct evidence for the causal role this region plays in supporting SIF is still lacking. In this registered report, our aim is putting to a strong empirical test such an idea by using cathodal transcranial direct current stimulation in a standard think/no-think procedure. Across two experiments, we will compare the SIF achieved by participants receiving cathodal transcranial direct current stimulation over the right LPFC\u2014which has been shown to disrupt prefrontally mediated inhibitory control\u2014with those receiving sham stimulation or cathodal stimulation over a control site. In addition, we will examine the lateralization of this effect by comparing stimulation of the right and left LPFC. Our results will provide novel and critical insights into the brain mechanisms of inhibitory control.",
      "author": "",
      "published_date": "2025-11-07T13:16:23+00:00",
      "source": "Cognitive Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 155,
      "reading_time": 1,
      "created_at": "2025-11-11T01:41:25.142029+00:00",
      "updated_at": "2025-11-11T01:41:25.142030+00:00"
    },
    {
      "id": "cd3a1c12b7b9a5f31966ba2774b15cf2",
      "url": "http://ieeexplore.ieee.org/document/11235878",
      "title": "Attention Modulates Stimulus Representations in Neural Feature Dimension Maps",
      "content": "Computational theories posit that attention is guided by a combination of spatial maps for individual features that can be dynamically weighted according to task goals. Consistent with this framework, when a stimulus contains several features, attending to one or another feature results in stronger fMRI responses in regions preferring the attended feature. We hypothesized that multivariate activation patterns across feature-responsive cortical regions form spatial \u201cfeature dimension maps,\u201d which combine to guide attentional priority. We tested this prediction by reconstructing spatial maps from fMRI activation patterns across retinotopic regions of visual cortex while participants performed a feature-selective attention task. Participants viewed a peripheral visual stimulus at a random location that always contained moving colored dots. On each trial, participants were precued to report the predominant direction of motion or color of the stimulus or to attend fixation. Stimulus representations in reconstructed maps based on a spatial inverted encoding model were selectively enhanced in color-selective regions when color was attended and in motion-selective regions when motion was attended. Whereas enhancement was localized to the stimulus position in color-selective regions, modulations in motion-selective regions were consistent with a more global enhancement when motion was task relevant. These results suggest feature-selective cortical regions support \u201cneural feature dimension maps\u201d: spatial maps of different visual features that are dynamically reweighted based on task demands to guide visual behavior to the most relevant locations based on important features.",
      "author": "",
      "published_date": "2025-11-07T13:16:23+00:00",
      "source": "Cognitive Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 231,
      "reading_time": 1,
      "created_at": "2025-11-11T01:41:25.141992+00:00",
      "updated_at": "2025-11-11T01:41:25.141994+00:00"
    },
    {
      "id": "2bc5c247ee2d0b76d1169f69e341752c",
      "url": "http://ieeexplore.ieee.org/document/11235876",
      "title": "Modeling the Role of the Alpha Rhythm in Attentional Processing during Distractor Suppression",
      "content": "Recent experimental results suggest that alpha oscillations in brain neuroelectrical activity do not merely represent an idling phenomenon but actively participate in attention to suppress distractors and reduce cognitive workload. However, the exact mechanism responsible for this attentional processing is still a matter of research. In this work, we propose a simple mechanism for distractor suppression using a neural mass model of oscillating, interconnected cortical regions, based on alpha oscillations and their interaction with the gamma rhythm. Essentially, the model distinguishes between certain \u201csensory\u201d areas, where stimuli are coded and represented via gamma oscillations, a downstream \u201cdetection\u201d area dedicated to processing these stimuli, and a \u201ccontrol\u201d region that generates the alpha rhythm. Unattended stimuli in a sensory area can be suppressed by simply imposing an alpha rhythm that is out of phase compared with the detection layer. A sensitivity analysis performed on a simple paradigmatic model emphasizes the robustness of the proposed mechanism versus parameter changes. Moreover, a more complex example (concerning spatial attention, where objects are represented through a Gestalt proximity rule) supports the capacity of the mechanism to suppress distractors in multi-unit networks. The model aligns with several experimental results and can be further utilized to investigate cognitive alterations in pathological conditions, such as schizophrenia, characterized by dysfunction in the gamma rhythm.",
      "author": "",
      "published_date": "2025-11-07T13:16:23+00:00",
      "source": "Cognitive Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 214,
      "reading_time": 1,
      "created_at": "2025-11-11T01:41:25.141946+00:00",
      "updated_at": "2025-11-11T01:41:25.141948+00:00"
    }
  ],
  "recently_processed": [
    {
      "id": "80d1f642eb4da0958753076107ac0cbe",
      "url": "http://daniellakens.blogspot.com/2025/07/easily-download-files-from-open-science.html",
      "title": "Easily download files from the Open Science Framework with Papercheck",
      "content": "<p>Researchers\nincreasingly use the <a href=\"https://osf.io/\">Open Science Framework</a> (OSF) to share files, such as data\nand code underlying scientific publications, or presentations and materials for\nscientific workshops. The OSF is an amazing service that has contributed\nimmensely to a changed research culture where psychologists share data, code, and\nmaterials. We are very grateful it exists.</p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">But it is\nnot always the most user-friendly. Specifically, downloading files from the OSF\nis a bigger hassle than we (<a href=\"https://debruine.github.io/\">Lisa DeBruine</a>\nand <a href=\"https://www.tue.nl/en/research/researchers/daniel-lakens/\">Daniel\nLakens</a>, the developers of Papercheck) would like it to be. Downloading individual\nfiles is so complex, <a href=\"https://bsky.app/profile/malte.the100.ci/post/3lpf4s6spns2i\">Malte Elson</a>\nrecently posted this meme on Bluesky. </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"NL\"><!--[if gte vml 1]><v:shapetype\n id=\"_x0000_t75\" coordsize=\"21600,21600\" o:spt=\"75\" o:preferrelative=\"t\"\n path=\"m@4@5l@4@11@9@11@9@5xe\" filled=\"f\" stroked=\"f\">\n <v:stroke joinstyle=\"miter\"/>\n <v:formulas>\n  <v:f eqn=\"if lineDrawn pixelLineWidth 0\"/>\n  <v:f eqn=\"sum @0 1 0\"/>\n  <v:f eqn=\"sum 0 0 @1\"/>\n  <v:f eqn=\"prod @2 1 2\"/>\n  <v:f eqn=\"prod @3 21600 pixelWidth\"/>\n  <v:f eqn=\"prod @3 21600 pixelHeight\"/>\n  <v:f eqn=\"sum @0 0 1\"/>\n  <v:f eqn=\"prod @6 1 2\"/>\n  <v:f eqn=\"prod @7 21600 pixelWidth\"/>\n  <v:f eqn=\"sum @8 21600 0\"/>\n  <v:f eqn=\"prod @7 21600 pixelHeight\"/>\n  <v:f eqn=\"sum @10 21600 0\"/>\n </v:formulas>\n <v:path o:extrusionok=\"f\" gradientshapeok=\"t\" o:connecttype=\"rect\"/>\n <o:lock v:ext=\"edit\" aspectratio=\"t\"/>\n</v:shapetype><v:shape id=\"_x0000_i1026\" type=\"#_x0000_t75\" style='width:453.75pt;\n height:276pt;visibility:visible;mso-wrap-style:square'>\n <v:imagedata src=\"file:///C:/Users/DLakens/AppData/Local/Temp/msohtmlclip1/01/clip_image001.jpg\"\n  o:title=\"\"/>\n</v:shape><![endif]--><!--[if !vml]--><img border=\"0\" height=\"368\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEinS5tFoL5qX14Z2OcgT1APMZLGlghAD3BfBhSnJ9pleVbJyRFUFLShqReS2j7SXGozmLMcVQkoM62UhneJDtH4yx3NRnXOkVZZi-Dm-OPwbGaidxr2raF9wzjx5fU92nfPpE3jmGfwZEwHS1WGSB4gUfRfV3XWjOC2-lCjOYR108h3fwORIHOnqxIX9m8\" width=\"605\" /><!--[endif]--></span><span lang=\"EN-US\"></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\"><span>&nbsp;</span></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">Not only is\nthe download button for files difficult to find, but downloading all files\nrelated to a project can be surprisingly effortful. It is possible to download\nall files in a zip folder that will be called \u2018osfstorage-archive.zip\u2019 when\ndownloaded. But as the OSF supports a nested folder structure, you might miss a\nfolder, and you will quickly end up with \u2018osfstorage-archive (1).zip\u2019, \u2018osfstorage-archive\n(2).zip\u2019, etc. Unzipping these archives creates a lot of files without the\norganized folder structure, in folders with meaningless names, making it\ndifficult to understand where files are. </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<h2 style=\"text-align: left;\"><b><span lang=\"EN-US\">The\nosf_file_download function in Papercheck </span></b></h2>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">We have added\na new function to our R package \u2018<a href=\"https://scienceverse.github.io/papercheck/\">Papercheck</a>\u2019 that will download all files and\nfolders in an OSF repository. It saves all files by recreating the folder\nstructure from the OSF in your download folder. Just install Papercheck, load\nthe library, and use the osf_file_download function to grab all files on the OSF:</span></p><p class=\"MsoNormal\"><span lang=\"EN-US\"><br /></span></p>\n\n<div style=\"text-align: left;\"><span style=\"font-family: courier;\"><b><span lang=\"EN-US\">devtools::install_github(\"scienceverse/papercheck\")<br /></span></b><b><span lang=\"EN-US\">library(papercheck)<br /></span></b><b><span lang=\"EN-US\">osf_file_download(\"6nt4v\")</span></b></span></div>\n\n\n\n\n\n<p class=\"MsoNormal\"><b><span lang=\"EN-US\">&nbsp;</span></b></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">All files\nwill be downloaded to your working directory. </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">Are you feeling\nFOMO for missing out on the <a href=\"https://www.kcl.ac.uk/events/open-research-summer-school-2025\">King Open\nResearch Summer School</a> that is going on these days, where <a href=\"https://research.tue.nl/en/persons/sajedeh-rasti\">Sajedeh Rasti</a> talked\nabout Preregistration, and <a href=\"https://research.tue.nl/en/persons/cristian-mesquida-caldentey\">Cristian\nMesquida</a> will give a workshop on using Papercheck? Well, at least it is\nvery easy to download all the files they have shared on the OSF and look at the\npresentations: </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\"><span style=\"font-family: courier;\">osf_file_download(\"b7es8\")</span></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">In the\noutput, we see that by default large files (more than 10mb) are omitted. <span><!--[if gte vml 1]><v:shape id=\"Picture_x0020_1\"\n o:spid=\"_x0000_i1025\" type=\"#_x0000_t75\" alt=\"A screenshot of a computer&#10;&#10;AI-generated content may be incorrect.\"\n style='width:453.75pt;height:292.5pt;visibility:visible;mso-wrap-style:square'>\n <v:imagedata src=\"file:///C:/Users/DLakens/AppData/Local/Temp/msohtmlclip1/01/clip_image003.png\"\n  o:title=\"A screenshot of a computer&#10;&#10;AI-generated content may be incorrect\"/>\n</v:shape><![endif]--><!--[if !vml]--><img alt=\"A screenshot of a computer\n\nAI-generated content may be incorrect.\" border=\"0\" height=\"390\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEj2jH76ywmEeLzL43u6gJl7GKR2lEGlhYS0LOXRPMMovOsJEVdXyamYCvmq96ez3p_GXHLoFz4JDyAKHlARK9pSy8QfzVa7yt1_uEg_H9IJfKgunnYWUwlROXABNcU6TvrA0_hx0KPZfj00b3Cb-Wn_7Bf3sFu9JApZoClcWoh_Vfl5bk1GQVZUH1tuGao\" width=\"605\" /><!--[endif]--></span></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">If you want\nto download all files, regardless of the size, then set the parameter to ignore\nthe maximum file size: </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\"><span style=\"font-family: courier;\">osf_file_download(\"b7es8\",\nmax_file_size = NULL)</span></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">Sometimes\nyou might want to download all files but ignore the file structure on the OSF,\nto just have all the files in one folder. Setting the parameter ignore_folder_structure\n= TRUE will give you all the files on the OSF in a single folder. By default, files will be downloaded into your working directory, but you can also specify\nwhere you want the files to be saved. </span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\"><span style=\"font-family: courier;\">osf_file_download(\"6nt4v\",\nignore_folder_structure = TRUE, download_to = \"C:\\\\test_download\")</span></span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">We hope\nthis function will make it easier for reviewers to access all supplementary\nfiles stored on the OSF during peer review, and for researchers who want to re-use\ndata, code, or materials shared on the OSF by downloading all the files they\nneed easily. Make sure to install the latest version of Papercheck (0.0.0.9050)\nto get access to this new function. Papercheck is still in active development,\nso report any bugs on <a href=\"https://github.com/scienceverse/papercheck\">GitHub</a>.</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n<p class=\"MsoNormal\"><span lang=\"EN-US\">&nbsp;</span></p>",
      "author": "noreply@blogger.com (Daniel Lakens)",
      "published_date": "2025-07-22T09:53:00+00:00",
      "source": "Twenty Percent Statistician",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 765,
      "reading_time": 3,
      "created_at": "2025-11-11T01:41:36.230242+00:00",
      "updated_at": "2025-11-11T03:10:21.610369+00:00",
      "metadata": {
        "processed_at": "2025-11-11T03:10:21.610379+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "5cf06dd1c8477abb17ef4e5c3b5426e0",
      "url": "https://erpinfo.org/blog/2021/12/22/applications-2023",
      "title": "Applications now being accepted for UC-Davis/SDSU ERP Boot Camp, July 31 \u2013 August 9, 2023",
      "content": "<p class=\"\">The next 10-day ERP Boot Camp will be held July 31 \u2013 August 9, 2023 in San Diego, California. We are now taking applications, which will be due by April 1, 2023. <a href=\"https://erpinfo.org/summer-boot-camp\">Click here</a> for more information.</p><p class=\"\">We are currently planning to hold this workshop as an in-person event. However, these plans are subject to change as the COVID-19 pandemic evolves. If the event is held in person, we will require that everyone is fully vaccinated, and we will also implement any other safety measures that are warranted at the time of the workshop.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"980\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/1609175691205-RTD3XM69YGOFMVP23U6T/Boot_Camp_Logo.png?format=1000w\" width=\"1148\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>",
      "author": "Steve Luck",
      "published_date": "2023-01-16T18:31:57+00:00",
      "source": "Erp Boot Camp",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 108,
      "reading_time": 1,
      "created_at": "2025-11-11T01:41:33.787324+00:00",
      "updated_at": "2025-11-11T03:10:21.610385+00:00",
      "metadata": {
        "processed_at": "2025-11-11T03:10:21.610387+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "bd7398ecbbd90ecd3269866b2fd3744f",
      "url": "https://erpinfo.org/blog/2023/6/23/decoding-webinar",
      "title": "ERP Decoding for Everyone: Software and Webinar",
      "content": "<p class=\"\"><strong>You can access the recording </strong><a href=\"https://video.ucdavis.edu/media/Virtual+ERP+Boot+CampA+Decoding+for+Everyone%2C+July+25+2023/1_lmwj6bu0\"><strong>here</strong></a><strong>.<br />You can access the final PDF of the slides </strong><a href=\"https://ucdavis.box.com/s/flf9gzeo12rz2jhxptih7xjl0omka2k7\"><strong>here</strong></a><strong>. <br />You can access the data </strong><a href=\"https://doi.org/10.18115/D5KS6S\"><strong>here</strong></a><strong>.</strong></p><p class=\"\">fMRI research has used decoding methods for over 20 years. These methods make it possible to decode what an individual is perceiving or holding in working memory on the basis of the pattern of BOLD activity across voxels. Remarkably, these methods can also be applied to ERP data, using the pattern of voltage across electrode sites rather than the pattern of activity across voxels to decode the information being represented by the brain (<a href=\"https://erpinfo.org/blog/2018/9/16/decoding\">see this previous blog post</a>). For example, ERPs can be used to decode the identity of a face that is being perceived, the emotional valence of a scene, the identity and semantic category of a word, and the features of an object that is being maintained in working memory. Moreover, decoding methods can be more sensitive than traditional methods for detecting conventional ERP effects (e.g., whether a word is semantically related or unrelated to a previous word in an N400 paradigm).</p><p class=\"\">So far, these methods have mainly been used by a small set of experts. We aim to change that with the upcoming Version 10 of <a href=\"https://erpinfo.org/erplab\">ERPLAB Toolbox</a>. This version of ERPLAB will contain an ERP decoding tool that makes it trivially easy for anyone who knows how to do conventional ERP processing to take advantage of the power of decoding. It should be available in mid-July at <a href=\"https://github.com/ucdavis/erplab/releases\">our GitHub site</a>. You can join the <a href=\"https://github.com/ucdavis/erplab/wiki/ERPLAB-email-list\">ERPLAB email list</a> to receive an announcement when this version is released. Please do not contact us with questions until it has been released and you have tried using it.</p><p class=\"\">On July 25, 2023, we will hold a 2-hour Zoom webinar to explain how decoding works at a conceptual level and show how to implement in ERPLAB Toolbox. The webinar will begin at 9:00 AM Pacific Time (California), 12:00 PM Eastern Time (New York), 5:00 PM British Summer Time (London), 6:00 PM Central European Summer Time (Berlin). </p><p class=\"\">The webinar is co-sponsored by the <a href=\"https://erpinfo.org/the-erp-boot-camp\">ERP Boot Camp</a> and the <a href=\"https://sprweb.org\">Society for Psychophysiological Research</a>. It is completely free, but you must register in advance at <a href=\"https://ucdavis.zoom.us/meeting/register/tJUrc-CtpzorEtBSmZXJINOlLJB9ZR0evpr4\">https://ucdavis.zoom.us/meeting/register/tJUrc-CtpzorEtBSmZXJINOlLJB9ZR0evpr4</a>. Once you register, you will receive an email with your own individual Zoom link. </p><p class=\"\">We will make a recording available a few days after the webinar on the <a href=\"https://erpinfo.org\">ERPinfo.org</a> web site.</p><p class=\"\">Please direct any questions about the webinar to <a href=\"mailto:erpbootcamp@gmail.com\">erpbootcamp@gmail.com</a>.</p>",
      "author": "Steve Luck",
      "published_date": "2023-06-23T21:05:26+00:00",
      "source": "Erp Boot Camp",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 420,
      "reading_time": 2,
      "created_at": "2025-11-11T01:41:33.787293+00:00",
      "updated_at": "2025-11-11T03:10:21.610389+00:00",
      "metadata": {
        "processed_at": "2025-11-11T03:10:21.610391+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "3d370217cb4a351bb54e7854066e15c3",
      "url": "https://erpinfo.org/blog/2024/2/4/optimal-filters",
      "title": "New Papers: Optimal Filter Settings for ERP Research",
      "content": "<p class=\"\">Zhang, G., Garrett, D. R., &amp; Luck, S. J. (in press). Optimal filters for ERP research I: A general approach for selecting filter settings. <em>Psychophysiology</em>. <a href=\"https://doi.org/10.1111/psyp.14531\"><span>https://doi.org/10.1111/psyp.14531</span></a> [<a href=\"https://www.researchgate.net/publication/377773270_Optimal_filters_for_ERP_research_I_A_general_approach_for_selecting_filter_settings\"><span>preprint</span></a>]</p><p class=\"\">Zhang, G., Garrett, D. R., &amp; Luck, S. J. (in press). Optimal filters for ERP research II: Recommended settings for seven common ERP components. <em>Psychophysiology</em>. <a href=\"https://doi.org/10.1111/psyp.14530\"><span>https://doi.org/10.1111/psyp.14530</span></a> [<a href=\"https://www.researchgate.net/publication/377766656_Optimal_filters_for_ERP_research_II_Recommended_settings_for_seven_common_ERP_components\"><span>preprint</span></a>]</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1490\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/d64086cc-e3b4-457d-89df-08d9b3f96439/Filter_Table.png?format=1000w\" width=\"2062\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">What filter settings should you apply to your ERP data? If your filters are too weak to attenuate the noise in your data, your effects may not be statistically significant. If your filters are too strong, they may create artifactual peaks that lead you to draw bogus conclusions.</p><p class=\"\">For years, I have been recommending a bandpass of 0.1\u201330 Hz for most cognitive and affective research in neurotypical young adults. In this kind of research, I have found that filtering from 0.1\u201330 Hz usually does a good job of minimizing noise while creating minimal waveform distortion. </p><p class=\"\">However, this recommendation was based on a combination of informal observations from many experimental paradigms and a careful examination of a couple paradigms, so it was a bit hand-wavy. In addition, the optimal filter settings will depend on the waveshape of the ERP effects and the nature of the noise in a given study, so I couldn\u2019t make any specific recommendations about other experimental paradigms and participant populations. Moreover, different filter settings may be optimal for different scoring methods (e.g., mean amplitude vs. peak amplitude vs. peak latency).</p><p class=\"\">Guanghui Zhang, David Garrett, and I spent the last year focusing on this issue. First we developed a general method that can be used to determine the optimal filter settings for a given dataset and scoring method (see <a href=\"https://doi.org/10.1111/psyp.14531\"><span>this paper</span></a>). Then we applied this method to the <a href=\"https://doi.org/10.1016/j.neuroimage.2020.117465\"><span>ERP CORE</span></a> data to determine the optimal filter settings for the N170, MMN, P3b, N400, N2pc, LRP, and ERN components in neurotypical young adults (see <a href=\"https://doi.org/10.1111/psyp.14530\"><span>this paper</span></a> and the table above).</p><p class=\"\">If you are doing research with these components (or similar components) in neurotypical young adults, you can simply use the filter settings that we identified. If you are using a very different paradigm or testing a very different subject population, you can apply our method to your own data to find the optimal settings. We added some new tools to <a href=\"https://github.com/ucdavis/erplab\"><span>ERPLAB Toolbox</span></a> to make this easier.</p><p class=\"\">One thing that we discovered was that our old recommendation of 0.1\u201330 Hz does a good job of avoiding filter artifacts but is overly conservative for some components. For example, we can raise the low end to 0.5 Hz when measuring N2pc and MMN amplitudes, which gets rid of more noise without producing problematic waveform distortions. And we can go all the way up to 0.9 Hz for the N170 component. However, later/slower components like P3b and N400 require lower cutoffs (no higher than 0.2 Hz).</p><p class=\"\">You might be wondering how we defined the \u201coptimal\u201d filter settings. At one level, the answer is simple: The optimal filter is the one that maximizes the signal-to-noise ratio without producing too much waveform distortion. The complexities arise in quantifying the signal-to-noise ratio, quantifying the waveform distortion, and deciding how much waveform distortion is \u201ctoo much\u201d. We believe we have found reasonably straightforward and practical solutions to these problems, which you can read about in the published papers.</p>",
      "author": "Steve Luck",
      "published_date": "2024-02-04T23:46:20+00:00",
      "source": "Erp Boot Camp",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 568,
      "reading_time": 2,
      "created_at": "2025-11-11T01:41:33.787241+00:00",
      "updated_at": "2025-11-11T03:10:21.610393+00:00",
      "metadata": {
        "processed_at": "2025-11-11T03:10:21.610395+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "b3cd4fc4257e4deef4e24f2c3cdd8b67",
      "url": "https://brain.ieee.org/publications/neuroethics-framework/education/education-social-and-cultural-issues/education-social-and-cultural-issues/",
      "title": "Education: Social and Cultural Issues",
      "content": "Devices that therapeutically aid users with cognitive and learning disabilities/differences should not be equally applied to a general population seeking learning advantages. It must not be assumed that therapies able to improve cognition for mental and cognitive disorders (such as executive control and working memory) would work similarly on nondisabled people linearly to improve their cognition above standard levels. Although ...",
      "author": "Adriel Carridice",
      "published_date": "2025-02-05T15:45:23+00:00",
      "source": "Brain",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 61,
      "reading_time": 1,
      "created_at": "2025-11-11T01:41:31.019440+00:00",
      "updated_at": "2025-11-11T03:10:21.610397+00:00",
      "metadata": {
        "processed_at": "2025-11-11T03:10:21.610398+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "902df770854423011000edd238dd0b09",
      "url": "http://ieeexplore.ieee.org/document/10972321",
      "title": "A Pilot Study on Fabric-Based Pneumatic Soft Gloves for Assisting Patients With Severe Brachial Plexus Injury",
      "content": "Objective: Robotic gloves show promise in hand assistance due to their wearability and home-based potential, yet empirical research remains limited. This pilot study presents a fabric-based pneumatic soft glove, aiming to identify its potential and challenges in clinical practice by evaluating its effectiveness in assisting patients with severe brachial plexus injury (BPI). Methods: The glove integrates a thumb abduction actuator and four bidirectional fabric-based pneumatic actuators (FPAs) with asymmetric chambers for high output force. Sixteen healthy volunteers and five individuals with BPI, all of whom lacked active hand and wrist movements, were recruited. Participants performed object grasping across 25 cm. The healthy group performed seven tasks using objects weighing up to 2 kg, with muscle activities recorded for analysis. The BPI group further performed tasks with eight objects from the action research arm test (ARAT) and twelve objects for activities of daily living (ADLs), encompassing various sizes, weights, and geometries. Results: In the healthy group, sEMG showed a decrease in 89.3% of trials, with 56.0% of these decreases being significant (p$< $0.01). For BPI group, the range of motion (ROM) improved, ranging from 28.5 $\\pm$ 7.9$^{\\circ }$ to 63.1 $\\pm$ 5.1$^{\\circ }$ (thumb) and 10.3 $\\pm$ 17.5$^{\\circ }$ to 122.5 $\\pm$ 19.0$^{\\circ }$ (index finger). With a zero baseline for all tasks, their completion rates were 6.8 $\\pm$ 0.8 out of 8 for ARAT tasks and 10.0 $\\pm$ 1.7 out of 12 for ADLs. Conclusion: The fabric-based pneumatic soft glove significantly enhanced the hand function of patients with severe BPI, demonstrating its potential for hand assistance.",
      "author": "",
      "published_date": "2025-04-22T13:18:18+00:00",
      "source": "Transactions Biomedical Engineering",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 256,
      "reading_time": 1,
      "created_at": "2025-11-10T23:40:13.004141+00:00",
      "updated_at": "2025-11-11T01:11:50.299796+00:00",
      "metadata": {
        "processed_at": "2025-11-11T01:11:50.299809+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "97b029153a3ff523dd3e21c1b2ebeaf8",
      "url": "http://ieeexplore.ieee.org/document/10971951",
      "title": "Building and Sustaining Open-Source Medical Device Projects",
      "content": "The open-source development model has been successfully applied to consumer and enterprise software, and recently to consumer hardware. Medical devices may become a beneficiary of this trend, as open-source medical device development has the potential to reduce costs, democratize patient access, and provide continued support to abandoned devices from failed companies. Unlike the consumer device market, the medical device market is highly regulated and involves considerable manufacturer liability that may limit the use of open-source technology. This review of open-source medical device development explores the current state of development in research and clinical products and suggests best practices for creating sustainable and effective open-source medical devices.",
      "author": "",
      "published_date": "2025-04-21T13:18:20+00:00",
      "source": "Transactions Biomedical Engineering",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 106,
      "reading_time": 1,
      "created_at": "2025-11-10T23:40:13.004103+00:00",
      "updated_at": "2025-11-11T01:11:50.299813+00:00",
      "metadata": {
        "processed_at": "2025-11-11T01:11:50.299815+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "0077ae0d8a956fdc349ff6b154403d02",
      "url": "http://ieeexplore.ieee.org/document/10971210",
      "title": "A Neighbor-Sensitive Multi-Modal Flexible Learning Framework for Improved Prostate Tumor Segmentation in Anisotropic MR Images",
      "content": "Accurate segmentation of prostate tumors from multi-modal magnetic resonance (MR) images is crucial for the diagnosis and treatment of prostate cancer. However, the robustness of existing segmentation methods is limited, mainly because these methods 1) fail to flexibly assess subject-specific information of each MR modality and integrate modality-specific information for accurate tumor delineation, and 2) lack effective utilization of inter-slice information across thick slices in MR images to segment the tumor as a whole 3D volume. In this work, we propose a neighbor-sensitive multi-modal flexible learning network (NesMFle) for accurate prostate tumor segmentation from multi-modal anisotropic MR images. Specifically, we perform multi-modal fusion for each slice by developing a Modality-informativeness Flexible Learning (MFLe) module for selecting and flexibly fusing informative representations of each modality based on inter-modality correlation in a pre-trained manner. After that, we exploit inter-slice feature correlation to derive volumetric tumor segmentation. In particular, we first use a Unet variant equipped with a Sequence Layer, which can coarsely capture slice relationship using 3D convolution and an attention mechanism. Then, we introduce an Activation Mapping Guidance (AMG) module to refine slice-wise representations using information from adjacent slices, ensuring consistent tumor segmentation across neighboring slices based on slice quality assessment on activation maps. Besides, during the network training, we further apply a random mask strategy to each MR modality for improving feature representation efficiency. Experiments on both in-house and public (PICAI) multi-modal prostate tumor datasets demonstrate that our proposed NesMFLe achieves competitive performance compared to state-of-the-art methods.",
      "author": "",
      "published_date": "2025-04-21T13:18:20+00:00",
      "source": "Transactions Biomedical Engineering",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 247,
      "reading_time": 1,
      "created_at": "2025-11-10T23:40:13.004072+00:00",
      "updated_at": "2025-11-11T01:11:50.299818+00:00",
      "metadata": {
        "processed_at": "2025-11-11T01:11:50.299820+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "239d99da9858bdb1b2399131dde345ea",
      "url": "https://www.sciencedirect.com/science/article/pii/S0006899325006018?dgcid=rss_sd_all",
      "title": "Aerobic exercise modulates plasma oxidized lipid metabolites and neurotransmitters in Parkinson\u2019s disease motor subtypes",
      "content": "<p>Publication date: 15 December 2025</p><p><b>Source:</b> Brain Research, Volume 1869</p><p>Author(s): Yangdanyu Li, Yuning Liu, Zihao Lin, Quanqing Wei, Jie Xiang, Wei Zhang, Liguo Dong, Fujia Li, Jie Zu, Guiyun Cui, Chuanying Xu</p>",
      "author": "",
      "published_date": null,
      "source": "Brain Research",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 31,
      "reading_time": 1,
      "created_at": "2025-11-10T23:40:02.082880+00:00",
      "updated_at": "2025-11-11T01:11:50.299825+00:00",
      "metadata": {
        "processed_at": "2025-11-11T01:11:50.299827+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "ff9aefe17ebe2dd9814289080a9642ac",
      "url": "https://www.sciencedirect.com/science/article/pii/S0306452225010498?dgcid=rss_sd_all",
      "title": "Impact of routine rehabilitation training on motor function and activities of daily living in oldest-old patients who have experienced a stroke",
      "content": "<p>Publication date: 5 December 2025</p><p><b>Source:</b> Neuroscience, Volume 590</p><p>Author(s): Yu-Juan Han, Hao-Ming Xu, Shan Han, Pei Dai, Xiao-Ping Kang</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroscience Journal",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 18,
      "reading_time": 1,
      "created_at": "2025-11-10T23:40:00.676101+00:00",
      "updated_at": "2025-11-11T01:11:50.299829+00:00",
      "metadata": {
        "processed_at": "2025-11-11T01:11:50.299831+00:00",
        "processing_method": "github_actions"
      }
    }
  ]
}