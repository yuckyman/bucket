{
  "last_updated": "2025-10-23T22:13:53.531882+00:00",
  "pending_count": 985,
  "processed_count": 15,
  "pending_articles": [
    {
      "id": "df2ef9da3a96611c7acaaa80f4e1c89d",
      "url": "https://arxiv.org/abs/2510.19031",
      "title": "CLiVR: Conversational Learning System in Virtual Reality with AI-Powered Patients",
      "content": "arXiv:2510.19031v1 Announce Type: new \nAbstract: Simulations constitute a fundamental component of medical and nursing education and traditionally employ standardized patients (SP) and high-fidelity manikins to develop clinical reasoning and communication skills. However, these methods require substantial resources, limiting accessibility and scalability. In this study, we introduce CLiVR, a Conversational Learning system in Virtual Reality that integrates large language models (LLMs), speech processing, and 3D avatars to simulate realistic doctor-patient interactions. Developed in Unity and deployed on the Meta Quest 3 platform, CLiVR enables trainees to engage in natural dialogue with virtual patients. Each simulation is dynamically generated from a syndrome-symptom database and enhanced with sentiment analysis to provide feedback on communication tone. Through an expert user study involving medical school faculty (n=13), we assessed usability, realism, and perceived educational impact. Results demonstrated strong user acceptance, high confidence in educational potential, and valuable feedback for improvement. CLiVR offers a scalable, immersive supplement to SP-based training.",
      "author": "Akilan Amithasagaran, Sagnik Dakshit, Bhavani Suryadevara, Lindsey Stockton",
      "published_date": "2025-10-23T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 154,
      "reading_time": 1,
      "created_at": "2025-10-23T21:38:23.112790+00:00",
      "updated_at": "2025-10-23T21:38:23.112792+00:00"
    },
    {
      "id": "38de6e9dd74dbe9a0c20fadedcbb6dcf",
      "url": "https://arxiv.org/abs/2510.19024",
      "title": "Examining the Impact of Label Detail and Content Stakes on User Perceptions of AI-Generated Images on Social Media",
      "content": "arXiv:2510.19024v1 Announce Type: new \nAbstract: AI-generated images are increasingly prevalent on social media, raising concerns about trust and authenticity. This study investigates how different levels of label detail (basic, moderate, maximum) and content stakes (high vs. low) influence user engagement with and perceptions of AI-generated images through a within-subjects experimental study with 105 participants. Our findings reveal that increasing label detail enhances user perceptions of label transparency but does not affect user engagement. However, content stakes significantly impact user engagement and perceptions, with users demonstrating higher engagement and trust in low-stakes images. These results suggest that social media platforms can adopt detailed labels to improve transparency without compromising user engagement, offering insights for effective labeling strategies for AI-generated content.",
      "author": "Jingruo Chen, TungYen Wang, Marie Williams, Natalia Jordan, Mingyi Shao, Linda Zhang, Susan R. Fussell",
      "published_date": "2025-10-23T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 119,
      "reading_time": 1,
      "created_at": "2025-10-23T21:38:23.112761+00:00",
      "updated_at": "2025-10-23T21:38:23.112763+00:00"
    },
    {
      "id": "ff85bac5bc6ceaccf5814d1da62550fc",
      "url": "https://arxiv.org/abs/2510.19017",
      "title": "SocializeChat: A GPT-Based AAC Tool Grounded in Personal Memories to Support Social Communication",
      "content": "arXiv:2510.19017v1 Announce Type: new \nAbstract: Elderly people with speech impairments often face challenges in engaging in meaningful social communication, particularly when using Augmentative and Alternative Communication (AAC) tools that primarily address basic needs. Moreover, effective chats often rely on personal memories, which is hard to extract and reuse. We introduce SocializeChat, an AAC tool that generates sentence suggestions by drawing on users' personal memory records. By incorporating topic preference and interpersonal closeness, the system reuses past experience and tailors suggestions to different social contexts and conversation partners. SocializeChat not only leverages past experiences to support interaction, but also treats conversations as opportunities to create new memories, fostering a dynamic cycle between memory and communication. A user study shows its potential to enhance the inclusivity and relevance of AAC-supported social interaction.",
      "author": "Wei Xiang, Yunkai Xu, Yuyang Fang, Zhuyu Teng, Zhaoqu Jiang, Beijia Hu, Jinguo Yang",
      "published_date": "2025-10-23T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 130,
      "reading_time": 1,
      "created_at": "2025-10-23T21:38:23.112735+00:00",
      "updated_at": "2025-10-23T21:38:23.112737+00:00"
    },
    {
      "id": "77ae1efa4d42401078aa2f25cae40045",
      "url": "https://arxiv.org/abs/2510.19008",
      "title": "Plural Voices, Single Agent: Towards Inclusive AI in Multi-User Domestic Spaces",
      "content": "arXiv:2510.19008v1 Announce Type: new \nAbstract: Domestic AI agents faces ethical, autonomy, and inclusion challenges, particularly for overlooked groups like children, elderly, and Neurodivergent users. We present the Plural Voices Model (PVM), a novel single-agent framework that dynamically negotiates multi-user needs through real-time value alignment, leveraging diverse public datasets on mental health, eldercare, education, and moral reasoning. Using human+synthetic curriculum design with fairness-aware scenarios and ethical enhancements, PVM identifies core values, conflicts, and accessibility requirements to inform inclusive principles. Our privacy-focused prototype features adaptive safety scaffolds, tailored interactions (e.g., step-by-step guidance for Neurodivergent users, simple wording for children), and equitable conflict resolution. In preliminary evaluations, PVM outperforms multi-agent baselines in compliance (76% vs. 70%), fairness (90% vs. 85%), safety-violation rate (0% vs. 7%), and latency. Design innovations, including video guidance, autonomy sliders, family hubs, and adaptive safety dashboards, demonstrate new directions for ethical and inclusive domestic AI, for building user-centered agentic systems in plural domestic contexts. Our Codes and Model are been open sourced, available for reproduction: https://github.com/zade90/Agora",
      "author": "Joydeep Chandra, Satyam Kumar Navneet",
      "published_date": "2025-10-23T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 167,
      "reading_time": 1,
      "created_at": "2025-10-23T21:38:23.112708+00:00",
      "updated_at": "2025-10-23T21:38:23.112710+00:00"
    },
    {
      "id": "e36c31977729bf7b0ffb1426a77146f8",
      "url": "https://arxiv.org/abs/2510.18881",
      "title": "Detecting AI-Assisted Cheating in Online Exams through Behavior Analytics",
      "content": "arXiv:2510.18881v1 Announce Type: new \nAbstract: AI-assisted cheating has emerged as a significant threat in the context of online exams. Advanced browser extensions now enable large language models (LLMs) to answer questions presented in online exams within seconds, thereby compromising the security of these assessments. In this study, the behaviors of students (N = 52) on an online exam platform during a proctored, face-to-face exam were analyzed using clustering methods, with the aim of identifying groups of students exhibiting suspicious behavior potentially associated with cheating. Additionally, students in different clusters were compared in terms of their exam scores. Suspicious exam behaviors in this study were defined as selecting text within the question area, right-clicking, and losing focus on the exam page. The total frequency of these behaviors performed by each student during the exam was extracted, and k-Means clustering was employed for the analysis. The findings revealed that students were classified into six clusters based on their suspicious behaviors. It was found that students in four of the six clusters, representing approximately 33% of the total sample, exhibited suspicious behaviors at varying levels. When the exam scores of these students were compared, it was observed that those who engaged in suspicious behaviors scored, on average, 30-40 points higher than those who did not. Although further research is necessary to validate these findings, this preliminary study provides significant insights into the detection of AI-assisted cheating in online exams using behavior analytics.",
      "author": "G\\\"okhan Ak\\c{c}ap{\\i}nar",
      "published_date": "2025-10-23T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 239,
      "reading_time": 1,
      "created_at": "2025-10-23T21:38:23.112676+00:00",
      "updated_at": "2025-10-23T21:38:23.112678+00:00"
    },
    {
      "id": "81658c3420b4e6ec0cbe547570d0d877",
      "url": "https://arxiv.org/abs/2510.18880",
      "title": "Towards Better Health Conversations: The Benefits of Context-seeking",
      "content": "arXiv:2510.18880v1 Announce Type: new \nAbstract: Navigating health questions can be daunting in the modern information landscape. Large language models (LLMs) may provide tailored, accessible information, but also risk being inaccurate, biased or misleading. We present insights from 4 mixed-methods studies (total N=163), examining how people interact with LLMs for their own health questions. Qualitative studies revealed the importance of context-seeking in conversational AIs to elicit specific details a person may not volunteer or know to share. Context-seeking by LLMs was valued by participants, even if it meant deferring an answer for several turns. Incorporating these insights, we developed a \"Wayfinding AI\" to proactively solicit context. In a randomized, blinded study, participants rated the Wayfinding AI as more helpful, relevant, and tailored to their concerns compared to a baseline AI. These results demonstrate the strong impact of proactive context-seeking on conversational dynamics, and suggest design patterns for conversational AI to help navigate health topics.",
      "author": "Rory Sayres, Yuexing Hao, Abbi Ward, Amy Wang, Beverly Freeman, Serena Zhan, Diego Ardila, Jimmy Li, I-Ching Lee, Anna Iurchenko, Siyi Kou, Kartikeya Badola, Jimmy Hu, Bhawesh Kumar, Keith Johnson, Supriya Vijay, Justin Krogue, Avinatan Hassidim, Yossi Matias, Dale R. Webster, Sunny Virmani, Yun Liu, Quang Duong, Mike Schaekermann",
      "published_date": "2025-10-23T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 153,
      "reading_time": 1,
      "created_at": "2025-10-23T21:38:23.112639+00:00",
      "updated_at": "2025-10-23T21:38:23.112641+00:00"
    },
    {
      "id": "efdfd28b720cefb1b9ea6340f3ed14dd",
      "url": "https://arxiv.org/abs/2510.18879",
      "title": "FIRETWIN: Digital Twin Advancing Multi-Modal Sensing, Interactive Analytics for Wildfire Response",
      "content": "arXiv:2510.18879v1 Announce Type: new \nAbstract: Current wildfire management systems lack integrated virtual environments that combine historical data with immersive digital representations, hindering deep analysis and effective decision making. This paper introduces FIRETWIN, a cyber-physical Digital Twin (DT) designed to bridge complex ecological data and operationally relevant, high-fidelity visualizations for actionable incident response. FIRETWIN generates a dynamic 3D virtual globe that visualizes evolving fire behavior in real time, driven by output from physics-based fire models. The system supports multimodal perspectives, including satellite and drone viewpoints comparable to NOAA GOES-18 imagery - enabling comprehensive scenario analysis. Users interact with the environment to assess current fire conditions, anticipate progression, and evaluate available resources. Leveraging Google Maps, Unreal Engine, and pre-generated outputs from the CAWFE coupled weather-wildland fire model, we reconstruct the spread of the 2014 King Fire in California Eldorado National Forest. Procedural forest generation and particle-level fire control enable a level of realism and interactivity not possible in field training.",
      "author": "Mayamin Hamid Raha, Ali Reza Tavakkoli, Chris Webb, Mobin Habibpour, Janice Coen, Eric Rowell, Fatemeh Afghah",
      "published_date": "2025-10-23T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 158,
      "reading_time": 1,
      "created_at": "2025-10-23T21:38:23.112609+00:00",
      "updated_at": "2025-10-23T21:38:23.112611+00:00"
    },
    {
      "id": "da67cddba7f02e9d3658451925f70d85",
      "url": "https://arxiv.org/abs/2510.18878",
      "title": "CityAQVis: Integrated ML-Visualization Sandbox Tool for Pollutant Estimation in Urban Regions Using Multi-Source Data (Software Article)",
      "content": "arXiv:2510.18878v1 Announce Type: new \nAbstract: Urban air pollution poses significant risks to public health, environmental sustainability, and policy planning. Effective air quality management requires predictive tools that can integrate diverse datasets and communicate complex spatial and temporal pollution patterns. There is a gap in interactive tools with seamless integration of forecasting and visualization of spatial distributions of air pollutant concentrations. We present CityAQVis, an interactive machine learning ML sandbox tool designed to predict and visualize pollutant concentrations at the ground level using multi-source data, which includes satellite observations, meteorological parameters, population density, elevation, and nighttime lights. While traditional air quality visualization tools often lack forecasting capabilities, CityAQVis enables users to build and compare predictive models, visualizing the model outputs and offering insights into pollution dynamics at the ground level. The pilot implementation of the tool is tested through case studies predicting nitrogen dioxide (NO2) concentrations in metropolitan regions, highlighting its adaptability to various pollutants. Through an intuitive graphical user interface (GUI), the user can perform comparative visualizations of the spatial distribution of surface-level pollutant concentration in two different urban scenarios. Our results highlight the potential of ML-driven visual analytics to improve situational awareness and support data-driven decision-making in air quality management.",
      "author": "Brij Bridhin Desai, Yukta Arvind, Aswathi Mundayatt, Jaya Sreevalsan-Nair",
      "published_date": "2025-10-23T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 201,
      "reading_time": 1,
      "created_at": "2025-10-23T21:38:23.112575+00:00",
      "updated_at": "2025-10-23T21:38:23.112577+00:00"
    },
    {
      "id": "c3f83ebb5e961168865d7844611e4f95",
      "url": "https://arxiv.org/abs/2510.18877",
      "title": "LLM Bazaar: A Service Design for Supporting Collaborative Learning with an LLM-Powered Multi-Party Collaboration Infrastructure",
      "content": "arXiv:2510.18877v1 Announce Type: new \nAbstract: For nearly two decades, conversational agents have played a critical role in structuring interactions in collaborative learning, shaping group dynamics, and supporting student engagement. The recent integration of large language models (LLMs) into these agents offers new possibilities for fostering critical thinking and collaborative problem solving. In this work, we begin with an open source collaboration support architecture called Bazaar and integrate an LLM-agent shell that enables introduction of LLM-empowered, real time, context sensitive collaborative support for group learning. This design and infrastructure paves the way for exploring how tailored LLM-empowered environments can reshape collaborative learning outcomes and interaction patterns.",
      "author": "Zhen Wu, Jiaxin Shi, R. Charles Murray, Carolyn Ros\\'e, Micah San Andres",
      "published_date": "2025-10-23T04:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 105,
      "reading_time": 1,
      "created_at": "2025-10-23T21:38:23.112532+00:00",
      "updated_at": "2025-10-23T21:38:23.112537+00:00"
    },
    {
      "id": "58b30a10902f20070a11b3e8a45ee35a",
      "url": "https://arxiv.org/abs/2502.02904",
      "title": "ScholaWrite: A Dataset of End-to-End Scholarly Writing Process",
      "content": "arXiv:2502.02904v4 Announce Type: replace-cross \nAbstract: Writing is a cognitively demanding activity that requires constant decision-making, heavy reliance on working memory, and frequent shifts between tasks of different goals. To build writing assistants that truly align with writers' cognition, we must capture and decode the complete thought process behind how writers transform ideas into final texts. We present ScholaWrite, the first dataset of end-to-end scholarly writing, tracing the multi-month journey from initial drafts to final manuscripts. We contribute three key advances: (1) a Chrome extension that unobtrusively records keystrokes on Overleaf, enabling the collection of realistic, in-situ writing data; (2) a novel corpus of full scholarly manuscripts, enriched with fine-grained annotations of cognitive writing intentions. The dataset includes \\LaTeX-based edits from five computer science preprints, capturing nearly 62K text changes over four months; and (3) analyses and insights into the micro-dynamics of scholarly writing, highlighting gaps between human writing processes and the current capabilities of large language models (LLMs) in providing meaningful assistance. ScholaWrite underscores the value of capturing end-to-end writing data to develop future writing assistants that support, not replace, the cognitive work of scientists.",
      "author": "Khanh Chi Le, Linghe Wang, Minhwa Lee, Ross Volkov, Luan Tuyen Chau, Dongyeop Kang",
      "published_date": "2025-10-23T04:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 185,
      "reading_time": 1,
      "created_at": "2025-10-23T21:38:21.935874+00:00",
      "updated_at": "2025-10-23T21:38:21.935875+00:00"
    }
  ],
  "recently_processed": [
    {
      "id": "7cd5915b404adde9692f79fbf455044d",
      "url": "http://ieeexplore.ieee.org/document/11037651",
      "title": "A Force/Torque Taxonomy for Classifying States During Physical Co-Manipulation",
      "content": "Achieving seamless human-robot collaboration requires a deeper understanding of how agents manage and communicate forces during shared tasks. Force interactions during collaborative manipulation are inherently complex, especially when considering how they evolve over time. To address this complexity, we propose a taxonomy of decomposed force and torque components, providing a structured framework for examining haptic communication and informing the development of robots capable of performing meaningful collaborative manipulation tasks with human partners. We propose a standardized terminology for force decomposition and classification, bridging the varied language in previous literature in the field, and conduct a review of physical human-human interaction and haptic communication. The proposed taxonomy allows for a more effective and nuanced discussion of important force combinations that we expect to occur during collaborative manipulation (between human-human or human-robot teams). We also include example scenarios to illustrate the value of the proposed taxonomy in describing interactions between agents.",
      "author": "",
      "published_date": "2025-06-17T13:16:38+00:00",
      "source": "Transactions Haptics",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 149,
      "reading_time": 1,
      "created_at": "2025-10-23T21:38:30.345070+00:00",
      "updated_at": "2025-10-23T22:13:53.428634+00:00",
      "metadata": {
        "processed_at": "2025-10-23T22:13:53.428643+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "bffad7ff78c038ce61497f8206575f26",
      "url": "http://ieeexplore.ieee.org/document/11045422",
      "title": "Haptic Relocation Away From the Fingertip: Where, Why, and How",
      "content": "Tactile haptic devices are often designed to render meaningful, complex, and realistic touch-based information on users\u2019 skin. While fingertips and hands are the most preferred body locations to render haptic feedback, recent trends allow such feedback to be extended to alternative body locations (e.g., wrist, arm, torso, foot) for various scenarios due to reasons such as wearability and needs of the application. In this paper, I address the new concept of haptic relocation. It refers to scenarios in which the expected feedback is related to the fingertips but rendered on a different body location instead \u2013 e.g., contact forces registered by two robotic fingers during teleoperation rendered to the users\u2019 wrist instead of the fingers. I investigated the design choices of wearable haptic devices for haptic relocation concerning different body locations, targeted applications, and actuator selection. I discuss approaches and design choices from the literature by speculating on the possible reasons, and conclude the paper by highlighting some challenges and issues to be mindful of in the future. This paper will guide engineers and researchers in searching for alternative haptic rendering solutions \u2013 especially when fingers and hands are not available for haptic interaction.",
      "author": "",
      "published_date": "2025-06-20T13:16:43+00:00",
      "source": "Transactions Haptics",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 194,
      "reading_time": 1,
      "created_at": "2025-10-23T21:38:30.345038+00:00",
      "updated_at": "2025-10-23T22:13:53.428647+00:00",
      "metadata": {
        "processed_at": "2025-10-23T22:13:53.428649+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "654c67a50800e0d8df1eb841fa063ae1",
      "url": "http://ieeexplore.ieee.org/document/10918829",
      "title": "Tactile\u2013Thermal Interactions: Cooperation and Competition",
      "content": "This review focuses on the interactions between the cutaneous senses, and in particular touch and temperature, as these are the most relevant for developing skin-based display technologies for use in virtual reality (VR) and for designing multimodal haptic devices. A broad spectrum of research is reviewed ranging from studies that have examined the mechanisms involved in thermal intensification and tactile masking, to more applied work that has focused on implementing thermal-tactile illusions such as thermal referral and illusory wetness in VR environments. Research on these tactile-thermal illusions has identified the differences between the senses of cold and warmth in terms of their effects on the perception of object properties and the prevalence of the perceptual experiences elicited. They have also underscored the fundamental spatial and temporal differences between the tactile and thermal senses. The wide-ranging body of research on compound sensations such as wetness and stickiness has highlighted the mechanisms involved in sensing moisture and provided a framework for measuring these sensations in a variety of contexts. Although the interactions between the two senses are complex, it is clear that the addition of thermal inputs to a tactile display enhances both user experience and enables novel sensory experiences.",
      "author": "",
      "published_date": "2025-03-10T13:16:41+00:00",
      "source": "Transactions Haptics",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 198,
      "reading_time": 1,
      "created_at": "2025-10-23T21:38:30.344997+00:00",
      "updated_at": "2025-10-23T22:13:53.428654+00:00",
      "metadata": {
        "processed_at": "2025-10-23T22:13:53.428656+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "604cffaea5736d8c2935253598862e29",
      "url": "http://ieeexplore.ieee.org/document/11174044",
      "title": "Twenty Years of World Haptics: Retrospective and Future Directions",
      "content": "null",
      "author": "",
      "published_date": "2025-09-19T13:16:57+00:00",
      "source": "Transactions Haptics",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 1,
      "reading_time": 1,
      "created_at": "2025-10-23T21:38:30.344955+00:00",
      "updated_at": "2025-10-23T22:13:53.428658+00:00",
      "metadata": {
        "processed_at": "2025-10-23T22:13:53.428660+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "65fcee7a3858adcf1bad71db41168384",
      "url": "http://ieeexplore.ieee.org/document/11174043",
      "title": "Table of Contents",
      "content": "null",
      "author": "",
      "published_date": "2025-09-19T13:16:57+00:00",
      "source": "Transactions Haptics",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 1,
      "reading_time": 1,
      "created_at": "2025-10-23T21:38:30.344934+00:00",
      "updated_at": "2025-10-23T22:13:53.428662+00:00",
      "metadata": {
        "processed_at": "2025-10-23T22:13:53.428663+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "0538cf39a75749ed45e73a2f60084b3a",
      "url": "https://www.embs.org/ojemb/search-for-editor-in-chief/#new_tab",
      "title": "Call for Applications Editor-in-Chief: IEEE Open Journal of Engineering in Medicine and Biology",
      "content": "<p>The post <a href=\"https://www.embs.org/ojemb/search-for-editor-in-chief/#new_tab\">Call for Applications Editor-in-Chief: IEEE Open Journal of Engineering in Medicine and Biology</a> appeared first on <a href=\"https://www.embs.org\">IEEE EMBS</a>.</p>",
      "author": "Deidre Artis",
      "published_date": "2025-04-04T13:34:20+00:00",
      "source": "Embs",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 22,
      "reading_time": 1,
      "created_at": "2025-10-23T19:39:04.504040+00:00",
      "updated_at": "2025-10-23T20:16:14.962284+00:00",
      "metadata": {
        "processed_at": "2025-10-23T20:16:14.962293+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "f7f416118a32b0e243911d8ef725d75c",
      "url": "https://www.embs.org/blog-post/change-foi-for-ieee-embs/",
      "title": "Notice to IEEE EMBS Members: Change to Field of Interest",
      "content": "<p>The post <a href=\"https://www.embs.org/blog-post/change-foi-for-ieee-embs/\">Notice to IEEE EMBS Members: Change to Field of Interest</a> appeared first on <a href=\"https://www.embs.org\">IEEE EMBS</a>.</p>",
      "author": "Nancy Zimmerman",
      "published_date": "2025-04-27T21:41:29+00:00",
      "source": "Embs",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 19,
      "reading_time": 1,
      "created_at": "2025-10-23T19:39:04.504020+00:00",
      "updated_at": "2025-10-23T20:16:14.962298+00:00",
      "metadata": {
        "processed_at": "2025-10-23T20:16:14.962299+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "1afc4c4e54184a244c216bb5b044f863",
      "url": "https://www.embs.org/blog-post/change-foi-for-ieee-embs/#new_tab",
      "title": "Notice to IEEE EMBS Members: Change to Field of Interest",
      "content": "<p>The post <a href=\"https://www.embs.org/blog-post/change-foi-for-ieee-embs/#new_tab\">Notice to IEEE EMBS Members: Change to Field of Interest</a> appeared first on <a href=\"https://www.embs.org\">IEEE EMBS</a>.</p>",
      "author": "Nancy Zimmerman",
      "published_date": "2025-04-27T21:46:11+00:00",
      "source": "Embs",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 19,
      "reading_time": 1,
      "created_at": "2025-10-23T19:39:04.504002+00:00",
      "updated_at": "2025-10-23T20:16:14.962302+00:00",
      "metadata": {
        "processed_at": "2025-10-23T20:16:14.962303+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "5d49304b30e3f1cca1ea313fc654375e",
      "url": "https://www.embs.org/uncategorized/call-for-adcom-nominations/",
      "title": "Open Call for AdCom Nominations",
      "content": "<p>The post <a href=\"https://www.embs.org/uncategorized/call-for-adcom-nominations/\">Open Call for AdCom Nominations</a> appeared first on <a href=\"https://www.embs.org\">IEEE EMBS</a>.</p>",
      "author": "Nancy Zimmerman",
      "published_date": "2025-05-02T17:09:21+00:00",
      "source": "Embs",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 14,
      "reading_time": 1,
      "created_at": "2025-10-23T19:39:04.503984+00:00",
      "updated_at": "2025-10-23T20:16:14.962305+00:00",
      "metadata": {
        "processed_at": "2025-10-23T20:16:14.962307+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "3727d0ebc34094cb889f4f09a3e22f0e",
      "url": "https://www.embs.org/press/embc-eic-sunghoon-ivan-lee/",
      "title": "IEEE EMBS Appoints Sunghoon \u201cIvan\u201d Lee, Ph.D., as Editor-in-Chief of EMBC Proceedings, the Leading Biomedical Engineering Conference Publication",
      "content": "<p>(Piscataway, N.J., August 12, 2025) Sunghoon \u201cIvan\u201d Lee, Ph.D., a Donna M. and Robert J. Manning Faculty Fellow and an Associate Professor of computer science, electrical and computer engineering, and&#8230; <a class=\"continue\" href=\"https://www.embs.org/press/embc-eic-sunghoon-ivan-lee/\">Continue Reading<span> IEEE EMBS Appoints Sunghoon \u201cIvan\u201d Lee, Ph.D., as Editor-in-Chief of EMBC Proceedings, the Leading Biomedical Engineering Conference Publication</span></a></p>\n<p>The post <a href=\"https://www.embs.org/press/embc-eic-sunghoon-ivan-lee/\">IEEE EMBS Appoints Sunghoon \u201cIvan\u201d Lee, Ph.D., as Editor-in-Chief of EMBC Proceedings, the Leading Biomedical Engineering Conference Publication</a> appeared first on <a href=\"https://www.embs.org\">IEEE EMBS</a>.</p>",
      "author": "Nancy Zimmerman",
      "published_date": "2025-08-19T14:41:24+00:00",
      "source": "Embs",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 79,
      "reading_time": 1,
      "created_at": "2025-10-23T19:39:04.503964+00:00",
      "updated_at": "2025-10-23T20:16:14.962312+00:00",
      "metadata": {
        "processed_at": "2025-10-23T20:16:14.962313+00:00",
        "processing_method": "github_actions"
      }
    }
  ]
}