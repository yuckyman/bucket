{
  "last_updated": "2025-12-21T04:33:47.709991+00:00",
  "pending_count": 703,
  "processed_count": 297,
  "pending_articles": [
    {
      "id": "3d6b5f8f7d117269f6d483cfe999ae04",
      "url": "https://www.frontiersin.org/articles/10.3389/fncom.2025.1641519",
      "title": "Fractal memory structure in the spatiotemporal learning rule",
      "content": "The spatiotemporal learning rule (STLR) can reproduce synaptic plasticity in the hippocampus. Analysis of the synaptic weights in the network with the STLR is challenging. Consequently, our previous research only focused on the network's outputs. However, a detailed analysis of the STLR requires focusing on the synaptic weights themselves. To address this issue, we mapped the synaptic weights to a distance space and analyzed the characteristics of the STLR. The results indicate that the synaptic weights form a fractal-like structure in Euclidean distance space. Furthermore, three analytical approaches\u2014multi-dimensional scaling, estimating fractal dimension, and modeling with an iterated function system\u2014demonstrate that the STLR forms a fractal structure in the synaptic weights through fractal coding. These findings contribute to clarifying the learning mechanisms in the hippocampus.",
      "author": "Yoshihiko Horio",
      "published_date": "2025-12-16T00:00:00+00:00",
      "source": "Frontiers Computational Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 124,
      "reading_time": 1,
      "created_at": "2025-12-20T22:42:24.823690+00:00",
      "updated_at": "2025-12-20T22:42:24.823695+00:00"
    },
    {
      "id": "e533e42c8519cc6178e085ef3d6fd4bf",
      "url": "https://www.frontiersin.org/articles/10.3389/fnhum.2025.1708257",
      "title": "Task-constrained self-initiated attention shifts are indexed by frontal-midline theta ramping",
      "content": "In everyday vision, we often shift attention internally without external cues. These self-initiated attention shifts are fundamental to voluntary behavior but are poorly understood because most studies use cue-based paradigms that predetermine when and where to shift attention. To address this gap, we designed a multi-sequential-choice rapid serial visual presentation (RSVP) paradigm with identical visual inputs to dissociate internal and external determinants of attention across three voluntary shift types: task-constrained self-initiated, externally instructed, and unconstrained free-viewing. Participants viewed four simultaneous streams of letters and made overt attention shifts among them, while EEG was recorded. We time-locked theta (4\u20137 Hz) and alpha (8\u201312 Hz) oscillations to shift onset and found distinct signatures for each condition. Notably, a frontal-midline theta ramping was observed before self-initiated shifts but not before instructed or free-viewing shifts, suggesting a preparatory buildup of cognitive control specific to internally driven shifts. Concurrently, sustained suppression of posterior alpha occurred before self-initiated shifts. In contrast, instructed and free-viewing shifts showed relatively higher posterior alpha. These findings suggest that internally generated, goal-driven shifts engage an anticipatory frontal control mechanism indexed by theta increase and reduce posterior inhibition, whereas externally cued or unguided shifts do not. By isolating these condition-specific neural dynamics under identical external stimuli, our study identifies a unique oscillatory signature, frontal-midline theta ramping, associated with task-constrained self-initiated attention shifts.",
      "author": "Satoshi Shioiri",
      "published_date": "2025-12-16T00:00:00+00:00",
      "source": "Frontiers Human Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 220,
      "reading_time": 1,
      "created_at": "2025-12-20T22:42:23.216749+00:00",
      "updated_at": "2025-12-20T22:42:23.216750+00:00"
    },
    {
      "id": "a62b50097ef389a0062d67d717405a8b",
      "url": "https://claude.com/chrome",
      "title": "Claude in Chrome",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46339777\">Comments</a>",
      "author": "",
      "published_date": "2025-12-20T21:26:14+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-20T22:41:52.282105+00:00",
      "updated_at": "2025-12-20T22:41:52.282106+00:00"
    },
    {
      "id": "f3794a5cc983f78771b0ad8a5b41b473",
      "url": "https://support.claude.com/en/articles/8452276-how-do-i-change-the-email-address-associated-with-my-account",
      "title": "Anthropic: You can't change your Claude account email address",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46339741\">Comments</a>",
      "author": "",
      "published_date": "2025-12-20T21:21:14+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-20T22:41:52.282048+00:00",
      "updated_at": "2025-12-20T22:41:52.282050+00:00"
    },
    {
      "id": "f3794a5cc983f78771b0ad8a5b41b473",
      "url": "https://support.claude.com/en/articles/8452276-how-do-i-change-the-email-address-associated-with-my-account",
      "title": "Anthropic: You can't change your Claude account email address",
      "content": "<p>Article URL: <a href=\"https://support.claude.com/en/articles/8452276-how-do-i-change-the-email-address-associated-with-my-account\">https://support.claude.com/en/articles/8452276-how-do-i-change-the-email-address-associated-with-my-account</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46339741\">https://news.ycombinator.com/item?id=46339741</a></p>\n<p>Points: 8</p>\n<p># Comments: 5</p>",
      "author": "behnamoh",
      "published_date": "2025-12-20T21:21:14+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-20T22:41:51.184193+00:00",
      "updated_at": "2025-12-20T22:41:51.184204+00:00"
    },
    {
      "id": "437dd11491bad5ef899b86bf9271e125",
      "url": "http://doi.org/10.1037/cns0000370",
      "title": "Investigating how individual differences in selective attention relate to schizotypy and altered states of consciousness.",
      "content": "Measures of altered states of consciousness (ASC) are useful for understanding anomalies within conscious experiences. Within psychedelic clinical trials, ASC have been associated with long-term positive treatment outcomes for numerous types of mental illnesses. Schizotypal Personality Scale (STA), a set of personality traits that can be related to psychedelic-induced ASC, is associated with potential changes in selective attention, such as being less bound to previously learned associations (i.e., reduced associative blocking). Given the similarity between schizotypy and psychedelic-induced ASC, we hypothesized that there may be attentional differences in individuals with past experiences of ASC. This study examined how differences in selective attention relate to past experiences of ASC and STA. In Study 1, participants completed a visual categorization task designed to elicit associative blocking, the STA, and the ASC scale. Results revealed slow learning feature\u2013category associations in participants high in ASC and STA. Study 2 tested whether this deficit in performance was due to widened attention by implementing additional inference trials that measured incidental learning of feature\u2013feature associations. Results from Study 2 confirmed that participants high in ASC and STA show deficits in learning categories, but this was not accounted for by wider selective attention per se. Our results suggest that flexible or widened attention may not be the locus of cognitive changes associated with past experiences of ASC. Rather, by showing reliable latency in an error-driven learning task, we add to a comprehensive understanding of the relationships between cognition and ASC. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2023-09-14T00:00:00+00:00",
      "source": "Clinical Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 251,
      "reading_time": 1,
      "created_at": "2025-12-20T22:19:42.627327+00:00",
      "updated_at": "2025-12-20T22:19:42.627329+00:00"
    },
    {
      "id": "06afba83115051547809d0a88f975375",
      "url": "https://www.reddit.com/r/Python/comments/1prj82s/django_test_manager_a_vs_code_extension_that/",
      "title": "Django Test Manager \u2013 A VS Code extension that brings a full test runner experience to Django.",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>What My Project Does</p> <p>Django Test Manager is a VS Code extension that lets you discover, organize, run, and debug Django tests natively inside the editor \u2014 without typing python manage.py test in the terminal. It automatically detects tests (including async tests) and displays them in a tree view by app, file, class, and method. You get one-click run/debug, instant search, test profiles, and CodeLens shortcuts directly next to test code. </p> <p>Target Audience</p> <p>This project is intended for developers working on Django applications who want a smoother, more integrated test workflow inside VS Code. It\u2019s suitable for real projects and professional use (not just a toy demo), especially when you\u2019re running large test suites and want faster navigation, debugging, and test re-runs. </p> <p>Comparison</p> <p>Compared to terminal-based testing workflows:</p> <p>You get a visual test tree with smart discovery instead of manually scanning test output. </p> <p>Compared to generic Python test extensions:</p> <p>It\u2019s Django-specific, tailored to Django\u2019s test layout and manage.py integration rather than forcing a generic test runner. </p> <p>Links</p> <p>GitHub (open source): <a href=\"https://github.com/viseshagarwal/django-test-manager\">https://github.com/viseshagarwal/django-test-manager</a></p> <p>VS Code Marketplace: <a href=\"https://marketplace.visualstudio.com/items?itemName=ViseshAgarwal.django-test-manager\">https://marketplace.visualstudio.com/items?itemName=ViseshAgarwal.django-test-manager</a></p> <p>Open VSX: <a href=\"https://open-vsx.org/extension/viseshagarwal/django-test-manager\">https://open-vsx.org/extension/viseshagarwal/django-test-manager</a></p> <p>I\u2019d really appreciate feedback from the Python community \u2014 and of course feature suggestions or contributions are welcome \ud83d\ude42</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/visesh-agarwal\"> /u/visesh-agarwal </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1prj82s/django_test_manager_a_vs_code_extension_that/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1prj82s/django_test_manager_a_vs_code_extension_that/\">[comments]</a></span>",
      "author": "/u/visesh-agarwal",
      "published_date": "2025-12-20T17:06:09+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 225,
      "reading_time": 1,
      "created_at": "2025-12-20T22:19:34.268489+00:00",
      "updated_at": "2025-12-20T22:19:34.268491+00:00"
    },
    {
      "id": "83d6a9fb1051980605b2acfdd66c7efb",
      "url": "https://afw.kuber.studio",
      "title": "Show HN: Fucking Websites",
      "content": "<p>Article URL: <a href=\"https://afw.kuber.studio\">https://afw.kuber.studio</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46339495\">https://news.ycombinator.com/item?id=46339495</a></p>\n<p>Points: 3</p>\n<p># Comments: 0</p>",
      "author": "kuberwastaken",
      "published_date": "2025-12-20T20:44:26+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-20T22:19:31.707823+00:00",
      "updated_at": "2025-12-20T22:19:31.707825+00:00"
    },
    {
      "id": "084f5a770aec7a0c6e26dccdda717fda",
      "url": "https://github.com/taylorsatula/mira-OSS",
      "title": "MIRA \u2013 An open-source persistent AI entity with memory",
      "content": "<p>Article URL: <a href=\"https://github.com/taylorsatula/mira-OSS\">https://github.com/taylorsatula/mira-OSS</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46339537\">https://news.ycombinator.com/item?id=46339537</a></p>\n<p>Points: 9</p>\n<p># Comments: 1</p>",
      "author": "taylorsatula",
      "published_date": "2025-12-20T20:50:43+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-20T22:19:31.707795+00:00",
      "updated_at": "2025-12-20T22:19:31.707801+00:00"
    },
    {
      "id": "fa250840ddf6808c93613cad856c7c25",
      "url": "http://doi.org/10.1037/cns0000353",
      "title": "Unmuting lucid dreams: Speech decoding and vocalization in real time.",
      "content": "Since the 1970s, scientists have been searching for ways to communicate with people in lucid dreams (LDs), during which it is possible to maintain consciousness. Previously, dreamers could hear sounds from reality and respond with some simple signals, but they could not speak back. In this study, facial surface electromyography (EMG) was tested as a proof of concept for unmuting people in LDs. Remmyo, an EMG distinctive constructed language, was used. The software was developed to translate facial EMG impulses into Remmyo sounds and letters, translate words into English, and digitally vocalize the final text in English. Four LD practitioners were trained to pronounce a short phrase or a word in Remmyo and were then asked to achieve the same task in LDs under polysomnographic observation. LDs were verified by preagreed eye movements in rapid eye movement (REM) sleep. Four volunteers tried to speak in Remmyo in 15 LDs. Due to software failures, mispronunciations, and missing sounds, the decoding efficiency in real time or in recordings ranged from 13% to 81%. The first phrase and word heard from sleeping people were \u201cno war\u201d and \u201cfreedom.\u201d The later was automatically translated and vocalized in English in real time for 11 times. Despite controversial results, the study shows that, with further development, people could possibly talk in LDs and could be heard in reality with the help of EMG sensors. To achieve this goal, a range of possible obstacles is discussed. This technology could provide opportunities for LD studies and their practical applications. (PsycInfo Database Record (c) 2025 APA, all rights reserved)",
      "author": "",
      "published_date": "2023-03-13T00:00:00+00:00",
      "source": "Clinical Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 260,
      "reading_time": 1,
      "created_at": "2025-12-20T20:41:31.083809+00:00",
      "updated_at": "2025-12-20T20:41:31.083811+00:00"
    }
  ],
  "recently_processed": [
    {
      "id": "2f10238af64327be1a1b33ce254d1ff0",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.17.695041v1?rss=1",
      "title": "OpenStride: an inexpensive, open-source force plate actometry system for quantification of rodent motor activity and behaviour",
      "content": "Introduction: Force plate actometry (FPA) enables quantitative assessment of rodent motor and behavioural activity. Through tracking centre of mass at high temporal and spatial resolution, FPA can directly quantifying motor performance and various behaviours in the context of operator-independent, naturalistic movement. Previously designed systems have been expensive and non-customisable, and they are no longer commercially available. Methods: We designed OpenStride, an open-source FPA system consisting of both hardware and software. Our system was designed to be able to be constructed with standard tools worldwide at a cost of ~$550 USD, with modifiable hardware files, modular software, and support for both Mac and Windows operating systems. Required tools include 3D printing and acrylic laser cutting. Results: OpenStride reliably tracks position within a 30 x 30 cm2 environment. Based on these positional data, OpenStride currently quantifies tremor, ataxia, distance, velocity, low-mobility bouts, and centre-vs-margin time, with potential to expand to additional analyses. Conclusions: OpenStride is intended to provide a valuable tool for high-throughput, inexpensive study of motor and behavioural function and dysfunction. Software and hardware files will be freely disseminated online via GitHub at the time of final publication to enable others to construct and utilise the OpenStride system.",
      "author": "Yang, Y., Cooper, B., Houghton, M., Dahiya, K., Haslam, S. E., Blackwell, H., Sekaran, K., Hu, L., Kavehei, O., Anderson, C. J.",
      "published_date": "2025-12-20T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 197,
      "reading_time": 1,
      "created_at": "2025-12-21T03:40:00.471937+00:00",
      "updated_at": "2025-12-21T04:33:47.599934+00:00",
      "metadata": {
        "processed_at": "2025-12-21T04:33:47.599944+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "00ea168b06c031212f5b8ef529861b2a",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.17.695049v1?rss=1",
      "title": "Theta-mediated conceptual reinstatement in vmPFC precedes perceptual reinstatement in ventral visual cortex during memory recall",
      "content": "When recalling past episodes, different features of an experience, such as conceptual meaning and perceptual detail, are reconstructed and reinstated across distributed cortical regions. However, current models of human memory remain unclear how these feature-specific reinstatements unfold over time, and whether they interact hierarchically during memory retrieval. Using magnetoencephalography (MEG) and time-resolved encoding-retrieval cross-phase classification analysis, we compared the time course of conceptual and perceptual reinstatement during cued visual recall. Conceptual information decoding in the ventromedial prefrontal cortex (vmPFC) preceded perceptual information decoding in the ventral visual cortex (VVC), and the two were expressed in distinct frequency bands: theta (4-8 Hz) for conceptual and gamma (30-40 Hz) for perceptual information. Cross-correlation and spectral Granger causality analyses revealed that during reinstatement conceptual information in vmPFC predicted and directed perceptual information in VVC, with theta-band information flow predominantly from vmPFC to VVC. In addition, bottom-up connectivity from VVC to vmPFC was expressed in the alpha band. These findings suggest that memory retrieval proceeds from abstract conceptual reconstruction to the reinstatement of perceptual details, mediated by theta oscillatory communication between prefrontal and sensory areas. We propose a hierarchical interactive model in which vmPFC initiates conceptual activation through theta-band top-down signals, while VVC provides alpha-band feedback for evaluating reconstructed perceptual details.",
      "author": "Zhang, L., Yuan, M., Gilboa, A., Alain, C.",
      "published_date": "2025-12-20T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 207,
      "reading_time": 1,
      "created_at": "2025-12-21T03:40:00.471894+00:00",
      "updated_at": "2025-12-21T04:33:47.599948+00:00",
      "metadata": {
        "processed_at": "2025-12-21T04:33:47.599950+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "ef1d360d604223946bde97ad8fab7bd1",
      "url": "https://www.frontiersin.org/articles/10.3389/fnbot.2025.1574044",
      "title": "Path planning of industrial robots based on the adaptive field cooperative sampling algorithm",
      "content": "For the low efficiency and poor generalization ability of path planning algorithm of industrial robots, this work proposes an adaptive field co-sampling algorithm (AFCS). Firstly, the environment complexity function is proposed to make full use of environment information and improve its generalization ability of the traditional rapidly random search tree algorithm (RRT) algorithm. Then an optimal sampling strategy is proposed to make the improvement of the efficiency and optimal direction of RRT algorithm. Finally, this article designs a collaborative extension strategy, which introduces the improved artificial potential field algorithm (APF) into the traditional RRT algorithm to determine the new nodes, so as to improve the orientation and expansion efficiency of the algorithm. The proposed AFCS algorithm completes simulation experiments in two environments with different complexity. Compared with the traditional RRT, RRT* and tRRT algorithm, the results show that the AFCS algorithm has achieved great improvement in environmental adaptability, stability and efficiency. At last, ROKAE industrial robot is taken as the object to build a simulation environment for the path planning, which further verifies the practicability of the algorithm.",
      "author": "Lv Wei",
      "published_date": "2025-11-13T00:00:00+00:00",
      "source": "Frontiers Neurorobotics",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 178,
      "reading_time": 1,
      "created_at": "2025-12-21T03:39:47.481043+00:00",
      "updated_at": "2025-12-21T04:33:47.599953+00:00",
      "metadata": {
        "processed_at": "2025-12-21T04:33:47.599954+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "607472031a54afb77cef53ac851abd33",
      "url": "https://www.reddit.com/r/Python/comments/1prdst8/vrdndi_a_local_contextaware_productivityfocused/",
      "title": "Vrdndi: A local context-aware productivity-focused recommendation system",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone,</p> <p><strong>What My Project Does:</strong> Vrdndi is a local-first recommendation system that curates media feed (currently YouTube) based on your current computer behavior. It uses <a href=\"https://activitywatch.net/\">ActivityWatch</a> (A time tracker) data to detect what you are working on (e.g., coding, gaming) and adjusts your feed to match your goal\u2014promoting productivity when you are working and entertainment when you are relaxing. (If you train it in this way)</p> <p><strong>Goal:</strong> To recommend content based on what you are actually doing (using your previous app history) and aiming for productivity, rather than what seems most interesting.</p> <p><strong>Target Audience:</strong> developers, self-hosters, and productivity enthusiasts</p> <p><strong>Comparison:</strong> As far as I know, I haven't seen someone else who has built an open-source recommendation that uses your app history to curate a feed, but probably just because I haven't found one. Unlike YouTube, which optimizes for <strong>watch time</strong>, Vrdndi optimizes for your <strong>intent</strong>\u2014aligning your feed with your current context (usually for productivity, if you train it for that)</p> <p><strong>The Stack:</strong></p> <ul> <li><strong>Backend</strong>: Python 3.11-3.12</li> <li><strong>ML Framework</strong>: PyTorch (custom neural network that can train on local app history).</li> <li><strong>Data Source</strong>: ActivityWatch (fetches your app history to understand context) and media data (currently Youtube)</li> <li><strong>Frontend</strong>: NiceGUI (for the web interface) &amp; Streamlit (for data labeling).</li> <li><strong>Database</strong>: SQLite (everything stays <strong>local</strong>).</li> </ul> <p><strong>How does it work:</strong> The system processes saved media data and fetches your current app history from ActivityWatch. The model rates the media based on your current context and saves the feed to the database, which the frontend displays. Since it uses a standard database, you could easily connect your own frontend to the model if you prefer.</p> <p>It\u2019s experimental currently. If anyone finds this project interesting, I would appreciate any thoughts you might have.</p> <p>Project: <a href=\"https://github.com/leuas/Vrdndi\">Vrdndi: A full-stack context-aware productivity-focused recommendation system </a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/AcrobaticWeb6671\"> /u/AcrobaticWeb6671 </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1prdst8/vrdndi_a_local_contextaware_productivityfocused/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1prdst8/vrdndi_a_local_contextaware_productivityfocused/\">[comments]</a></span>",
      "author": "/u/AcrobaticWeb6671",
      "published_date": "2025-12-20T13:00:28+00:00",
      "source": "Reddit Python",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 319,
      "reading_time": 1,
      "created_at": "2025-12-21T03:39:20.259239+00:00",
      "updated_at": "2025-12-21T04:33:47.599957+00:00",
      "metadata": {
        "processed_at": "2025-12-21T04:33:47.599958+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "9f3bb3c8c2a218e0d18fdfa6d7968503",
      "url": "https://haveibeenflocked.com/news/cyble-downtime",
      "title": "Flock and Cyble Inc. Weaponize \"Cybercrime\" Takedowns to Silence Critics",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46341305\">Comments</a>",
      "author": "",
      "published_date": "2025-12-21T01:12:31+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-21T03:39:18.949888+00:00",
      "updated_at": "2025-12-21T04:33:47.599960+00:00",
      "metadata": {
        "processed_at": "2025-12-21T04:33:47.599962+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "9f3bb3c8c2a218e0d18fdfa6d7968503",
      "url": "https://haveibeenflocked.com/news/cyble-downtime",
      "title": "Flock and Cyble Inc. Weaponize \"Cybercrime\" Takedowns to Silence Critics",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46341305\">Comments</a>",
      "author": "",
      "published_date": "2025-12-21T01:12:31+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-21T03:39:18.949888+00:00",
      "updated_at": "2025-12-21T04:33:47.599960+00:00",
      "metadata": {
        "processed_at": "2025-12-21T04:33:47.599962+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "1ef7771c4c1c4de0c75402ec8e03e168",
      "url": "https://www.reddit.com/r/Python/comments/1pri95o/internship_bachelors_degree/",
      "title": "Internship (Bachelors Degree)",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone, </p> <p>I have minor experience in python and looking for an internship. I have been working in a streamline application that scrapes my favorite games api for a specific item and provides an extract of buy and sell orders and a visual graph of the items price over time. Anyone who can provide advice for getting an internship, would be greatly appreciated. </p> <p>Project</p> <p>Like: <a href=\"https://github.com/Darienspider/webserver\">https://github.com/Darienspider/webserver</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Greedy_Point7755\"> /u/Greedy_Point7755 </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1pri95o/internship_bachelors_degree/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1pri95o/internship_bachelors_degree/\">[comments]</a></span>",
      "author": "/u/Greedy_Point7755",
      "published_date": "2025-12-20T16:25:20+00:00",
      "source": "Reddit Python",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 90,
      "reading_time": 1,
      "created_at": "2025-12-21T01:51:41.622648+00:00",
      "updated_at": "2025-12-21T03:25:46.689585+00:00",
      "metadata": {
        "processed_at": "2025-12-21T03:25:46.689594+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "32f485e2e1cdefefb3586abf8dd4a2f3",
      "url": "https://phys.org/news/2025-12-italian-villages-evolved-smaller-aggressive.html",
      "title": "Italian bears living near villages have evolved to be smaller and less agressive",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46274272\">Comments</a>",
      "author": "",
      "published_date": "2025-12-15T13:30:45+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-21T01:51:40.320430+00:00",
      "updated_at": "2025-12-21T03:25:46.689598+00:00",
      "metadata": {
        "processed_at": "2025-12-21T03:25:46.689601+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "344c4db5ac04eafacac6c0eca7452678",
      "url": "https://www.nber.org/papers/w34558",
      "title": "Anatomy of US inequality",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46340794\">Comments</a>",
      "author": "",
      "published_date": "2025-12-20T23:43:04+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-21T01:51:40.320336+00:00",
      "updated_at": "2025-12-21T03:25:46.689603+00:00",
      "metadata": {
        "processed_at": "2025-12-21T03:25:46.689605+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "344c4db5ac04eafacac6c0eca7452678",
      "url": "https://www.nber.org/papers/w34558",
      "title": "Anatomy of US inequality",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46340794\">Comments</a>",
      "author": "",
      "published_date": "2025-12-20T23:43:04+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-21T01:51:40.320336+00:00",
      "updated_at": "2025-12-21T03:25:46.689603+00:00",
      "metadata": {
        "processed_at": "2025-12-21T03:25:46.689605+00:00",
        "processing_method": "github_actions"
      }
    }
  ]
}