{
  "last_updated": "2025-11-24T06:24:36.071841+00:00",
  "pending_count": 681,
  "processed_count": 319,
  "pending_articles": [
    {
      "id": "9d42cd3aff70ff7344537cfc257583e7",
      "url": "https://arxiv.org/abs/2511.16823",
      "title": "Monte Carlo Expected Threat (MOCET) Scoring",
      "content": "arXiv:2511.16823v1 Announce Type: cross \nAbstract: Evaluating and measuring AI Safety Level (ASL) threats are crucial for guiding stakeholders to implement safeguards that keep risks within acceptable limits. ASL-3+ models present a unique risk in their ability to uplift novice non-state actors, especially in the realm of biosecurity. Existing evaluation metrics, such as LAB-Bench, BioLP-bench, and WMDP, can reliably assess model uplift and domain knowledge. However, metrics that better contextualize \"real-world risks\" are needed to inform the safety case for LLMs, along with scalable, open-ended metrics to keep pace with their rapid advancements. To address both gaps, we introduce MOCET, an interpretable and doubly-scalable metric (automatable and open-ended) that can quantify real-world risks.",
      "author": "Joseph Kim, Saahith Potluri",
      "published_date": "2025-11-24T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 112,
      "reading_time": 1,
      "created_at": "2025-11-24T05:22:56.313124+00:00",
      "updated_at": "2025-11-24T05:22:56.313125+00:00"
    },
    {
      "id": "5a412a81f429ca3e4bfc661f5fbb8d8a",
      "url": "https://arxiv.org/abs/2511.16814",
      "title": "Stable diffusion models reveal a persisting human and AI gap in visual creativity",
      "content": "arXiv:2511.16814v1 Announce Type: cross \nAbstract: While recent research suggests Large Language Models match human creative performance in divergent thinking tasks, visual creativity remains underexplored. This study compared image generation in human participants (Visual Artists and Non Artists) and using an image generation AI model (two prompting conditions with varying human input: high for Human Inspired, low for Self Guided). Human raters (N=255) and GPT4o evaluated the creativity of the resulting images. We found a clear creativity gradient, with Visual Artists being the most creative, followed by Non Artists, then Human Inspired generative AI, and finally Self Guided generative AI. Increased human guidance strongly improved GenAI's creative output, bringing its productions close to those of Non Artists. Notably, human and AI raters also showed vastly different creativity judgment patterns. These results suggest that, in contrast to language centered tasks, GenAI models may face unique challenges in visual domains, where creativity depends on perceptual nuance and contextual sensitivity, distinctly human capacities that may not be readily transferable from language models.",
      "author": "Silvia Rondini, Claudia Alvarez-Martin, Paula Angermair-Barkai, Olivier Penacchio, M. Paz, Matthew Pelowski, Dan Dediu, Antoni Rodriguez-Fornells, Xim Cerda-Company",
      "published_date": "2025-11-24T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 168,
      "reading_time": 1,
      "created_at": "2025-11-24T05:22:56.313098+00:00",
      "updated_at": "2025-11-24T05:22:56.313099+00:00"
    },
    {
      "id": "bcb6a6f227913d70c4e5472210cd84ba",
      "url": "https://arxiv.org/abs/2511.17443",
      "title": "GRAPHIC--Guidelines for Reviewing Algorithmic Practices in Human-centred Design and Interaction for Creativity",
      "content": "arXiv:2511.17443v1 Announce Type: new \nAbstract: Artificial Intelligence (AI) has been increasingly applied to creative domains, leading to the development of systems that collaborate with humans in design processes. In Graphic Design, integrating computational systems into co-creative workflows presents specific challenges, as it requires balancing scientific rigour with the subjective and visual nature of design practice. Following the PRISMA methodology, we identified 872 articles, resulting in a final corpus of 71 publications describing 68 unique systems. Based on this review, we introduce GRAPHIC (Guidelines for Reviewing Algorithmic Practices in Human-centred Design and Interaction for Creativity), a framework for analysing AI-based systems applied to Graphic Design. Its goal is to understand how current systems support human-AI collaboration in the Graphic Design discipline. The framework comprises main dimensions, which our analysis revealed to be essential across diverse system types: (1) Collaborative Panorama, (2) Processes and Modalities, and (3) Graphic Design Principles. Its application revealed research gaps, including the need to balance initiative and control between agents, improve communication through explainable interaction models, and promote systems that support transformational creativity grounded in core design principles.",
      "author": "Joana Rovira Martins, Pedro Martins, Ana Boavida",
      "published_date": "2025-11-24T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 181,
      "reading_time": 1,
      "created_at": "2025-11-24T05:22:56.313068+00:00",
      "updated_at": "2025-11-24T05:22:56.313070+00:00"
    },
    {
      "id": "64bc9b7f180c0fba53776c09e80ce203",
      "url": "https://arxiv.org/abs/2511.17246",
      "title": "Mixed Reality Scenic Live Streaming for Cultural Heritage: Visual Interactions in a Historic Landscape",
      "content": "arXiv:2511.17246v1 Announce Type: new \nAbstract: Scenic Live Streams (SLS), capturing real-world scenic sites from fixed cameras without streamers, have gained increasing popularity recently. They afford unique real-time lenses into remote sites for viewers' synchronous and collective engagement. Foregrounding its lack of dynamism and interactivity, we aim to maximize the potential of SLS by making it interactive. Namely MRSLS, we overlaid plain SLS with interactive Mixed Reality content that matches the site's geographical structures and local cultural backgrounds. We further highlight the substantial benefit of MRSLS to cultural heritage site interactions, and we demonstrate this design proposal with an MRSLS prototype at a UNESCO-listed heritage site in China. The design process includes an interview (N=6) to pinpoint local scenery and culture, as well as two iterative design studies (N=15, 14). A mixed-methods, between-subjects study (N=43, 37) shows that MRSLS affords immersive scenery appreciation, effective cultural imprints, and vivid shared experience. With its balance between cultural, participatory, and authentic attributes, we appeal for more HCI attention to (MR)SLS as an under-explored design space.",
      "author": "Zeyu Huang, Zuyu Xu, Yuanhao Zhang, Chengzhong Liu, Yanwei Zhao, Chuhan Shi, Jason Chen Zhao, Xiaojuan Ma",
      "published_date": "2025-11-24T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 171,
      "reading_time": 1,
      "created_at": "2025-11-24T05:22:56.313037+00:00",
      "updated_at": "2025-11-24T05:22:56.313038+00:00"
    },
    {
      "id": "5eccab12089249af57835805a2658512",
      "url": "https://arxiv.org/abs/2511.16990",
      "title": "Senti-iFusion: An Integrity-centered Hierarchical Fusion Framework for Multimodal Sentiment Analysis under Uncertain Modality Missingness",
      "content": "arXiv:2511.16990v1 Announce Type: new \nAbstract: Multimodal Sentiment Analysis (MSA) is critical for human-computer interaction but faces challenges when the modalities are incomplete or missing. Existing methods often assume pre-defined missing modalities or fixed missing rates, limiting their real-world applicability. To address this challenge, we propose Senti-iFusion, an integrity-centered hierarchical fusion framework capable of handling both inter- and intra-modality missingness simultaneously. It comprises three hierarchical components: Integrity Estimation, Integrity-weighted Completion, and Integrity-guided Fusion. First, the Integrity Estimation module predicts the completeness of each modality and mitigates the noise caused by incomplete data. Second, the Integrity-weighted Cross-modal Completion module employs a novel weighting mechanism to disentangle consistent semantic structures from modality-specific representations, enabling the precise recovery of sentiment-related features across language, acoustic, and visual modalities. To ensure consistency in reconstruction, a dual-depth validation with semantic- and feature-level losses ensures consistent reconstruction at both fine-grained (low-level) and semantic (high-level) scales. Finally, the Integrity-guided Adaptive Fusion mechanism dynamically selects the dominant modality for attention-based fusion, ensuring that the most reliable modality, based on completeness and quality, contributes more significantly to the final prediction. Senti-iFusion employs a progressive training approach to ensure stable convergence. Experimental results on popular MSA datasets demonstrate that Senti-iFusion outperforms existing methods, particularly in fine-grained sentiment analysis tasks. The code and our proposed Senti-iFusion model will be publicly available.",
      "author": "Liling Li, Guoyang Xu, Xiongri Shen, Zhifei Xu, Yanbo Zhang, Zhiguo Zhang, Zhenxi Song",
      "published_date": "2025-11-24T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 218,
      "reading_time": 1,
      "created_at": "2025-11-24T05:22:56.313004+00:00",
      "updated_at": "2025-11-24T05:22:56.313005+00:00"
    },
    {
      "id": "fc9027b9c746c346b6840d671d41365a",
      "url": "https://arxiv.org/abs/2511.16989",
      "title": "The Wireless Charger as a Gesture Sensor: A Novel Approach to Ubiquitous Interaction",
      "content": "arXiv:2511.16989v1 Announce Type: new \nAbstract: Advancements in information technology have increased demand for natural human-computer interaction in areas such as gaming, smart homes, and vehicles. However, conventional approaches like physical buttons or cameras are often limited by contact requirements, privacy concerns, and high costs.Motivated by the observation that these EM signals are not only strong and measurable but also rich in gesture-related information, we propose EMGesture, a novel contactless interaction technique that leverages the electromagnetic (EM) signals from Qi wireless chargers for gesture recognition. EMGesture analyzes the distinctive EM features and employs a robust classification model. The end-to-end framework enables it capable of accurately interpreting user intent. Experiments involving 30 participants, 10 mobile devices, and 5 chargers showed that EMGesture achieves over 97% recognition accuracy. Corresponding user studies also confirmed higher usability and convenience, which demonstrating that EMGesture is a practical, privacy-conscious, and cost-effective solution for pervasive interaction.",
      "author": "Weiyi Wang, Lanqing Yang, Linqian Gan, Guangtao Xue",
      "published_date": "2025-11-24T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 148,
      "reading_time": 1,
      "created_at": "2025-11-24T05:22:56.312968+00:00",
      "updated_at": "2025-11-24T05:22:56.312970+00:00"
    },
    {
      "id": "12b5ff79d5e0d4fd2229f71a66d7b47e",
      "url": "https://arxiv.org/abs/2511.16896",
      "title": "IsharaKotha: A Comprehensive Avatar-based Bangla Sign Language Corpus",
      "content": "arXiv:2511.16896v1 Announce Type: new \nAbstract: Sign language is a vital communication medium for the hearing-impaired community, enabling effective interaction and self-expression. To help bridge the communication gap between hearing and hearing-impaired individuals, a text-to-sign translation system is essential. Such systems can also support learners interested in acquiring sign language skills. This work presents IsharaKotha, the first HamNoSys-based Bangla Sign Language corpus, containing 3823 words. A deep learning based lemmatizer was integrated to extract root words, enabling sign generation for complete sentences. An evaluation interface was developed to assess the quality of sign animations for letters, digits, and sentences. Two professional interpreters and one real sign language user rated the animations using categorical numeric scores. The system achieved an average rating of 3.14 out of 4.00, indicating high quality performance between Good and Excellent. These results demonstrate the potential of IsharaKotha to support future advancements in dynamic sign language translation systems. The evaluation system is available at http://bdsl-isharakotha.ap-1.evennode.com",
      "author": "MD. Ashikul Islam, Prato Dewan, Md Fuadul Islam, Md. Ataullha, M. Shahidur Rahman",
      "published_date": "2025-11-24T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 157,
      "reading_time": 1,
      "created_at": "2025-11-24T05:22:56.312932+00:00",
      "updated_at": "2025-11-24T05:22:56.312935+00:00"
    },
    {
      "id": "3f90b860ccae68c9c2be37fefd303bb4",
      "url": "https://arxiv.org/abs/2511.16805",
      "title": "Scene Awareness While Using Multiple Navigation Aids in AR Search",
      "content": "arXiv:2511.16805v1 Announce Type: new \nAbstract: Augmented reality (AR) allows virtual information to be presented in the real world, providing support for numerous tasks including search and navigation. Allowing users access to multiple navigation aids may help leverage the benefits of different navigational guidance methods, but may also have negative perceptual and cognitive impacts. In this study, users performed searches for virtual gems within a large-scale augmented environment while choosing to deploy two different navigation aids either independently or simultaneously: world-locked arrows and an on-screen radar. After completing the search, participants were asked to recall objects that may or may not have been present in the scene. The use of navigation aids impacted object recall, with impaired recall of objects in the environment when an aid was switched on. The results point at possible impact factors of object awareness in mobile AR and underscore the potential for adaptable interfaces to support users navigating the physical world.",
      "author": "Radha Kumaran, You-Jin Kim, Emily Machniak, Shane Dirksen, Junhyung Yoon, Tom Bullock, Barry Giesbrecht, Tobias H\\\"ollerer",
      "published_date": "2025-11-24T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 155,
      "reading_time": 1,
      "created_at": "2025-11-24T05:22:56.312888+00:00",
      "updated_at": "2025-11-24T05:22:56.312890+00:00"
    },
    {
      "id": "9b6ac85d2afd26cb2702de2f1a16a06c",
      "url": "https://arxiv.org/abs/2511.16783",
      "title": "Generative Augmented Reality: Paradigms, Technologies, and Future Applications",
      "content": "arXiv:2511.16783v1 Announce Type: new \nAbstract: This paper introduces Generative Augmented Reality (GAR) as a next-generation paradigm that reframes augmentation as a process of world re-synthesis rather than world composition by a conventional AR engine. GAR replaces the conventional AR engine's multi-stage modules with a unified generative backbone, where environmental sensing, virtual content, and interaction signals are jointly encoded as conditioning inputs for continuous video generation. We formalize the computational correspondence between AR and GAR, survey the technical foundations that make real-time generative augmentation feasible, and outline prospective applications that leverage its unified inference model. We envision GAR as a future AR paradigm that delivers high-fidelity experiences in terms of realism, interactivity, and immersion, while eliciting new research challenges on technologies, content ecosystems, and the ethical and societal implications.",
      "author": "Chen Liang, Jiawen Zheng, Yufeng Zeng, Yi Tan, Hengye Lyu, Yuhui Zheng, Zisu Li, Yueting Weng, Jiaxin Shi, Hanwang Zhang",
      "published_date": "2025-11-24T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 128,
      "reading_time": 1,
      "created_at": "2025-11-24T05:22:56.312857+00:00",
      "updated_at": "2025-11-24T05:22:56.312859+00:00"
    },
    {
      "id": "ded58082f6a1ebca43d25332c74351c9",
      "url": "https://arxiv.org/abs/2511.16769",
      "title": "Trust in AI emerges from distrust in humans: A machine learning study on decision-making guidance",
      "content": "arXiv:2511.16769v1 Announce Type: new \nAbstract: This study explores the dynamics of trust in artificial intelligence (AI) agents, particularly large language models (LLMs), by introducing the concept of \"deferred trust\", a cognitive mechanism where distrust in human agents redirects reliance toward AI perceived as more neutral or competent. Drawing on frameworks from social psychology and technology acceptance models, the research addresses gaps in user-centric factors influencing AI trust. Fifty-five undergraduate students participated in an experiment involving 30 decision-making scenarios (factual, emotional, moral), selecting from AI agents (e.g., ChatGPT), voice assistants, peers, adults, or priests as guides. Data were analyzed using K-Modes and K-Means clustering for patterns, and XGBoost models with SHAP interpretations to predict AI selection based on sociodemographic and prior trust variables.\n  Results showed adults (35.05\\%) and AI (28.29\\%) as the most selected agents overall. Clustering revealed context-specific preferences: AI dominated factual scenarios, while humans prevailed in social/moral ones. Lower prior trust in human agents (priests, peers, adults) consistently predicted higher AI selection, supporting deferred trust as a compensatory transfer. Participant profiles with higher AI trust were distinguished by human distrust, lower technology use, and higher socioeconomic status. Models demonstrated consistent performance (e.g., average precision up to 0.863).\n  Findings challenge traditional models like TAM/UTAUT, emphasizing relational and epistemic dimensions in AI trust. They highlight risks of over-reliance due to fluency effects and underscore the need for transparency to calibrate vigilance. Limitations include sample homogeneity and static scenarios; future work should incorporate diverse populations and multimodal data to refine deferred trust across contexts.",
      "author": "Johan Sebasti\\'an Galindez-Acosta, Juan Jos\\'e Giraldo-Huertas",
      "published_date": "2025-11-24T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 252,
      "reading_time": 1,
      "created_at": "2025-11-24T05:22:56.312823+00:00",
      "updated_at": "2025-11-24T05:22:56.312827+00:00"
    }
  ],
  "recently_processed": [
    {
      "id": "d4a9f9fad0783fdeec1c049b206b2515",
      "url": "https://www.frontiersin.org/articles/10.3389/fnhum.2025.1683924",
      "title": "Emerging technologies and neuroscience-based approaches in dyslexia: a narrative review toward integrative and personalized solutions",
      "content": "BackgroundDevelopmental dyslexia is a common neurodevelopmental disorder that impairs reading ability despite adequate intelligence and education, affecting up to 17% of children worldwide. Advances in neuroscience have revealed complex mechanisms involving phonological, visual, and temporal processing, with cross-linguistic variability. At the same time, technological innovation is driving a shift toward AI-powered diagnostics, immersive learning tools, and neurostimulation-based interventions.MethodsThis narrative review synthesizes evidence from recent research published between 2015 and 2025, focusing on four thematic areas: (1) neurobiological underpinnings of dyslexia, (2) diagnostic innovations using AI and eye- or handwriting-based deep learning, (3) neurostimulation and immersive VR/AR interventions, and (4) policy, equity, and ethical considerations. Studies were identified through major academic databases and thematically analyzed to highlight trends, strengths, and limitations.ResultsAI-based diagnostic tools using eye-tracking and handwriting features have achieved reported accuracies exceeding 80% in multiple pilot studies. VR/game-based programs and neurostimulation interventions (TMS, tDCS) have shown promising short-term effects on reading fluency and phonological processing, though evidence for long-term literacy transfer remains limited. Across studies, methodological heterogeneity and small sample sizes constrain generalizability. Significant disparities in access persist across socioeconomic, linguistic, and geographic contexts.ConclusionsWhile these technologies offer promising avenues for more personalized and scalable dyslexia care, their integration must be accompanied by stronger evidence, ethical safeguards, and equity-focused policies. Technology should augment, not replace, human interaction in inclusive education. Future research should prioritize larger trials, cross-linguistic validation, and sustainable implementation strategies.",
      "author": "Feng Zhu",
      "published_date": "2025-11-19T00:00:00+00:00",
      "source": "Frontiers Human Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 231,
      "reading_time": 1,
      "created_at": "2025-11-24T05:45:04.994054+00:00",
      "updated_at": "2025-11-24T06:24:35.965147+00:00",
      "metadata": {
        "processed_at": "2025-11-24T06:24:35.965158+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "5de677cbd74105ea039fefec456373bd",
      "url": "https://www.frontiersin.org/articles/10.3389/fnins.2025.1737026",
      "title": "Editorial: Methods and applications of diffusion MRI tractometry",
      "content": "",
      "author": "Julio E. Villal\u00f3n-Reina",
      "published_date": "2025-11-19T00:00:00+00:00",
      "source": "Frontiers Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-11-24T05:45:02.094375+00:00",
      "updated_at": "2025-11-24T06:24:35.965162+00:00",
      "metadata": {
        "processed_at": "2025-11-24T06:24:35.965164+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "92c454fe6a24050f54e3301877c9f699",
      "url": "https://www.frontiersin.org/articles/10.3389/fnins.2025.1632251",
      "title": "Loss of Nocturnin increases neuronal viability in oxidative stress conditions",
      "content": "Oxidative stress, characterized by an imbalance between reactive oxygen species (ROS) and antioxidants, plays a critical role in neurodegenerative disorders like Parkinson\u2019s Disease (PD) and is strongly associated with neuronal cell death. Nocturnin was identified as a NADP(H) phosphatase and key regulator of oxidative stress. NADPH serves as a crucial co-factor for enzymes which regenerate antioxidants, and downregulation of its levels increases sensitivity to oxidative stress mediated neurodegeneration. In this study, we examined how the loss of Nocturnin impacts redox homeostasis and neuronal survival in Cath.a-differentiated (CAD) cells and dopaminergic neurodegeneration in a mutant alpha-synuclein overexpression PD mouse model (DASYN53). Here we demonstrate that loss of Nocturnin increases CAD cell viability by increasing total glutathione levels, boosting metabolites involved in antioxidant defense, and reducing oxidative damage. Additionally, Nocturnin deletion in DASYN53 mice promotes midbrain dopaminergic neuron survival. These findings suggest that the loss of Nocturnin protects neurons from oxidative stress by increasing antioxidant defense, which rescues neurodegeneration of dopaminergic neurons.",
      "author": "Carla B. Green",
      "published_date": "2025-11-19T00:00:00+00:00",
      "source": "Frontiers Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 160,
      "reading_time": 1,
      "created_at": "2025-11-24T05:45:02.094357+00:00",
      "updated_at": "2025-11-24T06:24:35.965167+00:00",
      "metadata": {
        "processed_at": "2025-11-24T06:24:35.965168+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "978cb9f0e0c20f67209dc289a1f4ea34",
      "url": "https://www.bbc.com/news/articles/c8676qpxgnqo",
      "title": "Japan's gamble to turn island of Hokkaido into global chip hub",
      "content": "<p>Article URL: <a href=\"https://www.bbc.com/news/articles/c8676qpxgnqo\">https://www.bbc.com/news/articles/c8676qpxgnqo</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46029929\">https://news.ycombinator.com/item?id=46029929</a></p>\n<p>Points: 10</p>\n<p># Comments: 0</p>",
      "author": "1659447091",
      "published_date": "2025-11-24T03:07:07+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-11-24T05:44:35.643605+00:00",
      "updated_at": "2025-11-24T06:24:35.965171+00:00",
      "metadata": {
        "processed_at": "2025-11-24T06:24:35.965172+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "fb690277a7116b5b52ed5486f1745626",
      "url": "https://www.ft.com/content/abfe9741-f438-4ed6-a673-075ec177dc62",
      "title": "Insurers retreat from AI cover as risk of multibillion-dollar claims mounts",
      "content": "<p>Article URL: <a href=\"https://www.ft.com/content/abfe9741-f438-4ed6-a673-075ec177dc62\">https://www.ft.com/content/abfe9741-f438-4ed6-a673-075ec177dc62</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46030360\">https://news.ycombinator.com/item?id=46030360</a></p>\n<p>Points: 14</p>\n<p># Comments: 1</p>",
      "author": "gwintrob",
      "published_date": "2025-11-24T04:22:12+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-11-24T05:44:35.643553+00:00",
      "updated_at": "2025-11-24T06:24:35.965174+00:00",
      "metadata": {
        "processed_at": "2025-11-24T06:24:35.965176+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "ad1925564c97f30cab5b55e76f20793b",
      "url": "https://www.embs.org/blog-post/regional-shifts-and-patterns/",
      "title": "Bridging Biotech: Regional shifts and patterns",
      "content": "<p>The post <a href=\"https://www.embs.org/blog-post/regional-shifts-and-patterns/\">Bridging Biotech: Regional shifts and patterns</a> appeared first on <a href=\"https://www.embs.org\">IEEE EMBS</a>.</p>",
      "author": "dziura",
      "published_date": "2025-02-05T15:45:50+00:00",
      "source": "Embs",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 15,
      "reading_time": 1,
      "created_at": "2025-11-24T04:09:33.371393+00:00",
      "updated_at": "2025-11-24T04:30:06.917691+00:00",
      "metadata": {
        "processed_at": "2025-11-24T04:30:06.917701+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "6b5f32570094f1cedcde640a7566d20a",
      "url": "https://www.embs.org/blog-post/welcoming-dr-ana-kyani-as-wibme-chair-ieee-embs/",
      "title": "Welcoming Dr. Ana Kyani as the New Women in Biomedical Engineering Chair for IEEE EMBS",
      "content": "<p>The post <a href=\"https://www.embs.org/blog-post/welcoming-dr-ana-kyani-as-wibme-chair-ieee-embs/\">Welcoming Dr. Ana Kyani as the New Women in Biomedical Engineering Chair for IEEE EMBS</a> appeared first on <a href=\"https://www.embs.org\">IEEE EMBS</a>.</p>",
      "author": "Nancy Zimmerman",
      "published_date": "2025-03-27T17:10:33+00:00",
      "source": "Embs",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 24,
      "reading_time": 1,
      "created_at": "2025-11-24T04:09:33.371374+00:00",
      "updated_at": "2025-11-24T04:30:06.917705+00:00",
      "metadata": {
        "processed_at": "2025-11-24T04:30:06.917707+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "138dbc20af95ce55414e7d62214f9607",
      "url": "https://www.embs.org/press/embc-eic-sunghoon-ivan-lee/#new_tab",
      "title": "Ivan Lee, Appointed Editor-in-Chief of EMBC Proceedings",
      "content": "<p>&#160;</p>\n<p>The post <a href=\"https://www.embs.org/press/embc-eic-sunghoon-ivan-lee/#new_tab\">Ivan Lee, Appointed Editor-in-Chief of EMBC Proceedings</a> appeared first on <a href=\"https://www.embs.org\">IEEE EMBS</a>.</p>",
      "author": "Nancy Zimmerman",
      "published_date": "2025-09-08T16:27:03+00:00",
      "source": "Embs",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 17,
      "reading_time": 1,
      "created_at": "2025-11-24T04:09:33.371216+00:00",
      "updated_at": "2025-11-24T04:30:06.917710+00:00",
      "metadata": {
        "processed_at": "2025-11-24T04:30:06.917711+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "bb27cc903a5ef331c30ec652efec23d3",
      "url": "https://www.frontiersin.org/articles/10.3389/fnhum.2025.1638595",
      "title": "Supporting autistic adults with complex communication needs in making their voices heard: examining an adaptation of the Autism Voices framework",
      "content": "IntroductionAutistic adults with speech, language and/or cognitive challenges are often excluded from research, particularly from studies examining first-person perspectives, as these generally require that participants have strong speech, language, and cognitive skills. The current pilot study extends previous work and examines whether the Autism Voices framework can be adapted for use with a pre-existing interview the Camberwell Assessment of Need for Adults with Developmental and Intellectual Disabilities-Research version (CANDID-R).MethodsEleven young autistic adults with complex communication needs completed the CANDID-R interview using visual supports. These visual supports were provided to assist participants\u2019 comprehension of interview questions and to support them in answering the interview questions. Participants\u2019 caregivers also completed the interview and their answers to specific validation questions were compared to those of their adult children. Additionally, behavioral observations were also completed.ResultsThe findings from this pilot study indicate that our adaptation of the Autism Voices framework was, at least partially successful in supporting participants in answering the interview questions. Additionally, behavioral observations indicate that the visual supports helped participants remain engaged throughout the interview. However, results also indicate that further adaptations, which we discuss, will be required.ConclusionAutistic people with complex communication needs must be included in research about the lived experiences of autistic people. Building on previous work, we show that, with dedication and imagination, equitable and inclusive research is possible.",
      "author": "Mayada Elsabbagh",
      "published_date": "2025-11-14T00:00:00+00:00",
      "source": "Frontiers Human Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 220,
      "reading_time": 1,
      "created_at": "2025-11-24T04:09:11.398577+00:00",
      "updated_at": "2025-11-24T04:30:06.917714+00:00",
      "metadata": {
        "processed_at": "2025-11-24T04:30:06.917715+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "3b02242cff6d2644a50ca45222ecc123",
      "url": "https://www.reddit.com/r/Python/comments/1p5649f/made_a_free_opensource_trading_bot_that_actually/",
      "title": "Made a free, open-source trading bot that actually works - thought you guys might find it useful",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>**What My Project Does**</p> <p>An automated cryptocurrency trading bot that monitors markets 24/7, executes trades based on technical analysis strategies, and provides real-time monitoring through a web dashboard. It includes:</p> <p>- Multiple trading strategies (SMA Crossover, RSI+Bollinger Bands, EMA Scalping)</p> <p>- Backtesting engine with comprehensive performance metrics (Sharpe ratio, drawdown analysis, etc.)</p> <p>- Real-time Flask web dashboard with live equity curves</p> <p>- SQLite database for trade history and analytics</p> <p>- Telegram integration for instant notifications</p> <p>- Advanced risk management (stop loss, take profit, trailing stops, kill switch)</p> <p>- Automated deployment guides for free cloud hosting (Oracle Cloud)</p> <p>Built entirely in Python using ccxt for exchange connectivity, pandas for data processing, and Flask for the web interface.</p> <p>**Target Audience**</p> <p>This project is designed for:</p> <p>- Intermediate to advanced Python developers interested in algorithmic trading</p> <p>- Traders looking to automate their crypto strategies with a production-ready solution</p> <p>- Students learning about quantitative finance and automated trading systems</p> <p>- Anyone wanting to understand how trading bots work under the hood</p> <p>It's production-ready but comes with comprehensive testnet support for safe testing. The codebase is educational yet robust enough for real trading (with proper risk management).</p> <p>**Comparison**</p> <p>Unlike popular alternatives like Freqtrade or Jesse:</p> <p>- **Simpler architecture**: More approachable codebase for learning (&lt; 5000 lines vs 50k+)</p> <p>- **Integrated dashboard**: Built-in Flask dashboard without needing separate frontend setup</p> <p>- **Database-first design**: SQLite integration from the ground up for easy analytics</p> <p>- **Free deployment guides**: Detailed instructions for Oracle Cloud's always-free tier (most bots assume you have hosting figured out)</p> <p>- **Bilingual documentation**: Full docs in English and Spanish</p> <p>- **Educational focus**: Heavily commented code designed for understanding, not just using</p> <p>Trade-off: Fewer built-in strategies than Freqtrade (3 vs 20+), but easier to add custom ones due to simpler architecture.</p> <p>**Repository**: <a href=\"https://github.com/Astolfu/trading-bot\">https://github.com/Astolfu/trading-bot</a></p> <p>All contributions, feedback, and questions welcome! Currently supports Binance but architecture is extensible to other exchanges via ccxt.</p> <p>---</p> <p>*Standard disclaimer: Educational purposes. Not financial advice. Trade responsibly.*</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Obakin1865\"> /u/Obakin1865 </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1p5649f/made_a_free_opensource_trading_bot_that_actually/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1p5649f/made_a_free_opensource_trading_bot_that_actually/\">[comments]</a></span>",
      "author": "/u/Obakin1865",
      "published_date": "2025-11-24T03:10:19+00:00",
      "source": "Reddit Python",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 347,
      "reading_time": 1,
      "created_at": "2025-11-24T04:08:46.332168+00:00",
      "updated_at": "2025-11-24T04:30:06.917717+00:00",
      "metadata": {
        "processed_at": "2025-11-24T04:30:06.917719+00:00",
        "processing_method": "github_actions"
      }
    }
  ]
}