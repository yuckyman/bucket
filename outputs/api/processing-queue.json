{
  "last_updated": "2025-12-08T06:27:37.617710+00:00",
  "pending_count": 670,
  "processed_count": 330,
  "pending_articles": [
    {
      "id": "dfa26a9fc14bebcee5d9308b3e064fc7",
      "url": "https://arxiv.org/abs/2512.05536",
      "title": "Eye of the Beholder: Towards Measuring Visualization Complexity",
      "content": "arXiv:2512.05536v1 Announce Type: new \nAbstract: Constructing expressive and legible visualizations is a key activity for visualization designers. While numerous design guidelines exist, research on how specific graphical features affect perceived visual complexity remains limited. In this paper, we report on a crowdsourced study to collect human ratings of perceived complexity for diverse visualizations. Using these ratings as ground truth, we then evaluated three methods to estimate this perceived complexity: image analysis metrics, multilinear regression using manually coded visualization features, and automated feature extraction using a large language model (LLM). Image complexity metrics showed no correlation with human-perceived visualization complexity. Manual feature coding produced a reasonable predictive model but required substantial effort. In contrast, a zero-shot LLM (GPT-4o mini) demonstrated strong capabilities in both rating complexity and extracting relevant features. Our findings suggest that visualization complexity is truly in the eye of the beholder, yet can be effectively approximated using zero-shot LLM prompting, offering a scalable approach for evaluating the complexity of visualizations. The dataset and code for the study and data analysis can be found at https://osf.io/w85a4/",
      "author": "Johannes Ellemose, Niklas Elmqvist",
      "published_date": "2025-12-08T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 177,
      "reading_time": 1,
      "created_at": "2025-12-08T05:24:38.209230+00:00",
      "updated_at": "2025-12-08T05:24:38.209232+00:00"
    },
    {
      "id": "b0c803378f86b1d2ea93f99c5f5095a8",
      "url": "https://arxiv.org/abs/2512.05519",
      "title": "User Negotiations of Authenticity, Ownership, and Governance on AI-Generated Video Platforms: Evidence from Sora",
      "content": "arXiv:2512.05519v1 Announce Type: new \nAbstract: As AI-generated video platforms rapidly advance, ethical challenges such as copyright infringement emerge. This study examines how users make sense of AI-generated videos on OpenAI's Sora by conducting a qualitative content analysis of user comments. Through a thematic analysis, we identified four dynamics that characterize how users negotiate authenticity, authorship, and platform governance on Sora. First, users acted as critical evaluators of realism, assessing micro-details such as lighting, shadows, fluid motion, and physics to judge whether AI-generated scenes could plausibly exist. Second, users increasingly shifted from passive viewers to active creators, expressing curiosity about prompts, techniques, and creative processes. Text prompts were perceived as intellectual property, generating concerns about plagiarism and remixing norms. Third, users reported blurred boundaries between real and synthetic media, worried about misinformation, and even questioned the authenticity of other commenters, suspecting bot-generated engagement. Fourth, users contested platform governance: some perceived moderation as inconsistent or opaque, while others shared tactics for evading prompt censorship through misspellings, alternative phrasing, emojis, or other languages. Despite this, many users also enforced ethical norms by discouraging the misuse of real people's images or disrespectful content. Together, these patterns highlighted how AI-mediated platforms complicate notions of reality, creativity, and rule-making in emerging digital ecosystems. Based on the findings, we discuss governance challenges in Sora and how user negotiations inform future platform governance.",
      "author": "Bohui Shen, Shrikar Bhatta, Alex Ireebanije, Zexuan Liu, Abhinav Choudhry, Ece Gumusel, Kyrie Zhixuan Zhou",
      "published_date": "2025-12-08T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 225,
      "reading_time": 1,
      "created_at": "2025-12-08T05:24:38.209199+00:00",
      "updated_at": "2025-12-08T05:24:38.209201+00:00"
    },
    {
      "id": "cd434a461637e004eda5bc776d1cdc23",
      "url": "https://arxiv.org/abs/2512.05506",
      "title": "When Scaffolding Breaks: Investigating Student Interaction with LLM-Based Writing Support in Real-Time K-12 EFL Classrooms",
      "content": "arXiv:2512.05506v1 Announce Type: new \nAbstract: Large language models (LLMs) are promising tools for scaffolding students' English writing skills, but their effectiveness in real-time K-12 classrooms remains underexplored. Addressing this gap, our study examines the benefits and limitations of using LLMs as real-time learning support, considering how classroom constraints, such as diverse proficiency levels and limited time, affect their effectiveness. We conducted a deployment study with 157 eighth-grade students in a South Korean middle school English class over six weeks. Our findings reveal that while scaffolding improved students' ability to compose grammatically correct sentences, this step-by-step approach demotivated lower-proficiency students and increased their system reliance. We also observed challenges to classroom dynamics, where extroverted students often dominated the teacher's attention, and the system's assistance made it difficult for teachers to identify struggling students. Based on these findings, we discuss design guidelines for integrating LLMs into real-time writing classes as inclusive educational tools.",
      "author": "Junho Myung, Hyunseung Lim, Hana Oh, Hyoungwook Jin, Nayeon Kang, So-Yeon Ahn, Hwajung Hong, Alice Oh, Juho Kim",
      "published_date": "2025-12-08T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 151,
      "reading_time": 1,
      "created_at": "2025-12-08T05:24:38.209165+00:00",
      "updated_at": "2025-12-08T05:24:38.209167+00:00"
    },
    {
      "id": "3db79f17aa81b9688de0a715208b6eea",
      "url": "https://arxiv.org/abs/2512.05450",
      "title": "Classification and taxonomy of mobile application usability issues",
      "content": "arXiv:2512.05450v1 Announce Type: new \nAbstract: Despite years of research on testing the usability of mobile applications, our understanding of the issues their users experience still remains fragmented and underexplored. While most earlier studies has provided interesting insights, they have varying limitations in methodology, input diversity, and depth of analysis.On the contrary, this study employs a triangulation strategy, using two research methods (systematic literature review and interview) and two data sources (scholarly literature and expert knowledge) to explore the traits underlying usability issues. Our study contributes to the field of human-computer interaction (HCI) by presenting a catalog of 16 usability issue categories, enriched with corresponding keywords and extended into a taxonomy, as well as a novel three-tier app-user-resource (AUR) classification system. At the first app level, usability issues arise from user interface design, as well as from efficiency, errors, and operability. At the second user level, they influence cognitive load, effectiveness, ease of use, learnability, memorability, and understandability. At the third resource level, usability issues stem from network quality and hardware, such as battery life, CPU speed, physical device button size and availability, RAM capacity, and screen size. The root cause of the usability issues is the user interface design. Detailed findings and takeaways for both researchers and practitioners are also discussed. Further research could focus on developing a measurement model for the identified variables to confirm the direction and strength of their relationships with perceived usability. Software vendors can also benefit by updating existing quality assurance programs, reviews and audits tools, as well as testing checklists.",
      "author": "Pawel Weichbroth",
      "published_date": "2025-12-08T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 256,
      "reading_time": 1,
      "created_at": "2025-12-08T05:24:38.209130+00:00",
      "updated_at": "2025-12-08T05:24:38.209131+00:00"
    },
    {
      "id": "b33f48c969ca3701c24f9442babb77b0",
      "url": "https://arxiv.org/abs/2512.05438",
      "title": "EXR: An Interactive Immersive EHR Visualization in Extended Reality",
      "content": "arXiv:2512.05438v1 Announce Type: new \nAbstract: This paper presents the design and implementation of an Extended Reality (XR) platform for immersive, interactive visualization of Electronic Health Records (EHRs). The system extends beyond conventional 2D interfaces by visualizing both structured and unstructured patient data into a shared 3D environment, enabling intuitive exploration and real-time collaboration. The modular infrastructure integrates FHIR-based EHR data with volumetric medical imaging and AI-generated segmentation, ensuring interoperability with modern healthcare systems. The platform's capabilities are demonstrated using synthetic EHR datasets and computed tomography (CT)-derived spine models processed through an AI-powered segmentation pipeline. This work suggests that such integrated XR solutions could form the foundation for next-generation clinical decision-support tools, where advanced data infrastructures are directly accessible in an interactive and spatially rich environment.",
      "author": "Benoit Marteau, Shaun Q. Y. Tan, Jieru Li, Andrew Hornback, Yishan Zhong, Shaunna Wang, Christian Lowson, Jason Woloff, Joshua M. Pahys, Steven W. Hwang, Coleman Hilton, May D. Wang",
      "published_date": "2025-12-08T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 125,
      "reading_time": 1,
      "created_at": "2025-12-08T05:24:38.209093+00:00",
      "updated_at": "2025-12-08T05:24:38.209095+00:00"
    },
    {
      "id": "e7c9301c8e49b9e7d4dbd534ee2575c9",
      "url": "https://arxiv.org/abs/2512.05433",
      "title": "From Vision to Touch: Bridging Visual and Tactile Principles for Accessible Data Representation",
      "content": "arXiv:2512.05433v1 Announce Type: new \nAbstract: Tactile graphics are widely used to present maps and statistical diagrams to blind and low vision (BLV) people, with accessibility guidelines recommending their use for graphics where spatial relationships are important. Their use is expected to grow with the advent of commodity refreshable tactile displays. However, in stark contrast to visual information graphics, we lack a clear understanding of the benefits that well-designed tactile information graphics offer over text descriptions for BLV people. To address this gap, we introduce a framework considering the three components of encoding, perception and cognition to examine the known benefits for visual information graphics and explore their applicability to tactile information graphics. This work establishes a preliminary theoretical foundation for the tactile-first design of information graphics and identifies future research avenues.",
      "author": "Kim Marriott, Matthew Butler, Leona Holloway, Bill Jolley, Bongshin Lee, Bruce Maguire, Danielle Albers Szafir",
      "published_date": "2025-12-08T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 131,
      "reading_time": 1,
      "created_at": "2025-12-08T05:24:38.209066+00:00",
      "updated_at": "2025-12-08T05:24:38.209068+00:00"
    },
    {
      "id": "5e5e17bec499b502319964c8eff33ee9",
      "url": "https://arxiv.org/abs/2512.05397",
      "title": "Simulating Life Paths with Digital Twins: AI-Generated Future Selves Influence Decision-Making and Expand Human Choice",
      "content": "arXiv:2512.05397v1 Announce Type: new \nAbstract: Major life transitions demand high-stakes decisions, yet people often struggle to imagine how their future selves will live with the consequences. To support this limited capacity for mental time travel, we introduce AI-enabled digital twins that have ``lived through'' simulated life scenarios. Rather than predicting optimal outcomes, these simulations extend prospective cognition by making alternative futures vivid enough to support deliberation without assuming which path is best. We evaluate this idea in a randomized controlled study (N=192) using multimodal synthesis - facial age progression, voice cloning, and large language model dialogue - to create personalized avatars representing participants 30 years forward. Young adults 18 to 28 years old described pending binary decisions and were assigned to guided imagination or one of four avatar conditions: single-option, balanced dual-option, or expanded three-option with a system-generated novel alternative. Results showed asymmetric effects: single-sided avatars increased shifts toward the presented option, while balanced presentation produced movement toward both. Introducing a system-generated third option increased adoption of this new alternative compared to control, suggesting that AI-generated future selves can expand choice by surfacing paths that might otherwise go unnoticed. Participants rated evaluative reasoning and eudaimonic meaning-making as more important than emotional or visual vividness. Perceived persuasiveness and baseline agency predicted decision change. These findings advance understanding of AI-mediated episodic prospection and raise questions about autonomy in AI-augmented decisions.",
      "author": "Rachel Poonsiriwong, Chayapatr Archiwaranguprok, Constanze Albrecht, Peggy Yin, Nattavudh Powthavee, Hal Hershfield, Monchai Lertsutthiwong, Kavin Winson, Pat Pataranutaporn",
      "published_date": "2025-12-08T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 228,
      "reading_time": 1,
      "created_at": "2025-12-08T05:24:38.209039+00:00",
      "updated_at": "2025-12-08T05:24:38.209041+00:00"
    },
    {
      "id": "d44ba204f5c9f6cf1d76e9b2cbafb028",
      "url": "https://arxiv.org/abs/2512.05389",
      "title": "CLIO: A Tour Guide Robot with Co-speech Actions for Visual Attention Guidance and Enhanced User Engagement",
      "content": "arXiv:2512.05389v1 Announce Type: new \nAbstract: While audio guides can offer rich information about an exhibit, it is challenging for visitors to focus on specific exhibit details based only on the verbal description. We present \\textit{CLIO}, a tour guide robot with co-speech actions to direct visitors' visual attention and thus enhance the overall user engagement in a guided tour. \\textit{CLIO} is equipped with designed actions to engage visitors. It builds eye contact with the visitor through tracking a visitor's face and blinking its eyes, or orient their attention by its head movement and laser pointer. We further use a Large Language Model (LLM) to coordinate the designed actions with a given narrative script for exhibition. We conducted a user study to evaluate the \\textit{CLIO} system in a mock-up exhibition of historical photographs. We collected feedback from questionnaires and quantitative data from a mobile eye tracker. Experimental results validated that the engaging actions are well designed and demonstrated its efficacy in guiding visual attention of the visitors. It was evidenced that \\textit{CLIO} achieved an enhanced engagement compared to the baseline system with only audio guidance.",
      "author": "Yuxuan Chen, Ian Leong Ting Lo, Bao Guo, Netitorn Kawmali, Chun Kit Chan, Ruoyu Wang, Jia Pan, Lei Yang",
      "published_date": "2025-12-08T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 183,
      "reading_time": 1,
      "created_at": "2025-12-08T05:24:38.209003+00:00",
      "updated_at": "2025-12-08T05:24:38.209004+00:00"
    },
    {
      "id": "3677782a33d9508433bccf38cc16ec17",
      "url": "https://arxiv.org/abs/2512.05310",
      "title": "Systematically Evaluating Equivalent Purpose for Digital Maps",
      "content": "arXiv:2512.05310v1 Announce Type: new \nAbstract: Digital geographic maps remain largely inaccessible to blind and low-vision individuals (BLVIs), despite global legislation adopting the Web Content Accessibility Guidelines (WCAG). A critical gap exists in defining \"equivalent purpose\" for maps under WCAG Success Criterion 1.1.1, which requires that non-text content provide a text alternative that serves the \"equivalent purpose\". This paper proposes a systematic framework for evaluating map accessibility, called the Map Equivalent-Purpose Framework (MEP Framework), defining purpose through three items (Generalized, Spatial Information, and Spatial Relationships), and establishing 15 measurable criteria for equivalent information communication. Eight text map representations were evaluated against visual map baselines using the proposed MEP Framework. Results show that legacy methods such as tables and turn-by-turn directions fail to meet the MEP Framework criteria, while Audiom Maps, Multi User Domain (MUD) Maps, and Audio Descriptions meet the criteria. The evaluation highlights the necessity of holistic, systematic approaches to ensure non-visual maps convey all generalized spatial information and relationships present in visual maps. The MEP Framework provides a replicable methodology for comprehensively assessing digital map accessibility, clarifying WCAG's \"equivalent purpose\", and guiding compliant and usable map creation. Compliant maps will support BLVIs' participation in map-dependent professions and civic engagement.",
      "author": "Brandon Biggs, David Sloan, Brett Oppegaard, Nicholas A. Giudice, James M. Coughlan, Bruce N. Walker",
      "published_date": "2025-12-08T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 200,
      "reading_time": 1,
      "created_at": "2025-12-08T05:24:38.208966+00:00",
      "updated_at": "2025-12-08T05:24:38.208970+00:00"
    },
    {
      "id": "8defd01de24098a6a35929709b75f97f",
      "url": "https://arxiv.org/abs/2512.05718",
      "title": "Emergence of Language in the Developing Brain",
      "content": "arXiv:2512.05718v1 Announce Type: new \nAbstract: A few million words suffice for children to acquire language. Yet, the brain mechanisms underlying this unique ability remain poorly understood. To address this issue, we investigate neural activity recorded from over 7,400 electrodes implanted in the brains of 46 children, teenagers, and adults for epilepsy monitoring, as they listened to an audiobook version of \"The Little Prince\". We then train neural encoding and decoding models using representations, derived either from linguistic theory or from large language models, to map the location, dynamics and development of the language hierarchy in the brain. We find that a broad range of linguistic features is robustly represented across the cortex, even in 2-5-year-olds. Crucially, these representations evolve with age: while fast phonetic features are already present in the superior temporal gyrus of the youngest individuals, slower word-level representations only emerge in the associative cortices of older individuals. Remarkably, this neuro-developmental trajectory is spontaneously captured by large language models: with training, these AI models learned representations that can only be identified in the adult human brain. Together, these findings reveal the maturation of language representations in the developing brain and show that modern AI systems provide a promising tool to model the neural bases of language acquisition.",
      "author": "Linnea Evanson, Christine Bulteau, Mathilde Chipaux, Georg Dorfm\\\"uller, Sarah Ferrand-Sorbets, Emmanuel Raffo, Sarah Rosenberg, Pierre Bourdillon, Jean-R\\'emi King",
      "published_date": "2025-12-08T05:00:00+00:00",
      "source": "Arxiv Qbio Nc",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 208,
      "reading_time": 1,
      "created_at": "2025-12-08T05:24:37.141113+00:00",
      "updated_at": "2025-12-08T05:24:37.141114+00:00"
    }
  ],
  "recently_processed": [
    {
      "id": "9b9b9688b1b7ad0daae0d07393c16aad",
      "url": "http://ieeexplore.ieee.org/document/11245797",
      "title": "Front Cover",
      "content": "null",
      "author": "",
      "published_date": "2025-11-13T13:16:42+00:00",
      "source": "Transactions Biomedical Engineering",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 1,
      "reading_time": 1,
      "created_at": "2025-12-08T05:47:23.071037+00:00",
      "updated_at": "2025-12-08T06:27:37.523955+00:00",
      "metadata": {
        "processed_at": "2025-12-08T06:27:37.523967+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "964e4e96f654e05ff88e26941ff8a354",
      "url": "https://www.nature.com/articles/s41598-025-31136-5",
      "title": "Instructional modality influences neurocognitive engagement during moral learning",
      "content": "",
      "author": "",
      "published_date": "2025-12-08T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-12-08T05:47:05.657546+00:00",
      "updated_at": "2025-12-08T06:27:37.523971+00:00",
      "metadata": {
        "processed_at": "2025-12-08T06:27:37.523972+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "e435802bf4d0d7eda38d5dd8d443c13a",
      "url": "https://www.nature.com/articles/s41419-025-08301-9",
      "title": "Regulation of NTRK2 alternative splicing by PRPF40B controls neural differentiation and synaptic plasticity",
      "content": "",
      "author": "",
      "published_date": "2025-12-08T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-12-08T05:47:05.657509+00:00",
      "updated_at": "2025-12-08T06:27:37.523975+00:00",
      "metadata": {
        "processed_at": "2025-12-08T06:27:37.523976+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "2e92ce669157727944f2ec8e9e4cb071",
      "url": "https://www.nature.com/articles/s41746-025-02188-8",
      "title": "Anatomically-guided Masked Autoencoder with Domain-Adaptive Prompting (AMAP) for multimodal cerebral aneurysm detection and segmentation",
      "content": "",
      "author": "",
      "published_date": "2025-12-08T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-12-08T05:47:05.657489+00:00",
      "updated_at": "2025-12-08T06:27:37.523978+00:00",
      "metadata": {
        "processed_at": "2025-12-08T06:27:37.523980+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "ecc1715f7857497b3a5d36f3a3aa8eb5",
      "url": "https://arxiv.org/abs/2512.05176",
      "title": "Towards A Cultural Intelligence and Values Inferences Quality Benchmark for Community Values and Common Knowledge",
      "content": "arXiv:2512.05176v1 Announce Type: cross \nAbstract: Large language models (LLMs) have emerged as a powerful technology, and thus, we have seen widespread adoption and use on software engineering teams. Most often, LLMs are designed as \"general purpose\" technologies meant to represent the general population. Unfortunately, this often means alignment with predominantly Western Caucasian narratives and misalignment with other cultures and populations that engage in collaborative innovation. In response to this misalignment, there have been recent efforts centered on the development of \"culturally-informed\" LLMs, such as ChatBlackGPT, that are capable of better aligning with historically marginalized experiences and perspectives. Despite this progress, there has been little effort aimed at supporting our ability to develop and evaluate culturally-informed LLMs. A recent effort proposed an approach for developing a national alignment benchmark that emphasizes alignment with national social values and common knowledge. However, given the range of cultural identities present in the United States (U.S.), a national alignment benchmark is an ineffective goal for broader representation. To help fill this gap in this US context, we propose a replication study that translates the process used to develop KorNAT, a Korean National LLM alignment benchmark, to develop CIVIQ, a Cultural Intelligence and Values Inference Quality benchmark centered on alignment with community social values and common knowledge. Our work provides a critical foundation for research and development aimed at cultural alignment of AI technologies in practice.",
      "author": "Brittany Johnson, Erin Reddick, Angela D. R. Smith",
      "published_date": "2025-12-08T05:00:00+00:00",
      "source": "Arxiv Cs Hc",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 230,
      "reading_time": 1,
      "created_at": "2025-12-08T05:24:38.209265+00:00",
      "updated_at": "2025-12-08T06:27:37.523982+00:00",
      "metadata": {
        "processed_at": "2025-12-08T06:27:37.523983+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "7b642de21bbacc9b4ce76cc372ead747",
      "url": "https://turtletoy.net/",
      "title": "Turtletoy",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46138459\">Comments</a>",
      "author": "",
      "published_date": "2025-12-03T18:57:08+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-08T04:07:20.877195+00:00",
      "updated_at": "2025-12-08T04:29:58.109228+00:00",
      "metadata": {
        "processed_at": "2025-12-08T04:29:58.109237+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "2d7472beebd02a461001301f2e954616",
      "url": "https://www.thepavement.xyz/p/the-era-of-jobs-is-ending",
      "title": "The era of jobs is ending",
      "content": "<p>Article URL: <a href=\"https://www.thepavement.xyz/p/the-era-of-jobs-is-ending\">https://www.thepavement.xyz/p/the-era-of-jobs-is-ending</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46186900\">https://news.ycombinator.com/item?id=46186900</a></p>\n<p>Points: 20</p>\n<p># Comments: 12</p>",
      "author": "SturgeonsLaw",
      "published_date": "2025-12-08T00:23:45+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-08T04:07:19.605130+00:00",
      "updated_at": "2025-12-08T04:29:58.109241+00:00",
      "metadata": {
        "processed_at": "2025-12-08T04:29:58.109244+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "33000ea9ce4b38a72e8be121ebf8fc02",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.03.692236v1?rss=1",
      "title": "S100A8/A9 Inhibition Reduces Splenic Myelopoiesis and Improves Outcomes After Stroke",
      "content": "Background: Neutrophils are among the earliest immune cells to infiltrate the ischemic brain and contribute to secondary neuronal damage. The alarmin S100 calcium-binding protein A8/A9 (S100A8/A9), predominantly released by neutrophils, is upregulated during this process. Although the bone marrow is recognised as the principal site of neutrophil production via myelopoiesis, the role of the spleen as an immune-responsive organ remains incompletely understood. Methods: In this study, we employed a transient middle cerebral artery occlusion (MCAO) model in male C57Bl/6 mice and examined immune responses 24 hours post-stroke in the blood, bone marrow and spleen using flow cytometry. To understand the role of S100A8/A9 in modulating stroke-induced myelopoiesis, we administered a small molecule inhibitor of S100A8/A9, ABR-215757, before and after stroke. Results: Neutrophils and S100A8/A9 were found in the infarcted brain tissue. Interestingly, we observed a marked increase in splenic neutrophils, accompanied by an expansion of myeloid progenitors, indicating activation of extramedullary myelopoiesis. Given our previous work showing that S100A8/A9 promotes myelopoiesis, we pharmacologically inhibited S100A8/A9 to determine if this would modulate stroke-induced myelopoiesis. Treatment with ABR-215757 at 24 hours post-stroke led to reduced splenic myelopoiesis, reversed neutrophilia, enhanced forelimb grip strength, and a one-third reduction in infarct size. Conclusion: These findings identify the spleen as a key contributor to neutrophil production following stroke and suggest that targeting S100A8/A9 may attenuate post-stroke inflammation and improve neurological recovery.",
      "author": "Kim, H. A., Al-Sharea, A., Chu, H., Tang, S.-C., Rupasinghe, S. A., Zhang, S. R., Nagareddy, P. R., Drummond, G. R., Arumugam, T. V., Murphy, A. J., Sobey, C. G., Lee, M. K.",
      "published_date": "2025-12-07T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 226,
      "reading_time": 1,
      "created_at": "2025-12-08T03:23:13.295483+00:00",
      "updated_at": "2025-12-08T04:29:58.109246+00:00",
      "metadata": {
        "processed_at": "2025-12-08T04:29:58.109248+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "5f8ded18951549b8b69d00a7d8b9166b",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.03.692215v1?rss=1",
      "title": "Inner-ear delivery of AAV2-retro robustly labels lateral olivocochlear efferents but results in off-target transfection in the contralateral cochlea and the brain",
      "content": "Gene delivery via adeno-associated viruses (AAVs) is a valuable tool for understanding the organization and function of auditory neuronal circuitry. In this study, we explored the use of AAVs injected into the inner ear to transfect the lateral olivocochlear (LOC) pathway, a poorly understood ipsilateral component of the auditory efferent feedback system. AAV serotypes exhibit a wide range of properties, including cell type selectivity and the capacity for retrograde transport, but none of the AAV serotypes used for inner ear delivery have been reported to successfully transfect the LOC pathway. Here, we show that unilateral inner ear delivery of AAV2-retro robustly labeled the LOC pathway. However, the ability of AAV2-retro to diffuse via the cochlear aqueduct from the perilymph into the cerebrospinal fluid resulted in off-target transfection in the brain and the labeling of LOC projections in the contralateral cochlea. The extent of contralateral transfection of LOC neurons depended on the age of the animal and the amount of virus delivered to the inner ear. These findings highlight the importance of considering the dosage and properties of AAV serotype when interpreting experimental results.",
      "author": "Khalil, M., Bisignani, M., Kandler, K.",
      "published_date": "2025-12-07T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 183,
      "reading_time": 1,
      "created_at": "2025-12-08T03:23:13.295435+00:00",
      "updated_at": "2025-12-08T04:29:58.109251+00:00",
      "metadata": {
        "processed_at": "2025-12-08T04:29:58.109252+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "c7a70f86784afcbdea67aec16026ae1e",
      "url": "https://www.nature.com/articles/s41598-025-28640-z",
      "title": "Net Promoter Score inversion may signal problematic digital use",
      "content": "",
      "author": "",
      "published_date": "2025-12-08T00:00:00+00:00",
      "source": "Nature Neuroscience Subjects",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 0,
      "reading_time": 1,
      "created_at": "2025-12-08T03:23:11.968742+00:00",
      "updated_at": "2025-12-08T04:29:58.109254+00:00",
      "metadata": {
        "processed_at": "2025-12-08T04:29:58.109256+00:00",
        "processing_method": "github_actions"
      }
    }
  ]
}