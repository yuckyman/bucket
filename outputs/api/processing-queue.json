{
  "last_updated": "2025-12-02T18:25:20.513283+00:00",
  "pending_count": 681,
  "processed_count": 319,
  "pending_articles": [
    {
      "id": "9e24e1c5b96f56cd9d7978969f8bb64d",
      "url": "https://www.biorxiv.org/content/10.1101/10.64898/2025.11.28.691222v1?rss=1",
      "title": "Reorganisation of Cortico-Hippocampal White Matter Pathways in Healthy Ageing: Evidence for Paradoxical Shifts in Structural Connectivity.",
      "content": "The hippocampus plays a central role in episodic memory and has been the focus of extensive research over past decades. A substantial body of work has demonstrated that age-related memory decline is linked to changes in how the hippocampus functionally interacts with distributed brain networks. While functional connectivity changes in ageing are well documented, relatively little is known about alterations in the structural connectivity (SC) of the hippocampus, despite its foundational role in supporting communication across neural systems. In this study, we combined high-quality data from the Human Connectome Project and advanced diffusion-weighted imaging (DWI) methods to investigate age-related changes in hippocampal SC. Using a recently developed tractography pipeline that allows greater anatomical specificity than conventional approaches, we systematically compared connectivity patterns between younger (26-30 years) and older (56-60 years) adults. Results revealed reduced hippocampal SC with the entorhinal cortex and medial parietal cortices in older participants, alongside increased SC with anterior temporal areas. This paradoxical pattern suggests that ageing is associated with both vulnerability and reorganisation of hippocampal networks, with increased hippocampal-temporal connectivity potentially reflecting compensatory plasticity in response to reduced posterior medial connection. These findings provide in vivo evidence of cortico-hippocampal structural reorganisation in late middle age, a critical period when pathological processes such as tau deposition are already detectable in cognitively healthy individuals. More broadly, they demonstrate the power of our anatomically refined tractography pipeline as a proof of concept for detecting subtle, regionally specific changes in hippocampal pathway density. This approach holds promise for charting normative ageing trajectories and identifying early biomarkers of vulnerability and compensation in memory-related networks.",
      "author": "Dalton, M. A., D'Souza, A., Ansari Mahabadian, A., Calamante, F., Piguet, O.",
      "published_date": "2025-12-02T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 263,
      "reading_time": 1,
      "created_at": "2025-12-02T17:27:23.147895+00:00",
      "updated_at": "2025-12-02T17:27:23.147897+00:00"
    },
    {
      "id": "35ae4805c59b0a7d6da80e482cf8da8a",
      "url": "https://www.biorxiv.org/content/10.1101/10.64898/2025.11.29.691281v1?rss=1",
      "title": "The PDE4D ortholog Dunce suppresses memory in Drosophila melanogaster",
      "content": "The regulation of cAMP concentration is a key component of the mechanisms underlying learning and memory. In Drosophila melanogaster, the cAMP-specific phosphodiesterase mutant dunce1 results in increased levels of cAMP but poorer associative short-term memory and anesthesia-resistant memory. This raises the question of how elevated cAMP levels can cause defects in both short-term and long-term memory. To answer this question, we analyzed associative olfactory learning and memory in Drosophila larvae of both sexes with the isoform-specific dunceD143 mutation. Flies with this mutation exhibited better learning than flies with the dunce1 mutant. The memory facilitated by dunceD143 was stable and easily reversable. The improvement in memory was also traced to a defined subset of neurons. A comparison of the subcellular localization of Dunce isoforms indicates that the regulation of cAMP in the soma suppresses early memory formation. We revealed that Dunce regulates at least two different aspects of learning and memory, specifically, preventing the premature formation of memory and facilitating the formation of memory after multiple training sessions. The different functions of Dunce might be due to different cell types.",
      "author": "Hasselmann, T., Verbrueggen, M., Mueller, M., Gompert, M., Scholz, H.",
      "published_date": "2025-12-02T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 179,
      "reading_time": 1,
      "created_at": "2025-12-02T17:27:23.147836+00:00",
      "updated_at": "2025-12-02T17:27:23.147838+00:00"
    },
    {
      "id": "3328fc5b103e28707e2c822f369e2226",
      "url": "https://www.biorxiv.org/content/10.1101/10.64898/2025.11.29.691280v1?rss=1",
      "title": "Neural information sharing across the orienting attentional network predicts intelligence in children",
      "content": "Efficient brain functioning is often defined as the ability to achieve high performance with minimal cognitive resources. This study investigated the relationship between intelligence and attentional network efficiency in school-aged children, using electroencephalography (EEG) during the Attention Network Test (ANT). Participants were 38 children aged 11-14 years, recruited from schools in the Maule Region of Chile. Attentional network efficiency was assessed through event-related potentials (ERPs), midfrontal theta power as an index of conflict processing, and weighted Symbolic Mutual Information (wSMI) to quantify large-scale, nonlinear information sharing. Higher full-scale IQ scores were specifically associated with reduced wSMI within the orienting network, suggesting greater neural efficiency through less widespread information exchange between dorsal frontoparietal nodes. No significant associations were found between IQ and theta-band power during conflict processing. These findings provide novel evidence linking intelligence in childhood to network-level neural efficiency in attentional orienting, supporting the view that individual differences in cognitive ability reflect not only localized neural activity but also the efficiency of information integration within task-relevant networks.",
      "author": "Lucero, B., Munoz-Quezada, M. T., Saracini, C., Lanfranco, R. C., Canales-Johnson, A.",
      "published_date": "2025-12-02T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 167,
      "reading_time": 1,
      "created_at": "2025-12-02T17:27:23.147789+00:00",
      "updated_at": "2025-12-02T17:27:23.147793+00:00"
    },
    {
      "id": "e7ba906edb8af0b67222b89479ff3a92",
      "url": "https://www.reddit.com/r/Python/comments/1pcce1w/pyimagecuda_gpuaccelerated_image_compositing_for/",
      "title": "PyImageCUDA - GPU-accelerated image compositing for Python",
      "content": "<!-- SC_OFF --><div class=\"md\"><h2>What My Project Does</h2> <p>PyImageCUDA is a lightweight (~1MB) library for <strong>GPU-accelerated image composition</strong>. Unlike OpenCV (computer vision) or Pillow (CPU-only), it fills the gap for high-performance design workflows.</p> <p><strong>10-400x speedups</strong> for GPU-friendly operations with a Pythonic API.</p> <h2>Target Audience</h2> <ul> <li><strong>Generative Art</strong> - Render thousands of variations in seconds</li> <li><strong>Video Processing</strong> - Real-time frame manipulation</li> <li><strong>Data Augmentation</strong> - Batch transformations for ML</li> <li><strong>Tool Development</strong> - Backend for image editors</li> <li><strong>Game Development</strong> - Procedural asset generation</li> </ul> <h2>Why I Built This</h2> <p>I wanted to <strong>learn CUDA from scratch</strong>. This evolved into the core engine for a <strong>parametric node-based image editor</strong> I'm building (release coming soon!).</p> <p><strong>The gap:</strong> CuPy/OpenCV lack design primitives. Pillow is CPU-only and slow. Existing solutions require CUDA Toolkit or lack composition features.</p> <p><strong>The solution:</strong> &quot;Pillow on steroids&quot; - render drop shadows, gradients, blend modes... without writing raw kernels. Zero heavy dependencies (just pip install), design-first API, smart memory management.</p> <h2>Key Features</h2> <p>\u2705 <strong>Zero Setup</strong> - No CUDA Toolkit/Visual Studio, just standard NVIDIA drivers<br /> \u2705 <strong>1MB Library</strong> - Ultra-lightweight<br /> \u2705 <strong>Float32 Precision</strong> - Prevents color banding<br /> \u2705 <strong>Smart Memory</strong> - Reuse buffers, resize without reallocation<br /> \u2705 <strong>NumPy Integration</strong> - Works with OpenCV, Pillow, Matplotlib<br /> \u2705 <strong>Rich Features</strong> - +40 operations (gradients, blend modes, effects...)</p> <h2>Quick Example</h2> <p>```python from pyimagecuda import Image, Fill, Effect, Blend, Transform, save</p> <p>with Image(1024, 1024) as bg: Fill.color(bg, (0, 1, 0.8, 1))</p> <pre><code>with Image(512, 512) as card: Fill.gradient(card, (1, 0, 0, 1), (0, 0, 1, 1), 'radial') Effect.rounded_corners(card, 50) with Effect.stroke(card, 10, (1, 1, 1, 1)) as stroked: with Effect.drop_shadow(stroked, blur=50, color=(0, 0, 0, 1)) as shadowed: with Transform.rotate(shadowed, 45) as rotated: Blend.normal(bg, rotated, anchor='center') save(bg, 'output.png') </code></pre> <p>```</p> <h2>Advanced: Zero-Allocation Batch Processing</h2> <p><strong>Buffer reuse eliminates allocations + dynamic resize without reallocation:</strong> ```python from pyimagecuda import Image, ImageU8, load, Filter, save</p> <h1>Pre-allocate buffers once (with max capacity)</h1> <p>src = Image(4096, 4096) # Source images dst = Image(4096, 4096) # Processed results<br /> temp = Image(4096, 4096) # Temp for operations u8 = ImageU8(4096, 4096) # I/O conversions</p> <h1>Process 1000 images with zero additional allocations</h1> <h1>Buffers resize dynamically within capacity</h1> <p>for i in range(1000): load(f&quot;input<em>{i}.jpg&quot;, f32_buffer=src, u8_buffer=u8) Filter.gaussian_blur(src, radius=10, dst_buffer=dst, temp_buffer=temp) save(dst, f&quot;output</em>{i}.jpg&quot;, u8_buffer=u8)</p> <h1>Cleanup once</h1> <p>src.free() dst.free() temp.free() u8.free() ```</p> <h2>Operations</h2> <ul> <li><a href=\"https://offerrall.github.io/pyimagecuda/fill/\">Fill</a> (Solid colors, Gradients, Checkerboard, Grid, Stripes, Dots, Circle, Ngon, Noise, Perlin)</li> <li><a href=\"https://offerrall.github.io/pyimagecuda/text/\">Text</a> (Rich typography, system fonts, HTML-like markup, letter spacing...)</li> <li><a href=\"https://offerrall.github.io/pyimagecuda/blend/\">Blend</a> (Normal, Multiply, Screen, Add, Overlay, Soft Light, Hard Light, Mask)</li> <li><a href=\"https://offerrall.github.io/pyimagecuda/resize/\">Resize</a> (Nearest, Bilinear, Bicubic, Lanczos)</li> <li><a href=\"https://offerrall.github.io/pyimagecuda/adjust/\">Adjust</a> (Brightness, Contrast, Saturation, Gamma, Opacity)</li> <li><a href=\"https://offerrall.github.io/pyimagecuda/transform/\">Transform</a> (Flip, Rotate, Crop)</li> <li><a href=\"https://offerrall.github.io/pyimagecuda/filter/\">Filter</a> (Gaussian Blur, Sharpen, Sepia, Invert, Threshold, Solarize, Sobel, Emboss)</li> <li><a href=\"https://offerrall.github.io/pyimagecuda/effect/\">Effect</a> (Drop Shadow, Rounded Corners, Stroke, Vignette)</li> </ul> <p><a href=\"https://offerrall.github.io/pyimagecuda/\"><strong>\u2192 Full Documentation</strong></a></p> <h2>Performance</h2> <ul> <li><strong>Advanced operations</strong> (blur, blend, Drop shadow...): <strong>10-260x faster</strong> than CPU</li> <li><strong>Simple operations</strong> (flip, crop...): <strong>3-20x faster</strong> than CPU</li> <li><strong>Single operation + file I/O</strong>: <strong>1.5-2.5x faster</strong> (CPU-GPU transfer adds overhead, but still outperforms Pillow/OpenCV - see benchmarks)</li> <li><strong>Multi-operation pipelines</strong>: <strong>Massive speedups</strong> (data stays on GPU)</li> </ul> <p>Maximum performance when chaining operations on GPU without saving intermediate results.</p> <p><a href=\"https://offerrall.github.io/pyimagecuda/benchmarks/\"><strong>\u2192 Full Benchmarks</strong></a></p> <h2>Installation</h2> <p><code>bash pip install pyimagecuda </code></p> <p><strong>Requirements:</strong> - Windows 10/11 or Linux (Ubuntu, Fedora, Arch, WSL2...) - NVIDIA GPU (GTX 900+) - Standard NVIDIA drivers</p> <p><strong>NOT required:</strong> CUDA Toolkit, Visual Studio, Conda</p> <h2>Status</h2> <p><strong>Version:</strong> 0.0.7 Alpha<br /> <strong>State:</strong> Core features stable, more coming soon</p> <h2>Links</h2> <ul> <li><strong>GitHub</strong>: <a href=\"https://github.com/offerrall/pyimagecuda\">https://github.com/offerrall/pyimagecuda</a></li> <li><strong>Docs</strong>: <a href=\"https://offerrall.github.io/pyimagecuda/\">https://offerrall.github.io/pyimagecuda/</a></li> <li><strong>PyPI</strong>: <code>pip install pyimagecuda</code></li> </ul> <hr /> <p><strong>Feedback welcome!</strong> </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/drboom9\"> /u/drboom9 </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1pcce1w/pyimagecuda_gpuaccelerated_image_compositing_for/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1pcce1w/pyimagecuda_gpuaccelerated_image_compositing_for/\">[comments]</a></span>",
      "author": "/u/drboom9",
      "published_date": "2025-12-02T16:07:57+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 595,
      "reading_time": 2,
      "created_at": "2025-12-02T17:26:47.534811+00:00",
      "updated_at": "2025-12-02T17:26:47.534813+00:00"
    },
    {
      "id": "7653cf9539ffd724a010995f44d78e2d",
      "url": "https://www.ycombinator.com/companies/poka-labs/jobs/RCQgmqB-founding-engineer",
      "title": "Poka Labs (YC S24) Is Hiring a Founding Engineer",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46123374\">Comments</a>",
      "author": "",
      "published_date": "2025-12-02T17:00:12+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-02T17:26:46.321133+00:00",
      "updated_at": "2025-12-02T17:26:46.321134+00:00"
    },
    {
      "id": "1a1ca4483f3cc4c1809be883021a5161",
      "url": "https://api.github.com/meta",
      "title": "API GitHub Meta",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46123469\">Comments</a>",
      "author": "",
      "published_date": "2025-12-02T17:06:24+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-02T17:26:46.321094+00:00",
      "updated_at": "2025-12-02T17:26:46.321096+00:00"
    },
    {
      "id": "7653cf9539ffd724a010995f44d78e2d",
      "url": "https://www.ycombinator.com/companies/poka-labs/jobs/RCQgmqB-founding-engineer",
      "title": "Poka Labs (YC S24) Is Hiring a Founding Engineer",
      "content": "<p>Article URL: <a href=\"https://www.ycombinator.com/companies/poka-labs/jobs/RCQgmqB-founding-engineer\">https://www.ycombinator.com/companies/poka-labs/jobs/RCQgmqB-founding-engineer</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46123374\">https://news.ycombinator.com/item?id=46123374</a></p>\n<p>Points: 0</p>\n<p># Comments: 0</p>",
      "author": "arbass",
      "published_date": "2025-12-02T17:00:12+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-02T17:26:45.048966+00:00",
      "updated_at": "2025-12-02T17:26:45.048968+00:00"
    },
    {
      "id": "1a1ca4483f3cc4c1809be883021a5161",
      "url": "https://api.github.com/meta",
      "title": "API GitHub Meta",
      "content": "<p>Article URL: <a href=\"https://api.github.com/meta\">https://api.github.com/meta</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46123469\">https://news.ycombinator.com/item?id=46123469</a></p>\n<p>Points: 11</p>\n<p># Comments: 0</p>",
      "author": "luispa",
      "published_date": "2025-12-02T17:06:24+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-02T17:26:45.048935+00:00",
      "updated_at": "2025-12-02T17:26:45.048943+00:00"
    },
    {
      "id": "086acbf16f45fb407e18e9f3023332e7",
      "url": "https://www.reddit.com/r/Python/comments/1pccbk4/structure_large_python_projects_for/",
      "title": "Structure Large Python Projects for Maintainability",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>I'm scaling a Python project from &quot;works for me&quot; to &quot;multiple people need to work on this,&quot; and I'm realizing my structure isn't great.</p> <p><strong>Current situation:</strong></p> <p>I have one main directory with 50+ modules. No clear separation of concerns. Tests are scattered. Imports are a mess. It works, but it's hard to navigate and modify.</p> <p><strong>Questions I have:</strong></p> <ul> <li>What's a good folder structure for a medium-sized Python project (5K-20K lines)?</li> <li>How do you organize code by domain vs by layer (models, services, utils)?</li> <li>How strict should you be about import rules (no circular imports, etc.)?</li> <li>When should you split code into separate packages?</li> <li>What does a good test directory structure look like?</li> <li>How do you handle configuration and environment-specific settings?</li> </ul> <p><strong>What I'm trying to achieve:</strong></p> <ul> <li>Make it easy for new developers to understand the codebase</li> <li>Prevent coupling between different parts</li> <li>Make testing straightforward</li> <li>Reduce merge conflicts when multiple people work on it</li> </ul> <p>Do you follow a specific pattern, or make your own rules?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Electrical-Signal858\"> /u/Electrical-Signal858 </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1pccbk4/structure_large_python_projects_for/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1pccbk4/structure_large_python_projects_for/\">[comments]</a></span>",
      "author": "/u/Electrical-Signal858",
      "published_date": "2025-12-02T16:05:15+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 188,
      "reading_time": 1,
      "created_at": "2025-12-02T16:57:05.182747+00:00",
      "updated_at": "2025-12-02T16:57:05.182749+00:00"
    },
    {
      "id": "30da574f63d47691cbe97ee8049b5df2",
      "url": "https://jacobin.com/2025/11/peter-thiel-palantir-apocalypse-antichrist",
      "title": "Peter Thiel's Apocalyptic Worldview Is a Dangerous Fantasy",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46122851\">Comments</a>",
      "author": "",
      "published_date": "2025-12-02T16:23:27+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-02T16:57:03.900230+00:00",
      "updated_at": "2025-12-02T16:57:03.900231+00:00"
    }
  ],
  "recently_processed": [
    {
      "id": "a406e8b4371a12d30d96d387de739736",
      "url": "https://www.sciencedirect.com/science/article/pii/S0006899325006274?dgcid=rss_sd_all",
      "title": "Static and dynamic alterations in local brain activity and their association with dysfunctional connectivity in depressed adolescents with suicide attempts and non-suicidal self-injury",
      "content": "<p>Publication date: 15 January 2026</p><p><b>Source:</b> Brain Research, Volume 1871</p><p>Author(s): Lianlian Yang, Shuai Wang, Zimo Zhou, Zhenru Guo, Shuaiyi Guo, Xiaoshan Gao, Yuanyuan Yang, Yu Xia, Haixia Huang, Jianhua Li, Haohao Zhu, Lin Tian</p>",
      "author": "",
      "published_date": null,
      "source": "Brain Research",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 33,
      "reading_time": 1,
      "created_at": "2025-12-02T17:49:02.580505+00:00",
      "updated_at": "2025-12-02T18:25:20.421832+00:00",
      "metadata": {
        "processed_at": "2025-12-02T18:25:20.421842+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "13dea6cc6634f46b41a55fac1839469d",
      "url": "https://www.sciencedirect.com/science/article/pii/S0006899325006432?dgcid=rss_sd_all",
      "title": "Crosstalk between ApoE-expressing cells and genotoxic stress in the mouse brain",
      "content": "<p>Publication date: 15 January 2026</p><p><b>Source:</b> Brain Research, Volume 1871</p><p>Author(s): Ummay Ayman, Takayoshi Otsuka, Godfried Dougnon, Hideaki Matsui</p>",
      "author": "",
      "published_date": null,
      "source": "Brain Research",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 17,
      "reading_time": 1,
      "created_at": "2025-12-02T17:49:02.580472+00:00",
      "updated_at": "2025-12-02T18:25:20.421846+00:00",
      "metadata": {
        "processed_at": "2025-12-02T18:25:20.421848+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "09929cfc993a571b33540175f583d3fe",
      "url": "https://snoutcover.com/billie-story",
      "title": "I Designed and Printed a Custom Nose Guard to Help My Dog with DLE",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46094460\">Comments</a>",
      "author": "",
      "published_date": "2025-11-30T06:56:33+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-02T17:48:16.443127+00:00",
      "updated_at": "2025-12-02T18:25:20.421851+00:00",
      "metadata": {
        "processed_at": "2025-12-02T18:25:20.421852+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "27acf52f6250fa48328ce9760685d724",
      "url": "https://www.biorxiv.org/content/10.1101/10.64898/2025.11.28.691140v1?rss=1",
      "title": "Lifelong maintenance of locomotion by embryonically active dopamine neurons",
      "content": "Locomotor skills arise early in life and must be maintained throughout the lifespan, yet how this continuity is achieved despite major neural remodeling remains unclear. Using Drosophila, which undergoes complete metamorphosis, we show that dopamine neurons (DANs) are active during the embryonic stage and that this early activity is essential for locomotion across all developmental stages and adulthood. Through stage-specific behavioral assays, optogenetics, in vivo brain imaging, and fluorescent neuronal tracking, we identify a subset of ventral nervous system (VNS) DANs that modulate locomotor function throughout life. Transcriptomic analyses reveal that they maintain expression of developmental transcription factors. Knocking down these factors in post-mitotic VNS DANs impairs adult locomotion. These findings uncover a previously overlooked function for embryonic DANs and suggest that stable locomotion during nervous system maturation relies on persistent developmental regulator expression coupled with structural remodeling.",
      "author": "Padmanabhan, A., Rahman, D., Zhu, R., Khorbtli, S., Sathianathan, S., Le Flohic, B., Assanga Bisse, L., Mollereau, B., Huang, C., Konstantinides, N., Issa, A. R.",
      "published_date": "2025-12-02T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 138,
      "reading_time": 1,
      "created_at": "2025-12-02T17:27:23.147958+00:00",
      "updated_at": "2025-12-02T18:25:20.421854+00:00",
      "metadata": {
        "processed_at": "2025-12-02T18:25:20.421856+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "da418564ae640d5e2532345cbc7c39c2",
      "url": "https://www.biorxiv.org/content/10.1101/10.64898/2025.11.28.689466v1?rss=1",
      "title": "Higher inter-trial latency variability contributes to reduced visual EEG responses in schizophrenia",
      "content": "Patients with schizophrenia show strong impairments in visual backward masking, which are associated with reduced EEG N1 responses. However, it is currently unclear whether reduced N1 amplitudes in patients reflect attenuated neural responses or increased inter-trial latency variability, as both can lead to reduced trial-averaged responses. Previous studies using trial-averaged data cannot distinguish between these two possibilities. Here, we estimated inter-trial latency variability of the visual N1 component and found significantly increased variability in patients compared to controls. Inter-trial latency-variability was a strong predictor of the N1 amplitude in both groups. Importantly, after accounting for the effect of latency variability in the group comparison, patients continued to exhibit significantly reduced N1 amplitudes, although the effect size diminished from large to medium. These findings indicate that both higher latency variability and attenuated neural responses contribute to visual processing deficits in schizophrenia.",
      "author": "Gordillo, D., da Cruz, J. R., Brand, A., Chkonia, E., Roinishvili, M., Figueiredo, P., Herzog, M. H.",
      "published_date": "2025-12-02T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 140,
      "reading_time": 1,
      "created_at": "2025-12-02T17:27:23.147928+00:00",
      "updated_at": "2025-12-02T18:25:20.421858+00:00",
      "metadata": {
        "processed_at": "2025-12-02T18:25:20.421859+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "3d370217cb4a351bb54e7854066e15c3",
      "url": "https://erpinfo.org/blog/2024/2/4/optimal-filters",
      "title": "New Papers: Optimal Filter Settings for ERP Research",
      "content": "<p class=\"\">Zhang, G., Garrett, D. R., &amp; Luck, S. J. (in press). Optimal filters for ERP research I: A general approach for selecting filter settings. <em>Psychophysiology</em>. <a href=\"https://doi.org/10.1111/psyp.14531\"><span>https://doi.org/10.1111/psyp.14531</span></a> [<a href=\"https://www.researchgate.net/publication/377773270_Optimal_filters_for_ERP_research_I_A_general_approach_for_selecting_filter_settings\"><span>preprint</span></a>]</p><p class=\"\">Zhang, G., Garrett, D. R., &amp; Luck, S. J. (in press). Optimal filters for ERP research II: Recommended settings for seven common ERP components. <em>Psychophysiology</em>. <a href=\"https://doi.org/10.1111/psyp.14530\"><span>https://doi.org/10.1111/psyp.14530</span></a> [<a href=\"https://www.researchgate.net/publication/377766656_Optimal_filters_for_ERP_research_II_Recommended_settings_for_seven_common_ERP_components\"><span>preprint</span></a>]</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n                \n                \n                \n                \n                \n                \n                \n                <img alt=\"\" height=\"1490\" src=\"https://images.squarespace-cdn.com/content/v1/5abefa62d274cb16de90e935/d64086cc-e3b4-457d-89df-08d9b3f96439/Filter_Table.png?format=1000w\" width=\"2062\" />\n\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n\n  <p class=\"\">What filter settings should you apply to your ERP data? If your filters are too weak to attenuate the noise in your data, your effects may not be statistically significant. If your filters are too strong, they may create artifactual peaks that lead you to draw bogus conclusions.</p><p class=\"\">For years, I have been recommending a bandpass of 0.1\u201330 Hz for most cognitive and affective research in neurotypical young adults. In this kind of research, I have found that filtering from 0.1\u201330 Hz usually does a good job of minimizing noise while creating minimal waveform distortion. </p><p class=\"\">However, this recommendation was based on a combination of informal observations from many experimental paradigms and a careful examination of a couple paradigms, so it was a bit hand-wavy. In addition, the optimal filter settings will depend on the waveshape of the ERP effects and the nature of the noise in a given study, so I couldn\u2019t make any specific recommendations about other experimental paradigms and participant populations. Moreover, different filter settings may be optimal for different scoring methods (e.g., mean amplitude vs. peak amplitude vs. peak latency).</p><p class=\"\">Guanghui Zhang, David Garrett, and I spent the last year focusing on this issue. First we developed a general method that can be used to determine the optimal filter settings for a given dataset and scoring method (see <a href=\"https://doi.org/10.1111/psyp.14531\"><span>this paper</span></a>). Then we applied this method to the <a href=\"https://doi.org/10.1016/j.neuroimage.2020.117465\"><span>ERP CORE</span></a> data to determine the optimal filter settings for the N170, MMN, P3b, N400, N2pc, LRP, and ERN components in neurotypical young adults (see <a href=\"https://doi.org/10.1111/psyp.14530\"><span>this paper</span></a> and the table above).</p><p class=\"\">If you are doing research with these components (or similar components) in neurotypical young adults, you can simply use the filter settings that we identified. If you are using a very different paradigm or testing a very different subject population, you can apply our method to your own data to find the optimal settings. We added some new tools to <a href=\"https://github.com/ucdavis/erplab\"><span>ERPLAB Toolbox</span></a> to make this easier.</p><p class=\"\">One thing that we discovered was that our old recommendation of 0.1\u201330 Hz does a good job of avoiding filter artifacts but is overly conservative for some components. For example, we can raise the low end to 0.5 Hz when measuring N2pc and MMN amplitudes, which gets rid of more noise without producing problematic waveform distortions. And we can go all the way up to 0.9 Hz for the N170 component. However, later/slower components like P3b and N400 require lower cutoffs (no higher than 0.2 Hz).</p><p class=\"\">You might be wondering how we defined the \u201coptimal\u201d filter settings. At one level, the answer is simple: The optimal filter is the one that maximizes the signal-to-noise ratio without producing too much waveform distortion. The complexities arise in quantifying the signal-to-noise ratio, quantifying the waveform distortion, and deciding how much waveform distortion is \u201ctoo much\u201d. We believe we have found reasonably straightforward and practical solutions to these problems, which you can read about in the published papers.</p>",
      "author": "Steve Luck",
      "published_date": "2024-02-04T23:46:20+00:00",
      "source": "Erp Boot Camp",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 568,
      "reading_time": 2,
      "created_at": "2025-12-02T15:47:30.420488+00:00",
      "updated_at": "2025-12-02T16:21:46.915831+00:00",
      "metadata": {
        "processed_at": "2025-12-02T16:21:46.915841+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "b3cd4fc4257e4deef4e24f2c3cdd8b67",
      "url": "https://brain.ieee.org/publications/neuroethics-framework/education/education-social-and-cultural-issues/education-social-and-cultural-issues/",
      "title": "Education: Social and Cultural Issues",
      "content": "Devices that therapeutically aid users with cognitive and learning disabilities/differences should not be equally applied to a general population seeking learning advantages. It must not be assumed that therapies able to improve cognition for mental and cognitive disorders (such as executive control and working memory) would work similarly on nondisabled people linearly to improve their cognition above standard levels. Although ...",
      "author": "Adriel Carridice",
      "published_date": "2025-02-05T15:45:23+00:00",
      "source": "Brain",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 61,
      "reading_time": 1,
      "created_at": "2025-12-02T15:47:27.874870+00:00",
      "updated_at": "2025-12-02T16:21:46.915845+00:00",
      "metadata": {
        "processed_at": "2025-12-02T16:21:46.915847+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "ecf1276cfb1b592a6d881c4dd471be33",
      "url": "https://www.sciencedirect.com/science/article/pii/S030645222501125X?dgcid=rss_sd_all",
      "title": "In vitro identification of kainic acid-induced, concentration-dependent responses in human cortical neuronal networks",
      "content": "<p>Publication date: 9 January 2026</p><p><b>Source:</b> Neuroscience, Volume 592</p><p>Author(s): Lotta Isosaari, Oskari Kulta, Satu J\u00e4ntti, Andrey Vinogradov, Elena Perez Morrissey, Ina Woods, Rachel Stewart, Jouni Sirvi\u00f6, Fikret Emre Kapucu, Jochen H.M. Prehn, Susanna Narkilahti</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroscience Journal",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 33,
      "reading_time": 1,
      "created_at": "2025-12-02T15:47:12.406416+00:00",
      "updated_at": "2025-12-02T16:21:46.915850+00:00",
      "metadata": {
        "processed_at": "2025-12-02T16:21:46.915851+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "4b11e46560dc5a82a154c422489e93a5",
      "url": "https://www.sciencedirect.com/science/article/pii/S0306452225011236?dgcid=rss_sd_all",
      "title": "Electroacupuncture alleviates chemotherapy-induced peripheral neuropathy and anxiety by reducing TRPC6/PKC-dependent activation of glutamatergic neurons in the paraventricular thalamic nucleus",
      "content": "<p>Publication date: 9 January 2026</p><p><b>Source:</b> Neuroscience, Volume 592</p><p>Author(s): Yi-Yang Jiang, Xue Li, Feng-Xian Hu, Dan-Ni Wang, Ji-Miao Zang, Zhen-Ling Liu, Fei Xu, Wen-Qiang Cui</p>",
      "author": "",
      "published_date": null,
      "source": "Neuroscience Journal",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 24,
      "reading_time": 1,
      "created_at": "2025-12-02T15:47:12.406394+00:00",
      "updated_at": "2025-12-02T16:21:46.915854+00:00",
      "metadata": {
        "processed_at": "2025-12-02T16:21:46.915855+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "1184e18a9d9bdbdbc8e7960f5454cc2f",
      "url": "https://www.nature.com/articles/s41593-025-02184-x",
      "title": "Author Correction: Projectome-based characterization of hypothalamic peptidergic neurons in male mice",
      "content": "<p>Nature Neuroscience, Published online: 02 December 2025; <a href=\"https://www.nature.com/articles/s41593-025-02184-x\">doi:10.1038/s41593-025-02184-x</a></p>Author Correction: Projectome-based characterization of hypothalamic peptidergic neurons in male mice",
      "author": "Xiaohong Xu",
      "published_date": "2025-12-02T00:00:00+00:00",
      "source": "Nature Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 19,
      "reading_time": 1,
      "created_at": "2025-12-02T15:47:06.846805+00:00",
      "updated_at": "2025-12-02T16:21:46.915858+00:00",
      "metadata": {
        "processed_at": "2025-12-02T16:21:46.915859+00:00",
        "processing_method": "github_actions"
      }
    }
  ]
}