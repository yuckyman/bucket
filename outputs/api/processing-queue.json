{
  "last_updated": "2025-12-16T20:19:12.505276+00:00",
  "pending_count": 709,
  "processed_count": 291,
  "pending_articles": [
    {
      "id": "c269b028afba4d3a70907e9a5b4c9bd7",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.12.694017v1?rss=1",
      "title": "Diffusion-weighted steady-state free precession imaging in the ex vivo macaque brain on a 10.5T human MRI scanner",
      "content": "Diffusion MRI provides a non-invasive probe of local fibre bundles and long-range anatomical connections to characterise the structural connectome. One way to achieve very high spatial resolution diffusion MRI data for connectivity investigations is to scan ex-vivo brains over many hours or days, ideally at ultra-high field strength to boost signal levels. However, conventional diffusion MRI acquisition techniques do not generally deliver good data quality for the challenging conditions of ex-vivo tissue, characterised by reduced diffusivities and relaxation times when compared to in vivo. In this work, we investigate the potential of the diffusion-weighted steady-state free precession (DW-SSFP) sequence for ex vivo diffusion imaging of the macaque brain using a 10.5 T human MRI scanner with a conventional (G_max=70 mT/m) gradient set. SNR-efficiency optimisations incorporating experimental relaxation times demonstrate that the DW-SSFP sequence is predicted to achieve improved or similar SNR efficiency compared to a diffusion-weighted spin- and stimulated-echo sequence. Importantly, DW-SSFP can achieve this with the additional benefit of negligible geometric distortions, unlike conventional diffusion MRI using an echo-planar imaging readout. Using optimised DW-SSFP sequence parameters, we propose a protocol at 0.4 mm isotropic resolution using a two-shell multi-orientation protocol (effective b-values of 3200 s/mm^2 and 5600 s/mm^2). We fit the data using Tensor, Ball and 3-Sticks and Constrained Spherical Deconvolution signal representations. The results demonstrate high-quality diffusivity estimates across the entire brain with the ability to resolve multiple fibre populations in challenging crossing-fibre regions. The data will be made fully open source and multimodal as part of the Center for Mesoscale Connectomics, providing a resource for future connectivity investigations.",
      "author": "Tendler, B. C., Warrington, S., Selim, M. K., Wu, W., Adriany, G., Auerbach, E. J., Bratch, A., Farooq, H., Harel, N., Heilbronner, S., Jbabdi, S., Jungst, S., Lenglet, C., Manea, A. M., Moeller, S., Pestilli, F., Pisharady, P. K., Ugurbil, K., Waks, M., Yacoub, E., Sotiropoulos, S. N., Miller, K. L., Zimmermann, J.",
      "published_date": "2025-12-16T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 261,
      "reading_time": 1,
      "created_at": "2025-12-16T19:20:47.650652+00:00",
      "updated_at": "2025-12-16T19:20:47.650656+00:00"
    },
    {
      "id": "86240da3eaca0f7ab44548529db5e4cd",
      "url": "https://www.frontiersin.org/articles/10.3389/fnbot.2025.1628368",
      "title": "A simple robot suggests trunk rotation is essential for emergence of inside leading limb during quadruped galloping turns",
      "content": "During turning maneuvers in the galloping gait of quadruped animals, a strong relationship exists between the turning direction and the sequence in which the forelimbs make ground contact: the outer forelimb acts as the \u201ctrailing limb\u201d while the inner forelimb serves as the \u201cleading limb.\u201d However, the control mechanisms underlying this behavior remain largely unclear. Understanding these mechanisms could deepen biological knowledge and assist in developing more agile robots. To address this issue, we hypothesized that decentralized interlimb coordination mechanism and trunk movement are essential for the emergence of an inside leading limb in a galloping turn. To test the hypothesis, we developed a quasi-quadruped robot with simplified wheeled hind limbs and variable trunk roll and yaw angles. For forelimb coordination, we implemented a simple decentralized control based on local load-dependent sensory feedback, utilizing trunk roll inclination and yaw bending as turning methods. Our experimental results confirmed that in addition to the decentralized control from previous studies which reproduces animal locomotion in a straight line, adjusting the trunk roll angle spontaneously generates a ground contact sequence similar to gallop turning in quadruped animals. Furthermore, roll inclination showed a greater influence than yaw bending on differentiating the leading and trailing limbs. This study suggests that physical interactions serve as a universal mechanism of locomotor control in both forward and turning movements of quadrupedal animals.",
      "author": "Akio Ishiguro",
      "published_date": "2025-10-23T00:00:00+00:00",
      "source": "Frontiers Neurorobotics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 223,
      "reading_time": 1,
      "created_at": "2025-12-16T19:20:35.096000+00:00",
      "updated_at": "2025-12-16T19:20:35.096001+00:00"
    },
    {
      "id": "7d358a50de2869f89d49bd22afee1514",
      "url": "https://www.frontiersin.org/articles/10.3389/fnbot.2025.1705970",
      "title": "Effective and efficient self-supervised masked model based on mixed feature training",
      "content": "Under the influence of Masked Language Modeling (MLM), Masked Image Modeling (MIM) employs an attention mechanism to perform masked training on images. However, processing a single image requires numerous iterations and substantial computational resources to reconstruct the masked regions, resulting in high computational complexity and significant time costs. To address this issue, we propose an Effective and Efficient self-supervised Masked model based on Mixed feature training (EESMM). First, we stack two images for encoding and input the fused features into the network, which not only reduces computational complexity but also enables the learning of more features. Second, during decoding, we obtain the decoding features corresponding to the original images based on the decoding features of the two input original images and the mixed images, and then construct a corresponding loss function to enhance feature representation. EESMM significantly reduces pre-training time without sacrificing accuracy, achieving 83% accuracy on ImageNet in just 363 h using four V100 GPUs\u2013only one-tenth of the training time required by SimMIM. This validates that the method can substantially accelerate the pre-training process without noticeable performance degradation.",
      "author": "Chunliu Cai",
      "published_date": "2025-10-30T00:00:00+00:00",
      "source": "Frontiers Neurorobotics",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 179,
      "reading_time": 1,
      "created_at": "2025-12-16T19:20:35.095961+00:00",
      "updated_at": "2025-12-16T19:20:35.095963+00:00"
    },
    {
      "id": "d5712b4c08069aedc8fb4517ff297159",
      "url": "https://www.reddit.com/r/Python/comments/1po9n17/whatsapp_wrapped_with_polars_plotly_analyze_chat/",
      "title": "WhatsApp Wrapped with Polars & Plotly: Analyze chat history locally",
      "content": "<!-- SC_OFF --><div class=\"md\"><p>I've always wanted something like Spotify Wrapped but for WhatsApp. There are some tools out there that do this, but every one I found either runs your chat history on their servers or is closed source. I wasn't comfortable with all that, so this year I built my own.</p> <h2>What My Project Does</h2> <p>WhatsApp Wrapped generates visual reports for your group chats. You export your chat from WhatsApp (without media), run it through the tool, and get an HTML report with analytics. Everything runs locally or in your own Colab session. Nothing gets sent anywhere.</p> <p><a href=\"https://duelion.github.io/whatsapp-wrapped/sample_report.html\">Here is a Sample Report.</a></p> <p>Features include message counts, activity patterns, emoji stats, word clouds, and calendar heatmaps. The easiest way to use it is through <a href=\"https://colab.research.google.com/github/Duelion/whatsapp-wrapped/blob/main/whatsapp_wrapped.ipynb\">Google Colab</a> - just upload your chat export and download the report. There's also a CLI for local use.</p> <h2>Target Audience</h2> <p>Anyone who wants to analyze their WhatsApp chats without uploading them to someone else's server. It's ready to use now.</p> <h2>Comparison</h2> <p>Unlike other web tools that require uploading your data, this runs entirely on your machine (or your own Colab). It's also open source, so you can see exactly what it does with your chats.</p> <p><strong>Tech:</strong> Python, Polars, Plotly, Jinja2.</p> <p><strong>Links:</strong> - <a href=\"https://github.com/Duelion/whatsapp-wrapped\">GitHub</a> - <a href=\"https://duelion.github.io/whatsapp-wrapped/sample_report.html\">Sample Report</a> - <a href=\"https://colab.research.google.com/github/Duelion/whatsapp-wrapped/blob/main/whatsapp_wrapped.ipynb\">Google Colab</a></p> <p>Happy to answer questions or hear feedback.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Duelion\"> /u/Duelion </a> <br /> <span><a href=\"https://www.reddit.com/r/Python/comments/1po9n17/whatsapp_wrapped_with_polars_plotly_analyze_chat/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/Python/comments/1po9n17/whatsapp_wrapped_with_polars_plotly_analyze_chat/\">[comments]</a></span>",
      "author": "/u/Duelion",
      "published_date": "2025-12-16T18:31:47+00:00",
      "source": "Reddit Python",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 244,
      "reading_time": 1,
      "created_at": "2025-12-16T19:20:05.865974+00:00",
      "updated_at": "2025-12-16T19:20:05.865977+00:00"
    },
    {
      "id": "5e1ce8325bff28cb59f77a38f2822b52",
      "url": "https://www.tabulamag.com/p/too-fast-to-think-the-hidden-fatigue",
      "title": "Too Fast to Think: The Hidden Fatigue of AI Vibe Coding",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46292365\">Comments</a>",
      "author": "",
      "published_date": "2025-12-16T18:32:46+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-16T19:20:04.545327+00:00",
      "updated_at": "2025-12-16T19:20:04.545329+00:00"
    },
    {
      "id": "0c9ba65ae63912a4d74af9cf03885736",
      "url": "https://restofworld.org/2025/engineering-graduates-ai-job-losses/",
      "title": "AI is wiping out entry-level tech jobs, leaving graduates stranded",
      "content": "<p>Article URL: <a href=\"https://restofworld.org/2025/engineering-graduates-ai-job-losses/\">https://restofworld.org/2025/engineering-graduates-ai-job-losses/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46291504\">https://news.ycombinator.com/item?id=46291504</a></p>\n<p>Points: 54</p>\n<p># Comments: 42</p>",
      "author": "cratermoon",
      "published_date": "2025-12-16T17:37:41+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-16T19:20:03.454022+00:00",
      "updated_at": "2025-12-16T19:20:03.454024+00:00"
    },
    {
      "id": "5e1ce8325bff28cb59f77a38f2822b52",
      "url": "https://www.tabulamag.com/p/too-fast-to-think-the-hidden-fatigue",
      "title": "Too Fast to Think: The Hidden Fatigue of AI Vibe Coding",
      "content": "<p>Article URL: <a href=\"https://www.tabulamag.com/p/too-fast-to-think-the-hidden-fatigue\">https://www.tabulamag.com/p/too-fast-to-think-the-hidden-fatigue</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46292365\">https://news.ycombinator.com/item?id=46292365</a></p>\n<p>Points: 33</p>\n<p># Comments: 19</p>",
      "author": "rom16384",
      "published_date": "2025-12-16T18:32:46+00:00",
      "source": "Hacker News",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-16T19:20:03.453990+00:00",
      "updated_at": "2025-12-16T19:20:03.453999+00:00"
    },
    {
      "id": "656586d609ab755e5f17cdf511215517",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.12.694014v1?rss=1",
      "title": "Rehabilitation drives functional reorganization of intact corticospinal-supraspinal projections following partial spinal cord injury",
      "content": "Spinal cord injury (SCI) disrupts corticospinal tract (CST) connectivity and impairs skilled voluntary movement, yet most human SCIs are anatomically incomplete, allowing spared CST pathways to engage in rehabilitation-mediated plasticity to promote functional recovery. How voluntary rehabilitation engages and reorganizes the supraspinal targets of the intact CST remains incompletely understood. Here, we combined unilateral pyramidotomy (uPyX) in male and female mice with continuous voluntary complex-wheel running to test whether fine motor-dependent rehabilitation drives supraspinal CST plasticity. uPyX mice rapidly resumed wheel running after a transient deficit. In contrast to lesion-only controls, rehabilitation significantly improved skilled forelimb performance on the horizontal ladder rung task. Immunohistochemical c-Fos labeling confirmed that complex-wheel running robustly activated the intact forelimb CST in motor cortex. Whole-brain CST projection mapping using intersectional viral vector tracing revealed targeted supraspinal reorganization localized to medullary motor nuclei. Three nuclei - the lateral paragigantocellular reticular nucleus (LPGi), gigantocellular reticular nucleus, alpha part (GiA), and ventral medullary reticular nucleus (MdV) - exhibited significant lesion- and/or rehabilitation-induced increases in CST innervation. Rehabilitation-driven CST sprouting correlated with regional c-Fos activation, indicating activity-dependent remodeling. Notably, CST projection density in the MdV, critical for skilled forelimb control, predicted functional recovery. These findings identify a set of spinally-projecting medullary nuclei as key substrates for rehabilitation-induced CST plasticity and highlight the MdV as a potential mediator of restored motor function. This work defines how voluntary rehabilitation reorganizes spared corticospinal pathways and provides targets for optimizing activity-based interventions after SCI.",
      "author": "Bonanno, J. L., Trivedi, S., O'Brien, C. F., Saha, S., Cafferty, W. B. J.",
      "published_date": "2025-12-16T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 241,
      "reading_time": 1,
      "created_at": "2025-12-16T18:34:35.385567+00:00",
      "updated_at": "2025-12-16T18:34:35.385569+00:00"
    },
    {
      "id": "68f615e8dae888dccad300334655f440",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.12.694005v1?rss=1",
      "title": "Mechanical Ventilation Suppresses Glymphatic Function in Parallel with Delirium-Like Symptoms in Mice",
      "content": "Delirium is a frequent and serious complication in intensive care patients, arising from overlapping vulnerabilities that obscure its primary causes. Using healthy mice, we tested whether mechanical ventilation combined with inhalation anesthetics and opioid sedation is sufficient to induce delirium-like behavior through disruption of cerebrospinal fluid (CSF) glymphatic dynamics. We found that ventilation acutely increased intracranial pressure and induced a long-lasting suppression of glymphatic transport, thereby re-routing and impairing brain waste clearance and promoting cytokine accumulation. These observations establish a mechanistic link between ventilator-associated alterations in brain fluid dynamics and delirium. Our findings identify glymphatic dysfunction and disturbed CSF flow as contributors to acute brain dysfunction following mechanical ventilation and suggest that therapies enhancing glymphatic flux or stabilizing intracranial pressure could reduce delirium incidence and severity in critically ill patients.",
      "author": "Liu, G., Wang, J., Tong, T., Arbanas, L. G., Liang, S., Newbold, E., Kroesbergen, E., Christian Boesen, H., Nedergaard, M., Du, T.",
      "published_date": "2025-12-16T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 130,
      "reading_time": 1,
      "created_at": "2025-12-16T18:34:35.385522+00:00",
      "updated_at": "2025-12-16T18:34:35.385524+00:00"
    },
    {
      "id": "94e4ae0c8be9a8cfdcc5bf7a72b59b53",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.12.693987v1?rss=1",
      "title": "Moderate prenatal alcohol exposure differentially alters acute ethanol sensitivity of GABAergic transmission in CRFR1- and CRFR1+ CeM neurons",
      "content": "Prenatal exposure to alcohol (PAE) increases the risk for misusing alcohol and/or developing an alcohol use disorder (AUD) by adulthood. The corticotropin releasing factor (CRF) system is a major target of pre- and post-natal ethanol (EtOH) exposure. CRF and its receptor (CRFR1), in part, mediate EtOH potentiated GABA release in the medial nucleus of the central amygdala (CeM) of adult male rodents. Interestingly, our lab has shown a disruption in the function and expression of CeM CRFR1 and acute EtOH's effects on GABA transmission in PAE adolescent animals, but it is unknown whether these alterations to the CRF system persist into adulthood or alter the actions of acute EtOH on GABAergic transmission in the CeM. Using CRF1-Cre-tdTomato rats, this study examined how moderate PAE alters acute EtOH modulation of GABAergic neurotransmission onto CRFR1+ and CRFR1- CeM neurons in adult offspring (P80-105). Pregnant dams were exposed to vaporized ethanol or room air (control) on gestational day 12 (G12) for 6 hours and whole-cell electrophysiology was performed in the CeM to assess the actions of acute EtOH (44, 66, & 88 mM) on GABAergic transmission onto CRFR1+ and CRFR1- neurons. We found unique effects of PAE that were cell type- and concentration-dependent in males and females, suggesting PAE dysregulates acute EtOH's modulation of GABA transmission within the CeM in a sex-specific manner. This study contributes to the expanding body of research exploring the effects of PAE and how a single exposure can impact neurophysiological mechanisms in brain regions associated with AUD.",
      "author": "Winchester, S., Diaz, M. R.",
      "published_date": "2025-12-16T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "pending",
      "priority": "medium",
      "tags": [],
      "word_count": 249,
      "reading_time": 1,
      "created_at": "2025-12-16T18:34:35.385484+00:00",
      "updated_at": "2025-12-16T18:34:35.385490+00:00"
    }
  ],
  "recently_processed": [
    {
      "id": "8a9c0b017ef432760f79b366ba5fce6d",
      "url": "https://yaschamounk.substack.com/p/the-world-happiness-report-is-a-sham",
      "title": "The World Happiness Report is beset with methodological problems",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46282874\">Comments</a>",
      "author": "",
      "published_date": "2025-12-16T00:06:49+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-16T19:40:13.526930+00:00",
      "updated_at": "2025-12-16T20:19:12.398877+00:00",
      "metadata": {
        "processed_at": "2025-12-16T20:19:12.398885+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "70c3599ef4230afa7a8f6864c560fc6a",
      "url": "https://www.drawize.com/",
      "title": "Show HN: My Tizen multiplayer drawing game flopped, but then hit 100M drawings",
      "content": "<p>Hi HN,<p>I built the first version of Drawize back in late 2016 specifically for a Samsung Tizen OS app contest. I crunched and built the whole thing (including the real-time multiplayer engine) in under 4 weeks.<p>It didn\u2019t win anything in the contest.<p>Since it was built with web tech anyway, I published it on the open web in early 2017 just to see what would happen. It started living its own life, and today \u2014 8 years later \u2014 the database processed the 100,000,000th drawing.<p>On the busiest days it\u2019s been 30k+ active users, and storing 100M drawings currently sits at ~3.16 TB.<p>The milestone moment: I was watching live logs today, terrified the 100Mth drawing would be NSFW. Luckily, the RNG gods smiled and it turned out to be a Red Balloon \n(You can see the 100Mth drawing here: <a href=\"https://www.drawize.com/blog/100-million-drawings-milestone\" rel=\"nofollow\">https://www.drawize.com/blog/100-million-drawings-milestone</a>)<p>Tech stack (boring but fast):<p>Backend: .NET + WebSockets (real-time sync)<p>Frontend: hand-coded HTML/JS + jQuery (no React, no bundlers)<p>Data: PostgreSQL & MongoDB<p>Storage: Wasabi Cloud (moved there to save on S3 costs)<p>Scaling as a solo dev: real-time lobbies + reconnection edge cases + moderation/content filtering. I use content classification models trained in 2021 to filter bad content, and the real-time multiplayer side is mostly highly optimized .NET code.<p>Happy to answer questions about the \u201cfailed\u201d Tizen origin, real-time multiplayer on the web, moderation, or how .NET handles the load.</p>\n<hr />\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46290213\">https://news.ycombinator.com/item?id=46290213</a></p>\n<p>Points: 4</p>\n<p># Comments: 0</p>",
      "author": "lombarovic",
      "published_date": "2025-12-16T16:02:39+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 236,
      "reading_time": 1,
      "created_at": "2025-12-16T19:40:12.186280+00:00",
      "updated_at": "2025-12-16T20:19:12.398890+00:00",
      "metadata": {
        "processed_at": "2025-12-16T20:19:12.398892+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "8cbcf1533bf8f3d5b32624109f0609bb",
      "url": "https://openai.com/index/new-chatgpt-images-is-here/",
      "title": "The new ChatGPT Images is here",
      "content": "<p>Article URL: <a href=\"https://openai.com/index/new-chatgpt-images-is-here/\">https://openai.com/index/new-chatgpt-images-is-here/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46291827\">https://news.ycombinator.com/item?id=46291827</a></p>\n<p>Points: 32</p>\n<p># Comments: 4</p>",
      "author": "meetpateltech",
      "published_date": "2025-12-16T17:58:59+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 13,
      "reading_time": 1,
      "created_at": "2025-12-16T19:40:12.186075+00:00",
      "updated_at": "2025-12-16T20:19:12.398894+00:00",
      "metadata": {
        "processed_at": "2025-12-16T20:19:12.398896+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "24bf764700053bd109520c37d18e0ce3",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.12.694037v1?rss=1",
      "title": "Towards Video-LLM Driven Workflow for Behavioral Segmentation and Scoring in Mice Performing a Skilled Water Reaching Task: An Evaluation of Recent LLM Models",
      "content": "Significance: Behavior scoring is labor-intensive and subjective, introducing variability in results. Large Language Models (LLMs) capable of video understanding offer a transformative solution to manual scoring, crucial for accelerating and standardizing neuroscience workflows. Aim: We sought to benchmark state-of-the-art video LLMs (Gemini 2.5 Pro, Qwen3-VL, and VideoLLaMA3) for automated behavioural segmentation and scoring of mice performing a water-reaching task. Approach: Videos of mice performing water reaching from the front view were analysed by the LLMs. Accuracy was compared across different models and against prompt adjustments within Gemini. To assess classification determinants, video fidelity was altered through pixel interpolation and key regions blurred (paws/snout-mouth). In addition, the models were asked to describe the mouse's actions over time. Results: Gemini 2.5 Pro (Mean: 0.74, SD: 0.12) and Qwen3-VL-30B (Mean: 0.67, SD: 0.13) exhibited ability to classify trial outcomes. Reliable classification required a minimum pixel resolution of 0.28 mm per pixel. Accuracy is significantly reduced upon obscuring the snout-mouth area. In 549/1058 of videos, Gemini 2.5 Pro also provided completely accurate frame-to- frame behaviour segmentations. Conclusions: Video-LLMs offer potential to accelerate neuroscience by providing scalable, objective quantification of goal-directed behaviors. By producing temporal annotations, Gemini enables fast first-pass labelling that markedly streamlines manual dataset curation.",
      "author": "Fong, T. L., Hu, H., Zeng, H., MURPHY, T. H.",
      "published_date": "2025-12-16T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 202,
      "reading_time": 1,
      "created_at": "2025-12-16T19:20:47.650728+00:00",
      "updated_at": "2025-12-16T20:19:12.398898+00:00",
      "metadata": {
        "processed_at": "2025-12-16T20:19:12.398900+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "76d11d77def583b884781f26e3f7066c",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.12.693881v1?rss=1",
      "title": "MRS4Brain: a processing toolbox for preclinical MR spectroscopy and spectroscopic imaging data",
      "content": "Magnetic resonance spectroscopy is a non-invasive technique for probing metabolism and underpins advanced methods such as magnetic resonance spectroscopic imaging (MRSI) and diffusion-weighted spectroscopy (DWS). MRSI enables spatial mapping of metabolite distributions, offering insights into regional metabolic heterogeneity that single-voxel spectroscopy (SVS) cannot capture. However, MRSI produces large multidimensional datasets and requires complex processing pipelines, limiting reproducibility and accessibility. While human studies benefit from advanced processing tools, similar developments in preclinical research remain scarce, highlighting a demand for practical tools accessible to non-experts. To address this need, we introduce the MRS4Brain Toolbox, a freely available MATLAB-based platform for preclinical spectroscopy, including MRSI, SVS, and DWS. The toolbox integrates reconstruction, preprocessing, quantification, quality control, brain segmentation automatically overlaid on metabolite maps, modeling, and statistical analysis into unified workflows accessible via a graphical interface. By streamlining data processing and reducing technical barriers, MRS4Brain Toolbox promotes reproducibility, harmonization, and broader adoption of advanced spectroscopic techniques in preclinical studies, ultimately facilitating translational research.",
      "author": "Alves, B., Phan, T. T., Briand, G., Siviglia, A., Nossa, G., Mosso, J., Mougel, E., Near, J., Dinh, T. N. A., Zenteno, O., Lanz, B., Le, T. P., Cudalbu, C.",
      "published_date": "2025-12-16T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 159,
      "reading_time": 1,
      "created_at": "2025-12-16T19:20:47.650691+00:00",
      "updated_at": "2025-12-16T20:19:12.398902+00:00",
      "metadata": {
        "processed_at": "2025-12-16T20:19:12.398904+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "7f7383292b5f231321c44f48a84ca2bf",
      "url": "https://resources.github.com/actions/2026-pricing-changes-for-github-actions/",
      "title": "Pricing Changes for GitHub Actions",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46291156\">Comments</a>",
      "author": "",
      "published_date": "2025-12-16T17:12:02+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-16T17:48:03.921104+00:00",
      "updated_at": "2025-12-16T18:24:40.811392+00:00",
      "metadata": {
        "processed_at": "2025-12-16T18:24:40.811402+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "7f7383292b5f231321c44f48a84ca2bf",
      "url": "https://resources.github.com/actions/2026-pricing-changes-for-github-actions/",
      "title": "Pricing Changes for GitHub Actions",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46291156\">Comments</a>",
      "author": "",
      "published_date": "2025-12-16T17:12:02+00:00",
      "source": "Hacker News",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 2,
      "reading_time": 1,
      "created_at": "2025-12-16T17:48:03.921104+00:00",
      "updated_at": "2025-12-16T18:24:40.811392+00:00",
      "metadata": {
        "processed_at": "2025-12-16T18:24:40.811402+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "307671786156803b09edaa9705ffbb17",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.12.694050v1?rss=1",
      "title": "People report having consistent idiosyncratic diets of imagined sensations when they re-experience the past, and pre-experience the future",
      "content": "To some extent, humans can re-experience the sensations of past events and pre-experience the future. These capacities are inter-related. But there are substantial individual differences. At the extremes, small minorities of people report that they either cannot have imagined experiences at all, or that their imagined sensations are as real to them as their actual experiences of the physical world. We wanted to know if such individual differences are uniform across different types of imagined experience (e.g. vision, audio, taste and smell), or if people generally have idiosyncratic patterns of different types (vision, audio, taste and smell) of imagined experiences. We find that people report having idiosyncratic diets of different types of imagined sensation, characterised by differences in salience. One person might have more salient imagined visual than taste experiences, while another reports the reverse. Moreover, these propensities are consistent across peoples attempts to re-experience the past, and to pre-experience the future, and they predict peoples experience and usage of different types of imagined sensation in their everyday lives.",
      "author": "Arnold, D. H., Bouyer, L. N., Saurels, B. W., Schwarzkopf, D. S.",
      "published_date": "2025-12-16T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 169,
      "reading_time": 1,
      "created_at": "2025-12-16T17:24:55.980903+00:00",
      "updated_at": "2025-12-16T18:24:40.811411+00:00",
      "metadata": {
        "processed_at": "2025-12-16T18:24:40.811412+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "865bb4fb6df43e59662df4eae14d8639",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.12.694043v1?rss=1",
      "title": "An Interactive Brain Atlas of Knowledge",
      "content": "Biomedical knowledge about the brain increases every day, with a rapidly growing number of scientific publications, datasets, and software tools. While this informational plethora is not merely comprehensible by human beings, recent developments in information science and computational linguistics aim to make this knowledge programmatically accessible by literature mining. However, integrating these semantic methods into neuroimaging standards remains insufficient, hindering researchers from unraveling their full potential. Therefore, we developed the semantic meta-analysis platform The Virtual Brain adapter of semantics (TVBase) that projects biomedical knowledge preserved in over 36 million scientific articles onto a 3D standardized brain. The literature-mining platform SCAIView was used to extract ontologically defined biomedical entities and their associations with brain anatomy from the PubMed database. By querying a specific concept, the association strength with each anatomical term was calculated using entropy. To project the data onto a standardized brain, we created a unique transformation matrix that links over 800 anatomical terms to voxel coordinates of a parcellated standard brain. This novel method of knowledge projection extracts region-specific information about biomedical concepts from the literature to support translational multi-scale approaches to computational neuroscience. The multi-purpose software framework TVBase is openly available as a Python library. It aims for hypothesis-free neuroimaging pattern interpretation, hypothesis generation, and applications in personalized medicine.",
      "author": "Stefanovski, L., Bu\u0308lau, K., Martin, L., Langford, C., Palmer, J., Sacks, M., Deger, L., Pille, M., Schirner, M., Meier, J., Neudorfer, C., Horn, A., Solodkin, A., Thirion, B., Hofmann-Apitius, M., Jacobs, M., Tom Kodamullil, A., for the Alzheimer's Disease Neuroimaging Initiative,, Ritter, P.",
      "published_date": "2025-12-16T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 211,
      "reading_time": 1,
      "created_at": "2025-12-16T17:24:55.980870+00:00",
      "updated_at": "2025-12-16T18:24:40.811414+00:00",
      "metadata": {
        "processed_at": "2025-12-16T18:24:40.811416+00:00",
        "processing_method": "github_actions"
      }
    },
    {
      "id": "f38769bb46e85ec3d3ec660d77ac913b",
      "url": "https://www.biorxiv.org/content/10.64898/2025.12.12.694045v1?rss=1",
      "title": "Projection-specific Routing of Odor Information in the Olfactory Cortex",
      "content": "Sensory processing in the mammalian cortex relies on extensive feedforward and feedback connections, yet how information is routed along these pathways remains poorly understood. Here, we examined the functional properties of feedback and feedforward neurons in the mouse olfactory (piriform) cortex. We selectively labeled neurons projecting to the olfactory bulb (OB, feedback) or medial prefrontal cortex (mPFC, feedforward) and recorded their activity during passive odor exposure and learning of an odor discrimination task. We found that odor identity and reward associations were encoded by OB-projecting ensembles early during odor exposure, whereas mPFC-projecting neurons encoded this information later, aligned with behavioral responses. Moreover, mPFC-projecting neurons maintained a stable representation of valence across days, while OB-projecting neurons exhibited pronounced plasticity. Together, these findings reveal that odor information is selectively routed through feedforward and feedback pathways and suggest that the functional properties of piriform neurons mirror the computational demands of their downstream targets.",
      "author": "Daste, S., Pham, T. H., Seppo, M., Andre, A., Srinivasan, S., Xiao, J., Sattin, A., Nardin, C., Fellin, T., Franks, K., Dyer, E., Fleischmann, A.",
      "published_date": "2025-12-16T00:00:00+00:00",
      "source": "Biorxiv Neuroscience",
      "status": "processed",
      "priority": "medium",
      "tags": [],
      "word_count": 150,
      "reading_time": 1,
      "created_at": "2025-12-16T17:24:55.980830+00:00",
      "updated_at": "2025-12-16T18:24:40.811418+00:00",
      "metadata": {
        "processed_at": "2025-12-16T18:24:40.811420+00:00",
        "processing_method": "github_actions"
      }
    }
  ]
}